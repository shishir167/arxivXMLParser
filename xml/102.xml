<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T04:09:43Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|101001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703148</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703148</id><created>2007-03-29</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author></authors><title>Computer Science and Game Theory: A Brief Survey</title><categories>cs.GT</categories><comments>To appear; Palgrave Dictionary of Economics</comments><abstract>  There has been a remarkable increase in work at the interface of computer
science and game theory in the past decade. In this article I survey some of
the main themes of work in the area, with a focus on the work in computer
science. Given the length constraints, I make no attempt at being
comprehensive, especially since other surveys are also available, and a
comprehensive survey book will appear shortly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703149</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703149</id><created>2007-03-29</created><authors><author><keyname>Teuscher</keyname><forenames>Christof</forenames></author></authors><title>Exploring Logic Artificial Chemistries: An Illogical Attempt?</title><categories>cs.NE nlin.AO</categories><journal-ref>The First IEEE Symposium on Artificial Life, April 1-5, 2007,
  Hawaii, USA</journal-ref><abstract>  Robustness to a wide variety of negative factors and the ability to
self-repair is an inherent and natural characteristic of all life forms on
earth. As opposed to nature, man-made systems are in most cases not inherently
robust and a significant effort has to be made in order to make them resistant
against failures. This can be done in a wide variety of ways and on various
system levels. In the field of digital systems, for example, techniques such as
triple modular redundancy (TMR) are frequently used, which results in a
considerable hardware overhead. Biologically-inspired computing by means of
bio-chemical metaphors offers alternative paradigms, which need to be explored
and evaluated.
  Here, we are interested to evaluate the potential of nature-inspired
artificial chemistries and membrane systems as an alternative information
representing and processing paradigm in order to obtain robust and spatially
extended Boolean computing systems in a distributed environment. We investigate
conceptual approaches inspired by artificial chemistries and membrane systems
and compare proof-of-concepts. First, we show, that elementary logical
functions can be implemented. Second, we illustrate how they can be made more
robust and how they can be assembled to larger-scale systems. Finally, we
discuss the implications for and paths to possible genuine implementations.
Compared to the main body of work in artificial chemistries, we take a very
pragmatic and implementation-oriented approach and are interested in realizing
Boolean computations only. The results emphasize that artificial chemistries
can be used to implement Boolean logic in a spatially extended and distributed
environment and can also be made highly robust, but at a significant price.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703150</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703150</id><created>2007-03-29</created><updated>2009-01-29</updated><authors><author><keyname>Shao</keyname><forenames>Xuancheng</forenames></author><author><keyname>Johnson</keyname><forenames>Steven G.</forenames></author></authors><title>Type-II/III DCT/DST algorithms with reduced number of arithmetic
  operations</title><categories>cs.NA cs.DS cs.MS</categories><comments>9 pages</comments><acm-class>F.2.1</acm-class><journal-ref>Signal Processing vol. 88, issue 6, p. 1553-1564 (2008)</journal-ref><doi>10.1016/j.sigpro.2008.01.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present algorithms for the discrete cosine transform (DCT) and discrete
sine transform (DST), of types II and III, that achieve a lower count of real
multiplications and additions than previously published algorithms, without
sacrificing numerical accuracy. Asymptotically, the operation count is reduced
from ~ 2N log_2 N to ~ (17/9) N log_2 N for a power-of-two transform size N.
Furthermore, we show that a further N multiplications may be saved by a certain
rescaling of the inputs or outputs, generalizing a well-known technique for N=8
by Arai et al. These results are derived by considering the DCT to be a special
case of a DFT of length 4N, with certain symmetries, and then pruning redundant
operations from a recent improved fast Fourier transform algorithm (based on a
recursive rescaling of the conjugate-pair split radix algorithm). The improved
algorithms for DCT-III, DST-II, and DST-III follow immediately from the
improved count for the DCT-II.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703151</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703151</id><created>2007-03-30</created><authors><author><keyname>Gharan</keyname><forenames>Shahab Oveis</forenames></author><author><keyname>Bayesteh</keyname><forenames>Alireza</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>Asymptotic Analysis of Amplify and Forward Relaying in a Parallel MIMO
  Relay Network</title><categories>cs.IT math.IT</categories><abstract>  This paper considers the setup of a parallel MIMO relay network in which $K$
relays, each equipped with $N$ antennas, assist the transmitter and the
receiver, each equipped with $M$ antennas, in the half-duplex mode, under the
assumption that $N\geq{M}$. This setup has been studied in the literature like
in \cite{nabar}, \cite{nabar2}, and \cite{qr}. In this paper, a simple scheme,
the so-called Incremental Cooperative Beamforming, is introduced and shown to
achieve the capacity of the network in the asymptotic case of $K\to{\infty}$
with a gap no more than $O(\frac{1}{\log(K)})$. This result is shown to hold,
as long as the power of the relays scales as $\omega(\frac{\log^9(K)}{K})$.
Finally, the asymptotic SNR behavior is studied and it is proved that the
proposed scheme achieves the full multiplexing gain, regardless of the number
of relays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703152</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703152</id><created>2007-03-30</created><authors><author><keyname>Lago</keyname><forenames>Ugo Dal</forenames></author><author><keyname>Masini</keyname><forenames>Andrea</forenames></author><author><keyname>Zorzi</keyname><forenames>Margherita</forenames></author></authors><title>Quantum Lambda Calculi with Classical Control: Syntax and Expressive
  Power</title><categories>cs.LO</categories><comments>25 pages</comments><acm-class>F.4.1</acm-class><abstract>  We study an untyped lambda calculus with quantum data and classical control.
This work stems from previous proposals by Selinger and Valiron and by Van
Tonder. We focus on syntax and expressiveness, rather than (denotational)
semantics. We prove subject reduction, confluence and a standardization
theorem. Moreover, we prove the computational equivalence of the proposed
calculus with a suitable class of quantum circuit families.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703153</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703153</id><created>2007-03-30</created><authors><author><keyname>Margenstern</keyname><forenames>Maurice</forenames></author></authors><title>The periodic domino problem is undecidable in the hyperbolic plane</title><categories>cs.CG cs.DM</categories><acm-class>F.2.2; G.2.1</acm-class><abstract>  In this paper, we consider the periodic tiling problem which was proved
undecidable in the Euclidean plane by Yu. Gurevich and I. Koriakov in 1972.
Here, we prove that the same problem for the hyperbolic plane is also
undecidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703154</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703154</id><created>2007-03-30</created><updated>2007-07-03</updated><authors><author><keyname>Koch</keyname><forenames>Tobias</forenames></author><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author><author><keyname>Sotiriadis</keyname><forenames>Paul P.</forenames></author></authors><title>A Hot Channel</title><categories>cs.IT math.IT</categories><comments>to be presented at 2007 IEEE Information Theory Workshop (ITW),
  replaced with version that will appear in the proceedings</comments><acm-class>H.1.1</acm-class><abstract>  This paper studies on-chip communication with non-ideal heat sinks. A channel
model is proposed where the variance of the additive noise depends on the
weighted sum of the past channel input powers. It is shown that, depending on
the weights, the capacity can be either bounded or unbounded in the input
power. A necessary condition and a sufficient condition for the capacity to be
bounded are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703155</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703155</id><created>2007-03-30</created><authors><author><keyname>Karkare</keyname><forenames>Amey</forenames></author><author><keyname>Khedker</keyname><forenames>Uday</forenames></author><author><keyname>Sanyal</keyname><forenames>Amitabha</forenames></author></authors><title>Liveness of Heap Data for Functional Programs</title><categories>cs.PL</categories><comments>Accepted at Heap Analysis and Verification workshop (HAV 2007), a
  satellite workshop of ETAPS 2007 (No formal proceedings for workshop); 15
  pages</comments><acm-class>D.3.2; D.3.4</acm-class><abstract>  Functional programming languages use garbage collection for heap memory
management. Ideally, garbage collectors should reclaim all objects that are
dead at the time of garbage collection. An object is dead at an execution
instant if it is not used in future. Garbage collectors collect only those dead
objects that are not reachable from any program variable. This is because they
are not able to distinguish between reachable objects that are dead and
reachable objects that are live.
  In this paper, we describe a static analysis to discover reachable dead
objects in programs written in first-order, eager functional programming
languages. The results of this technique can be used to make reachable dead
objects unreachable, thereby allowing garbage collectors to reclaim more dead
objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0703156</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0703156</id><created>2007-03-30</created><authors><author><keyname>D'Aquin</keyname><forenames>Mathieu</forenames><affiliation>KMI</affiliation></author><author><keyname>Badra</keyname><forenames>Fadi</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Lafrogne</keyname><forenames>Sandrine</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Lieber</keyname><forenames>Jean</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Napoli</keyname><forenames>Amedeo</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Szathmary</keyname><forenames>Laszlo</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Case Base Mining for Adaptation Knowledge Acquisition</title><categories>cs.AI</categories><proxy>ccsd inria-00127347</proxy><journal-ref>Dans Twentieth International Joint Conference on Artificial
  Intelligence - IJCAI'07 (2007) 750--755</journal-ref><abstract>  In case-based reasoning, the adaptation of a source case in order to solve
the target problem is at the same time crucial and difficult to implement. The
reason for this difficulty is that, in general, adaptation strongly depends on
domain-dependent knowledge. This fact motivates research on adaptation
knowledge acquisition (AKA). This paper presents an approach to AKA based on
the principles and techniques of knowledge discovery from databases and
data-mining. It is implemented in CABAMAKA, a system that explores the
variations within the case base to elicit adaptation knowledge. This system has
been successfully tested in an application of case-based reasoning to decision
support in the domain of breast cancer treatment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9301101</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9301101</id><created>2000-09-28</created><authors><author><keyname>Paulson</keyname><forenames>Lawrence C.</forenames></author></authors><title>Verifying the Unification Algorithm in LCF</title><categories>cs.LO</categories><acm-class>D.2.4; F.3.1; F.4.1</acm-class><journal-ref>Science of Computer Programming 5 (1985), 143-170</journal-ref><abstract>  Manna and Waldinger's theory of substitutions and unification has been
verified using the Cambridge LCF theorem prover. A proof of the monotonicity of
substitution is presented in detail, as an example of interaction with LCF.
Translating the theory into LCF's domain-theoretic logic is largely
straightforward. Well-founded induction on a complex ordering is translated
into nested structural inductions. Correctness of unification is expressed
using predicates for such properties as idempotence and most-generality. The
verification is presented as a series of lemmas. The LCF proofs are compared
with the original ones, and with other approaches. It appears difficult to find
a logic that is both simple and flexible, especially for proving termination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9301102</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9301102</id><created>2000-10-30</created><authors><author><keyname>Paulson</keyname><forenames>Lawrence C.</forenames></author></authors><title>Constructing Recursion Operators in Intuitionistic Type Theory</title><categories>cs.LO</categories><acm-class>F.3.1; F.4.1</acm-class><journal-ref>Journal of Symbolic Computation 2 (1986), 325-355</journal-ref><abstract>  Martin-L\&quot;of's Intuitionistic Theory of Types is becoming popular for formal
reasoning about computer programs. To handle recursion schemes other than
primitive recursion, a theory of well-founded relations is presented. Using
primitive recursion over higher types, induction and recursion are formally
derived for a large class of well-founded relations. Included are &lt; on natural
numbers, and relations formed by inverse images, addition, multiplication, and
exponentiation of other relations. The constructions are given in full detail
to allow their use in theorem provers for Type Theory, such as Nuprl. The
theory is compared with work in the field of ordinal recursion over higher
types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9301103</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9301103</id><created>2000-10-01</created><authors><author><keyname>Paulson</keyname><forenames>Lawrence C.</forenames></author></authors><title>Proving Termination of Normalization Functions for Conditional
  Expressions</title><categories>cs.LO</categories><acm-class>F.3.1; F.4.1</acm-class><journal-ref>Journal of Automated Reasoning 2 (1986), 63-74</journal-ref><abstract>  Boyer and Moore have discussed a recursive function that puts conditional
expressions into normal form [1]. It is difficult to prove that this function
terminates on all inputs. Three termination proofs are compared: (1) using a
measure function, (2) in domain theory using LCF, (3) showing that its
recursion relation, defined by the pattern of recursive calls, is well-founded.
The last two proofs are essentially the same though conducted in markedly
different logical frameworks. An obviously total variant of the normalize
function is presented as the `computational meaning' of those two proofs. A
related function makes nested recursive calls. The three termination proofs
become more complex: termination and correctness must be proved simultaneously.
The recursion relation approach seems flexible enough to handle subtle
termination proofs where previously domain theory seemed essential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9301104</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9301104</id><created>2000-10-30</created><authors><author><keyname>Paulson</keyname><forenames>Lawrence C.</forenames></author></authors><title>Natural Deduction as Higher-Order Resolution</title><categories>cs.LO</categories><acm-class>D.2.4; F.3.1; F.4.1</acm-class><journal-ref>Journal of Logic Programming 3 (1986), 237-258</journal-ref><abstract>  An interactive theorem prover, Isabelle, is under development. In LCF, each
inference rule is represented by one function for forwards proof and another (a
tactic) for backwards proof. In Isabelle, each inference rule is represented by
a Horn clause. Resolution gives both forwards and backwards proof, supporting a
large class of logics. Isabelle has been used to prove theorems in
Martin-L\&quot;of's Constructive Type Theory. Quantifiers pose several difficulties:
substitution, bound variables, Skolemization. Isabelle's representation of
logical syntax is the typed lambda-calculus, requiring higher- order
unification. It may have potential for logic programming. Depth-first
subgoaling along inference rules constitutes a higher-order Prolog.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9301105</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9301105</id><created>2000-10-30</created><authors><author><keyname>Paulson</keyname><forenames>Lawrence C.</forenames></author></authors><title>The Foundation of a Generic Theorem Prover</title><categories>cs.LO</categories><acm-class>F.3.1; F.4.1</acm-class><journal-ref>Journal of Automated Reasoning 5 (1989), 363-397</journal-ref><abstract>  Isabelle is an interactive theorem prover that supports a variety of logics.
It represents rules as propositions (not as functions) and builds proofs by
combining rules. These operations constitute a meta-logic (or `logical
framework') in which the object-logics are formalized. Isabelle is now based on
higher-order logic -- a precise and well-understood foundation. Examples
illustrate use of this meta-logic to formalize logics and proofs. Axioms for
first-order logic are shown sound and complete. Backwards proof is formalized
by meta-reasoning about object-level entailment. Higher-order logic has several
practical advantages over other meta-logics. Many proof techniques are known,
such as Huet's higher-order unification procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9301106</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9301106</id><created>2000-10-30</created><authors><author><keyname>Paulson</keyname><forenames>Lawrence C.</forenames></author></authors><title>Isabelle: The Next 700 Theorem Provers</title><categories>cs.LO</categories><acm-class>F.3.1; F.4.1</acm-class><journal-ref>published in P. Odifreddi (editor), Logic and Computer Science
  (Academic Press, 1990), 361-386</journal-ref><abstract>  Isabelle is a generic theorem prover, designed for interactive reasoning in a
variety of formal theories. At present it provides useful proof procedures for
Constructive Type Theory, various first-order logics, Zermelo-Fraenkel set
theory, and higher-order logic. This survey of Isabelle serves as an
introduction to the literature. It explains why generic theorem proving is
beneficial. It gives a thorough history of Isabelle, beginning with its origins
in the LCF system. It presents an account of how logics are represented,
illustrated using classical logic. The approach is compared with the Edinburgh
Logical Framework. Several of the Isabelle object-logics are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9301107</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9301107</id><created>2000-10-30</created><authors><author><keyname>Paulson</keyname><forenames>Lawrence C.</forenames></author></authors><title>A Formulation of the Simple Theory of Types (for Isabelle)</title><categories>cs.LO</categories><acm-class>F.3.1; F.4.1</acm-class><journal-ref>published in P. Martin-L\&quot;of &amp; G. Mints (editors), COLOG-88:
  International Conf. in Computer Logic (Springer LNCS 417, 1990), 246-274</journal-ref><abstract>  Simple type theory is formulated for use with the generic theorem prover
Isabelle. This requires explicit type inference rules. There are function,
product, and subset types, which may be empty. Descriptions (the eta-operator)
introduce the Axiom of Choice. Higher-order logic is obtained through
reflection between formulae and terms of type bool. Recursive types and
functions can be formally constructed. Isabelle proof procedures are described.
The logic appears suitable for general mathematics as well as computational
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9301108</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9301108</id><created>2001-03-28</created><authors><author><keyname>Paulson</keyname><forenames>Lawrence C.</forenames></author></authors><title>A Higher-Order Implementation of Rewriting</title><categories>cs.LO</categories><acm-class>D.1.1, D.2.4, F.4.1</acm-class><journal-ref>Science of Computer Programming 3 (1983), 119-149</journal-ref><abstract>  Many automatic theorem-provers rely on rewriting.  Using theorems as rewrite
rules helps to simplify the subgoals that arise during a proof.
  LCF is an interactive theorem-prover intended for reasoning about
computation.  Its implementation of rewriting is presented in detail.  LCF
provides a family of rewriting functions, and operators to combine them.  A
succession of functions is described, from pattern matching primitives to the
rewriting tool that performs most inferences in LCF proofs.
  The design is highly modular.  Each function performs a basic, specific task,
such as recognizing a certain form of tautology.  Each operator implements one
method of building a rewriting function from simpler ones.  These pieces can
be put together in numerous ways, yielding a variety of rewrit- ing
strategies.
  The approach involves programming with higher-order functions.  Rewriting
functions are data values, produced by computation on other rewriting
functions.  The code is in daily use at Cambridge, demonstrating the practical
use of functional programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9301109</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9301109</id><created>2001-03-28</created><authors><author><keyname>Paulson</keyname><forenames>Lawrence C.</forenames></author><author><keyname>Smith</keyname><forenames>Andrew W.</forenames></author></authors><title>Logic Programming, Functional Programming, and Inductive Definitions</title><categories>cs.LO</categories><acm-class>D.1.1, D.1.6</acm-class><journal-ref>published in P. Schroeder-Heister (editor), Extensions of Logic
  Programming (Springer, 1991), 283-310</journal-ref><abstract>  An attempt at unifying logic and functional programming is reported.  As a
starting point, we take the view that &quot;logic programs&quot; are not about logic but
constitute inductive definitions of sets and relations.  A skeletal language
design based on these considerations is sketched and a prototype implementation
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9301110</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9301110</id><created>2001-03-28</created><authors><author><keyname>Paulson</keyname><forenames>Lawrence C.</forenames></author></authors><title>Designing a Theorem Prover</title><categories>cs.LO</categories><acm-class>F.4.1, I.2.3, D.1.1</acm-class><journal-ref>published in S. Abramsky, D. M. Gabbay, T. S. E. Maibaum
  (editors), Handbook of Logic in Computer Science, Vol II (Oxford, 1992),
  415-475</journal-ref><abstract>  A step-by-step presentation of the code for a small theorem prover introduces
theorem-proving techniques.  The programming language used is Standard ML. The
prover operates on a sequent calculus formulation of first-order logic, which
is briefly explained.  The implementation of unification and logical inference
is shown.  The prover is demonstrated on several small examples, including
one that shows its limitations.  The final part of the paper is a survey of
contemporary research on interactive theorem proving.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9301111</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9301111</id><created>1989-12-31</created><authors><author><keyname>Knuth</keyname><forenames>Donald E.</forenames></author></authors><title>Nested satisfiability</title><categories>cs.CC</categories><report-no>Knuth migration 11/2004</report-no><journal-ref>Acta Inform. 28 (1990), no. 1, 1--6</journal-ref><abstract>  A special case of the satisfiability problem, in which the clauses have a
hierarchical structure, is shown to be solvable in linear time, assuming that
the clauses have been represented in a convenient way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9301112</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9301112</id><created>1990-03-31</created><authors><author><keyname>Knuth</keyname><forenames>Donald E.</forenames></author></authors><title>A note on digitized angles</title><categories>cs.GR</categories><report-no>Knuth migration 11/2004</report-no><journal-ref>Electronic Publishing 3 (1990), no. 2, 99--104</journal-ref><abstract>  We study the configurations of pixels that occur when two digitized straight
lines meet each other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9301113</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9301113</id><created>1991-07-31</created><authors><author><keyname>Knuth</keyname><forenames>Donald E.</forenames></author></authors><title>Textbook examples of recursion</title><categories>cs.CC</categories><report-no>Knuth migration 11/2004 207-229, Academic Press, Boston, MA, 1991</report-no><journal-ref>Artificial intelligence and mathematical theory of computation</journal-ref><abstract>  We discuss properties of recursive schemas related to McCarthy's ``91
function'' and to Takeuchi's triple recursion. Several theorems are proposed as
interesting candidates for machine verification, and some intriguing open
questions are raised.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9301114</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9301114</id><created>1991-10-31</created><authors><author><keyname>Knuth</keyname><forenames>Donald E.</forenames></author></authors><title>Theory and practice</title><categories>cs.GL</categories><comments>Abstract added by Greg Kuperberg</comments><report-no>Knuth migration 11/2004</report-no><journal-ref>Theoretical Comp. Sci. 90 (1991), 1--15</journal-ref><abstract>  The author argues to Silicon Valley that the most important and powerful part
of computer science is work that is simultaneously theoretical and practical.
He particularly considers the intersection of the theory of algorithms and
practical software development. He combines examples from the development of
the TeX typesetting system with clever jokes, criticisms, and encouragements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9301115</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9301115</id><created>1991-11-30</created><authors><author><keyname>Knuth</keyname><forenames>Donald E.</forenames></author></authors><title>Context-free multilanguages</title><categories>cs.DS</categories><comments>Abstract added by Greg Kuperberg</comments><report-no>Knuth migration 11/2004 1991</report-no><journal-ref>Theoretical Studies in Computer Science, Ginsburg Festschrift</journal-ref><abstract>  This article is a sketch of ideas that were once intended to appear in the
author's famous series, &quot;The Art of Computer Programming&quot;. He generalizes the
notion of a context-free language from a set to a multiset of words over an
alphabet. The idea is to keep track of the number of ways to parse a string.
For example, &quot;fruit flies like a banana&quot; can famously be parsed in two ways;
analogous examples in the setting of programming languages may yet be important
in the future.
  The treatment is informal but essentially rigorous.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9301116</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9301116</id><created>1992-06-30</created><authors><author><keyname>Knuth</keyname><forenames>Donald E.</forenames></author><author><keyname>Raghunathan</keyname><forenames>Arvind</forenames></author></authors><title>The problem of compatible representatives</title><categories>cs.DS math.CO</categories><report-no>Knuth migration 11/2004</report-no><journal-ref>SIAM J. Discrete Math. 5 (1992), no. 3, 422--427</journal-ref><abstract>  The purpose of this note is to attach a name to a natural class of
combinatorial problems and to point out that this class includes many important
special cases. We also show that a simple problem of placing nonoverlapping
labels on a rectangular map is NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9308101</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9308101</id><created>1993-07-31</created><authors><author><keyname>Ginsberg</keyname><forenames>M. L.</forenames></author></authors><title>Dynamic Backtracking</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 1, (1993), 25-46</journal-ref><abstract>  Because of their occasional need to return to shallow points in a search
tree, existing backtracking methods can sometimes erase meaningful progress
toward solving a search problem. In this paper, we present a method by which
backtrack points can be moved deeper in the search space, thereby avoiding this
difficulty. The technique developed is a variant of dependency-directed
backtracking that uses only polynomial space while still providing useful
control information and retaining the completeness guarantees provided by
earlier approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9308102</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9308102</id><created>1993-07-31</created><authors><author><keyname>Wellman</keyname><forenames>M. P.</forenames></author></authors><title>A Market-Oriented Programming Environment and its Application to
  Distributed Multicommodity Flow Problems</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 1, (1993), 1-23</journal-ref><abstract>  Market price systems constitute a well-understood class of mechanisms that
under certain conditions provide effective decentralization of decision making
with minimal communication overhead. In a market-oriented programming approach
to distributed problem solving, we derive the activities and resource
allocations for a set of computational agents by computing the competitive
equilibrium of an artificial economy. WALRAS provides basic constructs for
defining computational market structures, and protocols for deriving their
corresponding price equilibria. In a particular realization of this approach
for a form of multicommodity flow problem, we see that careful construction of
the decision process according to economic principles can lead to efficient
distributed resource allocation, and that the behavior of the system can be
meaningfully analyzed in economic terms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9309101</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9309101</id><created>1993-08-31</created><authors><author><keyname>Gent</keyname><forenames>I. P.</forenames></author><author><keyname>Walsh</keyname><forenames>T.</forenames></author></authors><title>An Empirical Analysis of Search in GSAT</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 1, (1993), 47-59</journal-ref><abstract>  We describe an extensive study of search in GSAT, an approximation procedure
for propositional satisfiability. GSAT performs greedy hill-climbing on the
number of satisfied clauses in a truth assignment. Our experiments provide a
more complete picture of GSAT's search than previous accounts. We describe in
detail the two phases of search: rapid hill-climbing followed by a long plateau
search. We demonstrate that when applied to randomly generated 3SAT problems,
there is a very simple scaling with problem size for both the mean number of
satisfied clauses and the mean branching rate. Our results allow us to make
detailed numerical conjectures about the length of the hill-climbing phase, the
average gradient of this phase, and to conjecture that both the average score
and average branching rate decay exponentially during plateau search. We end by
showing how these results can be used to direct future theoretical analysis.
This work provides a case study of how computer experiments can be used to
improve understanding of the theoretical properties of algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9311101</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9311101</id><created>1993-10-31</created><authors><author><keyname>Bergadano</keyname><forenames>F.</forenames></author><author><keyname>Gunetti</keyname><forenames>D.</forenames></author><author><keyname>Trinchero</keyname><forenames>U.</forenames></author></authors><title>The Difficulties of Learning Logic Programs with Cut</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 1, (1993), 91-107</journal-ref><abstract>  As real logic programmers normally use cut (!), an effective learning
procedure for logic programs should be able to deal with it. Because the cut
predicate has only a procedural meaning, clauses containing cut cannot be
learned using an extensional evaluation method, as is done in most learning
systems. On the other hand, searching a space of possible programs (instead of
a space of independent clauses) is unfeasible. An alternative solution is to
generate first a candidate base program which covers the positive examples, and
then make it consistent by inserting cut where appropriate. The problem of
learning programs with cut has not been investigated before and this seems to
be a natural and reasonable approach. We generalize this scheme and investigate
the difficulties that arise. Some of the major shortcomings are actually
caused, in general, by the need for intensional evaluation. As a conclusion,
the analysis of this paper suggests, on precise and technical grounds, that
learning cut is difficult, and current induction techniques should probably be
restricted to purely declarative logic languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9311102</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9311102</id><created>1993-10-31</created><authors><author><keyname>Schlimmer</keyname><forenames>J. C.</forenames></author><author><keyname>Hermens</keyname><forenames>L. A.</forenames></author></authors><title>Software Agents: Completing Patterns and Constructing User Interfaces</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 1, (1993), 61-89</journal-ref><abstract>  To support the goal of allowing users to record and retrieve information,
this paper describes an interactive note-taking system for pen-based computers
with two distinctive features. First, it actively predicts what the user is
going to write. Second, it automatically constructs a custom, button-box user
interface on request. The system is an example of a learning-apprentice
software- agent. A machine learning component characterizes the syntax and
semantics of the user's information. A performance system uses this learned
information to generate completion strings and construct a user interface.
Description of Online Appendix: People like to record information. Doing this
on paper is initially efficient, but lacks flexibility. Recording information
on a computer is less efficient but more powerful. In our new note taking
softwre, the user records information directly on a computer. Behind the
interface, an agent acts for the user. To help, it provides defaults and
constructs a custom user interface. The demonstration is a QuickTime movie of
the note taking agent in action. The file is a binhexed self-extracting
archive. Macintosh utilities for binhex are available from
mac.archive.umich.edu. QuickTime is available from ftp.apple.com in the
dts/mac/sys.soft/quicktime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9311103</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9311103</id><created>2000-10-30</created><authors><author><keyname>Paulson</keyname><forenames>Lawrence C.</forenames></author></authors><title>Set Theory for Verification: I. From Foundations to Functions</title><categories>cs.LO</categories><acm-class>D.2.4; F.3.1; F.4.1</acm-class><journal-ref>published in Journal of Journal of Automated Reasoning 11 (1993),
  353-389</journal-ref><abstract>  A logic for specification and verification is derived from the axioms of
Zermelo-Fraenkel set theory. The proofs are performed using the proof assistant
Isabelle. Isabelle is generic, supporting several different logics. Isabelle
has the flexibility to adapt to variants of set theory. Its higher-order syntax
supports the definition of new binding operators. Unknowns in subgoals can be
instantiated incrementally. The paper describes the derivation of rules for
descriptions, relations and functions, and discusses interactive proofs of
Cantor's Theorem, the Composition of Homomorphisms challenge [9], and Ramsey's
Theorem [5]. A generic proof assistant can stand up against provers dedicated
to particular logics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9312101</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9312101</id><created>1993-11-30</created><authors><author><keyname>Buchheit</keyname><forenames>M.</forenames></author><author><keyname>Donini</keyname><forenames>F. M.</forenames></author><author><keyname>Schaerf</keyname><forenames>A.</forenames></author></authors><title>Decidable Reasoning in Terminological Knowledge Representation Systems</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 1, (1993),
  109-138</journal-ref><abstract>  Terminological knowledge representation systems (TKRSs) are tools for
designing and using knowledge bases that make use of terminological languages
(or concept languages). We analyze from a theoretical point of view a TKRS
whose capabilities go beyond the ones of presently available TKRSs. The new
features studied, often required in practical applications, can be summarized
in three main points. First, we consider a highly expressive terminological
language, called ALCNR, including general complements of concepts, number
restrictions and role conjunction. Second, we allow to express inclusion
statements between general concepts, and terminological cycles as a particular
case. Third, we prove the decidability of a number of desirable TKRS-deduction
services (like satisfiability, subsumption and instance checking) through a
sound, complete and terminating calculus for reasoning in ALCNR-knowledge
bases. Our calculus extends the general technique of constraint systems. As a
byproduct of the proof, we get also the result that inclusion statements in
ALCNR can be simulated by terminological cycles, if descriptive semantics is
adopted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9401101</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9401101</id><created>1993-12-31</created><authors><author><keyname>Nilsson</keyname><forenames>N.</forenames></author></authors><title>Teleo-Reactive Programs for Agent Control</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 1, (1994),
  139-158</journal-ref><abstract>  A formalism is presented for computing and organizing actions for autonomous
agents in dynamic environments. We introduce the notion of teleo-reactive (T-R)
programs whose execution entails the construction of circuitry for the
continuous computation of the parameters and conditions on which agent action
is based. In addition to continuous feedback, T-R programs support parameter
binding and recursion. A primary difference between T-R programs and many other
circuit-based systems is that the circuitry of T-R programs is more compact; it
is constructed at run time and thus does not have to anticipate all the
contingencies that might arise over all possible runs. In addition, T-R
programs are intuitive and easy to write and are written in a form that is
compatible with automatic planning and learning methods. We briefly describe
some experimental applications of T-R programs in the control of simulated and
actual mobile robots.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9401102</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9401102</id><created>1993-12-31</created><authors><author><keyname>Knuth</keyname><forenames>Donald E.</forenames></author></authors><title>Mini-indexes for literate programs</title><categories>cs.PL</categories><report-no>Knuth migration 11/2004</report-no><journal-ref>Software -- Concepts and Tools 15 (1994), 2--11</journal-ref><abstract>  This paper describes how to implement a documentation technique that helps
readers to understand large programs or collections of programs, by providing
local indexes to all identifiers that are visible on every two-page spread. A
detailed example is given for a program that finds all Hamiltonian circuits in
an undirected graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9402101</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9402101</id><created>1994-01-31</created><authors><author><keyname>Ling</keyname><forenames>C. X.</forenames></author></authors><title>Learning the Past Tense of English Verbs: The Symbolic Pattern
  Associator vs. Connectionist Models</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 1, (1994),
  209-229</journal-ref><abstract>  Learning the past tense of English verbs - a seemingly minor aspect of
language acquisition - has generated heated debates since 1986, and has become
a landmark task for testing the adequacy of cognitive modeling. Several
artificial neural networks (ANNs) have been implemented, and a challenge for
better symbolic models has been posed. In this paper, we present a
general-purpose Symbolic Pattern Associator (SPA) based upon the decision-tree
learning algorithm ID3. We conduct extensive head-to-head comparisons on the
generalization ability between ANN models and the SPA under different
representations. We conclude that the SPA generalizes the past tense of unseen
verbs better than ANN models by a wide margin, and we offer insights as to why
this should be the case. We also discuss a new default strategy for
decision-tree learning algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9402102</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9402102</id><created>1994-01-31</created><authors><author><keyname>Cook</keyname><forenames>D. J.</forenames></author><author><keyname>Holder</keyname><forenames>L. B.</forenames></author></authors><title>Substructure Discovery Using Minimum Description Length and Background
  Knowledge</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 1, (1994),
  231-255</journal-ref><abstract>  The ability to identify interesting and repetitive substructures is an
essential component to discovering knowledge in structural data. We describe a
new version of our SUBDUE substructure discovery system based on the minimum
description length principle. The SUBDUE system discovers substructures that
compress the original data and represent structural concepts in the data. By
replacing previously-discovered substructures in the data, multiple passes of
SUBDUE produce a hierarchical description of the structural regularities in the
data. SUBDUE uses a computationally-bounded inexact graph match that identifies
similar, but not identical, instances of a substructure and finds an
approximate measure of closeness of two substructures when under computational
constraints. In addition to the minimum description length principle, other
background knowledge can be used by SUBDUE to guide the search towards more
appropriate substructures. Experiments in a variety of domains demonstrate
SUBDUE's ability to find substructures capable of compressing the original data
and to discover structural concepts important to the domain. Description of
Online Appendix: This is a compressed tar file containing the SUBDUE discovery
system, written in C. The program accepts as input databases represented in
graph form, and will output discovered substructures with their corresponding
value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9402103</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9402103</id><created>1994-01-31</created><authors><author><keyname>Koppel</keyname><forenames>M.</forenames></author><author><keyname>Feldman</keyname><forenames>R.</forenames></author><author><keyname>Segre</keyname><forenames>A. M.</forenames></author></authors><title>Bias-Driven Revision of Logical Domain Theories</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 1, (1994),
  159-208</journal-ref><abstract>  The theory revision problem is the problem of how best to go about revising a
deficient domain theory using information contained in examples that expose
inaccuracies. In this paper we present our approach to the theory revision
problem for propositional domain theories. The approach described here, called
PTR, uses probabilities associated with domain theory elements to numerically
track the ``flow'' of proof through the theory. This allows us to measure the
precise role of a clause or literal in allowing or preventing a (desired or
undesired) derivation for a given example. This information is used to
efficiently locate and repair flawed elements of the theory. PTR is proved to
converge to a theory which correctly classifies all examples, and shown
experimentally to be fast and accurate even for deep theories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9403101</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9403101</id><created>1994-02-28</created><authors><author><keyname>Murphy</keyname><forenames>P. M.</forenames></author><author><keyname>Pazzani</keyname><forenames>M. J.</forenames></author></authors><title>Exploring the Decision Forest: An Empirical Investigation of Occam's
  Razor in Decision Tree Induction</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 1, (1994),
  257-275</journal-ref><abstract>  We report on a series of experiments in which all decision trees consistent
with the training data are constructed. These experiments were run to gain an
understanding of the properties of the set of consistent decision trees and the
factors that affect the accuracy of individual trees. In particular, we
investigated the relationship between the size of a decision tree consistent
with some training data and the accuracy of the tree on test data. The
experiments were performed on a massively parallel Maspar computer. The results
of the experiments on several artificial and two real world problems indicate
that, for many of the problems investigated, smaller consistent decision trees
are on average less accurate than the average accuracy of slightly larger
trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9406101</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9406101</id><created>1994-05-31</created><authors><author><keyname>Borgida</keyname><forenames>A.</forenames></author><author><keyname>Patel-Schneider</keyname><forenames>P. F.</forenames></author></authors><title>A Semantics and Complete Algorithm for Subsumption in the CLASSIC
  Description Logic</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 1, (1994),
  277-308</journal-ref><abstract>  This paper analyzes the correctness of the subsumption algorithm used in
CLASSIC, a description logic-based knowledge representation system that is
being used in practical applications. In order to deal efficiently with
individuals in CLASSIC descriptions, the developers have had to use an
algorithm that is incomplete with respect to the standard, model-theoretic
semantics for description logics. We provide a variant semantics for
descriptions with respect to which the current implementation is complete, and
which can be independently motivated. The soundness and completeness of the
polynomial-time subsumption algorithm is established using description graphs,
which are an abstracted version of the implementation structures used in
CLASSIC, and are of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9406102</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9406102</id><created>1994-05-31</created><authors><author><keyname>Sebastiani</keyname><forenames>R.</forenames></author></authors><title>Applying GSAT to Non-Clausal Formulas</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 1, (1994),
  309-314</journal-ref><abstract>  In this paper we describe how to modify GSAT so that it can be applied to
non-clausal formulas. The idea is to use a particular ``score'' function which
gives the number of clauses of the CNF conversion of a formula which are false
under a given truth assignment. Its value is computed in linear time, without
constructing the CNF conversion itself. The proposed methodology applies to
most of the variants of GSAT proposed so far.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9408101</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9408101</id><created>1994-07-31</created><authors><author><keyname>Grove</keyname><forenames>A. J.</forenames></author><author><keyname>Halpern</keyname><forenames>J. Y.</forenames></author><author><keyname>Koller</keyname><forenames>D.</forenames></author></authors><title>Random Worlds and Maximum Entropy</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 2, (1994), 33-88</journal-ref><abstract>  Given a knowledge base KB containing first-order and statistical facts, we
consider a principled method, called the random-worlds method, for computing a
degree of belief that some formula Phi holds given KB. If we are reasoning
about a world or system consisting of N individuals, then we can consider all
possible worlds, or first-order models, with domain {1,...,N} that satisfy KB,
and compute the fraction of them in which Phi is true. We define the degree of
belief to be the asymptotic value of this fraction as N grows large. We show
that when the vocabulary underlying Phi and KB uses constants and unary
predicates only, we can naturally associate an entropy with each world. As N
grows larger, there are many more worlds with higher entropy. Therefore, we can
use a maximum-entropy computation to compute the degree of belief. This result
is in a similar spirit to previous work in physics and artificial intelligence,
but is far more general. Of equal interest to the result itself are the
limitations on its scope. Most importantly, the restriction to unary predicates
seems necessary. Although the random-worlds method makes sense in general, the
connection to maximum entropy seems to disappear in the non-unary case. These
observations suggest unexpected limitations to the applicability of
maximum-entropy methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9408102</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9408102</id><created>1994-07-31</created><authors><author><keyname>Kitani</keyname><forenames>T.</forenames></author><author><keyname>Eriguchi</keyname><forenames>Y.</forenames></author><author><keyname>Hara</keyname><forenames>M.</forenames></author></authors><title>Pattern Matching and Discourse Processing in Information Extraction from
  Japanese Text</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 2, (1994), 89-110</journal-ref><abstract>  Information extraction is the task of automatically picking up information of
interest from an unconstrained text. Information of interest is usually
extracted in two steps. First, sentence level processing locates relevant
pieces of information scattered throughout the text; second, discourse
processing merges coreferential information to generate the output. In the
first step, pieces of information are locally identified without recognizing
any relationships among them. A key word search or simple pattern search can
achieve this purpose. The second step requires deeper knowledge in order to
understand relationships among separately identified pieces of information.
Previous information extraction systems focused on the first step, partly
because they were not required to link up each piece of information with other
pieces. To link the extracted pieces of information and map them onto a
structured output format, complex discourse processing is essential. This paper
reports on a Japanese information extraction system that merges information
using a pattern matcher and discourse processor. Evaluation results show a high
level of system performance which approaches human performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9408103</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9408103</id><created>1994-07-31</created><authors><author><keyname>Murthy</keyname><forenames>S. K.</forenames></author><author><keyname>Kasif</keyname><forenames>S.</forenames></author><author><keyname>Salzberg</keyname><forenames>S.</forenames></author></authors><title>A System for Induction of Oblique Decision Trees</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 2, (1994), 1-32</journal-ref><abstract>  This article describes a new system for induction of oblique decision trees.
This system, OC1, combines deterministic hill-climbing with two forms of
randomization to find a good oblique split (in the form of a hyperplane) at
each node of a decision tree. Oblique decision tree methods are tuned
especially for domains in which the attributes are numeric, although they can
be adapted to symbolic or mixed symbolic/numeric attributes. We present
extensive empirical studies, using both real and artificial data, that analyze
OC1's ability to construct oblique trees that are smaller and more accurate
than their axis-parallel counterparts. We also examine the benefits of
randomization for the construction of oblique decision trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9409101</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9409101</id><created>1994-08-31</created><authors><author><keyname>Safra</keyname><forenames>S.</forenames></author><author><keyname>Tennenholtz</keyname><forenames>M.</forenames></author></authors><title>On Planning while Learning</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 2, (1994),
  111-129</journal-ref><abstract>  This paper introduces a framework for Planning while Learning where an agent
is given a goal to achieve in an environment whose behavior is only partially
known to the agent. We discuss the tractability of various plan-design
processes. We show that for a large natural class of Planning while Learning
systems, a plan can be presented and verified in a reasonable time. However,
coming up algorithmically with a plan, even for simple classes of systems is
apparently intractable. We emphasize the role of off-line plan-design
processes, and show that, in most natural cases, the verification (projection)
part can be carried out in an efficient algorithmic manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9412101</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9412101</id><created>1994-11-30</created><authors><author><keyname>Soderland</keyname><forenames>S.</forenames></author><author><keyname>W</keyname><forenames>Lehnert.</forenames></author></authors><title>Wrap-Up: a Trainable Discourse Module for Information Extraction</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 2, (1994),
  131-158</journal-ref><abstract>  The vast amounts of on-line text now available have led to renewed interest
in information extraction (IE) systems that analyze unrestricted text,
producing a structured representation of selected information from the text.
This paper presents a novel approach that uses machine learning to acquire
knowledge for some of the higher level IE processing. Wrap-Up is a trainable IE
discourse component that makes intersentential inferences and identifies
logical relations among information extracted from the text. Previous
corpus-based approaches were limited to lower level processing such as
part-of-speech tagging, lexical disambiguation, and dictionary construction.
Wrap-Up is fully trainable, and not only automatically decides what classifiers
are needed, but even derives the feature set for each classifier automatically.
Performance equals that of a partially trainable discourse module requiring
manual customization for each domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9412102</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9412102</id><created>1994-11-30</created><authors><author><keyname>Buntine</keyname><forenames>W. L.</forenames></author></authors><title>Operations for Learning with Graphical Models</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 2, (1994),
  159-225</journal-ref><abstract>  This paper is a multidisciplinary review of empirical, statistical learning
from a graphical model perspective. Well-known examples of graphical models
include Bayesian networks, directed graphs representing a Markov chain, and
undirected networks representing a Markov field. These graphical models are
extended to model data analysis and empirical learning using the notation of
plates. Graphical operations for simplifying and manipulating a problem are
provided including decomposition, differentiation, and the manipulation of
probability models from the exponential family. Two standard algorithm schemas
for learning are reviewed in a graphical framework: Gibbs sampling and the
expectation maximization algorithm. Using these operations and schemas, some
popular algorithms can be synthesized from their graphical specification. This
includes versions of linear regression, techniques for feed-forward networks,
and learning Gaussian and discrete Bayesian networks from data. The paper
concludes by sketching some implications for data analysis and summarizing how
some popular algorithms fall within the framework presented. The main original
contributions here are the decomposition techniques and the demonstration that
graphical models provide a framework for understanding and developing complex
learning algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9412103</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9412103</id><created>1994-11-30</created><authors><author><keyname>Minton</keyname><forenames>S.</forenames></author><author><keyname>Bresina</keyname><forenames>J.</forenames></author><author><keyname>Drummond</keyname><forenames>M.</forenames></author></authors><title>Total-Order and Partial-Order Planning: A Comparative Analysis</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 2, (1994),
  227-262</journal-ref><abstract>  For many years, the intuitions underlying partial-order planning were largely
taken for granted. Only in the past few years has there been renewed interest
in the fundamental principles underlying this paradigm. In this paper, we
present a rigorous comparative analysis of partial-order and total-order
planning by focusing on two specific planners that can be directly compared. We
show that there are some subtle assumptions that underly the wide-spread
intuitions regarding the supposed efficiency of partial-order planning. For
instance, the superiority of partial-order planning can depend critically upon
the search strategy and the structure of the search space. Understanding the
underlying assumptions is crucial for constructing efficient planners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9501101</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9501101</id><created>1994-12-31</created><authors><author><keyname>Dietterich</keyname><forenames>T. G.</forenames></author><author><keyname>Bakiri</keyname><forenames>G.</forenames></author></authors><title>Solving Multiclass Learning Problems via Error-Correcting Output Codes</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 2, (1995),
  263-286</journal-ref><abstract>  Multiclass learning problems involve finding a definition for an unknown
function f(x) whose range is a discrete set containing k &amp;gt 2 values (i.e., k
``classes''). The definition is acquired by studying collections of training
examples of the form [x_i, f (x_i)]. Existing approaches to multiclass learning
problems include direct application of multiclass algorithms such as the
decision-tree algorithms C4.5 and CART, application of binary concept learning
algorithms to learn individual binary functions for each of the k classes, and
application of binary concept learning algorithms with distributed output
representations. This paper compares these three approaches to a new technique
in which error-correcting codes are employed as a distributed output
representation. We show that these output representations improve the
generalization performance of both C4.5 and backpropagation on a wide range of
multiclass learning tasks. We also demonstrate that this approach is robust
with respect to changes in the size of the training sample, the assignment of
distributed representations to particular classes, and the application of
overfitting avoidance techniques such as decision-tree pruning. Finally, we
show that---like the other methods---the error-correcting code technique can
provide reliable class probability estimates. Taken together, these results
demonstrate that error-correcting output codes provide a general-purpose method
for improving the performance of inductive learning programs on multiclass
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9501102</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9501102</id><created>1994-12-31</created><authors><author><keyname>Hanks</keyname><forenames>S.</forenames></author><author><keyname>Weld</keyname><forenames>D. S.</forenames></author></authors><title>A Domain-Independent Algorithm for Plan Adaptation</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 2, (1995),
  319-360</journal-ref><abstract>  The paradigms of transformational planning, case-based planning, and plan
debugging all involve a process known as plan adaptation - modifying or
repairing an old plan so it solves a new problem. In this paper we provide a
domain-independent algorithm for plan adaptation, demonstrate that it is sound,
complete, and systematic, and compare it to other adaptation algorithms in the
literature. Our approach is based on a view of planning as searching a graph of
partial plans. Generative planning starts at the graph's root and moves from
node to node using plan-refinement operators. In planning by adaptation, a
library plan - an arbitrary node in the plan graph - is the starting point for
the search, and the plan-adaptation algorithm can apply both the same
refinement operators available to a generative planner and can also retract
constraints and steps from the plan. Our algorithm's completeness ensures that
the adaptation algorithm will eventually search the entire graph and its
systematicity ensures that it will do so without redundantly searching any
parts of the graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9501103</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9501103</id><created>1994-12-31</created><authors><author><keyname>Cichosz</keyname><forenames>P.</forenames></author></authors><title>Truncating Temporal Differences: On the Efficient Implementation of
  TD(lambda) for Reinforcement Learning</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 2, (1995),
  287-318</journal-ref><abstract>  Temporal difference (TD) methods constitute a class of methods for learning
predictions in multi-step prediction problems, parameterized by a recency
factor lambda. Currently the most important application of these methods is to
temporal credit assignment in reinforcement learning. Well known reinforcement
learning algorithms, such as AHC or Q-learning, may be viewed as instances of
TD learning. This paper examines the issues of the efficient and general
implementation of TD(lambda) for arbitrary lambda, for use with reinforcement
learning algorithms optimizing the discounted sum of rewards. The traditional
approach, based on eligibility traces, is argued to suffer from both
inefficiency and lack of generality. The TTD (Truncated Temporal Differences)
procedure is proposed as an alternative, that indeed only approximates
TD(lambda), but requires very little computation per action and can be used
with arbitrary function representation methods. The idea from which it is
derived is fairly simple and not new, but probably unexplored so far.
Encouraging experimental results are presented, suggesting that using lambda
&amp;gt 0 with the TTD procedure allows one to obtain a significant learning
speedup at essentially the same cost as usual TD(0) learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9503101</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9503101</id><created>1995-02-28</created><authors><author><keyname>Ortega</keyname><forenames>J.</forenames></author></authors><title>On the Informativeness of the DNA Promoter Sequences Domain Theory</title><categories>cs.AI q-bio</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 2, (1995),
  361-367</journal-ref><abstract>  The DNA promoter sequences domain theory and database have become popular for
testing systems that integrate empirical and analytical learning. This note
reports a simple change and reinterpretation of the domain theory in terms of
M-of-N concepts, involving no learning, that results in an accuracy of 93.4% on
the 106 items of the database. Moreover, an exhaustive search of the space of
M-of-N domain theory interpretations indicates that the expected accuracy of a
randomly chosen interpretation is 76.5%, and that a maximum accuracy of 97.2%
is achieved in 12 cases. This demonstrates the informativeness of the domain
theory, without the complications of understanding the interactions between
various learning algorithms and the theory. In addition, our results help
characterize the difficulty of learning using the DNA promoters theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9503102</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9503102</id><created>1995-02-28</created><authors><author><keyname>Turney</keyname><forenames>P. D.</forenames></author></authors><title>Cost-Sensitive Classification: Empirical Evaluation of a Hybrid Genetic
  Decision Tree Induction Algorithm</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 2, (1995),
  369-409</journal-ref><abstract>  This paper introduces ICET, a new algorithm for cost-sensitive
classification. ICET uses a genetic algorithm to evolve a population of biases
for a decision tree induction algorithm. The fitness function of the genetic
algorithm is the average cost of classification when using the decision tree,
including both the costs of tests (features, measurements) and the costs of
classification errors. ICET is compared here with three other algorithms for
cost-sensitive classification - EG2, CS-ID3, and IDX - and also with C4.5,
which classifies without regard to cost. The five algorithms are evaluated
empirically on five real-world medical datasets. Three sets of experiments are
performed. The first set examines the baseline performance of the five
algorithms on the five datasets and establishes that ICET performs
significantly better than its competitors. The second set tests the robustness
of ICET under a variety of conditions and shows that ICET maintains its
advantage. The third set looks at ICET's search in bias space and discovers a
way to improve the search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9504101</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9504101</id><created>1995-03-31</created><authors><author><keyname>Donoho</keyname><forenames>S. K.</forenames></author><author><keyname>Rendell</keyname><forenames>L. A.</forenames></author></authors><title>Rerepresenting and Restructuring Domain Theories: A Constructive
  Induction Approach</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 2, (1995),
  411-446</journal-ref><abstract>  Theory revision integrates inductive learning and background knowledge by
combining training examples with a coarse domain theory to produce a more
accurate theory. There are two challenges that theory revision and other
theory-guided systems face. First, a representation language appropriate for
the initial theory may be inappropriate for an improved theory. While the
original representation may concisely express the initial theory, a more
accurate theory forced to use that same representation may be bulky,
cumbersome, and difficult to reach. Second, a theory structure suitable for a
coarse domain theory may be insufficient for a fine-tuned theory. Systems that
produce only small, local changes to a theory have limited value for
accomplishing complex structural alterations that may be required.
Consequently, advanced theory-guided learning systems require flexible
representation and flexible structure. An analysis of various theory revision
systems and theory-guided learning systems reveals specific strengths and
weaknesses in terms of these two desired properties. Designed to capture the
underlying qualities of each system, a new system uses theory-guided
constructive induction. Experiments in three domains show improvement over
previous theory-guided systems. This leads to a study of the behavior,
limitations, and potential of theory-guided constructive induction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9505101</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9505101</id><created>1995-04-30</created><authors><author><keyname>David</keyname><forenames>P.</forenames></author></authors><title>Using Pivot Consistency to Decompose and Solve Functional CSPs</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 2, (1995),
  447-474</journal-ref><abstract>  Many studies have been carried out in order to increase the search efficiency
of constraint satisfaction problems; among them, some make use of structural
properties of the constraint network; others take into account semantic
properties of the constraints, generally assuming that all the constraints
possess the given property. In this paper, we propose a new decomposition
method benefiting from both semantic properties of functional constraints (not
bijective constraints) and structural properties of the network; furthermore,
not all the constraints need to be functional. We show that under some
conditions, the existence of solutions can be guaranteed. We first characterize
a particular subset of the variables, which we name a root set. We then
introduce pivot consistency, a new local consistency which is a weak form of
path consistency and can be achieved in O(n^2d^2) complexity (instead of
O(n^3d^3) for path consistency), and we present associated properties; in
particular, we show that any consistent instantiation of the root set can be
linearly extended to a solution, which leads to the presentation of the
aforementioned new method for solving by decomposing functional CSPs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9505102</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9505102</id><created>1995-04-30</created><authors><author><keyname>Schaerf</keyname><forenames>A.</forenames></author><author><keyname>Shoham</keyname><forenames>Y.</forenames></author><author><keyname>Tennenholtz</keyname><forenames>M.</forenames></author></authors><title>Adaptive Load Balancing: A Study in Multi-Agent Learning</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 2, (1995),
  475-500</journal-ref><abstract>  We study the process of multi-agent reinforcement learning in the context of
load balancing in a distributed system, without use of either central
coordination or explicit communication. We first define a precise framework in
which to study adaptive load balancing, important features of which are its
stochastic nature and the purely local information available to individual
agents. Given this framework, we show illuminating results on the interplay
between basic adaptive behavior parameters and their effect on system
efficiency. We then investigate the properties of adaptive load balancing in
heterogeneous populations, and address the issue of exploration vs.
exploitation in that context. Finally, we show that naive use of communication
may not improve, and might even harm system efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9505103</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9505103</id><created>1995-04-30</created><authors><author><keyname>Russell</keyname><forenames>S. J.</forenames></author><author><keyname>Subramanian</keyname><forenames>D.</forenames></author></authors><title>Provably Bounded-Optimal Agents</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 2, (1995),
  575-609</journal-ref><abstract>  Since its inception, artificial intelligence has relied upon a theoretical
foundation centered around perfect rationality as the desired property of
intelligent systems. We argue, as others have done, that this foundation is
inadequate because it imposes fundamentally unsatisfiable requirements. As a
result, there has arisen a wide gap between theory and practice in AI,
hindering progress in the field. We propose instead a property called bounded
optimality. Roughly speaking, an agent is bounded-optimal if its program is a
solution to the constrained optimization problem presented by its architecture
and the task environment. We show how to construct agents with this property
for a simple class of machine architectures in a broad class of real-time
environments. We illustrate these results using a simple model of an automated
mail sorting facility. We also define a weaker property, asymptotic bounded
optimality (ABO), that generalizes the notion of optimality in classical
complexity theory. We then construct universal ABO programs, i.e., programs
that are ABO no matter what real-time constraints are applied. Universal ABO
programs can be used as building blocks for more complex systems. We conclude
with a discussion of the prospects for bounded optimality as a theoretical
basis for AI, and relate it to similar trends in philosophy, economics, and
game theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9505104</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9505104</id><created>1995-04-30</created><authors><author><keyname>Cohen</keyname><forenames>W. W.</forenames></author></authors><title>Pac-Learning Recursive Logic Programs: Efficient Algorithms</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 2, (1995),
  501-539</journal-ref><abstract>  We present algorithms that learn certain classes of function-free recursive
logic programs in polynomial time from equivalence queries. In particular, we
show that a single k-ary recursive constant-depth determinate clause is
learnable. Two-clause programs consisting of one learnable recursive clause and
one constant-depth determinate non-recursive clause are also learnable, if an
additional ``basecase'' oracle is assumed. These results immediately imply the
pac-learnability of these classes. Although these classes of learnable
recursive programs are very constrained, it is shown in a companion paper that
they are maximally general, in that generalizing either class in any natural
way leads to a computationally difficult learning problem. Thus, taken together
with its companion paper, this paper establishes a boundary of efficient
learnability for recursive logic programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9505105</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9505105</id><created>1995-04-30</created><authors><author><keyname>Cohen</keyname><forenames>W. W.</forenames></author></authors><title>Pac-learning Recursive Logic Programs: Negative Results</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 2, (1995),
  541-573</journal-ref><abstract>  In a companion paper it was shown that the class of constant-depth
determinate k-ary recursive clauses is efficiently learnable. In this paper we
present negative results showing that any natural generalization of this class
is hard to learn in Valiant's model of pac-learnability. In particular, we show
that the following program classes are cryptographically hard to learn:
programs with an unbounded number of constant-depth linear recursive clauses;
programs with one constant-depth determinate clause containing an unbounded
number of recursive calls; and programs with one linear recursive clause of
constant locality. These results immediately imply the non-learnability of any
more general class of programs. We also show that learning a constant-depth
determinate program with either two linear recursive clauses or one linear
recursive clause and one non-recursive clause is as hard as learning boolean
DNF. Together with positive results from the companion paper, these negative
results establish a boundary of efficient learnability for recursive
function-free clauses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9506101</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9506101</id><created>1995-05-31</created><authors><author><keyname>Veloso</keyname><forenames>M.</forenames></author><author><keyname>Stone</keyname><forenames>P.</forenames></author></authors><title>FLECS: Planning with a Flexible Commitment Strategy</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 3, (1995), 25-52</journal-ref><abstract>  There has been evidence that least-commitment planners can efficiently handle
planning problems that involve difficult goal interactions. This evidence has
led to the common belief that delayed-commitment is the &quot;best&quot; possible
planning strategy. However, we recently found evidence that eager-commitment
planners can handle a variety of planning problems more efficiently, in
particular those with difficult operator choices. Resigned to the futility of
trying to find a universally successful planning strategy, we devised a planner
that can be used to study which domains and problems are best for which
planning strategies. In this article we introduce this new planning algorithm,
FLECS, which uses a FLExible Commitment Strategy with respect to plan-step
orderings. It is able to use any strategy from delayed-commitment to
eager-commitment. The combination of delayed and eager operator-ordering
commitments allows FLECS to take advantage of the benefits of explicitly using
a simulated execution state and reasoning about planning constraints. FLECS can
vary its commitment strategy across different problems and domains, and also
during the course of a single planning problem. FLECS represents a novel
contribution to planning in that it explicitly provides the choice of which
commitment strategy to use while planning. FLECS provides a framework to
investigate the mapping from planning domains and problems to efficient
planning strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9506102</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9506102</id><created>1995-05-31</created><authors><author><keyname>Mooney</keyname><forenames>R. J.</forenames></author><author><keyname>Califf</keyname><forenames>M. E.</forenames></author></authors><title>Induction of First-Order Decision Lists: Results on Learning the Past
  Tense of English Verbs</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 3, (1995), 1-24</journal-ref><abstract>  This paper presents a method for inducing logic programs from examples that
learns a new class of concepts called first-order decision lists, defined as
ordered lists of clauses each ending in a cut. The method, called FOIDL, is
based on FOIL (Quinlan, 1990) but employs intensional background knowledge and
avoids the need for explicit negative examples. It is particularly useful for
problems that involve rules with specific exceptions, such as learning the
past-tense of English verbs, a task widely studied in the context of the
symbolic/connectionist debate. FOIDL is able to learn concise, accurate
programs for this problem from significantly fewer examples than previous
methods (both connectionist and symbolic).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9507101</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9507101</id><created>1995-06-30</created><authors><author><keyname>Bergmann</keyname><forenames>R.</forenames></author><author><keyname>Wilke</keyname><forenames>W.</forenames></author></authors><title>Building and Refining Abstract Planning Cases by Change of
  Representation Language</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 3, (1995), 53-118</journal-ref><abstract>  ion is one of the most promising approaches to improve the performance of
problem solvers. In several domains abstraction by dropping sentences of a
domain description -- as used in most hierarchical planners -- has proven
useful. In this paper we present examples which illustrate significant
drawbacks of abstraction by dropping sentences. To overcome these drawbacks, we
propose a more general view of abstraction involving the change of
representation language. We have developed a new abstraction methodology and a
related sound and complete learning algorithm that allows the complete change
of representation language of planning cases from concrete to abstract.
However, to achieve a powerful change of the representation language, the
abstract language itself as well as rules which describe admissible ways of
abstracting states must be provided in the domain model. This new abstraction
approach is the core of Paris (Plan Abstraction and Refinement in an Integrated
System), a system in which abstract planning cases are automatically learned
from given concrete cases. An empirical study in the domain of process planning
in mechanical engineering shows significant advantages of the proposed
reasoning from abstract cases over classical hierarchical planning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9508101</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9508101</id><created>1995-07-31</created><authors><author><keyname>Zhao</keyname><forenames>Q.</forenames></author><author><keyname>Nishida</keyname><forenames>T.</forenames></author></authors><title>Using Qualitative Hypotheses to Identify Inaccurate Data</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 3, (1995),
  119-145</journal-ref><abstract>  Identifying inaccurate data has long been regarded as a significant and
difficult problem in AI. In this paper, we present a new method for identifying
inaccurate data on the basis of qualitative correlations among related data.
First, we introduce the definitions of related data and qualitative
correlations among related data. Then we put forward a new concept called
support coefficient function (SCF). SCF can be used to extract, represent, and
calculate qualitative correlations among related data within a dataset. We
propose an approach to determining dynamic shift intervals of inaccurate data,
and an approach to calculating possibility of identifying inaccurate data,
respectively. Both of the approaches are based on SCF. Finally we present an
algorithm for identifying inaccurate data by using qualitative correlations
among related data as confirmatory or disconfirmatory evidence. We have
developed a practical system for interpreting infrared spectra by applying the
method, and have fully tested the system against several hundred real spectra.
The experimental results show that the method is significantly better than the
conventional methods used in many similar systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9508102</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9508102</id><created>1995-07-31</created><authors><author><keyname>Giraud-Carrier</keyname><forenames>C. G.</forenames></author><author><keyname>Martinez</keyname><forenames>T. R.</forenames></author></authors><title>An Integrated Framework for Learning and Reasoning</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 3, (1995),
  147-185</journal-ref><abstract>  Learning and reasoning are both aspects of what is considered to be
intelligence. Their studies within AI have been separated historically,
learning being the topic of machine learning and neural networks, and reasoning
falling under classical (or symbolic) AI. However, learning and reasoning are
in many ways interdependent. This paper discusses the nature of some of these
interdependencies and proposes a general framework called FLARE, that combines
inductive learning using prior knowledge together with reasoning in a
propositional setting. Several examples that test the framework are presented,
including classical induction, many important reasoning protocols and two
simple expert systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9510101</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9510101</id><created>1995-09-30</created><authors><author><keyname>Bengio</keyname><forenames>Y.</forenames></author><author><keyname>Frasconi</keyname><forenames>P.</forenames></author></authors><title>Diffusion of Context and Credit Information in Markovian Models</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 3, (1995),
  249-270</journal-ref><abstract>  This paper studies the problem of ergodicity of transition probability
matrices in Markovian models, such as hidden Markov models (HMMs), and how it
makes very difficult the task of learning to represent long-term context for
sequential data. This phenomenon hurts the forward propagation of long-term
context information, as well as learning a hidden state representation to
represent long-term context, which depends on propagating credit information
backwards in time. Using results from Markov chain theory, we show that this
problem of diffusion of context and credit is reduced when the transition
probabilities approach 0 or 1, i.e., the transition probability matrices are
sparse and the model essentially deterministic. The results found in this paper
apply to learning approaches based on continuous optimization, such as gradient
descent and the Baum-Welch algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9510102</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9510102</id><created>1995-09-30</created><authors><author><keyname>Pinkas</keyname><forenames>G.</forenames></author><author><keyname>Dechter</keyname><forenames>R.</forenames></author></authors><title>Improving Connectionist Energy Minimization</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 3, (1995),
  223-248</journal-ref><abstract>  Symmetric networks designed for energy minimization such as Boltzman machines
and Hopfield nets are frequently investigated for use in optimization,
constraint satisfaction and approximation of NP-hard problems. Nevertheless,
finding a global solution (i.e., a global minimum for the energy function) is
not guaranteed and even a local solution may take an exponential number of
steps. We propose an improvement to the standard local activation function used
for such networks. The improved algorithm guarantees that a global minimum is
found in linear time for tree-like subnetworks. The algorithm, called activate,
is uniform and does not assume that the network is tree-like. It can identify
tree-like subnetworks even in cyclic topologies (arbitrary networks) and avoid
local minima along these trees. For acyclic networks, the algorithm is
guaranteed to converge to a global minimum from any initial state of the system
(self-stabilization) and remains correct under various types of schedulers. On
the negative side, we show that in the presence of cycles, no uniform algorithm
exists that guarantees optimality even under a sequential asynchronous
scheduler. An asynchronous scheduler can activate only one unit at a time while
a synchronous scheduler can activate any number of units in a single time step.
In addition, no uniform algorithm exists to optimize even acyclic networks when
the scheduler is synchronous. Finally, we show how the algorithm can be
improved using the cycle-cutset scheme. The general algorithm, called
activate-with-cutset, improves over activate and has some performance
guarantees that are related to the size of the network's cycle-cutset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9510103</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9510103</id><created>1995-09-30</created><authors><author><keyname>Woods</keyname><forenames>K.</forenames></author><author><keyname>Cook</keyname><forenames>D.</forenames></author><author><keyname>Hall</keyname><forenames>L.</forenames></author><author><keyname>Bowyer</keyname><forenames>K.</forenames></author><author><keyname>Stark</keyname><forenames>L.</forenames></author></authors><title>Learning Membership Functions in a Function-Based Object Recognition
  System</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 3, (1995),
  187-222</journal-ref><abstract>  Functionality-based recognition systems recognize objects at the category
level by reasoning about how well the objects support the expected function.
Such systems naturally associate a ``measure of goodness'' or ``membership
value'' with a recognized object. This measure of goodness is the result of
combining individual measures, or membership values, from potentially many
primitive evaluations of different properties of the object's shape. A
membership function is used to compute the membership value when evaluating a
primitive of a particular physical property of an object. In previous versions
of a recognition system known as Gruff, the membership function for each of the
primitive evaluations was hand-crafted by the system designer. In this paper,
we provide a learning component for the Gruff system, called Omlet, that
automatically learns membership functions given a set of example objects
labeled with their desired category measure. The learning algorithm is
generally applicable to any problem in which low-level membership values are
combined through an and-or tree structure to give a final overall membership
value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9511101</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9511101</id><created>1995-10-31</created><authors><author><keyname>Huffman</keyname><forenames>S. B.</forenames></author><author><keyname>Laird</keyname><forenames>J. E.</forenames></author></authors><title>Flexibly Instructable Agents</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 3, (1995),
  271-324</journal-ref><abstract>  This paper presents an approach to learning from situated, interactive
tutorial instruction within an ongoing agent. Tutorial instruction is a
flexible (and thus powerful) paradigm for teaching tasks because it allows an
instructor to communicate whatever types of knowledge an agent might need in
whatever situations might arise. To support this flexibility, however, the
agent must be able to learn multiple kinds of knowledge from a broad range of
instructional interactions. Our approach, called situated explanation, achieves
such learning through a combination of analytic and inductive techniques. It
combines a form of explanation-based learning that is situated for each
instruction with a full suite of contextually guided responses to incomplete
explanations. The approach is implemented in an agent called Instructo-Soar
that learns hierarchies of new tasks and other domain knowledge from
interactive natural language instructions. Instructo-Soar meets three key
requirements of flexible instructability that distinguish it from previous
systems: (1) it can take known or unknown commands at any instruction point;
(2) it can handle instructions that apply to either its current situation or to
a hypothetical situation specified in language (as in, for instance,
conditional instructions); and (3) it can learn, from instructions, each class
of knowledge it uses to perform tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9511102</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9511102</id><created>2000-11-13</created><authors><author><keyname>Paulson</keyname><forenames>Lawrence C.</forenames></author></authors><title>Set Theory for Verification: II. Induction and Recursion</title><categories>cs.LO</categories><acm-class>D.2.4; F.3.1; F.4.1</acm-class><journal-ref>published in Journal of Journal of Automated Reasoning 15 (1995),
  167-215</journal-ref><abstract>  A theory of recursive definitions has been mechanized in Isabelle's
Zermelo-Fraenkel (ZF) set theory. The objective is to support the formalization
of particular recursive definitions for use in verification, semantics proofs
and other computational reasoning. Inductively defined sets are expressed as
least fixedpoints, applying the Knaster-Tarski Theorem over a suitable set.
Recursive functions are defined by well-founded recursion and its derivatives,
such as transfinite recursion. Recursive data structures are expressed by
applying the Knaster-Tarski Theorem to a set, such as V[omega], that is closed
under Cartesian product and disjoint sum. Worked examples include the
transitive closure of a relation, lists, variable-branching trees and mutually
recursive trees and forests. The Schr\&quot;oder-Bernstein Theorem and the soundness
of propositional logic are proved in Isabelle sessions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9511103</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9511103</id><created>2001-03-28</created><authors><author><keyname>Paulson</keyname><forenames>Lawrence C.</forenames></author></authors><title>A Concrete Final Coalgebra Theorem for ZF Set Theory</title><categories>cs.LO</categories><comments>a greatly revised version has appeared in Mathematical Structures in
  Computer Science 9 (1999), 545-567. This version uses different methods and
  therefore retains some value</comments><acm-class>F.3.2</acm-class><journal-ref>published in P. Dybjer, B. Nordstrm and J. Smith (editors), Types
  for Proofs and Programs '94 (Springer LNCS 996, published 1995), 120-139</journal-ref><abstract>  A special final coalgebra theorem, in the style of Aczel's, is proved
within standard Zermelo-Fraenkel set theory. Aczel's Anti-Foundation Axiom is
replaced by a variant definition of function that admits non-well-founded
constructions. Variant ordered pairs and tuples, of possibly infinite length,
are special cases of variant functions. Analogues of Aczel's Solution and
Substitution Lemmas are proved in the style of Rutten and Turi. The
approach is less general than Aczel's, but the treatment of non-well-founded
objects is simple and concrete. The final coalgebra of a functor is its
greatest fixedpoint. The theory is intended for machine implementation and a
simple case of it is already implemented using the theorem prover Isabelle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9512101</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9512101</id><created>1995-11-30</created><authors><author><keyname>Webb</keyname><forenames>G. I.</forenames></author></authors><title>OPUS: An Efficient Admissible Algorithm for Unordered Search</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 3, (1995),
  431-465</journal-ref><abstract>  OPUS is a branch and bound search algorithm that enables efficient admissible
search through spaces for which the order of search operator application is not
significant. The algorithm's search efficiency is demonstrated with respect to
very large machine learning search spaces. The use of admissible search is of
potential value to the machine learning community as it means that the exact
learning biases to be employed for complex learning tasks can be precisely
specified and manipulated. OPUS also has potential for application in other
areas of artificial intelligence, notably, truth maintenance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9512102</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9512102</id><created>1995-11-30</created><authors><author><keyname>Broggi</keyname><forenames>A.</forenames></author><author><keyname>Berte</keyname><forenames>S.</forenames></author></authors><title>Vision-Based Road Detection in Automotive Systems: A Real-Time
  Expectation-Driven Approach</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 3, (1995),
  325-348</journal-ref><abstract>  The main aim of this work is the development of a vision-based road detection
system fast enough to cope with the difficult real-time constraints imposed by
moving vehicle applications. The hardware platform, a special-purpose massively
parallel system, has been chosen to minimize system production and operational
costs. This paper presents a novel approach to expectation-driven low-level
image segmentation, which can be mapped naturally onto mesh-connected massively
parallel SIMD architectures capable of handling hierarchical data structures.
The input image is assumed to contain a distorted version of a given template;
a multiresolution stretching process is used to reshape the original template
in accordance with the acquired image content, minimizing a potential function.
The distorted template is the process output.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9512103</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9512103</id><created>1995-11-30</created><authors><author><keyname>Idestam-Almquist</keyname><forenames>P.</forenames></author></authors><title>Generalization of Clauses under Implication</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 3, (1995),
  467-489</journal-ref><abstract>  In the area of inductive learning, generalization is a main operation, and
the usual definition of induction is based on logical implication. Recently
there has been a rising interest in clausal representation of knowledge in
machine learning. Almost all inductive learning systems that perform
generalization of clauses use the relation theta-subsumption instead of
implication. The main reason is that there is a well-known and simple technique
to compute least general generalizations under theta-subsumption, but not under
implication. However generalization under theta-subsumption is inappropriate
for learning recursive clauses, which is a crucial problem since recursion is
the basic program structure of logic programs. We note that implication between
clauses is undecidable, and we therefore introduce a stronger form of
implication, called T-implication, which is decidable between clauses. We show
that for every finite set of clauses there exists a least general
generalization under T-implication. We describe a technique to reduce
generalizations under implication of a clause to generalizations under
theta-subsumption of what we call an expansion of the original clause. Moreover
we show that for every non-tautological clause there exists a T-complete
expansion, which means that every generalization under T-implication of the
clause is reduced to a generalization under theta-subsumption of the expansion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9512104</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9512104</id><created>1995-11-30</created><authors><author><keyname>Heckerman</keyname><forenames>D.</forenames></author><author><keyname>Shachter</keyname><forenames>R.</forenames></author></authors><title>Decision-Theoretic Foundations for Causal Reasoning</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 3, (1995),
  405-430</journal-ref><abstract>  We present a definition of cause and effect in terms of decision-theoretic
primitives and thereby provide a principled foundation for causal reasoning.
Our definition departs from the traditional view of causation in that causal
assertions may vary with the set of decisions available. We argue that this
approach provides added clarity to the notion of cause. Also in this paper, we
examine the encoding of causal relationships in directed acyclic graphs. We
describe a special class of influence diagrams, those in canonical form, and
show its relationship to Pearl's representation of cause and effect. Finally,
we show how canonical form facilitates counterfactual reasoning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9512105</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9512105</id><created>1995-11-30</created><authors><author><keyname>Khardon</keyname><forenames>R.</forenames></author></authors><title>Translating between Horn Representations and their Characteristic Models</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 3, (1995),
  349-372</journal-ref><abstract>  Characteristic models are an alternative, model based, representation for
Horn expressions. It has been shown that these two representations are
incomparable and each has its advantages over the other. It is therefore
natural to ask what is the cost of translating, back and forth, between these
representations. Interestingly, the same translation questions arise in
database theory, where it has applications to the design of relational
databases. This paper studies the computational complexity of these problems.
Our main result is that the two translation problems are equivalent under
polynomial reductions, and that they are equivalent to the corresponding
decision problem. Namely, translating is equivalent to deciding whether a given
set of models is the set of characteristic models for a given Horn expression.
We also relate these problems to the hypergraph transversal problem, a well
known problem which is related to other applications in AI and for which no
polynomial time algorithm is known. It is shown that in general our translation
problems are at least as hard as the hypergraph transversal problem, and in a
special case they are equivalent to it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9512106</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9512106</id><created>1995-11-30</created><authors><author><keyname>Buro</keyname><forenames>M.</forenames></author></authors><title>Statistical Feature Combination for the Evaluation of Game Positions</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 3, (1995),
  373-382</journal-ref><abstract>  This article describes an application of three well-known statistical methods
in the field of game-tree search: using a large number of classified Othello
positions, feature weights for evaluation functions with a
game-phase-independent meaning are estimated by means of logistic regression,
Fisher's linear discriminant, and the quadratic discriminant function for
normally distributed features. Thereafter, the playing strengths are compared
by means of tournaments between the resulting versions of a world-class Othello
program. In this application, logistic regression - which is used here for the
first time in the context of game playing - leads to better results than the
other approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9512107</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9512107</id><created>1995-11-30</created><authors><author><keyname>Weiss</keyname><forenames>S. M.</forenames></author><author><keyname>Indurkhya</keyname><forenames>N.</forenames></author></authors><title>Rule-based Machine Learning Methods for Functional Prediction</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 3, (1995),
  383-403</journal-ref><abstract>  We describe a machine learning method for predicting the value of a
real-valued function, given the values of multiple input variables. The method
induces solutions from samples in the form of ordered disjunctive normal form
(DNF) decision rules. A central objective of the method and representation is
the induction of compact, easily interpretable solutions. This rule-based
decision model can be extended to search efficiently for similar cases prior to
approximating function values. Experimental results on real-world data
demonstrate that the new techniques are competitive with existing machine
learning and statistical methods and can sometimes yield superior regression
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9601101</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9601101</id><created>1995-12-31</created><authors><author><keyname>vanBeek</keyname><forenames>P.</forenames></author><author><keyname>Manchak</keyname><forenames>D. W.</forenames></author></authors><title>The Design and Experimental Analysis of Algorithms for Temporal Reasoning</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 4, (1996), 1-18</journal-ref><abstract>  Many applications -- from planning and scheduling to problems in molecular
biology -- rely heavily on a temporal reasoning component. In this paper, we
discuss the design and empirical analysis of algorithms for a temporal
reasoning system based on Allen's influential interval-based framework for
representing temporal information. At the core of the system are algorithms for
determining whether the temporal information is consistent, and, if so, finding
one or more scenarios that are consistent with the temporal information. Two
important algorithms for these tasks are a path consistency algorithm and a
backtracking algorithm. For the path consistency algorithm, we develop
techniques that can result in up to a ten-fold speedup over an already highly
optimized implementation. For the backtracking algorithm, we develop variable
and value ordering heuristics that are shown empirically to dramatically
improve the performance of the algorithm. As well, we show that a previously
suggested reformulation of the backtracking search problem can reduce the time
and space requirements of the backtracking search. Taken together, the
techniques we develop allow a temporal reasoning component to solve problems
that are of practical size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9602101</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9602101</id><created>1996-01-31</created><authors><author><keyname>Brewka</keyname><forenames>G.</forenames></author></authors><title>Well-Founded Semantics for Extended Logic Programs with Dynamic
  Preferences</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 4, (1996), 19-36</journal-ref><abstract>  The paper describes an extension of well-founded semantics for logic programs
with two types of negation. In this extension information about preferences
between rules can be expressed in the logical language and derived dynamically.
This is achieved by using a reserved predicate symbol and a naming technique.
Conflicts among rules are resolved whenever possible on the basis of derived
preference information. The well-founded conclusions of prioritized logic
programs can be computed in polynomial time. A legal reasoning example
illustrates the usefulness of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9602102</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9602102</id><created>1996-01-31</created><authors><author><keyname>Delcher</keyname><forenames>A. L.</forenames></author><author><keyname>Grove</keyname><forenames>A. J.</forenames></author><author><keyname>Kasif</keyname><forenames>S.</forenames></author><author><keyname>Pearl</keyname><forenames>J.</forenames></author></authors><title>Logarithmic-Time Updates and Queries in Probabilistic Networks</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 4, (1996), 37-59</journal-ref><abstract>  Traditional databases commonly support efficient query and update procedures
that operate in time which is sublinear in the size of the database. Our goal
in this paper is to take a first step toward dynamic reasoning in probabilistic
databases with comparable efficiency. We propose a dynamic data structure that
supports efficient algorithms for updating and querying singly connected
Bayesian networks. In the conventional algorithm, new evidence is absorbed in
O(1) time and queries are processed in time O(N), where N is the size of the
network. We propose an algorithm which, after a preprocessing phase, allows us
to answer queries in time O(log N) at the expense of O(log N) time per evidence
absorption. The usefulness of sub-linear processing time manifests itself in
applications requiring (near) real-time response over large probabilistic
databases. We briefly discuss a potential application of dynamic probabilistic
reasoning in computational biology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9603101</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9603101</id><created>1996-02-29</created><authors><author><keyname>Hogg</keyname><forenames>T.</forenames></author></authors><title>Quantum Computing and Phase Transitions in Combinatorial Search</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 4, (1996), 91-128</journal-ref><abstract>  We introduce an algorithm for combinatorial search on quantum computers that
is capable of significantly concentrating amplitude into solutions for some NP
search problems, on average. This is done by exploiting the same aspects of
problem structure as used by classical backtrack methods to avoid unproductive
search choices. This quantum algorithm is much more likely to find solutions
than the simple direct use of quantum parallelism. Furthermore, empirical
evaluation on small problems shows this quantum algorithm displays the same
phase transition behavior, and at the same location, as seen in many previously
studied classical search methods. Specifically, difficult problem instances are
concentrated near the abrupt change from underconstrained to overconstrained
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9603102</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9603102</id><created>1996-02-29</created><authors><author><keyname>Saul</keyname><forenames>L. K.</forenames></author><author><keyname>Jaakkola</keyname><forenames>T.</forenames></author><author><keyname>Jordan</keyname><forenames>M. I.</forenames></author></authors><title>Mean Field Theory for Sigmoid Belief Networks</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 4, (1996), 61-76</journal-ref><abstract>  We develop a mean field theory for sigmoid belief networks based on ideas
from statistical mechanics. Our mean field theory provides a tractable
approximation to the true probability distribution in these networks; it also
yields a lower bound on the likelihood of evidence. We demonstrate the utility
of this framework on a benchmark problem in statistical pattern
recognition---the classification of handwritten digits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9603103</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9603103</id><created>1996-02-29</created><authors><author><keyname>Quinlan</keyname><forenames>J. R.</forenames></author></authors><title>Improved Use of Continuous Attributes in C4.5</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 4, (1996), 77-90</journal-ref><abstract>  A reported weakness of C4.5 in domains with continuous attributes is
addressed by modifying the formation and evaluation of tests on continuous
attributes. An MDL-inspired penalty is applied to such tests, eliminating some
of them from consideration and altering the relative desirability of all tests.
Empirical trials show that the modifications lead to smaller decision trees
with higher predictive accuracies. Results also confirm that a new version of
C4.5 incorporating these changes is superior to recent approaches that use
global discretization and that construct small trees with multi-interval
splits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9603104</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9603104</id><created>1996-02-29</created><authors><author><keyname>Cohn</keyname><forenames>D. A.</forenames></author><author><keyname>Ghahramani</keyname><forenames>Z.</forenames></author><author><keyname>Jordan</keyname><forenames>M. I.</forenames></author></authors><title>Active Learning with Statistical Models</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 4, (1996),
  129-145</journal-ref><abstract>  For many types of machine learning algorithms, one can compute the
statistically `optimal' way to select training data. In this paper, we review
how optimal data selection techniques have been used with feedforward neural
networks. We then show how the same principles may be used to select data for
two alternative, statistically-based learning architectures: mixtures of
Gaussians and locally weighted regression. While the techniques for neural
networks are computationally expensive and approximate, the techniques for
mixtures of Gaussians and locally weighted regression are both efficient and
accurate. Empirically, we observe that the optimality criterion sharply
decreases the number of training examples the learner needs in order to achieve
good performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9604101</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9604101</id><created>1996-03-31</created><authors><author><keyname>Walsh</keyname><forenames>T.</forenames></author></authors><title>A Divergence Critic for Inductive Proof</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 4, (1996),
  209-235</journal-ref><abstract>  Inductive theorem provers often diverge. This paper describes a simple
critic, a computer program which monitors the construction of inductive proofs
attempting to identify diverging proof attempts. Divergence is recognized by
means of a ``difference matching'' procedure. The critic then proposes lemmas
and generalizations which ``ripple'' these differences away so that the proof
can go through without divergence. The critic enables the theorem prover Spike
to prove many theorems completely automatically from the definitions alone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9604102</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9604102</id><created>1996-03-31</created><authors><author><keyname>Marchiori</keyname><forenames>E.</forenames></author></authors><title>Practical Methods for Proving Termination of General Logic Programs</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 4, (1996),
  179-208</journal-ref><abstract>  Termination of logic programs with negated body atoms (here called general
logic programs) is an important topic. One reason is that many computational
mechanisms used to process negated atoms, like Clark's negation as failure and
Chan's constructive negation, are based on termination conditions. This paper
introduces a methodology for proving termination of general logic programs
w.r.t. the Prolog selection rule. The idea is to distinguish parts of the
program depending on whether or not their termination depends on the selection
rule. To this end, the notions of low-, weakly up-, and up-acceptable program
are introduced. We use these notions to develop a methodology for proving
termination of general logic programs, and show how interesting problems in
non-monotonic reasoning can be formalized and implemented by means of
terminating general logic programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9604103</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9604103</id><created>1996-03-31</created><authors><author><keyname>Fisher</keyname><forenames>D.</forenames></author></authors><title>Iterative Optimization and Simplification of Hierarchical Clusterings</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 4, (1996),
  147-178</journal-ref><abstract>  Clustering is often used for discovering structure in data. Clustering
systems differ in the objective function used to evaluate clustering quality
and the control strategy used to search the space of clusterings. Ideally, the
search strategy should consistently construct clusterings of high quality, but
be computationally inexpensive as well. In general, we cannot have it both
ways, but we can partition the search so that a system inexpensively constructs
a `tentative' clustering for initial examination, followed by iterative
optimization, which continues to search in background for improved clusterings.
Given this motivation, we evaluate an inexpensive strategy for creating initial
clusterings, coupled with several control strategies for iterative
optimization, each of which repeatedly modifies an initial clustering in search
of a better one. One of these methods appears novel as an iterative
optimization strategy in clustering contexts. Once a clustering has been
constructed it is judged by analysts -- often according to task-specific
criteria. Several authors have abstracted these criteria and posited a generic
performance task akin to pattern completion, where the error rate over
completed patterns is used to `externally' judge clustering utility. Given this
performance task, we adapt resampling-based pruning strategies used by
supervised learning systems to the task of simplifying hierarchical
clusterings, thus promising to ease post-clustering analysis. Finally, we
propose a number of objective functions, based on attribute-selection measures
for decision-tree induction, that might perform well on the error rate and
simplicity dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9605101</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9605101</id><created>1996-04-30</created><authors><author><keyname>Webb</keyname><forenames>G. I.</forenames></author></authors><title>Further Experimental Evidence against the Utility of Occam's Razor</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 4, (1996),
  397-417</journal-ref><abstract>  This paper presents new experimental evidence against the utility of Occam's
razor. A~systematic procedure is presented for post-processing decision trees
produced by C4.5. This procedure was derived by rejecting Occam's razor and
instead attending to the assumption that similar objects are likely to belong
to the same class. It increases a decision tree's complexity without altering
the performance of that tree on the training data from which it is inferred.
The resulting more complex decision trees are demonstrated to have, on average,
for a variety of common learning tasks, higher predictive accuracy than the
less complex original decision trees. This result raises considerable doubt
about the utility of Occam's razor as it is commonly applied in modern machine
learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9605102</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9605102</id><created>1996-04-30</created><authors><author><keyname>Nienhuys-Cheng</keyname><forenames>S. H.</forenames></author><author><keyname>deWolf</keyname><forenames>R.</forenames></author></authors><title>Least Generalizations and Greatest Specializations of Sets of Clauses</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 4, (1996),
  341-363</journal-ref><abstract>  The main operations in Inductive Logic Programming (ILP) are generalization
and specialization, which only make sense in a generality order. In ILP, the
three most important generality orders are subsumption, implication and
implication relative to background knowledge. The two languages used most often
are languages of clauses and languages of only Horn clauses. This gives a total
of six different ordered languages. In this paper, we give a systematic
treatment of the existence or non-existence of least generalizations and
greatest specializations of finite sets of clauses in each of these six ordered
sets. We survey results already obtained by others and also contribute some
answers of our own. Our main new results are, firstly, the existence of a
computable least generalization under implication of every finite set of
clauses containing at least one non-tautologous function-free clause (among
other, not necessarily function-free clauses). Secondly, we show that such a
least generalization need not exist under relative implication, not even if
both the set that is to be generalized and the background knowledge are
function-free. Thirdly, we give a complete discussion of existence and
non-existence of greatest specializations in each of the six ordered languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9605103</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9605103</id><created>1996-04-30</created><authors><author><keyname>Kaelbling</keyname><forenames>L. P.</forenames></author><author><keyname>Littman</keyname><forenames>M. L.</forenames></author><author><keyname>Moore</keyname><forenames>A. W.</forenames></author></authors><title>Reinforcement Learning: A Survey</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 4, (1996),
  237-285</journal-ref><abstract>  This paper surveys the field of reinforcement learning from a
computer-science perspective. It is written to be accessible to researchers
familiar with machine learning. Both the historical basis of the field and a
broad selection of current work are summarized. Reinforcement learning is the
problem faced by an agent that learns behavior through trial-and-error
interactions with a dynamic environment. The work described here has a
resemblance to work in psychology, but differs considerably in the details and
in the use of the word ``reinforcement.'' The paper discusses central issues of
reinforcement learning, including trading off exploration and exploitation,
establishing the foundations of the field via Markov decision theory, learning
from delayed reinforcement, constructing empirical models to accelerate
learning, making use of generalization and hierarchy, and coping with hidden
state. It concludes with a survey of some implemented systems and an assessment
of the practical utility of current methods for reinforcement learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9605104</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9605104</id><created>1996-04-30</created><authors><author><keyname>Gratch</keyname><forenames>J.</forenames></author><author><keyname>Chien</keyname><forenames>S.</forenames></author></authors><title>Adaptive Problem-solving for Large-scale Scheduling Problems: A Case
  Study</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 4, (1996),
  365-396</journal-ref><abstract>  Although most scheduling problems are NP-hard, domain specific techniques
perform well in practice but are quite expensive to construct. In adaptive
problem-solving solving, domain specific knowledge is acquired automatically
for a general problem solver with a flexible control architecture. In this
approach, a learning system explores a space of possible heuristic methods for
one well-suited to the eccentricities of the given domain and problem
distribution. In this article, we discuss an application of the approach to
scheduling satellite communications. Using problem distributions based on
actual mission requirements, our approach identifies strategies that not only
decrease the amount of CPU time required to produce schedules, but also
increase the percentage of problems that are solvable within computational
resource limitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9605105</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9605105</id><created>1996-04-30</created><authors><author><keyname>Tadepalli</keyname><forenames>P.</forenames></author><author><keyname>Natarajan</keyname><forenames>B. K.</forenames></author></authors><title>A Formal Framework for Speedup Learning from Problems and Solutions</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 4, (1996),
  445-475</journal-ref><abstract>  Speedup learning seeks to improve the computational efficiency of problem
solving with experience. In this paper, we develop a formal framework for
learning efficient problem solving from random problems and their solutions. We
apply this framework to two different representations of learned knowledge,
namely control rules and macro-operators, and prove theorems that identify
sufficient conditions for learning in each representation. Our proofs are
constructive in that they are accompanied with learning algorithms. Our
framework captures both empirical and explanation-based speedup learning in a
unified fashion. We illustrate our framework with implementations in two
domains: symbolic integration and Eight Puzzle. This work integrates many
strands of experimental and theoretical work in machine learning, including
empirical learning of control rules, macro-operator learning, Explanation-Based
Learning (EBL), and Probably Approximately Correct (PAC) Learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9605106</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9605106</id><created>1996-04-30</created><authors><author><keyname>Pryor</keyname><forenames>L.</forenames></author><author><keyname>Collins</keyname><forenames>G.</forenames></author></authors><title>2Planning for Contingencies: A Decision-based Approach</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 4, (1996),
  287-339</journal-ref><abstract>  A fundamental assumption made by classical AI planners is that there is no
uncertainty in the world: the planner has full knowledge of the conditions
under which the plan will be executed and the outcome of every action is fully
predictable. These planners cannot therefore construct contingency plans, i.e.,
plans in which different actions are performed in different circumstances. In
this paper we discuss some issues that arise in the representation and
construction of contingency plans and describe Cassandra, a partial-order
contingency planner. Cassandra uses explicit decision-steps that enable the
agent executing the plan to decide which plan branch to follow. The
decision-steps in a plan result in subgoals to acquire knowledge, which are
planned for in the same way as any other subgoals. Cassandra thus distinguishes
the process of gathering information from the process of making decisions. The
explicit representation of decisions in Cassandra allows a coherent approach to
the problems of contingent planning, and provides a solid base for extensions
such as the use of different decision-making procedures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9606101</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9606101</id><created>1996-05-31</created><authors><author><keyname>Bhansali</keyname><forenames>S.</forenames></author><author><keyname>Kramer</keyname><forenames>G. A.</forenames></author><author><keyname>Hoar</keyname><forenames>T. J.</forenames></author></authors><title>A Principled Approach Towards Symbolic Geometric Constraint Satisfaction</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 4, (1996),
  419-443</journal-ref><abstract>  An important problem in geometric reasoning is to find the configuration of a
collection of geometric bodies so as to satisfy a set of given constraints.
Recently, it has been suggested that this problem can be solved efficiently by
symbolically reasoning about geometry. This approach, called degrees of freedom
analysis, employs a set of specialized routines called plan fragments that
specify how to change the configuration of a set of bodies to satisfy a new
constraint while preserving existing constraints. A potential drawback, which
limits the scalability of this approach, is concerned with the difficulty of
writing plan fragments. In this paper we address this limitation by showing how
these plan fragments can be automatically synthesized using first principles
about geometric bodies, actions, and topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9606102</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9606102</id><created>1996-05-31</created><authors><author><keyname>Brafman</keyname><forenames>R. I.</forenames></author><author><keyname>Tennenholtz</keyname><forenames>M.</forenames></author></authors><title>On Partially Controlled Multi-Agent Systems</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 4, (1996),
  477-507</journal-ref><abstract>  Motivated by the control theoretic distinction between controllable and
uncontrollable events, we distinguish between two types of agents within a
multi-agent system: controllable agents, which are directly controlled by the
system's designer, and uncontrollable agents, which are not under the
designer's direct control. We refer to such systems as partially controlled
multi-agent systems, and we investigate how one might influence the behavior of
the uncontrolled agents through appropriate design of the controlled agents. In
particular, we wish to understand which problems are naturally described in
these terms, what methods can be applied to influence the uncontrollable
agents, the effectiveness of such methods, and whether similar methods work
across different domains. Using a game-theoretic framework, this paper studies
the design of partially controlled multi-agent systems in two contexts: in one
context, the uncontrollable agents are expected utility maximizers, while in
the other they are reinforcement learners. We suggest different techniques for
controlling agents' behavior in each domain, assess their success, and examine
their relationship.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9608103</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9608103</id><created>1996-07-31</created><authors><author><keyname>Yip</keyname><forenames>K.</forenames></author><author><keyname>Zhao</keyname><forenames>F.</forenames></author></authors><title>Spatial Aggregation: Theory and Applications</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 5, (1996), 1-26</journal-ref><abstract>  Visual thinking plays an important role in scientific reasoning. Based on the
research in automating diverse reasoning tasks about dynamical systems,
nonlinear controllers, kinematic mechanisms, and fluid motion, we have
identified a style of visual thinking, imagistic reasoning. Imagistic reasoning
organizes computations around image-like, analogue representations so that
perceptual and symbolic operations can be brought to bear to infer structure
and behavior. Programs incorporating imagistic reasoning have been shown to
perform at an expert level in domains that defy current analytic or numerical
methods. We have developed a computational paradigm, spatial aggregation, to
unify the description of a class of imagistic problem solvers. A program
written in this paradigm has the following properties. It takes a continuous
field and optional objective functions as input, and produces high-level
descriptions of structure, behavior, or control actions. It computes a
multi-layer of intermediate representations, called spatial aggregates, by
forming equivalence classes and adjacency relations. It employs a small set of
generic operators such as aggregation, classification, and localization to
perform bidirectional mapping between the information-rich field and
successively more abstract spatial aggregates. It uses a data structure, the
neighborhood graph, as a common interface to modularize computations. To
illustrate our theory, we describe the computational structure of three
implemented problem solvers -- KAM, MAPS, and HIPAIR --- in terms of the
spatial aggregation generic operators by mixing and matching a library of
commonly used routines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9608104</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9608104</id><created>1996-07-31</created><authors><author><keyname>Ben-Eliyahu</keyname><forenames>R.</forenames></author></authors><title>A Hierarchy of Tractable Subsets for Computing Stable Models</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 5, (1996), 27-52</journal-ref><abstract>  Finding the stable models of a knowledge base is a significant computational
problem in artificial intelligence. This task is at the computational heart of
truth maintenance systems, autoepistemic logic, and default logic.
Unfortunately, it is NP-hard. In this paper we present a hierarchy of classes
of knowledge bases, Omega_1,Omega_2,..., with the following properties: first,
Omega_1 is the class of all stratified knowledge bases; second, if a knowledge
base Pi is in Omega_k, then Pi has at most k stable models, and all of them may
be found in time O(lnk), where l is the length of the knowledge base and n the
number of atoms in Pi; third, for an arbitrary knowledge base Pi, we can find
the minimum k such that Pi belongs to Omega_k in time polynomial in the size of
Pi; and, last, where K is the class of all knowledge bases, it is the case that
union{i=1 to infty} Omega_i = K, that is, every knowledge base belongs to some
class in the hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9608105</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9608105</id><created>1996-08-21</created><authors><author><keyname>Janson</keyname><forenames>Svante</forenames></author><author><keyname>Knuth</keyname><forenames>Donald E.</forenames></author></authors><title>Shellsort with three increments</title><categories>cs.DS</categories><report-no>Knuth migration 11/2004</report-no><journal-ref>Random Structures Algorithms 10 (1997), no. 1-2, 125--142</journal-ref><abstract>  A perturbation technique can be used to simplify and sharpen A. C. Yao's
theorems about the behavior of shellsort with increments $(h,g,1)$. In
particular, when $h=\Theta(n^{7/15})$ and $g=\Theta(h^{1/5})$, the average
running time is $O(n^{23/15})$. The proof involves interesting properties of
the inversions in random permutations that have been $h$-sorted and $g$-sorted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9609101</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9609101</id><created>1996-08-31</created><authors><author><keyname>Gerevini</keyname><forenames>A.</forenames></author><author><keyname>Schubert</keyname><forenames>L.</forenames></author></authors><title>Accelerating Partial-Order Planners: Some Techniques for Effective
  Search Control and Pruning</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 5, (1996), 95-137</journal-ref><abstract>  We propose some domain-independent techniques for bringing well-founded
partial-order planners closer to practicality. The first two techniques are
aimed at improving search control while keeping overhead costs low. One is
based on a simple adjustment to the default A* heuristic used by UCPOP to
select plans for refinement. The other is based on preferring ``zero
commitment'' (forced) plan refinements whenever possible, and using LIFO
prioritization otherwise. A more radical technique is the use of operator
parameter domains to prune search. These domains are initially computed from
the definitions of the operators and the initial and goal conditions, using a
polynomial-time algorithm that propagates sets of constants through the
operator graph, starting in the initial conditions. During planning, parameter
domains can be used to prune nonviable operator instances and to remove
spurious clobbering threats. In experiments based on modifications of UCPOP,
our improved plan and goal selection strategies gave speedups by factors
ranging from 5 to more than 1000 for a variety of problems that are nontrivial
for the unmodified version. Crucially, the hardest problems gave the greatest
improvements. The pruning technique based on parameter domains often gave
speedups by an order of magnitude or more for difficult problems, both with the
default UCPOP search strategy and with our improved strategy. The Lisp code for
our techniques and for the test problems is provided in on-line appendices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9609102</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9609102</id><created>1996-08-31</created><authors><author><keyname>Litman</keyname><forenames>D. J.</forenames></author></authors><title>Cue Phrase Classification Using Machine Learning</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 5, (1996), 53-94</journal-ref><abstract>  Cue phrases may be used in a discourse sense to explicitly signal discourse
structure, but also in a sentential sense to convey semantic rather than
structural information. Correctly classifying cue phrases as discourse or
sentential is critical in natural language processing systems that exploit
discourse structure, e.g., for performing tasks such as anaphora resolution and
plan recognition. This paper explores the use of machine learning for
classifying cue phrases as discourse or sentential. Two machine learning
programs (Cgrendel and C4.5) are used to induce classification models from sets
of pre-classified cue phrases and their features in text and speech. Machine
learning is shown to be an effective technique for not only automating the
generation of classification models, but also for improving upon previous
results. When compared to manually derived classification models already in the
literature, the learned models often perform with higher accuracy and contain
new linguistic insights into the data. In addition, the ability to
automatically construct classification models makes it easier to comparatively
analyze the utility of alternative feature representations of the data.
Finally, the ease of retraining makes the learning approach more scalable and
flexible than manual methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9610101</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9610101</id><created>1996-09-30</created><authors><author><keyname>Zlotkin</keyname><forenames>G.</forenames></author><author><keyname>Rosenschein</keyname><forenames>J. S.</forenames></author></authors><title>Mechanisms for Automated Negotiation in State Oriented Domains</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 5, (1996),
  163-238</journal-ref><abstract>  This paper lays part of the groundwork for a domain theory of negotiation,
that is, a way of classifying interactions so that it is clear, given a domain,
which negotiation mechanisms and strategies are appropriate. We define State
Oriented Domains, a general category of interaction. Necessary and sufficient
conditions for cooperation are outlined. We use the notion of worth in an
altered definition of utility, thus enabling agreements in a wider class of
joint-goal reachable situations. An approach is offered for conflict
resolution, and it is shown that even in a conflict situation, partial
cooperative steps can be taken by interacting agents (that is, agents in
fundamental conflict might still agree to cooperate up to a certain point). A
Unified Negotiation Protocol (UNP) is developed that can be used in all types
of encounters. It is shown that in certain borderline cooperative situations, a
partial cooperative agreement (i.e., one that does not achieve all agents'
goals) might be preferred by all agents, even though there exists a rational
agreement that would achieve all their goals. Finally, we analyze cases where
agents have incomplete information on the goals and worth of other agents.
First we consider the case where agents' goals are private information, and we
analyze what goal declaration strategies the agents might adopt to increase
their utility. Then, we consider the situation where the agents' goals (and
therefore stand-alone costs) are common knowledge, but the worth they attach to
their goals is private information. We introduce two mechanisms, one 'strict',
the other 'tolerant', and analyze their affects on the stability and efficiency
of negotiation outcomes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9610102</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9610102</id><created>1996-09-30</created><authors><author><keyname>Quinlan</keyname><forenames>J. R.</forenames></author></authors><title>Learning First-Order Definitions of Functions</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 5, (1996),
  139-161</journal-ref><abstract>  First-order learning involves finding a clause-form definition of a relation
from examples of the relation and relevant background information. In this
paper, a particular first-order learning system is modified to customize it for
finding definitions of functional relations. This restriction leads to faster
learning times and, in some cases, to definitions that have higher predictive
accuracy. Other first-order learning systems might benefit from similar
specialization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9611101</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9611101</id><created>1996-10-31</created><authors><author><keyname>Helzerman</keyname><forenames>R. A</forenames></author><author><keyname>Harper</keyname><forenames>M. P.</forenames></author></authors><title>MUSE CSP: An Extension to the Constraint Satisfaction Problem</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 5, (1996),
  239-288</journal-ref><abstract>  This paper describes an extension to the constraint satisfaction problem
(CSP) called MUSE CSP (MUltiply SEgmented Constraint Satisfaction Problem).
This extension is especially useful for those problems which segment into
multiple sets of partially shared variables. Such problems arise naturally in
signal processing applications including computer vision, speech processing,
and handwriting recognition. For these applications, it is often difficult to
segment the data in only one way given the low-level information utilized by
the segmentation algorithms. MUSE CSP can be used to compactly represent
several similar instances of the constraint satisfaction problem. If multiple
instances of a CSP have some common variables which have the same domains and
constraints, then they can be combined into a single instance of a MUSE CSP,
reducing the work required to apply the constraints. We introduce the concepts
of MUSE node consistency, MUSE arc consistency, and MUSE path consistency. We
then demonstrate how MUSE CSP can be used to compactly represent lexically
ambiguous sentences and the multiple sentence hypotheses that are often
generated by speech recognition algorithms so that grammar constraints can be
used to provide parses for all syntactically correct sentences. Algorithms for
MUSE arc and path consistency are provided. Finally, we discuss how to create a
MUSE CSP from a set of CSPs which are labeled to indicate when the same
variable is shared by more than a single CSP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9612101</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9612101</id><created>1996-11-30</created><authors><author><keyname>Zhang</keyname><forenames>N. L.</forenames></author><author><keyname>Poole</keyname><forenames>D.</forenames></author></authors><title>Exploiting Causal Independence in Bayesian Network Inference</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 5, (1996),
  301-328</journal-ref><abstract>  A new method is proposed for exploiting causal independencies in exact
Bayesian network inference. A Bayesian network can be viewed as representing a
factorization of a joint probability into the multiplication of a set of
conditional probabilities. We present a notion of causal independence that
enables one to further factorize the conditional probabilities into a
combination of even smaller factors and consequently obtain a finer-grain
factorization of the joint probability. The new formulation of causal
independence lets us specify the conditional probability of a variable given
its parents in terms of an associative and commutative operator, such as
``or'', ``sum'' or ``max'', on the contribution of each parent. We start with a
simple algorithm VE for Bayesian network inference that, given evidence and a
query variable, uses the factorization to find the posterior distribution of
the query. We show how this algorithm can be extended to exploit causal
independence. Empirical studies, based on the CPCS networks for medical
diagnosis, show that this method is more efficient than previous methods and
allows for inference in larger networks than previous algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9612102</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9612102</id><created>1996-11-30</created><authors><author><keyname>Schlimmer</keyname><forenames>J. C.</forenames></author><author><keyname>Wells</keyname><forenames>P. C.</forenames></author></authors><title>Quantitative Results Comparing Three Intelligent Interfaces for
  Information Capture: A Case Study Adding Name Information into an Electronic
  Personal Organizer</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 5, (1996),
  329-349</journal-ref><abstract>  Efficiently entering information into a computer is key to enjoying the
benefits of computing. This paper describes three intelligent user interfaces:
handwriting recognition, adaptive menus, and predictive fillin. In the context
of adding a personUs name and address to an electronic organizer, tests show
handwriting recognition is slower than typing on an on-screen, soft keyboard,
while adaptive menus and predictive fillin can be twice as fast. This paper
also presents strategies for applying these three interfaces to other
information collection domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9612103</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9612103</id><created>1996-11-30</created><authors><author><keyname>deCampos</keyname><forenames>L. M.</forenames></author></authors><title>Characterizations of Decomposable Dependency Models</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 5, (1996),
  289-300</journal-ref><abstract>  Decomposable dependency models possess a number of interesting and useful
properties. This paper presents new characterizations of decomposable models in
terms of independence relationships, which are obtained by adding a single
axiom to the well-known set characterizing dependency models that are
isomorphic to undirected graphs. We also briefly discuss a potential
application of our results to the problem of learning graphical models from
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9612104</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9612104</id><created>2001-03-28</created><authors><author><keyname>Paulson</keyname><forenames>Lawrence C.</forenames></author><author><keyname>Grabczewski</keyname><forenames>Krzysztof</forenames></author></authors><title>Mechanizing Set Theory: Cardinal Arithmetic and the Axiom of Choice.</title><categories>cs.LO</categories><acm-class>F.4.1</acm-class><journal-ref>Journal of Automated Reasoning 17 (1996), 291-323</journal-ref><abstract>  Fairly deep results of Zermelo-Frenkel (ZF) set theory have been mechanized
using the proof assistant Isabelle. The results concern cardinal arithmetic
and the Axiom of Choice (AC). A key result about cardinal multiplication is
K*K = K, where K is any infinite cardinal. Proving this result required
developing theories of orders, order-isomorphisms, order types, ordinal
arithmetic, cardinals, etc.; this covers most of Kunen, Set Theory, Chapter
I. Furthermore, we have proved the equivalence of 7 formulations of the
Well-ordering Theorem and 20 formulations of AC; this covers the first two
chapters of Rubin and Rubin, Equivalents of the Axiom of Choice, and involves
highly technical material. The definitions used in the proofs are largely
faithful in style to the original mathematics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9701101</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9701101</id><created>1996-12-31</created><authors><author><keyname>Wilson</keyname><forenames>D. R.</forenames></author><author><keyname>Martinez</keyname><forenames>T. R.</forenames></author></authors><title>Improved Heterogeneous Distance Functions</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 6, (1997), 1-34</journal-ref><abstract>  Instance-based learning techniques typically handle continuous and linear
input values well, but often do not handle nominal input attributes
appropriately. The Value Difference Metric (VDM) was designed to find
reasonable distance values between nominal attribute values, but it largely
ignores continuous attributes, requiring discretization to map continuous
values into nominal values. This paper proposes three new heterogeneous
distance functions, called the Heterogeneous Value Difference Metric (HVDM),
the Interpolated Value Difference Metric (IVDM), and the Windowed Value
Difference Metric (WVDM). These new distance functions are designed to handle
applications with nominal attributes, continuous attributes, or both. In
experiments on 48 applications the new distance metrics achieve higher
classification accuracy on average than three previous distance functions on
those datasets that have both nominal and continuous attributes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9701102</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9701102</id><created>1996-12-31</created><authors><author><keyname>Wermter</keyname><forenames>S.</forenames></author><author><keyname>Weber</keyname><forenames>V.</forenames></author></authors><title>SCREEN: Learning a Flat Syntactic and Semantic Spoken Language Analysis
  Using Artificial Neural Networks</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 6, (1997), 35-85</journal-ref><abstract>  Previous approaches of analyzing spontaneously spoken language often have
been based on encoding syntactic and semantic knowledge manually and
symbolically. While there has been some progress using statistical or
connectionist language models, many current spoken- language systems still use
a relatively brittle, hand-coded symbolic grammar or symbolic semantic
component. In contrast, we describe a so-called screening approach for learning
robust processing of spontaneously spoken language. A screening approach is a
flat analysis which uses shallow sequences of category representations for
analyzing an utterance at various syntactic, semantic and dialog levels. Rather
than using a deeply structured symbolic analysis, we use a flat connectionist
analysis. This screening approach aims at supporting speech and language
processing by using (1) data-driven learning and (2) robustness of
connectionist networks. In order to test this approach, we have developed the
SCREEN system which is based on this new robust, learned and flat analysis. In
this paper, we focus on a detailed description of SCREEN's architecture, the
flat syntactic and semantic analysis, the interaction with a speech recognizer,
and a detailed evaluation analysis of the robustness under the influence of
noisy or incomplete input. The main result of this paper is that flat
representations allow more robust processing of spontaneous spoken language
than deeply structured representations. In particular, we show how the
fault-tolerance and learning capability of connectionist networks can support a
flat analysis for providing more robust spoken-language processing within an
overall hybrid symbolic/connectionist framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9703101</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9703101</id><created>1997-02-28</created><authors><author><keyname>DeGiacomo</keyname><forenames>G.</forenames></author><author><keyname>Lenzerini</keyname><forenames>M.</forenames></author></authors><title>A Uniform Framework for Concept Definitions in Description Logics</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 6, (1997), 87-110</journal-ref><abstract>  Most modern formalisms used in Databases and Artificial Intelligence for
describing an application domain are based on the notions of class (or concept)
and relationship among classes. One interesting feature of such formalisms is
the possibility of defining a class, i.e., providing a set of properties that
precisely characterize the instances of the class. Many recent articles point
out that there are several ways of assigning a meaning to a class definition
containing some sort of recursion. In this paper, we argue that, instead of
choosing a single style of semantics, we achieve better results by adopting a
formalism that allows for different semantics to coexist. We demonstrate the
feasibility of our argument, by presenting a knowledge representation
formalism, the description logic muALCQ, with the above characteristics. In
addition to the constructs for conjunction, disjunction, negation, quantifiers,
and qualified number restrictions, muALCQ includes special fixpoint constructs
to express (suitably interpreted) recursive definitions. These constructs
enable the usual frame-based descriptions to be combined with definitions of
recursive data structures such as directed acyclic graphs, lists, streams, etc.
We establish several properties of muALCQ, including the decidability and the
computational complexity of reasoning, by formulating a correspondence with a
particular modal logic of programs called the modal mu-calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9704101</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9704101</id><created>1997-03-31</created><authors><author><keyname>Agre</keyname><forenames>P.</forenames></author><author><keyname>Horswill</keyname><forenames>I.</forenames></author></authors><title>Lifeworld Analysis</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 6, (1997),
  111-145</journal-ref><abstract>  We argue that the analysis of agent/environment interactions should be
extended to include the conventions and invariants maintained by agents
throughout their activity. We refer to this thicker notion of environment as a
lifeworld and present a partial set of formal tools for describing structures
of lifeworlds and the ways in which they computationally simplify activity. As
one specific example, we apply the tools to the analysis of the Toast system
and show how versions of the system with very different control structures in
fact implement a common control structure together with different conventions
for encoding task state in the positions or states of objects in the
environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9705101</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9705101</id><created>1997-04-30</created><authors><author><keyname>Darwiche</keyname><forenames>A.</forenames></author><author><keyname>Provan</keyname><forenames>G.</forenames></author></authors><title>Query DAGs: A Practical Paradigm for Implementing Belief-Network
  Inference</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 6, (1997),
  147-176</journal-ref><abstract>  We describe a new paradigm for implementing inference in belief networks,
which consists of two steps: (1) compiling a belief network into an arithmetic
expression called a Query DAG (Q-DAG); and (2) answering queries using a simple
evaluation algorithm. Each node of a Q-DAG represents a numeric operation, a
number, or a symbol for evidence. Each leaf node of a Q-DAG represents the
answer to a network query, that is, the probability of some event of interest.
It appears that Q-DAGs can be generated using any of the standard algorithms
for exact inference in belief networks (we show how they can be generated using
clustering and conditioning algorithms). The time and space complexity of a
Q-DAG generation algorithm is no worse than the time complexity of the
inference algorithm on which it is based. The complexity of a Q-DAG evaluation
algorithm is linear in the size of the Q-DAG, and such inference amounts to a
standard evaluation of the arithmetic expression it represents. The intended
value of Q-DAGs is in reducing the software and hardware resources required to
utilize belief networks in on-line, real-world applications. The proposed
framework also facilitates the development of on-line inference on different
software and hardware platforms due to the simplicity of the Q-DAG evaluation
algorithm. Interestingly enough, Q-DAGs were found to serve other purposes:
simple techniques for reducing Q-DAGs tend to subsume relatively complex
optimization techniques for belief-network inference, such as network-pruning
and computation-caching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9705102</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9705102</id><created>1997-04-30</created><authors><author><keyname>Opitz</keyname><forenames>D. W.</forenames></author><author><keyname>Shavlik</keyname><forenames>J. W.</forenames></author></authors><title>Connectionist Theory Refinement: Genetically Searching the Space of
  Network Topologies</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 6, (1997),
  177-209</journal-ref><abstract>  An algorithm that learns from a set of examples should ideally be able to
exploit the available resources of (a) abundant computing power and (b)
domain-specific knowledge to improve its ability to generalize. Connectionist
theory-refinement systems, which use background knowledge to select a neural
network's topology and initial weights, have proven to be effective at
exploiting domain-specific knowledge; however, most do not exploit available
computing power. This weakness occurs because they lack the ability to refine
the topology of the neural networks they produce, thereby limiting
generalization, especially when given impoverished domain theories. We present
the REGENT algorithm which uses (a) domain-specific knowledge to help create an
initial population of knowledge-based neural networks and (b) genetic operators
of crossover and mutation (specifically designed for knowledge-based networks)
to continually search for better network topologies. Experiments on three
real-world domains indicate that our new algorithm is able to significantly
increase generalization compared to a standard connectionist theory-refinement
system, as well as our previous algorithm for growing knowledge-based networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9706101</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9706101</id><created>1997-05-31</created><authors><author><keyname>Pollack</keyname><forenames>M. E.</forenames></author><author><keyname>Joslin</keyname><forenames>D.</forenames></author><author><keyname>Paolucci</keyname><forenames>M.</forenames></author></authors><title>Flaw Selection Strategies for Partial-Order Planning</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 6, (1997),
  223-262</journal-ref><abstract>  Several recent studies have compared the relative efficiency of alternative
flaw selection strategies for partial-order causal link (POCL) planning. We
review this literature, and present new experimental results that generalize
the earlier work and explain some of the discrepancies in it. In particular, we
describe the Least-Cost Flaw Repair (LCFR) strategy developed and analyzed by
Joslin and Pollack (1994), and compare it with other strategies, including
Gerevini and Schubert's (1996) ZLIFO strategy. LCFR and ZLIFO make very
different, and apparently conflicting claims about the most effective way to
reduce search-space size in POCL planning. We resolve this conflict, arguing
that much of the benefit that Gerevini and Schubert ascribe to the LIFO
component of their ZLIFO strategy is better attributed to other causes. We show
that for many problems, a strategy that combines least-cost flaw selection with
the delay of separable threats will be effective in reducing search-space size,
and will do so without excessive computational overhead. Although such a
strategy thus provides a good default, we also show that certain domain
characteristics may reduce its effectiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9706102</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9706102</id><created>1997-05-31</created><authors><author><keyname>Jonsson</keyname><forenames>P.</forenames></author><author><keyname>Drakengren</keyname><forenames>T.</forenames></author></authors><title>A Complete Classification of Tractability in RCC-5</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 6, (1997),
  211-221</journal-ref><abstract>  We investigate the computational properties of the spatial algebra RCC-5
which is a restricted version of the RCC framework for spatial reasoning. The
satisfiability problem for RCC-5 is known to be NP-complete but not much is
known about its approximately four billion subclasses. We provide a complete
classification of satisfiability for all these subclasses into polynomial and
NP-complete respectively. In the process, we identify all maximal tractable
subalgebras which are four in total.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9707101</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9707101</id><created>1997-06-30</created><authors><author><keyname>Mammen</keyname><forenames>D. L.</forenames></author><author><keyname>Hogg</keyname><forenames>T.</forenames></author></authors><title>A New Look at the Easy-Hard-Easy Pattern of Combinatorial Search
  Difficulty</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 7, (1997), 47-66</journal-ref><abstract>  The easy-hard-easy pattern in the difficulty of combinatorial search problems
as constraints are added has been explained as due to a competition between the
decrease in number of solutions and increased pruning. We test the generality
of this explanation by examining one of its predictions: if the number of
solutions is held fixed by the choice of problems, then increased pruning
should lead to a monotonic decrease in search cost. Instead, we find the
easy-hard-easy pattern in median search cost even when the number of solutions
is held constant, for some search methods. This generalizes previous
observations of this pattern and shows that the existing theory does not
explain the full range of the peak in search cost. In these cases the pattern
appears to be due to changes in the size of the minimal unsolvable subproblems,
rather than changing numbers of solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9707102</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9707102</id><created>1997-06-30</created><authors><author><keyname>Drakengren</keyname><forenames>T.</forenames></author><author><keyname>Jonsson</keyname><forenames>P.</forenames></author></authors><title>Eight Maximal Tractable Subclasses of Allen's Algebra with Metric Time</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 7, (1997), 25-45</journal-ref><abstract>  This paper combines two important directions of research in temporal
resoning: that of finding maximal tractable subclasses of Allen's interval
algebra, and that of reasoning with metric temporal information. Eight new
maximal tractable subclasses of Allen's interval algebra are presented, some of
them subsuming previously reported tractable algebras. The algebras allow for
metric temporal constraints on interval starting or ending points, using the
recent framework of Horn DLRs. Two of the algebras can express the notion of
sequentiality between intervals, being the first such algebras admitting both
qualitative and metric time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9707103</identifier>
 <datestamp>2008-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9707103</id><created>1997-06-30</created><authors><author><keyname>Halpern</keyname><forenames>J. Y.</forenames></author></authors><title>Defining Relative Likelihood in Partially-Ordered Preferential Structures</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 7, (1997), 1-24</journal-ref><abstract>  Starting with a likelihood or preference order on worlds, we extend it to a
likelihood ordering on sets of worlds in a natural way, and examine the
resulting logic. Lewis earlier considered such a notion of relative likelihood
in the context of studying counterfactuals, but he assumed a total preference
order on worlds. Complications arise when examining partial orders that are not
present for total orders. There are subtleties involving the exact approach to
lifting the order on worlds to an order on sets of worlds. In addition, the
axiomatization of the logic of relative likelihood in the case of partial
orders gives insight into the connection between relative likelihood and
default reasoning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9709101</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9709101</id><created>1997-08-31</created><authors><author><keyname>Tambe</keyname><forenames>M.</forenames></author></authors><title>Towards Flexible Teamwork</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 7, (1997), 83-124</journal-ref><abstract>  Many AI researchers are today striving to build agent teams for complex,
dynamic multi-agent domains, with intended applications in arenas such as
education, training, entertainment, information integration, and collective
robotics. Unfortunately, uncertainties in these complex, dynamic domains
obstruct coherent teamwork. In particular, team members often encounter
differing, incomplete, and possibly inconsistent views of their environment.
Furthermore, team members can unexpectedly fail in fulfilling responsibilities
or discover unexpected opportunities. Highly flexible coordination and
communication is key in addressing such uncertainties. Simply fitting
individual agents with precomputed coordination plans will not do, for their
inflexibility can cause severe failures in teamwork, and their
domain-specificity hinders reusability. Our central hypothesis is that the key
to such flexibility and reusability is providing agents with general models of
teamwork. Agents exploit such models to autonomously reason about coordination
and communication, providing requisite flexibility. Furthermore, the models
enable reuse across domains, both saving implementation effort and enforcing
consistency. This article presents one general, implemented model of teamwork,
called STEAM. The basic building block of teamwork in STEAM is joint intentions
(Cohen &amp; Levesque, 1991b); teamwork in STEAM is based on agents' building up a
(partial) hierarchy of joint intentions (this hierarchy is seen to parallel
Grosz &amp; Kraus's partial SharedPlans, 1996). Furthermore, in STEAM, team members
monitor the team's and individual members' performance, reorganizing the team
as necessary. Finally, decision-theoretic communication selectivity in STEAM
ensures reduction in communication overheads of teamwork, with appropriate
sensitivity to the environmental conditions. This article describes STEAM's
application in three different complex domains, and presents detailed empirical
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9709102</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9709102</id><created>1997-08-31</created><authors><author><keyname>Nevill-Manning</keyname><forenames>C. G.</forenames></author><author><keyname>Witten</keyname><forenames>I. H.</forenames></author></authors><title>Identifying Hierarchical Structure in Sequences: A linear-time algorithm</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 7, (1997), 67-82</journal-ref><abstract>  SEQUITUR is an algorithm that infers a hierarchical structure from a sequence
of discrete symbols by replacing repeated phrases with a grammatical rule that
generates the phrase, and continuing this process recursively. The result is a
hierarchical representation of the original sequence, which offers insights
into its lexical structure. The algorithm is driven by two constraints that
reduce the size of the grammar, and produce structure as a by-product. SEQUITUR
breaks new ground by operating incrementally. Moreover, the method's simple
structure permits a proof that it operates in space and time that is linear in
the size of the input. Our implementation can process 50,000 symbols per second
and has been applied to an extensive range of real world sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9710101</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9710101</id><created>1997-09-30</created><authors><author><keyname>Leherte</keyname><forenames>L.</forenames></author><author><keyname>Glasgow</keyname><forenames>J.</forenames></author><author><keyname>Baxter</keyname><forenames>K.</forenames></author><author><keyname>Steeg</keyname><forenames>E.</forenames></author><author><keyname>Fortier</keyname><forenames>S.</forenames></author></authors><title>Analysis of Three-Dimensional Protein Images</title><categories>cs.AI q-bio</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 7, (1997),
  125-159</journal-ref><abstract>  A fundamental goal of research in molecular biology is to understand protein
structure. Protein crystallography is currently the most successful method for
determining the three-dimensional (3D) conformation of a protein, yet it
remains labor intensive and relies on an expert's ability to derive and
evaluate a protein scene model. In this paper, the problem of protein structure
determination is formulated as an exercise in scene analysis. A computational
methodology is presented in which a 3D image of a protein is segmented into a
graph of critical points. Bayesian and certainty factor approaches are
described and used to analyze critical point graphs and identify meaningful
substructures, such as alpha-helices and beta-sheets. Results of applying the
methodologies to protein images at low and medium resolution are reported. The
research is related to approaches to representation, segmentation and
classification in vision, as well as to top-down approaches to protein
structure prediction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9711102</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9711102</id><created>1997-10-31</created><authors><author><keyname>Ihrig</keyname><forenames>L. H.</forenames></author><author><keyname>Kambhampati</keyname><forenames>S.</forenames></author></authors><title>Storing and Indexing Plan Derivations through Explanation-based Analysis
  of Retrieval Failures</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 7, (1997),
  161-198</journal-ref><abstract>  Case-Based Planning (CBP) provides a way of scaling up domain-independent
planning to solve large problems in complex domains. It replaces the detailed
and lengthy search for a solution with the retrieval and adaptation of previous
planning experiences. In general, CBP has been demonstrated to improve
performance over generative (from-scratch) planning. However, the performance
improvements it provides are dependent on adequate judgements as to problem
similarity. In particular, although CBP may substantially reduce planning
effort overall, it is subject to a mis-retrieval problem. The success of CBP
depends on these retrieval errors being relatively rare. This paper describes
the design and implementation of a replay framework for the case-based planner
DERSNLP+EBL. DERSNLP+EBL extends current CBP methodology by incorporating
explanation-based learning techniques that allow it to explain and learn from
the retrieval failures it encounters. These techniques are used to refine
judgements about case similarity in response to feedback when a wrong decision
has been made. The same failure analysis is used in building the case library,
through the addition of repairing cases. Large problems are split and stored as
single goal subproblems. Multi-goal problems are stored only when these smaller
cases fail to be merged into a full solution. An empirical evaluation of this
approach demonstrates the advantage of learning from experienced retrieval
failure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9711103</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9711103</id><created>1997-10-31</created><authors><author><keyname>Zhang</keyname><forenames>N. L.</forenames></author><author><keyname>Liu</keyname><forenames>W.</forenames></author></authors><title>A Model Approximation Scheme for Planning in Partially Observable
  Stochastic Domains</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 7, (1997),
  199-230</journal-ref><abstract>  Partially observable Markov decision processes (POMDPs) are a natural model
for planning problems where effects of actions are nondeterministic and the
state of the world is not completely observable. It is difficult to solve
POMDPs exactly. This paper proposes a new approximation scheme. The basic idea
is to transform a POMDP into another one where additional information is
provided by an oracle. The oracle informs the planning agent that the current
state of the world is in a certain region. The transformed POMDP is
consequently said to be region observable. It is easier to solve than the
original POMDP. We propose to solve the transformed POMDP and use its optimal
policy to construct an approximate policy for the original POMDP. By
controlling the amount of additional information that the oracle provides, it
is possible to find a proper tradeoff between computational time and
approximation quality. In terms of algorithmic contributions, we study in
details how to exploit region observability in solving the transformed POMDP.
To facilitate the study, we also propose a new exact algorithm for general
POMDPs. The algorithm is conceptually simple and yet is significantly more
efficient than all previous exact algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9711104</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9711104</id><created>1997-10-31</created><authors><author><keyname>Monderer</keyname><forenames>D.</forenames></author><author><keyname>Tennenholtz</keyname><forenames>M.</forenames></author></authors><title>Dynamic Non-Bayesian Decision Making</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 7, (1997),
  231-248</journal-ref><abstract>  The model of a non-Bayesian agent who faces a repeated game with incomplete
information against Nature is an appropriate tool for modeling general
agent-environment interactions. In such a model the environment state
(controlled by Nature) may change arbitrarily, and the feedback/reward function
is initially unknown. The agent is not Bayesian, that is he does not form a
prior probability neither on the state selection strategy of Nature, nor on his
reward function. A policy for the agent is a function which assigns an action
to every history of observations and actions. Two basic feedback structures are
considered. In one of them -- the perfect monitoring case -- the agent is able
to observe the previous environment state as part of his feedback, while in the
other -- the imperfect monitoring case -- all that is available to the agent is
the reward obtained. Both of these settings refer to partially observable
processes, where the current environment state is unknown. Our main result
refers to the competitive ratio criterion in the perfect monitoring case. We
prove the existence of an efficient stochastic policy that ensures that the
competitive ratio is obtained at almost all stages with an arbitrarily high
probability, where efficiency is measured in terms of rate of convergence. It
is further shown that such an optimal policy does not exist in the imperfect
monitoring case. Moreover, it is proved that in the perfect monitoring case
there does not exist a deterministic policy that satisfies our long run
optimality criterion. In addition, we discuss the maxmin criterion and prove
that a deterministic efficient optimal strategy does exist in the imperfect
monitoring case under this criterion. Finally we show that our approach to
long-run optimality can be viewed as qualitative, which distinguishes it from
previous work in this area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9711105</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9711105</id><created>2000-10-30</created><authors><author><keyname>Paulson</keyname><forenames>Lawrence C.</forenames></author></authors><title>Mechanizing Coinduction and Corecursion in Higher-order Logic</title><categories>cs.LO</categories><acm-class>F.3.1; F.4.1</acm-class><journal-ref>published in Journal of Logic and Computation 7 (March 1997),
  175-204</journal-ref><abstract>  A theory of recursive and corecursive definitions has been developed in
higher-order logic (HOL) and mechanized using Isabelle. Least fixedpoints
express inductive data types such as strict lists; greatest fixedpoints express
coinductive data types, such as lazy lists. Well-founded recursion expresses
recursive functions over inductive data types; corecursion expresses functions
that yield elements of coinductive data types. The theory rests on a
traditional formalization of infinite trees. The theory is intended for use in
specification and verification. It supports reasoning about a wide range of
computable functions, but it does not formalize their operational semantics and
can express noncomputable functions also. The theory is illustrated using
finite and infinite lists. Corecursion expresses functions over infinite lists;
coinduction reasons about such functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9711106</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9711106</id><created>2001-03-28</created><authors><author><keyname>Paulson</keyname><forenames>Lawrence C.</forenames></author></authors><title>Generic Automatic Proof Tools</title><categories>cs.LO</categories><acm-class>F.4.1, I.2.3</acm-class><journal-ref>published in Robert Veroff (editor), Automated Reasoning and its
  Applications: Essays in Honor of Larry Wos (MIT Press, 1997), 23-47</journal-ref><abstract>  This book chapter establishes connections between the interactive proof tool
Isabelle and classical tableau and resolution technology.  Isabelle's
classical reasoner is described and demonstrated by an extended case study:
the Church-Rosser theorem for combinators.  Compared with other interactive
theorem provers, Isabelle's classical reasoner achieves a high degree of
automation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9712101</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9712101</id><created>1997-11-30</created><authors><author><keyname>Frank</keyname><forenames>J.</forenames></author><author><keyname>Cheeseman</keyname><forenames>P.</forenames></author><author><keyname>Stutz</keyname><forenames>J.</forenames></author></authors><title>When Gravity Fails: Local Search Topology</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 7, (1997),
  249-281</journal-ref><abstract>  Local search algorithms for combinatorial search problems frequently
encounter a sequence of states in which it is impossible to improve the value
of the objective function; moves through these regions, called plateau moves,
dominate the time spent in local search. We analyze and characterize plateaus
for three different classes of randomly generated Boolean Satisfiability
problems. We identify several interesting features of plateaus that impact the
performance of local search algorithms. We show that local minima tend to be
small but occasionally may be very large. We also show that local minima can be
escaped without unsatisfying a large number of clauses, but that systematically
searching for an escape route may be computationally expensive if the local
minimum is large. We show that plateaus with exits, called benches, tend to be
much larger than minima, and that some benches have very few exit states which
local search can use to escape. We show that the solutions (i.e., global
minima) of randomly generated problem instances form clusters, which behave
similarly to local minima. We revisit several enhancements of local search
algorithms and explain their performance in light of our results. Finally we
discuss strategies for creating the next generation of local search algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9712102</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9712102</id><created>1997-11-30</created><authors><author><keyname>Kaindl</keyname><forenames>H.</forenames></author><author><keyname>Kainz</keyname><forenames>G.</forenames></author></authors><title>Bidirectional Heuristic Search Reconsidered</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 7, (1997),
  283-317</journal-ref><abstract>  The assessment of bidirectional heuristic search has been incorrect since it
was first published more than a quarter of a century ago. For quite a long
time, this search strategy did not achieve the expected results, and there was
a major misunderstanding about the reasons behind it. Although there is still
wide-spread belief that bidirectional heuristic search is afflicted by the
problem of search frontiers passing each other, we demonstrate that this
conjecture is wrong. Based on this finding, we present both a new generic
approach to bidirectional heuristic search and a new approach to dynamically
improving heuristic values that is feasible in bidirectional search only. These
approaches are put into perspective with both the traditional and more recently
proposed approaches in order to facilitate a better overall understanding.
Empirical results of experiments with our new approaches show that
bidirectional heuristic search can be performed very efficiently and also with
limited memory. These results suggest that bidirectional heuristic search
appears to be better for solving certain difficult problems than corresponding
unidirectional search. This provides some evidence for the usefulness of a
search strategy that was long neglected. In summary, we show that bidirectional
heuristic search is viable and consequently propose that it be reconsidered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9801101</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9801101</id><created>1997-12-31</created><authors><author><keyname>Gogic</keyname><forenames>G.</forenames></author><author><keyname>Papadimitriou</keyname><forenames>C. H.</forenames></author><author><keyname>Sideri</keyname><forenames>M.</forenames></author></authors><title>Incremental Recompilation of Knowledge</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 8, (1998), 23-37</journal-ref><abstract>  Approximating a general formula from above and below by Horn formulas (its
Horn envelope and Horn core, respectively) was proposed by Selman and Kautz
(1991, 1996) as a form of ``knowledge compilation,'' supporting rapid
approximate reasoning; on the negative side, this scheme is static in that it
supports no updates, and has certain complexity drawbacks pointed out by
Kavvadias, Papadimitriou and Sideri (1993). On the other hand, the many
frameworks and schemes proposed in the literature for theory update and
revision are plagued by serious complexity-theoretic impediments, even in the
Horn case, as was pointed out by Eiter and Gottlob (1992), and is further
demonstrated in the present paper. More fundamentally, these schemes are not
inductive, in that they may lose in a single update any positive properties of
the represented sets of formulas (small size, Horn structure, etc.). In this
paper we propose a new scheme, incremental recompilation, which combines Horn
approximation and model-based updates; this scheme is inductive and very
efficient, free of the problems facing its constituents. A set of formulas is
represented by an upper and lower Horn approximation. To update, we replace the
upper Horn formula by the Horn envelope of its minimum-change update, and
similarly the lower one by the Horn core of its update; the key fact which
enables this scheme is that Horn envelopes and cores are easy to compute when
the underlying formula is the result of a minimum-change update of a Horn
formula by a clause. We conjecture that efficient algorithms are possible for
more complex updates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9801102</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9801102</id><created>1997-12-31</created><authors><author><keyname>Engelfriet</keyname><forenames>J.</forenames></author></authors><title>Monotonicity and Persistence in Preferential Logics</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 8, (1998), 1-21</journal-ref><abstract>  An important characteristic of many logics for Artificial Intelligence is
their nonmonotonicity. This means that adding a formula to the premises can
invalidate some of the consequences. There may, however, exist formulae that
can always be safely added to the premises without destroying any of the
consequences: we say they respect monotonicity. Also, there may be formulae
that, when they are a consequence, can not be invalidated when adding any
formula to the premises: we call them conservative. We study these two classes
of formulae for preferential logics, and show that they are closely linked to
the formulae whose truth-value is preserved along the (preferential) ordering.
We will consider some preferential logics for illustration, and prove syntactic
characterization results for them. The results in this paper may improve the
efficiency of theorem provers for preferential logics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9801103</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9801103</id><created>1998-01-14</created><authors><author><keyname>Knuth</keyname><forenames>Donald E.</forenames></author></authors><title>Linear probing and graphs</title><categories>cs.DS</categories><report-no>Knuth migration 11/2004</report-no><journal-ref>Algorithmica 22 (1998), no. 4, 561--568</journal-ref><abstract>  Mallows and Riordan showed in 1968 that labeled trees with a small number of
inversions are related to labeled graphs that are connected and sparse. Wright
enumerated sparse connected graphs in 1977, and Kreweras related the inversions
of trees to the so-called ``parking problem'' in 1980. A~combination of these
three results leads to a surprisingly simple analysis of the behavior of
hashing by linear probing, including higher moments of the cost of successful
search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9803101</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9803101</id><created>1998-02-28</created><authors><author><keyname>Srivastava</keyname><forenames>B.</forenames></author><author><keyname>Kambhampati</keyname><forenames>S.</forenames></author></authors><title>Synthesizing Customized Planners from Specifications</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 8, (1998), 93-128</journal-ref><abstract>  Existing plan synthesis approaches in artificial intelligence fall into two
categories -- domain independent and domain dependent. The domain independent
approaches are applicable across a variety of domains, but may not be very
efficient in any one given domain. The domain dependent approaches need to be
(re)designed for each domain separately, but can be very efficient in the
domain for which they are designed. One enticing alternative to these
approaches is to automatically synthesize domain independent planners given the
knowledge about the domain and the theory of planning. In this paper, we
investigate the feasibility of using existing automated software synthesis
tools to support such synthesis. Specifically, we describe an architecture
called CLAY in which the Kestrel Interactive Development System (KIDS) is used
to derive a domain-customized planner through a semi-automatic combination of a
declarative theory of planning, and the declarative control knowledge specific
to a given domain, to semi-automatically combine them to derive
domain-customized planners. We discuss what it means to write a declarative
theory of planning and control knowledge for KIDS, and illustrate our approach
by generating a class of domain-specific planners using state space
refinements. Our experiments show that the synthesized planners can outperform
classical refinement planners (implemented as instantiations of UCP,
Kambhampati &amp; Srivastava, 1995), using the same control knowledge. We will
contrast the costs and benefits of the synthesis approach with conventional
methods for customizing domain independent planners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9803102</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9803102</id><created>1998-02-28</created><authors><author><keyname>Moore</keyname><forenames>A.</forenames></author><author><keyname>Lee</keyname><forenames>M. S.</forenames></author></authors><title>Cached Sufficient Statistics for Efficient Machine Learning with Large
  Datasets</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 8, (1998), 67-91</journal-ref><abstract>  This paper introduces new algorithms and data structures for quick counting
for machine learning datasets. We focus on the counting task of constructing
contingency tables, but our approach is also applicable to counting the number
of records in a dataset that match conjunctive queries. Subject to certain
assumptions, the costs of these operations can be shown to be independent of
the number of records in the dataset and loglinear in the number of non-zero
entries in the contingency table. We provide a very sparse data structure, the
ADtree, to minimize memory use. We provide analytical worst-case bounds for
this structure for several models of data distribution. We empirically
demonstrate that tractably-sized data structures can be produced for large
real-world datasets by (a) using a sparse tree structure that never allocates
memory for counts of zero, (b) never allocating memory for counts that can be
deduced from other counts, and (c) not bothering to expand the tree fully near
its leaves. We show how the ADtree can be used to accelerate Bayes net
structure finding algorithms, rule learning algorithms, and feature selection
algorithms, and we provide a number of empirical results comparing ADtree
methods against traditional direct counting approaches. We also discuss the
possible uses of ADtrees in other machine learning methods, and discuss the
merits of ADtrees in comparison with alternative representations such as
kd-trees, R-trees and Frequent Sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9803103</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9803103</id><created>1998-02-28</created><authors><author><keyname>Argamon-Engelson</keyname><forenames>S.</forenames></author><author><keyname>Koppel</keyname><forenames>M.</forenames></author></authors><title>Tractability of Theory Patching</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 8, (1998), 39-65</journal-ref><abstract>  In this paper we consider the problem of `theory patching', in which we are
given a domain theory, some of whose components are indicated to be possibly
flawed, and a set of labeled training examples for the domain concept. The
theory patching problem is to revise only the indicated components of the
theory, such that the resulting theory correctly classifies all the training
examples. Theory patching is thus a type of theory revision in which revisions
are made to individual components of the theory. Our concern in this paper is
to determine for which classes of logical domain theories the theory patching
problem is tractable. We consider both propositional and first-order domain
theories, and show that the theory patching problem is equivalent to that of
determining what information contained in a theory is `stable' regardless of
what revisions might be performed to the theory. We show that determining
stability is tractable if the input theory satisfies two conditions: that
revisions to each theory component have monotonic effects on the classification
of examples, and that theory components act independently in the classification
of examples in the theory. We also show how the concepts introduced can be used
to determine the soundness and completeness of particular theory patching
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9805101</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9805101</id><created>1998-04-30</created><authors><author><keyname>Fuernkranz</keyname><forenames>J.</forenames></author></authors><title>Integrative Windowing</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 8, (1998),
  129-164</journal-ref><abstract>  In this paper we re-investigate windowing for rule learning algorithms. We
show that, contrary to previous results for decision tree learning, windowing
can in fact achieve significant run-time gains in noise-free domains and
explain the different behavior of rule learning algorithms by the fact that
they learn each rule independently. The main contribution of this paper is
integrative windowing, a new type of algorithm that further exploits this
property by integrating good rules into the final theory right after they have
been discovered. Thus it avoids re-learning these rules in subsequent
iterations of the windowing process. Experimental evidence in a variety of
noise-free domains shows that integrative windowing can in fact achieve
substantial run-time gains. Furthermore, we discuss the problem of noise in
windowing and present an algorithm that is able to achieve run-time gains in a
set of experiments in a simple domain with artificial noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9806101</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9806101</id><created>1998-05-31</created><authors><author><keyname>Darwiche</keyname><forenames>A.</forenames></author></authors><title>Model-Based Diagnosis using Structured System Descriptions</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 8, (1998),
  165-222</journal-ref><abstract>  This paper presents a comprehensive approach for model-based diagnosis which
includes proposals for characterizing and computing preferred diagnoses,
assuming that the system description is augmented with a system structure (a
directed graph explicating the interconnections between system components).
Specifically, we first introduce the notion of a consequence, which is a
syntactically unconstrained propositional sentence that characterizes all
consistency-based diagnoses and show that standard characterizations of
diagnoses, such as minimal conflicts, correspond to syntactic variations on a
consequence. Second, we propose a new syntactic variation on the consequence
known as negation normal form (NNF) and discuss its merits compared to standard
variations. Third, we introduce a basic algorithm for computing consequences in
NNF given a structured system description. We show that if the system structure
does not contain cycles, then there is always a linear-size consequence in NNF
which can be computed in linear time. For arbitrary system structures, we show
a precise connection between the complexity of computing consequences and the
topology of the underlying system structure. Finally, we present an algorithm
that enumerates the preferred diagnoses characterized by a consequence. The
algorithm is shown to take linear time in the size of the consequence if the
preference criterion satisfies some general conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9806102</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9806102</id><created>1998-05-31</created><authors><author><keyname>Finkelstein</keyname><forenames>L.</forenames></author><author><keyname>Markovitch</keyname><forenames>S.</forenames></author></authors><title>A Selective Macro-learning Algorithm and its Application to the NxN
  Sliding-Tile Puzzle</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for an online appendix and other files
  accompanying this article</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 8, (1998),
  223-263</journal-ref><abstract>  One of the most common mechanisms used for speeding up problem solvers is
macro-learning. Macros are sequences of basic operators acquired during problem
solving. Macros are used by the problem solver as if they were basic operators.
The major problem that macro-learning presents is the vast number of macros
that are available for acquisition. Macros increase the branching factor of the
search space and can severely degrade problem-solving efficiency. To make macro
learning useful, a program must be selective in acquiring and utilizing macros.
This paper describes a general method for selective acquisition of macros.
Solvable training problems are generated in increasing order of difficulty. The
only macros acquired are those that take the problem solver out of a local
minimum to a better state. The utility of the method is demonstrated in several
domains, including the domain of NxN sliding-tile puzzles. After learning on
small puzzles, the system is able to efficiently solve puzzles of any size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9808001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9808001</id><created>1998-08-21</created><authors><author><keyname>Chaves</keyname><forenames>M.</forenames></author></authors><title>Chess Pure Strategies are Probably Chaotic</title><categories>cs.CC cs.AI</categories><comments>7 pages, no figures</comments><acm-class>F.2.0; I.2.0</acm-class><abstract>  It is odd that chess grandmasters often disagree in their analysis of
positions, sometimes even of simple ones, and that a grandmaster can hold his
own against an powerful analytic machine such as Deep Blue. The fact that there
must exist pure winning strategies for chess is used to construct a control
strategy function. It is then shown that chess strategy is equivalent to an
autonomous system of differential equations, and conjectured that the system is
chaotic. If true the conjecture would explain the forenamed peculiarities and
would also imply that there cannot exist a static evaluator for chess.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9808002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9808002</id><created>1998-08-24</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Hempel</keyname><forenames>Harald</forenames></author></authors><title>Downward Collapse from a Weaker Hypothesis</title><categories>cs.CC</categories><report-no>see UR-CS-TR-98-681</report-no><acm-class>F.1.3</acm-class><abstract>  Hemaspaandra et al. proved that, for $m &gt; 0$ and $0 &lt; i &lt; k - 1$: if
$\Sigma_i^p \BoldfaceDelta DIFF_m(\Sigma_k^p)$ is closed under complementation,
then $DIFF_m(\Sigma_k^p) = coDIFF_m(\Sigma_k^p)$. This sharply asymmetric
result fails to apply to the case in which the hypothesis is weakened by
allowing the $\Sigma_i^p$ to be replaced by any class in its difference
hierarchy. We so extend the result by proving that, for $s,m &gt; 0$ and $0 &lt; i &lt;
k - 1$: if $DIFF_s(\Sigma_i^p) \BoldfaceDelta DIFF_m(\Sigma_k^p)$ is closed
under complementation, then $DIFF_m(\Sigma_k^p) = coDIFF_m(\Sigma_k^p)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9808003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9808003</id><created>1998-08-23</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author></authors><title>Creating Strong Total Commutative Associative Complexity-Theoretic
  One-Way Functions from Any Complexity-Theoretic One-Way Function</title><categories>cs.CC cs.CR</categories><report-no>see UR-CS-TR-98-688</report-no><acm-class>F.1.3; E.3</acm-class><abstract>  Rabi and Sherman [RS97] presented novel digital signature and unauthenticated
secret-key agreement protocols, developed by themselves and by Rivest and
Sherman. These protocols use ``strong,'' total, commutative (in the case of
multi-party secret-key agreement), associative one-way functions as their key
building blocks. Though Rabi and Sherman did prove that associative one-way
functions exist if $\p \neq \np$, they left as an open question whether any
natural complexity-theoretic assumption is sufficient to ensure the existence
of ``strong,'' total, commutative, associative one-way functions. In this
paper, we prove that if $\p \neq \np$ then ``strong,'' total, commutative,
associative one-way functions exist.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9808004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9808004</id><created>1998-08-25</created><authors><author><keyname>Crowcroft</keyname><forenames>Jon</forenames></author><author><keyname>Oechslin</keyname><forenames>Philippe</forenames></author></authors><title>Differentiated End-to-End Internet Services using a Weighted
  Proportional Fair Sharing TCP</title><categories>cs.NI cs.PF</categories><acm-class>C.2.2;C.2.6;K.6.2</acm-class><abstract>  In this document we study the application of weighted proportional fairness
to data flows in the Internet. We let the users set the weights of their
connections in order to maximise the utility they get from the network. When
combined with a pricing scheme where connections are billed by weight and time,
such a system is known to maximise the total utility of the network. Our study
case is a national Web cache server connected to long distance links. We
propose two ways of weighting TCP connections by manipulating some parameters
of the protocol and present results from simulations and prototypes. We finally
discuss how proportional fairness could be used to implement an Internet with
differentiated services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9808005</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9808005</id><created>1998-08-27</created><authors><author><keyname>Friedman</keyname><forenames>Nir</forenames></author><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Koller</keyname><forenames>Daphne</forenames></author></authors><title>First-Order Conditional Logic Revisited</title><categories>cs.AI cs.LO</categories><comments>This is an expanded version of a paper that appeared in AAAI '96</comments><acm-class>I.2.4; F.4.1</acm-class><abstract>  Conditional logics play an important role in recent attempts to formulate
theories of default reasoning. This paper investigates first-order conditional
logic. We show that, as for first-order probabilistic logic, it is important
not to confound statistical conditionals over the domain (such as ``most birds
fly''), and subjective conditionals over possible worlds (such as ``I believe
that Tweety is unlikely to fly''). We then address the issue of ascribing
semantics to first-order conditional logic. As in the propositional case, there
are many possible semantics. To study the problem in a coherent way, we use
plausibility structures. These provide us with a general framework in which
many of the standard approaches can be embedded. We show that while these
standard approaches are all the same at the propositional level, they are
significantly different in the context of a first-order language. Furthermore,
we show that plausibilities provide the most natural extension of conditional
logic to the first-order case: We provide a sound and complete axiomatization
that contains only the KLM properties and standard axioms of first-order modal
logic. We show that most of the other approaches have additional properties,
which result in an inappropriate treatment of an infinitary version of the
lottery paradox.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9808006</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9808006</id><created>1998-08-27</created><updated>2000-05-30</updated><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author></authors><title>Set-Theoretic Completeness for Epistemic and Conditional Logic</title><categories>cs.AI cs.LO</categories><comments>This is an expanded version of a paper that appeared in AI and
  Mathematics, 1998</comments><acm-class>I.2.4; F.4.1</acm-class><journal-ref>Annals of Mathematics and Artificial Intelligence, vol. 26, 1999,
  pp. 1-27</journal-ref><abstract>  The standard approach to logic in the literature in philosophy and
mathematics, which has also been adopted in computer science, is to define a
language (the syntax), an appropriate class of models together with an
interpretation of formulas in the language (the semantics), a collection of
axioms and rules of inference characterizing reasoning (the proof theory), and
then relate the proof theory to the semantics via soundness and completeness
results. Here we consider an approach that is more common in the economics
literature, which works purely at the semantic, set-theoretic level. We provide
set-theoretic completeness results for a number of epistemic and conditional
logics, and contrast the expressive power of the syntactic and set-theoretic
approaches
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9808007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9808007</id><created>1998-08-28</created><authors><author><keyname>Friedman</keyname><forenames>Nir</forenames></author><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author></authors><title>Plausibility Measures and Default Reasoning</title><categories>cs.AI cs.LO</categories><comments>This is an expanded version of a paper that appeared in AAAI '96</comments><acm-class>I.2.4; F.4.1</acm-class><abstract>  We introduce a new approach to modeling uncertainty based on plausibility
measures. This approach is easily seen to generalize other approaches to
modeling uncertainty, such as probability measures, belief functions, and
possibility measures. We focus on one application of plausibility measures in
this paper: default reasoning. In recent years, a number of different semantics
for defaults have been proposed, such as preferential structures,
$\epsilon$-semantics, possibilistic structures, and $\kappa$-rankings, that
have been shown to be characterized by the same set of axioms, known as the KLM
properties. While this was viewed as a surprise, we show here that it is almost
inevitable. In the framework of plausibility measures, we can give a necessary
condition for the KLM axioms to be sound, and an additional condition necessary
and sufficient to ensure that the KLM axioms are complete. This additional
condition is so weak that it is almost always met whenever the axioms are
sound. In particular, it is easily seen to hold for all the proposals made
in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9808008</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9808008</id><created>1998-08-31</created><authors><author><keyname>Agarwal</keyname><forenames>Pankaj K.</forenames></author><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>Computational Geometry Column 34</title><categories>cs.CG</categories><acm-class>F.2.2</acm-class><journal-ref>SIGACT News, 29(3) (Issue 108) 27-32, Sept. 1998</journal-ref><abstract>  Problems presented at the open-problem session of the 14th Annual ACM
Symposium on Computational Geometry are listed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9808101</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9808101</id><created>1998-07-31</created><authors><author><keyname>Littman</keyname><forenames>M. L.</forenames></author><author><keyname>Goldsmith</keyname><forenames>J.</forenames></author><author><keyname>Mundhenk</keyname><forenames>M.</forenames></author></authors><title>The Computational Complexity of Probabilistic Planning</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for any accompanying files</comments><journal-ref>Journal of Artificial Intelligence Research, Vol 9, (1998), 1-36</journal-ref><abstract>  We examine the computational complexity of testing and finding small plans in
probabilistic planning domains with both flat and propositional
representations. The complexity of plan evaluation and existence varies with
the plan type sought; we examine totally ordered plans, acyclic plans, and
looping plans, and partially ordered plans under three natural definitions of
plan value. We show that problems of interest are complete for a variety of
complexity classes: PL, P, NP, co-NP, PP, NP^PP, co-NP^PP, and PSPACE. In the
process of proving that certain planning problems are complete for NP^PP, we
introduce a new basic NP^PP-complete problem, E-MAJSAT, which generalizes the
standard Boolean satisfiability problem to computations involving probabilistic
quantities; our results suggest that the development of good heuristics for
E-MAJSAT could be important for the creation of efficient algorithms for a wide
variety of problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809001</id><created>1998-09-01</created><authors><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author></authors><title>Immunity and Simplicity for Exact Counting and Other Counting Classes</title><categories>cs.CC</categories><comments>20 pages</comments><report-no>University of Rochester Technical Report TR-98-679</report-no><acm-class>F.1.3; F.1.2</acm-class><abstract>  Ko [RAIRO 24, 1990] and Bruschi [TCS 102, 1992] showed that in some
relativized world, PSPACE (in fact, ParityP) contains a set that is immune to
the polynomial hierarchy (PH). In this paper, we study and settle the question
of (relativized) separations with immunity for PH and the counting classes PP,
C_{=}P, and ParityP in all possible pairwise combinations. Our main result is
that there is an oracle A relative to which C_{=}P contains a set that is
immune to BPP^{ParityP}. In particular, this C_{=}P^A set is immune to PH^{A}
and ParityP^{A}. Strengthening results of Tor\'{a}n [J.ACM 38, 1991] and Green
[IPL 37, 1991], we also show that, in suitable relativizations, NP contains a
C_{=}P-immune set, and ParityP contains a PP^{PH}-immune set. This implies the
existence of a C_{=}P^{B}-simple set for some oracle B, which extends results
of Balc\'{a}zar et al. [SIAM J.Comp. 14, 1985; RAIRO 22, 1988] and provides the
first example of a simple set in a class not known to be contained in PH. Our
proof technique requires a circuit lower bound for ``exact counting'' that is
derived from Razborov's [Mat. Zametki 41, 1987] lower bound for majority.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809002</id><created>1998-09-01</created><authors><author><keyname>Goldsmith</keyname><forenames>Judy</forenames></author><author><keyname>Ogihara</keyname><forenames>Mitsunori</forenames></author><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author></authors><title>Tally NP Sets and Easy Census Functions</title><categories>cs.CC</categories><comments>24 pages</comments><report-no>University of Rochester Technical Report TR-98-684</report-no><acm-class>F.1.3</acm-class><abstract>  We study the question of whether every P set has an easy (i.e.,
polynomial-time computable) census function. We characterize this question in
terms of unlikely collapses of language and function classes such as the
containment of #P_1 in FP, where #P_1 is the class of functions that count the
witnesses for tally NP sets. We prove that every #P_{1}^{PH} function can be
computed in FP^{#P_{1}^{#P_{1}}}. Consequently, every P set has an easy census
function if and only if every set in the polynomial hierarchy does. We show
that the assumption of #P_1 being contained in FP implies P = BPP and that PH
is contained in MOD_{k}P for each k \geq 2, which provides further evidence
that not all sets in P have an easy census function. We also relate a set's
property of having an easy census function to other well-studied properties of
sets, such as rankability and scalability (the closure of the rankable sets
under P-isomorphisms). Finally, we prove that it is no more likely that the
census function of any set in P can be approximated (more precisely, can be
n^{\alpha}-enumerated in time n^{\beta} for fixed \alpha and \beta) than that
it can be precisely computed in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809003</id><created>1998-09-01</created><authors><author><keyname>Fagin</keyname><forenames>R.</forenames></author><author><keyname>Halpern</keyname><forenames>J. Y.</forenames></author><author><keyname>Moses</keyname><forenames>Y.</forenames></author><author><keyname>Vardi</keyname><forenames>M.</forenames></author></authors><title>Common knowledge revisited</title><categories>cs.LO cs.DC</categories><comments>A previous version appeared in TARK (Theoretical Aspects of
  Rationality and Knowledge), 1996. This version will appear in Annals of Pure
  and Applied Logic. The material in this paper is basically taken from Chapter
  11 of our book Reasoning About Knowledge (MIT Press, 1995)</comments><acm-class>F.4.1, C.2.4</acm-class><abstract>  We consider the common-knowledge paradox raised by Halpern and Moses: common
knowledge is necessary for agreement and coordination, but common knowledge is
unattainable in the real world because of temporal imprecision. We discuss two
solutions to this paradox: (1) modeling the world with a coarser granularity,
and (2) relaxing the requirements for coordination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809004</id><created>1998-09-01</created><authors><author><keyname>Gray</keyname><forenames>Jim</forenames></author><author><keyname>Coates</keyname><forenames>Joshua</forenames></author><author><keyname>Nyberg</keyname><forenames>Chris</forenames></author></authors><title>Performance / Price Sort</title><categories>cs.DB cs.PF</categories><comments>Original word file at:
  http://research.microsoft.com/~gray/PennySort.doc</comments><acm-class>D.5;H.2</acm-class><abstract>  NTsort is an external sort on WindowsNT 5.0. It has minimal functionality but
excellent price performance. In particular, running on mail-order hardware it
can sort 1.5 GB for a penny. For commercially available sorts, Postman Sort
from Robert Ramey Software Development has elapsed time performance comparable
to NTsort, while using less processor time. It can sort 1.27 GB for a penny
(12.7 million records.) These sorts set new price-performance records. This
paper documents this and proposes that the PennySort benchmark be revised to
Performance/Price sort: a simple GB/$ sort metric based on a two-pass external
sort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809005</id><created>1998-09-01</created><authors><author><keyname>Gray</keyname><forenames>Jim</forenames></author><author><keyname>Graefe</keyname><forenames>Goetz</forenames></author></authors><title>The Five-Minute Rule Ten Years Later, and Other Computer Storage Rules
  of Thumb</title><categories>cs.DB</categories><comments>Original document at:
  http://research.microsoft.com/~gray/5_min_rule_SIGMOD.doc</comments><report-no>MSR-TR-97-33</report-no><acm-class>H.3.4</acm-class><journal-ref>ACM SIGMOD Record 26(4): 63-68 (1997)</journal-ref><abstract>  Simple economic and performance arguments suggest appropriate lifetimes for
main memory pages and suggest optimal page sizes. The fundamental tradeoffs are
the prices and bandwidths of RAMs and disks. The analysis indicates that with
today's technology, five minutes is a good lifetime for randomly accessed
pages, one minute is a good lifetime for two-pass sequentially accessed pages,
and 16 KB is a good size for index pages. These rules-of-thumb change in
predictable ways as technology ratios change. They also motivate the importance
of the new Kaps, Maps, Scans, and $/Kaps, $/Maps, $/TBscan metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809006</id><created>1998-09-02</created><authors><author><keyname>Vogels</keyname><forenames>Werner</forenames></author><author><keyname>Dumitriu</keyname><forenames>Dan</forenames></author><author><keyname>Birman</keyname><forenames>Ken</forenames></author><author><keyname>Gamache</keyname><forenames>Rod</forenames></author><author><keyname>Massa</keyname><forenames>Mike</forenames></author><author><keyname>Short</keyname><forenames>Rob</forenames></author><author><keyname>Vert</keyname><forenames>John</forenames></author><author><keyname>Barrera</keyname><forenames>Joe</forenames></author></authors><title>The Design and Architecture of the Microsoft Cluster Service -- A
  Practical Approach to High-Availability and Scalability</title><categories>cs.OS cs.DC</categories><comments>Original document at:
  http://research.microsoft.com/~gray/MSCS_FTCS98.doc</comments><report-no>Microsoft Research MSR-TR-98-16</report-no><acm-class>C.4; C.5;D.4.5</acm-class><journal-ref>Proceedings of FTCS'98, June 23-25, 1998 in Munich, Germany</journal-ref><abstract>  Microsoft Cluster Service (MSCS) extends the Win-dows NT operating system to
support high-availability services. The goal is to offer an execution
environment where off-the-shelf server applications can continue to operate,
even in the presence of node failures. Later ver-sions of MSCS will provide
scalability via a node and application management system that allows
applications to scale to hundreds of nodes. This paper provides a de-tailed
description of the MSCS architecture and the de-sign decisions that have driven
the implementation of the service. The paper also describes how some major
appli-cations use the MSCS features, and describes features added to make it
easier to implement and manage fault-tolerant applications on MSCS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809007</id><created>1998-09-02</created><authors><author><keyname>Gray</keyname><forenames>Jim</forenames></author></authors><title>Locally Served Network Computers</title><categories>cs.AR cs.DC</categories><comments>Original document at:
  http://research.microsoft.com/~gray/NC_Servers.doc</comments><report-no>MSR-TR-95-55</report-no><acm-class>D.4.7</acm-class><journal-ref>Middleware Spectra, 11.2, 1997</journal-ref><abstract>  NCs are the natural evolution of PCs, ubiquitous computers everywhere. The
current vision of NCs requires two improbable developments: (1) inexpensive
high-bandwidth WAN links to the Internet, and (2) inexpensive centralized
servers. The large NC bandwidth requirements will force each home or office to
have a local server LAN attached to the NCs. These servers will be much less
expensive to purchase and manage than a centralized solution. Centralized staff
are expensive and unresponsive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809008</id><created>1998-09-02</created><authors><author><keyname>Palamidessi</keyname><forenames>Catuscia</forenames></author></authors><title>Comparing the expressive power of the Synchronous and the Asynchronous
  pi-calculus</title><categories>cs.PL</categories><comments>10 pages. Proc. of the POPL'97 symposium</comments><acm-class>D.3, F.3</acm-class><journal-ref>Proc. of the 24th ACM Symposium on Principles of Programming
  Languages (POPL), pages 256--265, ACM, 1997</journal-ref><abstract>  The Asynchronous pi-calculus, as recently proposed by Boudol and,
independently, by Honda and Tokoro, is a subset of the pi-calculus which
contains no explicit operators for choice and output-prefixing. The
communication mechanism of this calculus, however, is powerful enough to
simulate output-prefixing, as shown by Boudol, and input-guarded choice, as
shown recently by Nestmann and Pierce. A natural question arises, then, whether
or not it is possible to embed in it the full pi-calculus. We show that this is
not possible, i.e. there does not exist any uniform, parallel-preserving,
translation from the pi-calculus into the asynchronous pi-calculus, up to any
``reasonable'' notion of equivalence. This result is based on the incapablity
of the asynchronous pi-calculus of breaking certain symmetries possibly present
in the initial communication graph. By similar arguments, we prove a separation
result between the pi-calculus and CCS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809009</id><created>1998-09-02</created><authors><author><keyname>Boisvert</keyname><forenames>Ronald F.</forenames></author><author><keyname>Dongarra</keyname><forenames>Jack J.</forenames></author><author><keyname>Pozo</keyname><forenames>Roldan</forenames></author><author><keyname>Remington</keyname><forenames>Karin</forenames></author><author><keyname>Stewart</keyname><forenames>G. W.</forenames></author></authors><title>Developing numerical libraries in Java</title><categories>cs.MS</categories><comments>11 pages. Revised version of paper presented to the 1998 ACM
  Conference on Java for High Performance Network Computing. To appear in
  Concurrency: Practice and Experience</comments><acm-class>G.4</acm-class><abstract>  The rapid and widespread adoption of Java has created a demand for reliable
and reusable mathematical software components to support the growing number of
compute-intensive applications now under development, particularly in science
and engineering. In this paper we address practical issues of the Java language
and environment which have an effect on numerical library design and
development. Benchmarks which illustrate the current levels of performance of
key numerical kernels on a variety of Java platforms are presented. Finally, a
strategy for the development of a fundamental numerical toolkit for Java is
proposed and its current status is described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809010</id><created>1998-09-02</created><authors><author><keyname>Bell</keyname><forenames>C. Gordon</forenames></author><author><keyname>Gray</keyname><forenames>Jim</forenames></author></authors><title>The Revolution Yet to Happen</title><categories>cs.GL</categories><comments>Original document at:
  http://research.microsoft.com/~gray/Revolution.doc</comments><report-no>Microsoft Technical report: MSR-TR-98-45</report-no><acm-class>C.0</acm-class><abstract>  All information about physical objects including humans, buildings,
processes, and organizations will be online. This trend is both desirable and
inevitable. Cyberspace will provide the basis for wonderful new ways to inform,
entertain, and educate people. The information and the corresponding systems
will streamline commerce, but will also provide new levels of personal service,
health care, and automation. The most significant benefit will be a
breakthrough in our ability to remotely communicate with one another using all
our senses.
  The ACM and the transistor were born in 1947. At that time the stored program
computer was a revolutionary idea and the transistor was just a curiosity. Both
ideas evolved rapidly. By the mid 1960s integrated circuits appeared --
allowing mass fabrication of transistors on silicon substrates. This allowed
low-cost mass-produced computers. These technologies enabled extraordinary
increases in processing speed and memory coupled with extraordinary price
declines.
  The only form of processing and memory more easily, cheaply, and rapidly
fabricated is the human brain. Peter Cohrane (1996) estimates the brain to have
a processing power of around 1000 million-million operations per second, (one
Petaops) and a memory of 10 Terabytes. If current trends continue, computers
could have these capabilities by 2047. Such computers could be 'on body'
personal assistants able to recall everything one reads, hears, and sees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809011</id><created>1998-09-04</created><authors><author><keyname>Barclay</keyname><forenames>Tom</forenames></author><author><keyname>Eberl</keyname><forenames>Robert</forenames></author><author><keyname>Gray</keyname><forenames>Jim</forenames></author><author><keyname>Nordlinger</keyname><forenames>John</forenames></author><author><keyname>Raghavendran</keyname><forenames>Guru</forenames></author><author><keyname>Slutz</keyname><forenames>Don</forenames></author><author><keyname>Smith</keyname><forenames>Greg</forenames></author><author><keyname>Smoot</keyname><forenames>Phil</forenames></author><author><keyname>Hoffman</keyname><forenames>John</forenames></author><author><keyname>Robb</keyname><forenames>Natt</forenames><suffix>III</suffix></author><author><keyname>Rossmeissl</keyname><forenames>Hedy</forenames></author><author><keyname>Duff</keyname><forenames>Beth</forenames></author><author><keyname>Lee</keyname><forenames>George</forenames></author><author><keyname>Mathesmier</keyname><forenames>Theresa</forenames></author><author><keyname>Sunne</keyname><forenames>Randall</forenames></author></authors><title>Microsoft TerraServer</title><categories>cs.DB cs.DL</categories><comments>Original file at
  http://research.microsoft.com/~gray/TerraServer_TR.doc</comments><report-no>Microsoft MSR-TR-98-17</report-no><acm-class>H.2.4;H.2.8;H.3.5</acm-class><abstract>  The Microsoft TerraServer stores aerial and satellite images of the earth in
a SQL Server Database served to the public via the Internet. It is the world's
largest atlas, combining five terabytes of image data from the United States
Geodetic Survey, Sovinformsputnik, and Encarta Virtual Globe. Internet browsers
provide intuitive spatial and gazetteer interfaces to the data. The TerraServer
is also an E-Commerce application. Users can buy the right to use the imagery
using Microsoft Site Servers managed by the USGS and Aerial Images. This paper
describes the TerraServer's design and implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809012</id><created>1998-09-08</created><authors><author><keyname>Karger</keyname><forenames>David R.</forenames></author></authors><title>A Fully Polynomial Randomized Approximation Scheme for the All Terminal
  Network Reliability Problem</title><categories>cs.DS</categories><comments>To appear in SICOMP</comments><acm-class>F.2.2; G.2.2</acm-class><abstract>  The classic all-terminal network reliability problem posits a graph, each of
whose edges fails independently with some given probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809013</id><created>1998-09-09</created><authors><author><keyname>Bacchus</keyname><forenames>Fahiem</forenames></author><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Levesque</keyname><forenames>Hector J.</forenames></author></authors><title>Reasoning about Noisy Sensors and Effectors in the Situation Calculus</title><categories>cs.AI cs.LO</categories><comments>A preliminary version of the paper appeared in IJCAI '95</comments><acm-class>I.2.4, F.4.1</acm-class><abstract>  Agents interacting with an incompletely known world need to be able to reason
about the effects of their actions, and to gain further information about that
world they need to use sensors of some sort. Unfortunately, both the effects of
actions and the information returned from sensors are subject to error. To cope
with such uncertainties, the agent can maintain probabilistic beliefs about the
state of the world. With probabilistic beliefs the agent will be able to
quantify the likelihood of the various outcomes of its actions and is better
able to utilize the information gathered from its error-prone actions and
sensors. In this paper, we present a model in which we can reason about an
agent's probabilistic degrees of belief and the manner in which these beliefs
change as various actions are executed. We build on a general logical theory of
action developed by Reiter and others, formalized in the situation calculus. We
propose a simple axiomatization that captures an agent's state of belief and
the manner in which these beliefs change when actions are executed. Our model
displays a number of intuitively reasonable properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809014</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809014</id><created>1998-09-10</created><authors><author><keyname>Nadathur</keyname><forenames>Gopalan</forenames></author></authors><title>Uniform Provability in Classical Logic</title><categories>cs.LO</categories><comments>23 pages</comments><acm-class>F.4.1</acm-class><journal-ref>Journal of Logic and Computation, Vol 8, No 96-15, pp 209-229,
  1998</journal-ref><abstract>  Uniform proofs are sequent calculus proofs with the following characteristic:
the last step in the derivation of a complex formula at any stage in the proof
is always the introduction of the top-level logical symbol of that formula. We
investigate the relevance of this uniform proof notion to structuring proof
search in classical logic. A logical language in whose context provability is
equivalent to uniform provability admits of a goal-directed proof procedure
that interprets logical symbols as search directives whose meanings are given
by the corresponding inference rules. While this uniform provability property
does not hold directly of classical logic, we show that it holds of a fragment
of it that only excludes essentially positive occurrences of universal
quantifiers under a modest, sound, modification to the set of assumptions: the
addition to them of the negation of the formula being proved. We further note
that all uses of the added formula can be factored into certain derived rules.
The resulting proof system and the uniform provability property that holds of
it are used to outline a proof procedure for classical logic. An interesting
aspect of this proof procedure is that it incorporates within it previously
proposed mechanisms for dealing with disjunctive information in assumptions and
for handling hypotheticals. Our analysis sheds light on the relationship
between these mechanisms and the notion of uniform proofs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809015</id><created>1998-09-10</created><authors><author><keyname>Nadathur</keyname><forenames>Gopalan</forenames></author></authors><title>Correspondences between Classical, Intuitionistic and Uniform Provability</title><categories>cs.LO</categories><comments>31 pages</comments><report-no>University of Chicago, CS Dept, TR-97-12</report-no><acm-class>F.4.1</acm-class><abstract>  Based on an analysis of the inference rules used, we provide a
characterization of the situations in which classical provability entails
intuitionistic provability. We then examine the relationship of these
derivability notions to uniform provability, a restriction of intuitionistic
provability that embodies a special form of goal-directedness. We determine,
first, the circumstances in which the former relations imply the latter. Using
this result, we identify the richest versions of the so-called abstract logic
programming languages in classical and intuitionistic logic. We then study the
reduction of classical and, derivatively, intuitionistic provability to uniform
provability via the addition to the assumption set of the negation of the
formula to be proved. Our focus here is on understanding the situations in
which this reduction is achieved. However, our discussions indicate the
structure of a proof procedure based on the reduction, a matter also considered
explicitly elsewhere.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809016</id><created>1998-09-10</created><authors><author><keyname>Nadathur</keyname><forenames>Gopalan</forenames></author><author><keyname>Jayaraman</keyname><forenames>Bharat</forenames></author><author><keyname>Kwon</keyname><forenames>Keehang</forenames></author></authors><title>Scoping Constructs in Logic Programming: Implementation Problems and
  their Solution</title><categories>cs.PL</categories><comments>46 pages</comments><acm-class>D.3.2</acm-class><journal-ref>Journal of Logic Programming, 25(2)-119:161, 1995</journal-ref><abstract>  The inclusion of universal quantification and a form of implication in goals
in logic programming is considered. These additions provide a logical basis for
scoping but they also raise new implementation problems. When universal and
existential quantifiers are permitted to appear in mixed order in goals, the
devices of logic variables and unification that are employed in solving
existential goals must be modified to ensure that constraints arising out of
the order of quantification are respected. Suitable modifications that are
based on attaching numerical tags to constants and variables and on using these
tags in unification are described. The resulting devices are amenable to an
efficient implementation and can, in fact, be assimilated easily into the usual
machinery of the Warren Abstract Machine (WAM). The provision of implications
in goals results in the possibility of program clauses being added to the
program for the purpose of solving specific subgoals. A naive scheme based on
asserting and retracting program clauses does not suffice for implementing such
additions for two reasons. First, it is necessary to also support the
resurrection of an earlier existing program in the face of backtracking.
Second, the possibility for implication goals to be surrounded by quantifiers
requires a consideration of the parameterization of program clauses by bindings
for their free variables. Devices for supporting these additional requirements
are described as also is the integration of these devices into the WAM. Further
extensions to the machine are outlined for handling higher-order additions to
the language. The ideas presented here are relevant to the implementation of
the higher-order logic programming language lambda Prolog.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809017</id><created>1998-09-11</created><authors><author><keyname>Hunt</keyname><forenames>Harry B.</forenames><suffix>III</suffix></author><author><keyname>Marathe</keyname><forenames>Madhav V.</forenames></author><author><keyname>Radhakrishnan</keyname><forenames>Venkatesh</forenames></author><author><keyname>Stearns</keyname><forenames>Richard E.</forenames></author></authors><title>The Complexity of Planar Counting Problems</title><categories>cs.CC cs.DM</categories><comments>25 pages, 12 figures, appears in SIAM J. Computing</comments><acm-class>F.1.3</acm-class><abstract>  We prove the #P-hardness of the counting problems associated with various
satisfiability, graph and combinatorial problems, when restricted to planar
instances. These problems include \begin{romannum} \item[{}] {\sc 3Sat, 1-3Sat,
1-Ex3Sat, Minimum Vertex Cover, Minimum Dominating Set, Minimum Feedback Vertex
Set, X3C, Partition Into Triangles, and Clique Cover.} \end{romannum} We also
prove the {\sf NP}-completeness of the {\sc Ambiguous Satisfiability} problems
\cite{Sa80} and the {\sf D$^P$}-completeness (with respect to random polynomial
reducibility) of the unique satisfiability problems \cite{VV85} associated with
several of the above problems, when restricted to planar instances. Previously,
very few {\sf #P}-hardness results, no {\sf NP}-hardness results, and no {\sf
D$^P$}-completeness results were known for counting problems, ambiguous
satisfiability problems and unique satisfiability problems, respectively, when
restricted to planar instances.
  Assuming {\sf P $\neq $ NP}, one corollary of the above results is
  There are no $\epsilon$-approximation algorithms for the problems of
maximizing or minimizing a linear objective function subject to a planar system
of linear inequality constraints over the integers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809018</id><created>1998-09-11</created><authors><author><keyname>Cranor</keyname><forenames>Lorrie Faith</forenames></author><author><keyname>Wright</keyname><forenames>Rebecca N.</forenames></author></authors><title>Influencing Software Usage</title><categories>cs.CY</categories><comments>Prepared for the 26th Telecommunications Policy Research Conference,
  October 3-5, 1998, Alexandria, VA</comments><acm-class>K.4.0;K.6.3</acm-class><abstract>  Technology designers often strive to design systems that are flexible enough
to be used in a wide range of situations. Software engineers, in particular,
are trained to seek general solutions to problems. General solutions can be
used not only to address the problem at hand, but also to address a wide range
of problems that the designers may not have even anticipated. Sometimes
designers wish to provide general solutions, while encouraging certain uses of
their technology and discouraging or precluding others. They may attempt to
influence the use of technology by ``hard-wiring'' it so that it only can be
used in certain ways, licensing it so that those who use it are legally
obligated to use it in certain ways, issuing guidelines for how it should be
used, or providing resources that make it easier to use the technology as the
designers intended than to use it in any other way.
  This paper examines several cases where designers have attempted to influence
the use of technology through one of these mechanisms. Such cases include key
recovery encryption, Pegasus Mail, Platform for Internet Content Selection
(PICS) Guidelines, Java, Platform for Privacy Preferences Project (P3P)
Implementation Guide, Apple's style guidelines, and Microsoft Foundation
Classes. In some of these cases, the designers sought to influence the use of
technology for competitive reasons or in order to promote standardization or
interoperability. However, in other cases designers were motivated by
policy-related goals such as protecting privacy or free speech. As new
technologies are introduced with the express purpose of advancing
policy-related goals (for example, PICS and P3P), it is especially important to
understand the roles designers might play in influencing the use of technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809019</id><created>1998-09-14</created><authors><author><keyname>Manthey</keyname><forenames>Michael</forenames></author></authors><title>Distributed Computation as Hierarchy</title><categories>cs.DC cs.NE</categories><comments>16 pages, 3 figures</comments><report-no>Aalborg University, Computer Science Dept. R-98-5005</report-no><acm-class>F.1; E.2; D.1; I.4</acm-class><abstract>  This paper presents a new distributed computational model of distributed
systems called the phase web that extends V. Pratt's orthocurrence relation
from 1986. The model uses mutual-exclusion to express sequence, and a new kind
of hierarchy to replace event sequences, posets, and pomsets. The model
explicitly connects computation to a discrete Clifford algebra that is in turn
extended into homology and co-homology, wherein the recursive nature of objects
and boundaries becomes apparent and itself subject to hierarchical recursion.
Topsy, a programming environment embodying the phase web, is available from
www.cs.auc.dk/topsy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809020</id><created>1998-09-15</created><authors><author><keyname>Kan</keyname><forenames>Min-Yen</forenames></author><author><keyname>Klavans</keyname><forenames>Judith L.</forenames></author><author><keyname>McKeown</keyname><forenames>Kathleen R.</forenames></author></authors><title>Linear Segmentation and Segment Significance</title><categories>cs.CL</categories><comments>9 pages, US Letter, 4 figures. Software License can be found at
  http://www.cs.columbia.edu/nlp/licenses/segmenterLicenseDownload.html</comments><acm-class>I.2.7</acm-class><journal-ref>Proceedings of 6th International Workshop of Very Large Corpora
  (WVLC-6), Montreal, Quebec, Canada: Aug. 1998. pp. 197-205</journal-ref><abstract>  We present a new method for discovering a segmental discourse structure of a
document while categorizing segment function. We demonstrate how retrieval of
noun phrases and pronominal forms, along with a zero-sum weighting scheme,
determines topicalized segmentation. Futhermore, we use term distribution to
aid in identifying the role that the segment performs in the document. Finally,
we present results of evaluation in terms of precision and recall which surpass
earlier approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809021</id><created>1998-09-16</created><authors><author><keyname>Wolinski</keyname><forenames>Francis</forenames><affiliation>Informatique CDC/DTA, Arcueil, France</affiliation></author><author><keyname>Vichot</keyname><forenames>Frantz</forenames><affiliation>Informatique CDC/DTA, Arcueil, France</affiliation></author><author><keyname>Gremont</keyname><forenames>Olivier</forenames><affiliation>Informatique CDC/DTA, Arcueil, France</affiliation></author></authors><title>Producing NLP-based On-line Contentware</title><categories>cs.CL cs.AR</categories><comments>7 pages, 5 figures</comments><acm-class>I.2.7</acm-class><journal-ref>Natural Language Processing &amp; Industrial Applications, Moncton,
  NB, Canada, Aug. 1998</journal-ref><abstract>  For its internal needs as well as for commercial purposes, CDC Group has
produced several NLP-based on-line contentware applications for years. The
development process of such applications is subject to numerous constraints
such as quality of service, integration of new advances in NLP, direct
reactions from users, continuous versioning, short delivery deadlines and cost
control. Following this industrial and commercial experience, malleability of
the applications, their openness towards foreign components, efficiency of
applications and their ease of exploitation have appeared to be key points. In
this paper, we describe TalLab, a powerful architecture for on-line contentware
which fulfils these requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809022</id><created>1998-09-17</created><authors><author><keyname>Ludwig</keyname><forenames>Bernd</forenames></author><author><keyname>Goerz</keyname><forenames>Guenther</forenames></author><author><keyname>Niemann</keyname><forenames>Heinrich</forenames></author></authors><title>Modelling Users, Intentions, and Structure in Spoken Dialog</title><categories>cs.CL</categories><comments>17 pages</comments><acm-class>H.5.2</acm-class><abstract>  We outline how utterances in dialogs can be interpreted using a partial first
order logic. We exploit the capability of this logic to talk about the truth
status of formulae to define a notion of coherence between utterances and
explain how this coherence relation can serve for the construction of AND/OR
trees that represent the segmentation of the dialog. In a BDI model we
formalize basic assumptions about dialog and cooperative behaviour of
participants. These assumptions provide a basis for inferring speech acts from
coherence relations between utterances and attitudes of dialog participants.
Speech acts prove to be useful for determining dialog segments defined on the
notion of completing expectations of dialog participants. Finally, we sketch
how explicit segmentation signalled by cue phrases and performatives is covered
by our dialog model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809023</id><created>1998-09-17</created><updated>1998-09-18</updated><authors><author><keyname>Rafiei</keyname><forenames>Davood</forenames></author><author><keyname>Mendelzon</keyname><forenames>Alberto</forenames></author></authors><title>Similarity-Based Queries for Time Series Data</title><categories>cs.DB</categories><acm-class>H.2.2</acm-class><journal-ref>In Proceedings of the ACM SIGMOD Intl. Conf. on Management of
  Data, pages 13-24, Tucson, Arizona, May 1997</journal-ref><abstract>  We study a set of linear transformations on the Fourier series representation
of a sequence that can be used as the basis for similarity queries on
time-series data. We show that our set of transformations is rich enough to
formulate operations such as moving average and time warping. We present a
query processing algorithm that uses the underlying R-tree index of a
multidimensional data set to answer similarity queries efficiently. Our
experiments show that the performance of this algorithm is competitive to that
of processing ordinary (exact match) queries using the index, and much faster
than sequential scanning. We relate our transformations to the general
framework for similarity queries of Jagadish et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809024</identifier>
 <datestamp>2012-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809024</id><created>1998-09-17</created><updated>1998-09-17</updated><authors><author><keyname>XTAG Research Group</keyname></author></authors><title>A Lexicalized Tree Adjoining Grammar for English</title><categories>cs.CL</categories><comments>310 pages, 181 Postscript figures, uses 11pt, psfig.tex</comments><report-no>IRCS Tech Report 98-18, ftp://ftp.cis.upenn.edu/pub/ircs/tr/98-18/</report-no><acm-class>I.2.7; D.3.1</acm-class><abstract>  This document describes a sizable grammar of English written in the TAG
formalism and implemented for use with the XTAG system. This report and the
grammar described herein supersedes the TAG grammar described in an earlier
1995 XTAG technical report. The English grammar described in this report is
based on the TAG formalism which has been extended to include lexicalization,
and unification-based feature structures. The range of syntactic phenomena that
can be handled is large and includes auxiliaries (including inversion), copula,
raising and small clause constructions, topicalization, relative clauses,
infinitives, gerunds, passives, adjuncts, it-clefts, wh-clefts, PRO
constructions, noun-noun modifications, extraposition, determiner sequences,
genitives, negation, noun-verb contractions, sentential adjuncts and
imperatives. This technical report corresponds to the XTAG Release 8/31/98. The
XTAG grammar is continuously updated with the addition of new analyses and
modification of old ones, and an online version of this report can be found at
the XTAG web page at http://www.cis.upenn.edu/~xtag/
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809025</id><created>1998-09-17</created><authors><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author><author><keyname>Adamic</keyname><forenames>Lada A.</forenames></author></authors><title>Novelty and Social Search in the World Wide Web</title><categories>cs.MA cs.DL</categories><acm-class>H.1.1</acm-class><abstract>  The World Wide Web is fast becoming a source of information for a large part
of the world's population. Because of its sheer size and complexity users often
resort to recommendations from others to decide which sites to visit. We
present a dynamical theory of recommendations which predicts site visits by
users of the World Wide Web. We show that it leads to a universal power law for
the number of users that visit given sites over periods of time, with an
exponent related to the rate at which users discover new sites on their own. An
extensive empirical study of user behavior in the Web that we conducted
confirms the existence of this law of influence while yielding bounds on the
rate of novelty encountered by users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809026</id><created>1998-09-17</created><authors><author><keyname>Nederhof</keyname><forenames>Mark-Jan</forenames><affiliation>DFKI</affiliation></author><author><keyname>Sarkar</keyname><forenames>Anoop</forenames><affiliation>UPenn</affiliation></author><author><keyname>Satta</keyname><forenames>Giorgio</forenames><affiliation>UPadova</affiliation></author></authors><title>Prefix Probabilities from Stochastic Tree Adjoining Grammars</title><categories>cs.CL</categories><comments>7 pages, 2 Postscript figures, uses colacl.sty, graphicx.sty,
  psfrag.sty</comments><acm-class>I.2.7; D.3.1</acm-class><journal-ref>In Proceedings of COLING-ACL '98 (Montreal)</journal-ref><abstract>  Language models for speech recognition typically use a probability model of
the form Pr(a_n | a_1, a_2, ..., a_{n-1}). Stochastic grammars, on the other
hand, are typically used to assign structure to utterances. A language model of
the above form is constructed from such grammars by computing the prefix
probability Sum_{w in Sigma*} Pr(a_1 ... a_n w), where w represents all
possible terminations of the prefix a_1 ... a_n. The main result in this paper
is an algorithm to compute such prefix probabilities given a stochastic Tree
Adjoining Grammar (TAG). The algorithm achieves the required computation in
O(n^6) time. The probability of subderivations that do not derive any words in
the prefix, but contribute structurally to its derivation, are precomputed to
achieve termination. This algorithm enables existing corpus-based estimation
techniques for stochastic TAGs to be used for language modelling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809027</id><created>1998-09-17</created><authors><author><keyname>Sarkar</keyname><forenames>Anoop</forenames><affiliation>University of Pennsylvania</affiliation></author></authors><title>Conditions on Consistency of Probabilistic Tree Adjoining Grammars</title><categories>cs.CL</categories><comments>7 pages, 4 Postscript figures, uses colacl.sty, graphicx.sty,
  psfrag.sty</comments><acm-class>I.2.7; D.3.1</acm-class><journal-ref>In Proceedings of COLING-ACL '98 (Montreal)</journal-ref><abstract>  Much of the power of probabilistic methods in modelling language comes from
their ability to compare several derivations for the same string in the
language. An important starting point for the study of such cross-derivational
properties is the notion of _consistency_. The probability model defined by a
probabilistic grammar is said to be _consistent_ if the probabilities assigned
to all the strings in the language sum to one. From the literature on
probabilistic context-free grammars (CFGs), we know precisely the conditions
which ensure that consistency is true for a given CFG. This paper derives the
conditions under which a given probabilistic Tree Adjoining Grammar (TAG) can
be shown to be consistent. It gives a simple algorithm for checking consistency
and gives the formal justification for its correctness. The conditions derived
here can be used to ensure that probability models that use TAGs can be checked
for _deficiency_ (i.e. whether any probability mass is assigned to strings that
cannot be generated).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809028</id><created>1998-09-18</created><authors><author><keyname>Sarkar</keyname><forenames>Anoop</forenames><affiliation>University of Pennsylvania</affiliation></author></authors><title>Separating Dependency from Constituency in a Tree Rewriting System</title><categories>cs.CL</categories><comments>7 pages, 6 Postscript figures, uses fullname.sty</comments><acm-class>I.2.7; D.3.1</acm-class><journal-ref>In Proceedings of the Fifth Meeting on Mathematics of Language,
  Saarbruecken, August 1997</journal-ref><abstract>  In this paper we present a new tree-rewriting formalism called Link-Sharing
Tree Adjoining Grammar (LSTAG) which is a variant of synchronous TAGs. Using
LSTAG we define an approach towards coordination where linguistic dependency is
distinguished from the notion of constituency. Such an approach towards
coordination that explicitly distinguishes dependencies from constituency gives
a better formal understanding of its representation when compared to previous
approaches that use tree-rewriting systems which conflate the two issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809029</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809029</id><created>1998-09-18</created><authors><author><keyname>Sarkar</keyname><forenames>Anoop</forenames><affiliation>University of Pennsylvania</affiliation></author></authors><title>Incremental Parser Generation for Tree Adjoining Grammars</title><categories>cs.CL</categories><comments>12 pages, 12 Postscript figures, uses fullname.sty</comments><acm-class>I.2.7; D.3.1</acm-class><journal-ref>Longer version of paper in Proceedings of the 34th Meeting of the
  ACL, Student Session. Santa Cruz, June 1996</journal-ref><doi>10.1063/1.1594535</doi><abstract>  This paper describes the incremental generation of parse tables for the
LR-type parsing of Tree Adjoining Languages (TALs). The algorithm presented
handles modifications to the input grammar by updating the parser generated so
far. In this paper, a lazy generation of LR-type parsers for TALs is defined in
which parse tables are created by need while parsing. We then describe an
incremental parser generator for TALs which responds to modification of the
input grammar by updating parse tables built so far.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809030</id><created>1998-09-18</created><authors><author><keyname>Paxson</keyname><forenames>Vern</forenames><affiliation>Network Research Group, Lawrence Berkeley National Laboratory</affiliation></author></authors><title>Fast, Approximate Synthesis of Fractional Gaussian Noise for Generating
  Self-Similar Network Traffic</title><categories>cs.NI</categories><comments>14 pages</comments><report-no>LBL-36750/UC-405</report-no><acm-class>C.2.m</acm-class><journal-ref>Computer Communication Review 27(5) (1997) 5-18</journal-ref><abstract>  Recent network traffic studies argue that network arrival processes are much
more faithfully modeled using statistically self-similar processes instead of
traditional Poisson processes [LTWW94,PF95]. One difficulty in dealing with
self-similar models is how to efficiently synthesize traces (sample paths)
corresponding to self-similar traffic. We present a fast Fourier transform
method for synthesizing approximate self-similar sample paths for one type of
self-similar process, Fractional Gaussian Noise, and assess its performance and
validity. We find that the method is as fast or faster than existing methods
and appears to generate close approximations to true self-similar sample paths.
We also discuss issues in using such synthesized sample paths for simulating
network traffic, and how an approximation used by our method can dramatically
speed up evaluation of Whittle's estimator for H, the Hurst parameter giving
the strength of long-range dependence present in a self-similar time series.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809031</id><created>1998-09-18</created><authors><author><keyname>Aiello</keyname><forenames>William</forenames></author><author><keyname>Bellare</keyname><forenames>Mihir</forenames></author><author><keyname>Di Crescenzo</keyname><forenames>Giovanni</forenames></author><author><keyname>Venkatesan</keyname><forenames>Ramarathnam</forenames></author></authors><title>Security amplification by composition: The case of doubly-iterated,
  ideal ciphers</title><categories>cs.CR</categories><comments>An extended abstract of this paper appeared in the proceedings of
  Crypto 98 conference (Springer Verlag LNCS Vol 1462, 1998). This is the full
  version</comments><acm-class>C.2.0</acm-class><abstract>  We investigate, in the Shannon model, the security of constructions
corresponding to double and (two-key) triple DES. That is, we consider
F_{k1}(F_{k2}(.)) and F_{k1}(F_{k2}^{-1}(F_{k1}(.))) with the component
functions being ideal ciphers. This models the resistance of these
constructions to ``generic'' attacks like meet in the middle attacks. We obtain
the first proof that composition actually increases the security of these
constructions in some meaningful sense. We compute a bound on the probability
of breaking the double cipher as a function of the number of computations of
the base cipher made, and the number of examples of the composed cipher seen,
and show that the success probability is the square of that for a single key
cipher. The same bound holds for the two-key triple cipher. The first bound is
tight and shows that meet in the middle is the best possible generic attack
against the double cipher.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809032</id><created>1998-09-18</created><authors><author><keyname>Marek</keyname><forenames>Victor W.</forenames></author><author><keyname>Truszczynski</keyname><forenames>Miroslaw</forenames></author></authors><title>Stable models and an alternative logic programming paradigm</title><categories>cs.LO cs.AI</categories><comments>21 pages</comments><acm-class>I.2.3, I.2.4</acm-class><journal-ref>The Logic Programming Paradigm, K.R. Apt, V.W. Marek, M.
  Truszczynski, D.S. Warren (eds.), pp. 375-398. Springer-Verlag, 1999</journal-ref><abstract>  In this paper we reexamine the place and role of stable model semantics in
logic programming and contrast it with a least Herbrand model approach to Horn
programs. We demonstrate that inherent features of stable model semantics
naturally lead to a logic programming system that offers an interesting
alternative to more traditional logic programming styles of Horn logic
programming, stratified logic programming and logic programming with
well-founded semantics. The proposed approach is based on the interpretation of
program clauses as constraints. In this setting programs do not describe a
single intended model, but a family of stable models. These stable models
encode solutions to the constraint satisfaction problem described by the
program. Our approach imposes restrictions on the syntax of logic programs. In
particular, function symbols are eliminated from the language. We argue that
the resulting logic programming system is well-attuned to problems in the class
NP, has a well-defined domain of applications, and an emerging methodology of
programming. We point out that what makes the whole approach viable is recent
progress in implementations of algorithms to compute stable models of
propositional logic programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809033</id><created>1998-09-18</created><updated>1998-09-25</updated><authors><author><keyname>Rafiei</keyname><forenames>Davood</forenames></author><author><keyname>Mendelzon</keyname><forenames>Alberto</forenames></author></authors><title>Efficient Retrieval of Similar Time Sequences Using DFT</title><categories>cs.DB</categories><acm-class>H.2;H.3</acm-class><journal-ref>Proceedings of 5th Intl. Conf. on Foundations of Data
  Organizations and Algorithms (FODO '98), November 1998, Kobe, Japan</journal-ref><abstract>  We propose an improvement of the known DFT-based indexing technique for fast
retrieval of similar time sequences. We use the last few Fourier coefficients
in the distance computation without storing them in the index since every
coefficient at the end is the complex conjugate of a coefficient at the
beginning and as strong as its counterpart. We show analytically that this
observation can accelerate the search time of the index by more than a factor
of two. This result was confirmed by our experiments, which were carried out on
real stock prices and synthetic data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809034</id><created>1998-09-18</created><authors><author><keyname>Labrou</keyname><forenames>Yannis</forenames></author><author><keyname>Finin</keyname><forenames>Tim</forenames></author></authors><title>Semantics and Conversations for an Agent Communication Language</title><categories>cs.MA cs.AI</categories><comments>Also in in &quot;Readings in Agents&quot;, Michael Huhns and Munindar Singh
  (eds), Morgan Kaufmann Publishers, Inc</comments><acm-class>I.2.11</acm-class><journal-ref>Proceedings of the Fifteenth International Joint Conference on
  Artificial Intelligence (IJCAI-97) August, 1997</journal-ref><abstract>  We address the issues of semantics and conversations for agent communication
languages and the Knowledge Query Manipulation Language (KQML) in particular.
Based on ideas from speech act theory, we present a semantic description for
KQML that associates ``cognitive'' states of the agent with the use of the
language's primitives (performatives). We have used this approach to describe
the semantics for the whole set of reserved KQML performatives. Building on the
semantics, we devise the conversation policies, i.e., a formal description of
how KQML performatives may be combined into KQML exchanges (conversations),
using a Definite Clause Grammar. Our research offers methods for a speech act
theory-based semantic description of a language of communication acts and for
the specification of the protocols associated with these acts. Languages of
communication acts address the issue of communication among software
applications at a level of abstraction that is useful to the emerging software
agents paradigm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809035</id><created>1998-09-18</created><updated>1998-10-24</updated><authors><author><keyname>Erickson</keyname><forenames>Jeff</forenames></author><author><keyname>Guibas</keyname><forenames>Leonidas J.</forenames></author><author><keyname>Stolfi</keyname><forenames>Jorge</forenames></author><author><keyname>Zhang</keyname><forenames>Li</forenames></author></authors><title>Separation-Sensitive Collision Detection for Convex Objects</title><categories>cs.CG cs.GR</categories><comments>10 pages, 8 figures; to appear in Proc. 10th Annual ACM-SIAM
  Symposium on Discrete Algorithms, 1999; see also
  http://www.uiuc.edu/ph/www/jeffe/pubs/kollide.html ; v2 replaces submission
  with camera-ready version</comments><acm-class>F.2.2;I.3.5</acm-class><abstract>  We develop a class of new kinetic data structures for collision detection
between moving convex polytopes; the performance of these structures is
sensitive to the separation of the polytopes during their motion. For two
convex polygons in the plane, let $D$ be the maximum diameter of the polygons,
and let $s$ be the minimum distance between them during their motion. Our
separation certificate changes $O(\log(D/s))$ times when the relative motion of
the two polygons is a translation along a straight line or convex curve,
$O(\sqrt{D/s})$ for translation along an algebraic trajectory, and $O(D/s)$ for
algebraic rigid motion (translation and rotation). Each certificate update is
performed in $O(\log(D/s))$ time. Variants of these data structures are also
shown that exhibit \emph{hysteresis}---after a separation certificate fails,
the new certificate cannot fail again until the objects have moved by some
constant fraction of their current separation. We can then bound the number of
events by the combinatorial size of a certain cover of the motion path by
balls.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809036</id><created>1998-09-20</created><authors><author><keyname>Stanski</keyname><forenames>P.</forenames></author><author><keyname>Giles</keyname><forenames>S.</forenames></author><author><keyname>Zaslavsky</keyname><forenames>A.</forenames></author></authors><title>Document Archiving, Replication and Migration Container for Mobile Web
  Users</title><categories>cs.MA cs.MM</categories><comments>5 pages</comments><acm-class>H.3.2; H.5.3; H.5.4</acm-class><journal-ref>Proceedings of the 1998 ACM Symposium on Applied Computing
  (SAC98), Feb. 27- March 1, pp. 400-404, ACM, ISBN 0-89791-969-6</journal-ref><abstract>  With the increasing use of mobile workstations for a wide variety of tasks
and associated information needs, and with many variations of available
networks, access to data becomes a prime consideration. This paper discusses
issues of workstation mobility and proposes a solution wherein the data
structures are accessed in an encapsulated form - through the Portable File
System (PFS) wrapper. The paper discusses an implementation of the Portable
File System, highlighting the architecture and commenting upon performance of
an experimental system. Although investigations have been focused upon mobile
access of WWW documents, this technique could be applied to any mobile data
access situation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809037</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809037</id><created>1998-09-21</created><updated>1999-07-26</updated><authors><author><keyname>Amenta</keyname><forenames>Nina</forenames></author><author><keyname>Bern</keyname><forenames>Marshall</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>Regression Depth and Center Points</title><categories>cs.CG math.CO</categories><comments>14 pages, 3 figures</comments><acm-class>G.3</acm-class><journal-ref>Discrete Comput. Geom. 23(3):305-323, 2000</journal-ref><doi>10.1007/PL00009502</doi><abstract>  We show that, for any set of n points in d dimensions, there exists a
hyperplane with regression depth at least ceiling(n/(d+1)). as had been
conjectured by Rousseeuw and Hubert. Dually, for any arrangement of n
hyperplanes in d dimensions there exists a point that cannot escape to infinity
without crossing at least ceiling(n/(d+1)) hyperplanes. We also apply our
approach to related questions on the existence of partitions of the data into
subsets such that a common plane has nonzero regression depth in each subset,
and to the computational complexity of regression depth problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809038</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809038</id><created>1998-09-21</created><updated>2000-05-03</updated><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Incremental and Decremental Maintenance of Planar Width</title><categories>cs.CG</categories><comments>7 pages; 2 figures. A preliminary version of this paper was presented
  at the 10th ACM/SIAM Symp. Discrete Algorithms (SODA '99); this is the
  journal version, and will appear in J. Algorithms</comments><acm-class>F.2.2</acm-class><journal-ref>J. Algorithms 37(2):570-577, Nov. 2000</journal-ref><doi>10.1006/jagm.2000.1107</doi><abstract>  We present an algorithm for maintaining the width of a planar point set
dynamically, as points are inserted or deleted. Our algorithm takes time
O(kn^epsilon) per update, where k is the amount of change the update causes in
the convex hull, n is the number of points in the set, and epsilon is any
arbitrarily small constant. For incremental or decremental update sequences,
the amortized time per update is O(n^epsilon).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809039</id><created>1998-09-22</created><authors><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author></authors><title>ABR Flow Control for Multipoint Connections</title><categories>cs.NI</categories><comments>5 pages, 2 figures submitted to IEEE Network Magazine, ATM Forum
  Perspectives column</comments><acm-class>C.2.1</acm-class><abstract>  Multipoint capabilities are essential for ATM networks to efficiently support
many applications, including IP multicasting and overlay applications. The
current signaling and routing specifications for ATM define point-to-multipoint
capabilities. Multipoint-to-point connection support is also being discussed by
the signaling and PNNI groups, and will be defined in the near future for the
unspecified bit rate (UBR) service. We examine point-to-multipoint and
multipoint-to-point flow control for the available bit rate (ABR) service, as
discussed in the traffic management working group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809040</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809040</id><created>1998-09-22</created><authors><author><keyname>Vandalore</keyname><forenames>Bobby</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Goyal</keyname><forenames>Mukul</forenames></author></authors><title>Overload Based Explicit Rate Switch Schemes with MCR Guarantees</title><categories>cs.NI</categories><comments>Submitted to the INFOCOM '99</comments><acm-class>C.2.1</acm-class><abstract>  An explicit rate switch scheme monitors the load at each link and gives
feedback to the sources. We define the overload factor as the ratio of the
input rate to the available capacity. In this paper, we present four overload
based ABR switch schemes which provide MCR guarantees. The switch schemes
proposed use the overload factor and other quantities to calculate feedback
rates. A dynamic queue control mechanism is used to achieve efficient usage of
the link, control queues and, achieve constant queuing delay at steady state.
The proposed algorithms are studied and compared using several configurations.
The configurations were chosen to test the performance of the algorithms in
presence of link bottlenecks, source bottlenecks and transient sources. A
comparison of the proposed algorithms based on the simulation results is
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809041</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809041</id><created>1998-09-22</created><authors><author><keyname>Vandalore</keyname><forenames>Bobby</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author></authors><title>Design and Analysis of Queue Control Functions for Explicit Rate Switch
  Schemes</title><categories>cs.NI</categories><comments>Proceedings of IC3N'98, October 1998</comments><acm-class>C.2.1</acm-class><abstract>  The main goals of a switch scheme are high utilization, low queuing delay and
fairness. To achieve high utilization the switch scheme can maintain non-zero
(small) queues in steady state which can be used if the sources do not have
data to send. Queue length (delay) can be controlled if part of the link
capacity is used for draining queues in the event of queue build up. In most
schemes a simple threshold function is used for queue control. Better control
of the queue and hence delay can be achieved by using sophisticated queue
control functions. It is very important to design and analyze such queue
control functions. We study step, linear, hyperbolic and inverse hyperbolic
queue control functions. Analytical explanation and simulation results
consistent with analysis are presented. From the study, we conclude that
inverse hyperbolic is the best control function and to reduce complexity the
linear control function can be used since it performs satisfactorily in most
cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809042</id><created>1998-09-22</created><authors><author><keyname>Vandalore</keyname><forenames>Bobby</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Goyal</keyname><forenames>Mukul</forenames></author></authors><title>A Definition of General Weighted Fairness and its Support in Explicit
  Rate Switch Algorithms</title><categories>cs.NI</categories><comments>Proceedings of ICNP'98, October1998</comments><acm-class>C.2.1</acm-class><abstract>  In this paper we give a general definition of weighted fairness and show how
this can achieve various fairness definitions, such as those mentioned in the
ATM Forum TM 4.0 Specifications. We discuss how a pricing policy can be mapped
to general weighted (GW) fairness. The GW fairness can be achieved by
calculating the $ExcessFairshare$ (weighted fairshare of the left over
bandwidth) for each VC. We show how a switch algorithm can be modified to
support the GW fairness by using the $ExcessFairshare$. We use ERICA+ as an
example switch algorithm and show how it can be modified to achieve the general
fairness. Simulations results are presented to demonstrate that the modified
switch algorithm achieves GW fairness. An analytical proof for convergence of
the modified ERICA+ algorithm is given in the appendix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809043</id><created>1998-09-22</created><authors><author><keyname>Vandalore</keyname><forenames>Bobby</forenames></author><author><keyname>Kalyanaraman</keyname><forenames>Shivkumar</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author></authors><title>Worst Case Buffer Requirements For Tcp Over ABR</title><categories>cs.NI</categories><comments>SICON'98, June 98</comments><acm-class>C.2.1</acm-class><abstract>  ATM (asynchronous transfer mode) is the technology chosen for the Broadband
Integrated Services Digital Network (B-ISDN). The ATM ABR (available bit rate)
service can be used to transport ``best-effort'' traffic. In this paper, we
extend our earlier work on the buffer requirements problem for TCP over ABR.
Here, a worst case scenario is generated such that TCP sources send a burst of
data at the time when the sources have large congestion windows and the ACRs
(allowed cell rates) for ABR are high. We find that ABR using the ERICA+ switch
algorithm can control the maximum queue lengths (hence the buffer requirements)
even for the worst case. We present analytical arguments for the expected queue
length and simulation results for different number of sources values and
parameter values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809045</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809045</id><created>1998-09-22</created><authors><author><keyname>Kalyanaraman</keyname><forenames>Shivkumar</forenames></author><author><keyname>Vandalore</keyname><forenames>Bobby</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Kim</keyname><forenames>Seong-Cheol</forenames></author><author><keyname>Kota</keyname><forenames>Sastri</forenames></author></authors><title>Performance of TCP over ABR with Long-Range Dependent VBR Background
  Traffic over Terrestrial and Satellite ATM networks</title><categories>cs.NI</categories><comments>Proceedings of LCN `98</comments><acm-class>C.2.1</acm-class><abstract>  Compressed video is well known to be self-similar in nature. We model VBR
carrying Long-Range Dependent (LRD), multiplexed MPEG-2 video sources. The
actual traffic for the model is generated using fast-fourier transform of
generate the fractional gaussian noise (FGN) sequence. Our model of compressed
video sources bears similarity to an MPEG-2 Transport Stream carrying video,
i.e., it is long-range dependent and generates traffic in a piecewise-CBR
fashion. We study the effect of such VBR traffic on ABR carrying TCP traffic.
The effect of such VBR traffic is that the ABR capacity is highly variant. We
find that a switch algorithm like ERICA+ can tolerate this variance in ABR
capacity while maintaining high throughput and low delay. We present simulation
results for terrestrial and satellite configurations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809046</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809046</id><created>1998-09-22</created><authors><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Vandalore</keyname><forenames>Bobby</forenames></author></authors><title>Fairness for ABR multipoint-to-point connections</title><categories>cs.NI</categories><comments>Proceedings of SPIE 98, November 1998</comments><acm-class>C.2.1</acm-class><doi>10.1117/12.325859</doi><abstract>  In multipoint-to-point connections, the traffic at the root (destination) is
the combination of all traffic originating at the leaves. A crucial concern in
the case of multiple senders is how to define fairness within a multicast group
and among groups and point-to-point connections. Fairness definition can be
complicated since the multipoint connection can have the same identifier
(VPI/VCI) on each link, and senders might not be distinguishable in this case.
Many rate allocation algorithms implicitly assume that there is only one sender
in each VC, which does not hold for multipoint-to-point cases. We give various
possibilities for defining fairness for multipoint connections, and show the
tradeoffs involved. In addition, we show that ATM bandwidth allocation
algorithms need to be adapted to give fair allocations for multipoint-to-point
connections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809047</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809047</id><created>1998-09-22</created><authors><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Narayanaswamy</keyname><forenames>Shobana</forenames></author></authors><title>Modeling Traffic Management in ATM Networks with OPNET</title><categories>cs.NI</categories><comments>Proc. of OPNETWORK'98, Washington DC., May 1998</comments><acm-class>C.2.1</acm-class><abstract>  Asynchronous transfer mode (ATM) is the new generation of computer and
communication networks that are being deployed throughout the telecommunication
industry as well as in campus backbones. ATM technology distinguishes itself
from the previous networking protocols in that it has the latest traffic
management technology and thus allows guaranteeing delay, throughput, and other
performance measures. This in turn, allows users to integrate voice, video, and
data on the same network. Available bit rate (ABR) service in ATM has been
designed to fairly distribute all unused capacity to data traffic and is
specified in the ATM Forum's Traffic Management (TM4.0) standard. This paper
will describe the OPNET models that have been developed for ATM and ABR design
and analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809048</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809048</id><created>1998-09-22</created><authors><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Lai</keyname><forenames>Steve</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Durresi</keyname><forenames>Arian</forenames></author></authors><title>laboratories for Data Communications and Computer Networks</title><categories>cs.NI</categories><comments>Proc. of Frontiers in Education (FIE98), Tempe, November 1998</comments><acm-class>C.2.1</acm-class><abstract>  In this paper we describe a hands-on laboratory oriented instructional
package that we have developed for data communications and networking. The
package consists of a software tool, together with instructional material for a
laboratory based networking curriculum. The software is based on a simulation
environment that enables the student to experiment with various networking
protocols, on an easy to use graphical user interface (GUI). Data message
flows, packet losses, control/routing message flows, virtual circuit setups,
link failures, bit errors etc., are some of the features that can be visualized
in this environment. The student can also modify the networking components
provided, as well as add new components using the C programming language. The
instructional material consists of a set of laboratory exercises for flow and
error control (HDLC), IEEE 802.3 CSMA/CD protocol, the token ring protocol,
interconnecting LANs via bridges, TCP congestion avoidance and control, IP
fragmentation and reassembly, ATM PNNI routing and ATM policing. The laboratory
exercises have facilitated the development of a networking curriculum based on
both the traditional computer networking principles, as well as the new
technologies in telecommunication networking. The laboratory environment has
been used in the networking curriculum at The Ohio State University, and is
being piloted at other universities. The entire package is freely available
over the Internet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809049</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809049</id><created>1998-09-23</created><authors><author><keyname>Bentley</keyname><forenames>Peter J</forenames></author></authors><title>Aspects of Evolutionary Design by Computers</title><categories>cs.NE</categories><comments>In Proceedings of the 3rd On-line World Conference on Soft Computing
  in Engineering Design and Manufacturing (WSC3)</comments><acm-class>A.1;E.2;F.4.1;I.2.0;I.2.6;I.2.8;I.2.9;I.2.11;I.3.5;I.6.0;J.6</acm-class><abstract>  This paper examines the four main types of Evolutionary Design by computers:
Evolutionary Design Optimisation, Evolutionary Art, Evolutionary Artificial
Life Forms and Creative Evolutionary Design. Definitions for all four areas are
provided. A review of current work in each of these areas is given, with
examples of the types of applications that have been tackled. The different
properties and requirements of each are examined. Descriptions of typical
representations and evolutionary algorithms are provided and examples of
designs evolved using these techniques are shown. The paper then discusses how
the boundaries of these areas are beginning to merge, resulting in four new
'overlapping' types of Evolutionary Design: Integral Evolutionary Design,
Artificial Life Based Evolutionary Design, Aesthetic Evolutionary AL and
Aesthetic Evolutionary Design. Finally, the last part of the paper discusses
some common problems faced by creators of Evolutionary Design systems,
including: interdependent elements in designs, epistasis, and constraint
handling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809050</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809050</id><created>1998-09-23</created><authors><author><keyname>Lezius</keyname><forenames>Wolfgang</forenames><affiliation>University of Paderborn</affiliation></author><author><keyname>Rapp</keyname><forenames>Reinhard</forenames><affiliation>University of Mainz</affiliation></author><author><keyname>Wettler</keyname><forenames>Manfred</forenames><affiliation>University of Paderborn</affiliation></author></authors><title>A Freely Available Morphological Analyzer, Disambiguator and Context
  Sensitive Lemmatizer for German</title><categories>cs.CL</categories><comments>5 pages, Postscript only</comments><acm-class>H.3.4</acm-class><journal-ref>Proceedings of the COLING-ACL 1998, pp. 743-748</journal-ref><abstract>  In this paper we present Morphy, an integrated tool for German morphology,
part-of-speech tagging and context-sensitive lemmatization. Its large lexicon
of more than 320,000 word forms plus its ability to process German compound
nouns guarantee a wide morphological coverage. Syntactic ambiguities can be
resolved with a standard statistical part-of-speech tagger. By using the output
of the tagger, the lemmatizer can determine the correct root even for ambiguous
word forms. The complete package is freely available and can be downloaded from
the World Wide Web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809051</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809051</id><created>1998-09-23</created><authors><author><keyname>Bernsen</keyname><forenames>Niels Ole</forenames><affiliation>The Natural Interactive Systems Group, Odense University, Denmark</affiliation></author><author><keyname>Dybkjaer</keyname><forenames>Laila</forenames><affiliation>The Natural Interactive Systems Group, Odense University, Denmark</affiliation></author><author><keyname>eds.</keyname><affiliation>The Natural Interactive Systems Group, Odense University, Denmark</affiliation></author></authors><title>Spoken Language Dialogue Systems and Components: Best practice in
  development and evaluation (DISC 24823) - Periodic Progress Report 1: Basic
  Details of the Action</title><categories>cs.CL cs.SE</categories><comments>27 pages</comments><report-no>DISC-D5.1</report-no><acm-class>I.2.7; H.5.2; D.2.2; I.3.6</acm-class><abstract>  The DISC project aims to (a) build an in-depth understanding of the
state-of-the-art in spoken language dialogue systems (SLDSs) and components
development and evaluation with the purpose of (b) developing a first best
practice methodology in the field. The methodology will be accompanied by (c) a
series of development and evaluation support tools. To the limited extent
possible within the duration of the project, the draft versions of the
methodology and the tools will be (d) tested by SLDS developers from industry
and research, and will be (e) packaged to best suit their needs. In the first
year of DISC, (a) has been accomplished, and (b) and (c) have started. A
proposal to complete the work proposed above by adding 12 months to the 18
months of the present project, has been submitted to Esprit Long-Term Research
in March 1998.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809052</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809052</id><created>1998-09-23</created><authors><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Kota</keyname><forenames>Sastri</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Vandalore</keyname><forenames>Bobby</forenames></author><author><keyname>Kallaus</keyname><forenames>Jerry</forenames></author></authors><title>Analysis and Simulation of Delay and Buffer Requirements of
  satellite-ATM Networks for TCP/IP Traffic</title><categories>cs.NI</categories><comments>Submitted to IEEE Journal of Selected Areas in Communications, March
  1998</comments><acm-class>C.2.1</acm-class><abstract>  In this paper we present a model to study the end-to-end delay performance of
a satellite-ATM netowrk. We describe a satellite-ATM network architecture. The
architecture presents a trade-off between the on-board switching/processing
features and the complexity of the satellite communication systems. The
end-to-end delay of a connection passing through a satellite constellation
consists of the transmission delay, the uplink and downlink ground
terminal-satellite propagation delay, the inter-satellite link delays, the
on-board switching, processing and buffering delays. In a broadband satellite
network, the propagation and the buffering delays have the most impact on the
overall delay. We present an analysis of the propagation and buffering delay
components for GEO and LEO systems. We model LEO constellations as satellites
evenly spaced in circular orbits around the earth. A simple routing algorithm
for LEO systems calculates locally optimal paths for the end-to-end connection.
This is used to calculate the end-to-end propagation delays for LEO networks.
We present a simulation model to calculate the buffering delay for TCP/IP
traffic over ATM ABR and UBR service categories. We apply this model to
calculate total end-to-end delays for TCP/IP over satellite-ATM networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809053</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809053</id><created>1998-09-23</created><authors><author><keyname>Goyal</keyname><forenames>ohit</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Kalyanaraman</keyname><forenames>Shiv</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Vandalore</keyname><forenames>Bobby</forenames></author></authors><title>Improving the Performance of TCP over the ATM-UBR service</title><categories>cs.NI</categories><acm-class>C.2.1</acm-class><abstract>  In this paper we study the design issues in improving TCP performance over
the ATM UBR service. ATM-UBR switches respond to congestion by dropping cells
when their buffers become full. TCP connections running over UBR can experience
low throughput and high unfairness. Intelligent switch drop policies and
end-system policies can improve the performance of TCP over UBR with limited
buffers. We describe the various design options available to the network as
well as to the end systems to improve TCP performance over UBR. We study the
effects of Early Packet Discard, and two per-VC accounting based buffer
management policies. We also study the effects of various TCP end system
congestion control policies including slow start and congestion avoidance, fast
retransmit and recovery and selective acknowledgments. We present simulation
results for various small and large latency configurations with varying buffer
sizes and number of sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809054</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809054</id><created>1998-09-23</created><authors><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Vandalore</keyname><forenames>Bobby</forenames></author><author><keyname>Kalyanaraman</keyname><forenames>Shivkumar</forenames></author></authors><title>Design Issues for providing Minimum Rate Guarantees to the ATM
  Unspecified Bit Rate Service</title><categories>cs.NI</categories><comments>Proceedings of ATM98, Fairfax, May 1998</comments><acm-class>C.2.1</acm-class><abstract>  Recent enhancements have been proposed to the ATM Unspecified Bit Rate (UBR)
service that guarantee a minimum rate at the frame level to the UBR VCs. These
enhancements have been called Guaranteed Frame Rate (GFR). In this paper, we
discuss the motivation, design and implementation issues for GFR. We present
the design of buffer management and policing mechanisms to implement GFR. We
study the effects of policing, per-VC buffer allocation, and per-VC queuing on
providing GFR to TCP/IP traffic. We conclude that per-VC scheduling is
necessary to provide minimum rate guarantees to TCP traffic. We examine the
role of frame tagging in the presence of scheduling and buffer management for
providing minumum rate guarantees. The use of GFR to support the Internet
Controlled Load Service is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809055</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809055</id><created>1998-09-23</created><authors><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Vandalore</keyname><forenames>Bobby</forenames></author></authors><title>Providing Rate Guarantees to TCP over the ATM GFR Service</title><categories>cs.NI</categories><comments>Submitted to LCN'98</comments><acm-class>C.2.1</acm-class><abstract>  The ATM Guaranteed Frame Rate (GFR) service is intended for best effort
traffic that can benefit from minimum throughput guarantees. Edge devices
connecting LANs to an ATM network can use GFR to transport multiple TCP/IP
connections over a single GFR VC.These devices would typically multiplex VCs
into a single FIFO queue. It has been shown that in general, FIFO queuing is
not sufficient to provide rate guarantees, and per-VC queuing with scheduling
is needed. We show that under conditions of low buffer allocation, it is
possible to control TCP rates with FIFO queuing and buffer management. We
present analysis and simulation results on controlling TCP rates by buffer
management. We present a buffer management policy that provides loose rate
guarantees to SACK TCP sources when the total buffer allocation is low. We
study the performance of this buffer management scheme by simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809056</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809056</id><created>1998-09-23</created><authors><author><keyname>Babic</keyname><forenames>G.</forenames></author><author><keyname>Vandalore</keyname><forenames>B.</forenames></author><author><keyname>Jain</keyname><forenames>R.</forenames></author></authors><title>Analysis and Modeling of Traffic in Modern Data Communication Networks</title><categories>cs.NI</categories><comments>Ohio State University Technical Report, Feburary 1998</comments><report-no>OSU-CISRC-1/98-TR02</report-no><acm-class>C.2.1</acm-class><abstract>  In performance analysis and design of communication netword modeling data
traffic is important. With introduction of new applications, the
characteristics of the data traffic changes. We present a brief review the
different models of data traffic and how they have evolved. We present results
of data traffic analysis and simulated traffic, which demonstrates that the
packet train model fits the traffic at source destination level and long-memory
(self-similar) model fits the traffic at the aggregate level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809057</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809057</id><created>1998-09-23</created><authors><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Kalyanaraman</keyname><forenames>Shivkumar</forenames></author><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Vandalore</keyname><forenames>Bobby</forenames></author></authors><title>On Determining the Fair Bandwidth Share for ABR Connections in ATM
  Networks</title><categories>cs.NI</categories><comments>Proceedings of the IEEE International Conference on Communications
  (ICC) 1998, June 1998</comments><acm-class>C.2.1</acm-class><abstract>  The ABR service is designed to fairly allocate the bandwidth unused by higher
priority services. The network indicates to the ABR sources the rates at which
they should transmit to minimize their cell loss. Switches must constantly
measure the demand and available capacity, and divide the capacity fairly among
the contending connections. In order to compute the fair and efficient
allocation for each connection, a switch needs to determine the effective
number of active connections. In this paper, we propose a method for
determining the number of active connections and the fair bandwidth share for
each. We prove the efficiency and fairness of the proposed method analytically,
and simulate it by incorporating it into the ERICA switch algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809058</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809058</id><created>1998-09-23</created><authors><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Kalyanaraman</keyname><forenames>Shiv</forenames></author><author><keyname>Viswanathan</keyname><forenames>Ram</forenames></author></authors><title>The OSU Scheme for Congestion Avoidance in ATM Networks: Lessons Learnt
  and Extensions</title><categories>cs.NI</categories><acm-class>C.2.1</acm-class><abstract>  The OSU scheme is a rate-based congestion avoidance scheme for ATM networks
using explicit rate indication. This work was one of the first attempts to
define explicit rate switch mechanisms and the Resource Management (RM) cell
format in Asynchronous Transfer Mode (ATM) networks. The key features of the
scheme include explicit rate feedback, congestion avoidance, fair operation
while maintaining high utilization, use of input rate as a congestion metric,
O(1) complexity. This paper presents an overview of the scheme, presents those
features of the scheme that have now become common features of other switch
algorithms and discusses three extensions of the scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809059</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809059</id><created>1998-09-23</created><authors><author><keyname>Kalyanaraman</keyname><forenames>Shivkumar</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Vandalore</keyname><forenames>Bobby</forenames></author></authors><title>The ERICA Switch Algorithm for ABR Traffic Management in ATM Networks</title><categories>cs.NI</categories><acm-class>C.2.1</acm-class><abstract>  We propose an explicit rate indication scheme for congestion avoidance in ATM
networks. In this scheme, the network switches monitor their load on each link,
determining a load factor, the available capacity, and the number of currently
active virtual channels. This information is used to advise the sources about
the rates at which they should transmit. The algorithm is designed to achieve
efficiency, fairness, controlled queueing delays, and fast transient response.
The algorithm is also robust to measurement errors caused due to variation in
ABR demand and capacity. We present performance analysis of the scheme using
both analytical arguments and simulation results. The scheme is being
implemented by several ATM switch manufacturers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809060</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809060</id><created>1998-09-23</created><authors><author><keyname>Buhrman</keyname><forenames>Harry</forenames><affiliation>CWI</affiliation></author><author><keyname>Jiang</keyname><forenames>Tao</forenames><affiliation>McMaster U.</affiliation></author><author><keyname>Li</keyname><forenames>Ming</forenames><affiliation>U of Waterloo</affiliation></author><author><keyname>Vitanyi</keyname><forenames>Paul</forenames><affiliation>CWI and U of Amsterdam</affiliation></author></authors><title>New Applications of the Incompressibility Method: Part II</title><categories>cs.CC cs.DM</categories><comments>13 pages. Submitted to TCS</comments><acm-class>F.1.3; G.2.1</acm-class><abstract>  The incompressibility method is an elementary yet powerful proof technique.
It has been used successfully in many areas. To further demonstrate its power
and elegance we exhibit new simple proofs using the incompressibility method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809061</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809061</id><created>1998-09-23</created><authors><author><keyname>Jiang</keyname><forenames>Tao</forenames><affiliation>McMaster U.</affiliation></author><author><keyname>Li</keyname><forenames>Ming</forenames><affiliation>U of Waterloo</affiliation></author><author><keyname>Vitanyi</keyname><forenames>Paul</forenames><affiliation>CWI and U of Amsterdam</affiliation></author></authors><title>New Applications of the Incompressibility Method: Part I</title><categories>cs.CC cs.DM</categories><comments>15 pages. To appear in The Computer Journal</comments><acm-class>F.1.3; G.2.1</acm-class><abstract>  The incompressibility method is an elementary yet powerful proof technique.
It has been used successfully in many areas. To further demonstrate its power
and elegance we exhibit new simple proofs using the incompressibility method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809062</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809062</id><created>1998-09-23</created><authors><author><keyname>Kota</keyname><forenames>Sastri</forenames></author><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author></authors><title>Satellite ATM Network Architectural Considerations and TCP/IP
  Performance</title><categories>cs.NI</categories><comments>Proceedings of the 3rd Ka Band Utilization Converence, Italy, 1997,
  pp481-488</comments><acm-class>C.2.1</acm-class><abstract>  In this paper, we have provided a summary of the design options in
Satellite-ATM technology. A satellite ATM network consists of a space segment
of satellites connected by inter-satellite crosslinks, and a ground segment of
the various ATM networks. A satellite-ATM interface module connects the
satellite network to the ATM networks and performs various call and control
functions. A network control center performs various network management and
resource allocation functions. Several issues such as the ATM service model,
media access protocols, and traffic management issues must be considered when
designing a satellite ATM network to effectively transport Internet traffic. We
have presented the buffer requirements for TCP/IP traffic over ATM-UBR for
satellite latencies. Our results are based on TCP with selective
acknowledgments and a per-VC buffer management policy at the switches. A buffer
size of about 0.5 * RTT to 1 * RTT is sufficient to provide over 98% throughput
to infinite TCP traffic for long latency networks and a large number of
sources. This buffer requirement is independent of the number of sources. The
fairness is high for a large numbers of sources because of the per-VC buffer
management performed at the switches and the nature of TCP traffic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809063</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809063</id><created>1998-09-23</created><authors><author><keyname>Vandalore</keyname><forenames>Bobby</forenames></author><author><keyname>Kalyanaraman</keyname><forenames>Shivkumar</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Kim</keyname><forenames>Seong-Cheol</forenames></author></authors><title>Performance of Bursty World Wide Web (WWW) Sources over ABR</title><categories>cs.NI</categories><comments>Submitted to WebNet `97, Toronto, November 97</comments><acm-class>C.2.1</acm-class><abstract>  We model World Wide Web (WWW) servers and clients running over an ATM network
using the ABR (available bit rate) service. The WWW servers are modeled using a
variant of the SPECweb96 benchmark, while the WWW clients are based on a model
by Mah. The traffic generated by this application is typically bursty, i.e., it
has active and idle periods in transmission. A timeout occurs after given
amount of idle period. During idle period the underlying TCP congestion windows
remain open until a timeout expires. These open windows may be used to send
data in a burst when the application becomes active again. This raises the
possibility of large switch queues if the source rates are not controlled by
ABR. We study this problem and show that ABR scales well with a large number of
bursty TCP sources in the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809064</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809064</id><created>1998-09-23</created><authors><author><keyname>Marathe</keyname><forenames>Madhav V.</forenames></author><author><keyname>Hunt</keyname><forenames>Harry B.</forenames><suffix>III</suffix></author><author><keyname>Stearns</keyname><forenames>Richard E.</forenames></author><author><keyname>Radhakrishnan</keyname><forenames>Venkatesh</forenames></author></authors><title>Approximation Algorithms for PSPACE-Hard Hierarchically and Periodically
  Specified Problems</title><categories>cs.CC cs.DS</categories><comments>5 Figures, 24 pages</comments><acm-class>F.1.3; F.2.2</acm-class><journal-ref>SIAM J. Computing, Vol. 27, No 5, Oct. 1998, pp. 1237--1261</journal-ref><abstract>  We study the efficient approximability of basic graph and logic problems in
the literature when instances are specified hierarchically as in \cite{Le89} or
are specified by 1-dimensional finite narrow periodic specifications as in
\cite{Wa93}. We show that, for most of the problems $\Pi$ considered when
specified using {\bf k-level-restricted} hierarchical specifications or
$k$-narrow periodic specifications the following holds:
  \item Let $\rho$ be any performance guarantee of a polynomial time
approximation algorithm for $\Pi$, when instances are specified using standard
specifications. Then $\forall \epsilon &gt; 0$, $ \Pi$ has a polynomial time
approximation algorithm with performance guarantee $(1 + \epsilon) \rho$. \item
$\Pi$ has a polynomial time approximation scheme when restricted to planar
instances. \end{romannum}
  These are the first polynomial time approximation schemes for PSPACE-hard
hierarchically or periodically specified problems. Since several of the
problems considered are PSPACE-hard, our results provide the first examples of
natural PSPACE-hard optimization problems that have polynomial time
approximation schemes. This answers an open question in Condon et. al.
\cite{CF+93}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809065</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809065</id><created>1998-09-23</created><authors><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Vandalore</keyname><forenames>Bobby</forenames></author><author><keyname>Kalyanaraman</keyname><forenames>Shivkumar</forenames></author><author><keyname>Kota</keyname><forenames>Sastri</forenames></author><author><keyname>Samudra</keyname><forenames>Pradeep</forenames></author></authors><title>Feedback Consolidation Algorithms for ABR Point-to-Multipoint
  Connections in ATM Networks</title><categories>cs.NI</categories><comments>Proceedings of IEEE INFOCOM 1998, March 1998, volume 3, pp. 1004-1013</comments><acm-class>C.2.1</acm-class><abstract>  ABR traffic management for point-to-multipoint connections controls the
source rate to the minimum rate supported by all the branches of the multicast
tree. A number of algorithms have been developed for extending ABR congestion
avoidance algorithms to perform feedback consolidation at the branch points.
This paper discusses various design options and implementation alternatives for
the consolidation algorithms, and proposes a number of new algorithms. The
performance of the proposed algorithms and the previous algorithms is compared
under a variety of conditions. Results indicate that the algorithms we propose
eliminate the consolidation noise (caused if the feedback is returned before
all branches respond), while exhibiting a fast transient response.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809066</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809066</id><created>1998-09-23</created><authors><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Kalyanaraman</keyname><forenames>Shivkumar</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Vandalore</keyname><forenames>Bobby</forenames></author><author><keyname>Kota</keyname><forenames>Sastri</forenames></author></authors><title>TCP Selective Acknowledgments and UBR Drop Policies to Improve ATM-UBR
  Performance over Terrestrial and Satellite Networks</title><categories>cs.NI</categories><comments>Proc. ICCCN97, Las Vegas, September 1997 pp17-27</comments><acm-class>C.2.1</acm-class><abstract>  We study the performance of Selective Acknowledgments with TCP over the
ATM-UBR service category. We examine various UBR drop policies, TCP mechanisms
and network configurations to recommend optimal parameters for TCP over UBR. We
discuss various TCP congestion control mechanisms compare their performance for
LAN and WAN networks. We describe the effect of satellite delays on TCP
performance over UBR and present simulation results for LAN, WAN and satellite
networks. SACK TCP improves the performance of TCP over UBR, especially for
large delay networks. Intelligent drop policies at the switches are an
important factor for good performance in local area networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809067</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809067</id><created>1998-09-23</created><authors><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Kalyanaraman</keyname><forenames>Shivkumar</forenames></author><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Vandalore</keyname><forenames>Bobby</forenames></author><author><keyname>Cai</keyname><forenames>Xiangrong</forenames></author></authors><title>A Survey of Protocols and Open Issues in ATM Multipoint Communication</title><categories>cs.NI</categories><comments>OSU Technical Report, August 21, 1997</comments><acm-class>C.2.1</acm-class><abstract>  Asynchronous transfer mode (ATM) networks must define multicast capabilities
in order to efficiently support numerous applications, such as video
conferencing and distributed applications, in addition to LAN emulation (LANE)
and Internet protocol (IP) multicasting. Several problems and issues arise in
ATM multicasting, such as signaling, routing, connection admission control, and
traffic management problems. IP integrated services over ATM poses further
challenges to ATM multicasting. Scalability and simplicity are the two main
concerns for ATM multicasting. This paper provides a survey of the current work
on multicasting problems in general, and ATM multicasting in particular. A
number of proposed schemes is examined, such as the schemes MARS, MCS, SEAM,
SMART, RSVP, and various multipoint traffic management and transport-layer
schemes. The paper also indicates a number of key open issues that remain
unresolved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809068</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809068</id><created>1998-09-23</created><authors><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Babic</keyname><forenames>Gojko</forenames></author></authors><title>Performance Testing Effort at the ATM Forum: An Overview</title><categories>cs.NI</categories><comments>IEEE Communication Magazine, Special issue on ATM performance,
  Version: April 10, 1997, pp110-116</comments><acm-class>C.2.1</acm-class><abstract>  The testing group at ATM Forum is working on developing a specification for
performance testing of ATM switches and networks. The emphasis is on the user
perceived frame-level performance. This paper explains what is different about
this new effort and gives its status.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809069</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809069</id><created>1998-09-23</created><authors><author><keyname>Kalyanaraman</keyname><forenames>Shiv</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Jiang</keyname><forenames>Jianping</forenames></author><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Samudra</keyname><forenames>Pradeep</forenames></author></authors><title>Design Considerations for the Virtual Source/Virtual Destination (VS/VD)
  Feature in the ABR Service of ATM Networks</title><categories>cs.NI</categories><comments>25 pages</comments><acm-class>C.2.1</acm-class><abstract>  The Available Bit Rate (ABR) service in ATM networks has been specified to
allow fair and efficient support of data applications over ATM utilizing
capacity left over after servicing higher priority classes. One of the
architectural features in the ABR specification [tm4] is the Virtual
Source/Virtual Destination (VS/VD) option. This option allows a switch to
divide an end-to-end ABR connection into separately controlled ABR segments by
acting like a destination on one segment, and like a source on the other. The
coupling in the VS/VD switch between the two ABR control segments is
implementation specific. In this paper, we model a VS/VD ATM switch and study
the issues in designing coupling between ABR segments. We identify a number of
implementation options for the coupling. A good choice significantly improves
the stability and transient performance of the system and reduces the buffer
requirements at the switches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809070</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809070</id><created>1998-09-23</created><authors><author><keyname>Kalyanaraman</keyname><forenames>Shivkumar</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Kim</keyname><forenames>Seong-Cheol</forenames></author></authors><title>Use-it or Lose-it Policies for the Available Bit Rate (ABR) Service in
  ATM Networks</title><categories>cs.NI</categories><comments>25 pages</comments><acm-class>C.2.1</acm-class><abstract>  The Available Bit Rate (ABR) service has been developed to support 21st
century data applications over Asynchronous Transfer Mode (ATM). The ABR
service uses a closed-loop rate-based traffic management framework where the
network divides left-over bandwidth among contending sources. The ATM Forum
traffic management group also incorporated open-loop control capabilities to
make the ABR service robust to temporary network failures and source
inactivity. An important problem addressed was whether rate allocations of
sources should be taken away if sources do not use them. The proposed
solutions, popularly known as the Use-It-or-Lose-It (UILI) policies, have had
significant impact on the ABR service capabilities. In this paper we discuss
the design, development, and the final shape of these policies and their impact
on the ABR service. We compare the various alternatives through a performance
evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809071</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809071</id><created>1998-09-23</created><authors><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Kalyanaraman</keyname><forenames>Shiv</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Kim</keyname><forenames>Seong-Cheol</forenames></author></authors><title>UBR+: Improving Performance of TCP over ATM-UBR service</title><categories>cs.NI</categories><comments>ICC'97, Montreal, June 1997, pp1042-1048</comments><acm-class>C.2.1</acm-class><abstract>  ATM-UBR switches respond to congestion by dropping cells when their buffers
become full. TCP connections running over UBR experience low throughput and
high unfairness. For 100% TCP throughput each switch needs buffers equal to the
sum of the window sizes of all the TCP connections. Intelligent drop policies
can improve the performance of TCP over UBR with limited buffers. The UBR+
service proposes enhancements to UBR for intelligent drop. Early Packet Discard
improves throughput but does not attempt to improve fairness. Selective packet
drop based on per-connection buffer occupancy improves fairness. The Fair
Buffer Allocation scheme further improves both throughput and fairness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809072</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809072</id><created>1998-09-23</created><authors><author><keyname>Kalyanaraman</keyname><forenames>Shiv</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Jiang</keyname><forenames>Jianping</forenames></author><author><keyname>Kim</keyname><forenames>Seong-Cheol</forenames></author></authors><title>Performance of TCP over ABR on ATM backbone and with various VBR traffic
  patterns</title><categories>cs.NI</categories><comments>ICC'97, Montreal, June 1997</comments><acm-class>C.2.1</acm-class><abstract>  We extend our earlier studies of buffer requirements of TCP over ABR in two
directions. First, we study the performance of TCP over ABR in an ATM backbone.
On the backbone, the TCP queues are at the edge router and not inside the ATM
network. The router requires buffer equal to the sum of the receiver window
sizes of the participating TCP connections. Second, we introduce various
patterns of VBR background traffic. The VBR background introduces variance in
the ABR capacity and the TCP traffic introduces variance in the ABR demand.
Some simple switch schemes are unable to keep up with the combined effect of
highly varying demands and highly varying ABR capacity. We present our
experiences with refining the ERICA+ switch scheme to handle these conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809073</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809073</id><created>1998-09-23</created><authors><author><keyname>Kalyanaraman</keyname><forenames>Shiv</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Kim</keyname><forenames>Seong-Cheol</forenames></author></authors><title>Performance and Buffering Requirements of Internet Protocols over ATM
  ABR and UBR Services</title><categories>cs.NI</categories><comments>IEEE Communications Magazine, Vol 36, no 6, pp152-157</comments><acm-class>C.2.1</acm-class><abstract>  The Asynchronous Transfer Mode (ATM) networks are quickly being adopted as
backbones over various parts of the Internet. This paper analyzes the
performance of TCP/IP protocols over ATM network's Available Bit Rate (ABR) and
Unspecified Bit Rate (UBR) services. It is shown that ABR pushes congestion to
the edges of the ATM network while UBR leaves it inside the ATM portion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809074</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809074</id><created>1998-09-23</created><authors><author><keyname>Kalyanaraman</keyname><forenames>Shiv</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Kim</keyname><forenames>Seong-Cheol</forenames></author></authors><title>Performance of TCP/IP Using ATM ABR and UBR Services over Satellite
  Networks</title><categories>cs.NI</categories><comments>IEEE Communication Society Workshop on Computer-Aided Modeling,
  Analysis and Design of Communication Links and Networks, Mclean, VA, October
  20, 1996</comments><acm-class>C.2.1</acm-class><abstract>  We study the buffering requirements for zero cell loss for TCP/IP over
satellite links using the available bit rate (ABR) and unspecified bit rate
(UBR) services of asynchronous transfer mode (ATM) networks. For the ABR
service, we explore the effect of feedback delay (a factor which depends upon
the position of the bottleneck), the switch scheme used, and background
variable bit rate (VBR) traffic. It is shown that the buffer requirement for
TCP over ABR is independent of the number of TCP sources, but depends on the
aforementioned factors. For the UBR service, we show that the buffer
requirement is the sum of the TCP receiver window sizes. We substantiate our
arguments with simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809075</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809075</id><created>1998-09-23</created><authors><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Kalyanaraman</keyname><forenames>Shivkumar</forenames></author><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Lu</keyname><forenames>Fang</forenames></author></authors><title>On Source Rules for ABR Service on ATM Networks with Satellite Links</title><categories>cs.NI</categories><comments>Proceedings of the First International Workshop on Satellite-based
  Information Services, Rye, New York, November 1996, pp108-115</comments><acm-class>C.2.1</acm-class><abstract>  During the design of ABR traffic management at the ATM Forum, we performed
several analyses to ensure that the ABR service will operate efficiently over
satellite links. In the cases where the performance was unacceptable, we
suggested modifications to the traffic management specifications. This paper
describes one such issue related to the count of missing resource management
cells (Crm) parameter of the ABR source behavior. The analysis presented here
led to the changes which are now part of the ATM traffic management (TM 4.0)
specification. In particular, the size of the transient buffer exposure (TBE)
parameter was set to 24 bits, and no size was enforced for the Crm parameter.
This simple change improved the throughput over OC-3 satellite links from 45
Mbps to 140 Mbps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809076</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809076</id><created>1998-09-23</created><authors><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Lu</keyname><forenames>Fang</forenames></author><author><keyname>Kalyanaraman</keyname><forenames>Shivkumar</forenames></author></authors><title>A Survey of Congestion Control Techniques and Data Link Protocols in
  Satellite Networks</title><categories>cs.NI</categories><acm-class>C.2.1</acm-class><abstract>  Satellite communication systems are the means of realizing a global broadband
integrated services digital network. Due to the statistical nature of the
integrated services traffic, the resulting rate fluctuations and burstiness
render congestion control a complicated, yet indispensable function. The long
propagation delay of the earth-satellite link further imposes severe demands
and constraints on the congestion control schemes, as well as the media access
control techniques and retransmission protocols that can be employed in a
satellite network. The problems in designing satellite network protocols, as
well as some of the solutions proposed to tackle these problems, will be the
primary focus of this survey.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809077</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809077</id><created>1998-09-23</created><authors><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Kalyanaraman</keyname><forenames>Shiv</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author><author><keyname>Kim</keyname><forenames>S.</forenames></author></authors><title>Source Behavior for ATM ABR Traffic Management: An Explanation</title><categories>cs.NI</categories><comments>IEEE Communications Magazine, November 1, 1996, vol 34, no11, pp50-57</comments><acm-class>C.2.1</acm-class><abstract>  The Available Bit Rate (ABR) service has been developed to support data
applications over Asynchronous Transfer Mode (ATM) networks. The network
continuously monitors its traffic and provides feedback to the source end
systems. This paper explains the rules that the sources have to follow to
achieve a fair and efficient allocation of network resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809078</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809078</id><created>1998-09-23</created><authors><author><keyname>Kalyanaraman</keyname><forenames>Shiv</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Fahmy</keyname><forenames>Sonia</forenames></author><author><keyname>Goyal</keyname><forenames>Rohit</forenames></author></authors><title>Buffer Requirements For TCP/IP Over ABR</title><categories>cs.NI</categories><comments>Proc. IEEE ATM'96 Workshop, San Fransisco, August 23-24, 1996</comments><acm-class>C.2.1</acm-class><abstract>  We study the buffering requirements for zero cell loss for TCP over ABR. We
show that the maximum buffers required at the switch is proportional to the
maximum round trip time (RTT) of all VCs through the link. The number of
round-trips depends upon the the switch algorithm used. With our ERICA
[erica-final] switch algorithm, we find that the buffering required is
independent of the number of TCP sources. We substantiate our arguments with
simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809079</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809079</id><created>1998-09-23</created><authors><author><keyname>Dommety</keyname><forenames>G.</forenames></author><author><keyname>Jain</keyname><forenames>Raj</forenames></author></authors><title>Potential Networking Applications of Global Positioning Systems (GPS)</title><categories>cs.NI</categories><comments>OSU Technical report, April 1996</comments><report-no>TR-24, April 1996</report-no><acm-class>C.2.1</acm-class><abstract>  The main goal of this study was to survey current applications of GPS to
distributed systems and networks. Detailed lists of GPS products, current
applications, addresses of manufacturers, and sources for further information
are included in this report.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809080</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809080</id><created>1998-09-23</created><authors><author><keyname>Jain</keyname><forenames>Raj</forenames></author><author><keyname>Kalyanaraman</keyname><forenames>Shiv</forenames></author><author><keyname>Viswanathan</keyname><forenames>Ram</forenames></author></authors><title>The OSU Scheme for Congestion Avoidance in ATM networks Using Explicit
  Rate Indication</title><categories>cs.NI</categories><comments>Proceedings WATM'95 First Workshop on ATM Traffic Management, Paris,
  December 1995 (proceedings also to appear in book form)</comments><acm-class>C.2.1</acm-class><abstract>  An explicit rate indication scheme for congestion avoidance in computer and
telecommunication networks is proposed. The sources monitor their load and
provide the information periodically to the switches. The switches, in turn,
compute the load level and ask the sources to adjust their rates up or down.
The scheme achieves high link utilization, fair allocation of rates among
contending sources and provides quick convergence. A backward congestion
notification option is also provided. The conditions under which this option is
useful are indicated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809081</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809081</id><created>1998-09-24</created><authors><author><keyname>Amenta</keyname><forenames>Nina</forenames></author><author><keyname>Bern</keyname><forenames>Marshall</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Optimal Point Placement for Mesh Smoothing</title><categories>cs.CG</categories><comments>12 pages, 3 figures. A preliminary version of this paper was
  presented at the 8th ACM/SIAM Symp. on Discrete Algorithms (SODA '97). This
  is the final version, and will appear in a special issue of J. Algorithms for
  papers from SODA '97</comments><acm-class>F.2.2</acm-class><journal-ref>J. Algorithms 30 (1999) 302-322</journal-ref><doi>10.1006/jagm.1998.0984</doi><abstract>  We study the problem of moving a vertex in an unstructured mesh of
triangular, quadrilateral, or tetrahedral elements to optimize the shapes of
adjacent elements. We show that many such problems can be solved in linear time
using generalized linear programming. We also give efficient algorithms for
some mesh smoothing problems that do not fit into the generalized linear
programming paradigm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809082</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809082</id><created>1998-09-24</created><authors><author><keyname>Charny</keyname><forenames>A.</forenames></author><author><keyname>Clark</keyname><forenames>D.</forenames></author><author><keyname>Jain</keyname><forenames>R.</forenames></author></authors><title>Congestion Control with Explicit Rate Indication</title><categories>cs.NI</categories><comments>Proc. ICC'95, June 1995, pp1954-1963</comments><acm-class>C.2.1</acm-class><abstract>  As the speed and the dynamic range of computer networks evolve, the issue of
efficient traffic management becomes increasingly important. This work
describes an approach to traffic management using explicit rate information
provided to the source by the network. We present an asynchronous distributed
algorithm for optimal rate calculation across the network, where optimality is
understood in the maxmin sense. The algorithm quickly converges to the optimal
rates and is shown to be well-behaved in transience.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809083</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809083</id><created>1998-09-24</created><authors><author><keyname>Siu</keyname><forenames>K.</forenames></author><author><keyname>Jain</keyname><forenames>R.</forenames></author></authors><title>A Brief Overview of ATM: Protocol Layers, LAN Emulation, and Traffic
  Management</title><categories>cs.NI</categories><comments>23 pages</comments><acm-class>C.2.1</acm-class><journal-ref>Computer Communications Review (ACM SIGCOMM), vol 25, no 2, April
  1995, pp6-28</journal-ref><abstract>  Asynchronous Transfer Mode (ATM) has emerged as the most promising technology
in supporting future broadband multimedia communication services. To accelerate
the deployment of ATM technology, the ATM Forum, which is a consortium of
service providers and equipment vendors in the communication industries has
been created to develop implementation and specification agreements. In this
article, we present a brief overview on ATM protocol layers and current
progress on LAN Emulation and Traffic Management in the ATM Forum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809084</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809084</id><created>1998-09-24</created><authors><author><keyname>Jain</keyname><forenames>R.</forenames></author></authors><title>ATM Networks: Issues and Challenges Ahead</title><categories>cs.NI</categories><comments>InterOp+Networld Engineering Conference, March 1995, Las Vegas, NV</comments><acm-class>C.2.1</acm-class><abstract>  The paper begins with a discussion of current trends in networking and a
historical reviews of past networking technologies some of which failed. This
leads us to the discussion about what it takes for a new technology to succeed
and what challenges we face in making the current dream of a seamless
world-wide high-speed ATM network a reality.
  Issues in using ATM cells for very high speed applications are presented.
Ensuring that the users benefit from ATM networks involves several other
related disciplines. These are reviewed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809085</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809085</id><created>1998-09-24</created><authors><author><keyname>Jain</keyname><forenames>R.</forenames></author></authors><title>Congestion Control and Traffic Management in ATM Networks: Recent
  Advances and A Survey</title><categories>cs.NI</categories><comments>Invited submission to Computer Networks and ISDN Systems</comments><acm-class>C.2.1</acm-class><journal-ref>Computer Networks and ISDN Systems, vol 28, no 13, February 1995,
  pp1723-1738</journal-ref><abstract>  Congestion control mechanisms for ATM networks as selected by the ATM Forum
traffic management group are described. Reasons behind these selections are
explained. In particular, selection criteria for selection between rate-based
and credit-based approach and the key points of the debate between the two
approaches are presented. The approach that was finally selected and several
other schemes that were considered are described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809086</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809086</id><created>1998-09-24</created><authors><author><keyname>Jain</keyname><forenames>R.</forenames></author></authors><title>FDDI: Current Issues and Future Trends</title><categories>cs.NI</categories><acm-class>C.2.1</acm-class><journal-ref>IEEE Communications Magazine, September 1993, pp. 98-105</journal-ref><abstract>  Key issues in upcoming FDDI standards including low-cost fiber, twisted-pair,
SONET mapping, and FDDI follow-on LAN are discussed after a brief introduction
to FDDI and FDDI-II
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809087</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809087</id><created>1998-09-24</created><authors><author><keyname>Jain</keyname><forenames>R.</forenames></author></authors><title>A Comparison of Hashing Schemes for Address Lookup in Computer Networks</title><categories>cs.NI</categories><acm-class>C.2.1</acm-class><journal-ref>IEEE Transactions on Communications, Vol. 40, No. 3, October 1992,
  pp. 1570-1573</journal-ref><abstract>  Using a trace of address references, we compared the efficiency of several
different hashing functions, such as cyclic redundancy checking (CRC)
polynomials, Fletcher checksum, folding of address octets using the
exclusive-or operation and bit extraction from the address. Guidelines are
provided for determining the size of the hashmark required to achieve a
specified level of performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809088</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809088</id><created>1998-09-24</created><authors><author><keyname>Jain</keyname><forenames>R.</forenames></author></authors><title>Myths about Congestion Management in High Speed Networks</title><categories>cs.NI</categories><acm-class>C.2.1</acm-class><journal-ref>Internetworking: Research and Experience, Volume 3, 1992, pp.
  101-113</journal-ref><abstract>  Weaknesses in several recently proposed ideas about congestion control and
avoidance in high-speed netwroks are identified. Both sides of the debate
concerning prior reservation of resources versus walk-in service, open-loop
control versus feedback control, rate control versus window control, and
router-based control versus source-based control are presented. The
circumstances under which backpressure is useful or not are discussed, and it
is argued that a single congestion scheme is not sufficient, but that a
combination of several schemes is required for complete congestion management
in a network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809089</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809089</id><created>1998-09-24</created><authors><author><keyname>Jain</keyname><forenames>R.</forenames></author></authors><title>Performance Analysis of FDDI Token Ring Networks: Effect of Parameters
  and Guidelines for Setting TTRT</title><categories>cs.NI</categories><acm-class>C.2.1</acm-class><journal-ref>IEEE Lightwave Telecommunication Systems, vol 20, no 2, May 1991,
  pp. 16-22</journal-ref><abstract>  The performance of Fiber-Distributed Data Interface (FDDI) depends upon
several workload parameters; for example; the arrival pattern, frame size, and
configuration parameters, such as the number of stations on the ring, extent of
the ring, and number of stations that are waiting to transmit. In addition, the
performance is affected by a parameter called the Target Token Rotation Time
(TTRT), which can be controlled by the network manager. We considered the
effect of TTRT on various performance metrics for different ring configurations
and concluded that a TTRT value of 8 ms provides a good performance over a wide
range of configurations and workloads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809090</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809090</id><created>1998-09-24</created><authors><author><keyname>Jain</keyname><forenames>R.</forenames></author></authors><title>Error Characteristics of Fiber Distributed Data Interface (FDDI)</title><categories>cs.NI</categories><acm-class>C.2.1</acm-class><journal-ref>IEEE Transactions on Communications, Vol. 38, No. 8, August 1990,
  pp. 1224-1252</journal-ref><abstract>  Fiber Distributed Data Interface (FDDI) is a 100 megabits per second fiber
optic local area network (LAN) standard being developed by the American
National Standard Institute (ANSI).
  We analyze the impact of various design decisions on the error detection
capability of the protocol. In particular, we quantify frame error rate, token
loss rate, and undetected error rate. Several characteristics of the 32-bit
frame check sequence (FCS) polynomial, which is also used in IEEE 802 LAN
protocols, are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809091</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809091</id><created>1998-09-24</created><authors><author><keyname>Jain</keyname><forenames>R.</forenames></author></authors><title>Congestion Control in Computer Networks: Trends and Issues</title><categories>cs.NI</categories><acm-class>C.2.1</acm-class><journal-ref>IEEE Network, May 1990, pp. 24-30</journal-ref><abstract>  Popular myths that cheaper memory, high-speed links and high-speed processors
will solve the problem of congestion in computer networks are shown to be
false. A simple definition for congestion based on supply and demand of
resources is proposed and is then used to classify various congestion schemes.
The issues that make the congestion problem a difficult one are discussed, and
then the architectural decisions that affect the design of a congestion scheme
are presented. It is argued that long-, medium- and short-term congestion
problems require different solutions. Some of the recent schemes are brifly
surveyed, and areas for further research are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809092</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809092</id><created>1998-09-24</created><authors><author><keyname>Jain</keyname><forenames>R.</forenames></author></authors><title>Characteristics of Destination Address Locality in Computer Networks: A
  Comparison of Caching Schemes</title><categories>cs.NI</categories><acm-class>C.2.1</acm-class><journal-ref>Journal of Computer Networks and ISDN, Vol. 18, 1989/90, pp.
  243-254</journal-ref><abstract>  The size of computer networks, along with their bandwidths, is growing
exponentially. To support these large, high-speed networks, it is neccessary to
be able to forward packets in a few microseconds. One part of the forwarding
operation consists of searching through a large address databse. This problem
is encountered in the design of bridges, routers, gateways and name servers.
  Caching can reduce the lookup time if there is a locality in the address
reference pattern. Using a destination reference trace measured on an extended
local are a network, we attempt to see if the destination refernces do have a
significant locality.
  We compared the performance of MIN, LRU, FIFO, and random cache replacement
algorithms. We found that the interactive (terminal) traffic in our sample had
quite different locality behavior than that of the noninteractive traffic. The
interactive traffic did not follow the LRU stack model while the
noninteractivetraffic did. Examples are shown of the environments in which
caching can help as well as those in which caching can hurt, unless the cache
size is large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809093</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809093</id><created>1998-09-24</created><authors><author><keyname>Jain</keyname><forenames>R.</forenames></author></authors><title>A Delay Based Approach for Congestion Avoidance in Interconnected
  Heterogeneous Computer Networks</title><categories>cs.NI</categories><acm-class>C.2.1</acm-class><journal-ref>Computer Communications Review, ACM SIGCOMM, October 1989, pp.
  56-71</journal-ref><abstract>  In heterogeneous networks, achieving congestion avoidance is difficult
because the congestion feedback from one subnetwork may have no meaning to
source on other other subnetworks. We propose using changes in round-trip delay
as an implicit feedback. Using a black-box model of the network, we derive an
expression for the optimal window as a function of the gradient of the
delay-window curve.
  The problems of selfish optimum and social optimum are also addressed. It is
shown that without a careful design, it is possible to get into a race
condition during heavy congestion, where each user wants more resources than
others, thereby leading to a diverging congestion
  It is shown that congestion avoidance using round trip delay is a promising
approach. The aproach has the advantage that there is absolutely no overhead
for the network itself. It is exemplified by a simple scheme. The performance
of the scheme is analyzed using a simulation model. The scheme is shown to be
efficient, fair, convergent and adaptive to changes in network configuration.
  The scheme as described works only for networks that can ne modelled with
queueing servers with constant service times. Further research is required to
extend it for implementation in practical networks. Several directions for
future research have beensuggested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809094</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809094</id><created>1998-09-24</created><authors><author><keyname>Jain</keyname><forenames>R.</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>K.</forenames></author><author><keyname>Chiu</keyname><forenames>D.</forenames></author></authors><title>Congestion Avoidance in Computer Networks with a Connectionless Network
  Layer</title><categories>cs.NI</categories><comments>DEC-TR-506, reprinted in C. Partridge, Ed., &quot;Innovations in
  Internetworking,&quot; published by Artech House, October 1988</comments><acm-class>C.2.1</acm-class><abstract>  Widespread use of computer networks and the use of varied technology for the
interconnection of computers has made congestion a significant problem.
  In this report, we summarize our research on congestion avoidance. We compare
the concept of congestion avoidance with that of congestion control.
  Briefly, congestion control is a recovery mechanism, while congestion
avoidance is a prevention mechanism. A congestion control scheme helps the
network to recover from the congestion state while a congestion avoidance
scheme allows a network to operate in the region of low delay and high
throughput with minimal queuing, thereby preventing it from entering the
congested state in which packets are lost due to buffer shortage.
  A number of possible alternatives for congestion avoidance were identified.
  From these alternatives we selected one called the binary feedback scheme in
which the network uses a single bit in the network layer header to feed back
the congestion information to its users, which then increase or decrease their
load to make optimal use of the resources. The concept of global optimality in
a distributed system is defined in terms of efficiency and fairness such that
they can be independently quantified and apply to any number of resources and
users.
  The proposed scheme has been simulated and shown to be globally efficient,
fair, responsive, convergent, robust, distributed, and
configuration-independent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809095</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809095</id><created>1998-09-24</created><authors><author><keyname>Jain</keyname><forenames>R.</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>K.</forenames></author></authors><title>Congestion Avoidance in Computer Networks with a Connectionless Network
  Layer, Part I: Concepts, Goals and Methodology</title><categories>cs.NI</categories><comments>roc. Computer Networking Symposium, Washington, D.C., April 11-13,
  1988, pp. 134-143</comments><acm-class>C.2.1</acm-class><abstract>  Congestion is said to occur in the network when the resource demands exceed
the capacity and packets are lost due to too much queuing in the network.
During congestion, the network throughput may drop to zero and the path delay
may become very high. A congestion control scheme helps the network to recover
from the congestion state. A congestion avoidance scheme allows a network to
operate in the region of low delay and high throughput. Such schemes prevent a
network from entering the congested state. Congestion avoidance is a prevention
mechanism while congestion control is a recovery mechanism. We compare the
concept of congestion avoidance with that of flow control and congestion
control. A number of possible alternative for congestion avoidance have been
identified. From these a few were selected for study. The criteria for
selection and goals for these schemes have been described. In particular, we
wanted the scheme to be globally efficient, fair, dynamic, convergent, robust,
distributed, configuration independent, etc. These goals and the test cases
used to verify whether a particular scheme has met the goals have been
described. We model the network and the user policies for congestion avoidance
as a feedback control system. The key components of a generic congestion
avoidance scheme are: congestion detection, congestion feedback, feedback
selector, signal filter, decision function, and increase/decrease algorithms.
These components have been explained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809096</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809096</id><created>1998-09-24</created><authors><author><keyname>Jain</keyname><forenames>R.</forenames></author></authors><title>A Timeout Based Congestion Control Scheme for Window Flow- Controlled
  Networks</title><categories>cs.NI</categories><comments>also reprinted in C. Partridge, Ed., &quot;Innovations in
  Internetworking,&quot; Artech House, Norwood, MA 1988</comments><acm-class>C.2.1</acm-class><journal-ref>IEEE Journal of Selected Areas in Communications, Vol. SAC-4, No.
  7, October 1986, pp. 1162-1167</journal-ref><abstract>  During overload, most networks drop packets due to buffer unavailability. The
resulting timeouts at the source provide an implicit mechanism to convey
congestion signals from the network to the source. On a timeout, a source
should not only retransmit the lost packet, but it should also reduce its load
on the network. Based on this realization, we have developed a simple
congestion control scheme using the acknowledgment timeouts as indications of
packet loss and congestion. This scheme does not require any new message
formats, therefore, it can be used in any network with window flow control,
e.g., ARPAnet or ISO.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809097</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809097</id><created>1998-09-24</created><authors><author><keyname>Jain</keyname><forenames>R.</forenames></author></authors><title>Divergence of Timeout Algorithms for Packet Retransmissions</title><categories>cs.NI</categories><comments>Proceedings IEEE Phoenix Conference on Computers and Communication,
  March 1986, pp. 174-179</comments><acm-class>C.2.1</acm-class><abstract>  The problem of adaptively setting the timeout interval for retransmitting a
packet has been discussed. A layered view of the algorithms has been presented.
It is shown that a timeout algorithm consists of essentially five layers or
procedures which can be independently chosen and modified. A number of timeout
algorithms proposed in the literature have been decomposed into these five
layers.
  One of the key layers not discussed in the literature is that of determining
the sample round trip delay for packets that have been transmitted more than
once. It is shown that this layer has a significant impact on the network
performance.
  Under repeated packet loss, most timeout algorithms either diverge or
converge to a wrong value. A number of alternative schemes have been presented.
It is argued that divergence is preferable to false convergence. It is a
feature that is helpful in reducing network traffic congestion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809098</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809098</id><created>1998-09-24</created><authors><author><keyname>Jain</keyname><forenames>R.</forenames></author></authors><title>On Caching out-of-order packets in window flow controlled networks</title><categories>cs.NI</categories><comments>DEC Technical Report DEC-TR-342, January 1985</comments><report-no>DEC-TR-342</report-no><acm-class>C.2.1</acm-class><abstract>  In window flow controlled networks, if a packet is lost the destination has
to decide whether to save (cache) subsequent out-of-order packets. Also, the
source has to decide whether to send just one packet or to send all packets
following it. This leads to four different types of caching schemes.
Simulations show, against our immediate intuition, that regardless of whether
the destination is caching or not, the source should retransmit only one
packet. This paper describes the alternatives to, and provides justification
for, schemes used in Digital Network Architecture and ARPAnet TCP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809099</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809099</id><created>1998-09-24</created><authors><author><keyname>Jain</keyname><forenames>R.</forenames></author><author><keyname>Chiu</keyname><forenames>D.</forenames></author><author><keyname>Hawe</keyname><forenames>W.</forenames></author></authors><title>A Quantitative Measure Of Fairness And Discrimination For Resource
  Allocation In Shared Computer Systems</title><categories>cs.NI</categories><comments>DEC Research Report TR-301, September 1984</comments><report-no>TR-301</report-no><acm-class>C.2.1</acm-class><abstract>  Fairness is an important performance criterion in all resource allocation
schemes, including those in distributed computer systems. However, it is often
specified only qualitatively. The quantitative measures proposed in the
literature are either too specific to a particular application, or suffer from
some undesirable characteristics. In this paper, we have introduced a
quantitative measure called Indiex of FRairness. The index is applicable to any
resource sharing or allocation problem. It is independent of the amount of the
resource. The fairness index always lies between 0 and 1. This boundedness aids
intuitive understanding of the fairness index. For example, a distribution
algorithm with a fairness of 0.10 means that it is unfair to 90% of the users.
Also, the discrimination index can be defined as 1 - fairness index.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809100</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809100</id><created>1998-09-24</created><authors><author><keyname>Jain</keyname><forenames>R.</forenames></author></authors><title>Data Flies Standby with ABR Service</title><categories>cs.NI</categories><acm-class>C.2.1</acm-class><journal-ref>Network World, June 12, 1995, page 43</journal-ref><abstract>  Explanation of ABR service in plain language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809101</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809101</id><created>1998-09-24</created><authors><author><keyname>Cho</keyname><forenames>Jaihyung</forenames></author><author><keyname>Breen</keyname><forenames>James</forenames></author></authors><title>Flood Routing Technique for Data Networks</title><categories>cs.NI</categories><acm-class>C.2.2</acm-class><journal-ref>ICICS`97;First International Conference on Information,
  Communications and Signal Processing, IEEE Singapore, vo. 3, Sep 1997. pp.
  1418-1422</journal-ref><abstract>  In this paper, a new routing algorithm based on a flooding method is
introduced. Flooding techniques have been used previously, e.g. for
broadcasting the routing table in the ARPAnet [1] and other special purpose
networks [3][4][5]. However, sending data using flooding can often saturate the
network [2] and it is usually regarded as an inefficient broadcast mechanism.
Our approach is to flood a very short packet to explore an optimal route
without relying on a pre-established routing table, and an efficient flood
control algorithm to reduce the signalling traffic overhead. This is an
inherently robust mechanism in the face of a network configuration change,
achieves automatic load sharing across alternative routes and has potential to
solve many contemporary routing problems. An earlier version of this mechanism
was originally developed for virtual circuit establishment in the experimental
Caroline ATM LAN [6][7] at Monash University.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809102</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809102</id><created>1998-09-24</created><authors><author><keyname>Cho</keyname><forenames>Jaihyung</forenames></author><author><keyname>Breen</keyname><forenames>James</forenames></author></authors><title>Analysis of Performance of Dynamic Multicast Routing Algorithms</title><categories>cs.NI</categories><acm-class>C.2.2;C.4</acm-class><journal-ref>ICCCN`98;IEEE 7th International Conference onComputer
  Communications and Networks, lafayett Louisiana, U.S.A, Oct. 1998</journal-ref><abstract>  In this paper, three new dynamic multicast routing algorithms based on the
greedy tree technique are proposed; Source Optimised Tree, Topology Based Tree
and Minimum Diameter Tree. A simulation analysis is presented showing various
performance aspects of the algorithms, in which a comparison is made with the
greedy and core based tree techniques. The effects of the tree source location
on dynamic membership change are also examined. The simulations demonstrate
that the Source Optimised Tree algorithm achieves a significant improvement in
terms of delay and link usage when compared to the Core Based Tree, and greedy
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809103</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809103</id><created>1998-09-24</created><authors><author><keyname>Marathe</keyname><forenames>Madhav V.</forenames></author><author><keyname>Ravi</keyname><forenames>R.</forenames></author><author><keyname>Sundaram</keyname><forenames>Ravi</forenames></author><author><keyname>Ravi</keyname><forenames>S. S.</forenames></author><author><keyname>Rosenkrantz</keyname><forenames>Daniel J.</forenames></author><author><keyname>Hunt</keyname><forenames>Harry B.</forenames><suffix>III</suffix></author></authors><title>Bicriteria Network Design Problems</title><categories>cs.CC cs.DS</categories><comments>24 pages 1 figure</comments><acm-class>F,2.2</acm-class><journal-ref>J. Algorithms, 28, 142-171, (1998)</journal-ref><abstract>  We study a general class of bicriteria network design problems. A generic
problem in this class is as follows: Given an undirected graph and two
minimization objectives (under different cost functions), with a budget
specified on the first, find a &lt;subgraph \from a given subgraph-class that
minimizes the second objective subject to the budget on the first. We consider
three different criteria - the total edge cost, the diameter and the maximum
degree of the network. Here, we present the first polynomial-time approximation
algorithms for a large class of bicriteria network design problems for the
above mentioned criteria. The following general types of results are presented.
  First, we develop a framework for bicriteria problems and their
approximations. Second, when the two criteria are the same %(note that the cost
functions continue to be different) we present a ``black box'' parametric
search technique. This black box takes in as input an (approximation) algorithm
for the unicriterion situation and generates an approximation algorithm for the
bicriteria case with only a constant factor loss in the performance guarantee.
Third, when the two criteria are the diameter and the total edge costs we use a
cluster-based approach to devise a approximation algorithms --- the solutions
output violate both the criteria by a logarithmic factor. Finally, for the
class of treewidth-bounded graphs, we provide pseudopolynomial-time algorithms
for a number of bicriteria problems using dynamic programming. We show how
these pseudopolynomial-time algorithms can be converted to fully
polynomial-time approximation schemes using a scaling technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809104</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809104</id><created>1998-09-24</created><authors><author><keyname>Vickers</keyname><forenames>Brett J.</forenames></author><author><keyname>Albuquerque</keyname><forenames>Celio</forenames></author><author><keyname>Suda</keyname><forenames>Tatsuya</forenames></author></authors><title>Adaptive Multicast of Multi-Layered Video: Rate-Based and Credit-Based
  Approaches</title><categories>cs.NI cs.MM</categories><comments>11 pages</comments><acm-class>C.2.1</acm-class><journal-ref>Proceedings of IEEE Infocom '98, pp. 1073-1083, April 1998</journal-ref><abstract>  Network architectures that can efficiently transport high quality, multicast
video are rapidly becoming a basic requirement of emerging multimedia
applications. The main problem complicating multicast video transport is
variation in network bandwidth constraints. An attractive solution to this
problem is to use an adaptive, multi-layered video encoding mechanism. In this
paper, we consider two such mechanisms for the support of video multicast; one
is a rate-based mechanism that relies on explicit rate congestion feedback from
the network, and the other is a credit-based mechanism that relies on
hop-by-hop congestion feedback. The responsiveness, bandwidth utilization,
scalability and fairness of the two mechanisms are evaluated through
simulations. Results suggest that while the two mechanisms exhibit performance
trade-offs, both are capable of providing a high quality video service in the
presence of varying bandwidth constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809105</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809105</id><created>1998-09-24</created><authors><author><keyname>Lippert</keyname><forenames>Thomas</forenames></author><author><keyname>Petkov</keyname><forenames>Nikolay</forenames></author><author><keyname>Palazzari</keyname><forenames>Paolo</forenames></author><author><keyname>Schilling</keyname><forenames>Klaus</forenames></author></authors><title>Hyper-Systolic Matrix Multiplication</title><categories>cs.MS</categories><comments>29 pages, 13 figures</comments><report-no>HLRZ1998-59</report-no><acm-class>D.1.3; G.4</acm-class><abstract>  A novel parallel algorithm for matrix multiplication is presented. The
hyper-systolic algorithm makes use of a one-dimensional processor abstraction.
The procedure can be implemented on all types of parallel systems. It can
handle matrix-vector multiplications as well as transposed matrix products.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809106</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809106</id><created>1998-09-25</created><authors><author><keyname>Barg</keyname><forenames>Petra</forenames><affiliation>University of Duesseldorf</affiliation></author><author><keyname>Walther</keyname><forenames>Markus</forenames><affiliation>University of Duesseldorf</affiliation></author></authors><title>Processing Unknown Words in HPSG</title><categories>cs.CL</categories><comments>5 pp., 1 PostScript figure</comments><acm-class>I.2.7</acm-class><journal-ref>Proceedings COLING-ACL'98, vol.I, 91-95</journal-ref><abstract>  The lexical acquisition system presented in this paper incrementally updates
linguistic properties of unknown words inferred from their surrounding context
by parsing sentences with an HPSG grammar for German. We employ a gradual,
information-based concept of ``unknownness'' providing a uniform treatment for
the range of completely known to maximally unknown lexical entries. ``Unknown''
information is viewed as revisable information, which is either generalizable
or specializable. Updating takes place after parsing, which only requires a
modified lexical lookup. Revisable pieces of information are identified by
grammar-specified declarations which provide access paths into the parse
feature structure. The updating mechanism revises the corresponding places in
the lexical feature structures iff the context actually provides new
information. For revising generalizable information, type union is required. A
worked-out example demonstrates the inferential capacity of our implemented
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809107</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809107</id><created>1998-09-25</created><authors><author><keyname>Walther</keyname><forenames>Markus</forenames><affiliation>University of Marburg</affiliation></author></authors><title>Computing Declarative Prosodic Morphology</title><categories>cs.CL</categories><comments>10 pages</comments><acm-class>I.2.7</acm-class><journal-ref>Proceedings of SIGPHON'98, pp. 11-20 (COLING-ACL'98
  Post-Conference Workshop on The Computation of Phonological Constraints)</journal-ref><abstract>  This paper describes a computational, declarative approach to prosodic
morphology that uses inviolable constraints to denote small finite candidate
sets which are filtered by a restrictive incremental optimization mechanism.
The new approach is illustrated with an implemented fragment of Modern Hebrew
verbs couched in MicroCUF, an expressive constraint logic formalism. For
generation and parsing of word forms, I propose a novel off-line technique to
eliminate run-time optimization. It produces a finite-state oracle that
efficiently restricts the constraint interpreter's search space. As a
byproduct, unknown words can be analyzed without special mechanisms. Unlike
pure finite-state transducer approaches, this hybrid setup allows for more
expressivity in constraints to specify e.g. token identity for reduplication or
arithmetic constraints for phonetics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809108</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809108</id><created>1998-09-26</created><authors><author><keyname>Vidal</keyname><forenames>Jose M.</forenames></author><author><keyname>Durfee</keyname><forenames>Edmund H.</forenames></author></authors><title>Learning Nested Agent Models in an Information Economy</title><categories>cs.MA cs.AI</categories><acm-class>I 2.11</acm-class><journal-ref>Journal of Experimental and Theoretical Artificial Intelligence.
  10(1998)291-308</journal-ref><abstract>  We present our approach to the problem of how an agent, within an economic
Multi-Agent System, can determine when it should behave strategically (i.e.
learn and use models of other agents), and when it should act as a simple
price-taker. We provide a framework for the incremental implementation of
modeling capabilities in agents, and a description of the forms of knowledge
required. The agents were implemented and different populations simulated in
order to learn more about their behavior and the merits of using and learning
agent models. Our results show, among other lessons, how savvy buyers can avoid
being ``cheated'' by sellers, how price volatility can be used to
quantitatively predict the benefits of deeper models, and how specific types of
agent populations influence system behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809109</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809109</id><created>1998-09-26</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Linear Complexity Hexahedral Mesh Generation</title><categories>cs.CG</categories><comments>12 pages, 17 figures. A preliminary version of this paper appeared at
  the 12th ACM Symp. on Computational Geometry. This is the final version, and
  will appear in a special issue of Computational Geometry: Theory and
  Applications for papers from SCG '96</comments><acm-class>F.2.2</acm-class><journal-ref>Comp. Geom. Theory &amp; Appl. 12 (1999) 3-16</journal-ref><doi>10.1016/S0925-7721(98)00032-7</doi><abstract>  We show that any polyhedron forming a topological ball with an even number of
quadrilateral sides can be partitioned into O(n) topological cubes, meeting
face to face. The result generalizes to non-simply-connected polyhedra
satisfying an additional bipartiteness condition. The same techniques can also
be used to reduce the geometric version of the hexahedral mesh generation
problem to a finite case analysis amenable to machine solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809110</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809110</id><created>1998-09-27</created><authors><author><keyname>Dagan</keyname><forenames>Ido</forenames></author><author><keyname>Lee</keyname><forenames>Lillian</forenames></author><author><keyname>Pereira</keyname><forenames>Fernando C. N.</forenames></author></authors><title>Similarity-Based Models of Word Cooccurrence Probabilities</title><categories>cs.CL cs.AI cs.LG</categories><comments>26 pages, 5 figures</comments><acm-class>I.2.7;I.2.6</acm-class><journal-ref>Machine Learning, 34, 43-69 (1999)</journal-ref><abstract>  In many applications of natural language processing (NLP) it is necessary to
determine the likelihood of a given word combination. For example, a speech
recognizer may need to determine which of the two word combinations ``eat a
peach'' and ``eat a beach'' is more likely. Statistical NLP methods determine
the likelihood of a word combination from its frequency in a training corpus.
However, the nature of language is such that many word combinations are
infrequent and do not occur in any given corpus. In this work we propose a
method for estimating the probability of such previously unseen word
combinations using available information on ``most similar'' words.
  We describe probabilistic word association models based on distributional
word similarity, and apply them to two tasks, language modeling and pseudo-word
disambiguation. In the language modeling task, a similarity-based model is used
to improve probability estimates for unseen bigrams in a back-off language
model. The similarity-based method yields a 20% perplexity improvement in the
prediction of unseen bigrams and statistically significant reductions in
speech-recognition error.
  We also compare four similarity-based estimation methods against back-off and
maximum-likelihood estimation methods on a pseudo-word sense disambiguation
task in which we controlled for both unigram and bigram frequency to avoid
giving too much weight to easy-to-disambiguate high-frequency configurations.
The similarity-based methods perform up to 40% better on this particular task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809111</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809111</id><created>1998-09-27</created><authors><author><keyname>Weaver</keyname><forenames>Lex</forenames></author><author><keyname>Bossomaier</keyname><forenames>Terry</forenames></author></authors><title>Evolution of Neural Networks to Play the Game of Dots-and-Boxes</title><categories>cs.NE cs.LG</categories><comments>8 pages, 5 figures, LaTeX 2.09 (works with LaTeX2e)</comments><acm-class>I.2.6</acm-class><journal-ref>Alife V: Poster Presentations, May 16-18 1996, pages 43-50</journal-ref><abstract>  Dots-and-Boxes is a child's game which remains analytically unsolved. We
implement and evolve artificial neural networks to play this game, evaluating
them against simple heuristic players. Our networks do not evaluate or predict
the final outcome of the game, but rather recommend moves at each stage.
Superior generalisation of play by co-evolved populations is found, and a
comparison made with networks trained by back-propagation using simple
heuristics as an oracle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809112</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809112</id><created>1998-09-28</created><authors><author><keyname>Padro</keyname><forenames>L.</forenames><affiliation>Universitat Politecnica de Catalunya</affiliation></author><author><keyname>Marquez</keyname><forenames>L.</forenames><affiliation>Universitat Politecnica de Catalunya</affiliation></author></authors><title>On the Evaluation and Comparison of Taggers: The Effect of Noise in
  Testing Corpora</title><categories>cs.CL</categories><comments>Appears in proceedings of joint COLING-ACL 1998, Montreal, Canada</comments><acm-class>I.2.7</acm-class><abstract>  This paper addresses the issue of {\sc pos} tagger evaluation. Such
evaluation is usually performed by comparing the tagger output with a reference
test corpus, which is assumed to be error-free. Currently used corpora contain
noise which causes the obtained performance to be a distortion of the real
value. We analyze to what extent this distortion may invalidate the comparison
between taggers or the measure of the improvement given by a new system. The
main conclusion is that a more rigorous testing experimentation
setting/designing is needed to reliably evaluate and compare tagger accuracies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809113</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809113</id><created>1998-09-28</created><authors><author><keyname>Marquez</keyname><forenames>L.</forenames><affiliation>Universitat Politecnica de Catalunya</affiliation></author><author><keyname>Padro</keyname><forenames>L.</forenames><affiliation>Universitat Politecnica de Catalunya</affiliation></author><author><keyname>Rodriguez</keyname><forenames>H.</forenames><affiliation>Universitat Politecnica de Catalunya</affiliation></author></authors><title>Improving Tagging Performance by Using Voting Taggers</title><categories>cs.CL</categories><comments>Appears in proceedings of NLP+IA/TAL+AI'98. Moncton, New Brunswick,
  Canada, 1998</comments><acm-class>I.2.7</acm-class><abstract>  We present a bootstrapping method to develop an annotated corpus, which is
specially useful for languages with few available resources. The method is
being applied to develop a corpus of Spanish of over 5Mw. The method consists
on taking advantage of the collaboration of two different POS taggers. The
cases in which both taggers agree present a higher accuracy and are used to
retrain the taggers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809114</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809114</id><created>1998-09-28</created><authors><author><keyname>Lautemann</keyname><forenames>Clemens</forenames></author><author><keyname>McKenzie</keyname><forenames>Pierre</forenames></author><author><keyname>Schwentick</keyname><forenames>Thomas</forenames></author><author><keyname>Vollmer</keyname><forenames>Heribert</forenames></author></authors><title>The descriptive complexity approach to LOGCFL</title><categories>cs.CC</categories><comments>10 pages, 1 figure</comments><acm-class>F.1.3</acm-class><abstract>  Building upon the known generalized-quantifier-based first-order
characterization of LOGCFL, we lay the groundwork for a deeper investigation.
Specifically, we examine subclasses of LOGCFL arising from varying the arity
and nesting of groupoidal quantifiers. Our work extends the elaborate theory
relating monoidal quantifiers to NC1 and its subclasses. In the absence of the
BIT predicate, we resolve the main issues: we show in particular that no single
outermost unary groupoidal quantifier with FO can capture all the context-free
languages, and we obtain the surprising result that a variant of Greibach's
``hardest context-free language'' is LOGCFL-complete under quantifier-free
BIT-free projections. We then prove that FO with unary groupoidal quantifiers
is strictly more expressive with the BIT predicate than without. Considering a
particular groupoidal quantifier, we prove that first-order logic with majority
of pairs is strictly more expressive than first-order with majority of
individuals. As a technical tool of independent interest, we define the notion
of an aperiodic nondeterministic finite automaton and prove that FO
translations are precisely the mappings computed by single-valued aperiodic
nondeterministic finite transducers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809115</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809115</id><created>1998-09-28</created><authors><author><keyname>Vollmer</keyname><forenames>Heribert</forenames></author></authors><title>A Generalized Quantifier Concept in Computational Complexity Theory</title><categories>cs.CC</categories><acm-class>F.1.3</acm-class><abstract>  A notion of generalized quantifier in computational complexity theory is
explored and used to give a unified treatment of leaf language definability,
oracle separations, type 2 operators, and circuits with monoidal gates.
Relations to Lindstroem quantifiers are pointed out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809116</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809116</id><created>1998-09-28</created><authors><author><keyname>Reith</keyname><forenames>Steffen</forenames></author><author><keyname>Vollmer</keyname><forenames>Heribert</forenames></author></authors><title>The Complexity of Computing Optimal Assignments of Generalized
  Propositional Formulae</title><categories>cs.CC</categories><comments>17 pages, 1 figure</comments><acm-class>F.1.3</acm-class><abstract>  We consider the problems of finding the lexicographically minimal (or
maximal) satisfying assignment of propositional formulae for different
restricted formula classes. It turns out that for each class from our
framework, the above problem is either polynomial time solvable or complete for
OptP. We also consider the problem of deciding if in the optimal assignment the
largest variable gets value 1. We show that this problem is either in P or P^NP
complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809117</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809117</id><created>1998-09-28</created><updated>1998-09-28</updated><authors><author><keyname>Horie</keyname><forenames>Satoshi</forenames></author><author><keyname>Watanabe</keyname><forenames>Osamu</forenames></author></authors><title>Hard instance generation for SAT</title><categories>cs.CC</categories><report-no>TR98-0007</report-no><acm-class>F.2</acm-class><journal-ref>In the Proc. of ISAAC'97, Lecture Notes in CS, Vol.1350, 22-31,
  1997</journal-ref><abstract>  We propose an algorithm of generating hard instances for the Satisfying
Assignment Search Problem (in short, SAT). The algorithm transforms instances
of the integer factorization problem into SAT instances efficiently by using
the Chinese Remainder Theorem. For example, it is possible to construct SAT
instances with about 5,600 variables that is as hard as factorizing 100 bit
integers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809118</identifier>
 <datestamp>2016-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809118</id><created>1998-09-28</created><authors><author><keyname>Schmitz</keyname><forenames>Heinz</forenames></author><author><keyname>Wagner</keyname><forenames>Klaus W.</forenames></author></authors><title>The Boolean Hierarchy over Level 1/2 of the Straubing-Therien Hierarchy</title><categories>cs.CC cs.FL</categories><report-no>201</report-no><acm-class>F.1.3; F.4.3</acm-class><abstract>  For some fixed alphabet A, a language L of A* is in the class L(1/2) of the
Straubing-Therien hierarchy if and only if it can be expressed as a finite
union of languages A*aA*bA*...A*cA*, where a,b,...,c are letters. The class
L(1) is defined as the boolean closure of L(1/2). It is known that the classes
L(1/2) and L(1) are decidable. We give a membership criterion for the single
classes of the boolean hierarchy over L(1/2). From this criterion we can
conclude that this boolean hierarchy is proper and that its classes are
decidable.In finite model theory the latter implies the decidability of the
classes of the boolean hierarchy over the class Sigma(1) of the FO(&lt;)-logic.
Moreover we prove a ``forbidden-pattern'' characterization of L(1) of the type:
L is in L(1) if and only if a certain pattern does not appear in the transition
graph of a deterministic finite automaton accepting L. We discuss complexity
theoretical consequences of our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809119</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809119</id><created>1998-09-29</created><authors><author><keyname>Juriev</keyname><forenames>Denis V.</forenames></author></authors><title>Droems: experimental mathematics, informatics and infinite dimensional
  geometry</title><categories>cs.HC cs.GR math.RT</categories><comments>bilingual version [English translation+Russian original]: 43 pages,
  AMSTEX</comments><report-no>RCMPI/96-05+</report-no><acm-class>H.1.2; I.3.8</acm-class><abstract>  The article is devoted to a problem of elaboration of the real-time
interactive videosystems for accelerated nonverbal cognitive computer and
telecommunications. The proposed approach is based on the using of droems
(dynamically reconstructed objects of experimental mathematics) and
interpretational figures as pointers to them. Four paragraphs of the article
are devoted to (1) an exposition of basic notions of the interpretational
geometry, (2) the operator methods in the theory of interactive dynamical
videosystems, (3) the general concept of organization of the integrated
interactive real-time videocognitive systems, (4) the droems and processes of
their dynamical reconstruction, where the general notions are illustrated by a
concrete example related to the infinite dimensional geometry. The exposition
is presumably heuristic and conceptual (the first and the third paragraphs)
though some particular aspects such as content of the second and the fourth
paragraphs, which allow deeper formalization and detailing in present, are
exposed on the mathematical level of rigor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809120</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809120</id><created>1998-09-29</created><authors><author><keyname>Miculan</keyname><forenames>Marino</forenames></author></authors><title>A Natural Deduction style proof system for propositional $\mu$-calculus
  and its formalization in inductive type theories</title><categories>cs.LO</categories><comments>17 pages; longer version of the paper which will appear in Proc.
  ICTCS'98 (World Scientific)</comments><acm-class>D.2.4; F.3.1; F.4.1</acm-class><abstract>  In this paper, we present a formalization of Kozen's propositional modal
$\mu$-calculus, in the Calculus of Inductive Constructions. We address several
problematic issues, such as the use of higher-order abstract syntax in
inductive sets in presence of recursive constructors, the encoding of modal
(``proof'') rules and of context sensitive grammars. The encoding can be used
in the \Coq system, providing an experimental computer-aided proof environment
for the interactive development of error-free proofs in the $\mu$-calculus. The
techniques we adopted can be readily ported to other languages and proof
systems featuring similar problematic issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809121</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809121</id><created>1998-09-29</created><authors><author><keyname>Rowe</keyname><forenames>Neil C.</forenames></author></authors><title>Using Local Optimality Criteria for Efficient Information Retrieval with
  Redundant Information Filters</title><categories>cs.IR cs.AI</categories><acm-class>H.3.3</acm-class><journal-ref>ACM Transactions on Information Systems, 14, 2 (April 1996),
  138-174</journal-ref><abstract>  We consider information retrieval when the data, for instance multimedia, is
coputationally expensive to fetch. Our approach uses &quot;information filters&quot; to
considerably narrow the universe of possiblities before retrieval. We are
especially interested in redundant information filters that save time over more
general but more costly filters. Efficient retrieval requires that decision
must be made about the necessity, order, and concurrent processing of proposed
filters (an &quot;execution plan&quot;). We develop simple polynomial-time local criteria
for optimal execution plans, and show that most forms of concurrency are
suboptimal with information filters. Although the general problem of finding an
optimal execution plan is likely exponential in the number of filters, we show
experimentally that our local optimality criteria, used in a polynomial-time
algorithm, nearly always find the global optimum with 15 filters or less, a
sufficient number of filters for most applications. Our methods do not require
special hardware and avoid the high processor idleness that is characteristic
of massive parallelism solutions to this problem. We apply our ideas to an
important application, information retrieval of cpationed data using
natural-language understanding, a problem for which the natural-language
processing can be the bottleneck if not implemented well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809122</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809122</id><created>1998-09-29</created><authors><author><keyname>Domingo</keyname><forenames>Carlos</forenames></author><author><keyname>Gavalda</keyname><forenames>Ricard</forenames></author><author><keyname>Watanabe</keyname><forenames>Osamu</forenames></author></authors><title>Practical algorithms for on-line sampling</title><categories>cs.LG cs.DS</categories><comments>To appear in the Proc. of Discovery Science '98, Dec. 1998</comments><report-no>C-123</report-no><acm-class>I.2.6;H.2.8</acm-class><abstract>  One of the core applications of machine learning to knowledge discovery
consists on building a function (a hypothesis) from a given amount of data (for
instance a decision tree or a neural network) such that we can use it
afterwards to predict new instances of the data. In this paper, we focus on a
particular situation where we assume that the hypothesis we want to use for
prediction is very simple, and thus, the hypotheses class is of feasible size.
We study the problem of how to determine which of the hypotheses in the class
is almost the best one. We present two on-line sampling algorithms for
selecting hypotheses, give theoretical bounds on the number of necessary
examples, and analize them exprimentally. We compare them with the simple batch
sampling approach commonly used and show that in most of the situations our
algorithms use much fewer number of examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809123</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809123</id><created>1998-09-30</created><authors><author><keyname>Domingo</keyname><forenames>Carlos</forenames></author><author><keyname>Watanabe</keyname><forenames>Osamu</forenames></author><author><keyname>Yamazaki</keyname><forenames>Tadashi</forenames></author></authors><title>A role of constraint in self-organization</title><categories>cs.NE cs.CG</categories><comments>To appear in the Proc. RANDOM'98, Oct. 1998</comments><report-no>C-124</report-no><acm-class>I.2.6;J.3</acm-class><abstract>  In this paper we introduce a neural network model of self-organization. This
model uses a variation of Hebb rule for updating its synaptic weights, and
surely converges to the equilibrium status. The key point of the convergence is
the update rule that constrains the total synaptic weight and this seems to
make the model stable. We investigate the role of the constraint and show that
it is the constraint that makes the model stable. For analyzing this setting,
we propose a simple probabilistic game that models the neural network and the
self-organization process. Then, we investigate the characteristics of this
game, namely, the probability that the game becomes stable and the number of
the steps it takes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809124</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809124</id><created>1998-09-30</created><authors><author><keyname>Hoagland</keyname><forenames>James A.</forenames></author><author><keyname>Pandey</keyname><forenames>Raju</forenames></author><author><keyname>Levitt</keyname><forenames>Karl N.</forenames></author></authors><title>Security Policy Specification Using a Graphical Approach</title><categories>cs.CR</categories><comments>28 pages, 22 figures, in color (but color is not essential for
  viewing); UC Davis CS department technical report (July 22, 1998)</comments><report-no>CSE-98-3</report-no><acm-class>c.2.0; D.4.6</acm-class><abstract>  A security policy states the acceptable actions of an information system, as
the actions bear on security. There is a pressing need for organizations to
declare their security policies, even informal statements would be better than
the current practice. But, formal policy statements are preferable to support
(1) reasoning about policies, e.g., for consistency and completeness, (2)
automated enforcement of the policy, e.g., using wrappers around legacy systems
or after the fact with an intrusion detection system, and (3) other formal
manipulation of policies, e.g., the composition of policies. We present LaSCO,
the Language for Security Constraints on Objects, in which a policy consists of
two parts: the domain (assumptions about the system) and the requirement (what
is allowed assuming the domain is satisfied). Thus policies defined in LaSCO
have the appearance of conditional access control statements. LaSCO policies
are specified as expressions in logic and as directed graphs, giving a visual
view of policy. LaSCO has a simple semantics in first order logic (which we
provide), thus permitting policies we write, even for complex policies, to be
very perspicuous. LaSCO has syntax to express many of the situations we have
found to be useful on policies or, more interesting, the composition of
policies. LaSCO has an object-oriented structure, permitting it to be useful to
describe policies on the objects and methods of an application written in an
object-oriented language, in addition to the traditional policies on operating
system objects. A LaSCO specification can be automatically translated into
executable code that checks an invocation of a program with respect to a
policy. The implementation of LaSCO is in Java, and generates wrappers to check
Java programs with respect to a policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9809125</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9809125</id><created>1998-09-14</created><authors><author><keyname>Manthey</keyname><forenames>Michael</forenames></author></authors><title>Distributed Computation, the Twisted Isomorphism, and Auto-Poiesis</title><categories>cs.DC</categories><comments>26 pages, 4 figures. Originally submitted to the neuro-sys archive
  which was never publicly announced (was 9809001)</comments><acm-class>F.1</acm-class><journal-ref>CASYS'97 First International Conference on Computing Anticipatory
  Systems, Liege (Belgium), August 11-15, 1997. D. Dubois, Ed (Dept.of
  Mathematics, University of Liege)</journal-ref><abstract>  This paper presents a synchronization-based, multi-process computational
model of anticipatory systems called the Phase Web. It describes a
self-organizing paradigm that explicitly recognizes and exploits the existence
of a boundary between inside and outside, accepts and exploits intentionality,
and uses explicit self-reference to describe eg. auto-poiesis. The model
explicitly connects computation to a discrete Clifford algebraic formalization
that is in turn extended into homology and co-homology, wherein the recursive
nature of objects and boundaries becomes apparent and itself subject to
hierarchical recursion. Topsy, a computer program embodying the Phase Web, is
available at www.cs.auc.dk/topsy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810001</id><created>1998-09-30</created><authors><author><keyname>Lu</keyname><forenames>Lunjin</forenames></author><author><keyname>Cleary</keyname><forenames>John G.</forenames></author></authors><title>On Dart-Zobel Algorithm for Testing Regular Type Inclusion</title><categories>cs.LO cs.PL</categories><comments>16 pages</comments><acm-class>F.3.2</acm-class><abstract>  This paper answers open questions about the correctness and the completeness
of Dart-Zobel algorithm for testing the inclusion relation between two regular
types. We show that the algorithm is incorrect for regular types. We also prove
that the algorithm is complete for regular types as well as correct for tuple
distributive regular types. Also presented is a simplified version of
Dart-Zobel algorithm for tuple distributive regular types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810002</id><created>1998-10-02</created><authors><author><keyname>Weaver</keyname><forenames>Lex</forenames></author><author><keyname>Johnson</keyname><forenames>Chris</forenames></author></authors><title>Pre-fetching tree-structured data in distributed memory</title><categories>cs.DC cs.DB</categories><comments>8 pages; added PDF version</comments><acm-class>H.3.4</acm-class><journal-ref>Proceedings of the Third Fujitsu Parallel Computing Workshop,
  pages P1-J-1 to P1-J-8, Kawasaki, Japan, November 1994. Fujitsu Laboratories
  Ltd</journal-ref><abstract>  A distributed heap storage manager has been implemented on the Fujitsu AP1000
multicomputer. The performance of various pre-fetching strategies is
experimentally compared. Subjective programming benefits and objective
performance benefits of up to 10% in pre-fetching are found for certain
applications, but not for all. The performance benefits of pre-fetching depend
on the specific data structure and access patterns. We suggest that control of
pre-fetching strategy be dynamically under the control of the application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810003</id><created>1998-10-01</created><authors><author><keyname>Siebert</keyname><forenames>Andreas</forenames></author></authors><title>A Linear Shift Invariant Multiscale Transform</title><categories>cs.CV</categories><comments>4 pages, 5 figures</comments><acm-class>I.4.3</acm-class><journal-ref>Proceedings 1998 International Conference on Image Processing,
  Chicago, 4-7 October 1998</journal-ref><abstract>  This paper presents a multiscale decomposition algorithm. Unlike standard
wavelet transforms, the proposed operator is both linear and shift invariant.
The central idea is to obtain shift invariance by averaging the aligned wavelet
transform projections over all circular shifts of the signal. It is shown how
the same transform can be obtained by a linear filter bank.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810004</id><created>1998-10-03</created><authors><author><keyname>Childers</keyname><forenames>Bruce R.</forenames></author><author><keyname>Cohoon</keyname><forenames>James P.</forenames></author><author><keyname>Davidson</keyname><forenames>Jack W.</forenames></author><author><keyname>Valle</keyname><forenames>Peter</forenames></author></authors><title>The Design of EzWindows: A Graphics API for an Introductory Programming
  Course</title><categories>cs.CY cs.GR</categories><comments>5 pages, 5 figures, conference submission</comments><acm-class>K.3.1;K.3.2;I.3.4</acm-class><abstract>  Teaching object-oriented programming in an introductory programming course
poses considerable challenges to the instructor. An often advocated approach to
meeting this challenge is the use of a simple, object-oriented graphics
library. We have developed a simple, portable graphics library for teaching
object-oriented programming using C++. The library, EzWindows, allows beginning
programmers to design and write programs that use the graphical display found
on all modern desktop computers. In addition to providing simple graphical
objects such as windows, geometric shapes, and bitmaps, EzWindows provides
facilities for introducing event-based programming using the mouse and timers.
EzWindows has proven to be extremely popular; it is currently in use at over
200 universities, colleges, and high schools. This paper describes the
rationale for EzWindows and its high-level design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810005</id><created>1998-10-05</created><authors><author><keyname>Sandholm</keyname><forenames>Tuomas</forenames></author><author><keyname>Larson</keyname><forenames>Kate</forenames></author><author><keyname>Andersson</keyname><forenames>Martin</forenames></author><author><keyname>Shehory</keyname><forenames>Onn</forenames></author><author><keyname>Tohme</keyname><forenames>Fernando</forenames></author></authors><title>Anytime Coalition Structure Generation with Worst Case Guarantees</title><categories>cs.MA cs.AI</categories><acm-class>I.2.11</acm-class><journal-ref>Proceedings of the National Conference on Artificial Intelligence,
  pp 46-53, Madison, WI, July 1998</journal-ref><abstract>  Coalition formation is a key topic in multiagent systems. One would prefer a
coalition structure that maximizes the sum of the values of the coalitions, but
often the number of coalition structures is too large to allow exhaustive
search for the optimal one. But then, can the coalition structure found via a
partial search be guaranteed to be within a bound from optimum? We show that
none of the previous coalition structure generation algorithms can establish
any bound because they search fewer nodes than a threshold that we show
necessary for establishing a bound. We present an algorithm that establishes a
tight bound within this minimal amount of search, and show that any other
algorithm would have to search strictly more. The fraction of nodes needed to
be searched approaches zero as the number of agents grows. If additional time
remains, our anytime algorithm searches further, and establishes a
progressively lower tight bound. Surprisingly, just searching one more node
drops the bound in half. As desired, our algorithm lowers the bound rapidly
early on, and exhibits diminishing returns to computation. It also drastically
outperforms its obvious contenders. Finally, we show how to distribute the
desired search across self-interested manipulative agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810006</id><created>1998-10-05</created><authors><author><keyname>McKeown</keyname><forenames>Nick</forenames><affiliation>Stanford University</affiliation></author><author><keyname>Izzard</keyname><forenames>Martin</forenames><affiliation>Texas Instruments</affiliation></author><author><keyname>Mekkittikul</keyname><forenames>Adisak</forenames><affiliation>Stanford University</affiliation></author><author><keyname>Ellersick</keyname><forenames>Bill</forenames><affiliation>Stanford University</affiliation></author><author><keyname>Horowitz</keyname><forenames>Mark</forenames><affiliation>Stanford University</affiliation></author></authors><title>The Tiny Tera: A Packet Switch Core</title><categories>cs.NI</categories><comments>13 pages, 10 figures</comments><acm-class>C.2.1</acm-class><journal-ref>Hot Interconnects V, Stanford University, August 1996; IEEE Micro
  Jan/Feb 1997, pp 26-33</journal-ref><abstract>  The objective is to design and build a small, high-bandwidth switch.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810007</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810007</id><created>1998-10-07</created><updated>1998-10-08</updated><authors><author><keyname>Devillers</keyname><forenames>Olivier</forenames></author></authors><title>Randomization yields simple O(n log star n) algorithms for difficult
  Omega(n) problems</title><categories>cs.CG</categories><comments>16 pages, 6 figures, Proc. 3rd Canad. Conf. Comput. Geom., 1991</comments><report-no>Rapport de recherche 1412, INRIA, 1991</report-no><acm-class>F.2.2</acm-class><journal-ref>Internat. J. Comput. Geom. Appl., 2(1):621--635, 1992</journal-ref><abstract>  We use here the results on the influence graph by Boissonnat et al. to adapt
them for particular cases where additional information is available. In some
cases, it is possible to improve the expected randomized complexity of
algorithms from O(n log n) to O(n log star n).
  This technique applies in the following applications: triangulation of a
simple polygon, skeleton of a simple polygon, Delaunay triangulation of points
knowing the EMST (euclidean minimum spanning tree).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810008</id><created>1998-10-07</created><authors><author><keyname>van Glabbeek</keyname><forenames>R. J.</forenames><affiliation>Stanford</affiliation></author></authors><title>Axiomatizing Flat Iteration</title><categories>cs.LO</categories><comments>15 pages. LaTeX 2.09. Filename: flat.tex.gz. On A4 paper print with:
  dvips -t a4 -O -2.15cm,-2.22cm -x 1225 flat. For US letter with: dvips -t
  letter -O -0.73in,-1.27in -x 1225 flat. More info at
  http://theory.stanford.edu/~rvg/abstracts.html#38</comments><report-no>STAN-CS-TN-97-57</report-no><acm-class>D.3.1; F.1.2; F.3.2</acm-class><journal-ref>Proc. CONCUR '97, Warsaw, Poland, July 1997 (A. Mazurkiewicz and
  J. Winkowski, eds.), LNCS 1243, Springer-Verlag, 1997, pp. 228-242</journal-ref><abstract>  Flat iteration is a variation on the original binary version of the Kleene
star operation P*Q, obtained by restricting the first argument to be a sum of
atomic actions. It generalizes prefix iteration, in which the first argument is
a single action. Complete finite equational axiomatizations are given for five
notions of bisimulation congruence over basic CCS with flat iteration, viz.
strong congruence, branching congruence, eta-congruence, delay congruence and
weak congruence. Such axiomatizations were already known for prefix iteration
and are known not to exist for general iteration. The use of flat iteration has
two main advantages over prefix iteration: 1.The current axiomatizations
generalize to full CCS, whereas the prefix iteration approach does not allow an
elimination theorem for an asynchronous parallel composition operator. 2.The
greater expressiveness of flat iteration allows for much shorter completeness
proofs.
  In the setting of prefix iteration, the most convenient way to obtain the
completeness theorems for eta-, delay, and weak congruence was by reduction to
the completeness theorem for branching congruence. In the case of weak
congruence this turned out to be much simpler than the only direct proof found.
In the setting of flat iteration on the other hand, the completeness theorems
for delay and weak (but not eta-) congruence can equally well be obtained by
reduction to the one for strong congruence, without using branching congruence
as an intermediate step. Moreover, the completeness results for prefix
iteration can be retrieved from those for flat iteration, thus obtaining a
second indirect approach for proving completeness for delay and weak congruence
in the setting of prefix iteration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810009</id><created>1998-10-08</created><authors><author><keyname>Pizzonia</keyname><forenames>Maurizio</forenames></author><author><keyname>Di Battista</keyname><forenames>Giuseppe</forenames></author></authors><title>Object-Oriented Design of Graph Oriented Data Structures</title><categories>cs.SE cs.CG cs.DS</categories><comments>10 pages, 9 figures, code examples, ALENEX (accepted)</comments><acm-class>D.2.3; D.2.11; D.2.13; E.1</acm-class><abstract>  Applied research in graph algorithms and combinatorial structures needs
comprehensive and versatile software libraries. However, the design and the
implementation of flexible libraries are challenging activities. Among the
other problems involved in such a difficult field, a very special role is
played by graph classification issues.
  We propose new techniques devised to help the designer and the programmer in
the development activities. Such techniques are especially suited for dealing
with graph classification problems and rely on an extension of the usual
object-oriented paradigm. In order to support the usage of our approach, we
devised an extension of the C++ programming language and implemented the
corresponding pre-compiler.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810010</id><created>1998-10-09</created><updated>1998-11-02</updated><authors><author><keyname>Veldhuizen</keyname><forenames>Todd L.</forenames></author></authors><title>C++ Templates as Partial Evaluation</title><categories>cs.PL cs.PF</categories><comments>13 pages</comments><report-no>IUCS 519</report-no><acm-class>F.3.2; D.3.3; D.3.4</acm-class><abstract>  This paper explores the relationship between C++ templates and partial
evaluation. Templates were designed to support generic programming, but
unintentionally provided the ability to perform compile-time computations and
code generation. These features are completely accidental, and as a result
their syntax is awkward. By recasting these features in terms of partial
evaluation, a much simpler syntax can be achieved. C++ may be regarded as a
two-level language in which types are first-class values. Template
instantiation resembles an offline partial evaluator. This paper describes
preliminary work toward a single mechanism based on Partial Evaluation which
unifies generic programming, compile-time computation and code generation. The
language Catat is introduced to illustrate these ideas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810011</id><created>1998-10-12</created><authors><author><keyname>Hardt</keyname><forenames>Wolfram</forenames></author><author><keyname>Kleinjohann</keyname><forenames>Bernd</forenames></author></authors><title>Flysig: Dataflow Oriented Delay-Insensitive Processor for Rapid
  Prototyping of Signal Processing</title><categories>cs.AR</categories><comments>6 pages, 10 figures</comments><acm-class>C.1.3; C.3</acm-class><journal-ref>Nineth IEEE International Workshop on Rapid System Prototyping
  1998, Belgium, IEEE Computer Society Press</journal-ref><abstract>  As the one-chip integration of HW-modules designed by different companies
becomes more and more popular reliability of a HW-design and evaluation of the
timing behavior during the prototype stage are absolutely necessary. One way to
guarantee reliability is the use of robust design styles, e.g.,
delay-insensitivity. For early timing evaluation two aspects must be
considered: a) The timing needs to be proportional to technology variations and
b) the implemented architecture should be identical for prototype and target.
The first can be met also by delay-insensitive implementation. The latter one
is the key point. A unified architecture is needed for prototyping as well as
implementation. Our new approach to rapid prototyping of signal processing
tasks is based on a configurable, delay-insensitive implemented processor
called Flysig. In essence, the Flysig processor can be understood as a complex
FPGA where the CLBs are substituted by bit-serial operators. In this paper the
general concept is detailed and first experimental results are given for
demonstration of the main advantages: delay-insensitive design style, direct
correspondence between prototyping and target architecture, high performance
and reasonable shortening of the design cycle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810012</identifier>
 <datestamp>2015-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810012</id><created>1998-10-13</created><updated>2001-07-08</updated><authors><author><keyname>Roberts</keyname><forenames>Mark D.</forenames></author></authors><title>Ultrametric Distance in Syntax</title><categories>cs.CL q-bio.NC</categories><comments>28 pages, 55508 bytes, 16 eps diagrams, 39 references, some small
  changes from the previous version, matrices reset, background to this work
  can be found at:
  http://cosmology.mth.uct.ac.za/~roberts/pastresearch/ultrametric.html</comments><acm-class>I.2.7;J.4;I.2.6</acm-class><journal-ref>Prague Bulletin of Mathematical Linguistics 103 (2015) 111-130</journal-ref><abstract>  Phrase structure trees have a hierarchical structure. In many subjects, most
notably in Taxonomy such tree structures have been studied using ultrametrics.
Here syntactical hierarchical phrase trees are subject to a similar analysis,
which is much siompler as the branching structure is more readily discernible
and switched. The occurence of hierarchical structure elsewhere in linguistics
is mentioned. The phrase tree can be represented by a matrix and the elements
of the matrix can be represented by triangles. The height at which branching
occurs is not prescribed in previous syntatic models, but it is by using the
ultrametric matrix. The ambiguity of which branching height to choose is
resolved by postulating that branching occurs at the lowest height available.
An ultrametric produces a measure of the complexity of sentences: presumably
the complexity of sentence increases as a language is aquired so that this can
be tested. A All ultrametric triangles are equilateral or isocles, here it is
shown that X structur implies that there are no equilateral triangles.
Restricting attention to simple syntax a minium ultrametric distance between
lexical categories is calculatex. This ultrametric distance is shown to be
different than the matrix obtasined from feaures. It is shown that the
definition of c-commabnd can be replaced by an equivalent ultrametric
definition. The new definition invokes a minimum distance between nodes and
this is more aesthetically satisfing than previouv varieties of definitions.
  From the new definition of c-command follows a new definition of government.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810013</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810013</id><created>1998-10-13</created><authors><author><keyname>Hanson</keyname><forenames>David R.</forenames></author></authors><title>Early Experience with ASDL in lcc</title><categories>cs.PL cs.SE</categories><comments>16 pages, 12 figures</comments><report-no>Microsoft Research MSR-TR-98-50</report-no><acm-class>D.3.4</acm-class><journal-ref>Software--Practice &amp; Experience, vol. 29, no. 5, 417-435, Apr.
  1999</journal-ref><abstract>  The Abstract Syntax Description Language (ASDL) is a language for specifying
the tree data structures often found in compiler intermediate representations.
The ASDL generator reads an ASDL specification and generates code to construct,
read, and write instances of the trees specified. Using ASDL permits a compiler
to be decomposed into semi-independent components that communicate by reading
and writing trees. Each component can be written in a different language,
because the ASDL generator can emit code in several languages, and the files
written by ASDL-generated code are machine- and language-independent. ASDL is
part of the National Compiler Infrastructure project, which seeks to reduce
dramatically the overhead of computer systems research by making it much easier
to build high-quality compilers. This paper describes dividing lcc, a widely
used retargetable C compiler, into two components that communicate via trees
defined in ASDL. As the first use of ASDL in a `real' compiler, this experience
reveals much about the effort required to retrofit an existing compiler to use
ASDL, the overheads involved, and the strengths and weaknesses of ASDL itself
and, secondarily, of lcc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810014</id><created>1998-10-13</created><authors><author><keyname>Klavans</keyname><forenames>Judith L.</forenames><affiliation>Columbia University</affiliation></author><author><keyname>McKeown</keyname><forenames>Kathleen R.</forenames><affiliation>Columbia University</affiliation></author><author><keyname>Kan</keyname><forenames>Min-Yen</forenames><affiliation>Columbia University</affiliation></author><author><keyname>Lee</keyname><forenames>Susan</forenames><affiliation>University of California at Berkeley</affiliation></author></authors><title>Resources for Evaluation of Summarization Techniques</title><categories>cs.CL</categories><comments>LaTeX source, 5 pages, US Letter, uses lrec98.sty</comments><acm-class>I.2.7</acm-class><journal-ref>in Proc. of First International Conference on Language Resources
  and Evaluation, Rubio, Gallardo, Castro, and Tejada (eds.), Granada, Spain,
  1998</journal-ref><abstract>  We report on two corpora to be used in the evaluation of component systems
for the tasks of (1) linear segmentation of text and (2) summary-directed
sentence extraction. We present characteristics of the corpora, methods used in
the collection of user judgments, and an overview of the application of the
corpora to evaluating the component system. Finally, we discuss the problems
and issues with construction of the test set which apply broadly to the
construction of evaluation resources for language technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810015</id><created>1998-10-13</created><authors><author><keyname>Satta</keyname><forenames>Giorgio</forenames><affiliation>Universita di Padova</affiliation></author><author><keyname>Schuler</keyname><forenames>William</forenames><affiliation>University of Pennsylvania</affiliation></author></authors><title>Restrictions on Tree Adjoining Languages</title><categories>cs.CL</categories><comments>7 pages LaTeX + 5 eps figures</comments><acm-class>I.2.7</acm-class><journal-ref>Proceedings of COLING-ACL'98</journal-ref><abstract>  Several methods are known for parsing languages generated by Tree Adjoining
Grammars (TAGs) in O(n^6) worst case running time. In this paper we investigate
which restrictions on TAGs and TAG derivations are needed in order to lower
this O(n^6) time complexity, without introducing large runtime constants, and
without losing any of the generative power needed to capture the syntactic
constructions in natural language that can be handled by unrestricted TAGs. In
particular, we describe an algorithm for parsing a strict subclass of TAG in
O(n^5), and attempt to show that this subclass retains enough generative power
to make it useful in the general case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810016</id><created>1998-10-16</created><authors><author><keyname>Muslea</keyname><forenames>Ion</forenames></author></authors><title>SYNERGY: A Linear Planner Based on Genetic Programming</title><categories>cs.AI</categories><comments>13 pages, European Conference on Planning 1997</comments><acm-class>I.2.8</acm-class><journal-ref>&quot;Recent Advances in AI Planning&quot; (Sam Steel &amp; Rachid Alami eds.),
  p. 312-325, Springer 1997 (LNAI 1348)</journal-ref><abstract>  In this paper we describe SYNERGY, which is a highly parallelizable, linear
planning system that is based on the genetic programming paradigm. Rather than
reasoning about the world it is planning for, SYNERGY uses artificial
selection, recombination and fitness measure to generate linear plans that
solve conjunctive goals. We ran SYNERGY on several domains (e.g., the briefcase
problem and a few variants of the robot navigation problem), and the
experimental results show that our planner is capable of handling problem
instances that are one to two orders of magnitude larger than the ones solved
by UCPOP. In order to facilitate the search reduction and to enhance the
expressive power of SYNERGY, we also propose two major extensions to our
planning system: a formalism for using hierarchical planning operators, and a
framework for planning in dynamic environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810017</id><created>1998-10-19</created><authors><author><keyname>Adler</keyname><forenames>Stephen L.</forenames></author></authors><title>General Theory of Image Normalization</title><categories>cs.CV</categories><comments>33 pages, plain tex, no figures</comments><report-no>IASSNS-HEP-95/89</report-no><acm-class>I.2.10, I.4.7, I.4.8</acm-class><abstract>  We give a systematic, abstract formulation of the image normalization method
as applied to a general group of image transformations, and then illustrate the
abstract analysis by applying it to the hierarchy of viewing transformations of
a planar object.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810018</id><created>1998-10-20</created><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author></authors><title>A Proof Theoretic View of Constraint Programming</title><categories>cs.AI cs.PL</categories><comments>25 pages</comments><acm-class>F.4.1;I.2.3;D.1.0</acm-class><journal-ref>Fundamenta Informaticae 34(1998), pp. 295-321</journal-ref><abstract>  We provide here a proof theoretic account of constraint programming that
attempts to capture the essential ingredients of this programming style. We
exemplify it by presenting proof rules for linear constraints over interval
domains, and illustrate their use by analyzing the constraint propagation
process for the {\tt SEND + MORE = MONEY} puzzle. We also show how this
approach allows one to build new constraint solvers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810019</id><created>1998-10-21</created><authors><author><keyname>Strom</keyname><forenames>Robert</forenames></author><author><keyname>Banavar</keyname><forenames>Guruduth</forenames></author><author><keyname>Chandra</keyname><forenames>Tushar</forenames></author><author><keyname>Kaplan</keyname><forenames>Marc</forenames></author><author><keyname>Miller</keyname><forenames>Kevan</forenames></author><author><keyname>Mukherjee</keyname><forenames>Bodhi</forenames></author><author><keyname>Sturman</keyname><forenames>Daniel</forenames></author><author><keyname>Ward</keyname><forenames>Michael</forenames></author></authors><title>Gryphon: An Information Flow Based Approach to Message Brokering</title><categories>cs.DC</categories><comments>Two page extended abstract</comments><acm-class>C.2.4</acm-class><abstract>  Gryphon is a distributed computing paradigm for message brokering, which is
the transferring of information in the form of streams of events from
information providers to information consumers. This extended abstract outlines
the major problems in message brokering and Gryphon's approach to solving them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810020</id><created>1998-10-22</created><authors><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>Computational Geometry Column 33</title><categories>cs.CG cs.AI cs.GR</categories><acm-class>F.2.2;I.3</acm-class><journal-ref>Internat. J. Comput. Geom. Appl., 8(3) 381-384, 1998. Also in
  SIGACT News, 29(2) (Issue 107) 14-16, 1998</journal-ref><abstract>  Several recent SIGGRAPH papers on surface simplification are described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810021</id><created>1998-10-22</created><authors><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>Computational Geometry Column 32</title><categories>cs.CG cs.GR</categories><acm-class>F.2.2</acm-class><journal-ref>Internat. J. Comput. Geom. Appl.,7(5) 509-513, 1997. Also in
  SIGACT News, 29(2) (Issue 107) 14-16, 1998</journal-ref><abstract>  The proof of Dey's new k-set bound is illustrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810022</id><created>1998-10-26</created><authors><author><keyname>Huggins</keyname><forenames>James K.</forenames></author></authors><title>Broy-Lamport Specification Problem: A Gurevich Abstract State Machine
  Solution</title><categories>cs.SE</categories><report-no>University of Michigan EECS Department Technical Report
  CSE-TR-320-96</report-no><acm-class>D.2.4</acm-class><abstract>  We apply the Gurevich Abstract State Machine methodology to a benchmark
specification problem of Broy and Lamport.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810023</id><created>1998-10-26</created><authors><author><keyname>Gurevich</keyname><forenames>Yuri</forenames></author><author><keyname>Huggins</keyname><forenames>James K.</forenames></author></authors><title>Equivalence is in the Eye of the Beholder</title><categories>cs.SE</categories><comments>See also the ASM web site at http://www.eecs.umich.edu/gasm/</comments><acm-class>D.2.4</acm-class><journal-ref>Theoretical Computer Science (179) 1-2 (1997), 353-380</journal-ref><abstract>  In a recent provocative paper, Lamport points out &quot;the insubstantiality of
processes&quot; by proving the equivalence of two different decompositions of the
same intuitive algorithm by means of temporal formulas. We point out that the
correct equivalence of algorithms is itself in the eye of the beholder. We
discuss a number of related issues and, in particular, whether algorithms can
be proved equivalent directly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810024</id><created>1998-10-26</created><authors><author><keyname>Gurevich</keyname><forenames>Yuri</forenames></author><author><keyname>Huggins</keyname><forenames>James K.</forenames></author></authors><title>Evolving Algebras and Partial Evaluation</title><categories>cs.SE</categories><comments>See also the web site at http://www.eecs.umich.edu/gasm/</comments><acm-class>D.2.4</acm-class><journal-ref>In IFIP 13th World Computer Congress 1994, Volume I: Technology
  and Foundations, eds. B. Pehrson and I. Simon, North-Holland, Amsterdam,
  587-592</journal-ref><abstract>  We describe an automated partial evaluator for evolving algebras implemented
at the University of Michigan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810025</id><created>1998-10-26</created><authors><author><keyname>Huggins</keyname><forenames>James K.</forenames></author></authors><title>An Offline Partial Evaluator for Evolving Algebras</title><categories>cs.SE</categories><comments>See also the web site at http://www.eecs.umich.edu/gasm/</comments><report-no>University of Michigan EECS Department Technical Report CSE-TR-229-95</report-no><acm-class>D.2.4</acm-class><abstract>  We describe the architecture of an evolving algebra partial evaluator, a
program which specializes an evolving algebra with respect to a portion of its
input. We discuss the particular analysis, specialization, and optimization
techniques used and show an example of its use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810026</id><created>1998-10-26</created><authors><author><keyname>Gurevich</keyname><forenames>Yuri</forenames></author><author><keyname>Huggins</keyname><forenames>James K.</forenames></author></authors><title>The Railroad Crossing Problem: An Experiment with Instantaneous Actions
  and Immediate Reactions</title><categories>cs.SE</categories><comments>See also the web site at http://www.eecs.umich.edu/gasm/</comments><acm-class>D.2.4</acm-class><journal-ref>Selected papers from CSL'95, ed. H.K. Buening, Springer Lecture
  Notes in Computer Science 1092, 1996, 266--290</journal-ref><abstract>  We give an evolving algebra solution for the well-known railroad crossing
problem and use the occasion to experiment with agents that perform
instantaneous actions in continuous time and in particular with agents that
fire at the moment they are enabled.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9810027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9810027</id><created>1998-10-29</created><authors><author><keyname>Kirby</keyname><forenames>G. N. C.</forenames></author><author><keyname>Morrison</keyname><forenames>R.</forenames></author><author><keyname>Stemple</keyname><forenames>D. W.</forenames></author></authors><title>Linguistic Reflection in Java</title><categories>cs.PL</categories><comments>25 pages. Source code for examples at
  http://www-ppg.dcs.st-and.ac.uk/Java/ReflectionExample/ Dynamic compilation
  package at http://www-ppg.dcs.st-and.ac.uk/Java/DynamicCompilation/</comments><acm-class>D.1.0</acm-class><journal-ref>Software - Practice &amp; Experience 28, 10 (1998) pp 1045-1077</journal-ref><abstract>  Reflective systems allow their own structures to be altered from within. Here
we are concerned with a style of reflection, called linguistic reflection,
which is the ability of a running program to generate new program fragments and
to integrate these into its own execution. In particular we describe how this
kind of reflection may be provided in the compiler-based, strongly typed
object-oriented programming language Java. The advantages of the programming
technique include attaining high levels of genericity and accommodating system
evolution. These advantages are illustrated by an example taken from persistent
programming which shows how linguistic reflection allows functionality (program
code) to be generated on demand (Just-In-Time) from a generic specification and
integrated into the evolving running program. The technique is evaluated
against alternative implementation approaches with respect to efficiency,
safety and ease of use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811001</id><created>1998-10-31</created><authors><author><keyname>Lu</keyname><forenames>Lunjin</forenames><affiliation>University of Waikato</affiliation></author></authors><title>A Polymorphic Groundness Analysis of Logic Programs</title><categories>cs.PL</categories><comments>30 pages</comments><acm-class>F.3.2;D.3.2</acm-class><abstract>  A polymorphic analysis is an analysis whose input and output contain
parameters which serve as placeholders for information that is unknown before
analysis but provided after analysis. In this paper, we present a polymorphic
groundness analysis that infers parameterised groundness descriptions of the
variables of interest at a program point. The polymorphic groundness analysis
is designed by replacing two primitive operators used in a monomorphic
groundness analysis and is shown to be as precise as the monomorphic groundness
analysis for any possible values for mode parameters. Experimental results of a
prototype implementation of the polymorphic groundness analysis are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811002</id><created>1998-10-31</created><authors><author><keyname>Tsarev</keyname><forenames>Serguei P.</forenames></author></authors><title>Factorization of linear partial differential operators and Darboux
  integrability of nonlinear PDEs</title><categories>cs.SC nlin.SI solv-int</categories><comments>LaTeX 2.09, acmconf.sty (included in the tar file), 8 pages.
  Presented at the Poster session of ISSAC'98 (Rostock, Germany)</comments><acm-class>I.1</acm-class><abstract>  Using a new definition of generalized divisors we prove that the lattice of
such divisors for a given linear partial differential operator is modular and
obtain analogues of the well-known theorems of the Loewy-Ore theory of
factorization of linear ordinary differential operators. Possible applications
to factorized Groebner bases computations in the commutative and
non-commutative cases are discussed, an application to finding criterions of
Darboux integrability of nonlinear PDEs is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811003</id><created>1998-10-31</created><authors><author><keyname>Golding</keyname><forenames>Andrew R.</forenames></author><author><keyname>Roth</keyname><forenames>Dan</forenames></author></authors><title>A Winnow-Based Approach to Context-Sensitive Spelling Correction</title><categories>cs.LG cs.CL</categories><comments>To appear in Machine Learning, Special Issue on Natural Language
  Learning, 1999. 25 pages</comments><acm-class>I.2.6; I.2.7</acm-class><abstract>  A large class of machine-learning problems in natural language require the
characterization of linguistic context. Two characteristic properties of such
problems are that their feature space is of very high dimensionality, and their
target concepts refer to only a small subset of the features in the space.
Under such conditions, multiplicative weight-update algorithms such as Winnow
have been shown to have exceptionally good theoretical properties. We present
an algorithm combining variants of Winnow and weighted-majority voting, and
apply it to a problem in the aforementioned class: context-sensitive spelling
correction. This is the task of fixing spelling errors that happen to result in
valid words, such as substituting &quot;to&quot; for &quot;too&quot;, &quot;casual&quot; for &quot;causal&quot;, etc.
We evaluate our algorithm, WinSpell, by comparing it against BaySpell, a
statistics-based method representing the state of the art for this task. We
find: (1) When run with a full (unpruned) set of features, WinSpell achieves
accuracies significantly higher than BaySpell was able to achieve in either the
pruned or unpruned condition; (2) When compared with other systems in the
literature, WinSpell exhibits the highest performance; (3) The primary reason
that WinSpell outperforms BaySpell is that WinSpell learns a better linear
separator; (4) When run on a test set drawn from a different corpus than the
training set was drawn from, WinSpell is better able than BaySpell to adapt,
using a strategy we will present that combines supervised learning on the
training set with unsupervised learning on the (noisy) test set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811004</id><created>1998-11-01</created><updated>2004-08-14</updated><authors><author><keyname>Roberts</keyname><forenames>Mark D.</forenames></author></authors><title>Does Meaning Evolve?</title><categories>cs.CL q-bio.PE</categories><comments>title changed, completely rewritten, new version 37 pages previous
  version 28 pages, to appear in Behaviour and Philosophy</comments><acm-class>I.2.7; J.4; I.2.0</acm-class><abstract>  A common method of making a theory more understandable, is by comparing it to
another theory which has been better developed. Radical interpretation is a
theory which attempts to explain how communication has meaning. Radical
interpretation is treated as another time-dependent theory and compared to the
time dependent theory of biological evolution. The main reason for doing this
is to find the nature of the time dependence; producing analogs between the two
theories is a necessary prerequisite to this and brings up many problems. Once
the nature of the time dependence is better known it might allow the underlying
mechanism to be uncovered. Several similarities and differences are uncovered,
there appear to be more differences than similarities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811005</id><created>1998-11-01</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Selman</keyname><forenames>Alan L.</forenames></author></authors><title>Writing and Editing Complexity Theory: Tales and Tools</title><categories>cs.GL cs.CC</categories><comments>11 pages. Will appear in the SIGACT News Complexity Theory Column</comments><acm-class>K.3.2; F.1.0</acm-class><abstract>  Each researcher should have a full shelf---physical or virtual---of books on
writing and editing prose. Though we make no claim to any special degree of
expertise, we recently edited a book of complexity theory surveys (Complexity
Theory Retrospective II, Springer-Verlag, 1997), and in doing so we were
brought into particularly close contact with the subject of this article, and
with a number of the excellent resources available to writers and editors. In
this article, we list some of these resources, and we also relate some of the
adventures we had as our book moved from concept to reality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811006</id><created>1998-11-02</created><authors><author><keyname>Mani</keyname><forenames>Inderjeet</forenames></author><author><keyname>Bloedorn</keyname><forenames>Eric</forenames></author></authors><title>Machine Learning of Generic and User-Focused Summarization</title><categories>cs.CL cs.LG</categories><comments>In Proceedings of the Fifteenth National Conference on AI (AAAI-98),
  p. 821-826</comments><acm-class>I.2.6; I.2.7</acm-class><abstract>  A key problem in text summarization is finding a salience function which
determines what information in the source should be included in the summary.
This paper describes the use of machine learning on a training corpus of
documents and their abstracts to discover salience functions which describe
what combination of features is optimal for a given summarization task. The
method addresses both &quot;generic&quot; and user-focused summaries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811007</id><created>1998-11-02</created><authors><author><keyname>Bass</keyname><forenames>L.</forenames></author><author><keyname>Chastek</keyname><forenames>G.</forenames></author><author><keyname>Clements</keyname><forenames>P.</forenames></author><author><keyname>Northrop</keyname><forenames>L.</forenames></author><author><keyname>Smith</keyname><forenames>D.</forenames></author><author><keyname>Withey</keyname><forenames>J.</forenames></author></authors><title>Second Product Line Practice Workshop Report</title><categories>cs.SE</categories><report-no>CMU/SEI-98-TR-015</report-no><acm-class>A.0</acm-class><abstract>  The second Software Engineering Institute Product Line Practice Workshop was
a hands-on meeting held in November 1997 to share industry practices in
software product lines and to explore the technical and non-technical issues
involved. This report synthesizes the workshop presentations and discussions,
which identified factors involved in product line practices and analyzed issues
in the areas of software engineering, technical management, and enterprise
management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811008</id><created>1998-11-02</created><authors><author><keyname>Edmonds</keyname><forenames>Philip</forenames><affiliation>University of Toronto</affiliation></author></authors><title>Translating near-synonyms: Possibilities and preferences in the
  interlingua</title><categories>cs.CL</categories><comments>8 pages, LaTeX2e, 1 eps figure, uses colacl.sty, epsfig.sty, avm.sty,
  times.sty</comments><acm-class>I.2.7; I.2.4</acm-class><journal-ref>Proceedings of the AMTA/SIG-IL Second Workshop on Interlinguas,
  October 1998</journal-ref><abstract>  This paper argues that an interlingual representation must explicitly
represent some parts of the meaning of a situation as possibilities (or
preferences), not as necessary or definite components of meaning (or
constraints). Possibilities enable the analysis and generation of nuance,
something required for faithful translation. Furthermore, the representation of
the meaning of words, especially of near-synonyms, is crucial, because it
specifies which nuances words can convey in which contexts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811009</id><created>1998-11-02</created><authors><author><keyname>Edmonds</keyname><forenames>Philip</forenames><affiliation>University of Toronto</affiliation></author></authors><title>Choosing the Word Most Typical in Context Using a Lexical Co-occurrence
  Network</title><categories>cs.CL</categories><comments>3 pages, LaTeX2e, 1 ps figure, uses mathptm.sty, colacl.sty,
  psfig.sty</comments><acm-class>I.2.7</acm-class><journal-ref>Proceedings of ACL-EACL '97, student session</journal-ref><abstract>  This paper presents a partial solution to a component of the problem of
lexical choice: choosing the synonym most typical, or expected, in context. We
apply a new statistical approach to representing the context of a word through
lexical co-occurrence networks. The implementation was trained and evaluated on
a large corpus, and results show that the inclusion of second-order
co-occurrence relations improves the performance of our implemented lexical
choice program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811010</id><created>1998-11-03</created><authors><author><keyname>Roth</keyname><forenames>Dan</forenames></author></authors><title>Learning to Resolve Natural Language Ambiguities: A Unified Approach</title><categories>cs.CL cs.LG</categories><acm-class>I.2.6 I.2.7</acm-class><journal-ref>Proceedings of of AAAI'98 pp. 806--813</journal-ref><abstract>  We analyze a few of the commonly used statistics based and machine learning
algorithms for natural language disambiguation tasks and observe that they can
be re-cast as learning linear separators in the feature space. Each of the
methods makes a priori assumptions, which it employs, given the data, when
searching for its hypothesis. Nevertheless, as we show, it searches a space
that is as rich as the space of all linear separators. We use this to build an
argument for a data driven approach which merely searches for a good linear
separator in the feature space, without further assumptions on the domain or a
specific problem.
  We present such an approach - a sparse network of linear separators,
utilizing the Winnow learning algorithm - and show how to use it in a variety
of ambiguity resolution problems. The learning approach presented is
attribute-efficient and, therefore, appropriate for domains having very large
number of attributes.
  In particular, we present an extensive experimental comparison of our
approach with other methods on several well studied lexical disambiguation
tasks such as context-sensitive spelling correction, prepositional phrase
attachment and part of speech tagging. In all cases we show that our approach
either outperforms other methods tried for these tasks or performs comparably
to the best.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811011</id><created>1998-11-04</created><authors><author><keyname>Ellison</keyname><forenames>Robert</forenames></author><author><keyname>Linger</keyname><forenames>Rick</forenames></author><author><keyname>Longstaff</keyname><forenames>Thomas</forenames></author><author><keyname>Mead</keyname><forenames>Nancy</forenames></author></authors><title>Case Study in Survivable Network System Analysis</title><categories>cs.SE</categories><report-no>CMU/SEI-98-TR-014</report-no><acm-class>C.2.3</acm-class><abstract>  This paper presents a method for analyzing the survivability of distributed
network systems and an example of its application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811012</id><created>1998-11-05</created><authors><author><keyname>Lu</keyname><forenames>Lunjin</forenames><affiliation>University of Waikato</affiliation></author></authors><title>Deriving Abstract Semantics for Forward Analysis of Normal Logic Programs</title><categories>cs.PL cs.LO</categories><comments>39 pages</comments><acm-class>F.3.2;D.3.2</acm-class><abstract>  The problem of forward abstract interpretation of {\em normal} logic programs
has not been formally addressed in the literature although negation as failure
is dealt with through the built-in predicate ! in the way it is implemented in
Prolog. This paper proposes a solution to this problem by deriving two generic
fixed-point abstract semantics $F^b and $F^\diamond for forward abstract
interpretation of {\em normal} logic programs. $F^b$ is intended for inferring
data descriptions for edges in the program graph where an edge denotes the
possibility that the control of execution transfers from its source program
point to its destination program point. $F^\diamond$ is derived from $F^b$ and
is intended for inferring data descriptions for textual program points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811013</id><created>1998-11-09</created><authors><author><keyname>Bernstein</keyname><forenames>Phil</forenames></author><author><keyname>Brodie</keyname><forenames>Michael</forenames></author><author><keyname>Ceri</keyname><forenames>Stefano</forenames></author><author><keyname>DeWitt</keyname><forenames>David</forenames></author><author><keyname>Franklin</keyname><forenames>Mike</forenames></author><author><keyname>Garcia-Molina</keyname><forenames>Hector</forenames></author><author><keyname>Gray</keyname><forenames>Jim</forenames></author><author><keyname>Held</keyname><forenames>Jerry</forenames></author><author><keyname>Hellerstein</keyname><forenames>Joe</forenames></author><author><keyname>Jagadish</keyname><forenames>H. V.</forenames></author><author><keyname>Lesk</keyname><forenames>Michael</forenames></author><author><keyname>Maier</keyname><forenames>Dave</forenames></author><author><keyname>Naughton</keyname><forenames>Jeff</forenames></author><author><keyname>Pirahesh</keyname><forenames>Hamid</forenames></author><author><keyname>Stonebraker</keyname><forenames>Mike</forenames></author><author><keyname>Ullman</keyname><forenames>Jeff</forenames></author></authors><title>The Asilomar Report on Database Research</title><categories>cs.DB cs.DL</categories><comments>20 pages in HTML; an original in MSword at
  http://research.microsoft.com/~gray/Asilomar_DB_98.doc</comments><report-no>MSR TR 98 57</report-no><acm-class>H.0;H.2;H.3;H.4;H.5</acm-class><journal-ref>ACM SIGMOD Record, December 1998</journal-ref><abstract>  The database research community is rightly proud of success in basic
research, and its remarkable record of technology transfer. Now the field needs
to radically broaden its research focus to attack the issues of capturing,
storing, analyzing, and presenting the vast array of online data. The database
research community should embrace a broader research agenda -- broadening the
definition of database management to embrace all the content of the Web and
other online data stores, and rethinking our fundamental assumptions in light
of technology shifts. To accelerate this transition, we recommend changing the
way research results are evaluated and presented. In particular, we advocate
encouraging more speculative and long-range work, moving conferences to a
poster format, and publishing all research literature on the Web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811014</id><created>1998-11-09</created><authors><author><keyname>Boerger</keyname><forenames>Egon</forenames></author><author><keyname>Huggins</keyname><forenames>James K.</forenames></author></authors><title>Abstract State Machines 1988-1998: Commented ASM Bibliography</title><categories>cs.SE</categories><comments>Also maintained as a BibTeX file at http://www.eecs.umich.edu/gasm/</comments><acm-class>D.2.4</acm-class><journal-ref>Formal Specification Column (H. Ehrig, ed.), EATCS Bulletin 64,
  February 1998, 105--127</journal-ref><abstract>  An annotated bibliography of papers which deal with or use Abstract State
Machines (ASMs), as of January 1998.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811015</id><created>1998-11-10</created><authors><author><keyname>Lu</keyname><forenames>Lunjin</forenames><affiliation>University of Waikato</affiliation></author><author><keyname>Cleary</keyname><forenames>John G.</forenames><affiliation>University of Waikato</affiliation></author></authors><title>An Emptiness Algorithm for Regular Types with Set Operators</title><categories>cs.LO cs.PL</categories><comments>22 pages</comments><acm-class>D.3.2; F.3.2</acm-class><abstract>  An algorithm to decide the emptiness of a regular type expression with set
operators given a set of parameterised type definitions is presented. The
algorithm can also be used to decide the equivalence of two regular type
expressions and the inclusion of one regular type expression in another. The
algorithm strictly generalises previous work in that tuple distributivity is
not assumed and set operators are permitted in type expressions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811016</id><created>1998-11-11</created><authors><author><keyname>Volk</keyname><forenames>Martin</forenames><affiliation>University of Zurich</affiliation></author><author><keyname>Schneider</keyname><forenames>Gerold</forenames><affiliation>University of Zurich</affiliation></author></authors><title>Comparing a statistical and a rule-based tagger for German</title><categories>cs.CL</categories><comments>8 pages</comments><acm-class>I.2.7</acm-class><abstract>  In this paper we present the results of comparing a statistical tagger for
German based on decision trees and a rule-based Brill-Tagger for German. We
used the same training corpus (and therefore the same tag-set) to train both
taggers. We then applied the taggers to the same test corpus and compared their
respective behavior and in particular their error rates. Both taggers perform
similarly with an error rate of around 5%. From the detailed error analysis it
can be seen that the rule-based tagger has more problems with unknown words
than the statistical tagger. But the results are opposite for tokens that are
many-ways ambiguous. If the unknown words are fed into the taggers with the
help of an external lexicon (such as the Gertwol system) the error rate of the
rule-based tagger drops to 4.7%, and the respective rate of the statistical
taggers drops to around 3.7%. Combining the taggers by using the output of one
tagger to help the other did not lead to any further improvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811017</id><created>1998-11-11</created><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>Bezem</keyname><forenames>Marc</forenames></author></authors><title>Formulas as Programs</title><categories>cs.LO cs.SC</categories><comments>34 pages, appears in: The Logic Programming Paradigm: a 25 Years
  Perspective, K.R. Apt, V. Marek, M. Truszczynski and D.S. Warren (eds),
  Springer-Verlag, Artificial Intelligence Series</comments><acm-class>F.3.1;F.4.1</acm-class><abstract>  We provide here a computational interpretation of first-order logic based on
a constructive interpretation of satisfiability w.r.t. a fixed but arbitrary
interpretation. In this approach the formulas themselves are programs. This
contrasts with the so-called formulas as types approach in which the proofs of
the formulas are typed terms that can be taken as programs. This view of
computing is inspired by logic programming and constraint logic programming but
differs from them in a number of crucial aspects.
  Formulas as programs is argued to yield a realistic approach to programming
that has been realized in the implemented programming language ALMA-0 (Apt et
al.) that combines the advantages of imperative and logic programming. The work
here reported can also be used to reason about the correctness of non-recursive
ALMA-0 programs that do not include destructive assignment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811018</id><created>1998-11-11</created><updated>2001-07-08</updated><authors><author><keyname>Roberts</keyname><forenames>Mark D.</forenames></author></authors><title>P-model Alternative to the T-model</title><categories>cs.CL q-bio.NC</categories><comments>28 pages, 73262 bytes, six eps diagrams, 53 references, background to
  this work is described:
  http://cosmology.mth.uct.ac.za/~roberts/pastresearch/pmodel.html</comments><acm-class>I.2.7;J.4;I.2.6</acm-class><abstract>  Standard linguistic analysis of syntax uses the T-model. This model requires
the ordering: D-structure $&gt;$ S-structure $&gt;$ LF. Between each of these
representations there is movement which alters the order of the constituent
words; movement is achieved using the principles and parameters of syntactic
theory. Psychological serial models do not accommodate the T-model immediately
so that here a new model called the P-model is introduced. Here it is argued
that the LF representation should be replaced by a variant of Frege's three
qualities. In the F-representation the order of elements is not necessarily the
same as that in LF and it is suggested that the correct ordering is:
F-representation $&gt;$ D-structure $&gt;$ S-structure. Within this framework
movement originates as the outcome of emphasis applied to the sentence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811019</id><created>1998-11-11</created><authors><author><keyname>Biedl</keyname><forenames>T.</forenames></author><author><keyname>Demaine</keyname><forenames>E.</forenames></author><author><keyname>Demaine</keyname><forenames>M.</forenames></author><author><keyname>Lazard</keyname><forenames>S.</forenames></author><author><keyname>Lubiw</keyname><forenames>A.</forenames></author><author><keyname>O'Rourke</keyname><forenames>J.</forenames></author><author><keyname>Overmars</keyname><forenames>M.</forenames></author><author><keyname>Robbins</keyname><forenames>S.</forenames></author><author><keyname>Streinu</keyname><forenames>I.</forenames></author><author><keyname>Toussaint</keyname><forenames>G.</forenames></author><author><keyname>Whitesides</keyname><forenames>S.</forenames></author></authors><title>Locked and Unlocked Polygonal Chains in 3D</title><categories>cs.CG cs.DS cs.RO</categories><comments>To appear in Proc. 10th ACM-SIAM Sympos. Discrete Algorithms, Jan.
  1999</comments><acm-class>F.2.2; I.2.9</acm-class><journal-ref>Proc. 10th ACM-SIAM Sympos. Discrete Algorithms, Jan. 1999, pp.
  S866-7.</journal-ref><abstract>  In this paper, we study movements of simple polygonal chains in 3D. We say
that an open, simple polygonal chain can be straightened if it can be
continuously reconfigured to a straight sequence of segments in such a manner
that both the length of each link and the simplicity of the chain are
maintained throughout the movement. The analogous concept for closed chains is
convexification: reconfiguration to a planar convex polygon. Chains that cannot
be straightened or convexified are called locked. While there are open chains
in 3D that are locked, we show that if an open chain has a simple orthogonal
projection onto some plane, it can be straightened. For closed chains, we show
that there are unknotted but locked closed chains, and we provide an algorithm
for convexifying a planar simple polygon in 3D with a polynomial number of
moves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811020</identifier>
 <datestamp>2008-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811020</id><created>1998-11-11</created><authors><author><keyname>Anderson</keyname><forenames>Elizabeth</forenames></author><author><keyname>Atkinson</keyname><forenames>Robert</forenames></author><author><keyname>Crego</keyname><forenames>Cynthia</forenames></author><author><keyname>Slisz</keyname><forenames>Jean</forenames></author><author><keyname>Tompson</keyname><forenames>Sara</forenames></author></authors><title>Digitizing Legacy Documents: A Knowledge-Base Preservation Project</title><categories>cs.DL</categories><comments>21 pages, 5 figures</comments><report-no>Fermilab-TM-2056</report-no><acm-class>H.3.7</acm-class><journal-ref>IllinoisLibraries80:211-219,1998</journal-ref><abstract>  This paper addresses the issue of making legacy information (that material
held in paper format only) electronically searchable and retrievable. We used
proprietary software and commercial hardware to create a process for scanning,
cataloging, archiving and electronically disseminating full-text documents.
This process is relatively easy to implement and reasonably affordable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811021</id><created>1998-11-12</created><authors><author><keyname>Kastrup</keyname><forenames>Bernardo</forenames></author></authors><title>Automatic Hardware Synthesis for a Hybrid Reconfigurable CPU Featuring
  Philips CPLDs</title><categories>cs.PL cs.AR</categories><comments>6 pages, 7 figures, PACT '98 Workshop on Reconfigurable Computing</comments><acm-class>D.3.4; C.1.3</acm-class><abstract>  A high-level architecture of a Hybrid Reconfigurable CPU, based on a
Philips-supported core processor, is introduced. It features the Philips XPLA2
CPLD as a reconfigurable functional unit. A compilation chain is presented, in
which automatic implementation of time-critical program segments in custom
hardware is performed. The entire process is transparent from the programmer's
point of view. The hardware synthesis module of the chain, which translates
segments of assembly code into a hardware netlist, is discussed in details.
Application examples are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811022</id><created>1998-11-12</created><updated>2000-01-25</updated><authors><author><keyname>Chelba</keyname><forenames>Ciprian</forenames><affiliation>CLSP The Johns Hopkins University</affiliation></author><author><keyname>Jelinek</keyname><forenames>Frederick</forenames><affiliation>CLSP The Johns Hopkins University</affiliation></author></authors><title>Expoiting Syntactic Structure for Language Modeling</title><categories>cs.CL</categories><comments>changed ACM-class membership and buggy author names</comments><acm-class>G.3, I.2.7, I.5.1, I.5.4</acm-class><journal-ref>Proceedings of ACL'98, Montreal, Canada</journal-ref><abstract>  The paper presents a language model that develops syntactic structure and
uses it to extract meaningful information from the word history, thus enabling
the use of long distance dependencies. The model assigns probability to every
joint sequence of words--binary-parse-structure with headword annotation and
operates in a left-to-right manner --- therefore usable for automatic speech
recognition. The model, its probabilistic parameterization, and a set of
experiments meant to evaluate its predictive power are presented; an
improvement over standard trigram modeling is achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811023</id><created>1998-11-12</created><authors><author><keyname>Fortnow</keyname><forenames>Lance</forenames></author><author><keyname>Rogers</keyname><forenames>John D.</forenames></author></authors><title>Complexity limitations on quantum computation</title><categories>cs.CC quant-ph</categories><comments>13 pages, no figures; presented at the 13th annual Conference on
  Computational Complexity (1998); submitted to the Journal of Computer and
  System Sciences</comments><report-no>CTI-TR-97003</report-no><acm-class>F.1.1;F.1.2;F.1.3</acm-class><abstract>  We use the powerful tools of counting complexity and generic oracles to help
understand the limitations of the complexity of quantum computation. We show
several results for the probabilistic quantum class BQP.
  1. BQP is low for PP, i.e., PP^BQP=PP.
  2. There exists a relativized world where P=BQP and the polynomial-time
hierarchy is infinite.
  3. There exists a relativized world where BQP does not have complete sets.
  4. There exists a relativized world where P=BQP but P is not equal to UP
intersect coUP and one-way functions exist. This gives a relativized answer to
an open question of Simon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811024</id><created>1998-11-13</created><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author></authors><title>The Essence of Constraint Propagation</title><categories>cs.AI</categories><comments>To appear in Theoretical Computer Science in the special issue
  devoted to the 24th ICALP conference (Bologna 1997)</comments><acm-class>I.1.2; I.2.2</acm-class><abstract>  We show that several constraint propagation algorithms (also called (local)
consistency, consistency enforcing, Waltz, filtering or narrowing algorithms)
are instances of algorithms that deal with chaotic iteration. To this end we
propose a simple abstract framework that allows us to classify and compare
these algorithms and to establish in a uniform way their basic properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811025</id><created>1998-11-13</created><updated>2000-01-25</updated><authors><author><keyname>Chelba</keyname><forenames>Ciprian</forenames><affiliation>CLSP, The Johns Hopkins University, USA</affiliation></author></authors><title>A Structured Language Model</title><categories>cs.CL</categories><comments>changed ACM-class membership, Proceedings of ACL-EACL'97, Student
  Section, Madrid, Spain</comments><acm-class>G.3, I.2.7, I.5.1, I.5.4</acm-class><abstract>  The paper presents a language model that develops syntactic structure and
uses it to extract meaningful information from the word history, thus enabling
the use of long distance dependencies. The model assigns probability to every
joint sequence of words - binary-parse-structure with headword annotation. The
model, its probabilistic parametrization, and a set of experiments meant to
evaluate its predictive power are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811026</id><created>1998-11-16</created><updated>1999-09-08</updated><authors><author><keyname>Rahman</keyname><forenames>Tarjin</forenames></author><author><keyname>Muter</keyname><forenames>Paul</forenames></author></authors><title>Designing an interface to optimize reading with small display windows</title><categories>cs.HC</categories><acm-class>H.1.2</acm-class><journal-ref>Human Factors 41 (1999) 106-117</journal-ref><abstract>  The electronic presentation of text in small display windows is mushrooming.
In the present paper, four ways of presenting text in a small display window
were examined and compared to a Normal Page condition: rapid serial visual
presentation (RSVP), RSVP with a Completion Meter, Sentence-by-Sentence
presentation, and Sentence-by-Sentence presentation with a Completion Meter.
Dependent measures were reading efficiency - speed and comprehension - and
preference. For designers of hardware or software with small display windows,
the results suggest the following: (1) Though RSVP is disliked by readers, the
present methods of allowing self-pacing and regressions in RSVP, unlike earlier
tested methods, are efficient and feasible. (2) Slower reading in RSVP should
be achieved by increasing pauses between sentences or by repeating sentences,
not by decreasing the within-sentence rate. (3) Completion meters do not
interfere with performance, and are usually preferred. (4) The space-saving
Sentence-by-Sentence format is as efficient and as preferred as the Normal Page
format.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811027</id><created>1998-11-20</created><authors><author><keyname>Martin-Flatin</keyname><forenames>J. P.</forenames></author></authors><title>Push vs. Pull in Web-Based Network Management</title><categories>cs.NI</categories><comments>21 pages, submitted to IM'99,
  http://tcomwww.epfl.ch/~jpmf/papers/tr_1998_022.pdf</comments><report-no>SSC/1998/022</report-no><acm-class>C.2.3; C.2.4</acm-class><abstract>  In this paper, we show how Web technologies can be used effectively to (i)
address some of the deficiencies of traditional IP network management
platforms, and (ii) render these expensive platforms redundant. We build on the
concept of embedded management application, proposed by Wellens and Auerbach,
and present two models of network management application designs that rely on
Web technologies. First, the pull model is based on the request/response
paradigm. It is typically used to perform data polling. Several commercial
management platforms already use Web technologies that rely on this model to
provide for ad hoc management; we demonstrate how to extend this to regular
management. Second, the push model is a novel approach which relies on the
publish/subscribe/distribute paradigm. It is better suited to regular
management than the pull model, and allows administrators to conserve network
bandwidth as well as CPU time on the management station. It can be seen as a
generalization of the paradigm commonly used for notification delivery.
Finally, we introduce the concept of the collapsed network management platform,
where these two models coexist.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811028</id><created>1998-11-20</created><authors><author><keyname>Kung</keyname><forenames>H. T.</forenames></author><author><keyname>Wang</keyname><forenames>S. Y.</forenames></author></authors><title>TCP Trunking</title><categories>cs.NI</categories><comments>postscript file</comments><acm-class>C.2.1</acm-class><abstract>  A TCP trunk is an IP tunnel under TCP control, capable of carrying packets
from any number of user flows. By exploiting properties of TCP, a TCP trunk
provides elastic and reliable transmission over a network, and automatically
shares the network fairly with other competing trunks. Moreover, by aggregating
user flows into a single trunk flow, TCP trunking can significantly reduce the
number of flows that the network needs to manage, thereby allowing use of
simplified management to achieve improved perfor mance. For example, when
dealing with only a small number of TCP trunk flows, a router with a simple
FIFO buffer can experience low packet loss rates.
  A TCP trunk is a &quot;soft&quot; circuit in the sense that it requires no flow states
to be maintained inside the network. Setting up a TCP trunk involves only
configuring the two end nodes. This is in contrast with traditional methods of
configuring circuits via signaling of network nodes.
  A simple packet-dropping mechanism based on packet accounting at the
transmitter of a TCP trunk assures that, when the trunk reduces its bandwidth
in response to network congestion, user TCP flows carried by the trunk will
reduce their bandwidths by the same proportion. Simu lation results have
demonstrated that TCP trunks can provide improved network performance to users,
while achieving high network utilization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811029</id><created>1998-11-20</created><authors><author><keyname>Ivanisevic</keyname><forenames>I.</forenames></author><author><keyname>Lumelsky</keyname><forenames>V.</forenames></author></authors><title>A Human - machine interface for teleoperation of arm manipulators in a
  complex environment</title><categories>cs.RO cs.AI</categories><comments>Appeared in Proc. IROS, Oct. 1998</comments><report-no>RL-97006</report-no><acm-class>I.2.9</acm-class><abstract>  This paper discusses the feasibility of using configuration space (C-space)
as a means of visualization and control in operator-guided real-time motion of
a robot arm manipulator. The motivation is to improve performance of the human
operator in tasks involving the manipulator motion in an environment with
obstacles. Unlike some other motion planning tasks, operators are known to make
expensive mistakes in such tasks, even in a simpler two-dimensional case. They
have difficulty learning better procedures and their performance improves very
little with practice. Using an example of a two-dimensional arm manipulator, we
show that translating the problem into C-space improves the operator
performance rather remarkably, on the order of magnitude compared to the usual
work space control. An interface that makes the transfer possible is described,
and an example of its use in a virtual environment is shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811030</id><created>1998-11-24</created><authors><author><keyname>Corrigan</keyname><forenames>Gerald</forenames></author><author><keyname>Massey</keyname><forenames>Noel</forenames></author><author><keyname>Karaali</keyname><forenames>Orhan</forenames></author></authors><title>Generating Segment Durations in a Text-To-Speech System: A Hybrid
  Rule-Based/Neural Network Approach</title><categories>cs.NE cs.HC</categories><comments>4 pages, PostScript</comments><acm-class>I.2.6; K.3.2</acm-class><journal-ref>Proceedings of Eurospeech (1997) 2675-2678. Rhodes, Greece</journal-ref><abstract>  A combination of a neural network with rule firing information from a
rule-based system is used to generate segment durations for a text-to-speech
system. The system shows a slight improvement in performance over a neural
network system without the rule firing information. Synthesized speech using
segment durations was accepted by listeners as having about the same quality as
speech generated using segment durations extracted from natural speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811031</id><created>1998-11-24</created><authors><author><keyname>Karaali</keyname><forenames>Orhan</forenames></author><author><keyname>Corrigan</keyname><forenames>Gerald</forenames></author><author><keyname>Gerson</keyname><forenames>Ira</forenames></author></authors><title>Speech Synthesis with Neural Networks</title><categories>cs.NE cs.HC</categories><comments>6 pages, PostScript</comments><acm-class>I.2.6; K.3.2</acm-class><journal-ref>World Congress on Neural Networks (1996) 45-50. San Diego</journal-ref><abstract>  Text-to-speech conversion has traditionally been performed either by
concatenating short samples of speech or by using rule-based systems to convert
a phonetic representation of speech into an acoustic representation, which is
then converted into speech. This paper describes a system that uses a
time-delay neural network (TDNN) to perform this phonetic-to-acoustic mapping,
with another neural network to control the timing of the generated speech. The
neural network system requires less memory than a concatenation system, and
performed well in tests comparing it to commercial systems using other
technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9811032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9811032</id><created>1998-11-24</created><authors><author><keyname>Karaali</keyname><forenames>Orhan</forenames></author><author><keyname>Corrigan</keyname><forenames>Gerald</forenames></author><author><keyname>Gerson</keyname><forenames>Ira</forenames></author><author><keyname>Massey</keyname><forenames>Noel</forenames></author></authors><title>Text-To-Speech Conversion with Neural Networks: A Recurrent TDNN Approach</title><categories>cs.NE cs.HC</categories><comments>4 pages, PostScript</comments><acm-class>I.2.6; K.3.2</acm-class><journal-ref>Proceedings of Eurospeech (1997) 561-564. Rhodes, Greece</journal-ref><abstract>  This paper describes the design of a neural network that performs the
phonetic-to-acoustic mapping in a speech synthesis system. The use of a
time-domain neural network architecture limits discontinuities that occur at
phone boundaries. Recurrent data input also helps smooth the output parameter
tracks. Independent testing has demonstrated that the voice quality produced by
this system compares favorably with speech from existing commercial
text-to-speech systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812001</id><created>1998-12-01</created><updated>1998-12-02</updated><authors><author><keyname>LI</keyname><forenames>Hang</forenames><affiliation>NEC Corporation</affiliation></author></authors><title>A Probabilistic Approach to Lexical Semantic Knowledge Acquisition and S
  tructural Disambiguation</title><categories>cs.CL</categories><comments>PhD. Thesis, Univ. of Tokyo, July 1998; latex file, eps figures; 136
  pages, page numbers do not comfort to the original; ps font changes</comments><acm-class>I.2.6;I.2.7</acm-class><abstract>  In this thesis, I address the problem of automatically acquiring lexical
semantic knowledge, especially that of case frame patterns, from large corpus
data and using the acquired knowledge in structural disambiguation. The
approach I adopt has the following characteristics: (1) dividing the problem
into three subproblems: case slot generalization, case dependency learning, and
word clustering (thesaurus construction). (2) viewing each subproblem as that
of statistical estimation and defining probability models for each subproblem,
(3) adopting the Minimum Description Length (MDL) principle as learning
strategy, (4) employing efficient learning algorithms, and (5) viewing the
disambiguation problem as that of statistical prediction. Major contributions
of this thesis include: (1) formalization of the lexical knowledge acquisition
problem, (2) development of a number of learning methods for lexical knowledge
acquisition, and (3) development of a high-performance disambiguation method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812002</id><created>1998-12-03</created><authors><author><keyname>Likas</keyname><forenames>A.</forenames></author><author><keyname>Lagaris</keyname><forenames>I. E.</forenames></author></authors><title>Training Reinforcement Neurocontrollers Using the Polytope Algorithm</title><categories>cs.NE</categories><report-no>Preprint, Dept. of Computer Science, Univ. of Ioannina, 1996</report-no><acm-class>C.1.3</acm-class><abstract>  A new training algorithm is presented for delayed reinforcement learning
problems that does not assume the existence of a critic model and employs the
polytope optimization algorithm to adjust the weights of the action network so
that a simple direct measure of the training performance is maximized.
Experimental results from the application of the method to the pole balancing
problem indicate improved training performance compared with critic-based and
genetic reinforcement approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812003</id><created>1998-12-03</created><authors><author><keyname>Lagaris</keyname><forenames>I. E.</forenames></author><author><keyname>Likas</keyname><forenames>A.</forenames></author><author><keyname>Papageorgiou</keyname><forenames>D. G.</forenames></author></authors><title>Neural Network Methods for Boundary Value Problems Defined in
  Arbitrarily Shaped Domains</title><categories>cs.NE cond-mat.dis-nn cs.NA math-ph math.MP math.NA physics.comp-ph</categories><report-no>Preprint no. 7-98, Dept. of Computer Science, Univ. of Ioannina,
  Greece, 1998</report-no><acm-class>C.1.3</acm-class><abstract>  Partial differential equations (PDEs) with Dirichlet boundary conditions
defined on boundaries with simple geometry have been succesfuly treated using
sigmoidal multilayer perceptrons in previous works. This article deals with the
case of complex boundary geometry, where the boundary is determined by a number
of points that belong to it and are closely located, so as to offer a
reasonable representation. Two networks are employed: a multilayer perceptron
and a radial basis function network. The later is used to account for the
satisfaction of the boundary conditions. The method has been successfuly tested
on two-dimensional and three-dimensional PDEs and has yielded accurate
solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812004</id><created>1998-12-04</created><authors><author><keyname>Roberts</keyname><forenames>Mark D.</forenames></author></authors><title>Name Strategy: Its Existence and Implications</title><categories>cs.CL cs.AI math.HO</categories><comments>32 pages, 2 ascii diagrams</comments><acm-class>I.2.6;J.4;I.2.7</acm-class><journal-ref>Int.J.Computational Cognition Volume 3 Pages 1-14 (2005).</journal-ref><abstract>  It is argued that colour name strategy, object name strategy, and chunking
strategy in memory are all aspects of the same general phenomena, called
stereotyping. It is pointed out that the Berlin-Kay universal partial ordering
of colours and the frequency of traffic accidents classified by colour are
surprisingly similar. Some consequences of the existence of a name strategy for
the philosophy of language and mathematics are discussed. It is argued that
real valued quantities occur {\it ab initio}. The implication of real valued
truth quantities is that the {\bf Continuum Hypothesis} of pure mathematics is
side-stepped. The existence of name strategy shows that thought/sememes and
talk/phonemes can be separate, and this vindicates the assumption of thought
occurring before talk used in psycholinguistic speech production models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812005</id><created>1998-12-04</created><authors><author><keyname>Heinonen</keyname><forenames>Oskari</forenames><affiliation>University of Helsinki</affiliation></author></authors><title>Optimal Multi-Paragraph Text Segmentation by Dynamic Programming</title><categories>cs.CL</categories><comments>5 pages, 3 eps figures, LaTeX2e; includes errata; uses colacl, epsf,
  times</comments><acm-class>I.2.7</acm-class><journal-ref>Proceedings of COLING-ACL '98, pp. 1484-1486, Montreal, Canada</journal-ref><abstract>  There exist several methods of calculating a similarity curve, or a sequence
of similarity values, representing the lexical cohesion of successive text
constituents, e.g., paragraphs. Methods for deciding the locations of fragment
boundaries are, however, scarce. We propose a fragmentation method based on
dynamic programming. The method is theoretically sound and guaranteed to
provide an optimal splitting on the basis of a similarity curve, a preferred
fragment length, and a cost function defined. The method is especially useful
when control on fragment size is of importance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812006</id><created>1998-12-04</created><authors><author><keyname>Karaali</keyname><forenames>Orhan</forenames></author><author><keyname>Corrigan</keyname><forenames>Gerald</forenames></author><author><keyname>Massey</keyname><forenames>Noel</forenames></author><author><keyname>Miller</keyname><forenames>Corey</forenames></author><author><keyname>Schnurr</keyname><forenames>Otto</forenames></author><author><keyname>Mackie</keyname><forenames>Andrew</forenames></author></authors><title>A High Quality Text-To-Speech System Composed of Multiple Neural
  Networks</title><categories>cs.NE cs.HC</categories><comments>Source link (9812006.tar.gz) contains: 1 PostScript file (4 pages)
  and 3 WAV audio files. If your system does not support Windows WAV files, try
  a tool like &quot;sox&quot; to translate the audio into a format of your choice</comments><acm-class>I.2.6; K.3.2</acm-class><journal-ref>Proceedings of the IEEE International Conference on Acoustics,
  Speech and Signal Processing (1998) 2:1237-1240. Seattle, Washington</journal-ref><abstract>  While neural networks have been employed to handle several different
text-to-speech tasks, ours is the first system to use neural networks
throughout, for both linguistic and acoustic processing. We divide the
text-to-speech task into three subtasks, a linguistic module mapping from text
to a linguistic representation, an acoustic module mapping from the linguistic
representation to speech, and a video module mapping from the linguistic
representation to animated images. The linguistic module employs a
letter-to-sound neural network and a postlexical neural network. The acoustic
module employs a duration neural network and a phonetic neural network. The
visual neural network is employed in parallel to the acoustic module to drive a
talking head. The use of neural networks that can be retrained on the
characteristics of different voices and languages affords our system a degree
of adaptability and naturalness heretofore unavailable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812007</id><created>1998-12-08</created><authors><author><keyname>Karger</keyname><forenames>David R.</forenames></author></authors><title>Minimum Cuts in Near-Linear Time</title><categories>cs.DS</categories><acm-class>F.2.2;G.2.2;G.3</acm-class><abstract>  We significantly improve known time bounds for solving the minimum cut
problem on undirected graphs. We use a ``semi-duality'' between minimum cuts
and maximum spanning tree packings combined with our previously developed
random sampling techniques. We give a randomized algorithm that finds a minimum
cut in an m-edge, n-vertex graph with high probability in O(m log^3 n) time. We
also give a simpler randomized algorithm that finds all minimum cuts with high
probability in O(n^2 log n) time. This variant has an optimal RNC
parallelization. Both variants improve on the previous best time bound of O(n^2
log^3 n). Other applications of the tree-packing approach are new, nearly tight
bounds on the number of near minimum cuts a graph may have and a new data
structure for representing them in a space-efficient manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812008</id><created>1998-12-08</created><authors><author><keyname>Karger</keyname><forenames>David</forenames></author><author><keyname>Motwani</keyname><forenames>Rajeev</forenames></author><author><keyname>Sudan</keyname><forenames>Madhu</forenames></author></authors><title>Approximate Graph Coloring by Semidefinite Programming</title><categories>cs.DS</categories><acm-class>F.2.2;G.2.2;G.3</acm-class><journal-ref>JACM 45(2), mar. 1998, pp.246--265</journal-ref><abstract>  We consider the problem of coloring k-colorable graphs with the fewest
possible colors. We present a randomized polynomial time algorithm that colors
a 3-colorable graph on $n$ vertices with min O(Delta^{1/3} log^{1/2} Delta log
n), O(n^{1/4} log^{1/2} n) colors where Delta is the maximum degree of any
vertex. Besides giving the best known approximation ratio in terms of n, this
marks the first non-trivial approximation result as a function of the maximum
degree Delta. This result can be generalized to k-colorable graphs to obtain a
coloring using min O(Delta^{1-2/k} log^{1/2} Delta log n), O(n^{1-3/(k+1)}
log^{1/2} n) colors. Our results are inspired by the recent work of Goemans and
Williamson who used an algorithm for semidefinite optimization problems, which
generalize linear programs, to obtain improved approximations for the MAX CUT
and MAX 2-SAT problems. An intriguing outcome of our work is a duality
relationship established between the value of the optimum solution to our
semidefinite program and the Lovasz theta-function. We show lower bounds on the
gap between the optimum solution of our semidefinite program and the actual
chromatic number; by duality this also demonstrates interesting new facts about
the theta-function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812009</id><created>1998-12-10</created><authors><author><keyname>Crestani</keyname><forenames>Fabio</forenames></author></authors><title>Vocal Access to a Newspaper Archive: Design Issues and Preliminary
  Investigation</title><categories>cs.DL</categories><acm-class>H.3.7</acm-class><abstract>  This paper presents the design and the current prototype implementation of an
interactive vocal Information Retrieval system that can be used to access
articles of a large newspaper archive using a telephone. The results of
preliminary investigation into the feasibility of such a system are also
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812010</id><created>1998-12-10</created><authors><author><keyname>Mueller</keyname><forenames>Erik T.</forenames></author><author><keyname>Dyer</keyname><forenames>Michael G.</forenames></author></authors><title>Towards a computational theory of human daydreaming</title><categories>cs.AI</categories><comments>10 pages. Appears in: Proceedings of the Seventh Annual Conference of
  the Cognitive Science Society (pp. 120-129). Irvine, CA. 1985</comments><acm-class>I.2.0</acm-class><abstract>  This paper examines the phenomenon of daydreaming: spontaneously recalling or
imagining personal or vicarious experiences in the past or future. The
following important roles of daydreaming in human cognition are postulated:
plan preparation and rehearsal, learning from failures and successes, support
for processes of creativity, emotion regulation, and motivation.
  A computational theory of daydreaming and its implementation as the program
DAYDREAMER are presented. DAYDREAMER consists of 1) a scenario generator based
on relaxed planning, 2) a dynamic episodic memory of experiences used by the
scenario generator, 3) a collection of personal goals and control goals which
guide the scenario generator, 4) an emotion component in which daydreams
initiate, and are initiated by, emotional states arising from goal outcomes,
and 5) domain knowledge of interpersonal relations and common everyday
occurrences.
  The role of emotions and control goals in daydreaming is discussed. Four
control goals commonly used in guiding daydreaming are presented:
rationalization, failure/success reversal, revenge, and preparation. The role
of episodic memory in daydreaming is considered, including how daydreamed
information is incorporated into memory and later used. An initial version of
DAYDREAMER which produces several daydreams (in English) is currently running.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812011</id><created>1998-12-10</created><authors><author><keyname>Mueller</keyname><forenames>Erik T.</forenames></author><author><keyname>Moore</keyname><forenames>Johanna D.</forenames></author><author><keyname>Popek</keyname><forenames>Gerald J.</forenames></author></authors><title>A nested transaction mechanism for LOCUS</title><categories>cs.OS cs.DC</categories><comments>17 pages. Appears in: Proceedings of the Ninth ACM Symposium on
  Operating Systems Principles (pp. 71-87). Operating Systems Review. Vol. 17,
  No. 5. New York: Association for Computing Machinery. 1983</comments><acm-class>H.2.4</acm-class><abstract>  A working implementation of nested transactions has been produced for LOCUS,
an integrated distributed operating system which provides a high degree of
network transparency. Several aspects of our mechanism are novel. First, the
mechanism allows a transaction to access objects directly without regard to the
location of the object. Second, processes running on behalf of a single
transaction may be located at many sites. Thus there is no need to invoke a new
transaction to perform processing or access objects at a remote site. Third,
unlike other environments, LOCUS allows replication of data objects at more
than one site in the network, and this capability is incorporated into the
transaction mechanism. If the copy of an object that is currently being
accessed becomes unavailable, it is possible to continue work by using another
one of the replicated copies. Finally, an efficient orphan removal algorithm is
presented, and the problem of providing continued operation during network
partitions is addressed in detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812012</id><created>1998-12-10</created><authors><author><keyname>Watrous</keyname><forenames>John</forenames><affiliation>University of Montreal</affiliation></author></authors><title>Quantum simulations of classical random walks and undirected graph
  connectivity</title><categories>cs.CC quant-ph</categories><comments>11 pages, submitted to Complexity'99</comments><acm-class>F.1.3; F.2.2; G.2.2</acm-class><abstract>  It is not currently known if quantum Turing machines can efficiently simulate
probabilistic computations in the space-bounded case. In this paper we show
that space-bounded quantum Turing machines can efficiently simulate a limited
class of random processes: random walks on undirected graphs. By means of such
simulations, it is demonstrated that the undirected graph connectivity problem
for regular graphs can be solved by one-sided error quantum Turing machines
that run in logspace and halt absolutely. It follows that symmetric logspace is
contained in the quantum analogue of randomized logspace.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812013</id><created>1998-12-11</created><authors><author><keyname>Hodjat</keyname><forenames>Babak</forenames></author><author><keyname>Amamiya</keyname><forenames>Makoto</forenames></author></authors><title>The Self-Organizing Symbiotic Agent</title><categories>cs.NE cs.CC</categories><comments>12 pages, 2 figures</comments><acm-class>I.2.8; D.2.11;F.1.13; I.2.11</acm-class><abstract>  In [N. A. Baas, Emergence, Hierarchies, and Hyper-structures, in C.G. Langton
ed., Artificial Life III, Addison Wesley, 1994.] a general framework for the
study of Emergence and hyper-structure was presented. This approach is mostly
concerned with the description of such systems. In this paper we will try to
bring forth a different aspect of this model we feel will be useful in the
engineering of agent based solutions, namely the symbiotic approach. In this
approach a self-organizing method of dividing the more complex &quot;main-problem&quot;
to a hyper-structure of &quot;sub-problems&quot; with the aim of reducing complexity is
desired. A description of the general problem will be given along with some
instances of related work. This paper is intended to serve as an introductory
challenge for general solutions to the described problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812014</id><created>1998-12-11</created><authors><author><keyname>Hodjat</keyname><forenames>Babak</forenames></author><author><keyname>Savoie</keyname><forenames>Christopher J.</forenames></author><author><keyname>Amamiya</keyname><forenames>Makoto</forenames></author></authors><title>An Adaptive Agent Oriented Software Architecture</title><categories>cs.DC cs.MA</categories><comments>14 pages, 5 figures. Presemted at PRICAI '98 (5th Pacific Rim
  Conference on Artificial Intelligence)</comments><acm-class>D.2.11; D.2.1</acm-class><abstract>  A new approach to software design based on an agent-oriented architecture is
presented. Unlike current research, we consider software to be designed and
implemented with this methodology in mind. In this approach agents are
considered adaptively communicating concurrent modules which are divided into a
white box module responsible for the communications and learning, and a black
box which is the independent specialized processes of the agent. A distributed
Learning policy is also introduced for adaptability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812015</id><created>1998-12-11</created><authors><author><keyname>Hodjat</keyname><forenames>Babak</forenames></author><author><keyname>Amamiya</keyname><forenames>Makoto</forenames></author></authors><title>Adaptive Interaction Using the Adaptive Agent Oriented Software
  Architecture (AAOSA)</title><categories>cs.HC cs.DC</categories><comments>14 pages, 4 figures</comments><acm-class>D.2.2; I.2.7; J.7; I.2.11</acm-class><abstract>  User interfaces that adapt their characteristics to those of the user are
referred to as adaptive interfaces. We propose Adaptive Agent Oriented Software
Architecture (AAOSA) as a new way of designing adaptive interfaces. AAOSA is a
new approach to software design based on an agent-oriented architecture. In
this approach agents are considered adaptively communicating concurrent modules
which are divided into a white box module responsible for the communications
and learning, and a black box which is responsible for the independent
specialized processes of the agent. A distributed learning policy that makes
use of this architecture is used for purposes of system adaptability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812016</id><created>1998-12-14</created><authors><author><keyname>Hitchcock</keyname><forenames>Steve</forenames></author><author><keyname>Carr</keyname><forenames>Les</forenames></author><author><keyname>Hall</keyname><forenames>Wendy</forenames></author></authors><title>Making the most of electronic journals</title><categories>cs.DL</categories><comments>11 pages</comments><acm-class>I.7.4</acm-class><abstract>  As most electronic journals available today have been derived from print
originals, print journals have become a vital element in the broad development
of electronic journals publishing. Further dependence on the print publishing
model, however, will be a constraint on the continuing development of
e-journals, and a series of conflicts are likely to arise. Making the most of
e-journals requires that a distinctive new publishing model is developed. We
consider some of the issues that will be fundamental in this new model,
starting with user motivations and some reported publisher experiences, both of
which suggest a broadening desire for comprehensive linked archives. This leads
in turn to questions about the impact of rights assignment by authors, in
particular the common practice of giving exlusive rights to publishers for
individual works. Some non-prescriptive solutions are suggested, and four steps
towards optimum e-journals are proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812017</id><created>1998-12-15</created><authors><author><keyname>Raggl</keyname><forenames>Andreas</forenames></author><author><keyname>Slany</keyname><forenames>Wolfgang</forenames></author></authors><title>A reusable iterative optimization software library to solve
  combinatorial problems with approximate reasoning</title><categories>cs.AI</categories><comments>33 pages, 9 figures; for a project overview see
  http://www.dbai.tuwien.ac.at/proj/StarFLIP/</comments><report-no>DBAI-TR-98-23</report-no><acm-class>I.2.8; I.2.1; J.6; I.2.4; F.2.2</acm-class><journal-ref>International Journal of Approximate Reasoning, 19(1--2):161--191,
  July/August 1998</journal-ref><abstract>  Real world combinatorial optimization problems such as scheduling are
typically too complex to solve with exact methods. Additionally, the problems
often have to observe vaguely specified constraints of different importance,
the available data may be uncertain, and compromises between antagonistic
criteria may be necessary. We present a combination of approximate reasoning
based constraints and iterative optimization based heuristics that help to
model and solve such problems in a framework of C++ software libraries called
StarFLIP++. While initially developed to schedule continuous caster units in
steel plants, we present in this paper results from reusing the library
components in a shift scheduling system for the workforce of an industrial
production plant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812018</id><created>1998-12-16</created><authors><author><keyname>Busemann</keyname><forenames>Stephan</forenames><affiliation>DFKI GmbH</affiliation></author><author><keyname>Horacek</keyname><forenames>Helmut</forenames><affiliation>DFKI GmbH</affiliation></author></authors><title>A Flexible Shallow Approach to Text Generation</title><categories>cs.CL</categories><comments>LaTeX, 10 pages</comments><acm-class>I.2.7</acm-class><journal-ref>Proc. 9th International Workshop on Natural Language Generation,
  Niagara-on-the-Lake, Canada, August 1998, 238-247</journal-ref><abstract>  In order to support the efficient development of NL generation systems, two
orthogonal methods are currently pursued with emphasis: (1) reusable, general,
and linguistically motivated surface realization components, and (2) simple,
task-oriented template-based techniques. In this paper we argue that, from an
application-oriented perspective, the benefits of both are still limited. In
order to improve this situation, we suggest and evaluate shallow generation
methods associated with increased flexibility. We advise a close connection
between domain-motivated and linguistic ontologies that supports the quick
adaptation to new tasks and domains, rather than the reuse of general
resources. Our method is especially designed for generating reports with
limited linguistic variations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812019</id><created>1998-12-16</created><authors><author><keyname>Hines</keyname><forenames>Peter M.</forenames></author></authors><title>Symmetries and transitions of bounded Turing machines</title><categories>cs.LO math.CT</categories><comments>21 pages, submitted</comments><acm-class>F.1.1;f.4.1</acm-class><abstract>  We consider the structures given by repeatedly generalising the definition of
finite state automata by symmetry considerations, and constructing analogues of
transition monoids at each step. This approach first gives us non-deterministic
automata, then (non-deterministic) two-way automata and bounded Turing machines
--- that is, Turing machines where the read / write head is unable to move past
the end of the input word.
  In the case of two-way automata, the transition monoids generalise to
endomorphism monoids in compact closed categories. These use Girard's
resolution formula (from the Geometry of Interaction representation of linear
logic) to construct the images of singleton words.
  In the case of bounded Turing machines, the transition homomorphism
generalises to a monoid homomorphism from the natural numbers to a monoid
constructed from the union of endomorphism monoids of a compact closed
category, together with an appropriate composition. These use Girard's
execution formula (also from the Geometry of Interaction representation of
linear logic) to construct images of singletons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812020</id><created>1998-12-22</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Lagoze</keyname><forenames>Carl</forenames></author></authors><title>The Computing Research Repository: Promoting the Rapid Dissemination and
  Archiving of Computer Science Research</title><categories>cs.DL</categories><comments>Submission to ACM DL99</comments><acm-class>H.3.7</acm-class><abstract>  We describe the Computing Research Repository (CoRR), a new electronic
archive for rapid dissemination and archiving of computer science research
results. CoRR was initiated in September 1998 through the cooperation of ACM,
LANL (Los Alamos National Laboratory) e-Print archive, and NCSTRL (Networked
Computer Science Technical Research Library. Through its implementation of the
Dienst protocol, CoRR combines the open and extensible architecture of NCSTRL
with the reliable access and well-established management practices of the LANL
XXX e-Print repository. This architecture will allow integration with other
e-Print archives and provides a foundation for a future broad-based scholarly
digital library. We describe the decisions that were made in creating CoRR, the
architecture of the CoRR/NCSTRL interoperation, and issues that have arisen
during the operation of CoRR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812021</id><created>1998-12-22</created><authors><author><keyname>Daelemans</keyname><forenames>Walter</forenames></author><author><keyname>Bosch</keyname><forenames>Antal van den</forenames></author><author><keyname>Zavrel</keyname><forenames>Jakub</forenames></author></authors><title>Forgetting Exceptions is Harmful in Language Learning</title><categories>cs.CL cs.LG</categories><comments>31 pages, 7 figures, 10 tables. uses 11pt, fullname, a4wide tex
  styles. Pre-print version of article to appear in Machine Learning 11:1-3,
  Special Issue on Natural Language Learning. Figures on page 22 slightly
  compressed to avoid page overload</comments><acm-class>I.2.6; I.2.7</acm-class><abstract>  We show that in language learning, contrary to received wisdom, keeping
exceptional training instances in memory can be beneficial for generalization
accuracy. We investigate this phenomenon empirically on a selection of
benchmark natural language processing tasks: grapheme-to-phoneme conversion,
part-of-speech tagging, prepositional-phrase attachment, and base noun phrase
chunking. In a first series of experiments we combine memory-based learning
with training set editing techniques, in which instances are edited based on
their typicality and class prediction strength. Results show that editing
exceptional instances (with low typicality or low class prediction strength)
tends to harm generalization accuracy. In a second series of experiments we
compare memory-based learning and decision-tree learning methods on the same
selection of tasks, and find that decision-tree learning often performs worse
than memory-based learning. Moreover, the decrease in performance can be linked
to the degree of abstraction from exceptions (i.e., pruning or eagerness). We
provide explanations for both results in terms of the properties of the natural
language processing tasks and the learning algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812022</id><created>1998-12-28</created><authors><author><keyname>Gottlob</keyname><forenames>G.</forenames></author><author><keyname>Leone</keyname><forenames>N.</forenames></author><author><keyname>Scarcello</keyname><forenames>F.</forenames></author></authors><title>Hypertree Decompositions and Tractable Queries</title><categories>cs.DB cs.AI</categories><comments>30 pages, 7 figures, uses fancybox, epsfig, epic, and eepic</comments><report-no>DBAI-TR-98/21</report-no><acm-class>F.2.2; H.2.4; I.2.8; G.2.2</acm-class><journal-ref>Journal of Computer and System Sciences, 64(3):579-627, 2002</journal-ref><doi>10.1006/jcss.2001.1809</doi><abstract>  Several important decision problems on conjunctive queries (CQs) are
NP-complete in general but become tractable, and actually highly
parallelizable, if restricted to acyclic or nearly acyclic queries. Examples
are the evaluation of Boolean CQs and query containment. These problems were
shown tractable for conjunctive queries of bounded treewidth and of bounded
degree of cyclicity. The so far most general concept of nearly acyclic queries
was the notion of queries of bounded query-width introduced by Chekuri and
Rajaraman (1997). While CQs of bounded query width are tractable, it remained
unclear whether such queries are efficiently recognizable. Chekuri and
Rajaraman stated as an open problem whether for each constant k it can be
determined in polynomial time if a query has query width less than or equal to
k. We give a negative answer by proving this problem NP-complete (specifically,
for k=4). In order to circumvent this difficulty, we introduce the new concept
of hypertree decomposition of a query and the corresponding notion of hypertree
width. We prove: (a) for each k, the class of queries with query width bounded
by k is properly contained in the class of queries whose hypertree width is
bounded by k; (b) unlike query width, constant hypertree-width is efficiently
recognizable; (c) Boolean queries of constant hypertree width can be
efficiently evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9812023</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9812023</id><created>1998-12-29</created><authors><author><keyname>Paul</keyname><forenames>Soumyadeep</forenames></author><author><keyname>Sinha</keyname><forenames>Sudipta N.</forenames></author><author><keyname>Mukerjee</keyname><forenames>Amitabha</forenames></author></authors><title>Virtual Kathakali : Gesture Driven Metamorphosis</title><categories>cs.HC</categories><comments>Proceedings of International Conference on Knowledge Based Computer
  Systems, Mumbai, India, Dec '98. 12 pages, 19 figures</comments><acm-class>K.3.1; I.3.7; H.5.2; H.5.1</acm-class><abstract>  Training in motor skills such as athletics, dance, or gymnastics is not
possible today except in the direct presence of the coach/instructor. This
paper describes a computer vision based gesture recognition system which is
used to metamorphose the user into a Virtual person, e.g. as a Kathakali
dancer, which is graphically recreated at a near or diatant location. Thus this
can be seen by an off-site coach using low-bandwidth joint-motion data which
permits real time animation. The metamorphosis involves altering the appearance
and identity of the user and also creating a specific environment possibly in
interaction with other virtual creatures.
  A robust vision module is used to identify the user, based on very simple
binary image processing in real time which also manages to resolve
self-occlusion, correct for clothing/colour and other variations among users.
Gestures are identified by locating key points at the shoulder, elbow and wrist
joint, which are then recreated in an articulated humanoid model, which in this
instance, representes a Kathakali dancer in elaborate traditional dress. Unlike
glove based or other and movement tracking systems, this application requires
the user to wear no hardwire devices and is aimed at making gesture tracking
simpler, cheaper, and more user friendly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9901001</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9901001</id><created>1999-01-04</created><authors><author><keyname>Baxter</keyname><forenames>Jonathan</forenames></author><author><keyname>Tridgell</keyname><forenames>Andrew</forenames></author><author><keyname>Weaver</keyname><forenames>Lex</forenames></author></authors><title>TDLeaf(lambda): Combining Temporal Difference Learning with Game-Tree
  Search</title><categories>cs.LG cs.AI</categories><comments>5 pages. Also in Proceedings of the Ninth Australian Conference on
  Neural Networks (ACNN'98), Brisbane QLD, February 1998, pages 168-172</comments><acm-class>I.2.6</acm-class><journal-ref>Australian Journal of Intelligent Information Processing Systems,
  ISSN 1321-2133, Vol. 5 No. 1, Autumn 1998, pages 39-43</journal-ref><abstract>  In this paper we present TDLeaf(lambda), a variation on the TD(lambda)
algorithm that enables it to be used in conjunction with minimax search. We
present some experiments in both chess and backgammon which demonstrate its
utility and provide comparisons with TD(lambda) and another less radical
variant, TD-directed(lambda). In particular, our chess program, ``KnightCap,''
used TDLeaf(lambda) to learn its evaluation function while playing on the Free
Internet Chess Server (FICS, fics.onenet.net). It improved from a 1650 rating
to a 2100 rating in just 308 games. We discuss some of the reasons for this
success and the relationship between our results and Tesauro's results in
backgammon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9901002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9901002</id><created>1999-01-09</created><authors><author><keyname>Baxter</keyname><forenames>Jonathan</forenames></author><author><keyname>Tridgell</keyname><forenames>Andrew</forenames></author><author><keyname>Weaver</keyname><forenames>Lex</forenames></author></authors><title>KnightCap: A chess program that learns by combining TD(lambda) with
  game-tree search</title><categories>cs.LG cs.AI</categories><comments>9 pages</comments><acm-class>I.2.6</acm-class><journal-ref>MACHINE LEARNING Proceedings of the Fifteenth International
  Conference (ICML '98), ISBN 1-55860-556-8, ISSN 1049-1910, Madison WISCONSIN,
  July 24-27 1998, pages 28-36</journal-ref><abstract>  In this paper we present TDLeaf(lambda), a variation on the TD(lambda)
algorithm that enables it to be used in conjunction with game-tree search. We
present some experiments in which our chess program ``KnightCap'' used
TDLeaf(lambda) to learn its evaluation function while playing on the Free
Internet Chess Server (FICS, fics.onenet.net). The main success we report is
that KnightCap improved from a 1650 rating to a 2150 rating in just 308 games
and 3 days of play. As a reference, a rating of 1650 corresponds to about level
B human play (on a scale from E (1000) to A (1800)), while 2150 is human master
level. We discuss some of the reasons for this success, principle among them
being the use of on-line, rather than self-play.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9901003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9901003</id><created>1999-01-12</created><authors><author><keyname>Denecker</keyname><forenames>M.</forenames></author><author><keyname>Marek</keyname><forenames>V.</forenames></author><author><keyname>Truszczynski</keyname><forenames>M.</forenames></author></authors><title>Fixpoint 3-valued semantics for autoepistemic logic</title><categories>cs.LO cs.AI</categories><comments>Proceedings of the Fifteenth National Conference on Artificial
  Intelligence (AAAI-98), pages 840--845, (MIT Press, 1998)</comments><acm-class>I.2.4, F.4.1, I.2.3</acm-class><abstract>  The paper presents a constructive fixpoint semantics for autoepistemic logic
(AEL). This fixpoint characterizes a unique but possibly three-valued belief
set of an autoepistemic theory. It may be three-valued in the sense that for a
subclass of formulas F, the fixpoint may not specify whether F is believed or
not. The paper presents a constructive 3-valued semantics for autoepistemic
logic (AEL). We introduce a derivation operator and define the semantics as its
least fixpoint. The semantics is 3-valued in the sense that, for some formulas,
the least fixpoint does not specify whether they are believed or not. We show
that complete fixpoints of the derivation operator correspond to Moore's stable
expansions. In the case of modal representations of logic programs our least
fixpoint semantics expresses well-founded semantics or 3-valued Fitting-Kunen
semantics (depending on the embedding used). We show that, computationally, our
semantics is simpler than the semantics proposed by Moore (assuming that the
polynomial hierarchy does not collapse).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9901004</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9901004</id><created>1999-01-12</created><authors><author><keyname>Pestov</keyname><forenames>Vladimir</forenames></author></authors><title>On the geometry of similarity search: dimensionality curse and
  concentration of measure</title><categories>cs.IR cs.CG cs.DB cs.DS</categories><comments>7 pages, LaTeX 2e</comments><report-no>RP-99-01, Victoria University of Wellington, NZ</report-no><acm-class>H.3.3;H.2.4;F.2.2</acm-class><journal-ref>Information Processing Letters 73 (2000), 47-51.</journal-ref><abstract>  We suggest that the curse of dimensionality affecting the similarity-based
search in large datasets is a manifestation of the phenomenon of concentration
of measure on high-dimensional structures. We prove that, under certain
geometric assumptions on the query domain $\Omega$ and the dataset $X$, if
$\Omega$ satisfies the so-called concentration property, then for most query
points $x^\ast$ the ball of radius $(1+\e)d_X(x^\ast)$ centred at $x^\ast$
contains either all points of $X$ or else at least $C_1\exp(-C_2\e^2n)$ of
them. Here $d_X(x^\ast)$ is the distance from $x^\ast$ to the nearest neighbour
in $X$ and $n$ is the dimension of $\Omega$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9901005</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9901005</id><created>1999-01-13</created><authors><author><keyname>Wiebe</keyname><forenames>Janyce</forenames><affiliation>New Mexico State University</affiliation></author><author><keyname>O'Hara</keyname><forenames>Thomas P.</forenames><affiliation>New Mexico State University</affiliation></author><author><keyname>Ohrstrom-Sandgren</keyname><forenames>Thorsten</forenames><affiliation>New Mexico State University</affiliation></author><author><keyname>McKeever</keyname><forenames>Kenneth K.</forenames><affiliation>New Mexico State University</affiliation></author></authors><title>An Empirical Approach to Temporal Reference Resolution (journal version)</title><categories>cs.CL</categories><comments>Tar archive with LaTeX source, postscript figures, and style files</comments><acm-class>I.2.7</acm-class><journal-ref>Journal of Artificial Intelligence Research (JAIR), 9:247-293</journal-ref><abstract>  Scheduling dialogs, during which people negotiate the times of appointments,
are common in everyday life. This paper reports the results of an in-depth
empirical investigation of resolving explicit temporal references in scheduling
dialogs. There are four phases of this work: data annotation and evaluation,
model development, system implementation and evaluation, and model evaluation
and analysis. The system and model were developed primarily on one set of data,
and then applied later to a much more complex data set, to assess the
generalizability of the model for the task being performed. Many different
types of empirical methods are applied to pinpoint the strengths and weaknesses
of the approach. Detailed annotation instructions were developed and an
intercoder reliability study was performed, showing that naive annotators can
reliably perform the targeted annotations. A fully automatic system has been
developed and evaluated on unseen test data, with good results on both data
sets. We adopt a pure realization of a recency-based focus model to identify
precisely when it is and is not adequate for the task being addressed. In
addition to system results, an in-depth evaluation of the model itself is
presented, based on detailed manual annotations. The results are that few
errors occur specifically due to the model of focus being used, and the set of
anaphoric relations defined in the model are low in ambiguity for both data
sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9901006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9901006</id><created>1999-01-13</created><authors><author><keyname>Vlasov</keyname><forenames>Alexander Yu.</forenames><affiliation>FCR/IRH, St.-Petersburg, Russia</affiliation></author></authors><title>Object Oriented and Functional Programming for Symbolic Manipulation</title><categories>cs.SC cs.PL</categories><comments>6 pages, LaTeX, poster presentation at 5th International Workshop on
  New Computing Techniques in Physics Research (AIHENP'96),
  http://lapphp0.in2p3.fr/aihep/aihep96/abstracts/sm.html , EPFL Lausanne,
  (Switzerland), 2 - 6 Sep 1996; corrected due to referee suggestions (Nov 96),
  adjusted to LaTeX2e article class (Jan 99)</comments><acm-class>I.1.0; D.1.1; D.1.5; D.3.2</acm-class><abstract>  The advantages of mixed approach with using different kinds of programming
techniques for symbolic manipulation are discussed. The main purpose of
approach offered is merge the methods of object oriented programming that
convenient for presentation data and algorithms for user with advantages of
functional languages for data manipulation, internal presentation, and
portability of software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9901007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9901007</id><created>1999-01-15</created><authors><author><keyname>Vlasov</keyname><forenames>Alexander Yu.</forenames><affiliation>FCR/IRH, St.-Petersburg, Russia</affiliation></author></authors><title>Universal Object Oriented Languages and Computer Algebra</title><categories>cs.PL</categories><comments>5 pages LaTeX, (3 pages extended abstract of talk at International
  Conference: Computer Algebra in Scientific Computing, CASC'98, 20-24 Apr
  1998, St.-Petersburg, Russia; + 2 pages of comments to 3 slides included as 3
  separate ps files)</comments><acm-class>D.1.5; D.3.2</acm-class><journal-ref>Computer Algebra in Scientific Computing. Extended abstracts of
  the International Conference CASC-98, ed by N.N.Vasiliev -- St.-Petersburg,
  1998, pages 130 -- 132</journal-ref><abstract>  The universal object oriented languages made programming more simple and
efficient. In the article is considered possibilities of using similar methods
in computer algebra. A clear and powerful universal language is useful if
particular problem was not implemented in standard software packages like
REDUCE, MATHEMATICA, etc. and if the using of internal programming languages of
the packages looks not very efficient.
 Functional languages like LISP had some advantages and traditions for
algebraic and symbolic manipulations. Functional and object oriented
programming are not incompatible ones. An extension of the model of an object
for manipulation with pure functions and algebraic expressions is considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9901008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9901008</id><created>1999-01-16</created><authors><author><keyname>Fossgaard</keyname><forenames>Eirik</forenames></author></authors><title>Fast Computational Algorithms for the Discrete Wavelet Transform and
  Applications of Localized Orthonormal Bases in Signal Classification</title><categories>cs.MS cs.CE</categories><comments>127 pages, 25 figures, LaTeX2e</comments><report-no>82-90487-93-2</report-no><acm-class>F.2.1; G.4; I.5.4</acm-class><abstract>  We construct an algorithm for implementing the discrete wavelet transform by
means of matrices in SO_2(R) for orthonormal compactly supported wavelets and
matrices in SL_m(R), m &gt; = 2, for compactly supported biorthogonal wavelets. We
show that in 1 dimension the total operation count using this algorithm can be
reduced to about 50% of the conventional convolution and downsampling by
2-operation for both orthonormal and biorthogonal filters. In the special case
of biorthogonal symmetric odd-odd filters, we show an implementation yielding a
total operation count of about 38% of the conventional method. In 2 dimensions
we show an implementation of this algorithm yielding a reduction in the total
operation count of about 70% when the filters are orthonormal, a reduction of
about 62% for general biorthogonal filters, and a reduction of about 70% if the
filters are symmetric odd-odd length filters. We further extend these results
to 3 dimensions. We also show how the SO_2(R)-method for implementing the
discrete wavelet transform may be exploited to compute short FIR filters, and
we construct edge mappings where we try to improve upon the degree of
preservation of regularity in the conventional methods. We also consider a
two-class waveform discrimination problem. A statistical space-frequency
analysis is performed on a training data set using the LDB-algorithm of N.Saito
and R.Coifman. The success of the algorithm on this particular problem is
evaluated on a disjoint test data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9901009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9901009</id><created>1999-01-20</created><authors><author><keyname>Odlyzko</keyname><forenames>Andrew</forenames></author></authors><title>Competition and cooperation: Libraries and publishers in the transition
  to electronic scholarly journals</title><categories>cs.DL</categories><acm-class>H.3.7; K.4.1; K.4.4</acm-class><abstract>  The conversion of scholarly journals to digital format is proceeding rapidly,
especially for those from large commercial and learned society publishers. This
conversion offers the best hope for survival for such publishers. The infamous
&quot;journal crisis&quot; is more of a library cost crisis than a publisher pricing
problem, with internal library costs much higher than the amount spent on
purchasing books and journals. Therefore publishers may be able to retain or
even increase their revenues and profits, while at the same time providing a
superior service. To do this, they will have to take over many of the function
of libraries, and they can do that only in the digital domain. This paper
examines publishers' strategies, how they are likely to evolve, and how they
will affect libraries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9901010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9901010</id><created>1999-01-20</created><authors><author><keyname>Jiang</keyname><forenames>Tao</forenames><affiliation>McMaster U.</affiliation></author><author><keyname>Li</keyname><forenames>Ming</forenames><affiliation>U of Waterloo</affiliation></author><author><keyname>Vitanyi</keyname><forenames>Paul</forenames><affiliation>CWI and U of Amsterdam</affiliation></author></authors><title>Average-Case Complexity of Shellsort</title><categories>cs.DS cs.CC</categories><comments>11 pages. Submitted to ICALP'99</comments><acm-class>F.2.2; F.1.3</acm-class><abstract>  We prove a general lower bound on the average-case complexity of Shellsort:
the average number of data-movements (and comparisons) made by a $p$-pass
Shellsort for any incremental sequence is $\Omega (pn^{1 + 1/p)$ for all $p
\leq \log n$. Using similar arguments, we analyze the average-case complexity
of several other sorting algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9901011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9901011</id><created>1999-01-22</created><authors><author><keyname>Leiner</keyname><forenames>Barry M.</forenames></author><author><keyname>Cerf</keyname><forenames>Vinton G.</forenames></author><author><keyname>Clark</keyname><forenames>David D.</forenames></author><author><keyname>Kahn</keyname><forenames>Robert E.</forenames></author><author><keyname>Kleinrock</keyname><forenames>Leonard</forenames></author><author><keyname>Lynch</keyname><forenames>Daniel C.</forenames></author><author><keyname>Postel</keyname><forenames>Jon</forenames></author><author><keyname>Roberts</keyname><forenames>Larry G.</forenames></author><author><keyname>Wolf</keyname><forenames>Stephen</forenames></author></authors><title>A Brief History of the Internet</title><categories>cs.NI</categories><acm-class>K.2</acm-class><abstract>  The Internet has revolutionized the computer and communications world like
nothing before. The invention of the telegraph, telephone, radio, and computer
set the stage for this unprecedented integration of capabilities. The Internet
is at once a world-wide broadcasting capability, a mechanism for information
dissemination, and a medium for collaboration and interaction between
individuals and their computers without regard for geographic location.
  In this paper, several of us involved in the development and evolution of the
Internet share our views of its origins and history. This is intended to be a
brief, necessarily cursory and incomplete history. This history revolves around
four distinct aspects. There is the technological evolution that began with
early research on packet switching and the ARPANET (and related technologies),
and where current research continues to expand the horizons of the
infrastructure along several dimensions, such as scale, performance, and higher
level functionality. There is the operations and management aspect of a global
and complex operational infrastructure. There is the social aspect, which
resulted in a broad community of Internauts working together to create and
evolve the technology. And there is the commercialization aspect, resulting in
an extremely effective transition of research results into a broadly deployed
and available information infrastructure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9901012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9901012</id><created>1999-01-25</created><authors><author><keyname>Cholewinski</keyname><forenames>Pawel</forenames></author><author><keyname>Truszczynski</keyname><forenames>Miroslaw</forenames></author></authors><title>Extremal problems in logic programming and stable model computation</title><categories>cs.LO cs.AI</categories><acm-class>I.2.3;I.2.4;F.4.1</acm-class><journal-ref>Journal of Logic Programming, 38(1999), pp. 219-242</journal-ref><abstract>  We study the following problem: given a class of logic programs C, determine
the maximum number of stable models of a program from C. We establish the
maximum for the class of all logic programs with at most n clauses, and for the
class of all logic programs of size at most n. We also characterize the
programs for which the maxima are attained. We obtain similar results for the
class of all disjunctive logic programs with at most n clauses, each of length
at most m, and for the class of all disjunctive logic programs of size at most
n. Our results on logic programs have direct implication for the design of
algorithms to compute stable models. Several such algorithms, similar in spirit
to the Davis-Putnam procedure, are described in the paper. Our results imply
that there is an algorithm that finds all stable models of a program with n
clauses after considering the search space of size O(3^{n/3}) in the worst
case. Our results also provide some insights into the question of
representability of families of sets as families of stable models of logic
programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9901013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9901013</id><created>1999-01-26</created><authors><author><keyname>Maneewongvatana</keyname><forenames>Songrit</forenames></author><author><keyname>Mount</keyname><forenames>David M.</forenames></author></authors><title>Analysis of approximate nearest neighbor searching with clustered point
  sets</title><categories>cs.CG</categories><comments>20 pages, 8 figures. Presented at ALENEX '99, Baltimore, MD, Jan
  15-16, 1999</comments><acm-class>E.1; F.2.2</acm-class><abstract>  We present an empirical analysis of data structures for approximate nearest
neighbor searching. We compare the well-known optimized kd-tree splitting
method against two alternative splitting methods. The first, called the
sliding-midpoint method, which attempts to balance the goals of producing
subdivision cells of bounded aspect ratio, while not producing any empty cells.
The second, called the minimum-ambiguity method is a query-based approach. In
addition to the data points, it is also given a training set of query points
for preprocessing. It employs a simple greedy algorithm to select the splitting
plane that minimizes the average amount of ambiguity in the choice of the
nearest neighbor for the training points. We provide an empirical analysis
comparing these two methods against the optimized kd-tree construction for a
number of synthetically generated data and query sets. We demonstrate that for
clustered data and query sets, these algorithms can provide significant
improvements over the standard kd-tree construction for approximate nearest
neighbor searching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9901014</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9901014</id><created>1999-01-27</created><authors><author><keyname>Vitanyi</keyname><forenames>Paul</forenames><affiliation>CWI and University of Amsterdam</affiliation></author><author><keyname>Li</keyname><forenames>Ming</forenames><affiliation>University of Waterloo</affiliation></author></authors><title>Minimum Description Length Induction, Bayesianism, and Kolmogorov
  Complexity</title><categories>cs.LG cs.AI cs.CC cs.IT cs.LO math.IT math.PR physics.data-an</categories><comments>35 pages, Latex. Submitted IEEE Trans. Inform. Theory</comments><report-no>CWI Tech Report 1998</report-no><acm-class>E.4,F.2,H.3,I.2,I.5,I.7</acm-class><journal-ref>IEEE Transactions on Information Theory, 46:2(2000), 446-464</journal-ref><abstract>  The relationship between the Bayesian approach and the minimum description
length approach is established. We sharpen and clarify the general modeling
principles MDL and MML, abstracted as the ideal MDL principle and defined from
Bayes's rule by means of Kolmogorov complexity. The basic condition under which
the ideal principle should be applied is encapsulated as the Fundamental
Inequality, which in broad terms states that the principle is valid when the
data are random, relative to every contemplated hypothesis and also these
hypotheses are random relative to the (universal) prior. Basically, the ideal
principle states that the prior probability associated with the hypothesis
should be given by the algorithmic universal probability, and the sum of the
log universal probability of the model plus the log of the probability of the
data given the model should be minimized. If we restrict the model class to the
finite sets then application of the ideal principle turns into Kolmogorov's
minimal sufficient statistic. In general we show that data compression is
almost always the best strategy, both in hypothesis identification and
prediction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9901015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9901015</id><created>1999-01-27</created><authors><author><keyname>Watrous</keyname><forenames>John</forenames></author></authors><title>PSPACE has 2-round quantum interactive proof systems</title><categories>cs.CC quant-ph</categories><comments>13 pages</comments><acm-class>F.1.2;F.1.3</acm-class><abstract>  In this paper we consider quantum interactive proof systems, i.e.,
interactive proof systems in which the prover and verifier may perform quantum
computations and exchange quantum messages. It is proved that every language in
PSPACE has a quantum interactive proof system that requires only two rounds of
communication between the prover and verifier, while having exponentially small
(one-sided) probability of error. It follows that quantum interactive proof
systems are strictly more powerful than classical interactive proof systems in
the constant-round case unless the polynomial time hierarchy collapses to the
second level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9901016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9901016</id><created>1999-01-28</created><authors><author><keyname>Marek</keyname><forenames>Victor</forenames></author><author><keyname>Treur</keyname><forenames>Jan</forenames></author><author><keyname>Truszczynski</keyname><forenames>Miroslaw</forenames></author></authors><title>Representation Theory for Default Logic</title><categories>cs.LO cs.AI</categories><comments>Annals of Mathematics and Artificial Intelligence, 21 (1997), pp.
  343-358</comments><acm-class>I.2.4, F.4.1, I.2.3</acm-class><abstract>  Default logic can be regarded as a mechanism to represent families of belief
sets of a reasoning agent. As such, it is inherently second-order. In this
paper, we study the problem of representability of a family of theories as the
set of extensions of a default theory. We give a complete solution to the
representability by means of normal default theories. We obtain partial results
on representability by arbitrary default theories. We construct examples of
denumerable families of non-including theories that are not representable. We
also study the concept of equivalence between default theories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902001</id><created>1999-01-31</created><authors><author><keyname>Krotov</keyname><forenames>Alexander</forenames><affiliation>Department of Computer Science, University of Sheffield, UK</affiliation></author><author><keyname>Hepple</keyname><forenames>Mark</forenames><affiliation>Department of Computer Science, University of Sheffield, UK</affiliation></author><author><keyname>Gaizauskas</keyname><forenames>Robert</forenames><affiliation>Department of Computer Science, University of Sheffield, UK</affiliation></author><author><keyname>Wilks</keyname><forenames>Yorick</forenames><affiliation>Department of Computer Science, University of Sheffield, UK</affiliation></author></authors><title>Compacting the Penn Treebank Grammar</title><categories>cs.CL</categories><comments>5 pages, 2 figures</comments><acm-class>I.2.7</acm-class><journal-ref>In Proceedings of COLING-98 (Montreal), pages 699-703</journal-ref><abstract>  Treebanks, such as the Penn Treebank (PTB), offer a simple approach to
obtaining a broad coverage grammar: one can simply read the grammar off the
parse trees in the treebank. While such a grammar is easy to obtain, a
square-root rate of growth of the rule set with corpus size suggests that the
derived grammar is far from complete and that much more treebanked text would
be required to obtain a complete grammar, if one exists at some limit. However,
we offer an alternative explanation in terms of the underspecification of
structures within the treebank. This hypothesis is explored by applying an
algorithm to compact the derived grammar by eliminating redundant rules --
rules whose right hand sides can be parsed by other rules. The size of the
resulting compacted grammar, which is significantly less than that of the full
treebank grammar, is shown to approach a limit. However, such a compacted
grammar does not yield very good performance figures. A version of the
compaction algorithm taking rule probabilities into account is proposed, which
is argued to be more linguistically motivated. Combined with simple
thresholding, this method can be used to give a 58% reduction in grammar size
without significant change in parsing performance, and can produce a 69%
reduction with some gain in recall, but a loss in precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902002</id><created>1999-02-01</created><authors><author><keyname>Chen</keyname><forenames>Kuang-hua</forenames></author></authors><title>Automatic Identification of Subjects for Textual Documents in Digital
  Libraries</title><categories>cs.DL cs.CL</categories><comments>7 pages, 6 tables</comments><acm-class>H.3.1; H.3.7; I.2.7</acm-class><abstract>  The amount of electronic documents in the Internet grows very quickly. How to
effectively identify subjects for documents becomes an important issue. In
past, the researches focus on the behavior of nouns in documents. Although
subjects are composed of nouns, the constituents that determine which nouns are
subjects are not only nouns. Based on the assumption that texts are
well-organized and event-driven, nouns and verbs together contribute the
process of subject identification. This paper considers four factors: 1) word
importance, 2) word frequency, 3) word co-occurrence, and 4) word distance and
proposes a model to identify subjects for textual documents. The preliminary
experiments show that the performance of the proposed model is close to that of
human beings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902003</id><created>1999-02-02</created><authors><author><keyname>Morgan</keyname><forenames>Eric Lease</forenames></author></authors><title>MyLibrary: A Model for Implementing a User-centered, Customizable
  Interface to a Library's Collection of Information Resources</title><categories>cs.DL</categories><comments>10 pages, 6 figures</comments><acm-class>H.1; H.5.2; H.5.3; J.1</acm-class><abstract>  The paper describes an extensible model for implementing a user-centered,
customizable interface to a library's collection of information resources. This
model, called MyLibrary, integrates the principles of librarianship
(collection, organization, dissemination, and evaluation) with globally
networked computing resources creating a dynamic, customer-driven front-end to
any library's set of materials. The model supports a framework for libraries to
provide enhanced access to local and remote sets of data, information, and
knowledge. At the same, the model does not overwhelm its users with too much
information because the users control exactly how much information is displayed
to them at any given time. The model is active and not passive; direct human
interaction, computer mediated guidance and communication technologies, as well
as current awareness services all play indispensable roles in this system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902004</id><created>1999-02-02</created><authors><author><keyname>Morgan</keyname><forenames>Eric Lease</forenames></author></authors><title>The Alex Catalogue, A Collection of Digital Texts with Automatic Methods
  for Acquisition and Cataloging, User-Defined Typography, Cross-searching of
  Indexed Content, and a Sense of Community</title><categories>cs.DL</categories><comments>9 pages, 2 figures</comments><acm-class>H.3; H.5.2; J.1</acm-class><abstract>  This paper describes the Alex Catalogue of Electronic Texts, the only
Internet-accessible collection of digital documents allowing the user to 1)
dynamically create customized, typographically readable documents on demand, 2)
search the content of one or more documents from the collection simultaneously,
3) create sets of documents from the collection for review and annotation, and
4) publish these sets of annotated documents in turn fostering a sense of
community around the Catalogue. More than a just a collection of links that
will break over time, Alex is an archive of electronic texts providing
unprecedented access to its content and features allowing it to meet the needs
of a wide variety of users and settings. Furthermore, the process of
maintaining the Catalogue is streamlined with tools for automatic acquisition
and cataloging making it possible to sustain the service with a minimum of
personnel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902005</id><created>1999-02-02</created><authors><author><keyname>Buhrman</keyname><forenames>Harry</forenames><affiliation>CWI</affiliation></author><author><keyname>Franklin</keyname><forenames>Matthew</forenames><affiliation>Xerox PARC</affiliation></author><author><keyname>Garay</keyname><forenames>Juan A.</forenames><affiliation>Bell Labs - Lucent Technologies</affiliation></author><author><keyname>Hoepman</keyname><forenames>Jaap-Henk</forenames><affiliation>University Twente</affiliation></author><author><keyname>Tromp</keyname><forenames>John</forenames><affiliation>CWI</affiliation></author><author><keyname>Vitanyi</keyname><forenames>Paul</forenames><affiliation>CWI and University of Amsterdam</affiliation></author></authors><title>Mutual Search</title><categories>cs.DS cs.CC cs.DB cs.DC cs.DM cs.IR</categories><comments>18 pages, Latex, 5 figures, J. Assoc. Comp. Mach., To appear</comments><acm-class>F.2,C.2,E,1,D.4.4</acm-class><abstract>  We introduce a search problem called ``mutual search'' where $k$ \agents,
arbitrarily distributed over $n$ sites, are required to locate one another by
posing queries of the form ``Anybody at site $i$?''. We ask for the least
number of queries that is necessary and sufficient. For the case of two \agents
using deterministic protocols we obtain the following worst-case results: In an
oblivious setting (where all pre-planned queries are executed) there is no
savings: $n-1$ queries are required and are sufficient. In a nonoblivious
setting we can exploit the paradigm of ``no news is also news'' to obtain
significant savings: in the synchronous case $0.586n$ queries suffice and
$0.536n$ queries are required; in the asynchronous case $0.896n$ queries
suffice and a fortiori 0.536 queries are required; for $o(\sqrt{n})$ \agents
using a deterministic protocol less than $n$ queries suffice; there is a simple
randomized protocol for two \agents with worst-case expected $0.5n$ queries and
all randomized protocols require at least $0.125n$ worst-case expected queries.
The graph-theoretic framework we formulate for expressing and analyzing
algorithms for this problem may be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902006</id><created>1999-02-02</created><authors><author><keyname>Vitanyi</keyname><forenames>Paul</forenames></author></authors><title>A Discipline of Evolutionary Programming</title><categories>cs.NE cs.AI cs.CC cs.DS cs.LG cs.MA</categories><comments>25 pages, LaTeX source, Theoretical Computer Science, To appear</comments><acm-class>I.2,E.1,F.1</acm-class><journal-ref>Theoret. Comp. Sci., 241:1-2 (2000), 3--23.</journal-ref><abstract>  Genetic fitness optimization using small populations or small population
updates across generations generally suffers from randomly diverging
evolutions. We propose a notion of highly probable fitness optimization through
feasible evolutionary computing runs on small size populations. Based on
rapidly mixing Markov chains, the approach pertains to most types of
evolutionary genetic algorithms, genetic programming and the like. We establish
that for systems having associated rapidly mixing Markov chains and appropriate
stationary distributions the new method finds optimal programs (individuals)
with probability almost 1. To make the method useful would require a structured
design methodology where the development of the program and the guarantee of
the rapidly mixing property go hand in hand. We analyze a simple example to
show that the method is implementable. More significant examples require
theoretical advances, for example with respect to the Metropolis filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902007</id><created>1999-02-04</created><authors><author><keyname>Witten</keyname><forenames>Ian H.</forenames></author><author><keyname>Paynter</keyname><forenames>Gordon W.</forenames></author><author><keyname>Frank</keyname><forenames>Eibe</forenames></author><author><keyname>Gutwin</keyname><forenames>Carl</forenames></author><author><keyname>Nevill-Manning</keyname><forenames>Craig G.</forenames></author></authors><title>KEA: Practical Automatic Keyphrase Extraction</title><categories>cs.DL</categories><comments>9 pages</comments><acm-class>H.3.7</acm-class><abstract>  Keyphrases provide semantic metadata that summarize and characterize
documents. This paper describes Kea, an algorithm for automatically extracting
keyphrases from text. Kea identifies candidate keyphrases using lexical
methods, calculates feature values for each candidate, and uses a
machine-learning algorithm to predict which candidates are good keyphrases.
The machine learning scheme first builds a prediction model using training
documents with known keyphrases, and then uses the model to find keyphrases in
new documents. We use a large test corpus to evaluate Kea's effectiveness in
terms of how many author-assigned keyphrases are correctly identified. The
system is simple, robust, and publicly available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902008</id><created>1999-02-05</created><authors><author><keyname>Winter</keyname><forenames>Mario</forenames></author></authors><title>Managing Object-Oriented Integration and Regression Testing</title><categories>cs.SE</categories><comments>Proc. 6th euroSTAR, Munich, 30 November-4 December 1998</comments><acm-class>D.2.5; D.2.9</acm-class><abstract>  Systematic testing of object-oriented software turned out to be much more
complex than testing conventional software. Especially the highly incremental
and iterative development cycle demands both many more changes and partially
implemented resp. re-implemented classes. Much more integration and regression
testing has to be done to reach stable stages during the development. In this
presentation we propose a diagram capturing all possible dependencies and
interactions in an object-oriented program. Then we give algorithms and
coverage criteria to identify integration resp. regression test strategys and
all test cases to be executed after some implementation resp. modification
activities. Finally, we summarize some practical experiences and heuristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902009</id><created>1999-02-05</created><authors><author><keyname>Hartley</keyname><forenames>Roger T.</forenames></author><author><keyname>Crumpton</keyname><forenames>Kathleen</forenames></author></authors><title>Quality of OCR for Degraded Text Images</title><categories>cs.DL</categories><comments>7 pages</comments><acm-class>I.7.5</acm-class><abstract>  Commercial OCR packages work best with high-quality scanned images. They
often produce poor results when the image is degraded, either because the
original itself was poor quality, or because of excessive photocopying. The
ability to predict the word failure rate of OCR from a statistical analysis of
the image can help in making decisions in the trade-off between the success
rate of OCR and the cost of human correction of errors. This paper describes an
investigation of OCR of degraded text images using a standard OCR engine (Adobe
Capture). The documents were selected from those in the archive at Los Alamos
National Laboratory. By introducing noise in a controlled manner into perfect
documents, we show how the quality of OCR can be predicted from the nature of
the noise. The preliminary results show that a simple noise model can give good
prediction of the number of OCR errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902010</id><created>1999-02-08</created><authors><author><keyname>Smith</keyname><forenames>Adam</forenames></author><author><keyname>Stiglic</keyname><forenames>Anton</forenames></author></authors><title>Multiparty computation unconditionally secure against Q^2 adversary
  structures</title><categories>cs.CR</categories><comments>11 pages. McGill University School of Computer Science tech. report</comments><report-no>SOCS-98.2</report-no><acm-class>F.m</acm-class><abstract>  We present here a generalization of the work done by Rabin and Ben-Or. We
give a protocol for multiparty computation which tolerates any Q^2 active
adversary structure based on the existence of a broadcast channel, secure
communication between each pair of participants, and a monotone span program
with multiplication tolerating the structure. The secrecy achieved is
unconditional although we allow an exponentially small probability of error.
This is possible due to a protocol for computing the product of two values
already shared by means of a homomorphic commitment scheme which appeared
originally in a paper of Chaum, Evertse and van de Graaf.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902011</id><created>1999-02-07</created><authors><author><keyname>Mooney</keyname><forenames>Raymond J.</forenames><affiliation>University of Texas at Austin</affiliation></author><author><keyname>Roy</keyname><forenames>Loriene</forenames><affiliation>University of Texas at Austin</affiliation></author></authors><title>Content-Based Book Recommending Using Learning for Text Categorization</title><categories>cs.DL</categories><comments>8 pages, 3 figures, Submission to Fourth ACM Conference on Digital
  Libraries</comments><acm-class>H.3.7; I.2.6; I.2.7</acm-class><abstract>  Recommender systems improve access to relevant products and information by
making personalized suggestions based on previous examples of a user's likes
and dislikes. Most existing recommender systems use social filtering methods
that base recommendations on other users' preferences. By contrast,
content-based methods use information about an item itself to make suggestions.
This approach has the advantage of being able to recommended previously unrated
items to users with unique interests and to provide explanations for its
recommendations. We describe a content-based book recommending system that
utilizes information extraction and a machine-learning algorithm for text
categorization. Initial experimental results demonstrate that this approach can
produce accurate recommendations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902012</id><created>1999-02-07</created><authors><author><keyname>McGrath</keyname><forenames>Robert E.</forenames></author><author><keyname>Futrelle</keyname><forenames>Joe</forenames></author><author><keyname>Plante</keyname><forenames>Ray</forenames></author><author><keyname>Guillaume</keyname><forenames>Damien</forenames></author></authors><title>Digital Library Technology for Locating and Accessing Scientific Data</title><categories>cs.DL</categories><acm-class>H.3.7</acm-class><abstract>  In this paper we describe our efforts to bring scientific data into the
digital library. This has required extension of the standard WWW, and also the
extension of metadata standards far beyond the Dublin Core. Our system
demonstrates this technology for real scientific data from astronomy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902013</id><created>1999-02-08</created><authors><author><keyname>France</keyname><forenames>Robert K.</forenames></author><author><keyname>Nowell</keyname><forenames>Lucy Terry</forenames></author><author><keyname>Fox</keyname><forenames>Edward A.</forenames></author><author><keyname>Saad</keyname><forenames>Rani A.</forenames></author><author><keyname>Zhao</keyname><forenames>Jianxin</forenames></author></authors><title>Use and usability in a digital library search system</title><categories>cs.DL</categories><comments>System paper</comments><acm-class>H.3.7</acm-class><abstract>  Digital libraries must reach out to users from all walks of life, serving
information needs at all levels. To do this, they must attain high standards of
usability over an extremely broad audience. This paper details the evolution of
one important digital library component as it has grown in functionality and
usefulness over several years of use by a live, unrestricted community. Central
to its evolution have been user studies, analysis of use patterns, and
formative usability evaluation. We extrapolate that all three components are
necessary in the production of successful digital library systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902014</id><created>1999-02-08</created><authors><author><keyname>Leiner</keyname><forenames>Barry M.</forenames></author><author><keyname>Drozdova</keyname><forenames>Ekaterina A.</forenames></author></authors><title>Proceedings from Critical Infrastructure: The Path Ahead (XIWT Symposium
  on Cross-Industry Activities for Information Infrastructure Robustness)</title><categories>cs.NI</categories><acm-class>C.2.0</acm-class><abstract>  The Cross-Industry Working Team (XIWT), with the support of the Stanford
University Consortium for Research on Information Security and Policy (CRISP),
sponsored a symposium on cross-industry activities aimed at improving the
reliability, dependability, and robustness of the information infrastructure.
Held 3-4 November 1998 in Crystal City, Virginia, the symposium engaged
representatives from industry, academia, and government in discussion of
current and potential cross-industry, cross-sector activities including
information exchange, collaborative operations, and cooperative research and
development. This proceedings summarizes the discussions and results of the
meeting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902015</id><created>1999-02-08</created><authors><author><keyname>Chevalier</keyname><forenames>Franck</forenames></author><author><keyname>Harle</keyname><forenames>David</forenames></author><author><keyname>Smith</keyname><forenames>Geoffrey</forenames></author></authors><title>Resource Discovery in Trilogy</title><categories>cs.DL cs.AI cs.MA</categories><comments>9 pages, 5 figures, DL'99 conference</comments><report-no>STRA1</report-no><acm-class>H.3.4;I.2.0</acm-class><abstract>  Trilogy is a collaborative project whose key aim is the development of an
integrated virtual laboratory to support research training within each
institution and collaborative projects between the partners. In this paper, the
architecture and underpinning platform of the system is described with
particular emphasis being placed on the structure and the integration of the
distributed database. A key element is the ontology that provides the
multi-agent system with a conceptualisation specification of the domain; this
ontology is explained, accompanied by a discussion how such a system is
integrated and used within the virtual laboratory. Although in this paper,
Telecommunications and in particular Broadband networks are used as exemplars,
the underlying system principles are applicable to any domain where a
combination of experimental and literature-based resources are required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902016</id><created>1999-02-08</created><authors><author><keyname>Hu</keyname><forenames>Michael J.</forenames></author><author><keyname>Jian</keyname><forenames>Ye</forenames></author></authors><title>Multimedia Description Framework (MDF) for Content Description of
  Audio/Video Documents</title><categories>cs.DL</categories><comments>20 pages</comments><acm-class>H3.3; H3.7</acm-class><abstract>  MPEG is undertaking a new initiative to standardize content description of
audio and video data/documents. When it is finalized in 2001, MPEG-7 is
expected to provide standardized description schemes for concise and
unambiguous content description of data/documents of complex media types.
Meanwhile, other meta-data or description schemes, such as Dublin Core, XML,
etc., are becoming popular in different application domains. In this paper, we
propose the Multimedia Description Framework (MDF), which is designated to
accommodate multiple description (meta-data) schemes, both MPEG-7 and
non-MPEG-7, into integrated architecture. We will use examples to show how MDF
description makes use of combined strength of different description schemes to
enhance its expression power and flexibility. We conclude the paper with
discussion of using MDF description of a movie video to search/retrieve
required scene clips from the movie, on the MDF prototype system we have
implemented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902017</id><created>1999-02-08</created><updated>1999-02-11</updated><authors><author><keyname>Available</keyname><forenames>Not</forenames></author></authors><title>Not Available</title><categories>cs.DL cs.DB</categories><acm-class>Not Available</acm-class><abstract>  withdrawn by author
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902018</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902018</id><created>1999-02-08</created><authors><author><keyname>Lin</keyname><forenames>Yong</forenames></author><author><keyname>Xu</keyname><forenames>Jian</forenames></author><author><keyname>Lim</keyname><forenames>Ee-Peng</forenames></author><author><keyname>Ng</keyname><forenames>Wee-Keong</forenames></author></authors><title>ZBroker: A Query Routing Broker for Z39.50 Databases</title><categories>cs.DL cs.DB</categories><comments>10 pages, 8 figures</comments><acm-class>H3.3</acm-class><abstract>  A query routing broker is a software agent that determines from a large set
of accessing information sources the ones most relevant to a user's information
need. As the number of information sources on the Internet increases
dramatically, future users will have to rely on query routing brokers to decide
a small number of information sources to query without incurring too much query
processing overheads. In this paper, we describe a query routing broker known
as ZBroker developed for bibliographic database servers that support the Z39.50
protocol. ZBroker samples the content of each bibliographic database by using
training queries and their results, and summarizes the bibliographic database
content into a knowledge base. We present the design and implementation of
ZBroker and describe its Web-based user interface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902019</id><created>1999-02-08</created><authors><author><keyname>Ding</keyname><forenames>Wei</forenames></author><author><keyname>Marchionini</keyname><forenames>Gary</forenames></author><author><keyname>Soergel</keyname><forenames>Dagobert</forenames></author></authors><title>Multimodal Surrogates for Video Browsing</title><categories>cs.DL cs.HC</categories><comments>11 pages</comments><acm-class>H5.1; H3.1</acm-class><abstract>  Three types of video surrogates - visual (keyframes), verbal
(keywords/phrases), and combination of the two - were designed and studied in a
qualitative investigation of user cognitive processes. The results favor the
combined surrogates in which verbal information and images reinforce each
other, lead to better comprehension, and may actually require less processing
time. The results also highlight image features users found most helpful. These
findings will inform the interface design and video representation for video
retrieval and browsing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902020</id><created>1999-02-09</created><authors><author><keyname>Dushay</keyname><forenames>Naomi</forenames></author><author><keyname>French</keyname><forenames>James C.</forenames></author><author><keyname>Lagoze</keyname><forenames>Carl</forenames></author></authors><title>Using Query Mediators for Distributed Searching in Federated Digital
  Libraries</title><categories>cs.DL</categories><comments>Submission to ACM DL99 Conference</comments><acm-class>H.3.7</acm-class><abstract>  We describe an architecture and investigate the characteristics of
distributed searching in federated digital libraries. We introduce the notion
of a query mediator as a digital library service responsible for selecting
among available search engines, routing queries to those search engines, and
aggregating results. We examine operational data from the NCSTRL distributed
digital library that reveals a number of characteristics of distributed
resource discovery. These include availability and response time of indexers
and the distinction between the query mediator view of these characteristics
and the indexer view.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902021</id><created>1999-02-10</created><authors><author><keyname>Song</keyname><forenames>Sa-Kwang</forenames></author><author><keyname>Myaeng</keyname><forenames>Sung Hyon</forenames></author></authors><title>Visualization of Retrieved Documents using a Presentation Server</title><categories>cs.DL cs.IR</categories><comments>13 pages</comments><acm-class>H.3.3; H.3.4</acm-class><abstract>  In any search-based digital library (DL) systems dealing with a non-trivial
number of documents, users are often required to go through a long list of
short document descriptions in order to identify what they are looking for. To
tackle the problem, a variety of document organization algorithms and/or
visualization techniques have been used to guide users in selecting relevant
documents. Since these techniques require heavy computations, however, we
developed a presentation server designed to serve as an intermediary between
retrieval servers and clients equipped with a visualization interface. In
addition, we designed our own visual interface by which users can view a set of
documents from different perspectives through layers of document maps. We
finally ran experiments to show that the visual interface, in conjunction with
the presentation server, indeed helps users in selecting relevant documents
from the retrieval results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902022</id><created>1999-02-10</created><authors><author><keyname>Schiel</keyname><forenames>Ulrich</forenames></author><author><keyname>de Souza</keyname><forenames>Ianna M. Sodre Ferreira</forenames></author><author><keyname>Ferneda</keyname><forenames>Edberto</forenames></author></authors><title>Semi-Automatic Indexing of Multilingual Documents</title><categories>cs.DL</categories><comments>9 pages. Submission to the Fourth ACM Conference on Digital Libraries</comments><acm-class>H.3.1; H.3.3</acm-class><abstract>  With the growing significance of digital libraries and the Internet, more and
more electronic texts become accessible to a wide and geographically disperse
public. This requires adequate tools to facilitate indexing, storage, and
retrieval of documents written in different languages. We present a method for
semi-automatic indexing of electronic documents and construction of a
multilingual thesaurus, which can be used for query formulation and information
retrieval. We use special dictionaries and user interaction in order to solve
ambiguities and find adequate canonical terms in the language and adequate
abstract language-independent terms. The abstract thesaurus is updated
incrementally by new indexed documents and is used to search document
concerning terms in a query to the document base.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902023</id><created>1999-02-11</created><authors><author><keyname>Wechsler</keyname><forenames>Martin</forenames></author><author><keyname>Schauble</keyname><forenames>Peter</forenames></author></authors><title>A New Ranking Principle for Multimedia Information Retrieval</title><categories>cs.DL</categories><comments>submission for DL'99. conference compliant format (two-column, etc.)
  will be produced later</comments><acm-class>H.3.3;H.3.4;H.3.7;H.2.4;C.2.4</acm-class><abstract>  A theoretic framework for multimedia information retrieval is introduced
which guarantees optimal retrieval effectiveness. In particular, a Ranking
Principle for Distributed Multimedia-Documents (RPDM) is described together
with an algorithm that satisfies this principle. Finally, the RPDM is shown to
be a generalization of the Probability Ranking principle (PRP) which guarantees
optimal retrieval effectiveness in the case of text document retrieval. The PRP
justifies theoretically the relevance ranking adopted by modern search engines.
In contrast to the classical PRP, the new RPDM takes into account transmission
and inspection time, and most importantly, aspectual recall rather than simple
recall.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902024</id><created>1999-02-11</created><authors><author><keyname>Bogdanov</keyname><forenames>Alexander V.</forenames></author><author><keyname>Bykov</keyname><forenames>Nick Yu.</forenames></author><author><keyname>Grishin</keyname><forenames>Igor A.</forenames></author><author><keyname>Khanlarov</keyname><forenames>Gregory O.</forenames></author><author><keyname>Lukianov</keyname><forenames>German A.</forenames></author><author><keyname>Zakharov</keyname><forenames>Vladimir V.</forenames></author></authors><title>Algorithms of Two-Level Parallelization for DSMC of Unsteady Flows in
  Molecular Gasdynamics</title><categories>cs.CE cs.PF</categories><comments>20 pages, 17 postscript figures Submitted to the conference HPCN
  Europe 99</comments><report-no>10-98</report-no><acm-class>G.1.0;G.3;I.6.8</acm-class><abstract>  The general scheme of two-level parallelization (TLP) for direct simulation
Monte Carlo of unsteady gas flows on shared memory multiprocessor computers has
been described. The high efficient algorithm of parallel independent runs is
used on the first level. The data parallelization is employed for the second
one. Two versions of TLP algorithm are elaborated with static and dynamic load
balancing. The method of dynamic processor reallocation is used for dynamic
load balancing. Two gasdynamic unsteady problems were used to study speedup and
efficiency of the algorithms. The conditions of efficient application field for
the algorithms have been determined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902025</id><created>1999-02-12</created><authors><author><keyname>Ohlsson</keyname><forenames>Mattias</forenames></author><author><keyname>Peterson</keyname><forenames>Carsten</forenames></author><author><keyname>S&#xf6;derberg</keyname><forenames>Bo</forenames></author></authors><title>An Efficient Mean Field Approach to the Set Covering Problem</title><categories>cs.NE</categories><comments>17 pages, 2 figures</comments><acm-class>G.1.6</acm-class><abstract>  A mean field feedback artificial neural network algorithm is developed and
explored for the set covering problem. A convenient encoding of the inequality
constraints is achieved by means of a multilinear penalty function. An
approximate energy minimum is obtained by iterating a set of mean field
equations, in combination with annealing. The approach is numerically tested
against a set of publicly available test problems with sizes ranging up to
5x10^3 rows and 10^6 columns. When comparing the performance with exact results
for sizes where these are available, the approach yields results within a few
percent from the optimal solutions. Comparisons with other approximate methods
also come out well, in particular given the very low CPU consumption required
-- typically a few seconds. Arbitrary problems can be processed using the
algorithm via a public domain server.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902026</id><created>1999-02-14</created><authors><author><keyname>Ambainis</keyname><forenames>Andris</forenames></author></authors><title>Probabilistic Inductive Inference:a Survey</title><categories>cs.LG cs.CC cs.LO math.LO</categories><comments>16 pages, to appear in Theoretical Computer Science</comments><acm-class>F.1.1., F.4.1., I.2.3., I.2.6</acm-class><abstract>  Inductive inference is a recursion-theoretic theory of learning, first
developed by E. M. Gold (1967). This paper surveys developments in
probabilistic inductive inference. We mainly focus on finite inference of
recursive functions, since this simple paradigm has produced the most
interesting (and most complex) results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902027</id><created>1999-02-16</created><authors><author><keyname>Roberts</keyname><forenames>Mark D.</forenames></author></authors><title>Autocatalytic Theory of Meaning</title><categories>cs.CL adap-org nlin.AO</categories><comments>4 pages, no diagrams, LaTex2e</comments><acm-class>I.2.6; J.4; I.2.7</acm-class><journal-ref>PSYCHOLOQUY.99.10.014</journal-ref><abstract>  Recently it has been argued that autocatalytic theory could be applied to the
origin of culture. Here possible application to a theory of meaning in the
philosophy of language, called radical interpretation, is commented upon and
compared to previous applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902028</id><created>1999-02-24</created><updated>1999-02-25</updated><authors><author><keyname>Byrd</keyname><forenames>Donald</forenames></author></authors><title>A Scrollbar-based Visualization for Document Navigation</title><categories>cs.IR cs.HC</categories><comments>2 figures, about 12 pages; corrected references, added librarians'
  Comments on the visualization</comments><report-no>IR-163</report-no><acm-class>H5.2; H3.3; I7.2; H3.7</acm-class><abstract>  We are interested in questions of improving user control in best-match
text-retrieval systems, specifically questions as to whether simple
visualizations that nonetheless go beyond the minimal ones generally available
can significantly help users. Recently, we have been investigating ways to help
users decide-given a set of documents retrieved by a query-which documents and
passages are worth closer examination. We built a document viewer incorporating
a visualization centered around a novel content-displaying scrollbar and color
term highlighting, and studied whether the visualization is helpful to
non-expert searchers. Participants' reaction to the visualization was very
positive, while the objective results were inconclusive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902029</id><created>1999-02-25</created><authors><author><keyname>Wilks</keyname><forenames>Yorick</forenames></author></authors><title>The &quot;Fodor&quot;-FODOR fallacy bites back</title><categories>cs.CL</categories><report-no>cs-98-13</report-no><acm-class>I.2</acm-class><abstract>  The paper argues that Fodor and Lepore are misguided in their attack on
Pustejovsky's Generative Lexicon, largely because their argument rests on a
traditional, but implausible and discredited, view of the lexicon on which it
is effectively empty of content, a view that stands in the long line of
explaining word meaning (a) by ostension and then (b) explaining it by means of
a vacuous symbol in a lexicon, often the word itself after typographic
transmogrification. (a) and (b) both share the wrong belief that to a word must
correspond a simple entity that is its meaning. I then turn to the semantic
rules that Pustejovsky uses and argue first that, although they have novel
features, they are in a well-established Artificial Intelligence tradition of
explaining meaning by reference to structures that mention other structures
assigned to words that may occur in close proximity to the first. It is argued
that Fodor and Lepore's view that there cannot be such rules is without
foundation, and indeed systems using such rules have proved their practical
worth in computational systems. Their justification descends from line of
argument, whose high points were probably Wittgenstein and Quine that meaning
is not to be understood by simple links to the world, ostensive or otherwise,
but by the relationship of whole cultural representational structures to each
other and to the world as a whole.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9902030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9902030</id><created>1999-02-25</created><authors><author><keyname>Wilks</keyname><forenames>Yorick</forenames></author></authors><title>Is Word Sense Disambiguation just one more NLP task?</title><categories>cs.CL</categories><report-no>cs-98-12</report-no><acm-class>I.2</acm-class><abstract>  This paper compares the tasks of part-of-speech (POS) tagging and
word-sense-tagging or disambiguation (WSD), and argues that the tasks are not
related by fineness of grain or anything like that, but are quite different
kinds of task, particularly becuase there is nothing in POS corresponding to
sense novelty. The paper also argues for the reintegration of sub-tasks that
are being separated for evaluation
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9903001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9903001</id><created>1999-02-28</created><authors><author><keyname>Milson</keyname><forenames>R.</forenames></author></authors><title>Introduction to the RSA algorithm and modular arithmetic</title><categories>cs.CR</categories><comments>Notes for the Dalhousie Integrated Science Program</comments><acm-class>E.2; G.0</acm-class><abstract>  These notes are a brief introduction to the RSA algorithm and modular
arithmetic. They are intended for an undergraduate audience.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9903002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9903002</id><created>1999-03-01</created><authors><author><keyname>Dinesh</keyname><forenames>T. B.</forenames><affiliation>Academic Systems Corp.</affiliation></author><author><keyname>Haveraaen</keyname><forenames>M.</forenames><affiliation>UiB</affiliation></author><author><keyname>Heering</keyname><forenames>J.</forenames><affiliation>CWI</affiliation></author></authors><title>An Algebraic Programming Style for Numerical Software and its
  Optimization</title><categories>cs.SE cs.AI cs.CE cs.MS</categories><comments>19 pages. Submitted to Scientific Programming</comments><report-no>SEN-R9844 (CWI, Amsterdam)</report-no><acm-class>D.1.5; D.2.2; J.2</acm-class><journal-ref>Scientific Programming 8 (2000) 4 pages 247-259 (Special issue on
  coordinate-free numerics)</journal-ref><abstract>  The abstract mathematical theory of partial differential equations (PDEs) is
formulated in terms of manifolds, scalar fields, tensors, and the like, but
these algebraic structures are hardly recognizable in actual PDE solvers. The
general aim of the Sophus programming style is to bridge the gap between theory
and practice in the domain of PDE solvers. Its main ingredients are a library
of abstract datatypes corresponding to the algebraic structures used in the
mathematical theory and an algebraic expression style similar to the expression
style used in the mathematical theory. Because of its emphasis on abstract
datatypes, Sophus is most naturally combined with object-oriented languages or
other languages supporting abstract datatypes. The resulting source code
patterns are beyond the scope of current compiler optimizations, but are
sufficiently specific for a dedicated source-to-source optimizer. The limited,
domain-specific, character of Sophus is the key to success here. This kind of
optimization has been tested on computationally intensive Sophus style code
with promising results. The general approach may be useful for other styles and
in other application domains as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9903003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9903003</id><created>1999-03-02</created><authors><author><keyname>Bird</keyname><forenames>Steven</forenames><affiliation>University of Pennsylvania</affiliation></author><author><keyname>Liberman</keyname><forenames>Mark</forenames><affiliation>University of Pennsylvania</affiliation></author></authors><title>A Formal Framework for Linguistic Annotation</title><categories>cs.CL</categories><comments>49 pages</comments><report-no>Tech Report MS-CIS-99-01, Dept of Computer and Information Science</report-no><acm-class>A.1; E.2; H.2.1; H.3.3; H.3.7; I.2.7</acm-class><abstract>  `Linguistic annotation' covers any descriptive or analytic notations applied
to raw language data. The basic data may be in the form of time functions --
audio, video and/or physiological recordings -- or it may be textual. The added
notations may include transcriptions of all sorts (from phonetic features to
discourse structures), part-of-speech and sense tagging, syntactic analysis,
`named entity' identification, co-reference annotation, and so on. While there
are several ongoing efforts to provide formats and tools for such annotations
and to publish annotated linguistic databases, the lack of widely accepted
standards is becoming a critical problem. Proposed standards, to the extent
they exist, have focussed on file formats. This paper focuses instead on the
logical structure of linguistic annotations. We survey a wide variety of
existing annotation formats and demonstrate a common conceptual core, the
annotation graph. This provides a formal framework for constructing,
maintaining and searching linguistic annotations, while remaining consistent
with many alternative data structures and file formats.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9903004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9903004</id><created>1999-03-03</created><updated>1999-03-31</updated><authors><author><keyname>Smith</keyname><forenames>Denvil</forenames></author></authors><title>A Flit Level Simulator for Wormhole Routing</title><categories>cs.DC cs.OS</categories><comments>Complete Thesis 359 pages, 32 tables, 70 figures, HTML (add GIF files)</comments><acm-class>B.4.4; C.2.6; D.4.4</acm-class><abstract>  Wormhole routing, the latest switching technique to be utilized by massively
parallel computers, enjoys the distinct advantage of a low latency when
compared to other switching techniques. This low latency is due to the nearly
distance insensitive routing traits in the absence of channel contention. The
low latency of wormhole routing brings about a liability of this switching
technique, a chance of deadlock. Deadlock is a concern in wormhole routed
networks due to the fact a message does not release its allocated resources
until all flits of a message have completely traversed the router in which
these resources are associated. The deadlock condition is addressed in the
routing algorithm. Simulation tools are currently needed that will aid in the
size and number of resources necessary to obtain the optimum utilization of
network resources for an algorithm. Some of these resources include the
topology of the network along with the number of nodes for the topology, the
size of the message, and the number and size of buffers at each router.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9903005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9903005</id><created>1999-03-04</created><authors><author><keyname>Lecomte</keyname><forenames>Pierre B. A.</forenames></author><author><keyname>Rigo</keyname><forenames>Michel</forenames></author></authors><title>Numeration systems on a regular language</title><categories>cs.OH</categories><comments>15 pages</comments><acm-class>F.1.1;F.4.3</acm-class><abstract>  Generalizations of linear numeration systems in which the set of natural
numbers is recognizable by finite automata are obtained by describing an
arbitrary infinite regular language following the lexicographic ordering. For
these systems of numeration, we show that ultimately periodic sets are
recognizable. We also study the translation and the multiplication by constants
as well as the order dependence of the recognizability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9903006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9903006</id><created>1999-03-05</created><authors><author><keyname>Plotnikov</keyname><forenames>Anatoly D.</forenames><affiliation>Vinnitsa Institute of Regional Economics and Management</affiliation></author></authors><title>Designing SAT for HCP</title><categories>cs.LO</categories><comments>7 pages, 1 figures. It has sent to 6th Twente Workshop on Graphs and
  Combinatorial Optimization</comments><acm-class>F.4.1;G.2.1;G.2.2</acm-class><abstract>  For arbitrary undirected graph $G$, we are designing SATISFIABILITY problem
(SAT) for HCP, using tools of Boolean algebra only. The obtained SAT be the
logic formulation of conditions for Hamiltonian cycle existence, and use $m$
Boolean variables, where $m$ is the number of graph edges. This Boolean
expression is true if and only if an initial graph is Hamiltonian. That is,
each satisfying assignment of the Boolean variables determines a Hamiltonian
cycle of $G$, and each Hamiltonian cycle of $G$ corresponds to a satisfying
assignment of the Boolean variables. In common case, the obtained Boolean
expression may has an exponential length (the number of Boolean literals).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9903007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9903007</id><created>1999-03-05</created><authors><author><keyname>Dymetman</keyname><forenames>Marc</forenames></author></authors><title>Some Remarks on the Geometry of Grammar</title><categories>cs.CL cs.LO</categories><comments>22 pages, 15 figures</comments><acm-class>I.2.7; F.4.2</acm-class><abstract>  This paper, following (Dymetman:1998), presents an approach to grammar
description and processing based on the geometry of cancellation diagrams, a
concept which plays a central role in combinatorial group theory
(Lyndon-Schuppe:1977). The focus here is on the geometric intuitions and on
relating group-theoretical diagrams to the traditional charts associated with
context-free grammars and type-0 rewriting systems. The paper is structured as
follows. We begin in Section 1 by analyzing charts in terms of constructs
called cells, which are a geometrical counterpart to rules. Then we move in
Section 2 to a presentation of cancellation diagrams and show how they can be
used computationally. In Section 3 we give a formal algebraic presentation of
the concept of group computation structure, which is based on the standard
notions of free group and conjugacy. We then relate in Section 4 the geometric
and the algebraic views of computation by using the fundamental theorem of
combinatorial group theory (Rotman:1994). In Section 5 we study in more detail
the relationship between the two views on the basis of a simple grammar stated
as a group computation structure. In section 6 we extend this grammar to handle
non-local constructs such as relative pronouns and quantifiers. We conclude in
Section 7 with some brief notes on the differences between normal submonoids
and normal subgroups, group computation versus rewriting systems, and the use
of group morphisms to study the computational complexity of parsing and
generation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9903008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9903008</id><created>1999-03-05</created><authors><author><keyname>Litman</keyname><forenames>Diane J.</forenames><affiliation>AT&amp;T Labs - Research</affiliation></author><author><keyname>Pan</keyname><forenames>Shimei</forenames><affiliation>Columbia University</affiliation></author></authors><title>Empirically Evaluating an Adaptable Spoken Dialogue System</title><categories>cs.CL</categories><comments>to be published in the Proceedings of the 7th International
  Conference on User Modeling (UM'99); uses llncs.cls,um97.sty</comments><acm-class>I.2.7</acm-class><abstract>  Recent technological advances have made it possible to build real-time,
interactive spoken dialogue systems for a wide variety of applications.
However, when users do not respect the limitations of such systems, performance
typically degrades. Although users differ with respect to their knowledge of
system limitations, and although different dialogue strategies make system
limitations more apparent to users, most current systems do not try to improve
performance by adapting dialogue behavior to individual users. This paper
presents an empirical evaluation of TOOT, an adaptable spoken dialogue system
for retrieving train schedules on the web. We conduct an experiment in which 20
users carry out 4 tasks with both adaptable and non-adaptable versions of TOOT,
resulting in a corpus of 80 dialogues. The values for a wide range of
evaluation measures are then extracted from this corpus. Our results show that
adaptable TOOT generally outperforms non-adaptable TOOT, and that the utility
of adaptation depends on TOOT's initial dialogue strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9903009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9903009</id><created>1999-03-10</created><authors><author><keyname>Buhrman</keyname><forenames>Harry</forenames><affiliation>CWI</affiliation></author><author><keyname>Hoepman</keyname><forenames>Jaap-Henk</forenames><affiliation>CWI and University of Amsterdam</affiliation></author><author><keyname>Vitanyi</keyname><forenames>Paul</forenames><affiliation>CWI and University of Amsterdam</affiliation></author></authors><title>Space-Efficient Routing Tables for Almost All Networks and the
  Incompressibility Method</title><categories>cs.DC cs.AR cs.CC cs.DS cs.NI</categories><comments>19 pages, Latex, 1 table, 1 figure; SIAM J. Comput., To appear</comments><report-no>CWI Tech Report 1997</report-no><acm-class>C.2, F.2, D.4</acm-class><abstract>  We use the incompressibility method based on Kolmogorov complexity to
determine the total number of bits of routing information for almost all
network topologies. In most models for routing, for almost all labeled graphs
$\Theta (n^2)$ bits are necessary and sufficient for shortest path routing. By
`almost all graphs' we mean the Kolmogorov random graphs which constitute a
fraction of $1-1/n^c$ of all graphs on $n$ nodes, where $c &gt; 0$ is an arbitrary
fixed constant. There is a model for which the average case lower bound rises
to $\Omega(n^2 \log n)$ and another model where the average case upper bound
drops to $O(n \log^2 n)$. This clearly exposes the sensitivity of such bounds
to the model under consideration. If paths have to be short, but need not be
shortest (if the stretch factor may be larger than 1), then much less space is
needed on average, even in the more demanding models. Full-information routing
requires $\Theta (n^3)$ bits on average. For worst-case static networks we
prove a $\Omega(n^2 \log n)$ lower bound for shortest path routing and all
stretch factors $&lt;2$ in some networks where free relabeling is not allowed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9903010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9903010</id><created>1999-03-11</created><authors><author><keyname>Plotnikov</keyname><forenames>Anatoly D.</forenames><affiliation>Vinnitsa Institute of Regional Economics and Management</affiliation></author></authors><title>A class of problems of NP to be worth to search an efficient solving
  algorithm</title><categories>cs.DS</categories><comments>9 pages, 1 figures</comments><acm-class>F.2.2;G.2.1;G.2.2</acm-class><abstract>  We examine possibility to design an efficient solving algorithm for problems
of the class \np. It is introduced a classification of \np problems by the
property that a partial solution of size $k$ can be extended into a partial
solution of size $k+1$ in polynomial time. It is defined an unique class
problems to be worth to search an efficient solving algorithm. The problems,
which are outside of this class, are inherently exponential. We show that the
Hamiltonian cycle problem is inherently exponential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9903011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9903011</id><created>1999-03-11</created><authors><author><keyname>Mertens</keyname><forenames>Stephan</forenames></author></authors><title>A complete anytime algorithm for balanced number partitioning</title><categories>cs.DS cond-mat.dis-nn cs.AI</categories><comments>12 pages, 5 figures</comments><acm-class>F.2.2</acm-class><abstract>  Given a set of numbers, the balanced partioning problem is to divide them
into two subsets, so that the sum of the numbers in each subset are as nearly
equal as possible, subject to the constraint that the cardinalities of the
subsets be within one of each other. We combine the balanced largest
differencing method (BLDM) and Korf's complete Karmarkar-Karp algorithm to get
a new algorithm that optimally solves the balanced partitioning problem. For
numbers with twelve significant digits or less, the algorithm can optimally
solve balanced partioning problems of arbitrary size in practice. For numbers
with greater precision, it first returns the BLDM solution, then continues to
find better solutions as time allows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9903012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9903012</id><created>1999-03-16</created><authors><author><keyname>Plotnikov</keyname><forenames>Anatoly D.</forenames></author></authors><title>Formalization of the class of problems solvable by a nondeterministic
  Turing machine</title><categories>cs.DS cs.CC</categories><comments>10 pages, 2 figures</comments><acm-class>F.2.2;F.1.2</acm-class><journal-ref>Cybernetics and Systems Analysis. Vol. 33, 5(1997) pp. 635-640</journal-ref><abstract>  The objective of this article is to formalize the definition of NP problems.
  We construct a mathematical model of discrete problems as independence
systems with weighted elements. We introduce two auxiliary sets that
characterize the solution of the problem: the adjoint set, which contains the
elements from the original set none of which can be adjoined to the already
chosen solution elements; and the residual set, in which every element can be
adjoined to previously chosen solution elements.
  In a problem without lookahead, every adjoint set can be generated by the
solution algorithm effectively, in polynomial time.
  The main result of the study is the assertion that the NP class is identical
with the class of problems without lookahead. Hence it follows that if we fail
to find an effective (polynomial-time) solution algorithm for a given problem,
then we need to look for an alternative formulation of the problem in set of
problems without lookahead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9903013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9903013</id><created>1999-03-18</created><authors><author><keyname>Das</keyname><forenames>Tapas Kumar</forenames></author></authors><title>The Impact of Net Culture on Mainstream Societies: a Global Analysis</title><categories>cs.CY</categories><comments>8 pages, no figure, Submitted to The Economic and Political Weekly</comments><acm-class>K.4.0;K.4.1;K.4.2</acm-class><abstract>  In this work the impact of the Internet culture on standard mainstream
societies has been analyzed. After analytically establishing the fact that the
Net can be viewed as a pan-societal superstructure which supports its own
distinct culture, an ethnographic analysis is provided to find out the key
aspects of this culture. The elements of this culture which have an empowering
impacts on the standard mainstream societies, as well as the elements in it
which can cause discouraging social effects are then discussed by a global
investigation of the present status of various fundamental aspects (e,g,
education, economics, politics, entertainment etc) of the mainstream societies
as well as their links with the Net culture. Though immensely potential for
providing various prominent positive impacts, the key findings of this work
indicate that misuse of Internet can create tremendous harm to the members of
the mainstream societies by generating a set of morally crippled people as well
as a future generation completely void of principles and ethics. This
structured diagnostic approach to the social problems caused by the manhandling
of Internet leads to a concrete effort of providing the measures that can be
taken to enhance or to overcome the supporting and limiting effects of the Net
culture respectively with the intent to benefit our society and to protect the
teratoidation of certain ethical values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9903014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9903014</id><created>1999-03-22</created><authors><author><keyname>Kistler</keyname><forenames>Thomas</forenames></author><author><keyname>Franz</keyname><forenames>Michael</forenames></author></authors><title>Perpetual Adaptation of Software to Hardware: An Extensible Architecture
  for Providing Code Optimization as a Central System Service</title><categories>cs.OS cs.PL</categories><comments>22 pages</comments><report-no>ICS-TR-99-12</report-no><acm-class>D.3.4</acm-class><abstract>  We present an open architecture for just-in-time code generation and dynamic
code optimization that is flexible, customizable, and extensible. While
previous research has primarily investigated functional aspects of such a
system, architectural aspects have so far remained unexplored. In this paper,
we argue that these properties are important to generate optimal code for a
variety of hardware architectures and different processor generations within
processor families. These properties are also important to make system-level
code generation useful in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9903015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9903015</id><created>1999-03-22</created><authors><author><keyname>Kling</keyname><forenames>Rob</forenames></author><author><keyname>McKim</keyname><forenames>Geoffrey</forenames></author></authors><title>Scholarly Communication and the Continuum of Electronic Publishing</title><categories>cs.CY physics.soc-ph</categories><comments>35 pages</comments><acm-class>I.7.4; J2; J3</acm-class><journal-ref>Journal of the American Society for Information Science 50(10):
  890-906. (July 19, 1999)</journal-ref><abstract>  Electronic publishing opportunities, manifested today in a variety of
electronic journals and Web-based compendia, have captured the imagination of
many scholars. These opportunities have also destabilized norms about the
character of legitimate scholarly publishing in some fields. Unfortunately,
much of the literature about scholarly e-publishing homogenizes the character
of publishing. This article provides an analytical approach for evaluating
disciplinary conventions and for proposing policies about scholarly
e-publishing. We characterize three dimensions of scholarly publishing as a
communicative practice -- publicity, access, and trustworthiness, and examine
several forms of paper and electronic publications in this framework. This
analysis shows how the common claim that e-publishing &quot;substantially expands
access&quot; is over-simplified. It also indicates how peer-reviewing (whether in
paper or electronically) provides valuable functions for scholarly
communication that are not effectively replaced by self-posting articles in
electronic media.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9903016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9903016</id><created>1999-03-23</created><authors><author><keyname>Friedman</keyname><forenames>N</forenames></author><author><keyname>Halpern</keyname><forenames>J. Y.</forenames></author></authors><title>Modeling Belief in Dynamic Systems, Part II: Revision and Update</title><categories>cs.AI</categories><comments>See http://www.jair.org/ for other files accompanying this article</comments><acm-class>I.2</acm-class><journal-ref>Journal of Artificial Intelligence Research, Vol.10 (1999) 117-167</journal-ref><abstract>  The study of belief change has been an active area in philosophy and AI. In
recent years two special cases of belief change, belief revision and belief
update, have been studied in detail. In a companion paper (Friedman &amp; Halpern,
1997), we introduce a new framework to model belief change. This framework
combines temporal and epistemic modalities with a notion of plausibility,
allowing us to examine the change of beliefs over time. In this paper, we show
how belief revision and belief update can be captured in our framework. This
allows us to compare the assumptions made by each method, and to better
understand the principles underlying them. In particular, it shows that Katsuno
and Mendelzon's notion of belief update (Katsuno &amp; Mendelzon, 1991a) depends on
several strong assumptions that may limit its applicability in artificial
intelligence. Finally, our analysis allow us to identify a notion of minimal
change that underlies a broad range of belief change operations including
revision and update.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9903017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9903017</id><created>1999-03-28</created><authors><author><keyname>Meier-Schellersheim</keyname><forenames>M.</forenames></author><author><keyname>Mack</keyname><forenames>G.</forenames></author></authors><title>SIMMUNE, a tool for simulating and analyzing immune system behavior</title><categories>cs.MA q-bio</categories><comments>23 pages, 10 figures</comments><report-no>DESY-99-034</report-no><acm-class>I.6.3;I.6.4;I.6.5</acm-class><abstract>  We present a new approach to the simulation and analysis of immune system
behavior. The simulations that can be done with our software package called
SIMMUNE are based on immunological data that describe the behavior of immune
system agents (cells, molecules) on a microscopial (i.e. agent-agent
interaction) scale by defining cellular stimulus-response mechanisms. Since the
behavior of the agents in SIMMUNE can be very flexibly configured, its
application is not limited to immune system simulations. We outline the
principles of SIMMUNE's multiscale analysis of emergent structure within the
simulated immune system that allow the identification of immunological contexts
using minimal a priori assumptions about the higher level organization of the
immune system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9903018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9903018</id><created>1999-03-30</created><authors><author><keyname>Cassino</keyname><forenames>Carlos</forenames></author><author><keyname>Ierusalimschy</keyname><forenames>Roberto</forenames></author><author><keyname>Rodriguez</keyname><forenames>Noemi</forenames></author></authors><title>LuaJava - A Scripting Tool for Java</title><categories>cs.SE</categories><comments>10 pages, LaTeX, 1 figure. Available at
  http://www.tecgraf.puc-rio.br/~cassino/luajava</comments><report-no>PUC-RioInf.MCC02/99</report-no><acm-class>D.2.11</acm-class><abstract>  Scripting languages are becoming more and more important as a tool for
software development, as they provide great flexibility for rapid prototyping
and for configuring componentware applications. In this paper we present
LuaJava, a scripting tool for Java. LuaJava adopts Lua, a dynamically typed
interpreted language, as its script language. Great emphasis is given to the
transparency of the integration between the two languages, so that objects from
one language can be used inside the other like native objects. The final result
of this integration is a tool that allows the construction of configurable Java
applications, using off-the-shelf components, in a high abstraction level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9903019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9903019</id><created>1999-03-30</created><updated>1999-03-31</updated><authors><author><keyname>Maskeliunas</keyname><forenames>Saulius</forenames><affiliation>Institute of Mathematics &amp; Informatics, Vilnius</affiliation></author></authors><title>Workflow Automation with Lotus Notes for the Governmental Administrative
  Information System</title><categories>cs.HC</categories><comments>8 pages, 7 figures</comments><report-no>MII.PSIS/SM.99-01</report-no><acm-class>H.4.1; H.5.3; J.1</acm-class><abstract>  The paper presents an introductory overview of the workflow automation area,
outlining the main types, basic technologies, the essential features of
workflow applications. Two sorts of process models for the definition of
workflows (according to the conversation-based and activity-based
methodologies) are sketched. Later on, the nature of Lotus Notes and its
capabilities (as an environment for workflow management systems development)
are indicated. Concluding, the experience of automating administrative
workflows (developing a Subsystem of Inter-institutional Document Management of
the VADIS project) is briefly outlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9903020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9903020</id><created>1999-03-31</created><updated>2001-09-28</updated><authors><author><keyname>Durr</keyname><forenames>Christoph</forenames></author><author><keyname>Goles</keyname><forenames>Eric</forenames></author><author><keyname>Rapaport</keyname><forenames>Ivan</forenames></author><author><keyname>Remila</keyname><forenames>Eric</forenames></author></authors><title>Tiling with bars under tomographic constraints</title><categories>cs.DS cs.CC</categories><comments>Updated references</comments><acm-class>F.2.2</acm-class><abstract>  We wish to tile a rectangle or a torus with only vertical and horizontal bars
of a given length, such that the number of bars in every column and row equals
given numbers. We present results for particular instances and for a more
general problem, while leaving open the initial problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904001</id><created>1999-04-01</created><authors><author><keyname>Edmonds</keyname><forenames>Bruce</forenames></author></authors><title>A Proposal for the Establishment of Review Boards - a flexible approach
  to the selection of academic knowledge</title><categories>cs.CY cs.DL cs.IR</categories><comments>Other formats at http://www.cpm.mmu.ac.uk/cpmrep50.html</comments><report-no>CPM-99-50</report-no><acm-class>K.4.3; K.3.m;H.5.3</acm-class><abstract>  Paper journals use a small number of trusted academics to select information
on behalf of all their readers. This inflexibility in the selection was
justified due to the expense of publishing. The advent of cheap distribution
via the internet allows a new trade-off between time and expense and the
flexibility of the selection process. This paper explores one such possible
process one where the role of mark-up and archiving is separated from that of
review. The idea is that authors publish their papers on their own web pages or
in a public paper archive, a board of reviewers judge that paper on a number of
different criteria. The detailed results of the reviews are stored in such a
way as to enable readers to use these judgements to find the papers they want
using search engines on the web. Thus instead of journals using generic
selection criteria readers can set their own to suit their needs. The resulting
system might be even cheaper than web-journals to implement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904002</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904002</id><created>1999-04-07</created><updated>1999-06-20</updated><authors><author><keyname>Pestov</keyname><forenames>Vladimir</forenames></author></authors><title>A geometric framework for modelling similarity search</title><categories>cs.IR cs.DB cs.DS</categories><comments>11 pages, LaTeX 2.e</comments><report-no>RP-99-12, School of Math and Comp Sci, Victoria University of
  Wellington, New Zealand</report-no><acm-class>H.3.1; H.3.3</acm-class><journal-ref>Proc. 10-th Int. Workshop on Database and Expert Systems
  Applications (DEXA'99), Sept. 1-3, 1999, Florence, Italy, IEEE Comp. Soc.,
  pp. 150-154.</journal-ref><abstract>  The aim of this paper is to propose a geometric framework for modelling
similarity search in large and multidimensional data spaces of general nature,
which seems to be flexible enough to address such issues as analysis of
complexity, indexability, and the `curse of dimensionality.' Such a framework
is provided by the concept of the so-called similarity workload, which is a
probability metric space $\Omega$ (query domain) with a distinguished finite
subspace $X$ (dataset), together with an assembly of concepts, techniques, and
results from metric geometry. They include such notions as metric transform,
$\e$-entropy, and the phenomenon of concentration of measure on
high-dimensional structures. In particular, we discuss the relevance of the
latter to understanding the curse of dimensionality. As some of those concepts
and techniques are being currently reinvented by the database community, it
seems desirable to try and bridge the gap between database research and the
relevant work already done in geometry and analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904003</id><created>1999-04-11</created><authors><author><keyname>Chen</keyname><forenames>W.</forenames></author><author><keyname>Wang</keyname><forenames>W.</forenames></author><author><keyname>Zhong</keyname><forenames>T.</forenames></author></authors><title>The Structure of Weighting Coefficient Matrices of Harmonic Differential
  Quadrature and Its Applications</title><categories>cs.CE cs.NA</categories><comments>12 pages, 1 table, Original MS. Word format, published in Common.
  Numer. Methods. Engrg</comments><acm-class>G.1.3, G.1.8</acm-class><journal-ref>Commnuications in Numerical Methods in Engineering, 12 (1996), pp.
  455-459</journal-ref><abstract>  The structure of weighting coefficient matrices of Harmonic Differential
Quadrature (HDQ) is found to be either centrosymmetric or skew centrosymmetric
depending on the order of the corresponding derivatives. The properties of both
matrices are briefly discussed in this paper. It is noted that the
computational effort of the harmonic quadrature for some problems can be
further reduced up to 75 per cent by using the properties of the
above-mentioned matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904004</id><created>1999-04-12</created><authors><author><keyname>Lee</keyname><forenames>Mark</forenames></author><author><keyname>Barnden</keyname><forenames>John</forenames></author></authors><title>Mixing Metaphors</title><categories>cs.CL cs.AI</categories><acm-class>I.2.0; I.2.7</acm-class><journal-ref>Proceedings of the AISB'99 Symposium on Metaphor, Artificial
  Intelligence, and Cognition, pages 11-16, Edinburgh</journal-ref><abstract>  Mixed metaphors have been neglected in recent metaphor research. This paper
suggests that such neglect is short-sighted. Though mixing is a more complex
phenomenon than straight metaphors, the same kinds of reasoning and knowledge
structures are required. This paper provides an analysis of both parallel and
serial mixed metaphors within the framework of an AI system which is already
capable of reasoning about straight metaphorical manifestations and argues that
the processes underlying mixing are central to metaphorical meaning. Therefore,
any theory of metaphors must be able to account for mixing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904005</id><created>1999-04-14</created><authors><author><keyname>Eaves</keyname><forenames>Walter</forenames></author></authors><title>Transport Level Security: a proof using the Gong-Needham-Yahalom Logic</title><categories>cs.CR</categories><comments>22 pages, 2 figures, 1 appendix</comments><acm-class>C.2.0; C.2.2; E.4; F.4.3</acm-class><abstract>  This paper provides a proof of the proposed Internet standard Transport Level
Security protocol using the Gong-Needham-Yahalom logic. It is intended as a
teaching aid and hopes to show to students: the potency of a formal method for
protocol design; some of the subtleties of authenticating parties on a network
where all messages can be intercepted; the design of what should be a widely
accepted standard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904006</id><created>1999-04-15</created><authors><author><keyname>Chen</keyname><forenames>W.</forenames></author></authors><title>Jacobian matrix: a bridge between linear and nonlinear polynomial-only
  problems</title><categories>cs.CE cs.NA</categories><comments>Six chapters, 28 pages, Original MS. Word format, interested readers
  can contact me in chenw@homer.shinshu-u.ac.jp or chenwwhy@hotmail.com</comments><acm-class>G.1.3, G.1.8</acm-class><abstract>  By using the Hadamard matrix product concept, this paper introduces two
generalized matrix formulation forms of numerical analogue of nonlinear
differential operators. The SJT matrix-vector product approach is found to be a
simple, efficient and accurate technique in the calculation of the Jacobian
matrix of the nonlinear discretization by finite difference, finite volume,
collocation, dual reciprocity BEM or radial functions based numerical methods.
We also present and prove simple underlying relationship (theorem (3.1))
between general nonlinear analogue polynomials and their corresponding Jacobian
matrices, which forms the basis of this paper. By means of theorem 3.1,
stability analysis of numerical solutions of nonlinear initial value problems
can be easily handled based on the well-known results for linear problems.
Theorem 3.1 also leads naturally to the straightforward extension of various
linear iterative algorithms such as the SOR, Gauss-Seidel and Jacobi methods to
nonlinear algebraic equations. Since an exact alternative of the quasi-Newton
equation is established via theorem 3.1, we derive a modified BFGS quasi-Newton
method. A simple formula is also given to examine the deviation between the
approximate and exact Jacobian matrices. Furthermore, in order to avoid the
evaluation of the Jacobian matrix and its inverse, the pseudo-Jacobian matrix
is introduced with a general applicability of any nonlinear systems of
equations. It should be pointed out that a large class of real-world nonlinear
problems can be modeled or numerically discretized polynomial-only algebraic
system of equations. The results presented here are in general applicable for
all these problems. This paper can be considered as a starting point in the
research of nonlinear computation and analysis from an innovative viewpoint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904007</id><created>1999-04-15</created><authors><author><keyname>Chen</keyname><forenames>W.</forenames><affiliation>Corresponding author</affiliation></author><author><keyname>Zhong</keyname><forenames>Tingxiu</forenames></author></authors><title>The Study on the Nonlinear Computations of the DQ and DC Methods</title><categories>cs.CE cs.NA</categories><comments>31 pages, 1 table, Original Word format, interested readers may
  contact Dr. Chen in chenw@homer.shinshu-u.ac.jp or chenwwhy@hotmail.com</comments><acm-class>G.1.3, G.1.8</acm-class><abstract>  This paper points out that the differential quadrature (DQ) and differential
cubature (DC) methods due to their global domain property are more efficient
for nonlinear problems than the traditional numerical techniques such as finite
element and finite difference methods. By introducing the Hadamard product of
matrices, we obtain an explicit matrix formulation for the DQ and DC solutions
of nonlinear differential and integro-differential equations. Due to its
simplicity and flexibility, the present Hadamard product approach makes the DQ
and DC methods much easier to be used. Many studies on the Hadamard product can
be fully exploited for the DQ and DC nonlinear computations. Furthermore, we
first present SJT product of matrix and vector to compute accurately and
efficiently the Frechet derivative matrix in the Newton-Raphson method for the
solution of the nonlinear formulations. We also propose a simple approach to
simplify the DQ or DC formulations for some nonlinear differential operators
and thus the computational efficiency of these methods is improved
significantly. We give the matrix multiplication formulas to compute
efficiently the weighting coefficient matrices of the DC method. The spherical
harmonics are suggested as the test functions in the DC method to handle the
nonlinear differential equations occurring in global and hemispheric weather
forecasting problems. Some examples are analyzed to demonstrate the simplicity
and efficiency of the presented techniques. It is emphasized that innovations
presented are applicable to the nonlinear computations of the other numerical
methods as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904008</id><created>1999-04-15</created><authors><author><keyname>Gerdemann</keyname><forenames>Dale</forenames></author><author><keyname>van Noord</keyname><forenames>Gertjan</forenames></author></authors><title>Transducers from Rewrite Rules with Backreferences</title><categories>cs.CL</categories><comments>8 pages, EACL 1999 Bergen</comments><acm-class>F.1.1; F.4.3; I.2.1; J.5</acm-class><abstract>  Context sensitive rewrite rules have been widely used in several areas of
natural language processing, including syntax, morphology, phonology and speech
processing. Kaplan and Kay, Karttunen, and Mohri &amp; Sproat have given various
algorithms to compile such rewrite rules into finite-state transducers. The
present paper extends this work by allowing a limited form of backreferencing
in such rules. The explicit use of backreferencing leads to more elegant and
general solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904009</id><created>1999-04-15</created><authors><author><keyname>Lee</keyname><forenames>Mark</forenames></author><author><keyname>Wilks</keyname><forenames>Yorick</forenames></author></authors><title>An ascription-based approach to speech acts</title><categories>cs.CL</categories><comments>6 pages</comments><acm-class>I.2.0; I.2.1; I.2.7</acm-class><journal-ref>Proceedings of COLING`96, Copenhagen. (1996)</journal-ref><abstract>  The two principal areas of natural language processing research in pragmatics
are belief modelling and speech act processing. Belief modelling is the
development of techniques to represent the mental attitudes of a dialogue
participant. The latter approach, speech act processing, based on speech act
theory, involves viewing dialogue in planning terms. Utterances in a dialogue
are modelled as steps in a plan where understanding an utterance involves
deriving the complete plan a speaker is attempting to achieve. However,
previous speech act based approaches have been limited by a reliance upon
relatively simplistic belief modelling techniques and their relationship to
planning and plan recognition. In particular, such techniques assume
precomputed nested belief structures. In this paper, we will present an
approach to speech act processing based on novel belief modelling techniques
where nested beliefs are propagated on demand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904010</id><created>1999-04-18</created><authors><author><keyname>Cranor</keyname><forenames>Lorrie Faith</forenames></author><author><keyname>Reagle</keyname><forenames>Joseph</forenames></author><author><keyname>Ackerman</keyname><forenames>Mark S.</forenames></author></authors><title>Beyond Concern: Understanding Net Users' Attitudes About Online Privacy</title><categories>cs.CY cs.HC</categories><comments>5 figures and appendix</comments><report-no>AT&amp;T Labs-Research Technical Report TR 99.4.3</report-no><acm-class>K.4.1</acm-class><abstract>  People are concerned about privacy, particularly on the Internet. While many
studies have provided evidence of this concern, few have explored the nature of
the concern in detail, especially for the online environment. With this study,
we have tried to better understand the nature of online privacy concerns; we
look beyond the fact that people are concerned and attempt to understand how
they are concerned. We hope our results will help inform both policy decisions
as well as the development of technology tools that can assist Internet users
in protecting their privacy.
  We present results here from the analysis of 381 questionnaires completed
between November 6 and November 13, 1998 by American Internet users. The sample
was drawn from the FamilyPC magazine/Digital Research, Inc. Family Panel. While
this is not a statistically representative sample of US Internet users, our
respondents are heavy Internet users, and quite possibly lead innovators. As
such, we believe that this sample is important for understanding the future
Internet user population.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904011</id><created>1999-04-21</created><authors><author><keyname>Zhang</keyname><forenames>Yin</forenames></author></authors><title>WebScript -- A Scripting Language for the Web</title><categories>cs.NI cs.PL</categories><comments>19 pages, 11 figures</comments><acm-class>D.3.m; H.5.4; I.7.m</acm-class><abstract>  WebScript is a scripting language for processing Web documents. Designed as
an extension to Jacl, the Java implementation of Tcl, WebScript allows
programmers to manipulate HTML in the same way as Tcl manipulates text strings
and GUI elements. This leads to a completely new way of writing the next
generation of Web applications. This paper presents the motivation behind the
design and implementation of WebScript, an overview of its major features, as
well as some demonstrations of its power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904012</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904012</id><created>1999-04-21</created><authors><author><keyname>Bush</keyname><forenames>Stephen F.</forenames></author></authors><title>Active Virtual Network Management Protocol</title><categories>cs.NI</categories><comments>presented at PADS'99</comments><acm-class>C.2</acm-class><abstract>  This paper introduces a novel algorithm, the Active Virtual Network
Management Protocol (AVNMP), for predictive network management. It explains how
the AVNMP facilitates the management of an active network by allowing future
predicted state information within an active network to be available to network
management algorithms. This is accomplished by coupling ideas from optimistic
discrete event simulation with active networking. The optimistic discrete event
simulation method used is a form of self-adjusting Time Warp. It is
self-adjusting because the system adjusts for predictions which are inaccurate
beyond a given tolerance. The concept of a streptichron and autoanaplasis are
introduced as mechanisms which take advantage of the enhanced flexibility and
intelligence of active packets. Finally, it is demonstrated that the AVNMP is a
feasible concept.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904013</id><created>1999-04-21</created><authors><author><keyname>Bush</keyname><forenames>Stephen F.</forenames></author><author><keyname>Frost</keyname><forenames>Victor S.</forenames></author><author><keyname>Evans</keyname><forenames>Joseph B.</forenames></author></authors><title>Network Management of Predictive Mobile Networks</title><categories>cs.NI</categories><acm-class>C.2</acm-class><journal-ref>Journal of Network and Systems Management, volume 7, number 2,
  June, 1999</journal-ref><abstract>  There is a trend toward the use of predictive systems in communications
networks. At the systems and network management level predictive capabilities
are focused on anticipating network faults and performance degradation.
Simultaneously, mobile communication networks are being developed with
predictive location and tracking mechanisms. The interactions and synergies
between these systems present a new set of problems. A new predictive network
management framework is developed and examined. The interaction between a
predictive mobile network and the proposed network management system is
discussed. The Rapidly Deployable Radio Network is used as a specific example
to illustrate these interactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904014</id><created>1999-04-22</created><authors><author><keyname>Bush</keyname><forenames>Stephen F.</forenames></author><author><keyname>Jagannath</keyname><forenames>Sunil</forenames></author><author><keyname>Evans</keyname><forenames>Joseph B.</forenames></author><author><keyname>Frost</keyname><forenames>Victor</forenames></author><author><keyname>Minden</keyname><forenames>Gary</forenames></author><author><keyname>Shanmugan</keyname><forenames>K. Sam</forenames></author></authors><title>A Control and Management Network for Wireless ATM Systems</title><categories>cs.NI</categories><comments>author's web page at http://www.crd.ge.com/people/bush</comments><acm-class>C.2</acm-class><journal-ref>ACM-Baltzer Wireless Networks (WINET), volume 3, pages
  267-283,1997</journal-ref><abstract>  This paper describes the design of a control and management network
(orderwire) for a mobile wireless Asynchronous Transfer Mode (ATM) network.
This mobile wireless ATM network is part of the Rapidly Deployable Radio
Network (RDRN). The orderwire system consists of a packet radio network which
overlays the mobile wireless ATM network, each network element in this network
uses Global Positioning System (GPS) information to control a beamforming
antenna subsystem which provides for spatial reuse. This paper also proposes a
novel Virtual Network Configuration (VNC) algorithm for predictive network
configuration. A mobile ATM Private Network-Network Interface (PNNI) based on
VNC is also discussed. Finally, as a prelude to the system implementation,
results of a Maisie simulation of the orderwire system are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904015</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904015</id><created>1999-04-22</created><authors><author><keyname>Bush</keyname><forenames>Stephen F.</forenames></author><author><keyname>Jagannath</keyname><forenames>Sunil</forenames></author><author><keyname>Evans</keyname><forenames>Joseph B.</forenames></author><author><keyname>Frost</keyname><forenames>Victor</forenames></author></authors><title>Mobile ATM Buffer Capacity Analysis</title><categories>cs.NI</categories><comments>author's web page at http://www.crd.ge.com/people/bush</comments><acm-class>C.2</acm-class><journal-ref>ACM-Baltzer Mobile Networks and Nomadic Applications (NOMAD),1996,
  volume 1, number 1, pages 67-73, February</journal-ref><abstract>  This paper extends a stochastic theory for buffer fill distribution for
multiple ``on'' and ``off'' sources to a mobile environment. Queue fill
distribution is described by a set of differential equations assuming sources
alternate asynchronously between exponentially distributed periods in ``on''
and ``off'' states. This paper includes the probabilities that mobile sources
have links to a given queue. The sources represent mobile user nodes, and the
queue represents the capacity of a switch. This paper presents a method of
analysis which uses mobile parameters such as speed, call rates per unit area,
cell area, and call duration and determines queue fill distribution at the ATM
cell level. The analytic results are compared with simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904016</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904016</id><created>1999-04-22</created><authors><author><keyname>Bush</keyname><forenames>Stephen F.</forenames></author><author><keyname>Hershey</keyname><forenames>John</forenames></author><author><keyname>Vosburgh</keyname><forenames>Kirby</forenames></author></authors><title>Brittle System Analysis</title><categories>cs.NI cs.CC cs.GL cs.PF</categories><acm-class>C.2;C.4;B.8;F.2;H.1</acm-class><abstract>  The goal of this paper is to define and analyze systems which exhibit brittle
behavior. This behavior is characterized by a sudden and steep decline in
performance as the system approaches the limits of tolerance. This can be due
to input parameters which exceed a specified input, or environmental conditions
which exceed specified operating boundaries. An analogy is made between brittle
commmunication systems in particular and materials science.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904017</id><created>1999-04-23</created><authors><author><keyname>Hanson</keyname><forenames>David R.</forenames></author></authors><title>A Machine-Independent Debugger--Revisited</title><categories>cs.PL cs.SE</categories><comments>12 pages; 6 figures; 3 tables</comments><report-no>Microsoft Research MSR-TR-99-04</report-no><acm-class>D.3.4</acm-class><journal-ref>Software--Practice &amp; Experience, vol. 29, no. 10, 849-862, Aug.
  1999</journal-ref><abstract>  Most debuggers are notoriously machine-dependent, but some recent research
prototypes achieve varying degrees of machine-independence with novel designs.
Cdb, a simple source-level debugger for C, is completely independent of its
target architecture. This independence is achieved by embedding symbol tables
and debugging code in the target program, which costs both time and space. This
paper describes a revised design and implementation of cdb that reduces the
space cost by nearly one-half and the time cost by 13% by storing symbol tables
in external files. A symbol table is defined by a 31-line grammar in the
Abstract Syntax Description Language (ASDL). ASDL is a domain-specific language
for specifying tree data structures. The ASDL tools accept an ASDL grammar and
generate code to construct, read, and write these data structures. Using ASDL
automates implementing parts of the debugger, and the grammar documents the
symbol table concisely. Using ASDL also suggested simplifications to the
interface between the debugger and the target program. Perhaps most important,
ASDL emphasizes that symbol tables are data structures, not file formats. Many
of the pitfalls of working with low-level file formats can be avoided by
focusing instead on high-level data structures and automating the
implementation details.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904018</id><created>1999-04-24</created><authors><author><keyname>Cahn</keyname><forenames>Janet E.</forenames></author></authors><title>A Computational Memory and Processing Model for Processing</title><categories>cs.CL</categories><comments>4 pages, 5 figures</comments><acm-class>I.2.7, I.2.0</acm-class><abstract>  This paper links prosody to the information in a text and how it is processed
by the speaker. It describes the operation and output of LOQ, a text-to-speech
implementation that includes a model of limited attention and working memory.
Attentional limitations are key. Varying the attentional parameter in the
simulations varies in turn what counts as given and new in a text, and
therefore, the intonational contours with which it is uttered. Currently, the
system produces prosody in three different styles: child-like, adult
expressive, and knowledgeable. This prosody also exhibits differences within
each style -- no two simulations are alike. The limited resource approach
captures some of the stylistic and individual variety found in natural prosody.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904019</id><created>1999-04-26</created><updated>1999-08-17</updated><authors><author><keyname>Buhrman</keyname><forenames>H.</forenames><affiliation>CWI</affiliation></author><author><keyname>Cleve</keyname><forenames>R.</forenames><affiliation>U.Calgary</affiliation></author><author><keyname>de Wolf</keyname><forenames>R.</forenames><affiliation>CWI and U.Amsterdam</affiliation></author><author><keyname>Zalka</keyname><forenames>Ch.</forenames><affiliation>LANL</affiliation></author></authors><title>Bounds for Small-Error and Zero-Error Quantum Algorithms</title><categories>cs.CC quant-ph</categories><comments>11 pages, LaTeX. New title and some sections are rewritten. This
  version to appear in IEEE FOCS'99</comments><acm-class>F.1.1; F.2.0</acm-class><abstract>  We present a number of results related to quantum algorithms with small error
probability and quantum algorithms that are zero-error. First, we give a tight
analysis of the trade-offs between the number of queries of quantum search
algorithms, their error probability, the size of the search space, and the
number of solutions in this space. Using this, we deduce new lower and upper
bounds for quantum versions of amplification problems. Next, we establish
nearly optimal quantum-classical separations for the query complexity of
monotone functions in the zero-error model (where our quantum zero-error model
is defined so as to be robust when the quantum gates are noisy). Also, we
present a communication complexity problem related to a total function for
which there is a quantum-classical communication complexity gap in the
zero-error model. Finally, we prove separations for monotone graph properties
in the zero-error and other error models which imply that the evasiveness
conjecture for such properties does not hold for quantum computers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904020</id><created>1999-04-26</created><authors><author><keyname>Eaves</keyname><forenames>Walter</forenames></author></authors><title>ODP channel objects that provide services transparently for distributing
  processing systems</title><categories>cs.DC cs.OS</categories><comments>35 pages, 10 figures</comments><acm-class>C.2.0; C.2.4; D.4.7; H.5.1; K.6.4; D.4.6</acm-class><abstract>  This paper describes an architecture for a distributing processing system
that would allow remote procedure calls to invoke other services as messages
are passed between clients and servers. It proposes that an additional class of
data processing objects be located in the software communications channel. The
objects in this channel would then be used to enforce protocols on
client-server applications without any additional effort by the application
programmers. For example, services such as key-management, time-stamping,
sequencing and encryption can be implemented at different levels of the
software communications stack to provide a complete authentication service. A
distributing processing environment could be used to control broadband network
data delivery. Architectures and invocation semantics are discussed, Example
classes and interfaces for channel objects are given in the Java programming
language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9904021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9904021</id><created>1999-04-28</created><authors><author><keyname>Chen</keyname><forenames>W.</forenames></author></authors><title>Hadamard product nonlinear formulation of Galerkin and finite element
  methods</title><categories>cs.CE cs.NA</categories><comments>8 pages, welcome any comments to author: chenw@homer.shinshu-u.ac.jp
  or chenwwhy@hotmail.com</comments><acm-class>G.1.2; G.1.5; G.1.8, G.1.3</acm-class><abstract>  A novel nonlinear formulation of the finite element and Galerkin methods is
presented here, which leads to the Hadamard product expression of the resultant
nonlinear algebraic analogue. The presented formulation attains the advantages
of weak formulation in the standard finite element and Galerkin schemes and
avoids the costly repeated numerical integration of the Jacobian matrix via the
recently developed SJT product approach. This also provides possibility of the
nonlinear decoupling computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9905001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9905001</id><created>1999-05-02</created><authors><author><keyname>Hwa</keyname><forenames>Rebecca</forenames></author></authors><title>Supervised Grammar Induction Using Training Data with Limited
  Constituent Information</title><categories>cs.CL</categories><comments>7 pages, 2 figures, to appear in the proc. of ACL '99</comments><acm-class>I.2.6; I.2.7</acm-class><abstract>  Corpus-based grammar induction generally relies on hand-parsed training data
to learn the structure of the language. Unfortunately, the cost of building
large annotated corpora is prohibitively expensive. This work aims to improve
the induction strategy when there are few labels in the training data. We show
that the most informative linguistic constituents are the higher nodes in the
parse trees, typically denoting complex noun phrases and sentential clauses.
They account for only 20% of all constituents. For inducing grammars from
sparsely labeled training data (e.g., only higher-level constituent labels), we
propose an adaptation strategy, which produces grammars that parse almost as
well as grammars induced from fully labeled corpora. Our results suggest that
for a partial parser to replace human annotators, it must be able to
automatically extract higher-level constituents rather than base noun phrases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9905002</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9905002</id><created>1999-05-04</created><authors><author><keyname>Burow</keyname><forenames>Burkhard D.</forenames></author></authors><title>DRAFT : Task System and Item Architecture (TSIA)</title><categories>cs.PL cs.DC cs.GL cs.OS</categories><comments>vii+244 pages, including 126 figures of diagrams and code examples.
  Submitted to Springer Verlag. For further information see http://www.tsia.org</comments><report-no>DESY 99-066</report-no><acm-class>A.1;D.1.1;D.1.3;D.1.4;D.2.3;D.2.11;D.3.2;D.3.3;D.3.4;D.4.1;D.4.5;
  D.4.7;E.1;F.1.2;F.3.3</acm-class><abstract>  During its execution, a task is independent of all other tasks. For an
application which executes in terms of tasks, the application definition can be
free of the details of the execution. Many projects have demonstrated that a
task system (TS) can provide such an application with a parallel, distributed,
heterogeneous, adaptive, dynamic, real-time, interactive, reliable, secure or
other execution. A task consists of items and thus the application is defined
in terms of items. An item architecture (IA) can support arrays, routines and
other structures of items, thus allowing for a structured application
definition. Taking properties from many projects, the support can extend
through to currying, application defined types, conditional items, streams and
other definition elements. A task system and item architecture (TSIA) thus
promises unprecedented levels of support for application execution and
definition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9905003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9905003</id><created>1999-05-10</created><authors><author><keyname>Eaves</keyname><forenames>Walter</forenames></author></authors><title>Collective Choice Theory in Collaborative Computing</title><categories>cs.MA cs.DC</categories><comments>40 pages, 10 figures</comments><acm-class>H.5.3 I.2.11 J.4 K.4.1 K.4.3 F.1.2</acm-class><abstract>  This paper presents some fundamental collective choice theory for information
system designers, particularly those working in the field of computer-supported
cooperative work. This paper is focused on a presentation of Arrow's
Possibility and Impossibility theorems which form the fundamental boundary on
the efficacy of collective choice: voting and selection procedures. It restates
the conditions that Arrow placed on collective choice functions in more
rigorous second-order logic, which could be used as a set of test conditions
for implementations, and a useful probabilistic result for analyzing votes on
issue pairs. It also describes some simple collective choice functions. There
is also some discussion of how enterprises should approach putting their
resources under collective control: giving an outline of a superstructure of
performative agents to carry out this function and what distributing processing
technology would be needed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9905004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9905004</id><created>1999-05-10</created><authors><author><keyname>Wolpert</keyname><forenames>David H.</forenames></author><author><keyname>Tumer</keyname><forenames>Kagan</forenames></author><author><keyname>Frank</keyname><forenames>Jeremy</forenames></author></authors><title>Using Collective Intelligence to Route Internet Traffic</title><categories>cs.LG adap-org cond-mat.stat-mech cs.DC cs.NI nlin.AO</categories><comments>7 pages</comments><acm-class>I.2.6; I.2.11</acm-class><journal-ref>Advances in Information Processing Systems - 11, eds M. Kearns, S.
  Solla, D. Cohn, MIT Press, 1999</journal-ref><abstract>  A COllective INtelligence (COIN) is a set of interacting reinforcement
learning (RL) algorithms designed in an automated fashion so that their
collective behavior optimizes a global utility function. We summarize the
theory of COINs, then present experiments using that theory to design COINs to
control internet traffic routing. These experiments indicate that COINs
outperform all previously investigated RL-based, shortest path routing
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9905005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9905005</id><created>1999-05-10</created><authors><author><keyname>Wolpert</keyname><forenames>David H.</forenames></author><author><keyname>Wheeler</keyname><forenames>Kevin R.</forenames></author><author><keyname>Tumer</keyname><forenames>Kagan</forenames></author></authors><title>General Principles of Learning-Based Multi-Agent Systems</title><categories>cs.MA adap-org cond-mat.stat-mech cs.DC cs.LG nlin.AO</categories><comments>7 pages, 6 figures</comments><acm-class>I.2.6 ; I.2.11</acm-class><journal-ref>Proceedings of the Third International Conference on Autonomous
  Agents, Seatle, WA 1999</journal-ref><abstract>  We consider the problem of how to design large decentralized multi-agent
systems (MAS's) in an automated fashion, with little or no hand-tuning. Our
approach has each agent run a reinforcement learning algorithm. This converts
the problem into one of how to automatically set/update the reward functions
for each of the agents so that the global goal is achieved. In particular we do
not want the agents to ``work at cross-purposes'' as far as the global goal is
concerned. We use the term artificial COllective INtelligence (COIN) to refer
to systems that embody solutions to this problem. In this paper we present a
summary of a mathematical framework for COINs. We then investigate the
real-world applicability of the core concepts of that framework via two
computer experiments: we show that our COINs perform near optimally in a
difficult variant of Arthur's bar problem (and in particular avoid the tragedy
of the commons for that problem), and we also illustrate optimal performance
for our COINs in the leader-follower problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9905006</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9905006</id><created>1999-05-11</created><authors><author><keyname>Bush</keyname><forenames>Stephen F.</forenames></author></authors><title>The Design and Analysis of Virtual Network Configuration for a Wireless
  Mobile ATM Network</title><categories>cs.NI</categories><comments>PhD Thesis</comments><acm-class>C.2;I.6</acm-class><abstract>  This research concentrates on the design and analysis of an algorithm
referred to as Virtual Network Configuration (VNC) which uses predicted future
states of a system for faster network configuration and management. VNC is
applied to the configuration of a wireless mobile ATM network. VNC is built on
techniques from parallel discrete event simulation merged with constraints from
real-time systems and applied to mobile ATM configuration and handoff.
  Configuration in a mobile network is a dynamic and continuous process.
Factors such as load, distance, capacity and topology are all constantly
changing in a mobile environment. The VNC algorithm anticipates configuration
changes and speeds the reconfiguration process by pre-computing and caching
results. VNC propagates local prediction results throughout the VNC enhanced
system. The Global Positioning System is an enabling technology for the use of
VNC in mobile networks because it provides location information and accurate
time for each node.
  This research has resulted in well defined structures for the encapsulation
of physical processes within Logical Processes and a generic library for
enhancing a system with VNC. Enhancing an existing system with VNC is straight
forward assuming the existing physical processes do not have side effects. The
benefit of prediction is gained at the cost of additional traffic and
processing. This research includes an analysis of VNC and suggestions for
optimization of the VNC algorithm and its parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9905007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9905007</id><created>1999-05-12</created><authors><author><keyname>Brent</keyname><forenames>Michael R.</forenames></author></authors><title>An Efficient, Probabilistically Sound Algorithm for Segmentation and
  Word Discovery</title><categories>cs.CL cs.LG</categories><comments>65 double-spaced ms. pages including 3 figures</comments><acm-class>I.2.0;I.2.6;I.2.7</acm-class><journal-ref>Brent, M. R. (1999). An efficient, probabilistically sound
  algorithm for segmentation and word discovery. Machine Learning 34, 71-105</journal-ref><abstract>  This paper presents a model-based, unsupervised algorithm for recovering word
boundaries in a natural-language text from which they have been deleted. The
algorithm is derived from a probability model of the source that generated the
text. The fundamental structure of the model is specified abstractly so that
the detailed component models of phonology, word-order, and word frequency can
be replaced in a modular fashion. The model yields a language-independent,
prior probability distribution on all possible sequences of all possible words
over a given alphabet, based on the assumption that the input was generated by
concatenating words from a fixed but unknown lexicon. The model is unusual in
that it treats the generation of a complete corpus, regardless of length, as a
single event in the probability space. Accordingly, the algorithm does not
estimate a probability distribution on words; instead, it attempts to calculate
the prior probabilities of various word sequences that could underlie the
observed text. Experiments on phonemic transcripts of spontaneous speech by
parents to young children suggest that this algorithm is more effective than
other proposed algorithms, at least when utterance boundaries are given and the
text includes a substantial number of short utterances.
  Keywords: Bayesian grammar induction, probability models, minimum description
length (MDL), unsupervised learning, cognitive modeling, language acquisition,
segmentation
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9905008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9905008</id><created>1999-05-19</created><authors><author><keyname>Rooth</keyname><forenames>Mats</forenames><affiliation>IMS, University of Stuttgart</affiliation></author><author><keyname>Riezler</keyname><forenames>Stefan</forenames><affiliation>IMS, University of Stuttgart</affiliation></author><author><keyname>Prescher</keyname><forenames>Detlef</forenames><affiliation>IMS, University of Stuttgart</affiliation></author><author><keyname>Carroll</keyname><forenames>Glenn</forenames><affiliation>IMS, University of Stuttgart</affiliation></author><author><keyname>Beil</keyname><forenames>Franz</forenames><affiliation>IMS, University of Stuttgart</affiliation></author></authors><title>Inducing a Semantically Annotated Lexicon via EM-Based Clustering</title><categories>cs.CL cs.AI cs.LG</categories><comments>8 pages, uses colacl.sty. Proceedings of the 37th Annual Meeting of
  the ACL, 1999</comments><acm-class>I.2.6; I.2.7; I.5.3</acm-class><abstract>  We present a technique for automatic induction of slot annotations for
subcategorization frames, based on induction of hidden classes in the EM
framework of statistical estimation. The models are empirically evalutated by a
general decision test. Induction of slot labeling for subcategorization frames
is accomplished by a further application of EM, and applied experimentally on
frame observations derived from parsing large corpora. We outline an
interpretation of the learned representations as theoretical-linguistic
decompositional lexical entries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9905009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9905009</id><created>1999-05-19</created><authors><author><keyname>Beil</keyname><forenames>Franz</forenames><affiliation>IMS, University of Stuttgart</affiliation></author><author><keyname>Carroll</keyname><forenames>Glenn</forenames><affiliation>IMS, University of Stuttgart</affiliation></author><author><keyname>Prescher</keyname><forenames>Detlef</forenames><affiliation>IMS, University of Stuttgart</affiliation></author><author><keyname>Riezler</keyname><forenames>Stefan</forenames><affiliation>IMS, University of Stuttgart</affiliation></author><author><keyname>Rooth</keyname><forenames>Mats</forenames><affiliation>IMS, University of Stuttgart</affiliation></author></authors><title>Inside-Outside Estimation of a Lexicalized PCFG for German</title><categories>cs.CL cs.LG</categories><comments>8 pages, uses colacl.sty. Proceedings of the 37th Annual Meeting of
  the ACL, 1999</comments><acm-class>I.2.6; I.2.7</acm-class><abstract>  The paper describes an extensive experiment in inside-outside estimation of a
lexicalized probabilistic context free grammar for German verb-final clauses.
Grammar and formalism features which make the experiment feasible are
described. Successive models are evaluated on precision and recall of phrase
markup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9905010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9905010</id><created>1999-05-19</created><authors><author><keyname>Riezler</keyname><forenames>Stefan</forenames><affiliation>IMS, University of Stuttgart</affiliation></author></authors><title>Statistical Inference and Probabilistic Modelling for Constraint-Based
  NLP</title><categories>cs.CL cs.LG</categories><comments>12 pages, uses knvns98.sty. Proceedings of the 4th Conference on
  Natural Language Processing (KONVENS-98)</comments><acm-class>I.2.6; I.2.7</acm-class><abstract>  We present a probabilistic model for constraint-based grammars and a method
for estimating the parameters of such models from incomplete, i.e., unparsed
data. Whereas methods exist to estimate the parameters of probabilistic
context-free grammars from incomplete data (Baum 1970), so far for
probabilistic grammars involving context-dependencies only parameter estimation
techniques from complete, i.e., fully parsed data have been presented (Abney
1997). However, complete-data estimation requires labor-intensive, error-prone,
and grammar-specific hand-annotating of large language corpora. We present a
log-linear probability model for constraint logic programming, and a general
algorithm to estimate the parameters of such models from incomplete data by
extending the estimation algorithm of Della-Pietra, Della-Pietra, and Lafferty
(1997) to incomplete data settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9905011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9905011</id><created>1999-05-20</created><authors><author><keyname>Tumer</keyname><forenames>Kagan</forenames></author><author><keyname>Ramanujam</keyname><forenames>Nirmala</forenames></author><author><keyname>Ghosh</keyname><forenames>Joydeep</forenames></author><author><keyname>Richards-Kortum</keyname><forenames>Rebecca</forenames></author></authors><title>Ensembles of Radial Basis Function Networks for Spectroscopic Detection
  of Cervical Pre-Cancer</title><categories>cs.NE cs.LG q-bio</categories><comments>23 pages</comments><acm-class>I.5.1 ; J.3</acm-class><journal-ref>IEEE Transactions on Biomedical Engineering, vol 45, no. 8, pp
  953-962, 1998</journal-ref><abstract>  The mortality related to cervical cancer can be substantially reduced through
early detection and treatment. However, current detection techniques, such as
Pap smear and colposcopy, fail to achieve a concurrently high sensitivity and
specificity.
  In vivo fluorescence spectroscopy is a technique which quickly,
non-invasively and quantitatively probes the biochemical and morphological
changes that occur in pre-cancerous tissue.
  A multivariate statistical algorithm was used to extract clinically useful
information from tissue spectra acquired from 361 cervical sites from 95
patients at 337, 380 and 460 nm excitation wavelengths. The multivariate
statistical analysis was also employed to reduce the number of fluorescence
excitation-emission wavelength pairs required to discriminate healthy tissue
samples from pre-cancerous tissue samples. The use of connectionist methods
such as multi layered perceptrons, radial basis function networks, and
ensembles of such networks was investigated. RBF ensemble algorithms based on
fluorescence spectra potentially provide automated, and near real-time
implementation of pre-cancer detection in the hands of non-experts. The results
are more reliable, direct and accurate than those achieved by either human
experts or multivariate statistical algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9905012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9905012</id><created>1999-05-20</created><authors><author><keyname>Tumer</keyname><forenames>Kagan</forenames></author><author><keyname>Ghosh</keyname><forenames>Joydeep</forenames></author></authors><title>Linear and Order Statistics Combiners for Pattern Classification</title><categories>cs.NE cs.LG</categories><comments>31 pages</comments><acm-class>I.5.1 ; I.2.6</acm-class><journal-ref>Combining Artificial Neural Networks,Ed. Amanda Sharkey, pp
  127-162, Springer Verlag, 1999</journal-ref><abstract>  Several researchers have experimentally shown that substantial improvements
can be obtained in difficult pattern recognition problems by combining or
integrating the outputs of multiple classifiers. This chapter provides an
analytical framework to quantify the improvements in classification results due
to combining. The results apply to both linear combiners and order statistics
combiners. We first show that to a first order approximation, the error rate
obtained over and above the Bayes error rate, is directly proportional to the
variance of the actual decision boundaries around the Bayes optimum boundary.
Combining classifiers in output space reduces this variance, and hence reduces
the &quot;added&quot; error. If N unbiased classifiers are combined by simple averaging,
the added error rate can be reduced by a factor of N if the individual errors
in approximating the decision boundaries are uncorrelated. Expressions are then
derived for linear combiners which are biased or correlated, and the effect of
output correlations on ensemble performance is quantified. For order statistics
based non-linear combiners, we derive expressions that indicate how much the
median, the maximum and in general the ith order statistic can improve
classifier performance. The analysis presented here facilitates the
understanding of the relationships among error rates, classifier boundary
distributions, and combining in output space. Experimental results on several
public domain data sets are provided to illustrate the benefits of combining
and to support the analytical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9905013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9905013</id><created>1999-05-20</created><authors><author><keyname>Tumer</keyname><forenames>Kagan</forenames></author><author><keyname>Ghosh</keyname><forenames>Joydeep</forenames></author></authors><title>Robust Combining of Disparate Classifiers through Order Statistics</title><categories>cs.LG cs.CV cs.NE</categories><comments>22 pages</comments><report-no>UT-CVIS-TR-99-001 (The University of Texas)</report-no><acm-class>I.5.1 ; G.3</acm-class><abstract>  Integrating the outputs of multiple classifiers via combiners or
meta-learners has led to substantial improvements in several difficult pattern
recognition problems. In the typical setting investigated till now, each
classifier is trained on data taken or resampled from a common data set, or
(almost) randomly selected subsets thereof, and thus experiences similar
quality of training data. However, in certain situations where data is acquired
and analyzed on-line at several geographically distributed locations, the
quality of data may vary substantially, leading to large discrepancies in
performance of individual classifiers. In this article we introduce and
investigate a family of classifiers based on order statistics, for robust
handling of such cases. Based on a mathematical modeling of how the decision
boundaries are affected by order statistic combiners, we derive expressions for
the reductions in error expected when such combiners are used. We show
analytically that the selection of the median, the maximum and in general, the
$i^{th}$ order statistic improves classification performance. Furthermore, we
introduce the trim and spread combiners, both based on linear combinations of
the ordered classifier outputs, and show that they are quite beneficial in
presence of outliers or uneven classifier performance. Experimental results on
several public domain data sets corroborate these findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9905014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9905014</id><created>1999-05-21</created><authors><author><keyname>Dietterich</keyname><forenames>Thomas G.</forenames></author></authors><title>Hierarchical Reinforcement Learning with the MAXQ Value Function
  Decomposition</title><categories>cs.LG</categories><comments>63 pages, 15 figures</comments><acm-class>I.2.6</acm-class><abstract>  This paper presents the MAXQ approach to hierarchical reinforcement learning
based on decomposing the target Markov decision process (MDP) into a hierarchy
of smaller MDPs and decomposing the value function of the target MDP into an
additive combination of the value functions of the smaller MDPs. The paper
defines the MAXQ hierarchy, proves formal results on its representational
power, and establishes five conditions for the safe use of state abstractions.
The paper presents an online model-free learning algorithm, MAXQ-Q, and proves
that it converges wih probability 1 to a kind of locally-optimal policy known
as a recursively optimal policy, even in the presence of the five kinds of
state abstraction. The paper evaluates the MAXQ representation and MAXQ-Q
through a series of experiments in three domains and shows experimentally that
MAXQ-Q (with state abstractions) converges to a recursively optimal policy much
faster than flat Q learning. The fact that MAXQ learns a representation of the
value function has an important benefit: it makes it possible to compute and
execute an improved, non-hierarchical policy via a procedure similar to the
policy improvement step of policy iteration. The paper demonstrates the
effectiveness of this non-hierarchical execution experimentally. Finally, the
paper concludes with a comparison to related work and a discussion of the
design tradeoffs in hierarchical reinforcement learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9905015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9905015</id><created>1999-05-21</created><authors><author><keyname>Dietterich</keyname><forenames>Thomas G.</forenames></author></authors><title>State Abstraction in MAXQ Hierarchical Reinforcement Learning</title><categories>cs.LG</categories><comments>7 pages, 2 figures</comments><acm-class>I.2.6</acm-class><abstract>  Many researchers have explored methods for hierarchical reinforcement
learning (RL) with temporal abstractions, in which abstract actions are defined
that can perform many primitive actions before terminating. However, little is
known about learning with state abstractions, in which aspects of the state
space are ignored. In previous work, we developed the MAXQ method for
hierarchical RL. In this paper, we define five conditions under which state
abstraction can be combined with the MAXQ value function decomposition. We
prove that the MAXQ-Q learning algorithm converges under these conditions and
show experimentally that state abstraction is important for the successful
application of MAXQ-Q learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9905016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9905016</id><created>1999-05-27</created><authors><author><keyname>Chaves</keyname><forenames>M.</forenames></author></authors><title>Programs with Stringent Performance Objectives Will Often Exhibit
  Chaotic Behavior</title><categories>cs.CE cs.CC</categories><comments>7 pages, no figures</comments><acm-class>68N05,68Q20,90D05,90D80</acm-class><abstract>  Software for the resolution of certain kind of problems, those that rate high
in the Stringent Performance Objectives adjustment factor (IFPUG scheme), can
be described using a combination of game theory and autonomous systems. From
this description it can be shown that some of those problems exhibit chaotic
behavior, an important fact in understanding the functioning of the related
software. As a relatively simple example, it is shown that chess exhibits
chaotic behavior in its configuration space. This implies that static
evaluators in chess programs have intrinsic limitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906001</identifier>
 <datestamp>2007-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906001</id><created>1999-06-01</created><authors><author><keyname>Bent</keyname><forenames>Russell</forenames></author><author><keyname>Schear</keyname><forenames>Michael</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Istrate</keyname><forenames>Gabriel</forenames></author></authors><title>On Bounded-Weight Error-Correcting Codes</title><categories>cs.IT math.IT</categories><comments>10 pages, 3 tables</comments><acm-class>H.1.1; E.4</acm-class><abstract>  This paper computationally obtains optimal bounded-weight, binary,
error-correcting codes for a variety of distance bounds and dimensions. We
compare the sizes of our codes to the sizes of optimal constant-weight, binary,
error-correcting codes, and evaluate the differences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906002</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906002</id><created>1999-06-01</created><authors><author><keyname>Harnad</keyname><forenames>Stevan</forenames></author></authors><title>The Symbol Grounding Problem</title><categories>cs.AI</categories><acm-class>I.2.0</acm-class><journal-ref>Physica D 42: 335-346</journal-ref><doi>10.1016/0167-2789(90)90087-6</doi><abstract>  How can the semantic interpretation of a formal symbol system be made
intrinsic to the system, rather than just parasitic on the meanings in our
heads? How can the meanings of the meaningless symbol tokens, manipulated
solely on the basis of their (arbitrary) shapes, be grounded in anything but
other meaningless symbols? The problem is analogous to trying to learn Chinese
from a Chinese/Chinese dictionary alone. A candidate solution is sketched:
Symbolic representations must be grounded bottom-up in nonsymbolic
representations of two kinds: (1) &quot;iconic representations,&quot; which are analogs
of the proximal sensory projections of distal objects and events, and (2)
&quot;categorical representations,&quot; which are learned and innate feature-detectors
that pick out the invariant features of object and event categories from their
sensory projections. Elementary symbols are the names of these object and event
categories, assigned on the basis of their (nonsymbolic) categorical
representations. Higher-order (3) &quot;symbolic representations,&quot; grounded in these
elementary symbols, consist of symbol strings describing category membership
relations (e.g., &quot;An X is a Y that is Z&quot;).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906003</id><created>1999-06-02</created><authors><author><keyname>Siegel</keyname><forenames>Melanie</forenames></author></authors><title>The syntactic processing of particles in Japanese spoken language</title><categories>cs.CL</categories><comments>8 pages</comments><acm-class>F.2.2</acm-class><journal-ref>Proceedings of the 13th Pacific Asia Conference on Language,
  Information and Computation. 1999</journal-ref><abstract>  Particles fullfill several distinct central roles in the Japanese language.
They can mark arguments as well as adjuncts, can be functional or have semantic
funtions. There is, however, no straightforward matching from particles to
functions, as, e.g., GA can mark the subject, the object or an adjunct of a
sentence. Particles can cooccur. Verbal arguments that could be identified by
particles can be eliminated in the Japanese sentence. And finally, in spoken
language particles are often omitted. A proper treatment of particles is thus
necessary to make an analysis of Japanese sentences possible. Our treatment is
based on an empirical investigation of 800 dialogues. We set up a type
hierarchy of particles motivated by their subcategorizational and
modificational behaviour. This type hierarchy is part of the Japanese syntax in
VERBMOBIL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906004</id><created>1999-06-02</created><authors><author><keyname>Buchholz</keyname><forenames>Sabine</forenames></author><author><keyname>Veenstra</keyname><forenames>Jorn</forenames></author><author><keyname>Daelemans</keyname><forenames>Walter</forenames></author></authors><title>Cascaded Grammatical Relation Assignment</title><categories>cs.CL cs.LG</categories><comments>8 pages, to appear in: proceedings of EMNLP/VLC-99, University of
  Maryland, USA, June 21-22, 1999</comments><report-no>ILK-9908</report-no><acm-class>I.6.2;I.7.1</acm-class><abstract>  In this paper we discuss cascaded Memory-Based grammatical relations
assignment. In the first stages of the cascade, we find chunks of several types
(NP,VP,ADJP,ADVP,PP) and label them with their adverbial function (e.g. local,
temporal). In the last stage, we assign grammatical relations to pairs of
chunks. We studied the effect of adding several levels to this cascaded
classifier and we found that even the less performing chunkers enhanced the
performance of the relation finder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906005</id><created>1999-06-02</created><authors><author><keyname>Daelemans</keyname><forenames>Walter</forenames></author><author><keyname>Buchholz</keyname><forenames>Sabine</forenames></author><author><keyname>Veenstra</keyname><forenames>Jorn</forenames></author></authors><title>Memory-Based Shallow Parsing</title><categories>cs.CL cs.LG</categories><comments>8 pages, to appear in: Proceedings of the EACL'99 workshop on
  Computational Natural Language Learning (CoNLL-99), Bergen, Norway, June 1999</comments><report-no>ILK-9907</report-no><acm-class>I.6.2;I.7.1</acm-class><abstract>  We present a memory-based learning (MBL) approach to shallow parsing in which
POS tagging, chunking, and identification of syntactic relations are formulated
as memory-based modules. The experiments reported in this paper show
competitive results, the F-value for the Wall Street Journal (WSJ) treebank is:
93.8% for NP chunking, 94.7% for VP chunking, 77.1% for subject detection and
79.0% for object detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906006</id><created>1999-06-02</created><updated>1999-06-03</updated><authors><author><keyname>Sima'an</keyname><forenames>Khalil</forenames></author></authors><title>Learning Efficient Disambiguation</title><categories>cs.CL cs.AI</categories><comments>222 pages</comments><report-no>Ph.d. thesis, ILLC Dissertation Series number 1999-02, University of
  Amsterdam</report-no><acm-class>I.2.6, I.2.7, J.5, F.2</acm-class><abstract>  This dissertation analyses the computational properties of current
performance-models of natural language parsing, in particular Data Oriented
Parsing (DOP), points out some of their major shortcomings and suggests
suitable solutions. It provides proofs that various problems of probabilistic
disambiguation are NP-Complete under instances of these performance-models, and
it argues that none of these models accounts for attractive efficiency
properties of human language processing in limited domains, e.g. that frequent
inputs are usually processed faster than infrequent ones. The central
hypothesis of this dissertation is that these shortcomings can be eliminated by
specializing the performance-models to the limited domains. The dissertation
addresses &quot;grammar and model specialization&quot; and presents a new framework, the
Ambiguity-Reduction Specialization (ARS) framework, that formulates the
necessary and sufficient conditions for successful specialization. The
framework is instantiated into specialization algorithms and applied to
specializing DOP. Novelties of these learning algorithms are 1) they limit the
hypotheses-space to include only &quot;safe&quot; models, 2) are expressed as constrained
optimization formulae that minimize the entropy of the training tree-bank given
the specialized grammar, under the constraint that the size of the specialized
model does not exceed a predefined maximum, and 3) they enable integrating the
specialized model with the original one in a complementary manner. The
dissertation provides experiments with initial implementations and compares the
resulting Specialized DOP (SDOP) models to the original DOP models with
encouraging results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906007</identifier>
 <datestamp>2008-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906007</id><created>1999-06-04</created><authors><author><keyname>Engelfriet</keyname><forenames>Joost</forenames></author><author><keyname>Hoogeboom</keyname><forenames>Hendrik Jan</forenames></author></authors><title>MSO definable string transductions and two-way finite state transducers</title><categories>cs.LO cs.CC</categories><comments>63 pages, LaTeX2e. Extended abstract presented at 26-th ICALP, 1999</comments><report-no>TR 98-13, LIACS, Leiden University, The Netherlands</report-no><acm-class>F.4.1; F.4.3; F.1.1</acm-class><abstract>  String transductions that are definable in monadic second-order (mso) logic
(without the use of parameters) are exactly those realized by deterministic
two-way finite state transducers. Nondeterministic mso definable string
transductions (i.e., those definable with the use of parameters) correspond to
compositions of two nondeterministic two-way finite state transducers that have
the finite visit property. Both families of mso definable string transductions
are characterized in terms of Hennie machines, i.e., two-way finite state
transducers with the finite visit property that are allowed to rewrite their
input tape.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906008</identifier>
 <datestamp>2015-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906008</id><created>1999-06-04</created><updated>2015-01-28</updated><authors><author><keyname>Jiang</keyname><forenames>Tao</forenames><affiliation>McMaster U.</affiliation></author><author><keyname>Li</keyname><forenames>Ming</forenames><affiliation>U. Waterloo</affiliation></author><author><keyname>Vitanyi</keyname><forenames>Paul</forenames><affiliation>CWI &amp; U. Amsterdam</affiliation></author></authors><title>A Lower Bound on the Average-Case Complexity of Shellsort</title><categories>cs.CC cs.DS</categories><comments>Preliminary version 10 pages, 2 figures, Proc ICALP 99, Springer
  LNCS; final version (given here) LaTeX 5 pages published in J. Assoc. Comp.
  Mach. as below</comments><acm-class>F.2.2; E.1</acm-class><journal-ref>T. Jiang, M. Li, and P. Vitanyi, A lower bound on the average-case
  complexity of Shellsort, J. Assoc. Comp. Mach., 47:5(2000), 905--91</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove a general lower bound on the average-case complexity of Shellsort:
the average number of data-movements (and comparisons) made by a $p$-pass
Shellsort for any incremental sequence is $\Omega (pn^{1 + 1/p})$ for every
$p$. The proof method is an incompressibility argument based on Kolmogorov
complexity. Using similar techniques, the average-case complexity of several
other sorting algorithms is analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906009</id><created>1999-06-06</created><authors><author><keyname>Brants</keyname><forenames>Thorsten</forenames></author></authors><title>Cascaded Markov Models</title><categories>cs.CL</categories><comments>8 pages</comments><acm-class>I.2.7</acm-class><journal-ref>Proceedings of EACL-99, Bergen, Norway</journal-ref><abstract>  This paper presents a new approach to partial parsing of context-free
structures. The approach is based on Markov Models. Each layer of the resulting
structure is represented by its own Markov Model, and output of a lower layer
is passed as input to the next higher layer. An empirical evaluation of the
method yields very good results for NP/PP chunking of German newspaper texts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906010</id><created>1999-06-07</created><authors><author><keyname>Makarov</keyname><forenames>Victor</forenames></author></authors><title>Predicate Logic with Definitions</title><categories>cs.LO cs.AI</categories><comments>15 pages</comments><acm-class>F.4.1; I.2.4</acm-class><abstract>  Predicate Logic with Definitions (PLD or D-logic) is a modification of
first-order logic intended mostly for practical formalization of mathematics.
The main syntactic constructs of D-logic are terms, formulas and definitions. A
definition is a definition of variables, a definition of constants, or a
composite definition (D-logic has also abbreviation definitions called
abbreviations). Definitions can be used inside terms and formulas. This
possibility alleviates introducing new quantifier-like names. Composite
definitions allow constructing new definitions from existing ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906011</id><created>1999-06-09</created><authors><author><keyname>Chen</keyname><forenames>W.</forenames></author></authors><title>A Newton method without evaluation of nonlinear function values</title><categories>cs.CE cs.NA</categories><comments>Welcome any comments to chenw@homer.shinshu-u.ac.jp or
  chenwwhy@hotmail.com</comments><acm-class>G.1.3; G.1.5; G.1.2</acm-class><abstract>  The present author recently proposed and proved a relationship theorem
between nonlinear polynomial equations and the corresponding Jacobian matrix.
By using this theorem, this paper derives a Newton iterative formula without
requiring the evaluation of nonlinear function values in the solution of
nonlinear polynomial-only problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906012</id><created>1999-06-09</created><authors><author><keyname>Chen</keyname><forenames>W.</forenames></author><author><keyname>Shu</keyname><forenames>C.</forenames></author><author><keyname>He</keyname><forenames>W.</forenames></author></authors><title>The application of special matrix product to differential quadrature
  solution of geometrically nonlinear bending of orthotropic rectangular plates</title><categories>cs.CE cs.NA</categories><comments>Welcome any comments to chenw@homer.shinshu-u.ac.jp or
  chenwwhy@hotmail.com</comments><acm-class>G.1.3; G.1.5; G.1.2; G.1.8</acm-class><abstract>  The Hadamard and SJT product of matrices are two types of special matrix
product. The latter was first defined by Chen. In this study, they are applied
to the differential quadrature (DQ) solution of geometrically nonlinear bending
of isotropic and orthotropic rectangular plates. By using the Hadamard product,
the nonlinear formulations are greatly simplified, while the SJT product
approach minimizes the effort to evaluate the Jacobian derivative matrix in the
Newton-Raphson method for solving the resultant nonlinear formulations. In
addition, the coupled nonlinear formulations for the present problems can
easily be decoupled by means of the Hadamard and SJT product. Therefore, the
size of the simultaneous nonlinear algebraic equations is reduced by two-thirds
and the computing effort and storage requirements are alleviated greatly. Two
recent approaches applying the multiple boundary conditions are employed in the
present DQ nonlinear computations. The solution accuracies are improved
obviously in comparison to the previously given by Bert et al. The numerical
results and detailed solution procedures are provided to demonstrate the superb
efficiency, accuracy and simplicity of the new approaches in applying DQ method
for nonlinear computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906013</id><created>1999-06-14</created><authors><author><keyname>Glesner</keyname><forenames>Sabine</forenames></author><author><keyname>Stroetmann</keyname><forenames>Karl</forenames></author></authors><title>Combining Inclusion Polymorphism and Parametric Polymorphism</title><categories>cs.LO cs.PL</categories><comments>14 pages</comments><acm-class>D.3.3; F.3.3</acm-class><abstract>  We show that the question whether a term is typable is decidable for type
systems combining inclusion polymorphism with parametric polymorphism provided
the type constructors are at most unary. To prove this result we first reduce
the typability problem to the problem of solving a system of type inequations.
The result is then obtained by showing that the solvability of the resulting
system of type inequations is decidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906014</id><created>1999-06-14</created><authors><author><keyname>van Zanten</keyname><forenames>Gert Veldhuijzen</forenames></author><author><keyname>Bouma</keyname><forenames>Gosse</forenames></author><author><keyname>Sima'an</keyname><forenames>Khalil</forenames></author><author><keyname>van Noord</keyname><forenames>Gertjan</forenames></author><author><keyname>Bonnema</keyname><forenames>Remko</forenames></author></authors><title>Evaluation of the NLP Components of the OVIS2 Spoken Dialogue System</title><categories>cs.CL</categories><comments>Proceedings of CLIN 99</comments><acm-class>H.4.0;H.5.1;H.5.2;I.2.7</acm-class><abstract>  The NWO Priority Programme Language and Speech Technology is a 5-year
research programme aiming at the development of spoken language information
systems. In the Programme, two alternative natural language processing (NLP)
modules are developed in parallel: a grammar-based (conventional, rule-based)
module and a data-oriented (memory-based, stochastic, DOP) module. In order to
compare the NLP modules, a formal evaluation has been carried out three years
after the start of the Programme. This paper describes the evaluation procedure
and the evaluation results. The grammar-based component performs much better
than the data-oriented one in this comparison.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906015</id><created>1999-06-14</created><authors><author><keyname>Ferro</keyname><forenames>Lisa</forenames></author><author><keyname>Vilain</keyname><forenames>Marc</forenames></author><author><keyname>Yeh</keyname><forenames>Alexander</forenames></author></authors><title>Learning Transformation Rules to Find Grammatical Relations</title><categories>cs.CL</categories><comments>10 pages. Uses latex-acl.sty and named.sty</comments><acm-class>I.2.7</acm-class><journal-ref>Computational Natural Language Learning (CoNLL-99), pages 43-52,
  June, 1999. Bergen, Norway</journal-ref><abstract>  Grammatical relationships are an important level of natural language
processing. We present a trainable approach to find these relationships through
transformation sequences and error-driven learning. Our approach finds
grammatical relationships between core syntax groups and bypasses much of the
parsing phase. On our training and test set, our procedure achieves 63.6%
recall and 77.3% precision (f-score = 69.8).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906016</id><created>1999-06-17</created><authors><author><keyname>Samuel</keyname><forenames>Ken</forenames></author><author><keyname>Carberry</keyname><forenames>Sandra</forenames></author><author><keyname>Vijay-Shanker</keyname><forenames>K.</forenames></author></authors><title>Automatically Selecting Useful Phrases for Dialogue Act Tagging</title><categories>cs.AI cs.LG</categories><comments>14 pages, published in PACLING'99</comments><acm-class>I.2.7; I.2.6</acm-class><journal-ref>Samuel, Ken and Carberry, Sandra and Vijay-Shanker, K. 1999.
  Automatically Selecting Useful Phrases for Dialogue Act Tagging. In
  Proceedings of the Fourth Conference of the Pacific Association for
  Computational Linguistics. Waterloo, Ontario, Canada</journal-ref><abstract>  We present an empirical investigation of various ways to automatically
identify phrases in a tagged corpus that are useful for dialogue act tagging.
We found that a new method (which measures a phrase's deviation from an
optimally-predictive phrase), enhanced with a lexical filtering mechanism,
produces significantly better cues than manually-selected cue phrases, the
exhaustive set of phrases in a training corpus, and phrases chosen by
traditional metrics, like mutual information and information gain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906017</id><created>1999-06-22</created><authors><author><keyname>Rigo</keyname><forenames>Michel</forenames></author></authors><title>Generalization of automatic sequences for numeration systems on a
  regular language</title><categories>cs.CC</categories><comments>10 pages, 3 figures</comments><acm-class>F.1.1; F.1.3; F.4.3</acm-class><journal-ref>Theoret. Comput. Sci. 244 (2000) 271--281</journal-ref><abstract>  Let L be an infinite regular language on a totally ordered alphabet (A,&lt;).
Feeding a finite deterministic automaton (with output) with the words of L
enumerated lexicographically with respect to &lt; leads to an infinite sequence
over the output alphabet of the automaton. This process generalizes the concept
of k-automatic sequence for abstract numeration systems on a regular language
(instead of systems in base k). Here, I study the first properties of these
sequences and their relations with numeration systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906018</id><created>1999-06-21</created><authors><author><keyname>Durr</keyname><forenames>Christoph</forenames></author><author><keyname>Chrobak</keyname><forenames>Marek</forenames></author></authors><title>Reconstructing Polyatomic Structures from Discrete X-Rays:
  NP-Completeness Proof for Three Atoms</title><categories>cs.DS cs.CC</categories><acm-class>F.2.2; G.2.1</acm-class><journal-ref>Proceedings of the 23rd International Symposium on Mathematical
  Foundations of Computer Science, LNCS vol 1450, 185-193, 1998</journal-ref><abstract>  We address a discrete tomography problem that arises in the study of the
atomic structure of crystal lattices. A polyatomic structure T can be defined
as an integer lattice in dimension D&gt;=2, whose points may be occupied by $c$
distinct types of atoms. To ``analyze'' T, we conduct ell measurements that we
call_discrete X-rays_. A discrete X-ray in direction xi determines the number
of atoms of each type on each line parallel to xi. Given ell such non-parallel
X-rays, we wish to reconstruct T.
  The complexity of the problem for c=1 (one atom type) has been completely
determined by Gardner, Gritzmann and Prangenberg, who proved that the problem
is NP-complete for any dimension D&gt;=2 and ell&gt;=3 non-parallel X-rays, and that
it can be solved in polynomial time otherwise.
  The NP-completeness result above clearly extends to any c&gt;=2, and therefore
when studying the polyatomic case we can assume that ell=2. As shown in another
article by the same authors, this problem is also NP-complete for c&gt;=6 atoms,
even for dimension D=2 and axis-parallel X-rays. They conjecture that the
problem remains NP-complete for c=3,4,5, although, as they point out, the proof
idea does not seem to extend to c&lt;=5.
  We resolve the conjecture by proving that the problem is indeed NP-complete
for c&gt;=3 in 2D, even for axis-parallel X-rays. Our construction relies heavily
on some structure results for the realizations of 0-1 matrices with given row
and column sums.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906019</id><created>1999-06-22</created><updated>1999-06-30</updated><authors><author><keyname>Petasis</keyname><forenames>G.</forenames><affiliation>Software &amp; Knowledge Engineering Lab, Institute of Informatics &amp; Telecommunications, NCSR Demokritos, Greece</affiliation></author><author><keyname>Paliouras</keyname><forenames>G.</forenames><affiliation>Software &amp; Knowledge Engineering Lab, Institute of Informatics &amp; Telecommunications, NCSR Demokritos, Greece</affiliation></author><author><keyname>Karkaletsis</keyname><forenames>V.</forenames><affiliation>Software &amp; Knowledge Engineering Lab, Institute of Informatics &amp; Telecommunications, NCSR Demokritos, Greece</affiliation></author><author><keyname>Spyropoulos</keyname><forenames>C. D.</forenames><affiliation>Software &amp; Knowledge Engineering Lab, Institute of Informatics &amp; Telecommunications, NCSR Demokritos, Greece</affiliation></author><author><keyname>Androutsopoulos</keyname><forenames>I.</forenames><affiliation>Software &amp; Knowledge Engineering Lab, Institute of Informatics &amp; Telecommunications, NCSR Demokritos, Greece</affiliation></author></authors><title>Resolving Part-of-Speech Ambiguity in the Greek Language Using Learning
  Techniques</title><categories>cs.CL cs.AI</categories><comments>6 pages. To appear in the Proceedings of the ECCAI Advanced Course on
  Artificial Intelligence(ACAI'99), Chania, Greece, July 1999</comments><acm-class>I.2.6 ; I.2.7</acm-class><journal-ref>In Fakotakis, N. et al. (Eds.), Machine Learning in Human Language
  Technology (Proceedings of the ACAI Workshop), pp. 29-34, Chania, Greece,
  1999.</journal-ref><abstract>  This article investigates the use of Transformation-Based Error-Driven
learning for resolving part-of-speech ambiguity in the Greek language. The aim
is not only to study the performance, but also to examine its dependence on
different thematic domains. Results are presented here for two different test
cases: a corpus on &quot;management succession events&quot; and a general-theme corpus.
The two experiments show that the performance of this method does not depend on
the thematic domain of the corpus, and its accuracy for the Greek language is
around 95%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906020</id><created>1999-06-22</created><authors><author><keyname>Androutsopoulos</keyname><forenames>I.</forenames><affiliation>Software &amp; Knowledge Engineering Lab, Institute of Informatics &amp; Telecommunications, NCSR Demokritos, Greece</affiliation></author></authors><title>Temporal Meaning Representations in a Natural Language Front-End</title><categories>cs.CL</categories><comments>15 pages. To appear in the Proceedings of the 12th International
  Symposium on Languages for Intensional Programming, Athens, Greece, 1999</comments><acm-class>I.2.7; F.4.1; H.5.2</acm-class><journal-ref>In Gergatsoulis, M. and Rondogiannis, P. (Eds.), Intensional
  Programming II (Proceedings of the 12th International Symposium on Languages
  for Intensional Programming, Athens, Greece, 1999), pp. 197-213, World
  Scientific, 2000.</journal-ref><abstract>  Previous work in the context of natural language querying of temporal
databases has established a method to map automatically from a large subset of
English time-related questions to suitable expressions of a temporal logic-like
language, called TOP. An algorithm to translate from TOP to the TSQL2 temporal
database language has also been defined. This paper shows how TOP expressions
could be translated into a simpler logic-like language, called BOT. BOT is very
close to traditional first-order predicate logic (FOPL), and hence existing
methods to manipulate FOPL expressions can be exploited to interface to
time-sensitive applications other than TSQL2 databases, maintaining the
existing English-to-TOP mapping.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906021</id><created>1999-06-22</created><authors><author><keyname>Durr</keyname><forenames>Christoph</forenames></author><author><keyname>Chrobak</keyname><forenames>Marek</forenames></author></authors><title>Reconstructing hv-Convex Polyominoes from Orthogonal Projections</title><categories>cs.DS</categories><acm-class>F.2.2; G.2.1</acm-class><journal-ref>Information Processing Letters, 69, 1999, 283-289</journal-ref><abstract>  Tomography is the area of reconstructing objects from projections. Here we
wish to reconstruct a set of cells in a two dimensional grid, given the number
of cells in every row and column. The set is required to be an hv-convex
polyomino, that is all its cells must be connected and the cells in every row
and column must be consecutive. A simple, polynomial algorithm for
reconstructing hv-convex polyominoes is provided, which is several orders of
magnitudes faster than the best previously known algorithm from Barcucci et al.
In addition, the problem of reconstructing a special class of centered
hv-convex polyominoes is addressed. (An object is centered if it contains a row
whose length equals the total width of the object). It is shown that in this
case the reconstruction problem can be solved in linear time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906022</id><created>1999-06-22</created><authors><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author><author><keyname>Pashchenko</keyname><forenames>Irena</forenames></author></authors><title>Zero-Parity Stabbing Information</title><categories>cs.CG cs.DM</categories><acm-class>F.2.2</acm-class><journal-ref>Proc. Japan Conf. Discrete Comput. Geom. '98, Dec. 1998, 93--97</journal-ref><abstract>  Everett et al. introduced several varieties of stabbing information for the
lines determined by pairs of vertices of a simple polygon P, and established
their relationships to vertex visibility and other combinatorial data. In the
same spirit, we define the ``zero-parity (ZP) stabbing information'' to be a
natural weakening of their ``weak stabbing information,'' retaining only the
distinction among {zero, odd, even&gt;0} in the number of polygon edges stabbed.
Whereas the weak stabbing information's relation to visibility remains an open
problem, we completely settle the analogous questions for zero-parity
information, with three results: (1) ZP information is insufficient to
distinguish internal from external visibility graph edges; (2) but it does
suffice for all polygons that avoid a certain complex substructure; and (3) the
natural generalization of ZP information to the continuous case of smooth
curves does distinguish internal from external visibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906023</id><created>1999-06-22</created><authors><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>Computational Geometry Column 35</title><categories>cs.CG</categories><acm-class>F.2.2</acm-class><journal-ref>SIGACT News, 30(2) Issue #111 (1999) 31-32</journal-ref><abstract>  The subquadratic algorithm of Kapoor for finding shortest paths on a
polyhedron is described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906024</id><created>1999-06-23</created><updated>2000-10-27</updated><authors><author><keyname>Durr</keyname><forenames>Christoph</forenames></author><author><keyname>LeThanh</keyname><forenames>Huong</forenames></author><author><keyname>Santha</keyname><forenames>Miklos</forenames></author></authors><title>A decision procedure for well-formed linear quantum cellular automata</title><categories>cs.DS cs.CC quant-ph</categories><acm-class>F.1.1; F.2.1</acm-class><journal-ref>Random Structures and Algorithms 11, 381-394, 1997</journal-ref><abstract>  In this paper we introduce a new quantum computation model, the linear
quantum cellular automaton. Well-formedness is an essential property for any
quantum computing device since it enables us to define the probability of a
configuration in an observation as the squared magnitude of its amplitude. We
give an efficient algorithm which decides if a linear quantum cellular
automaton is well-formed. The complexity of the algorithm is $O(n^2)$ in the
algebraic model of computation if the input automaton has continuous
neighborhood.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906025</id><created>1999-06-24</created><authors><author><keyname>Daude</keyname><forenames>J.</forenames><affiliation>TALP Research Center. LSI Dept. Universitat Politecnica de Catalunya. Barcelona</affiliation></author><author><keyname>Padro</keyname><forenames>L.</forenames><affiliation>TALP Research Center. LSI Dept. Universitat Politecnica de Catalunya. Barcelona</affiliation></author><author><keyname>Rigau</keyname><forenames>G.</forenames><affiliation>TALP Research Center. LSI Dept. Universitat Politecnica de Catalunya. Barcelona</affiliation></author></authors><title>Mapping Multilingual Hierarchies Using Relaxation Labeling</title><categories>cs.CL</categories><comments>8 pages. 1 eps figure</comments><acm-class>I.2.7</acm-class><abstract>  This paper explores the automatic construction of a multilingual Lexical
Knowledge Base from pre-existing lexical resources. We present a new and robust
approach for linking already existing lexical/semantic hierarchies. We used a
constraint satisfaction algorithm (relaxation labeling) to select --among all
the candidate translations proposed by a bilingual dictionary-- the right
English WordNet synset for each sense in a taxonomy automatically derived from
a Spanish monolingual dictionary. Although on average, there are 15 possible
WordNet connections for each sense in the taxonomy, the method achieves an
accuracy over 80%. Finally, we also propose several ways in which this
technique could be applied to enrich and improve existing lexical databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906026</id><created>1999-06-25</created><authors><author><keyname>van Noord</keyname><forenames>Gertjan</forenames></author><author><keyname>Bouma</keyname><forenames>Gosse</forenames></author><author><keyname>Koeling</keyname><forenames>Rob</forenames></author><author><keyname>Nederhof</keyname><forenames>Mark-Jan</forenames></author></authors><title>Robust Grammatical Analysis for Spoken Dialogue Systems</title><categories>cs.CL</categories><comments>Accepted for JNLE</comments><acm-class>H.4.0;H.5.1;H.5.2;I.2.7</acm-class><abstract>  We argue that grammatical analysis is a viable alternative to concept
spotting for processing spoken input in a practical spoken dialogue system. We
discuss the structure of the grammar, and a model for robust parsing which
combines linguistic sources of information and statistical sources of
information. We discuss test results suggesting that grammatical processing
allows fast and accurate processing of spoken input.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906027</id><created>1999-06-25</created><authors><author><keyname>Wilks</keyname><forenames>Yorick</forenames></author><author><keyname>Catizone</keyname><forenames>Roberta</forenames></author></authors><title>Human-Computer Conversation</title><categories>cs.CL cs.HC</categories><comments>14 pages, 1 figure</comments><report-no>CS-99-04</report-no><acm-class>I.2.7;H.1.2</acm-class><abstract>  The article surveys a little of the history of the technology, sets out the
main current theoretical approaches in brief, and discusses the on-going
opposition between theoretical and empirical approaches. It illustrates the
situation with some discussion of CONVERSE, a system that won the Loebner prize
in 1997 and which displays features of both approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906028</id><created>1999-06-26</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author></authors><title>On the Power of Positive Turing Reductions</title><categories>cs.CC</categories><comments>7 pages</comments><acm-class>F.1.3; F.1.2</acm-class><abstract>  In the early 1980s, Selman's seminal work on positive Turing reductions
showed that positive Turing reduction to NP yields no greater computational
power than NP itself. Thus, positive Turing and Turing reducibility to NP
differ sharply unless the polynomial hierarchy collapses.
  We show that the situation is quite different for DP, the next level of the
boolean hierarchy. In particular, positive Turing reduction to DP already
yields all (and only) sets Turing reducibility to NP. Thus, positive Turing and
Turing reducibility to DP yield the same class. Additionally, we show that an
even weaker class, P(NP[1]), can be substituted for DP in this context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906029</id><created>1999-06-28</created><updated>1999-06-29</updated><authors><author><keyname>Chechik</keyname><forenames>M.</forenames></author><author><keyname>Paun</keyname><forenames>D.</forenames></author></authors><title>Events in Property Patterns</title><categories>cs.SE cs.AI cs.CL cs.SC</categories><comments>14 pages, 3 figures</comments><acm-class>D.2.4;F.3.1;F.4.1;I.2.4;D.2.1</acm-class><journal-ref>Lecture notes in Computer Science (Proceedings of 6 Spin'99
  Workshop)</journal-ref><abstract>  A pattern-based approach to the presentation, codification and reuse of
property specifications for finite-state verification was proposed by Dwyer and
his collegues. The patterns enable non-experts to read and write formal
specifications for realistic systems and facilitate easy conversion of
specifications between formalisms, such as LTL, CTL, QRE. In this paper, we
extend the pattern system with events - changes of values of variables in the
context of LTL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906030</id><created>1999-06-28</created><authors><author><keyname>Chechik</keyname><forenames>M.</forenames></author></authors><title>SCR3: towards usability of formal methods</title><categories>cs.SE</categories><comments>15 pages, 10 figures</comments><acm-class>D.2.4;D.2.6;D.2.2;D.2.1</acm-class><journal-ref>Proceedings of CASCON'98, December 1998, pp. 177-191</journal-ref><abstract>  This paper gives an overview of SCR3 -- a toolset designed to increase the
usability of formal methods for software development. Formal requirements are
specified in SCR3 in an easy to use and review format, and then used in
checking requirements for correctness and in verifying consistency between
annotated code and requirements.
  In this paper we discuss motivations behind this work, describe several tools
which are part of SCR3, and illustrate their operation on an example of a
Cruise Control system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906031</id><created>1999-06-28</created><authors><author><keyname>Paun</keyname><forenames>D.</forenames></author><author><keyname>Chechik</keyname><forenames>M.</forenames></author></authors><title>Events in Linear-Time Properties</title><categories>cs.SE</categories><comments>10 pages, 4 figures</comments><acm-class>D.2.4;F.3.1;F.4.1;I.2.4;D.2.1</acm-class><journal-ref>Proceedings of 4th IEEE International Symposium on Requirements
  Engineering, June 1999, pp. 123-132</journal-ref><abstract>  For over a decade, researchers in formal methods tried to create formalisms
that permit natural specification of systems and allow mathematical reasoning
about their correctness. The availability of fully-automated reasoning tools
enables more non-specialists to use formal methods effectively --- their
responsibility reduces to just specifying the model and expressing the desired
properties. Thus, it is essential that these properties be represented in a
language that is easy to use and sufficiently expressive.
  Linear-time temporal logic is a formalism that has been extensively used by
researchers for specifying properties of systems. When such properties are
closed under stuttering, i.e. their interpretation is not modified by
transitions that leave the system in the same state, verification tools can
utilize a partial-order reduction technique to reduce the size of the model and
thus analyze larger systems. If LTL formulas do not contain the ``next''
operator, the formulas are closed under stuttering, but the resulting language
is not expressive enough to capture many important properties, e.g., properties
involving events. Determining if an arbitrary LTL formula is closed under
stuttering is hard --- it has been proven to be PSPACE-complete.
  In this paper we relax the restriction on LTL that guarantees closure under
stuttering, introduce the notion of edges in the context of LTL, and provide
theorems that enable syntactic reasoning about closure under stuttering of LTL
formulas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906032</id><created>1999-06-29</created><authors><author><keyname>Wong</keyname><forenames>A.</forenames></author><author><keyname>Chechik</keyname><forenames>M.</forenames></author></authors><title>Formal Modeling in a Commercial Setting: A Case Study</title><categories>cs.SE</categories><comments>18 pages, 5 figures, to appear in Proceedings of FM'99: World
  Congress on Formal Methods, September 1999</comments><acm-class>F.3.1;K.6.3;D.2.7;D.2.5;D.2.1;C.3;D.2.4</acm-class><abstract>  This paper describes a case study conducted in collaboration with Nortel to
demonstrate the feasibility of applying formal modeling techniques to
telecommunication systems. A formal description language, SDL, was chosen by
our qualitative CASE tool evaluation to model a multimedia-messaging system
described by an 80-page natural language specification. Our model was used to
identify errors in the software requirements document and to derive test
suites, shadowing the existing development process and keeping track of a
variety of productivity data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906033</id><created>1999-06-29</created><authors><author><keyname>Cai</keyname><forenames>Jin-Yi</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Wechsung</keyname><forenames>Gerd</forenames></author></authors><title>Robust Reductions</title><categories>cs.CC</categories><comments>26 pages; 1 figure; will appear in Theory of Computing Systems;
  earlier versions appear as UR-CS-TR-666 and in COCOON 98</comments><acm-class>F.1.3; F.1.2</acm-class><abstract>  We continue the study of robust reductions initiated by Gavalda and Balcazar.
In particular, a 1991 paper of Gavalda and Balcazar claimed an optimal
separation between the power of robust and nondeterministic strong reductions.
Unfortunately, their proof is invalid. We re-establish their theorem.
  Generalizing robust reductions, we note that robustly strong reductions are
built from two restrictions, robust underproductivity and robust
overproductivity, both of which have been separately studied before in other
contexts. By systematically analyzing the power of these reductions, we explore
the extent to which each restriction weakens the power of reductions. We show
that one of these reductions yields a new, strong form of the Karp-Lipton
Theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9906034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9906034</id><created>1999-06-30</created><authors><author><keyname>Turcato</keyname><forenames>Davide</forenames></author><author><keyname>McFetridge</keyname><forenames>Paul</forenames></author><author><keyname>Popowich</keyname><forenames>Fred</forenames></author><author><keyname>Toole</keyname><forenames>Janine</forenames></author></authors><title>A Unified Example-Based and Lexicalist Approach to Machine Translation</title><categories>cs.CL</categories><comments>11 pages, to be presented at the 8th International Conference on
  Theoretical and Methodological Issues in Machine Translation (TMI-99)</comments><acm-class>I.2.7</acm-class><abstract>  We present an approach to Machine Translation that combines the ideas and
methodologies of the Example-Based and Lexicalist theoretical frameworks. The
approach has been implemented in a multilingual Machine Translation system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907001</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907001</id><created>1999-07-02</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Setting Parameters by Example</title><categories>cs.DS cs.CG</categories><comments>13 pages, 3 figures. To be presented at 40th IEEE Symp. Foundations
  of Computer Science (FOCS '99)</comments><acm-class>F.2.2; I.2.6</acm-class><journal-ref>SIAM J. Computing 32(3):643-653, 2003</journal-ref><doi>10.1137/S0097539700370084</doi><abstract>  We introduce a class of &quot;inverse parametric optimization&quot; problems, in which
one is given both a parametric optimization problem and a desired optimal
solution; the task is to determine parameter values that lead to the given
solution. We describe algorithms for solving such problems for minimum spanning
trees, shortest paths, and other &quot;optimal subgraph&quot; problems, and discuss
applications in multicast routing, vehicle path planning, resource allocation,
and board game programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907002</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907002</id><created>1999-07-02</created><authors><author><keyname>Ge</keyname><forenames>Xian-ping</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Smyth</keyname><forenames>Padhraic</forenames></author></authors><title>The Distribution of Cycle Lengths in Graphical Models for Iterative
  Decoding</title><categories>cs.DM</categories><comments>23 pages, 11 figures</comments><acm-class>E.4; G.2.2</acm-class><journal-ref>IEEE Trans. Information Theory 47(6):2549-2553, 2001</journal-ref><doi>10.1109/18.945266</doi><abstract>  This paper analyzes the distribution of cycle lengths in turbo decoding and
low-density parity check (LDPC) graphs. The properties of such cycles are of
significant interest in the context of iterative decoding algorithms which are
based on belief propagation or message passing. We estimate the probability
that there exist no simple cycles of length less than or equal to k at a
randomly chosen node in a turbo decoding graph using a combination of counting
arguments and independence assumptions. For large block lengths n, this
probability is approximately e^{-{2^{k-1}-4}/n}, k&gt;=4. Simulation results
validate the accuracy of the various approximations. For example, for turbo
codes with a block length of 64000, a randomly chosen node has a less than 1%
chance of being on a cycle of length less than or equal to 10, but has a
greater than 99.9% chance of being on a cycle of length less than or equal to
20. The effect of the &quot;S-random&quot; permutation is also analyzed and it is shown
that while it eliminates short cycles of length k&lt;8, it does not significantly
affect the overall distribution of cycle lengths. Similar analyses and
simulations are also presented for graphs for LDPC codes. The paper concludes
by commenting briefly on how these results may provide insight into the
practical success of iterative decoding methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907003</id><created>1999-07-05</created><authors><author><keyname>Bird</keyname><forenames>Steven</forenames></author><author><keyname>Liberman</keyname><forenames>Mark</forenames></author></authors><title>Annotation graphs as a framework for multidimensional linguistic data
  analysis</title><categories>cs.CL</categories><comments>10 pages, 10 figures, Towards Standards and Tools for Discourse
  Tagging, Proceedings of the Workshop. pp. 1-10. Association for Computational
  Linguistics</comments><acm-class>A.1; E.2; H.2.1; H.3.3; H.3.7; I.2.7</acm-class><abstract>  In recent work we have presented a formal framework for linguistic annotation
based on labeled acyclic digraphs. These `annotation graphs' offer a simple yet
powerful method for representing complex annotation structures incorporating
hierarchy and overlap. Here, we motivate and illustrate our approach using
discourse-level annotations of text and speech data drawn from the CALLHOME,
COCONUT, MUC-7, DAMSL and TRAINS annotation schemes. With the help of domain
specialists, we have constructed a hybrid multi-level annotation for a fragment
of the Boston University Radio Speech Corpus which includes the following
levels: segment, word, breath, ToBI, Tilt, Treebank, coreference and named
entity. We show how annotation graphs can represent hybrid multi-level
structures which derive from a diverse set of file formats. We also show how
the approach facilitates substantive comparison of multiple annotations of a
single signal based on different theoretical models. The discussion shows how
annotation graphs open the door to wide-ranging integration of tools, formats
and corpora.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907004</id><created>1999-07-05</created><updated>1999-10-13</updated><authors><author><keyname>Venkataraman</keyname><forenames>Anand</forenames></author></authors><title>MAP Lexicon is useful for segmentation and word discovery in
  child-directed speech</title><categories>cs.CL cs.LG</categories><comments>Because of rather fundamental changes to the underlying model
  proposed in the paper, it has been withdrawn from the archive.</comments><acm-class>I.2.6; I.2.7</acm-class><abstract>  Because of rather fundamental changes to the underlying model proposed in the
paper, it has been withdrawn from the archive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907005</id><created>1999-07-06</created><authors><author><keyname>Fossgaard</keyname><forenames>Eirik</forenames></author></authors><title>Alternative Local Discriminant Bases Using Empirical Expectation and
  Variance Estimation</title><categories>cs.NA</categories><comments>11 pages</comments><acm-class>I.5.2;I.5.3;I.5.4</acm-class><abstract>  We propose alternative discriminant measures for selecting the best basis
among a large collection of orthonormal bases for classification purposes. A
generalization of the Local Discriminant Basis Algorithm of Saito and Coifman
is constructed. The success of these new methods is evaluated and compared to
earlier methods in experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907006</id><created>1999-07-06</created><authors><author><keyname>Sang</keyname><forenames>Erik F. Tjong Kim</forenames></author><author><keyname>Veenstra</keyname><forenames>Jorn</forenames></author></authors><title>Representing Text Chunks</title><categories>cs.CL</categories><comments>7 pages</comments><acm-class>I.2.7</acm-class><journal-ref>EACL'99, Bergen</journal-ref><abstract>  Dividing sentences in chunks of words is a useful preprocessing step for
parsing, information extraction and information retrieval. (Ramshaw and Marcus,
1995) have introduced a &quot;convenient&quot; data representation for chunking by
converting it to a tagging task. In this paper we will examine seven different
data representations for the problem of recognizing noun phrase chunks. We will
show that the the data representation choice has a minor influence on chunking
performance. However, equipped with the most suitable data representation, our
memory-based learning chunker was able to improve the best published chunking
results for a standard data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907007</id><created>1999-07-06</created><updated>1999-07-07</updated><authors><author><keyname>Fujii</keyname><forenames>Atsushi</forenames></author><author><keyname>Ishikawa</keyname><forenames>Tetsuya</forenames></author></authors><title>Cross-Language Information Retrieval for Technical Documents</title><categories>cs.CL</categories><comments>9 pages, 5 Postscript figures, uses colacl.sty and psfig.tex</comments><acm-class>H.3.3; I.2.7</acm-class><journal-ref>Proceedings of the Joint ACL SIGDAT Conference on Empirical
  Methods in Natural Language Processing and Very Large Corpora, pp.29-37, 1999</journal-ref><abstract>  This paper proposes a Japanese/English cross-language information retrieval
(CLIR) system targeting technical documents. Our system first translates a
given query containing technical terms into the target language, and then
retrieves documents relevant to the translated query. The translation of
technical terms is still problematic in that technical terms are often compound
words, and thus new terms can be progressively created simply by combining
existing base words. In addition, Japanese often represents loanwords based on
its phonogram. Consequently, existing dictionaries find it difficult to achieve
sufficient coverage. To counter the first problem, we use a compound word
translation method, which uses a bilingual dictionary for base words and
collocational statistics to resolve translation ambiguity. For the second
problem, we propose a transliteration method, which identifies phonetic
equivalents in the target language. We also show the effectiveness of our
system using a test collection for CLIR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907008</id><created>1999-07-06</created><authors><author><keyname>Toole</keyname><forenames>Janine</forenames></author><author><keyname>Popowich</keyname><forenames>Fred</forenames></author><author><keyname>Nicholson</keyname><forenames>Devlan</forenames></author><author><keyname>Turcato</keyname><forenames>Davide</forenames></author><author><keyname>McFetridge</keyname><forenames>Paul</forenames></author></authors><title>Explanation-based Learning for Machine Translation</title><categories>cs.CL</categories><comments>12 pages, 3 figures, To appear in Proceedings of the 8th
  International Conference on Theoretical and Methodological Issues in Machine
  Translation</comments><acm-class>J.5</acm-class><abstract>  In this paper we present an application of explanation-based learning (EBL)
in the parsing module of a real-time English-Spanish machine translation system
designed to translate closed captions. We discuss the efficiency/coverage
trade-offs available in EBL and introduce the techniques we use to increase
coverage while maintaining a high level of space and time efficiency. Our
performance results indicate that this approach is effective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907009</id><created>1999-07-06</created><authors><author><keyname>Szalay</keyname><forenames>Alexander S.</forenames></author><author><keyname>Kunszt</keyname><forenames>Peter</forenames></author><author><keyname>Thakar</keyname><forenames>Ani</forenames></author><author><keyname>Gray</keyname><forenames>Jim</forenames></author></authors><title>Designing and Mining Multi-Terabyte Astronomy Archives: The Sloan
  Digital Sky Survey</title><categories>cs.DB cs.DL</categories><comments>9 pages, original at
  research.microsoft.com/~gray/papers/MS_TR_99_30_Sloan_Digital_Sky_Survey.doc</comments><report-no>MS_TR_99_30</report-no><acm-class>H.2, H.2.8,H.3.5, h.3.7</acm-class><abstract>  The next-generation astronomy digital archives will cover most of the
universe at fine resolution in many wave-lengths, from X-rays to ultraviolet,
optical, and infrared. The archives will be stored at diverse geographical
locations. One of the first of these projects, the Sloan Digital Sky Survey
(SDSS) will create a 5-wavelength catalog over 10,000 square degrees of the sky
(see http://www.sdss.org/). The 200 million objects in the multi-terabyte
database will have mostly numerical attributes, defining a space of 100+
dimensions. Points in this space have highly correlated distributions.
  The archive will enable astronomers to explore the data interactively. Data
access will be aided by a multidimensional spatial index and other indices.
The data will be partitioned in many ways. Small tag objects consisting of the
most popular attributes speed up frequent searches. Splitting the data among
multiple servers enables parallel, scalable I/O and applies parallel processing
to the data. Hashing techniques allow efficient clustering and pair-wise
comparison algorithms that parallelize nicely. Randomly sampled subsets allow
debugging otherwise large queries at the desktop. Central servers will operate
a data pump that supports sweeping searches that touch most of the data. The
anticipated queries require special operators related to angular distances and
complex similarity tests of object properties, like shapes, colors, velocity
vectors, or temporal behaviors. These issues pose interesting data management
challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907010</id><created>1999-07-07</created><authors><author><keyname>Elworthy</keyname><forenames>David</forenames></author></authors><title>Language Identification With Confidence Limits</title><categories>cs.CL</categories><comments>8 pages; needs colacl.sty. Appeared in Proceedings of the Sixth
  Workshop on Very Large Corpora (COLING-ACL 98)</comments><acm-class>I.2.7; I.5.3</acm-class><abstract>  A statistical classification algorithm and its application to language
identification from noisy input are described. The main innovation is to
compute confidence limits on the classification, so that the algorithm
terminates when enough evidence to make a clear decision has been made, and so
avoiding problems with categories that have similar characteristics. A second
application, to genre identification, is briefly examined. The results show
that some of the problems of other language identification techniques can be
avoided, and illustrate a more important point: that a statistical language
process can be used to provide feedback about its own success rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907011</id><created>1999-07-07</created><updated>2000-11-15</updated><authors><author><keyname>Chen</keyname><forenames>Zhi-Zhong</forenames></author><author><keyname>Kao</keyname><forenames>Ming-Yang</forenames></author></authors><title>Reducing Randomness via Irrational Numbers</title><categories>cs.DS cs.DM</categories><acm-class>F.0; F.1.2; F.2.2; F.2.3; G2; G3</acm-class><journal-ref>SIAM Journal on Computing, 29(4):1247--1256, 2000</journal-ref><abstract>  We propose a general methodology for testing whether a given polynomial with
integer coefficients is identically zero. The methodology evaluates the
polynomial at efficiently computable approximations of suitable irrational
points. In contrast to the classical technique of DeMillo, Lipton, Schwartz,
and Zippel, this methodology can decrease the error probability by increasing
the precision of the approximations instead of using more random bits.
Consequently, randomized algorithms that use the classical technique can
generally be improved using the new methodology. To demonstrate the
methodology, we discuss two nontrivial applications. The first is to decide
whether a graph has a perfect matching in parallel. Our new NC algorithm uses
fewer random bits while doing less work than the previously best NC algorithm
by Chari, Rohatgi, and Srinivasan. The second application is to test the
equality of two multisets of integers. Our new algorithm improves upon the
previously best algorithms by Blum and Kannan and can speed up their checking
algorithm for sorting programs on a large range of inputs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907012</id><created>1999-07-08</created><authors><author><keyname>Minnen</keyname><forenames>Guido</forenames><affiliation>University of Sussex</affiliation></author></authors><title>Selective Magic HPSG Parsing</title><categories>cs.CL</categories><comments>9 pages, LaTeX with 4 postscript figures (uses avm.sty, eaclap.sty
  and psfig-scale.sty)</comments><acm-class>I.2.7</acm-class><journal-ref>Proceedings of EACL99, Bergen, Norway, June 8-11</journal-ref><abstract>  We propose a parser for constraint-logic grammars implementing HPSG that
combines the advantages of dynamic bottom-up and advanced top-down control. The
parser allows the user to apply magic compilation to specific constraints in a
grammar which as a result can be processed dynamically in a bottom-up and
goal-directed fashion. State of the art top-down processing techniques are used
to deal with the remaining constraints. We discuss various aspects concerning
the implementation of the parser as part of a grammar development system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907013</id><created>1999-07-08</created><authors><author><keyname>Carroll</keyname><forenames>John</forenames><affiliation>University of Sussex</affiliation></author><author><keyname>Minnen</keyname><forenames>Guido</forenames><affiliation>University of Sussex</affiliation></author><author><keyname>Briscoe</keyname><forenames>Ted</forenames><affiliation>Cambridge University</affiliation></author></authors><title>Corpus Annotation for Parser Evaluation</title><categories>cs.CL</categories><comments>7 pages, LaTeX (uses eaclap.sty)</comments><acm-class>I.2.7</acm-class><journal-ref>Proceedings of the EACL99 workshop on Linguistically Interpreted
  Corpora (LINC), Bergen, Norway, June 12</journal-ref><abstract>  We describe a recently developed corpus annotation scheme for evaluating
parsers that avoids shortcomings of current methods. The scheme encodes
grammatical relations between heads and dependents, and has been used to mark
up a new public-domain corpus of naturally occurring English text. We show how
the corpus can be used to evaluate the accuracy of a robust parser, and relate
the corpus to extant resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907014</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907014</id><created>1999-07-08</created><authors><author><keyname>Venkataraman</keyname><forenames>Anand</forenames></author><author><keyname>Kemp</keyname><forenames>Ray</forenames></author></authors><title>No information can be conveyed by certain events: The case of the clever
  widows of Fornicalia and the Stobon Oracle</title><categories>cs.LO cs.GL</categories><comments>17 pgs; dbl spc</comments><acm-class>E.4; D.1.6; D.3.0</acm-class><abstract>  In this short article, we look at an old logical puzzle, its solution and
proof and discuss some interesting aspects concerning its representation in a
logic programming language like Prolog. We also discuss an intriguing
information theoretic aspect of the puzzle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907015</id><created>1999-07-09</created><updated>2000-11-14</updated><authors><author><keyname>Kao</keyname><forenames>Ming-Yang</forenames></author><author><keyname>Wang</keyname><forenames>Jie</forenames></author></authors><title>Linear-Time Approximation Algorithms for Computing Numerical Summation
  with Provably Small Errors</title><categories>cs.DS cs.NA</categories><acm-class>G.1; F.2</acm-class><journal-ref>SIAM Journal on Computing, 29(5):1568--1576, 2000</journal-ref><abstract>  Given a multiset $X=\{x_1,..., x_n\}$ of real numbers, the {\it
floating-point set summation} problem asks for $S_n=x_1+...+x_n$. Let $E^*_n$
denote the minimum worst-case error over all possible orderings of evaluating
$S_n$. We prove that if $X$ has both positive and negative numbers, it is
NP-hard to compute $S_n$ with the worst-case error equal to $E^*_n$. We then
give the first known polynomial-time approximation algorithm that has a
provably small error for arbitrary $X$. Our algorithm incurs a worst-case error
at most $2(\mix)E^*_n$.\footnote{All logarithms $\log$ in this paper are base
2.} After $X$ is sorted, it runs in O(n) time. For the case where $X$ is either
all positive or all negative, we give another approximation algorithm with a
worst-case error at most $\lceil\log\log n\rceil E^*_n$. Even for unsorted $X$,
this algorithm runs in O(n) time. Previously, the best linear-time
approximation algorithm had a worst-case error at most $\lceil\log n\rceil
E^*_n$, while $E^*_n$ was known to be attainable in $O(n \log n)$ time using
Huffman coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907016</id><created>1999-07-09</created><authors><author><keyname>Slutz</keyname><forenames>Tom Barclay Jim Gray Don</forenames></author></authors><title>Microsoft TerraServer: A Spatial Data Warehouse</title><categories>cs.DB cs.DL</categories><comments>Original MSword format at
  http://research.microsoft.com/~gray/papers/MS_TR_99_30_TerraServer.doc</comments><report-no>Microsoft Research Technical Report MSR-TR-99-29</report-no><acm-class>H.2, H.2.4, H.2.8, H.3.5, H.5.1,J.2</acm-class><abstract>  The TerraServer stores aerial, satellite, and topographic images of the earth
in a SQL database available via the Internet. It is the world's largest online
atlas, combining five terabytes of image data from the United States Geological
Survey (USGS) and SPIN-2. This report describes the system-redesign based on
our experience over the last year. It also reports usage and operations results
over the last year -- over 2 billion web hits and over 20 Terabytes of imagry
served over the Internet. Internet browsers provide intuitive spatial and text
interfaces to the data. Users need no special hardware, software, or knowledge
to locate and browse imagery. This paper describes how terabytes of &quot;Internet
unfriendly&quot; geo-spatial images were scrubbed and edited into hundreds of
millions of &quot;Internet friendly&quot; image tiles and loaded into a SQL data
warehouse. Microsoft TerraServer demonstrates that general-purpose relational
database technology can manage large scale image repositories, and shows that
web browsers can be a good geospatial image presentation system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907017</id><created>1999-07-09</created><authors><author><keyname>Turcato</keyname><forenames>Davide</forenames></author><author><keyname>McFetridge</keyname><forenames>Paul</forenames></author><author><keyname>Popowich</keyname><forenames>Fred</forenames></author><author><keyname>Toole</keyname><forenames>Janine</forenames></author></authors><title>A Bootstrap Approach to Automatically Generating Lexical Transfer Rules</title><categories>cs.CL</categories><comments>8 pages, 1 figure, to be presented at Machine Translation Summit VII,
  September 13-17, 1999, Singapore</comments><acm-class>I.2.7</acm-class><abstract>  We describe a method for automatically generating Lexical Transfer Rules
(LTRs) from word equivalences using transfer rule templates. Templates are
skeletal LTRs, unspecified for words. New LTRs are created by instantiating a
template with words, provided that the words belong to the appropriate lexical
categories required by the template. We define two methods for creating an
inventory of templates and using them to generate new LTRs. A simpler method
consists of extracting a finite set of templates from a sample of hand coded
LTRs and directly using them in the generation process. A further method
consists of abstracting over the initial finite set of templates to define
higher level templates, where bilingual equivalences are defined in terms of
correspondences involving phrasal categories. Phrasal templates are then mapped
onto sets of lexical templates with the aid of grammars. In this way an
infinite set of lexical templates is recursively defined. New LTRs are created
by parsing input words, matching a template at the phrasal level and using the
corresponding lexical categories to instantiate the lexical template. The
definition of an infinite set of templates enables the automatic creation of
LTRs for multi-word, non-compositional word equivalences of any cardinality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907018</id><created>1999-07-10</created><updated>2003-03-23</updated><authors><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Demaine</keyname><forenames>Martin L.</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Frederickson</keyname><forenames>Greg N.</forenames></author><author><keyname>Friedman</keyname><forenames>Erich</forenames></author></authors><title>Hinged Dissection of Polyominoes and Polyforms</title><categories>cs.CG cs.DM</categories><comments>27 pages, 39 figures. Accepted to Computational Geometry: Theory and
  Applications. v3 incorporates several comments by referees. v2 added many new
  results and a new coauthor (Frederickson)</comments><acm-class>G.2.1; F.2.2</acm-class><abstract>  A hinged dissection of a set of polygons S is a collection of polygonal
pieces hinged together at vertices that can be folded into any member of S. We
present a hinged dissection of all edge-to-edge gluings of n congruent copies
of a polygon P that join corresponding edges of P. This construction uses kn
pieces, where k is the number of vertices of P. When P is a regular polygon, we
show how to reduce the number of pieces to ceiling(k/2)*(n-1). In particular,
we consider polyominoes (made up of unit squares), polyiamonds (made up of
equilateral triangles), and polyhexes (made up of regular hexagons). We also
give a hinged dissection of all polyabolos (made up of right isosceles
triangles), which do not fall under the general result mentioned above.
Finally, we show that if P can be hinged into Q, then any edge-to-edge gluing
of n congruent copies of P can be hinged into any edge-to-edge gluing of n
congruent copies of Q.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907019</id><created>1999-07-12</created><authors><author><keyname>Bordelon</keyname><forenames>Craig</forenames></author></authors><title>A Reasonable C++ Wrappered Java Native Interface</title><categories>cs.SE</categories><comments>27 pages, 18 figures; Submitted to Software Practice &amp; Experience;
  Withdrawn after 3 month negotiation failed to reach compromise on copyright
  (Wiley Publisher vs. Telcordia Technologies); jH software inquiries to
  http://www.telcordia.com</comments><acm-class>D.2.3</acm-class><abstract>  A reasonable C++ Java Native Interface (JNI) technique termed C++ Wrappered
JNI (C++WJ) is presented. The technique simplifies current error-prone JNI
development by wrappering JNI calls. Provided development is done with the aid
of a C++ compiler, C++WJ offers type checking and behind the scenes caching. A
tool (jH) patterned on javah automates the creation of C++WJ classes.
  The paper presents the rationale behind the choices that led to C++WJ.
Handling of Java class and interface hierarchy including Java type downcasts is
discussed. Efficiency considerations in the C++WJ lead to two flavors of C++
classes: jtypes and Jtypes. A jtype is a lightweight less than full wrapper of
a JNI object reference. A Jtype is a heavyweight full wrapper of a JNI object
reference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907020</id><created>1999-07-12</created><updated>1999-07-14</updated><authors><author><keyname>Chen</keyname><forenames>W.</forenames></author></authors><title>Generalized linearization in nonlinear modeling of data</title><categories>cs.CE cs.NA</categories><comments>This modified version of the original paper corrected two crucial
  errors in Eqs. (1) and (3). The interested readers may contact the author in
  chenw@homer.shinshu-u.ac.jp or chenwwhy@hotmail.com</comments><acm-class>G.1.3; G.1.8</acm-class><abstract>  The principal innovative idea in this paper is to transform the original
complex nonlinear modeling problem into a combination of linear problem and
very simple nonlinear problems. The key step is the generalized linearization
of nonlinear terms. This paper only presents the introductory strategy of this
methodology. The practical numerical experiments will be provided subsequently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907021</id><created>1999-07-14</created><authors><author><keyname>Goerz</keyname><forenames>Guenther</forenames></author><author><keyname>Spilker</keyname><forenames>Joerg</forenames></author><author><keyname>Strom</keyname><forenames>Volker</forenames></author><author><keyname>Weber</keyname><forenames>Hans</forenames></author></authors><title>Architectural Considerations for Conversational Systems -- The
  Verbmobil/INTARC Experience</title><categories>cs.CL</categories><comments>10 pages, to appear in proceedings of First International Workshop on
  Human Computer Conversation, Bellagio, Italy</comments><acm-class>I.2.7</acm-class><abstract>  The paper describes the speech to speech translation system INTARC, developed
during the first phase of the Verbmobil project. The general design goals of
the INTARC system architecture were time synchronous processing as well as
incrementality and interactivity as a means to achieve a higher degree of
robustness and scalability. Interactivity means that in addition to the
bottom-up (in terms of processing levels) data flow the ability to process
top-down restrictions considering the same signal segment for all processing
levels. The construction of INTARC 2.0, which has been operational since fall
1996, followed an engineering approach focussing on the integration of symbolic
(linguistic) and stochastic (recognition) techniques which led to a
generalization of the concept of a ``one pass'' beam search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907022</id><created>1999-07-16</created><authors><author><keyname>Kuroda</keyname><forenames>Satoru</forenames></author></authors><title>Weak length induction and slow growing depth boolean circuits</title><categories>cs.LO</categories><acm-class>F.4.1</acm-class><abstract>  We define a hierarchy of circuit complexity classes LD^i, whose depth are the
inverse of a function in Ackermann hierarchy. Then we introduce extremely weak
versions of length induction and construct a bounded arithmetic theory L^i_2
whose provably total functions exactly correspond to functions computable by
LD^i circuits. Finally, we prove a non-conservation result between L^i_2 and a
weaker theory AC^0CA which corresponds to the class AC^0. Our proof utilizes
KPT witnessing theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907023</id><created>1999-07-16</created><authors><author><keyname>Devillers</keyname><forenames>Olivier</forenames></author></authors><title>On Deletion in Delaunay Triangulation</title><categories>cs.CG</categories><comments>15 pages 5 figures. in Proc. 15th Annu. ACM Sympos. Comput. Geom.,
  181--188, 1999</comments><report-no>INRIA Research report 3451</report-no><acm-class>F.2.2; I.3.5</acm-class><abstract>  This paper presents how the space of spheres and shelling may be used to
delete a point from a $d$-dimensional triangulation efficiently. In dimension
two, if k is the degree of the deleted vertex, the complexity is O(k log k),
but we notice that this number only applies to low cost operations, while time
consuming computations are only done a linear number of times.
  This algorithm may be viewed as a variation of Heller's algorithm, which is
popular in the geographic information system community. Unfortunately, Heller
algorithm is false, as explained in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907024</id><created>1999-07-16</created><authors><author><keyname>Devillers</keyname><forenames>Olivier</forenames></author></authors><title>Improved Incremental Randomized Delaunay Triangulation</title><categories>cs.CG</categories><comments>19 pages, 7 figures Proc. 14th Annu. ACM Sympos. Comput. Geom.,
  106--115, 1998</comments><report-no>INRIA Research Report 3298</report-no><acm-class>F.2.2; I.3.5</acm-class><abstract>  We propose a new data structure to compute the Delaunay triangulation of a
set of points in the plane. It combines good worst case complexity, fast
behavior on real data, and small memory occupation.
  The location structure is organized into several levels. The lowest level
just consists of the triangulation, then each level contains the triangulation
of a small sample of the levels below. Point location is done by marching in a
triangulation to determine the nearest neighbor of the query at that level,
then the march restarts from that neighbor at the level below. Using a small
sample (3%) allows a small memory occupation; the march and the use of the
nearest neighbor to change levels quickly locate the query.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907025</id><created>1999-07-16</created><authors><author><keyname>Bronnimann</keyname><forenames>Herve</forenames></author><author><keyname>Devillers</keyname><forenames>Olivier</forenames></author></authors><title>The union of unit balls has quadratic complexity, even if they all
  contain the origin</title><categories>cs.CG</categories><comments>5 pages, 5 figures</comments><acm-class>F.2.2</acm-class><abstract>  We provide a lower bound construction showing that the union of unit balls in
three-dimensional space has quadratic complexity, even if they all contain the
origin. This settles a conjecture of Sharir.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907026</id><created>1999-07-16</created><authors><author><keyname>Pianta</keyname><forenames>Emanuele</forenames></author><author><keyname>Tovena</keyname><forenames>Lucia M.</forenames></author></authors><title>Mixing representation levels: The hybrid approach to automatic text
  generation</title><categories>cs.CL cs.AI</categories><comments>6 pages</comments><acm-class>I.2.7</acm-class><journal-ref>Proceedings of the AISB'99 Workshop on ``Reference Architectures
  and Data Standards for NLP'', Edinburgh Scotland, April 1999, 8-13</journal-ref><abstract>  Natural language generation systems (NLG) map non-linguistic representations
into strings of words through a number of steps using intermediate
representations of various levels of abstraction. Template based systems, by
contrast, tend to use only one representation level, i.e. fixed strings, which
are combined, possibly in a sophisticated way, to generate the final text.
  In some circumstances, it may be profitable to combine NLG and template based
techniques. The issue of combining generation techniques can be seen in more
abstract terms as the issue of mixing levels of representation of different
degrees of linguistic abstraction. This paper aims at defining a reference
architecture for systems using mixed representations. We argue that mixed
representations can be used without abandoning a linguistically grounded
approach to language generation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907027</id><created>1999-07-19</created><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>Schaerf</keyname><forenames>Andrea</forenames></author></authors><title>The Alma Project, or How First-Order Logic Can Help Us in Imperative
  Programming</title><categories>cs.LO cs.PL</categories><comments>25 pages</comments><acm-class>D.3.2;F.3.2;F.3.3;I.2.8;I.5.5</acm-class><abstract>  The aim of the Alma project is the design of a strongly typed constraint
programming language that combines the advantages of logic and imperative
programming. The first stage of the project was the design and implementation
of Alma-0, a small programming language that provides a support for declarative
programming within the imperative programming framework. It is obtained by
extending a subset of Modula-2 by a small number of features inspired by the
logic programming paradigm. In this paper we discuss the rationale for the
design of Alma-0, the benefits of the resulting hybrid programming framework,
and the current work on adding constraint processing capabilities to the
language. In particular, we discuss the role of the logical and customary
variables, the interaction between the constraint store and the program, and
the need for lists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907028</id><created>1999-07-19</created><authors><author><keyname>Devillers</keyname><forenames>Olivier</forenames></author><author><keyname>Preparata</keyname><forenames>Franco P.</forenames></author></authors><title>Further Results on Arithmetic Filters for Geometric Predicates</title><categories>cs.CG</categories><comments>7 pages 2 figures presented at the 15th European Workshop Comput.
  Geom., 113--116, 1999 improve previous results (in other paper)</comments><report-no>INRIA Research report 3528</report-no><acm-class>F.2.2; I.3.5</acm-class><journal-ref>Comput. Geom. Theory Appl. 1999 13:141-148</journal-ref><abstract>  An efficient technique to solve precision problems consists in using exact
computations. For geometric predicates, using systematically expensive exact
computations can be avoided by the use of filters. The predicate is first
evaluated using rounding computations, and an error estimation gives a
certificate of the validity of the result. In this note, we studies the
statistical efficiency of filters for cosphericity predicate with an assumption
of regular distribution of the points. We prove that the expected value of the
polynomial corresponding to the in sphere test is greater than epsilon with
probability O(epsilon log 1/epsilon) improving the results of a previous paper
by the same authors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907029</id><created>1999-07-19</created><updated>1999-07-21</updated><authors><author><keyname>Devillers</keyname><forenames>Olivier</forenames></author><author><keyname>Preparata</keyname><forenames>Franco P.</forenames></author></authors><title>A Probabilistic Analysis of the Power of Arithmetic Filters</title><categories>cs.CG</categories><comments>22 pages 7 figures Results for in sphere test inproved in
  cs.CG/9907028</comments><report-no>INRIA Research report 2971</report-no><acm-class>F.2.2; I.3.5</acm-class><journal-ref>Discrete and Computational Geometry, 20:523--547, 1998</journal-ref><abstract>  The assumption of real-number arithmetic, which is at the basis of
conventional geometric algorithms, has been seriously challenged in recent
years, since digital computers do not exhibit such capability.
  A geometric predicate usually consists of evaluating the sign of some
algebraic expression. In most cases, rounded computations yield a reliable
result, but sometimes rounded arithmetic introduces errors which may invalidate
the algorithms. The rounded arithmetic may produce an incorrect result only if
the exact absolute value of the algebraic expression is smaller than some
(small) varepsilon, which represents the largest error that may arise in the
evaluation of the expression. The threshold varepsilon depends on the structure
of the expression and on the adopted computer arithmetic, assuming that the
input operands are error-free.
  A pair (arithmetic engine,threshold) is an &quot;arithmetic filter&quot;. In this paper
we develop a general technique for assessing the efficacy of an arithmetic
filter. The analysis consists of evaluating both the threshold and the
probability of failure of the filter.
  To exemplify the approach, under the assumption that the input points be
chosen randomly in a unit ball or unit cube with uniform density, we analyze
the two important predicates &quot;which-side&quot; and &quot;insphere&quot;. We show that the
probability that the absolute values of the corresponding determinants be no
larger than some positive value V, with emphasis on small V, is Theta(V) for
the which-side predicate, while for the insphere predicate it is Theta(V^(2/3))
in dimension 1, O(sqrt(V)) in dimension 2, and O(sqrt(V) ln(1/V)) in higher
dimensions. Constants are small, and are given in the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907030</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907030</id><created>1999-07-19</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Bern</keyname><forenames>Marshall W.</forenames></author><author><keyname>Hutchings</keyname><forenames>Brad</forenames></author></authors><title>Algorithms for Coloring Quadtrees</title><categories>cs.CG</categories><comments>7 pages, 9 figures</comments><acm-class>F.2.2</acm-class><journal-ref>Algorithmica 32(1):87-94, 2002</journal-ref><doi>10.1007/s00453-001-0054-2</doi><abstract>  We describe simple linear time algorithms for coloring the squares of
balanced and unbalanced quadtrees so that no two adjacent squares are given the
same color. If squares sharing sides are defined as adjacent, we color balanced
quadtrees with three colors, and unbalanced quadtrees with four colors; these
results are both tight, as some quadtrees require this many colors. If squares
sharing corners are defined as adjacent, we color balanced or unbalanced
quadtrees with six colors; for some quadtrees, at least five colors are
required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907031</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907031</id><created>1999-07-20</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Beta-Skeletons have Unbounded Dilation</title><categories>cs.CG math.MG</categories><comments>8 pages, 9 figures</comments><acm-class>F.2.2</acm-class><journal-ref>Computational Geometry Theory &amp; Appl. 23:43-52, 2002</journal-ref><doi>10.1016/S0925-7721(01)00055-4</doi><abstract>  A fractal construction shows that, for any beta&gt;0, the beta-skeleton of a
point set can have arbitrarily large dilation. In particular this applies to
the Gabriel graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907032</id><created>1999-07-21</created><updated>2000-04-14</updated><authors><author><keyname>Fisher</keyname><forenames>Michael</forenames><affiliation>Department of Computing and Mathematics, Manchester Metropolitan University, Manchester, UK</affiliation></author><author><keyname>Dixon</keyname><forenames>Clare</forenames><affiliation>Department of Computing and Mathematics, Manchester Metropolitan University, Manchester, UK</affiliation></author><author><keyname>Peim</keyname><forenames>Martin</forenames><affiliation>Department of Computer Science, Victoria University of Manchester, Manchester, UK</affiliation></author></authors><title>Clausal Temporal Resolution</title><categories>cs.LO cs.AI</categories><comments>35 pages, 0 figures Expanded related work, corrected typos, expanded
  proofs</comments><acm-class>I.2.3;F.4.1</acm-class><abstract>  In this article, we examine how clausal resolution can be applied to a
specific, but widely used, non-classical logic, namely discrete linear temporal
logic. Thus, we first define a normal form for temporal formulae and show how
arbitrary temporal formulae can be translated into the normal form, while
preserving satisfiability. We then introduce novel resolution rules that can be
applied to formulae in this normal form, provide a range of examples and
examine the correctness and complexity of this approach is examined and. This
clausal resolution approach. Finally, we describe related work and future
developments concerning this work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907033</id><created>1999-07-26</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author></authors><title>Unambiguous Computation: Boolean Hierarchies and Sparse Turing-Complete
  Sets</title><categories>cs.CC</categories><comments>27 pages</comments><report-no>earlier version appeared as University of Rochester TR-94-483</report-no><acm-class>F.1.3</acm-class><journal-ref>SIAM Journal on Computing vol. 26, no. 3, pp. 634--653, 1997</journal-ref><abstract>  It is known that for any class C closed under union and intersection, the
Boolean closure of C, the Boolean hierarchy over C, and the symmetric
difference hierarchy over C all are equal. We prove that these equalities hold
for any complexity class closed under intersection; in particular, they thus
hold for unambiguous polynomial time (UP). In contrast to the NP case, we prove
that the Hausdorff hierarchy and the nested difference hierarchy over UP both
fail to capture the Boolean closure of UP in some relativized worlds.
  Karp and Lipton proved that if nondeterministic polynomial time has sparse
Turing-complete sets, then the polynomial hierarchy collapses. We establish the
first consequences from the assumption that unambiguous polynomial time has
sparse Turing-complete sets: (a) UP is in Low_2, where Low_2 is the second
level of the low hierarchy, and (b) each level of the unambiguous polynomial
hierarchy is contained one level lower in the promise unambiguous polynomial
hierarchy than is otherwise known to be the case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907034</id><created>1999-07-25</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Jiang</keyname><forenames>Zhigen</forenames></author><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author><author><keyname>Watanabe</keyname><forenames>Osamu</forenames></author></authors><title>Polynomial-Time Multi-Selectivity</title><categories>cs.CC</categories><comments>40 pages</comments><report-no>earlier version appeared as FSU Jena TR Math/Inf/96/11</report-no><acm-class>F.1.2; F.1.3</acm-class><journal-ref>Journal of Universal Computer Science vol. 3, no. 3, pp. 197--229,
  1997</journal-ref><abstract>  We introduce a generalization of Selman's P-selectivity that yields a more
flexible notion of selectivity, called (polynomial-time) multi-selectivity, in
which the selector is allowed to operate on multiple input strings. Since our
introduction of this class, it has been used to prove the first known (and
optimal) lower bounds for generalized selectivity-like classes in terms of
EL_2, the second level of the extended low hierarchy. We study the resulting
selectivity hierarchy, denoted by SH, which we prove does not collapse. In
particular, we study the internal structure and the properties of SH and
completely establish, in terms of incomparability and strict inclusion, the
relations between our generalized selectivity classes and Ogihara's P-mc
(polynomial-time membership-comparable) classes. Although SH is a strictly
increasing infinite hierarchy, we show that the core results that hold for the
P-selective sets and that prove them structurally simple also hold for SH. In
particular, all sets in SH have small circuits; the NP sets in SH are in Low_2,
the second level of the low hierarchy within NP; and SAT cannot be in SH unless
P = NP. Finally, it is known that P-Sel, the class of P-selective sets, is not
closed under union or intersection. We provide an extended selectivity
hierarchy that is based on SH and that is large enough to capture those
closures of the P-selective sets, and yet, in contrast with the P-mc classes,
is refined enough to distinguish them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907035</id><created>1999-07-25</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author><author><keyname>Wechsung</keyname><forenames>Gerd</forenames></author></authors><title>Easy Sets and Hard Certificate Schemes</title><categories>cs.CC</categories><comments>26 pages</comments><report-no>earlier version appeared as FSU Jena TR Math/95/5</report-no><acm-class>F.1.3</acm-class><journal-ref>Acta Informatica vol. 34, no 11, pp. 859--879, 1997</journal-ref><abstract>  Can easy sets only have easy certificate schemes? In this paper, we study the
class of sets that, for all NP certificate schemes (i.e., NP machines), always
have easy acceptance certificates (i.e., accepting paths) that can be computed
in polynomial time. We also study the class of sets that, for all NP
certificate schemes, infinitely often have easy acceptance certificates.
  In particular, we provide equivalent characterizations of these classes in
terms of relative generalized Kolmogorov complexity, showing that they are
robust. We also provide structural conditions---regarding immunity and class
collapses---that put upper and lower bounds on the sizes of these two classes.
Finally, we provide negative results showing that some of our positive claims
are optimal with regard to being relativizable. Our negative results are proven
using a novel observation: we show that the classical ``wide spacing'' oracle
construction technique yields instant non-bi-immunity results. Furthermore, we
establish a result that improves upon Baker, Gill, and Solovay's classical
result that NP \neq P = NP \cap coNP holds in some relativized world.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907036</id><created>1999-07-25</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author></authors><title>Exact Analysis of Dodgson Elections: Lewis Carroll's 1876 Voting System
  is Complete for Parallel Access to NP</title><categories>cs.CC</categories><comments>22 pages</comments><report-no>earlier version appeared as University of Rochester TR-96-640</report-no><acm-class>F.1.3; F.2.2; J.4</acm-class><journal-ref>Journal of the ACM vol. 44, no. 6, pp. 806--825, 1997</journal-ref><abstract>  In 1876, Lewis Carroll proposed a voting system in which the winner is the
candidate who with the fewest changes in voters' preferences becomes a
Condorcet winner---a candidate who beats all other candidates in pairwise
majority-rule elections. Bartholdi, Tovey, and Trick provided a lower
bound---NP-hardness---on the computational complexity of determining the
election winner in Carroll's system. We provide a stronger lower bound and an
upper bound that matches our lower bound. In particular, determining the winner
in Carroll's system is complete for parallel access to NP, i.e., it is complete
for $\thetatwo$, for which it becomes the most natural complete problem known.
It follows that determining the winner in Carroll's elections is not
NP-complete unless the polynomial hierarchy collapses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907037</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907037</id><created>1999-07-25</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Jiang</keyname><forenames>Zhigen</forenames></author><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author><author><keyname>Watanabe</keyname><forenames>Osamu</forenames></author></authors><title>Boolean Operations, Joins, and the Extended Low Hierarchy</title><categories>cs.CC</categories><comments>12 pages</comments><report-no>earlier version appeared as University of Rochester TR-96-627</report-no><acm-class>F.1.3</acm-class><journal-ref>Theoretical Computer Science vol. 205, no. 1-2, pp. 317--327, 1998</journal-ref><abstract>  We prove that the join of two sets may actually fall into a lower level of
the extended low hierarchy than either of the sets. In particular, there exist
sets that are not in the second level of the extended low hierarchy, EL_2, yet
their join is in EL_2. That is, in terms of extended lowness, the join operator
can lower complexity. Since in a strong intuitive sense the join does not lower
complexity, our result suggests that the extended low hierarchy is unnatural as
a complexity measure. We also study the closure properties of EL_ and prove
that EL_2 is not closed under certain Boolean operations. To this end, we
establish the first known (and optimal) EL_2 lower bounds for certain notions
generalizing Selman's P-selectivity, which may be regarded as an interesting
result in its own right.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907038</id><created>1999-07-25</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author></authors><title>A Second Step Towards Complexity-Theoretic Analogs of Rice's Theorem</title><categories>cs.CC</categories><comments>14 pages. To appear in Theoretical Computer Science</comments><report-no>earlier version appeared as University of Rochester TR-97-662</report-no><acm-class>F.1.3</acm-class><abstract>  Rice's Theorem states that every nontrivial language property of the
recursively enumerable sets is undecidable. Borchert and Stephan initiated the
search for complexity-theoretic analogs of Rice's Theorem. In particular, they
proved that every nontrivial counting property of circuits is UP-hard, and that
a number of closely related problems are SPP-hard.
  The present paper studies whether their UP-hardness result itself can be
improved to SPP-hardness. We show that their UP-hardness result cannot be
strengthened to SPP-hardness unless unlikely complexity class containments
hold. Nonetheless, we prove that every P-constructibly bi-infinite counting
property of circuits is SPP-hard. We also raise their general lower bound from
unambiguous nondeterminism to constant-ambiguity nondeterminism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907039</id><created>1999-07-25</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author></authors><title>Raising NP Lower Bounds to Parallel NP Lower Bounds</title><categories>cs.CC</categories><comments>14 pages</comments><report-no>earlier version appeared as University of Rochester TR-97-658</report-no><acm-class>F.1.3</acm-class><journal-ref>SIGACT News vol. 28, no. 2, pp. 2--13, 1997</journal-ref><abstract>  A decade ago, a beautiful paper by Wagner developed a ``toolkit'' that in
certain cases allows one to prove problems hard for parallel access to NP.
However, the problems his toolkit applies to most directly are not overly
natural. During the past year, problems that previously were known only to be
NP-hard or coNP-hard have been shown to be hard even for the class of sets
solvable via parallel access to NP. Many of these problems are longstanding and
extremely natural, such as the Minimum Equivalent Expression problem (which was
the original motivation for creating the polynomial hierarchy), the problem of
determining the winner in the election system introduced by Lewis Carroll in
1876, and the problem of determining on which inputs heuristic algorithms
perform well. In the present article, we survey this recent progress in raising
lower bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907040</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907040</id><created>1999-07-26</created><authors><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author></authors><title>Characterizations of the Existence of Partial and Total One-Way
  Permutations</title><categories>cs.CC cs.CR</categories><comments>12 pages; An extended abstract of this paper was presented at the
  Third Italian Conference on Algorithms and Complexity</comments><acm-class>F.1.3; E.3</acm-class><abstract>  In this note, we study the easy certificate classes introduced by
Hemaspaandra, Rothe, and Wechsung, with regard to the question of whether or
not surjective one-way functions exist. This is an important open question in
cryptology. We show that the existence of partial one-way permutations can be
characterized by separating P from the class of UP sets that, for all
unambiguous polynomial-time Turing machines accepting them, always have easy
(i.e., polynomial-time computable) certificates. This extends results of
Grollmann and Selman. By Gr\&quot;adel's recent results about one-way functions,
this also links statements about easy certificates of NP sets with statements
in finite model theory. Similarly, there exist surjective poly-one one-way
functions if and only if there is a set L in P such that not all FewP machines
accepting L always have easy certificates. We also establish a condition
necessary and sufficient for the existence of (total) one-way permutations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907041</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907041</id><created>1999-07-26</created><authors><author><keyname>Borchert</keyname><forenames>Bernd</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author></authors><title>Restrictive Acceptance Suffices for Equivalence Problems</title><categories>cs.CC</categories><comments>14 pages; to appear in Proc. FCT'99</comments><report-no>Revises Friedrich-Schiller-Universit\&quot;at Jena Technical Report
  Math/Inf/96/13</report-no><acm-class>F.1.3</acm-class><abstract>  One way of suggesting that an NP problem may not be NP-complete is to show
that it is in the class UP. We suggest an analogous new approach---weaker in
strength of evidence but more broadly applicable---to suggesting that
concrete~NP problems are not NP-complete. In particular we introduce the class
EP, the subclass of NP consisting of those languages accepted by NP machines
that when they accept always have a number of accepting paths that is a power
of two. Since if any NP-complete set is in EP then all NP sets are in EP, it
follows---with whatever degree of strength one believes that EP differs from
NP---that membership in EP can be viewed as evidence that a problem is not
NP-complete.
  We show that the negation equivalence problem for OBDDs (ordered binary
decision diagrams) and the interchange equivalence problem for 2-dags are in
EP. We also show that for boolean negation the equivalence problem is in
EP^{NP}, thus tightening the existing NP^{NP} upper bound. We show that FewP,
bounded ambiguity polynomial time, is contained in EP, a result that is not
known to follow from the previous SPP upper bound. For the three problems and
classes just mentioned with regard to EP, no proof of membership/containment in
UP is known, and for the problem just mentioned with regard to EP^{NP}, no
proof of membership in UP^{NP} is known. Thus, EP is indeed a tool that gives
evidence against NP-completeness in natural cases where UP cannot currently be
applied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907042</id><created>1999-07-27</created><authors><author><keyname>Nicholson</keyname><forenames>Scott</forenames></author></authors><title>Raising Reliability of Web Search Tool Research through Replication and
  Chaos Theory</title><categories>cs.IR cs.DL</categories><acm-class>H.3.4; H.3.5</acm-class><abstract>  Because the World Wide Web is a dynamic collection of information, the Web
search tools (or &quot;search engines&quot;) that index the Web are dynamic. Traditional
information retrieval evaluation techniques may not provide reliable results
when applied to the Web search tools. This study is the result of ten
replications of the classic 1996 Ding and Marchionini Web search tool research.
It explores the effects that replication can have on transforming unreliable
results from one iteration into replicable and therefore reliable results after
multiple iterations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9907043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9907043</id><created>1999-07-30</created><authors><author><keyname>Best</keyname><forenames>Christoph</forenames><affiliation>ZIB, Berlin, and J. v. Neumann Institute, Juelich</affiliation></author></authors><title>A simple C++ library for manipulating scientific data sets as structured
  data</title><categories>cs.CE cs.DB</categories><comments>22 pages, LaTeX. Also available at
  http://www.zib.de/PaperWeb/abstracts/TR-98-06/</comments><report-no>TR 98-06 (ZIB Berlin)</report-no><acm-class>E.5</acm-class><abstract>  Representing scientific data sets efficiently on external storage usually
involves converting them to a byte string representation using specialized
reader/writer routines. The resulting storage files are frequently difficult to
interpret without these specialized routines as they do not contain information
about the logical structure of the data. Avoiding such problems usually
involves heavy-weight data format libraries or data base systems. We present a
simple C++ library that allows to create and access data files that store
structured data. The structure of the data is described by a data type that can
be built from elementary data types (integer and floating-point numbers, byte
strings) and composite data types (arrays, structures, unions). An abstract
data access class presents the data to the application. Different actual data
file structures can be implemented under this layer. This method is
particularly suited to applications that require complex data structures, e.g.
molecular dynamics simulations. Extensions such as late type binding and object
persistence are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9908001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9908001</id><created>1999-08-01</created><authors><author><keyname>Marx</keyname><forenames>Zvika</forenames><affiliation>Bar-Ilan University</affiliation><affiliation>The Hebrew University of Jerusalem</affiliation></author><author><keyname>Dagan</keyname><forenames>Ido</forenames><affiliation>Bar-Ilan University</affiliation></author><author><keyname>Shamir</keyname><forenames>Eli</forenames><affiliation>The Hebrew University of Jerusalem</affiliation></author></authors><title>Detecting Sub-Topic Correspondence through Bipartite Term Clustering</title><categories>cs.CL</categories><comments>html with 3 gif figures; generated from 7 pages MS-Word file</comments><acm-class>I.2.6, I.2.7, H.3.1</acm-class><journal-ref>Proceedings of ACL'99 Workshop on Unsupervised Learning in Natural
  Language Processing, 1999, pp 45-51</journal-ref><abstract>  This paper addresses a novel task of detecting sub-topic correspondence in a
pair of text fragments, enhancing common notions of text similarity. This task
is addressed by coupling corresponding term subsets through bipartite
clustering. The paper presents a cost-based clustering scheme and compares it
with a bipartite version of the single-link method, providing illustrating
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9908002</identifier>
 <datestamp>2007-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9908002</id><created>1999-08-03</created><authors><author><keyname>Burow</keyname><forenames>Burkhard D.</forenames></author></authors><title>After Compilers and Operating Systems : The Third Advance in Application
  Support</title><categories>cs.PL cs.DC cs.GL cs.OS</categories><comments>20 pages including 13 figures of diagrams and code examples. Based on
  invited seminars held in May-July 1999 at IBM, Caltech and elsewhere. For
  further information see http://www.tsia.org</comments><acm-class>A.1;D.1.1;D.1.3;D.1.4;D.2.11;D.3.2;D.3.3;D.3.4;D.4.5;D.4.7;E.1;F.1.2</acm-class><abstract>  After compilers and operating systems, TSIAs are the third advance in
application support. A compiler supports a high level application definition in
a programming language. An operating system supports a high level interface to
the resources used by an application execution. A Task System and Item
Architecture (TSIA) provides an application with a transparent reliable,
distributed, heterogeneous, adaptive, dynamic, real-time, interactive,
parallel, secure or other execution. In addition to supporting the application
execution, a TSIA also supports the application definition. This run-time
support for the definition is complementary to the compile-time support of a
compiler. For example, this allows a language similar to Fortran or C to
deliver features promised by functional computing. While many TSIAs exist, they
previously have not been recognized as such and have served only a particular
type of application. Existing TSIAs and other projects demonstrate that TSIAs
are feasible for most applications. As the next paradigm for application
support, the TSIA simplifies and unifies existing computing practice and
research. By solving many outstanding problems, the TSIA opens many, many new
opportunities for computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9908003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9908003</id><created>1999-08-03</created><updated>2001-08-27</updated><authors><author><keyname>Bern</keyname><forenames>Marshall</forenames></author><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Kuo</keyname><forenames>Eric</forenames></author><author><keyname>Mantler</keyname><forenames>Andrea</forenames></author><author><keyname>Snoeyink</keyname><forenames>Jack</forenames></author></authors><title>Ununfoldable Polyhedra with Convex Faces</title><categories>cs.CG cs.DM</categories><comments>14 pages, 9 figures, LaTeX 2e. To appear in Computational Geometry:
  Theory and Applications. Major revision with two new authors, solving the
  open problem about triangular faces</comments><acm-class>G.2.1; F.2.2</acm-class><journal-ref>Computational Geometry: Theory and Applications 24(2):51-62,
  February 2003</journal-ref><abstract>  Unfolding a convex polyhedron into a simple planar polygon is a well-studied
problem. In this paper, we study the limits of unfoldability by studying
nonconvex polyhedra with the same combinatorial structure as convex polyhedra.
In particular, we give two examples of polyhedra, one with 24 convex faces and
one with 36 triangular faces, that cannot be unfolded by cutting along edges.
We further show that such a polyhedron can indeed be unfolded if cuts are
allowed to cross faces. Finally, we prove that ``open'' polyhedra with
triangular faces may not be unfoldable no matter how they are cut.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9908004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9908004</id><created>1999-08-06</created><authors><author><keyname>Simons</keyname><forenames>Patrik</forenames></author></authors><title>Extending the Stable Model Semantics with More Expressive Rules</title><categories>cs.LO cs.AI</categories><comments>18 pages, a shortened version will be published in the proceedings of
  the 5th International Conference on Logic Programming and Nonmonotonic
  Reasoning (LPNMR'99)</comments><acm-class>I.2.3; I.2.8; F.4.1</acm-class><abstract>  The rules associated with propositional logic programs and the stable model
semantics are not expressive enough to let one write concise programs. This
problem is alleviated by introducing some new types of propositional rules.
Together with a decision procedure that has been used as a base for an
efficient implementation, the new rules supplant the standard ones in practical
applications of the stable model semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9908005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9908005</id><created>1999-08-11</created><updated>2001-02-20</updated><authors><author><keyname>Cocan</keyname><forenames>Roxana</forenames></author><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>Polygonal Chains Cannot Lock in 4D</title><categories>cs.CG cs.DM</categories><comments>Major revision of the Aug. 1999 version, including: Proof extended to
  show trees cannot lock in 4D; new example of the implementation straightening
  a chain of n=100 vertices; improved time complexity for chain to O(n^2);
  fixed several minor technical errors. (Thanks to three referees.) 29 pages;
  15 figures. v3: Reference updated</comments><report-no>Smith Technical Report 063</report-no><acm-class>F.2.2; G.2.1</acm-class><abstract>  We prove that, in all dimensions d&gt;=4, every simple open polygonal chain and
every tree may be straightened, and every simple closed polygonal chain may be
convexified. These reconfigurations can be achieved by algorithms that use
polynomial time in the number of vertices, and result in a polynomial number of
``moves.'' These results contrast to those known for d=2, where trees can
``lock,'' and for d=3, where open and closed chains can lock.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9908006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9908006</id><created>1999-08-11</created><updated>1999-08-13</updated><authors><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>Computational Geometry Column 36</title><categories>cs.CG</categories><comments>To appear in SIGACT News and in Int. J. Comp. Geom. Appl., 1999.
  Replacement corrects disk-packing reference: [BDDH98] -&gt; [BDEH98]</comments><acm-class>F.2.2</acm-class><abstract>  Two results in &quot;computational origami&quot; are illustrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9908007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9908007</id><created>1999-08-11</created><authors><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>Computational Geometry Column 37</title><categories>cs.CG</categories><comments>To appear in SIGACT News, and in Int. J. Comp. Geom. Appl., 1999</comments><acm-class>F.2.2</acm-class><abstract>  Open problems from the 15th Annual ACM Symposium on Computational Geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9908008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9908008</id><created>1999-08-12</created><authors><author><keyname>Malkhi</keyname><forenames>Dahlia</forenames></author><author><keyname>Merritt</keyname><forenames>Michael</forenames></author><author><keyname>Rodeh</keyname><forenames>Ohad</forenames></author></authors><title>Secure Multicast in a WAN</title><categories>cs.CR cs.DC</categories><comments>preprint of a paper to appear in the Distributed Computing Journal</comments><acm-class>c.2.0;c.2.4;c.4</acm-class><abstract>  A secure reliable multicast protocol enables a process to send a message to a
group of recipients such that all correct destinations receive the same
message, despite the malicious efforts of fewer than a third of the total
number of processes, including the sender. This has been sh own to be a useful
tool in building secure distributed services, albeit with a cost that typically
grows linearly with the size of the system. For very large networks, for which
this is prohibitive, we present two approaches for reducing the cost: First, we
show a protocol whose cost is on the order of the number of tolerated failures.
Secondly, we show how relaxing the consistency requirement to a probabilistic
guarantee can reduce the associated cost, effectively to a constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9908009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9908009</id><created>1999-08-12</created><authors><author><keyname>Malkhi</keyname><forenames>Dahlia</forenames></author><author><keyname>Reiter</keyname><forenames>Michael</forenames></author></authors><title>Secure Execution of Java Applets using a Remote Playground</title><categories>cs.CR cs.NI</categories><comments>preprint of a paper to appear in IEEE Transactions on Software
  Engineering</comments><acm-class>C.2.0</acm-class><abstract>  Mobile code presents a number of threats to machines that execute it. We
introduce an approach for protecting machines and the resources they hold from
mobile code, and describe a system based on our approach for protecting host
machines from Java 1.1 applets. In our approach, each Java applet downloaded to
the protected domain is rerouted to a dedicated machine (or set of machines),
the {\em playground}, at which it is executed. Prior to execution the applet is
transformed to use the downloading user's web browser as a graphics terminal
for its input and output, and so the user has the illusion that the applet is
running on her own machine. In reality, however, mobile code runs only in the
sanitized environment of the playground, where user files cannot be mounted and
from which only limited network connections are accepted by machines in the
protected domain. Our playground thus provides a second level of defense
against mobile code that circumvents language-based defenses. The paper
presents the design and implementation of a playground for Java 1.1 applets,
and discusses extensions of it for other forms of mobile code including Java
1.2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9908010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9908010</id><created>1999-08-12</created><authors><author><keyname>Malkhi</keyname><forenames>Dahlia</forenames></author><author><keyname>Mansour</keyname><forenames>Yishay</forenames></author><author><keyname>Reiter</keyname><forenames>Michael</forenames></author></authors><title>On Propagating Updates in a Byzantine Environment</title><categories>cs.DC cs.CR</categories><acm-class>C.2.0;C.2.4;C.4</acm-class><abstract>  We study how to efficiently diffuse updates to a large distributed system of
data replicas, some of which may exhibit arbitrary (Byzantine) failures. We
assume that strictly fewer than $t$ replicas fail, and that each update is
initially received by at least $t$ correct replicas. The goal is to diffuse
each update to all correct replicas while ensuring that correct replicas accept
no updates generated spuriously by faulty replicas. To achieve reliable
diffusion, each correct replica accepts an update only after receiving it from
at least $t$ others. We provide the first analysis of epidemic-style protocols
for such environments. This analysis is fundamentally different from known
analyses for the benign case due to our treatment of fully Byzantine
failures---which, among other things, precludes the use of digital signatures
for authenticating forwarded updates. We propose two epidemic-style diffusion
algorithms and two measures that characterize the efficiency of diffusion
algorithms in general. We characterize both of our algorithms according to
these measures, and also prove lower bounds with regards to these measures that
show that our algorithms are close to optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9908011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9908011</id><created>1999-08-12</created><authors><author><keyname>Malkhi</keyname><forenames>Dahlia</forenames></author><author><keyname>Reiter</keyname><forenames>Michael</forenames></author><author><keyname>Wool</keyname><forenames>Avishai</forenames></author></authors><title>The Load and Availability of Byzantine Quorum Systems</title><categories>cs.DC cs.CR</categories><comments>preprint of a paper to appear in the SIAM Journal of Computing</comments><acm-class>C.2.4;C.4</acm-class><abstract>  Replicated services accessed via {\em quorums} enable each access to be
performed at only a subset (quorum) of the servers, and achieve consistency
across accesses by requiring any two quorums to intersect. Recently,
$b$-masking quorum systems, whose intersections contain at least $2b+1$
servers, have been proposed to construct replicated services tolerant of $b$
arbitrary (Byzantine) server failures. In this paper we consider a hybrid fault
model allowing benign failures in addition to the Byzantine ones. We present
four novel constructions for $b$-masking quorum systems in this model, each of
which has optimal {\em load} (the probability of access of the busiest server)
or optimal availability (probability of some quorum surviving failures). To
show optimality we also prove lower bounds on the load and availability of any
$b$-masking quorum system in this model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9908012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9908012</id><created>1999-08-16</created><authors><author><keyname>Gladney</keyname><forenames>H. M.</forenames></author></authors><title>Safe Deals Between Strangers</title><categories>cs.CR cs.DL</categories><comments>31 pages, 6 figures</comments><acm-class>D.4.6; H.2.7; K.6.5</acm-class><abstract>  E-business, information serving, and ubiquitous computing will create heavy
request traffic from strangers or even incognitos. Such requests must be
managed automatically. Two ways of doing this are well known: giving every
incognito consumer the same treatment, and rendering service in return for
money. However, different behavior will be often wanted, e.g., for a university
library with different access policies for undergraduates, graduate students,
faculty, alumni, citizens of the same state, and everyone else.
  For a data or process server contacted by client machines on behalf of users
not previously known, we show how to provide reliable automatic access
administration conforming to service agreements. Implementations scale well
from very small collections of consumers and producers to immense client/server
networks. Servers can deliver information, effect state changes, and control
external equipment.
  Consumer privacy is easily addressed by the same protocol. We support
consumer privacy, but allow servers to deny their resources to incognitos. A
protocol variant even protects against statistical attacks by consortia of
service organizations.
  One e-commerce application would put the consumer's tokens on a smart card
whose readers are in vending kiosks. In e-business we can simplify supply chain
administration. Our method can also be used in sensitive networks without
introducing new security loopholes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9908013</identifier>
 <datestamp>2009-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9908013</id><created>1999-08-17</created><authors><author><keyname>Wolpert</keyname><forenames>David H.</forenames></author><author><keyname>Wheeler</keyname><forenames>Kevin R.</forenames></author><author><keyname>Tumer</keyname><forenames>Kagan</forenames></author></authors><title>Collective Intelligence for Control of Distributed Dynamical Systems</title><categories>cs.LG adap-org cond-mat cs.AI cs.DC cs.MA nlin.AO</categories><comments>8 pages</comments><report-no>NASA-ARC-IC-99-44</report-no><acm-class>I.2.6 ; I.2.11</acm-class><doi>10.1209/epl/i2000-00208-x</doi><abstract>  We consider the El Farol bar problem, also known as the minority game (W. B.
Arthur, ``The American Economic Review'', 84(2): 406--411 (1994), D. Challet
and Y.C. Zhang, ``Physica A'', 256:514 (1998)). We view it as an instance of
the general problem of how to configure the nodal elements of a distributed
dynamical system so that they do not ``work at cross purposes'', in that their
collective dynamics avoids frustration and thereby achieves a provided global
goal. We summarize a mathematical theory for such configuration applicable when
(as in the bar problem) the global goal can be expressed as minimizing a global
energy function and the nodes can be expressed as minimizers of local free
energy functions. We show that a system designed with that theory performs
nearly optimally for the bar problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9908014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9908014</id><created>1999-08-17</created><authors><author><keyname>Wolpert</keyname><forenames>David H.</forenames></author><author><keyname>Tumer</keyname><forenames>Kagan</forenames></author></authors><title>An Introduction to Collective Intelligence</title><categories>cs.LG adap-org cond-mat cs.DC cs.MA nlin.AO</categories><comments>88 pages, 10 figs, 297 refs</comments><report-no>NASA-ARC-IC-99-63</report-no><acm-class>I.2.6 ; I.2.11</acm-class><abstract>  This paper surveys the emerging science of how to design a ``COllective
INtelligence'' (COIN). A COIN is a large multi-agent system where:
  (i) There is little to no centralized communication or control; and
  (ii) There is a provided world utility function that rates the possible
histories of the full system.
  In particular, we are interested in COINs in which each agent runs a
reinforcement learning (RL) algorithm. Rather than use a conventional modeling
approach (e.g., model the system dynamics, and hand-tune agents to cooperate),
we aim to solve the COIN design problem implicitly, via the ``adaptive''
character of the RL algorithms of each of the agents. This approach introduces
an entirely new, profound design problem: Assuming the RL algorithms are able
to achieve high rewards, what reward functions for the individual agents will,
when pursued by those agents, result in high world utility? In other words,
what reward functions will best ensure that we do not have phenomena like the
tragedy of the commons, Braess's paradox, or the liquidity trap?
  Although still very young, research specifically concentrating on the COIN
design problem has already resulted in successes in artificial domains, in
particular in packet-routing, the leader-follower problem, and in variants of
Arthur's El Farol bar problem. It is expected that as it matures and draws upon
other disciplines related to COINs, this research will greatly expand the range
of tasks addressable by human engineers. Moreover, in addition to drawing on
them, such a fully developed scie nce of COIN design may provide much insight
into other already established scientific fields, such as economics, game
theory, and population biology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9908015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9908015</id><created>1999-08-19</created><authors><author><keyname>Shum</keyname><forenames>Simon Buckingham</forenames></author><author><keyname>Motta</keyname><forenames>Enrico</forenames></author><author><keyname>Domingue</keyname><forenames>John</forenames></author></authors><title>Representing Scholarly Claims in Internet Digital Libraries: A Knowledge
  Modelling Approach</title><categories>cs.DL cs.AI cs.HC cs.IR</categories><comments>18 pages. Preprint, to appear: Proceedings of ECDL'99: Third European
  Conference on Research and Advanced Technology for Digital Libraries, Paris,
  France, September 22-24, 1999. Springer-Verlag Lecture Notes in Computer
  Science (Eds.) Serge Abiteboul and Anne-Marie Vercoustre</comments><report-no>KMI-TR-80</report-no><acm-class>H.3.7; H.1.2; H5.2; H.5.4; I.2.4; I.7.4</acm-class><abstract>  This paper is concerned with tracking and interpreting scholarly documents in
distributed research communities. We argue that current approaches to document
description, and current technological infrastructures particularly over the
World Wide Web, provide poor support for these tasks. We describe the design of
a digital library server which will enable authors to submit a summary of the
contributions they claim their documents makes, and its relations to the
literature. We describe a knowledge-based Web environment to support the
emergence of such a community-constructed semantic hypertext, and the services
it could provide to assist the interpretation of an idea or document in the
context of its literature. The discussion considers in detail how the approach
addresses usability issues associated with knowledge structuring environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9908016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9908016</id><created>1999-08-19</created><authors><author><keyname>Bern</keyname><forenames>Marshall</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Quadrilateral Meshing by Circle Packing</title><categories>cs.CG</categories><comments>12 pages, 10 figures. To appear in Int. J. Comp. Geom. &amp; Appl. A
  preliminary version of this work was presented at the 6th Int. Meshing
  Roundtable, Park City, Utah, 1997</comments><acm-class>F.2.2</acm-class><journal-ref>Int. J. Comp. Geom. &amp; Appl. 10(4):347-360, Aug. 2000</journal-ref><abstract>  We use circle-packing methods to generate quadrilateral meshes for polygonal
domains, with guaranteed bounds both on the quality and the number of elements.
We show that these methods can generate meshes of several types: (1) the
elements form the cells of a Voronoi diagram, (2) all elements have two
opposite right angles, (3) all elements are kites, or (4) all angles are at
most 120 degrees. In each case the total number of elements is O(n), where n is
the number of input vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9908017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9908017</id><created>1999-08-26</created><authors><author><keyname>Siebert</keyname><forenames>Andreas</forenames></author></authors><title>A Differential Invariant for Zooming</title><categories>cs.CV</categories><comments>5 pages, 7 figures</comments><acm-class>I.4.7</acm-class><journal-ref>Proceedings 1999 International Conference on Image Processing,
  Kobe, 25-28 October 1999</journal-ref><abstract>  This paper presents an invariant under scaling and linear brightness change.
The invariant is based on differentials and therefore is a local feature.
Rotationally invariant 2-d differential Gaussian operators up to third order
are proposed for the implementation of the invariant. The performance is
analyzed by simulating a camera zoom-out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9908018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9908018</id><created>1999-08-27</created><authors><author><keyname>Rigo</keyname><forenames>Michel</forenames></author></authors><title>Construction of regular languages and recognizability of polynomials</title><categories>cs.CC</categories><comments>11 pages</comments><acm-class>F.1.1; F.4.3</acm-class><abstract>  A generalization of numeration system in which the set N of the natural
numbers is recognizable by finite automata can be obtained by describing a
lexicographically ordered infinite regular language. Here we show that if P
belonging to Q[x] is a polynomial such that P(N) is a subset of N then we can
construct a numeration system in which the set of representations of P(N) is
regular. The main issue in this construction is to setup a regular language
with a density function equals to P(n+1)-P(n) for n large enough.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9909001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9909001</id><created>1999-09-01</created><authors><author><keyname>Bern</keyname><forenames>Marshall</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Agarwal</keyname><forenames>Pankaj K.</forenames></author><author><keyname>Amenta</keyname><forenames>Nina</forenames></author><author><keyname>Chew</keyname><forenames>Paul</forenames></author><author><keyname>Dey</keyname><forenames>Tamal</forenames></author><author><keyname>Dobkin</keyname><forenames>David P.</forenames></author><author><keyname>Edelsbrunner</keyname><forenames>Herbert</forenames></author><author><keyname>Grimm</keyname><forenames>Cindy</forenames></author><author><keyname>Guibas</keyname><forenames>Leonidas J.</forenames></author><author><keyname>Harer</keyname><forenames>John</forenames></author><author><keyname>Hass</keyname><forenames>Joel</forenames></author><author><keyname>Hicks</keyname><forenames>Andrew</forenames></author><author><keyname>Johnson</keyname><forenames>Carroll K.</forenames></author><author><keyname>Lerman</keyname><forenames>Gilad</forenames></author><author><keyname>Letscher</keyname><forenames>David</forenames></author><author><keyname>Plassmann</keyname><forenames>Paul</forenames></author><author><keyname>Sedgwick</keyname><forenames>Eric</forenames></author><author><keyname>Snoeyink</keyname><forenames>Jack</forenames></author><author><keyname>Weeks</keyname><forenames>Jeff</forenames></author><author><keyname>Yap</keyname><forenames>Chee</forenames></author><author><keyname>Zorin</keyname><forenames>Denis</forenames></author></authors><title>Emerging Challenges in Computational Topology</title><categories>cs.CG math.GT</categories><comments>20 pages</comments><acm-class>F.2.2; I.2.9; I.2.10; I.3.5; J.2</acm-class><abstract>  Here we present the results of the NSF-funded Workshop on Computational
Topology, which met on June 11 and 12 in Miami Beach, Florida. This report
identifies important problems involving both computation and topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9909002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9909002</id><created>1999-09-02</created><authors><author><keyname>Ballim</keyname><forenames>Afzal</forenames></author><author><keyname>Pallotta</keyname><forenames>Vincenzo</forenames></author></authors><title>Semantic robust parsing for noun extraction from natural language
  queries</title><categories>cs.CL</categories><acm-class>I.2.7</acm-class><journal-ref>Proceedings of WPDI'99 (Workshop on Procedures in Discourse
  Interpretation),1999, Iasi - Romania</journal-ref><abstract>  This paper describes how robust parsing techniques can be fruitful applied
for building a query generation module which is part of a pipelined NLP
architecture aimed at process natural language queries in a restricted domain.
We want to show that semantic robustness represents a key issue in those NLP
systems where it is more likely to have partial and ill-formed utterances due
to various factors (e.g. noisy environments, low quality of speech recognition
modules, etc...) and where it is necessary to succeed, even if partially, in
extracting some meaningful information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9909003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9909003</id><created>1999-09-03</created><authors><author><keyname>Mohanty</keyname><forenames>S.</forenames><affiliation>Department of Computer Science and Application Utkal University, Bhubaneswar, India</affiliation></author><author><keyname>Behera</keyname><forenames>R. N.</forenames><affiliation>National Informatics Centre, Puri, India</affiliation></author></authors><title>Iterative Deepening Branch and Bound</title><categories>cs.AI</categories><comments>39 html pages + 4 gif files (fig1,fig1(a),fig2,fig3)</comments><acm-class>I.2.8</acm-class><abstract>  In tree search problem the best-first search algorithm needs too much of
space . To remove such drawbacks of these algorithms the IDA* was developed
which is both space and time cost efficient. But again IDA* can give an optimal
solution for real valued problems like Flow shop scheduling, Travelling
Salesman and 0/1 Knapsack due to their real valued cost estimates. Thus further
modifications are done on it and the Iterative Deepening Branch and Bound
Search Algorithms is developed which meets the requirements. We have tried
using this algorithm for the Flow Shop Scheduling Problem and have found that
it is quite effective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9909004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9909004</id><created>1999-09-03</created><authors><author><keyname>Boissonnat</keyname><forenames>Jean-Daniel</forenames></author><author><keyname>Czyzowicz</keyname><forenames>Jurek</forenames></author><author><keyname>Devillers</keyname><forenames>Olivier</forenames></author><author><keyname>Robert</keyname><forenames>Jean-Marc</forenames></author><author><keyname>Yvinec</keyname><forenames>Mariette</forenames></author></authors><title>Convex Tours of Bounded Curvature</title><categories>cs.CG</categories><comments>11 pages, 5 figures, abstract presented at European Symposium on
  Algorithms 1993</comments><report-no>INRIA Research report 2375</report-no><acm-class>F.2.2; I.3.5</acm-class><abstract>  We consider the motion planning problem for a point constrained to move along
a smooth closed convex path of bounded curvature. The workspace of the moving
point is bounded by a convex polygon with m vertices, containing an obstacle in
a form of a simple polygon with $n$ vertices. We present an O(m+n) time
algorithm finding the path, going around the obstacle, whose curvature is the
smallest possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9909005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9909005</id><created>1999-09-03</created><authors><author><keyname>Boissonnat</keyname><forenames>Jean-Daniel</forenames></author><author><keyname>Czyzowicz</keyname><forenames>Jurek</forenames></author><author><keyname>Devillers</keyname><forenames>Olivier</forenames></author><author><keyname>Urrutia</keyname><forenames>Jorge</forenames></author><author><keyname>Yvinec</keyname><forenames>Mariette</forenames></author></authors><title>Computing largest circles separating two sets of segments</title><categories>cs.CG</categories><comments>14 pages, 3 figures, abstract presented at 8th Canadian Conference on
  Computational Geometry, 1996</comments><report-no>INRIA Research report 2705</report-no><acm-class>F.2.2; I.3.5</acm-class><abstract>  A circle $C$ separates two planar sets if it encloses one of the sets and its
open interior disk does not meet the other set. A separating circle is a
largest one if it cannot be locally increased while still separating the two
given sets. An Theta(n log n) optimal algorithm is proposed to find all largest
circles separating two given sets of line segments when line segments are
allowed to meet only at their endpoints. In the general case, when line
segments may intersect $\Omega(n^2)$ times, our algorithm can be adapted to
work in O(n alpha(n) log n) time and O(n \alpha(n)) space, where alpha(n)
represents the extremely slowly growing inverse of the Ackermann function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9909006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9909006</id><created>1999-09-03</created><authors><author><keyname>Boissonnat</keyname><forenames>Jean-Daniel</forenames></author><author><keyname>Devillers</keyname><forenames>Olivier</forenames></author><author><keyname>Lazard</keyname><forenames>Sylvain</forenames></author></authors><title>Motion Planning of Legged Robots</title><categories>cs.CG</categories><comments>29 pages, 22 figures, prelininar results presented at WAFR94 and IEEE
  Robotics &amp; Automation 94</comments><report-no>INRIA Research report 3214</report-no><acm-class>F.2.2; I.3.5</acm-class><abstract>  We study the problem of computing the free space F of a simple legged robot
called the spider robot. The body of this robot is a single point and the legs
are attached to the body. The robot is subject to two constraints: each leg has
a maximal extension R (accessibility constraint) and the body of the robot must
lie above the convex hull of its feet (stability constraint). Moreover, the
robot can only put its feet on some regions, called the foothold regions. The
free space F is the set of positions of the body of the robot such that there
exists a set of accessible footholds for which the robot is stable. We present
an efficient algorithm that computes F in O(n2 log n) time using O(n2 alpha(n))
space for n discrete point footholds where alpha(n) is an extremely slowly
growing function (alpha(n) &lt;= 3 for any practical value of n). We also present
an algorithm for computing F when the foothold regions are pairwise disjoint
polygons with n edges in total. This algorithm computes F in O(n2 alpha8(n) log
n) time using O(n2 alpha8(n)) space (alpha8(n) is also an extremely slowly
growing function). These results are close to optimal since Omega(n2) is a
lower bound for the size of F.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9909007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9909007</id><created>1999-09-03</created><authors><author><keyname>Boissonnat</keyname><forenames>Jean-Daniel</forenames></author><author><keyname>Czyzowicz</keyname><forenames>Jurek</forenames></author><author><keyname>Devillers</keyname><forenames>Olivier</forenames></author><author><keyname>Yvinec</keyname><forenames>Mariette</forenames></author></authors><title>Circular Separability of Polygons</title><categories>cs.CG</categories><comments>23 pages, 7 figures, abstract presented at SODA95</comments><report-no>INRIA Research report 2406</report-no><acm-class>F.2.2; I.3.5</acm-class><abstract>  Two planar sets are circularly separable if there exists a circle enclosing
one of the sets and whose open interior disk does not intersect the other set.
 This paper studies two problems related to circular separability. A
linear-time algorithm is proposed to decide if two polygons are circularly
separable. The algorithm outputs the smallest separating circle. The second
problem asks for the largest circle included in a preprocessed, convex polygon,
under some point and/or line constraints. The resulting circle must contain the
query points and it must lie in the halfplanes delimited by the query lines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9909008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9909008</id><created>1999-09-07</created><updated>2000-04-29</updated><authors><author><keyname>Kling</keyname><forenames>Rob</forenames></author><author><keyname>McKim</keyname><forenames>Geoffrey</forenames></author></authors><title>Not Just a Matter of Time: Field Differences and the Shaping of
  Electronic Media in Supporting Scientific Communication</title><categories>cs.CY</categories><comments>Accepted for publication in the Journal of the American Society for
  Information Science. Version was reformatted with several minor text changes</comments><acm-class>I.7.4; J2; J3</acm-class><abstract>  The shift towards the use of electronic media in scholarly communication
appears to be an inescapable imperative. However, these shifts are uneven, both
with respect to field and with respect to the form of communication. Different
scientific fields have developed and use distinctly different communicative
forums, both in the paper and electronic arenas, and these forums play
different communicative roles within the field. One common claim is that we are
in the early stages of an electronic revolution, that it is only a matter of
time before other fields catch up with the early adopters, and that all fields
converge on a stable set of electronic forums. A social shaping of technology
(SST) perspective helps us to identify important social forces centered around
disciplinary constructions of trust and of legitimate communication that pull
against convergence. This analysis concludes that communicative plurality and
communicative heterogeneity are durable features of the scholarly landscape,
and that we are likely to see field differences in the use of and meaning
ascribed to communications forums persist, even as overall use of electronic
communications technologies both in science and in society as a whole
increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9909009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9909009</id><created>1999-09-08</created><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author></authors><title>The Rough Guide to Constraint Propagation</title><categories>cs.AI cs.PL</categories><comments>23 pages. To appear in the Proc. 5th International Conference on
  Principles and Practice of Constraint Programming as an invited talk</comments><acm-class>D.3.3; I.1.2; I.2.2</acm-class><abstract>  We provide here a simple, yet very general framework that allows us to
explain several constraint propagation algorithms in a systematic way. In
particular, using the notions commutativity and semi-commutativity, we show how
the well-known AC-3, PC-2, DAC and DPC algorithms are instances of a single
generic algorithm. The work reported here extends and simplifies that of Apt,
cs.AI/9811024.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9909010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9909010</id><created>1999-09-08</created><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>Monfroy</keyname><forenames>Eric</forenames></author></authors><title>Automatic Generation of Constraint Propagation Algorithms for Small
  Finite Domains</title><categories>cs.AI cs.PL</categories><comments>15 pages. To appear in the Proc. 5th International Conference on
  Principles and Practice of Constraint Programming</comments><acm-class>D.#.2; I.2.2; I.2.3</acm-class><abstract>  We study here constraint satisfaction problems that are based on predefined,
explicitly given finite constraints. To solve them we propose a notion of rule
consistency that can be expressed in terms of rules derived from the explicit
representation of the initial constraints.
  This notion of local consistency is weaker than arc consistency for
constraints of arbitrary arity but coincides with it when all domains are unary
or binary. For Boolean constraints rule consistency coincides with the closure
under the well-known propagation rules for Boolean constraints.
  By generalizing the format of the rules we obtain a characterization of arc
consistency in terms of so-called inclusion rules. The advantage of rule
consistency and this rule based characterization of the arc consistency is that
the algorithms that enforce both notions can be automatically generated, as CHR
rules. So these algorithms could be integrated into constraint logic
programming systems such as Eclipse.
  We illustrate the usefulness of this approach to constraint propagation by
discussing the implementations of both algorithms and their use on various
examples, including Boolean constraints, three valued logic of Kleene,
constraints dealing with Waltz's language for describing polyhedreal scenes,
and Allen's qualitative approach to temporal logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9909011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9909011</id><created>1999-09-08</created><authors><author><keyname>Cidon</keyname><forenames>Israel</forenames></author><author><keyname>Mokryn</keyname><forenames>Osnat</forenames></author></authors><title>Distributed Algorithms in Multihop Broadcast Networks</title><categories>cs.DC cs.NI</categories><comments>Apeared at the 12th International Symposium on DIStributed Computing,
  (DISC98)</comments><report-no>Technical Report CC #241, Center for Communication and Information
  Technologies, Technion - Israel Institute of Technology</report-no><acm-class>g.2.2;c.2.4</acm-class><abstract>  Broadcast networks are often used in modern communication systems. A common
broadcast network is a single hop shared media system, where a transmitted
message is heard by all neighbors, such as some LAN networks. In this work we
consider a more complex environment, in which a transmitted message is heard
only by a group of neighbors, such as Ad-Hoc networks, satellite and radio
networks, as well as wireless multistation backbone system for mobile
communication. It is important to design efficient algorithms for such
environments. Our main result is a new Leader Election algorithm, with O(n)
time complexity and O(n*lg(n)) message transmission complexity. Our distributed
solution uses a propagation of information with feedback (PIF) building block
tuned to the broadcast media, and a special counting and joining approach for
the election procedure phase. The latter is required for achieving the linear
time. It is demonstrated that the broadcast model requires solutions which are
different from the known point-to-point model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9909012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9909012</id><created>1999-09-17</created><authors><author><keyname>Willemson</keyname><forenames>Jan</forenames></author></authors><title>Certificate Revocation Paradigms</title><categories>cs.CR</categories><comments>Tech report on 14 pages, 2 figures</comments><acm-class>E.3;H.3</acm-class><abstract>  Research in the field of electronic signature confirmation has been active
for some 20 years now. Unfortunately present certificate-based solutions also
come from that age when no-one knew about online data transmission. The
official standardized X.509 framework also depends heavily on offline
operations, one of the most complicated ones being certificate revocation
handling. This is done via huge Certificate Revocation Lists which are both
inconvenient and expencive. Several improvements to these lists are proposed
and in this report we try to analyze them briefly. We conclude that although it
is possible to do better than in the original X.509 setting, none of the
solutions presented this far is good enough.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9909013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9909013</id><created>1999-09-21</created><authors><author><keyname>Hoepman</keyname><forenames>Jaap-Henk</forenames></author></authors><title>Self-stabilizing mutual exclusion on a ring, even if K=N</title><categories>cs.DC</categories><comments>2 pages</comments><acm-class>D.4.5; D.1.3</acm-class><abstract>  We show that, contrary to common belief, Dijkstra's self-stabilizing mutual
exclusion algorithm on a ring [Dij74,Dij82] also stabilizes when the number of
states per node is one less than the number of nodes on the ring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9909014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9909014</id><created>1999-09-21</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Shore</keyname><forenames>Richard A.</forenames></author></authors><title>Reasoning About Common Knowledge with Infinitely Many Agents</title><categories>cs.LO cs.AI</categories><comments>Preliminary version appears in 14th IEEE Symposium on Logic in
  Computer Science, 1999. This is the full version</comments><acm-class>F.4.1; I.2.4</acm-class><abstract>  Complete axiomatizations and exponential-time decision procedures are
provided for reasoning about knowledge and common knowledge when there are
infinitely many agents. The results show that reasoning about knowledge and
common knowledge with infinitely many agents is no harder than when there are
finitely many agents, provided that we can check the cardinality of certain set
differences G - G', where G and G' are sets of agents. Since our complexity
results are independent of the cardinality of the sets G involved, they
represent improvements over the previous results even with the sets of agents
involved are finite. Moreover, our results make clear the extent to which
issues of complexity and completeness depend on how the sets of agents involved
are represented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9909015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9909015</id><created>1999-09-21</created><authors><author><keyname>Chu</keyname><forenames>Francis C.</forenames></author><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author></authors><title>A decision-theoretic approach to reliable message delivery</title><categories>cs.DC</categories><comments>This is the full version of a paper that appears in the Proceedings
  of the 12th International Symposium on Distributed Computing, 1998, pp. 89-10</comments><acm-class>F.3.1, C.2.4, C.2.1, D.4.7</acm-class><abstract>  We argue that the tools of decision theory need to be taken more seriously in
the specification and analysis of systems. We illustrate this by considering a
simple problem involving reliable communication, showing how considerations of
utility and probability can be used to decide when it is worth sending
heartbeat messages and, if they are sent, how often they should be sent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9909016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9909016</id><created>1999-09-21</created><authors><author><keyname>Chu</keyname><forenames>Francis C.</forenames></author><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Seshadri</keyname><forenames>Praveen</forenames></author></authors><title>Least expected cost query optimization: an exercise in utility</title><categories>cs.DB</categories><comments>This paper appears in Proceedings of the Eighteenth Annual ACM
  Symposium on Principles of Database Systems, 1999, pp. 138--147</comments><acm-class>H.2.4</acm-class><abstract>  We identify two unreasonable, though standard, assumptions made by database
query optimizers that can adversely affect the quality of the chosen evaluation
plans. One assumption is that it is enough to optimize for the expected
case---that is, the case where various parameters (like available memory) take
on their expected value. The other assumption is that the parameters are
constant throughout the execution of the query. We present an algorithm based
on the ``System R''-style query optimization algorithm that does not rely on
these assumptions. The algorithm we present chooses the plan of the least
expected cost instead of the plan of least cost given some fixed value of the
parameters. In execution environments that exhibit a high degree of
variability, our techniques should result in better performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9909017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9909017</id><created>1999-09-27</created><authors><author><keyname>Devillers</keyname><forenames>Olivier</forenames></author><author><keyname>Mukhopadhyay</keyname><forenames>Asish</forenames></author></authors><title>Finding an ordinary conic and an ordinary hyperplane</title><categories>cs.CG</categories><comments>7 pages, 2 figures</comments><report-no>INRIA Research report 3517</report-no><acm-class>F.2.2; I.3.5</acm-class><abstract>  Given a finite set of non-collinear points in the plane, there exists a line
that passes through exactly two points. Such a line is called an ordinary line.
An efficient algorithm for computing such a line was proposed by Mukhopadhyay
et al. In this note we extend this result in two directions. We first show how
to use this algorithm to compute an ordinary conic, that is, a conic passing
through exactly five points, assuming that all the points do not lie on the
same conic. Both our proofs of existence and the consequent algorithms are
simpler than previous ones. We next show how to compute an ordinary hyperplane
in three and higher dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9909018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9909018</id><created>1999-09-28</created><authors><author><keyname>Devillers</keyname><forenames>Olivier</forenames></author><author><keyname>Gandoin</keyname><forenames>Pierre-Maris</forenames></author></authors><title>Geometric compression for progressive transmission</title><categories>cs.CG cs.GR</categories><comments>16 pages, 10 figures</comments><report-no>INRIA Research report 3766, in french</report-no><acm-class>F.2.2; I.3.5</acm-class><abstract>  The compression of geometric structures is a relatively new field of data
compression. Since about 1995, several articles have dealt with the coding of
meshes, using for most of them the following approach: the vertices of the mesh
are coded in an order such that it contains partially the topology of the mesh.
In the same time, some simple rules attempt to predict the position of the
current vertex from the positions of its neighbours that have been previously
coded. In this article, we describe a compression algorithm whose principle is
completely different: the order of the vertices is used to compress their
coordinates, and then the topology of the mesh is reconstructed from the
vertices. This algorithm, particularly suited for terrain models, achieves
compression factors that are slightly greater than those of the currently
available algorithms, and moreover, it allows progressive and interactive
transmission of the meshes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9909019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9909019</id><created>1999-09-30</created><authors><author><keyname>Lomuscio</keyname><forenames>A. R.</forenames></author><author><keyname>van der Meyden</keyname><forenames>R.</forenames></author><author><keyname>Ryan</keyname><forenames>M. D.</forenames></author></authors><title>Knowledge in Multi-Agent Systems: Initial Configurations and Broadcast</title><categories>cs.LO cs.AI</categories><comments>32 Pages, 2 Figures. Submitted to Transactions of Computational Logic</comments><acm-class>F.4.1; I.2.4</acm-class><abstract>  The semantic framework for the modal logic of knowledge due to Halpern and
Moses provides a way to ascribe knowledge to agents in distributed and
multi-agent systems. In this paper we study two special cases of this
framework: full systems and hypercubes. Both model static situations in which
no agent has any information about another agent's state. Full systems and
hypercubes are an appropriate model for the initial configurations of many
systems of interest. We establish a correspondence between full systems and
hypercube systems and certain classes of Kripke frames. We show that these
classes of systems correspond to the same logic. Moreover, this logic is also
the same as that generated by the larger class of weakly directed frames. We
provide a sound and complete axiomatization, S5WDn, of this logic. Finally, we
show that under certain natural assumptions, in a model where knowledge evolves
over time, S5WDn characterizes the properties of knowledge not just at the
initial configuration, but also at all later configurations. In particular,
this holds for homogeneous broadcast systems, which capture settings in which
agents are initially ignorant of each others local states, operate
synchronously, have perfect recall and can communicate only by broadcasting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9909020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9909020</id><created>1999-09-30</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Hempel</keyname><forenames>Harald</forenames></author><author><keyname>Wechsung</keyname><forenames>Gerd</forenames></author></authors><title>Query Order</title><categories>cs.CC</categories><comments>18 pages, 1 figure (earlier version appears as UR-CS-TR-95-596)</comments><acm-class>F.1.3</acm-class><journal-ref>SIAM Journal on Computing, 28, 637-651, 1999</journal-ref><abstract>  We study the effect of query order on computational power, and show that
$\pjk$-the languages computable via a polynomial-time machine given one query
to the jth level of the boolean hierarchy followed by one query to the kth
level of the boolean hierarchy-equals $\redttnp{j+2k-1}$ if j is even and k is
odd, and equals $\redttnp{j+2k}$ otherwise. Thus, unless the polynomial
hierarchy collapses, it holds that for each $1\leq j \leq k$: $\pjk = \pkj \iff
(j=k) \lor (j{is even} \land k=j+1)$. We extend our analysis to apply to more
general query classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910001</id><created>1999-10-01</created><updated>2001-02-19</updated><authors><author><keyname>Flum</keyname><forenames>Joerg</forenames></author><author><keyname>Grohe</keyname><forenames>Martin</forenames></author></authors><title>Fixed-parameter tractability, definability, and model checking</title><categories>cs.CC cs.LO</categories><comments>To appear in SIAM Journal on Computing</comments><acm-class>F.1.3;F.4.1</acm-class><abstract>  In this article, we study parameterized complexity theory from the
perspective of logic, or more specifically, descriptive complexity theory.
  We propose to consider parameterized model-checking problems for various
fragments of first-order logic as generic parameterized problems and show how
this approach can be useful in studying both fixed-parameter tractability and
intractability. For example, we establish the equivalence between the
model-checking for existential first-order logic, the homomorphism problem for
relational structures, and the substructure isomorphism problem. Our main
tractability result shows that model-checking for first-order formulas is
fixed-parameter tractable when restricted to a class of input structures with
an excluded minor. On the intractability side, for every t &gt;= 0 we prove an
equivalence between model-checking for first-order formulas with t quantifier
alternations and the parameterized halting problem for alternating Turing
machines with t alternations. We discuss the close connection between this
alternation hierarchy and Downey and Fellows' W-hierarchy.
  On a more abstract level, we consider two forms of definability, called Fagin
definability and slicewise definability, that are appropriate for describing
parameterized problems. We give a characterization of the class FPT of all
fixed-parameter tractable problems in terms of slicewise definability in finite
variable least fixed-point logic, which is reminiscent of the Immerman-Vardi
Theorem characterizing the class PTIME in terms of definability in least
fixed-point logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910002</id><created>1999-10-01</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Hempel</keyname><forenames>Harald</forenames></author></authors><title>What's Up with Downward Collapse: Using the Easy-Hard Technique to Link
  Boolean and Polynomial Hierarchy Collapses</title><categories>cs.CC</categories><comments>37 pages. an extended abstract appeared in SIGACT News, 29, 10-22,
  1998</comments><report-no>UR-CS-TR-98-682</report-no><acm-class>F.1.3</acm-class><abstract>  During the past decade, nine papers have obtained increasingly strong
consequences from the assumption that boolean or bounded-query hierarchies
collapse. The final four papers of this nine-paper progression actually achieve
downward collapse---that is, they show that high-level collapses induce
collapses at (what beforehand were thought to be) lower complexity levels. For
example, for each $k\geq 2$ it is now known that if $\psigkone=\psigktwo$ then
$\ph=\sigmak$. This article surveys the history, the results, and the
technique---the so-called easy-hard method---of these nine papers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910003</id><created>1999-10-01</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Hempel</keyname><forenames>Harald</forenames></author></authors><title>R_{1-tt}^{SN}(NP) Distinguishes Robust Many-One and Turing Completeness</title><categories>cs.CC</categories><comments>22 pages</comments><report-no>earlier version appears as UR-CS-TR-96-635</report-no><acm-class>F.1.3</acm-class><journal-ref>Theory of Computing Systems, 31, 307-325, 1998</journal-ref><abstract>  Do complexity classes have many-one complete sets if and only if they have
Turing-complete sets? We prove that there is a relativized world in which a
relatively natural complexity class-namely a downward closure of NP, \rsnnp -
has Turing-complete sets but has no many-one complete sets. In fact, we show
that in the same relativized world this class has 2-truth-table complete sets
but lacks 1-truth-table complete sets. As part of the groundwork for our
result, we prove that \rsnnp has many equivalent forms having to do with
ordered and parallel access to $\np$ and $\npinterconp$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910004</id><created>1999-10-01</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Hempel</keyname><forenames>Harald</forenames></author></authors><title>An Introduction to Query Order</title><categories>cs.CC</categories><comments>15 pages</comments><report-no>earlier version appears as UR-CS-TR-97-665</report-no><acm-class>F.1.3</acm-class><journal-ref>Bulletin of the EATCS, 63, 93-107, 1997</journal-ref><abstract>  Hemaspaandra, Hempel, and Wechsung [cs.CC/9909020] raised the following
questions: If one is allowed one question to each of two different information
sources, does the order in which one asks the questions affect the class of
problems that one can solve with the given access? If so, which order yields
the greater computational power?
  The answers to these questions have been learned-inasfar as they can be
learned without resolving whether or not the polynomial hierarchy collapses-for
both the polynomial hierarchy and the boolean hierarchy. In the polynomial
hierarchy, query order never matters. In the boolean hierarchy, query order
sometimes does not matter and, unless the polynomial hierarchy collapses,
sometimes does matter. Furthermore, the study of query order has yielded
dividends in seemingly unrelated areas, such as bottleneck computations and
downward translation of equality.
  In this article, we present some of the central results on query order. The
article is written in such a way as to encourage the reader to try his or her
own hand at proving some of these results. We also give literature pointers to
the quickly growing set of related results and applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910005</id><created>1999-10-01</created><updated>1999-10-04</updated><authors><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Hempel</keyname><forenames>Harald</forenames></author></authors><title>Query Order and the Polynomial Hierarchy</title><categories>cs.CC</categories><comments>14 pages</comments><report-no>earlier version appears as UR-CS-TR-96-634</report-no><acm-class>F.1.3</acm-class><journal-ref>Journal of Universal Computer Science, 4, 574-588, 1998</journal-ref><abstract>  Hemaspaandra, Hempel, and Wechsung [cs.CC/9909020] initiated the field of
query order, which studies the ways in which computational power is affected by
the order in which information sources are accessed. The present paper studies,
for the first time, query order as it applies to the levels of the polynomial
hierarchy. We prove that the levels of the polynomial hierarchy are
order-oblivious. Yet, we also show that these ordered query classes form new
levels in the polynomial hierarchy unless the polynomial hierarchy collapses.
We prove that all leaf language classes - and thus essentially all standard
complexity classes - inherit all order-obliviousness results that hold for P.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910006</id><created>1999-10-01</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Hempel</keyname><forenames>Harald</forenames></author><author><keyname>Wechsung</keyname><forenames>Gerd</forenames></author></authors><title>Self-Specifying Machines</title><categories>cs.CC</categories><comments>15 pages, to appear in IJFCS</comments><report-no>earlier version appears as UR-CS-TR-97-654</report-no><acm-class>F.1.3</acm-class><abstract>  We study the computational power of machines that specify their own
acceptance types, and show that they accept exactly the languages that
$\manyonesharp$-reduce to NP sets. A natural variant accepts exactly the
languages that $\manyonesharp$-reduce to P sets. We show that these two classes
coincide if and only if $\psone = \psnnoplusbigohone$, where the latter class
denotes the sets acceptable via at most one question to $\sharpp$ followed by
at most a constant number of questions to $\np$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910007</id><created>1999-10-01</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Hempel</keyname><forenames>Harald</forenames></author></authors><title>A Downward Collapse within the Polynomial Hierarchy</title><categories>cs.CC</categories><comments>14 pages</comments><report-no>earlier version appears as UR-CS-TR-96-630</report-no><acm-class>F.1.3</acm-class><journal-ref>SIAM Journal on Computing, 28, 383-393, 1999</journal-ref><abstract>  Downward collapse (a.k.a. upward separation) refers to cases where the
equality of two larger classes implies the equality of two smaller classes. We
provide an unqualified downward collapse result completely within the
polynomial hierarchy. In particular, we prove that, for k &gt; 2, if $\psigkone =
\psigktwo$ then $\sigmak = \pik = \ph$. We extend this to obtain a more general
downward collapse result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910008</id><created>1999-10-01</created><updated>1999-10-04</updated><authors><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Hempel</keyname><forenames>Harald</forenames></author></authors><title>Translating Equality Downwards</title><categories>cs.CC</categories><comments>13 pages, an extended abstract was presented at the 16th Symposium on
  Theoretical Aspects of Computer Science</comments><report-no>earlier version appears as UR-CS-TR-97-657</report-no><acm-class>F.1.3</acm-class><abstract>  Downward translation of equality refers to cases where a collapse of some
pair of complexity classes would induce a collapse of some other pair of
complexity classes that (a priori) one expects are smaller. Recently, the first
downward translation of equality was obtained that applied to the polynomial
hierarchy-in particular, to bounded access to its levels [cs.CC/9910007]. In
this paper, we provide a much broader downward translation that extends not
only that downward translation but also that translation's elegant enhancement
by Buhrman and Fortnow. Our work also sheds light on previous research on the
structure of refined polynomial hierarchies, and strengthens the connection
between the collapse of bounded query hierarchies and the collapse of the
polynomial hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910009</id><created>1999-10-08</created><authors><author><keyname>Biedl</keyname><forenames>T.</forenames></author><author><keyname>Demaine</keyname><forenames>E.</forenames></author><author><keyname>Demaine</keyname><forenames>M.</forenames></author><author><keyname>Lazard</keyname><forenames>S.</forenames></author><author><keyname>Lubiw</keyname><forenames>A.</forenames></author><author><keyname>O'Rourke</keyname><forenames>J.</forenames></author><author><keyname>Overmars</keyname><forenames>M.</forenames></author><author><keyname>Robbins</keyname><forenames>S.</forenames></author><author><keyname>Streinu</keyname><forenames>I.</forenames></author><author><keyname>Toussaint</keyname><forenames>G.</forenames></author><author><keyname>Whitesides</keyname><forenames>S.</forenames></author></authors><title>Locked and Unlocked Polygonal Chains in 3D</title><categories>cs.CG cs.DM</categories><comments>29 pages; This is a revised and expanded version of an abstract that
  appeared in Proc. 10th ACM-SIAM Sympos. Discrete Algorithms (SODA '98), Jan.
  1998, pp. 866-867</comments><report-no>Smith Tech. Rep. 060</report-no><acm-class>F.2.2</acm-class><abstract>  In this paper, we study movements of simple polygonal chains in 3D. We say
that an open, simple polygonal chain can be straightened if it can be
continuously reconfigured to a straight sequence of segments in such a manner
that both the length of each link and the simplicity of the chain are
maintained throughout the movement. The analogous concept for closed chains is
convexification: reconfiguration to a planar convex polygon. Chains that cannot
be straightened or convexified are called locked. While there are open chains
in 3D that are locked, we show that if an open chain has a simple orthogonal
projection onto some plane, it can be straightened. For closed chains, we show
that there are unknotted but locked closed chains, and we provide an algorithm
for convexifying a planar simple polygon in 3D. All our algorithms require only
O(n) basic ``moves'' and run in linear time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910010</id><created>1999-10-12</created><updated>2000-04-28</updated><authors><author><keyname>Buhrman</keyname><forenames>Harry</forenames><affiliation>CWI, Amsterdam</affiliation></author><author><keyname>de Wolf</keyname><forenames>Ronald</forenames><affiliation>CWI and U of Amsterdam</affiliation></author></authors><title>Communication Complexity Lower Bounds by Polynomials</title><categories>cs.CC quant-ph</categories><comments>16 pages LaTeX, no figures. 2nd version: rewritten and some results
  added</comments><acm-class>E.4; F.1.1; F.2.0</acm-class><abstract>  The quantum version of communication complexity allows the two communicating
parties to exchange qubits and/or to make use of prior entanglement (shared
EPR-pairs). Some lower bound techniques are available for qubit communication
complexity, but except for the inner product function, no bounds are known for
the model with unlimited prior entanglement. We show that the log-rank lower
bound extends to the strongest model (qubit communication + unlimited prior
entanglement). By relating the rank of the communication matrix to properties
of polynomials, we are able to derive some strong bounds for exact protocols.
In particular, we prove both the &quot;log-rank conjecture&quot; and the polynomial
equivalence of quantum and classical communication complexity for various
classes of functions. We also derive some weaker bounds for bounded-error
quantum protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910011</id><created>1999-10-12</created><authors><author><keyname>Venkataraman</keyname><forenames>Anand</forenames></author></authors><title>A statistical model for word discovery in child directed speech</title><categories>cs.CL cs.LG</categories><comments>48 pgs, 10 figs</comments><acm-class>I.2.6; I.2.7</acm-class><abstract>  A statistical model for segmentation and word discovery in child directed
speech is presented. An incremental unsupervised learning algorithm to infer
word boundaries based on this model is described and results of empirical tests
showing that the algorithm is competitive with other models that have been used
for similar tasks are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910012</id><created>1999-10-13</created><authors><author><keyname>Reynolds</keyname><forenames>M.</forenames></author></authors><title>The Complexity of Temporal Logic over the Reals</title><categories>cs.LO cs.CC</categories><acm-class>F4.1;F2.2</acm-class><abstract>  It is shown that the decision problem for the temporal logic with until and
since connectives over real-numbers time is PSPACE-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910013</id><created>1999-10-13</created><authors><author><keyname>Chen</keyname><forenames>Zhi-Zhong</forenames></author><author><keyname>Grigni</keyname><forenames>Michelangelo</forenames></author><author><keyname>Papadimitriou</keyname><forenames>Christos</forenames></author></authors><title>Map Graphs</title><categories>cs.DM cs.DS</categories><comments>46 pages, LaTeX with 41 PS figures; see
  http://www.mathcs.emory.edu/~mic/mapgraphs/ for hi-res figures</comments><acm-class>G.2.2; F.2.2</acm-class><abstract>  We consider a modified notion of planarity, in which two nations of a map are
considered adjacent when they share any point of their boundaries (not
necessarily an edge, as planarity requires). Such adjacencies define a map
graph. We give an NP characterization for such graphs, and a cubic time
recognition algorithm for a restricted version: given a graph, decide whether
it is realized by adjacencies in a map without holes, in which at most four
nations meet at any point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910014</id><created>1999-10-14</created><updated>2000-07-06</updated><authors><author><keyname>Bryant</keyname><forenames>Randal E.</forenames></author><author><keyname>German</keyname><forenames>Steven</forenames></author><author><keyname>Velev</keyname><forenames>Miroslav N.</forenames></author></authors><title>Processor Verification Using Efficient Reductions of the Logic of
  Uninterpreted Functions to Propositional Logic</title><categories>cs.LO cs.AR</categories><comments>46 pages</comments><acm-class>F.4.1</acm-class><abstract>  The logic of equality with uninterpreted functions (EUF) provides a means of
abstracting the manipulation of data by a processor when verifying the
correctness of its control logic. By reducing formulas in this logic to
propositional formulas, we can apply Boolean methods such as Ordered Binary
Decision Diagrams (BDDs) and Boolean satisfiability checkers to perform the
verification.
  We can exploit characteristics of the formulas describing the verification
conditions to greatly simplify the propositional formulas generated. In
particular, we exploit the property that many equations appear only in positive
form. We can therefore reduce the set of interpretations of the function
symbols that must be considered to prove that a formula is universally valid to
those that are ``maximally diverse.''
  We present experimental results demonstrating the efficiency of this approach
when verifying pipelined processors using the method proposed by Burch and
Dill.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910015</id><created>1999-10-18</created><updated>2000-04-25</updated><authors><author><keyname>Ramakrishnan</keyname><forenames>Naren</forenames></author></authors><title>PIPE: Personalizing Recommendations via Partial Evaluation</title><categories>cs.IR cs.AI</categories><acm-class>H.4.2</acm-class><abstract>  It is shown that personalization of web content can be advantageously viewed
as a form of partial evaluation --- a technique well known in the programming
languages community. The basic idea is to model a recommendation space as a
program, then partially evaluate this program with respect to user preferences
(and features) to obtain specialized content. This technique supports both
content-based and collaborative approaches, and is applicable to a range of
applications that require automatic information integration from multiple web
sources. The effectiveness of this methodology is illustrated by two example
applications --- (i) personalizing content for visitors to the Blacksburg
Electronic Village (http://www.bev.net), and (ii) locating and selecting
scientific software on the Internet. The scalability of this technique is
demonstrated by its ability to interface with online web ontologies that index
thousands of web pages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910016</id><created>1999-10-21</created><authors><author><keyname>Dix</keyname><forenames>Juergen</forenames></author><author><keyname>Nanni</keyname><forenames>Mirco</forenames></author><author><keyname>Subrahmanian</keyname><forenames>VS</forenames></author></authors><title>Probabilistic Agent Programs</title><categories>cs.AI</categories><comments>44 pages, 1 figure, Appendix</comments><acm-class>D.1.6</acm-class><abstract>  Agents are small programs that autonomously take actions based on changes in
their environment or ``state.'' Over the last few years, there have been an
increasing number of efforts to build agents that can interact and/or
collaborate with other agents. In one of these efforts, Eiter, Subrahmanian amd
Pick (AIJ, 108(1-2), pages 179-255) have shown how agents may be built on top
of legacy code. However, their framework assumes that agent states are
completely determined, and there is no uncertainty in an agent's state. Thus,
their framework allows an agent developer to specify how his agents will react
when the agent is 100% sure about what is true/false in the world state. In
this paper, we propose the concept of a \emph{probabilistic agent program} and
show how, given an arbitrary program written in any imperative language, we may
build a declarative ``probabilistic'' agent program on top of it which supports
decision making in the presence of uncertainty. We provide two alternative
semantics for probabilistic agent programs. We show that the second semantics,
though more epistemically appealing, is more complex to compute. We provide
sound and complete algorithms to compute the semantics of \emph{positive} agent
programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910017</id><created>1999-10-21</created><authors><author><keyname>Erickson</keyname><forenames>Jeff</forenames></author></authors><title>Finite-resolution hidden surface removal</title><categories>cs.CG cs.GR</categories><comments>10 pages, many figures; To appear in Proceedings of the 11th Annual
  ACM-SIAM Symposium on Discrete Algorithms, 2000; See also
  http://www.uiuc.edu/~jeffe/pubs/gridvis.html</comments><acm-class>I.3.7,F.2.2</acm-class><abstract>  We propose a hybrid image-space/object-space solution to the classical hidden
surface removal problem: Given n disjoint triangles in Real^3 and p sample
points (``pixels'') in the xy-plane, determine the first triangle directly
behind each pixel. Our algorithm constructs the sampled visibility map of the
triangles with respect to the pixels, which is the subset of the trapezoids in
a trapezoidal decomposition of the analytic visibility map that contain at
least one pixel. The sampled visibility map adapts to local changes in image
complexity, and its complexity is bounded both by the number of pixels and by
the complexity of the analytic visibility map. Our algorithm runs in time
O(n^{1+e} + n^{2/3+e}t^{2/3} + p), where t is the output size and e is any
positive constant. This is nearly optimal in the worst case and compares
favorably with the best output-sensitive algorithms for both ray casting and
analytic hidden surface removal. In the special case where the pixels form a
regular grid, a sweepline variant of our algorithm runs in time O(n^{1+e} +
n^{2/3+e}t^{2/3} + t log p), which is usually sublinear in the number of
pixels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910018</id><created>1999-10-21</created><authors><author><keyname>Wang</keyname><forenames>S. Y.</forenames></author></authors><title>Decoupling Control from Data for TCP Congestion Control</title><categories>cs.NI</categories><comments>Ph.D. Thesis, Harvard University, September 1999. This thesis's
  Chapter 3 about &quot;TCP Trunking&quot; will be published in IEEE ICNP'99 Proceedings.
  A condensed version of this thesis is currently submitted to a conference</comments><acm-class>C.2.2; C.2.5; C.2.6</acm-class><abstract>  Many applications want to use TCP congestion control to regulate the
transmission rate of a data packet stream. A natural way to achieve this goal
is to transport the data packet stream on a TCP connection. However, because
TCP implements both congestion and error control, transporting a data packet
stream directly using a TCP connection forces the data packet stream to be
subject to TCP's other properties caused by TCP error control, which may be
inappropriate for these applications.
  The TCP decoupling approach proposed in this thesis is a novel way of
applying TCP congestion control to a data packet stream without actually
transporting the data packet stream on a TCP connection. Instead, a TCP
connection using the same network path as the data packet stream is set up
separately and the transmission rate of the data packet stream is then
associated with that of the TCP packets. Since the transmission rate of these
TCP packets is under TCP congestion control, so is that of the data packet
stream. Furthermore, since the data packet stream is not transported on a TCP
connection, the regulated data packet stream is not subject to TCP error
control.
  Because of this flexibility, the TCP decoupling approach opens up many new
opportunities, solves old problems, and improves the performance of some
existing applications. All of these advantages will be demonstrated in the
thesis.
  This thesis presents the design, implementation, and analysis of the TCP
decoupling approach, and its successful applications in TCP trunking, wireless
communication, and multimedia streaming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910019</id><created>1999-10-22</created><authors><author><keyname>Baldoni</keyname><forenames>R.</forenames></author><author><keyname>Quaglia</keyname><forenames>F.</forenames></author><author><keyname>Raynal</keyname><forenames>M.</forenames></author></authors><title>Consistent Checkpointing in Distributed Databases: Towards a Formal
  Approach</title><categories>cs.DB cs.DC</categories><comments>13 pages, 3 figures</comments><report-no>Rapporto di Ricerca, Dipartimento di Informatica e Sistemistica,
  Universita' di Roma &quot;La Sapienza&quot;-(Italy) n. 27-97, July 1997</report-no><acm-class>C.2.4; H.2</acm-class><abstract>  Whether it is for audit or for recovery purposes, data checkpointing is an
important problem of distributed database systems. Actually, transactions
establish dependence relations on data checkpoints taken by data object
managers. So, given an arbitrary set of data checkpoints (including at least a
single data checkpoint from a data manager, and at most a data checkpoint from
each data manager), an important question is the following one: ``Can these
data checkpoints be members of a same consistent global checkpoint?''. This
paper answers this question by providing a necessary and sufficient condition
suited for database systems. Moreover, to show the usefulness of this
condition, two {\em non-intrusive} data checkpointing protocols are derived
from this condition. It is also interesting to note that this paper, by
exhibiting ``correspondences'', establishes a bridge between the data
object/transaction model and the process/message-passing model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910020</id><created>1999-10-23</created><authors><author><keyname>Fujii</keyname><forenames>Atsushi</forenames></author><author><keyname>Inui</keyname><forenames>Kentaro</forenames></author><author><keyname>Tokunaga</keyname><forenames>Takenobu</forenames></author><author><keyname>Tanaka</keyname><forenames>Hozumi</forenames></author></authors><title>Selective Sampling for Example-based Word Sense Disambiguation</title><categories>cs.CL</categories><comments>25 pages, 14 Postscript figures</comments><acm-class>I.2.7</acm-class><journal-ref>Computational Linguistics, Vol.24, No.4, pp.573-597, 1998</journal-ref><abstract>  This paper proposes an efficient example sampling method for example-based
word sense disambiguation systems. To construct a database of practical size, a
considerable overhead for manual sense disambiguation (overhead for
supervision) is required. In addition, the time complexity of searching a
large-sized database poses a considerable problem (overhead for search). To
counter these problems, our method selectively samples a smaller-sized
effective subset from a given example set for use in word sense disambiguation.
Our method is characterized by the reliance on the notion of training utility:
the degree to which each example is informative for future example sampling
when used for the training of the system. The system progressively collects
examples by selecting those with greatest utility. The paper reports the
effectiveness of our method through experiments on about one thousand
sentences. Compared to experiments with other example sampling methods, our
method reduced both the overhead for supervision and the overhead for search,
without the degeneration of the performance of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910021</id><created>1999-10-25</created><authors><author><keyname>Roy</keyname><forenames>Prasan</forenames></author><author><keyname>Seshadri</keyname><forenames>S.</forenames></author><author><keyname>Sudarshan</keyname><forenames>S.</forenames></author><author><keyname>Bhobe</keyname><forenames>Siddhesh</forenames></author></authors><title>Efficient and Extensible Algorithms for Multi Query Optimization</title><categories>cs.DB</categories><acm-class>H.2.4;H.2.7</acm-class><abstract>  Complex queries are becoming commonplace, with the growing use of decision
support systems. These complex queries often have a lot of common
sub-expressions, either within a single query, or across multiple such queries
run as a batch. Multi-query optimization aims at exploiting common
sub-expressions to reduce evaluation cost. Multi-query optimization has
hither-to been viewed as impractical, since earlier algorithms were exhaustive,
and explore a doubly exponential search space.
  In this paper we demonstrate that multi-query optimization using heuristics
is practical, and provides significant benefits. We propose three cost-based
heuristic algorithms: Volcano-SH and Volcano-RU, which are based on simple
modifications to the Volcano search strategy, and a greedy heuristic. Our
greedy heuristic incorporates novel optimizations that improve efficiency
greatly. Our algorithms are designed to be easily added to existing optimizers.
We present a performance study comparing the algorithms, using workloads
consisting of queries from the TPC-D benchmark. The study shows that our
algorithms provide significant benefits over traditional optimization, at a
very acceptable overhead in optimization time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910022</id><created>1999-10-25</created><authors><author><keyname>Nederhof</keyname><forenames>Mark-Jan</forenames></author></authors><title>Practical experiments with regular approximation of context-free
  languages</title><categories>cs.CL</categories><comments>28 pages. To appear in Computational Linguistics 26(1), March 2000</comments><acm-class>F.4.3; F.1.1</acm-class><abstract>  Several methods are discussed that construct a finite automaton given a
context-free grammar, including both methods that lead to subsets and those
that lead to supersets of the original context-free language. Some of these
methods of regular approximation are new, and some others are presented here in
a more refined form with respect to existing literature. Practical experiments
with the different methods of regular approximation are performed for
spoken-language input: hypotheses from a speech recognizer are filtered through
a finite automaton.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910023</id><created>1999-10-28</created><updated>2007-01-27</updated><authors><author><keyname>Guglielmi</keyname><forenames>Alessio</forenames></author></authors><title>A System of Interaction and Structure</title><categories>cs.LO</categories><comments>This is the authoritative version of the article, with readable
  pictures, in colour, also available at
  &lt;http://cs.bath.ac.uk/ag/p/SystIntStr.pdf&gt;. (The published version contains
  errors introduced by the editorial processing.) Web site for Deep Inference
  and the Calculus of Structures at &lt;http://alessio.guglielmi.name/res/cos&gt;</comments><acm-class>F.4.1; F.1.2</acm-class><journal-ref>ACM Transactions on Computational Logic, Vol. 8 (1:1), 2007, pp.
  1-64</journal-ref><doi>10.1145/1182613.1182614</doi><abstract>  This paper introduces a logical system, called BV, which extends
multiplicative linear logic by a non-commutative self-dual logical operator.
This extension is particularly challenging for the sequent calculus, and so far
it is not achieved therein. It becomes very natural in a new formalism, called
the calculus of structures, which is the main contribution of this work.
Structures are formulae submitted to certain equational laws typical of
sequents. The calculus of structures is obtained by generalising the sequent
calculus in such a way that a new top-down symmetry of derivations is observed,
and it employs inference rules that rewrite inside structures at any depth.
These properties, in addition to allow the design of BV, yield a modular proof
of cut elimination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9910024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9910024</id><created>1999-11-01</created><updated>2000-09-28</updated><authors><author><keyname>Biedl</keyname><forenames>Therese</forenames></author><author><keyname>Demaine</keyname><forenames>Erik</forenames></author><author><keyname>Demaine</keyname><forenames>Martin</forenames></author><author><keyname>Lazard</keyname><forenames>Sylvain</forenames></author><author><keyname>Lubiw</keyname><forenames>Anna</forenames></author><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author><author><keyname>Robbins</keyname><forenames>Steve</forenames></author><author><keyname>Streinu</keyname><forenames>Ileana</forenames></author><author><keyname>Toussaint</keyname><forenames>Godfried</forenames></author><author><keyname>Whitesides</keyname><forenames>Sue</forenames></author></authors><title>On Reconfiguring Tree Linkages: Trees can Lock</title><categories>cs.CG cs.DM</categories><comments>16 pages, 6 figures Introduction reworked and references added, as
  the main open problem was recently closed</comments><report-no>SOCS-00.7</report-no><acm-class>F2.2</acm-class><abstract>  It has recently been shown that any simple (i.e. nonintersecting) polygonal
chain in the plane can be reconfigured to lie on a straight line, and any
simple polygon can be reconfigured to be convex. This result cannot be extended
to tree linkages: we show that there are trees with two simple configurations
that are not connected by a motion that preserves simplicity throughout the
motion. Indeed, we prove that an $N$-link tree can have $2^{\Omega(N)}$
equivalence classes of configurations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9911001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9911001</id><created>1999-11-04</created><updated>1999-11-26</updated><authors><author><keyname>Heering</keyname><forenames>Jan</forenames></author><author><keyname>Klint</keyname><forenames>Paul</forenames></author></authors><title>Semantics of Programming Languages: A Tool-Oriented Approach</title><categories>cs.PL</categories><comments>12 pages, 2 figures. Submitted to ACM SIGPLAN Notices</comments><report-no>SEN-R9920 (CWI, Amsterdam)</report-no><acm-class>D.2.2; D.3.1; D.3.4; F.3.2</acm-class><journal-ref>ACM SIGPLAN Notices V. 35(3) March 2000 pp. 39-48</journal-ref><abstract>  By paying more attention to semantics-based tool generation, programming
language semantics can significantly increase its impact. Ultimately, this may
lead to ``Language Design Assistants'' incorporating substantial amounts of
semantic knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9911002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9911002</id><created>1999-11-08</created><updated>2000-01-20</updated><authors><author><keyname>Rigo</keyname><forenames>Michel</forenames></author></authors><title>Numeration systems on a regular language: Arithmetic operations,
  Recognizability and Formal power series</title><categories>cs.CC</categories><comments>34 pages; corrected typos, two sections concerning exponential case
  and relation with positional systems added</comments><acm-class>F.1.1; F.4.3</acm-class><journal-ref>Theoret. Comput. Sci. 269 (2001) 469--498</journal-ref><abstract>  Generalizations of numeration systems in which N is recognizable by a finite
automaton are obtained by describing a lexicographically ordered infinite
regular language L over a finite alphabet A. For these systems, we obtain a
characterization of recognizable sets of integers in terms of rational formal
series. We also show that, if the complexity of L is Theta (n^q) (resp. if L is
the complement of a polynomial language), then multiplication by an integer k
preserves recognizability only if k=t^{q+1} (resp. if k is not a power of the
cardinality of A) for some integer t. Finally, we obtain sufficient conditions
for the notions of recognizability and U-recognizability to be equivalent,
where U is some positional numeration system related to a sequence of integers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9911003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9911003</id><created>1999-11-09</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Subgraph Isomorphism in Planar Graphs and Related Problems</title><categories>cs.DS</categories><comments>27 pages, 6 figures. A preliminary version of this paper appeared at
  the 6th ACM-SIAM Symp. Discrete Algorithms, 1995</comments><acm-class>F.2.2</acm-class><journal-ref>J. Graph Algorithms &amp; Applications 3(3):1-27, 1999</journal-ref><abstract>  We solve the subgraph isomorphism problem in planar graphs in linear time,
for any pattern of constant size. Our results are based on a technique of
partitioning the planar graph into pieces of small tree-width, and applying
dynamic programming within each piece. The same methods can be used to solve
other planar graph problems including connectivity, diameter, girth, induced
subgraph isomorphism, and shortest paths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9911004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9911004</id><created>1999-11-10</created><authors><author><keyname>Slany</keyname><forenames>Wolfgang</forenames></author></authors><title>Graph Ramsey games</title><categories>cs.CC cs.DM math.CO</categories><comments>47 pages; To actually play small but nontrivial game instances, go to
  http://www.dbai.tuwien.ac.at/proj/ramsey/</comments><report-no>DBAI-TR-99-34</report-no><acm-class>F.1.3; F.2.2; G.2.1; G.2.2; G.2.3; H.3.5; I.2.6; I.2.8</acm-class><abstract>  We consider combinatorial avoidance and achievement games based on graph
Ramsey theory: The players take turns in coloring still uncolored edges of a
graph G, each player being assigned a distinct color, choosing one edge per
move. In avoidance games, completing a monochromatic subgraph isomorphic to
another graph A leads to immediate defeat or is forbidden and the first player
that cannot move loses. In the avoidance+ variants, both players are free to
choose more than one edge per move. In achievement games, the first player that
completes a monochromatic subgraph isomorphic to A wins. Erdos &amp; Selfridge
(1973) were the first to identify some tractable subcases of these games,
followed by a large number of further studies. We complete these investigations
by settling the complexity of all unrestricted cases: We prove that general
graph Ramsey avoidance, avoidance+, and achievement games and several variants
thereof are PSPACE-complete. We ultra-strongly solve some nontrivial instances
of graph Ramsey avoidance games that are based on symmetric binary Ramsey
numbers and provide strong evidence that all other cases based on symmetric
binary Ramsey numbers are effectively intractable.
  Keywords: combinatorial games, graph Ramsey theory, Ramsey game,
PSPACE-completeness, complexity, edge coloring, winning strategy, achievement
game, avoidance game, the game of Sim, Polya's enumeration formula,
probabilistic counting, machine learning, heuristics, Java applet
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9911005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9911005</id><created>1999-11-11</created><authors><author><keyname>Gray</keyname><forenames>Jim</forenames></author></authors><title>What Next? A Dozen Information-Technology Research Goals</title><categories>cs.GL</categories><comments>MS word original:
  http://research.microsoft.com/~gray/papers/MS_TR_99_50_TuringTalk.doc</comments><report-no>MS TR 99-50</report-no><acm-class>D.2;H.2;H.3;H.5; I.2</acm-class><abstract>  Charles Babbage's vision of computing has largely been realized. We are on
the verge of realizing Vannevar Bush's Memex. But, we are some distance from
passing the Turing Test. These three visions and their associated problems have
provided long-range research goals for many of us. For example, the scalability
problem has motivated me for several decades. This talk defines a set of
fundamental research problems that broaden the Babbage, Bush, and Turing
visions. They extend Babbage's computational goal to include highly-secure,
highly-available, self-programming, self-managing, and self-replicating
systems. They extend Bush's Memex vision to include a system that automatically
organizes, indexes, digests, evaluates, and summarizes information (as well as
a human might). Another group of problems extends Turing's vision of
intelligent machines to include prosthetic vision, speech, hearing, and other
senses. Each problem is simply stated and each is orthogonal from the others,
though they share some common core technologies
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9911006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9911006</id><created>1999-11-15</created><authors><author><keyname>Murata</keyname><forenames>M.</forenames><affiliation>CRL</affiliation></author><author><keyname>Utiyama</keyname><forenames>M.</forenames><affiliation>CRL</affiliation></author><author><keyname>Isahara</keyname><forenames>H.</forenames><affiliation>CRL</affiliation></author></authors><title>Question Answering System Using Syntactic Information</title><categories>cs.CL</categories><comments>6 pages, 0 figures. Computation and Language</comments><acm-class>H.3.3; I.2.7</acm-class><abstract>  Question answering task is now being done in TREC8 using English documents.
We examined question answering task in Japanese sentences. Our method selects
the answer by matching the question sentence with knowledge-based data written
in natural language. We use syntactic information to obtain highly accurate
answers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9911007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9911007</id><created>1999-11-15</created><authors><author><keyname>Beygelzimer</keyname><forenames>A.</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>L. A.</forenames></author><author><keyname>Homan</keyname><forenames>C. M.</forenames></author><author><keyname>Rothe</keyname><forenames>J.</forenames></author></authors><title>One-Way Functions in Worst-Case Cryptography: Algebraic and Security
  Properties</title><categories>cs.CC cs.CR</categories><comments>17 pages</comments><report-no>University of Rochester Technical Report UR-CS TR 722</report-no><acm-class>F.1.3; E.3</acm-class><abstract>  We survey recent developments in the study of (worst-case) one-way functions
having strong algebraic and security properties. According to [RS93], this line
of research was initiated in 1984 by Rivest and Sherman who designed two-party
secret-key agreement protocols that use strongly noninvertible, total,
associative one-way functions as their key building blocks. If commutativity is
added as an ingredient, these protocols can be used by more than two parties,
as noted by Rabi and Sherman [RS93] who also developed digital signature
protocols that are based on such enhanced one-way functions.
  Until recently, it was an open question whether one-way functions having the
algebraic and security properties that these protocols require could be created
from any given one-way function. Recently, Hemaspaandra and Rothe [HR99]
resolved this open issue in the affirmative, by showing that one-way functions
exist if and only if strong, total, commutative, associative one-way functions
exist.
  We discuss this result, and the work of Rabi, Rivest, and Sherman, and recent
work of Homan [Hom99] that makes progress on related issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9911008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9911008</id><created>1999-11-16</created><authors><author><keyname>Watrous</keyname><forenames>John</forenames><affiliation>University of Calgary</affiliation></author></authors><title>On quantum and classical space-bounded processes with algebraic
  transition amplitudes</title><categories>cs.CC quant-ph</categories><comments>18 pages. Appears in FOCS '99</comments><acm-class>F.1.2; F.1.3</acm-class><abstract>  We define a class of stochastic processes based on evolutions and
measurements of quantum systems, and consider the complexity of predicting
their long-term behavior. It is shown that a very general class of decision
problems regarding these stochastic processes can be efficiently solved
classically in the space-bounded case. The following corollaries are implied by
our main result: (1) Any space O(s) uniform family of quantum circuits acting
on s qubits and consisting of unitary gates and measurement gates defined in a
typical way by matrices of algebraic numbers can be simulated by an unbounded
error space O(s) ordinary (i.e., fair-coin flipping) probabilistic Turing
machine, and hence by space O(s) uniform classical (deterministic) circuits of
depth O(s^2) and size 2^(O(s)). The quantum circuits are not required to
operate with bounded error and may have depth exponential in s. (2) Any
(unbounded error) quantum Turing machine running in space s, having arbitrary
algebraic transition amplitudes, allowing unrestricted measurements during its
computation, and having no restrictions on running time can be simulated by an
unbounded error space O(s) ordinary probabilistic Turing machine, and hence
deterministically in space O(s^2).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9911009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9911009</id><created>1999-11-16</created><authors><author><keyname>Ambainis</keyname><forenames>Andris</forenames><affiliation>UC Berkeley</affiliation></author><author><keyname>Watrous</keyname><forenames>John</forenames><affiliation>University of Calgary</affiliation></author></authors><title>Two-way finite automata with quantum and classical states</title><categories>cs.CC quant-ph</categories><comments>11 pages</comments><acm-class>F.1.1</acm-class><abstract>  We introduce 2-way finite automata with quantum and classical states
(2qcfa's). This is a variant on the 2-way quantum finite automata (2qfa) model
which may be simpler to implement than unrestricted 2qfa's; the internal state
of a 2qcfa may include a quantum part that may be in a (mixed) quantum state,
but the tape head position is required to be classical.
  We show two languages for which 2qcfa's are better than classical 2-way
automata. First, 2qcfa's can recognize palindromes, a language that cannot be
recognized by 2-way deterministic or probabilistic finite automata. Second, in
polynomial time 2qcfa's can recognize {a^n b^n | n&gt;=0}, a language that can be
recognized classically by a 2-way probabilistic automaton but only in
exponential time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9911010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9911010</id><created>1999-11-17</created><authors><author><keyname>O'Donnell</keyname><forenames>Michael J.</forenames></author></authors><title>The Sources of Certainty in Computation and Formal Systems</title><categories>cs.OH</categories><comments>33 pages, 8 figures, presented at the conference, Computer Science as
  a Human Science, the 1999-2000 Sawyer Seminar at the University of Chicago</comments><acm-class>F.4.0</acm-class><abstract>  In his Discourse on the Method of Rightly Conducting the Reason, and Seeking
Truth in the Sciences, Rene Descartes sought ``clear and certain knowledge of
all that is useful in life.'' Almost three centuries later, in ``The
foundations of mathematics,'' David Hilbert tried to ``recast mathematical
definitions and inferences in such a way that they are unshakable.'' Hilbert's
program relied explicitly on formal systems (equivalently, computational
systems) to provide certainty in mathematics. The concepts of computation and
formal system were not defined in his time, but Descartes' method may be
understood as seeking certainty in essentially the same way.
  In this article, I explain formal systems as concrete artifacts, and
investigate the way in which they provide a high level of certainty---arguably
the highest level achievable by rational discourse. The rich understanding of
formal systems achieved by mathematical logic and computer science in this
century illuminates the nature of programs, such as Descartes' and Hilbert's,
that seek certainty through rigorous analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9911011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9911011</id><created>1999-11-19</created><authors><author><keyname>Walther</keyname><forenames>Markus</forenames><affiliation>University of Marburg</affiliation></author></authors><title>One-Level Prosodic Morphology</title><categories>cs.CL</categories><comments>64 pages, A4 size, LaTeX2e, 16 PostScript figures</comments><acm-class>I.2.7</acm-class><abstract>  Recent developments in theoretical linguistics have lead to a widespread
acceptance of constraint-based analyses of prosodic morphology phenomena such
as truncation, infixation, floating morphemes and reduplication. Of these,
reduplication is particularly challenging for state-of-the-art computational
morphology, since it involves copying of some part of a phonological string. In
this paper I argue for certain extensions to the one-level model of phonology
and morphology (Bird &amp; Ellison 1994) to cover the computational aspects of
prosodic morphology using finite-state methods. In a nutshell, enriched lexical
representations provide additional automaton arcs to repeat or skip sounds and
also to allow insertion of additional material. A kind of resource
consciousness is introduced to control this additional freedom, distinguishing
between producer and consumer arcs. The non-finite-state copying aspect of
reduplication is mapped to automata intersection, itself a non-finite-state
operation. Bounded local optimization prunes certain automaton arcs that fail
to contribute to linguistic optimisation criteria. The paper then presents
implemented case studies of Ulwa construct state infixation, German
hypocoristic truncation and Tagalog over-applying reduplication that illustrate
the expressive power of this approach, before its merits and limitations are
discussed and possible extensions are sketched. I conclude that the one-level
approach to prosodic morphology presents an attractive way of extending
finite-state techniques to difficult phenomena that hitherto resisted elegant
computational analyses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9911012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9911012</id><created>1999-11-27</created><updated>1999-12-01</updated><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author></authors><title>Cox's Theorem Revisited</title><categories>cs.AI</categories><comments>Changed running head from original submission</comments><acm-class>I.2.3; I.2.7</acm-class><journal-ref>Journal of AI Research, vol. 11, 1999, pp. 429-435</journal-ref><abstract>  The assumptions needed to prove Cox's Theorem are discussed and examined.
Various sets of assumptions under which a Cox-style theorem can be proved are
provided, although all are rather strong and, arguably, not natural.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9911013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9911013</id><created>1999-11-28</created><authors><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author><author><keyname>Group</keyname><forenames>The Smith Problem Solving</forenames></author></authors><title>PushPush is NP-hard in 3D</title><categories>cs.CG cs.DM</categories><comments>10 pages, 7 figures</comments><report-no>Smith Tech. Rep. 064, Nov. 1999</report-no><acm-class>F.2.2</acm-class><abstract>  We prove that a particular pushing-blocks puzzle is intractable in 3D. The
puzzle, inspired by the game PushPush, consists of unit square blocks on an
integer lattice. An agent may push blocks (but never pull them) in attempting
to move between given start and goal positions. In the PushPush version, the
agent can only push one block at a time, and moreover, each block, when pushed,
slides the maximal extent of its free range. We prove this version is NP-hard
in 3D by reduction from SAT. The corresponding problem in 2D remains open.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9911014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9911014</id><created>1999-11-28</created><updated>2005-12-24</updated><authors><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author></authors><title>The Complexity of Poor Man's Logic</title><categories>cs.LO cs.CC</categories><comments>Corrected version of the journal version. The changes are in Section
  6, where Theorem 6.3(2) was added to handle two missing cases</comments><acm-class>F.4.1; F.2.2</acm-class><journal-ref>Journal of Logic and Computation, 11(4), 609--622, 2001. Extended
  abstract in STACS 2000</journal-ref><abstract>  Motivated by description logics, we investigate what happens to the
complexity of modal satisfiability problems if we only allow formulas built
from literals, $\wedge$, $\Diamond$, and $\Box$. Previously, the only known
result was that the complexity of the satisfiability problem for K dropped from
PSPACE-complete to coNP-complete (Schmidt-Schauss and Smolka, 1991 and Donini
et al., 1992). In this paper we show that not all modal logics behave like K.
In particular, we show that the complexity of the satisfiability problem with
respect to frames in which each world has at least one successor drops from
PSPACE-complete to P, but that in contrast the satisfiability problem with
respect to the class of frames in which each world has at most two successors
remains PSPACE-complete. As a corollary of the latter result, we also solve the
open problem from Donini et al.'s complexity classification of description
logics (Donini et al., 1997). In the last section, we classify the complexity
of the satisfiability problem for K for all other restrictions on the set of
operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912001</id><created>1999-12-01</created><authors><author><keyname>Istrate</keyname><forenames>Gabriel</forenames></author></authors><title>The phase transition in random Horn satisfiability and its algorithmic
  implications</title><categories>cs.DS cs.CC</categories><comments>26 pages. Journal version of papers in AIM'98, SODA'99. Submitted to
  Random Structures and Algorithms</comments><acm-class>F.2.2;I.1.2;G.3</acm-class><abstract>  Let c&gt;0 be a constant, and $\Phi$ be a random Horn formula with n variables
and $m=c\cdot 2^{n}$ clauses, chosen uniformly at random (with repetition) from
the set of all nonempty Horn clauses in the given variables. By analyzing \PUR,
a natural implementation of positive unit resolution, we show that
$\lim_{n\goesto \infty} \PR ({$\Phi$ is satisfiable})= 1-F(e^{-c})$, where
$F(x)=(1-x)(1-x^2)(1-x^4)(1-x^8)... $. Our method also yields as a byproduct an
average-case analysis of this algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912002</id><created>1999-12-05</created><authors><author><keyname>Kim</keyname><forenames>Myung Ho</forenames></author></authors><title>A Geometric Model for Information Retrieval Systems</title><categories>cs.IR cs.CC cs.DL</categories><comments>13 pages</comments><acm-class>H.1.1</acm-class><abstract>  This decade has seen a great deal of progress in the development of
information retrieval systems. Unfortunately, we still lack a systematic
understanding of the behavior of the systems and their relationship with
documents. In this paper we present a completely new approach towards the
understanding of the information retrieval systems. Recently, it has been
observed that retrieval systems in TREC 6 show some remarkable patterns in
retrieving relevant documents. Based on the TREC 6 observations, we introduce a
geometric linear model of information retrieval systems. We then apply the
model to predict the number of relevant documents by the retrieval systems. The
model is also scalable to a much larger data set. Although the model is
developed based on the TREC 6 routing test data, I believe it can be readily
applicable to other information retrieval systems. In Appendix, we explained a
simple and efficient way of making a better system from the existing systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912003</id><created>1999-12-12</created><authors><author><keyname>Murata</keyname><forenames>M.</forenames><affiliation>CRL</affiliation></author><author><keyname>Isahara</keyname><forenames>H.</forenames><affiliation>CRL</affiliation></author><author><keyname>Nagao</keyname><forenames>M.</forenames><affiliation>Kyoto University</affiliation></author></authors><title>Resolution of Indirect Anaphora in Japanese Sentences Using Examples 'X
  no Y (Y of X)'</title><categories>cs.CL</categories><comments>8 pages, 0 figures. Computation and Language</comments><acm-class>I.2.7</acm-class><journal-ref>ACL'99 Workshop on 'Coreference and Its Applications', Maryland,
  USA, June 22, 1999</journal-ref><abstract>  A noun phrase can indirectly refer to an entity that has already been
mentioned. For example, ``I went into an old house last night. The roof was
leaking badly and ...'' indicates that ``the roof'' is associated with `` an
old house}'', which was mentioned in the previous sentence. This kind of
reference (indirect anaphora) has not been studied well in natural language
processing, but is important for coherence resolution, language understanding,
and machine translation. In order to analyze indirect anaphora, we need a case
frame dictionary for nouns that contains knowledge of the relationships between
two nouns but no such dictionary presently exists. Therefore, we are forced to
use examples of ``X no Y'' (Y of X) and a verb case frame dictionary instead.
We tried estimating indirect anaphora using this information and obtained a
recall rate of 63% and a precision rate of 68% on test sentences. This
indicates that the information of ``X no Y'' is useful to a certain extent when
we cannot make use of a noun case frame dictionary. We estimated the results
that would be given by a noun case frame dictionary, and obtained recall and
precision rates of 71% and 82% respectively. Finally, we proposed a way to
construct a noun case frame dictionary by using examples of ``X no Y.''
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912004</id><created>1999-12-12</created><authors><author><keyname>Murata</keyname><forenames>M.</forenames><affiliation>CRL</affiliation></author><author><keyname>Isahara</keyname><forenames>H.</forenames><affiliation>CRL</affiliation></author><author><keyname>Nagao</keyname><forenames>M.</forenames><affiliation>Kyoto University</affiliation></author></authors><title>Pronoun Resolution in Japanese Sentences Using Surface Expressions and
  Examples</title><categories>cs.CL</categories><comments>8 pages, 0 figures. Computation and Language</comments><acm-class>I.2.7</acm-class><journal-ref>ACL'99 Workshop on 'Coreference and Its Applications', Maryland,
  USA, June 22, 1999</journal-ref><abstract>  In this paper, we present a method of estimating referents of demonstrative
pronouns, personal pronouns, and zero pronouns in Japanese sentences using
examples, surface expressions, topics and foci. Unlike conventional work which
was semantic markers for semantic constraints, we used examples for semantic
constraints and showed in our experiments that examples are as useful as
semantic markers. We also propose many new methods for estimating referents of
pronouns. For example, we use the form ``X of Y'' for estimating referents of
demonstrative adjectives. In addition to our new methods, we used many
conventional methods. As a result, experiments using these methods obtained a
precision rate of 87% in estimating referents of demonstrative pronouns,
personal pronouns, and zero pronouns for training sentences, and obtained a
precision rate of 78% for test sentences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912005</id><created>1999-12-13</created><authors><author><keyname>Murata</keyname><forenames>M.</forenames><affiliation>CRL</affiliation></author><author><keyname>Nagao</keyname><forenames>M.</forenames><affiliation>Kyoto University</affiliation></author></authors><title>An Estimate of Referent of Noun Phrases in Japanese Sentences</title><categories>cs.CL</categories><comments>5 pages, 0 figures. Computation and Language</comments><acm-class>I.2.7</acm-class><journal-ref>Coling-ACL '98, Montrial, Canada, August 10, 1998 p912-916</journal-ref><abstract>  In machine translation and man-machine dialogue, it is important to clarify
referents of noun phrases. We present a method for determining the referents of
noun phrases in Japanese sentences by using the referential properties,
modifiers, and possessors of noun phrases. Since the Japanese language has no
articles, it is difficult to decide whether a noun phrase has an antecedent or
not. We had previously estimated the referential properties of noun phrases
that correspond to articles by using clue words in the sentences. By using
these referential properties, our system determined the referents of noun
phrases in Japanese sentences. Furthermore we used the modifiers and possessors
of noun phrases in determining the referents of noun phrases. As a result, on
training sentences we obtained a precision rate of 82% and a recall rate of 85%
in the determination of the referents of noun phrases that have antecedents. On
test sentences, we obtained a precision rate of 79% and a recall rate of 77%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912006</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912006</id><created>1999-12-13</created><authors><author><keyname>Murata</keyname><forenames>M.</forenames><affiliation>Kyoto University</affiliation></author><author><keyname>Nagao</keyname><forenames>M.</forenames><affiliation>Kyoto University</affiliation></author></authors><title>Resolution of Verb Ellipsis in Japanese Sentence using Surface
  Expressions and Examples</title><categories>cs.CL</categories><comments>6 pages, 0 figures. Computation and Language</comments><acm-class>I.2.7</acm-class><journal-ref>Natural Language Processing Pacific Rim Symposium 1997 (NLPRS'97),
  Cape Panwa Hotel, Phuket, Thailand, December 2-4, 1997 p75-80</journal-ref><abstract>  Verbs are sometimes omitted in Japanese sentences. It is necessary to recover
omitted verbs for purposes of language understanding, machine translation, and
conversational processing. This paper describes a practical way to recover
omitted verbs by using surface expressions and examples. We experimented the
resolution of verb ellipses by using this information, and obtained a recall
rate of 73% and a precision rate of 66% on test sentences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912007</id><created>1999-12-13</created><authors><author><keyname>Murata</keyname><forenames>M.</forenames><affiliation>CRL</affiliation></author><author><keyname>Ma</keyname><forenames>Q.</forenames><affiliation>CRL</affiliation></author><author><keyname>Uchimoto</keyname><forenames>K.</forenames><affiliation>CRL</affiliation></author><author><keyname>Isahara</keyname><forenames>H.</forenames><affiliation>CRL</affiliation></author></authors><title>An Example-Based Approach to Japanese-to-English Translation of Tense,
  Aspect, and Modality</title><categories>cs.CL</categories><comments>11 pages, 0 figures. Computation and Language</comments><acm-class>I.2.7</acm-class><journal-ref>TMI'99, Chester, UK, August 23, 1999</journal-ref><abstract>  We have developed a new method for Japanese-to-English translation of tense,
aspect, and modality that uses an example-based method. In this method the
similarity between input and example sentences is defined as the degree of
semantic matching between the expressions at the ends of the sentences. Our
method also uses the k-nearest neighbor method in order to exclude the effects
of noise; for example, wrongly tagged data in the bilingual corpora.
Experiments show that our method can translate tenses, aspects, and modalities
more accurately than the top-level MT software currently available on the
market can. Moreover, it does not require hand-craft rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912008</id><created>1999-12-13</created><updated>2001-01-26</updated><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>New Error Bounds for Solomonoff Prediction</title><categories>cs.AI cs.LG</categories><comments>13 pages, Journal of Computer and System Science, minor changes to
  1st version</comments><report-no>IDSIA-11-00</report-no><acm-class>I.2.6; F.1.3; E.4; F.2</acm-class><journal-ref>J. Computer and System Science 62:4 (2001) 653-667</journal-ref><abstract>  Solomonoff sequence prediction is a scheme to predict digits of binary
strings without knowing the underlying probability distribution. We call a
prediction scheme informed when it knows the true probability distribution of
the sequence. Several new relations between universal Solomonoff sequence
prediction and informed prediction and general probabilistic prediction schemes
will be proved. Among others, they show that the number of errors in Solomonoff
prediction is finite for computable distributions, if finite in the informed
case. Deterministic variants will also be studied. The most interesting result
is that the deterministic variant of Solomonoff prediction is optimal compared
to any other probabilistic or deterministic prediction scheme apart from
additive square root corrections only. This makes it well suited even for
difficult prediction problems, where it does not suffice when the number of
errors is minimal to within some factor greater than one. Solomonoff's original
bound and the ones presented here complement each other in a useful way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912009</id><created>1999-12-15</created><authors><author><keyname>Hess</keyname><forenames>Michael</forenames></author></authors><title>Deduction over Mixed-Level Logic Representations for Text Passage
  Retrieval</title><categories>cs.CL</categories><comments>8 pages, Proceedings of the Eighth International Conference on Tools
  with Artificial Intelligence (TAI'96), Los Alamitos CA</comments><acm-class>H.3.1; I.2.3; I.2.7</acm-class><journal-ref>IEEE Computer Society Press, 1996. 383-390</journal-ref><abstract>  A system is described that uses a mixed-level representation of (part of)
meaning of natural language documents (based on standard Horn Clause Logic) and
a variable-depth search strategy that distinguishes between the different
levels of abstraction in the knowledge representation to locate specific
passages in the documents. Mixed-level representations as well as
variable-depth search strategies are applicable in fields outside that of NLP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912010</id><created>1999-12-17</created><authors><author><keyname>Devlin</keyname><forenames>Bill</forenames></author><author><keyname>Gray</keyname><forenames>Jim</forenames></author><author><keyname>Laing</keyname><forenames>Bill</forenames></author><author><keyname>Spix</keyname><forenames>George</forenames></author></authors><title>Scalability Terminology: Farms, Clones, Partitions, Packs, RACS and RAPS</title><categories>cs.AR cs.DC</categories><comments>MSword version of file at
  http://research.microsoft.com/~gray/papers/MS_TR_99_85_Scalability_Terminolog
  y.doc</comments><report-no>MS TR 99 85</report-no><acm-class>C.0</acm-class><abstract>  Defines a vocabulary for scaleable systems: Geoplexes, Farms, Clones, RACS,
RAPS, clones, partitions, and packs and dicusses the design tradeoffs of using
clones, partitons, and packs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912011</id><created>1999-12-20</created><authors><author><keyname>Wolpert</keyname><forenames>David H.</forenames></author><author><keyname>Kirshner</keyname><forenames>Sergey</forenames></author><author><keyname>Merz</keyname><forenames>Chris J.</forenames></author><author><keyname>Tumer</keyname><forenames>Kagan</forenames></author></authors><title>Adaptivity in Agent-Based Routing for Data Networks</title><categories>cs.MA adap-org cs.NI nlin.AO</categories><report-no>NASA-ARC-IC-99-122</report-no><acm-class>I.2.11 ; C.2.0</acm-class><abstract>  Adaptivity, both of the individual agents and of the interaction structure
among the agents, seems indispensable for scaling up multi-agent systems
(MAS's) in noisy environments. One important consideration in designing
adaptive agents is choosing their action spaces to be as amenable as possible
to machine learning techniques, especially to reinforcement learning (RL)
techniques. One important way to have the interaction structure connecting
agents itself be adaptive is to have the intentions and/or actions of the
agents be in the input spaces of the other agents, much as in Stackelberg
games. We consider both kinds of adaptivity in the design of a MAS to control
network packet routing.
  We demonstrate on the OPNET event-driven network simulator the perhaps
surprising fact that simply changing the action space of the agents to be
better suited to RL can result in very large improvements in their potential
performance: at their best settings, our learning-amenable router agents
achieve throughputs up to three and one half times better than that of the
standard Bellman-Ford routing algorithm, even when the Bellman-Ford protocol
traffic is maintained. We then demonstrate that much of that potential
improvement can be realized by having the agents learn their settings when the
agent interaction structure is itself adaptive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912012</id><created>1999-12-20</created><authors><author><keyname>Tumer</keyname><forenames>Kagan</forenames></author><author><keyname>Wolpert</keyname><forenames>David H.</forenames></author></authors><title>Avoiding Braess' Paradox through Collective Intelligence</title><categories>cs.DC adap-org cs.MA cs.NI nlin.AO</categories><comments>28 pages</comments><report-no>NASA-ARC-IC-99-124</report-no><acm-class>C.2.0; I.2.11</acm-class><abstract>  In an Ideal Shortest Path Algorithm (ISPA), at each moment each router in a
network sends all of its traffic down the path that will incur the lowest cost
to that traffic. In the limit of an infinitesimally small amount of traffic for
a particular router, its routing that traffic via an ISPA is optimal, as far as
cost incurred by that traffic is concerned. We demonstrate though that in many
cases, due to the side-effects of one router's actions on another routers
performance, having routers use ISPA's is suboptimal as far as global aggregate
cost is concerned, even when only used to route infinitesimally small amounts
of traffic. As a particular example of this we present an instance of Braess'
paradox for ISPA's, in which adding new links to a network decreases overall
throughput. We also demonstrate that load-balancing, in which the routing
decisions are made to optimize the global cost incurred by all traffic
currently being routed, is suboptimal as far as global cost averaged across
time is concerned. This is also due to &quot;side-effects&quot;, in this case of current
routing decision on future traffic.
  The theory of COllective INtelligence (COIN) is concerned precisely with the
issue of avoiding such deleterious side-effects. We present key concepts from
that theory and use them to derive an idealized algorithm whose performance is
better than that of the ISPA, even in the infinitesimal limit. We present
experiments verifying this, and also showing that a machine-learning-based
version of this COIN algorithm in which costs are only imprecisely estimated (a
version potentially applicable in the real world) also outperforms the ISPA,
despite having access to less information than does the ISPA. In particular,
this COIN algorithm avoids Braess' paradox.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912013</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912013</id><created>1999-12-20</created><authors><author><keyname>Bern</keyname><forenames>Marshall</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Multivariate Regression Depth</title><categories>cs.CG math.CO</categories><comments>12 pages, 3 figures</comments><acm-class>G.3</acm-class><journal-ref>Discrete Comput. Geom. 28(1):1-17, July 2002</journal-ref><doi>10.1007/s00454-001-0092-1</doi><abstract>  The regression depth of a hyperplane with respect to a set of n points in R^d
is the minimum number of points the hyperplane must pass through in a rotation
to vertical. We generalize hyperplane regression depth to k-flats for any k
between 0 and d-1. The k=0 case gives the classical notion of center points. We
prove that for any k and d, deep k-flats exist, that is, for any set of n
points there always exists a k-flat with depth at least a constant fraction of
n. As a consequence, we derive a linear-time (1+epsilon)-approximation
algorithm for the deepest flat.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912014</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912014</id><created>1999-12-21</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Fast Hierarchical Clustering and Other Applications of Dynamic Closest
  Pairs</title><categories>cs.DS</categories><comments>20 pages, 9 figures. A preliminary version of this paper appeared at
  the 9th ACM-SIAM Symp. on Discrete Algorithms, San Francisco, 1998, pp.
  619-628. For source code and experimental results, see
  http://www.ics.uci.edu/~eppstein/projects/pairs/</comments><acm-class>F.2.2</acm-class><journal-ref>J. Experimental Algorithmics 5(1):1-23, 2000</journal-ref><doi>10.1145/351827.351829</doi><abstract>  We develop data structures for dynamic closest pair problems with arbitrary
distance functions, that do not necessarily come from any geometric structure
on the objects. Based on a technique previously used by the author for
Euclidean closest pairs, we show how to insert and delete objects from an
n-object set, maintaining the closest pair, in O(n log^2 n) time per update and
O(n) space. With quadratic space, we can instead use a quadtree-like structure
to achieve an optimal time bound, O(n) per update. We apply these data
structures to hierarchical clustering, greedy matching, and TSP heuristics, and
discuss other potential applications in machine learning, Groebner bases, and
local improvement algorithms for partition and placement problems. Experiments
show our new methods to be faster in practice than previously used heuristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912015</id><created>1999-12-22</created><authors><author><keyname>Bonifati</keyname><forenames>Angela</forenames></author><author><keyname>Ceri</keyname><forenames>Stefano</forenames></author></authors><title>Comparative Analysis of Five XML Query Languages</title><categories>cs.DB</categories><comments>TeX v3.1415, 17 pages, 6 figures, to be published in ACM Sigmod
  Record, March 2000</comments><report-no>Dipartimento di Elettronica e Informazione, Politecnico di Milano
  (Italy) Technical Report nr.99-76</report-no><acm-class>H.2; H.2.3; I.7; I.7.1; I.7.2</acm-class><abstract>  XML is becoming the most relevant new standard for data representation and
exchange on the WWW. Novel languages for extracting and restructuring the XML
content have been proposed, some in the tradition of database query languages
(i.e. SQL, OQL), others more closely inspired by XML. No standard for XML query
language has yet been decided, but the discussion is ongoing within the World
Wide Web Consortium and within many academic institutions and Internet-related
major companies. We present a comparison of five, representative query
languages for XML, highlighting their common features and differences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912016</id><created>1999-12-22</created><authors><author><keyname>Kim</keyname><forenames>Jin-Dong</forenames></author><author><keyname>Lee</keyname><forenames>Sang-Zoo</forenames></author><author><keyname>Rim</keyname><forenames>Hae-Chang</forenames></author></authors><title>HMM Specialization with Selective Lexicalization</title><categories>cs.CL cs.LG</categories><comments>7 pages, 6 figures</comments><acm-class>I.2.6; I.2.7</acm-class><journal-ref>Proceedings of the 1999 Joint SIGDAT Conference on Empirical
  Methods in Natural Language Processing and Very Large Corpora, pp.121-127,
  1999</journal-ref><abstract>  We present a technique which complements Hidden Markov Models by
incorporating some lexicalized states representing syntactically uncommon
words. Our approach examines the distribution of transitions, selects the
uncommon words, and makes lexicalized states for the words. We performed a
part-of-speech tagging experiment on the Brown corpus to evaluate the resultant
language model and discovered that this technique improved the tagging accuracy
by 0.21% at the 95% level of confidence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912017</id><created>1999-12-23</created><authors><author><keyname>Hess</keyname><forenames>Michael</forenames></author></authors><title>Mixed-Level Knowledge Representation and Variable-Depth Inference in
  Natural Language Processing</title><categories>cs.CL</categories><comments>29 pages</comments><acm-class>H.3.1; I.2.3; I.2.7</acm-class><journal-ref>International Journal on Artificial Intelligence Tools (IJAIT),
  vol 6, no 4, 1997. 481-509</journal-ref><abstract>  A system is described that uses a mixed-level knowledge representation based
on standard Horn Clause Logic to represent (part of) the meaning of natural
language documents. A variable-depth search strategy is outlined that
distinguishes between the different levels of abstraction in the knowledge
representation to locate specific passages in the documents. A detailed
description of the linguistic aspects of the system is given. Mixed-level
representations as well as variable-depth search strategies are applicable in
fields outside that of NLP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912018</id><created>1999-12-24</created><authors><author><keyname>Pachl</keyname><forenames>Jan</forenames></author><author><keyname>Zaks</keyname><forenames>Shmuel</forenames></author></authors><title>Computation in an algebra of test selection criteria</title><categories>cs.SE</categories><comments>Unpublished paper dated May 12, 1993. 37 pages, LaTeX</comments><acm-class>D.2.5; B.8.1</acm-class><abstract>  One of the key concepts in testing is that of adequate test sets. A test
selection criterion decides which test sets are adequate. In this paper, a
language schema for specifying a large class of test selection criteria is
developed; the schema is based on two operations for building complex criteria
from simple ones. Basic algebraic properties of the two operations are derived.
  In the second part of the paper, a simple language-an instance of the
general schema-is studied in detail, with the goal of generating small
adequate test sets automatically. It is shown that one version of the problem
is intractable, while another is solvable by an efficient algorithm. An
implementation of the algorithm is described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912019</id><created>1999-12-27</created><updated>2000-01-09</updated><authors><author><keyname>Mayers</keyname><forenames>Dominic</forenames></author></authors><title>Quantum Bit Commitment Expansion</title><categories>cs.CR</categories><comments>The paper was retracted</comments><acm-class>H.1.1</acm-class><abstract>  The paper was retracted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912020</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912020</id><created>1999-12-30</created><updated>2002-05-24</updated><authors><author><keyname>Hegland</keyname><forenames>Markus</forenames></author><author><keyname>Pestov</keyname><forenames>Vladimir</forenames></author></authors><title>Additive models in high dimensions</title><categories>cs.DS</categories><comments>LaTeX 2e document, 21 pages, 5 figures</comments><acm-class>H.2.8</acm-class><journal-ref>Proc. of 12th Computational Techniques and Applications
  Conference, CTAC-2004 (Rob May and A.J. Roberts, eds.), ANZIAM J. 46 (2005),
  C1205-C1221.</journal-ref><abstract>  We discuss some aspects of approximating functions on high-dimensional data
sets with additive functions or ANOVA decompositions, that is, sums of
functions depending on fewer variables each. It is seen that under appropriate
smoothness conditions, the errors of the ANOVA decompositions are of order
$O(n^{m/2})$ for approximations using sums of functions of up to $m$ variables
under some mild restrictions on the (possibly dependent) predictor variables.
Several simulated examples illustrate this behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/9912021</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/9912021</id><created>1999-12-31</created><updated>2000-06-11</updated><authors><author><keyname>Gunther</keyname><forenames>Neil J.</forenames></author></authors><title>Seeing the Forest in the Tree: Applying VRML to Mathematical Problems in
  Number Theory</title><categories>cs.MS cs.CE</categories><comments>12 pages. Published in Proc. IEEE-SPIE 2000 12th International
  Symposium on Internet Imaging. Condensed online abstract. Extended discusson
  in sections 3.1 and 3.2; edited section 5; edited references</comments><acm-class>G.2.2;G.4;H.5.1;I.3.2;I.3.7;I.6.8;I.7.2;J.2;K.3.1</acm-class><journal-ref>Proc. IEEE-SPIE 2000 12th International Symposium on Internet
  Imaging</journal-ref><doi>10.1117/12.373461</doi><abstract>  We show how VRML (Virtual Reality Modeling Language) can provide potentially
powerful insight into the 3x + 1 problem via the introduction of a unique
geometrical object, called the 'G-cell', akin to a fractal generator. We
present an example of a VRML world developed programmatically with the G-cell.
The role of VRML as a tool for furthering the understanding the 3x+1 problem is
potentially significant for several reasons: a) VRML permits the observer to
zoom into the geometric structure at all scales (up to limitations of the
computing platform). b) VRML enables rotation to alter comparative visual
perspective (similar to Tukey's data-spinning concept). c) VRML facilitates the
demonstration of interesting tree features between collaborators on the
internet who might otherwise have difficulty conveying their ideas
unambiguously. d) VRML promises to reveal any dimensional dependencies among
3x+1 sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:gr-qc/0209061</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>gr-qc/0209061</id><created>2002-09-18</created><authors><author><keyname>Brun</keyname><forenames>Todd A.</forenames><affiliation>Institute for Advanced Study</affiliation></author></authors><title>Computers with closed timelike curves can solve hard problems</title><categories>gr-qc cs.CC quant-ph</categories><comments>9 pages LaTeX; submitted to Foundations of Physics Letters</comments><journal-ref>Found.Phys.Lett. 16 (2003) 245-253</journal-ref><abstract>  A computer which has access to a closed timelike curve, and can thereby send
the results of calculations into its own past, can exploit this to solve
difficult computational problems efficiently. I give a specific demonstration
of this for the problem of factoring large numbers, and argue that a similar
approach can solve NP-complete and PSPACE-complete problems. I discuss the
potential impact of quantum effects on this result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:gr-qc/0209096</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>gr-qc/0209096</id><created>2002-09-25</created><updated>2002-09-30</updated><authors><author><keyname>Vulcanov</keyname><forenames>D. N.</forenames><affiliation>Max-Planck-Institut fur Gravitationsphysik, Albert-Einstein-Institut, Golm, Germany</affiliation></author></authors><title>Gravity, torsion, Dirac field and computer algebra using MAPLE and
  REDUCE</title><categories>gr-qc cs.SC hep-th physics.comp-ph</categories><comments>20 pages, Latex</comments><abstract>  The article presents computer algebra procedures and routines applied to the
study of the Dirac field on curved spacetimes. The main part of the procedures
is devoted to the construction of Pauli and Dirac matrices algebra on an
anholonomic orthonormal reference frame. Then these procedures are used to
compute the Dirac equation on curved spacetimes in a sequence of special
dedicated routines. A comparative review of such procedures obtained for two
computer algebra platforms (REDUCE + EXCALC and MAPLE + GRTensorII) is carried
out. Applications for the calculus of Dirac equation on specific examples of
spacetimes with or without torsion are pointed out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:hep-lat/0003009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>hep-lat/0003009</id><created>2000-03-14</created><authors><author><keyname>McNeile</keyname><forenames>Craig</forenames></author></authors><title>Data storage issues in lattice QCD calculations</title><categories>hep-lat cs.DB</categories><comments>Invited talk at: Workshop on Advanced Data Storage / Management
  Techniques for HPC, 23rd - 25th February 2000, Daresbury Laboratory,
  Warrington, UK. 10 pages html</comments><abstract>  I describe some of the data management issues in lattice Quantum
Chromodynamics calculations. I focus on the experience of the UKQCD
collaboration. I describe an attempt to use a relational database to store part
of the data produced by a lattice QCD calculation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:hep-lat/0004007</identifier>
 <datestamp>2009-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>hep-lat/0004007</id><created>2000-04-11</created><updated>2001-08-14</updated><authors><author><keyname>Di Pierro</keyname><forenames>Massimo</forenames></author></authors><title>Matrix Distributed Processing: A set of C++ Tools for implementing
  generic lattice computations on parallel systems</title><categories>hep-lat cs.DC cs.MS physics.comp-ph</categories><comments>Minor esthetical modifications from previous versions</comments><report-no>FERMILAB-PUB-00-079-T</report-no><journal-ref>Comput.Phys.Commun. 141 (2001) 98-148</journal-ref><doi>10.1016/S0010-4655(01)00297-1</doi><abstract>  We present a set of programming tools (classes and functions written in C++
and based on Message Passing Interface) for fast development of generic
parallel (and non-parallel) lattice simulations. They are collectively called
MDP 1.2.
  These programming tools include classes and algorithms for matrices, random
number generators, distributed lattices (with arbitrary topology), fields and
parallel iterations. No previous knowledge of MPI is required in order to use
them.
  Some applications in electromagnetism, electronics, condensed matter and
lattice QCD are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:hep-lat/0307015</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>hep-lat/0307015</id><created>2003-07-09</created><updated>2003-07-10</updated><authors><author><keyname>Sroczynski</keyname><forenames>Z.</forenames></author><author><keyname>Eicker</keyname><forenames>N.</forenames></author><author><keyname>Lippert</keyname><forenames>Th.</forenames></author><author><keyname>Orth</keyname><forenames>B.</forenames></author><author><keyname>Schilling</keyname><forenames>K.</forenames></author></authors><title>On the scaling of computational particle physics codes on cluster
  computers</title><categories>hep-lat cs.DC</categories><comments>26pp. LaTeX2e using package graphicx. 16 PostScript figures</comments><report-no>LTH 583</report-no><abstract>  Many appplications in computational science are sufficiently
compute-intensive that they depend on the power of parallel computing for
viability. For all but the &quot;embarrassingly parallel&quot; problems, the performance
depends upon the level of granularity that can be achieved on the computer
platform.
  Our computational particle physics applications require machines that can
support a wide range of granularities, but in general, compute-intensive
state-of-the-art projects will require finely grained distributions. Of the
different types of machines available for the task, we consider cluster
computers.
  The use of clusters of commodity computers in high performance computing has
many advantages including the raw price/performance ratio and the flexibility
of machine configuration and upgrade. Here we focus on what is usually
considered the weak point of cluster technology; the scaling behaviour when
faced with a numerically intensive parallel computation. To this end we examine
the scaling of our own applications from numerical quantum field theory on a
cluster and infer conclusions about the more general case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:hep-lat/0308005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>hep-lat/0308005</id><created>2003-08-08</created><authors><author><keyname>Cucchieri</keyname><forenames>Attilio</forenames></author><author><keyname>Mendes</keyname><forenames>Tereza</forenames></author><author><keyname>Travieso</keyname><forenames>Gonzalo</forenames></author><author><keyname>Taurines</keyname><forenames>Andre R.</forenames></author></authors><title>Parallel implementation of a lattice-gauge-theory code: studying quark
  confinement on PC clusters</title><categories>hep-lat cs.DC</categories><comments>9 pages with 1 figures and 5 tables; using LaTeX2e class file ieee;
  accepted for presentation at the 15th Symposium on Computer Architecture and
  High Performance Computing (Sao Paulo, 10--12 November 2003)</comments><abstract>  We consider the implementation of a parallel Monte Carlo code for
high-performance simulations on PC clusters with MPI. We carry out tests of
speedup and efficiency. The code is used for numerical simulations of pure
SU(2) lattice gauge theory at very large lattice volumes, in order to study the
infrared behavior of gluon and ghost propagators. This problem is directly
related to the confinement of quarks and gluons in the physics of strong
interactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:hep-lat/0505005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>hep-lat/0505005</id><created>2005-05-09</created><authors><author><keyname>Di Pierro</keyname><forenames>Massimo</forenames></author></authors><title>Parallel Programming with Matrix Distributed Processing</title><categories>hep-lat cs.CE physics.comp-ph</categories><comments>submitted to HiPC 2005 - download from www.fermiqcd.net</comments><abstract>  Matrix Distributed Processing (MDP) is a C++ library for fast development of
efficient parallel algorithms. It constitues the core of FermiQCD. MDP enables
programmers to focus on algorithms, while parallelization is dealt with
automatically and transparently. Here we present a brief overview of MDP and
examples of applications in Computer Science (Cellular Automata), Engineering
(PDE Solver) and Physics (Ising Model).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:hep-lat/9808001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>hep-lat/9808001</id><created>1998-08-02</created><updated>1998-08-24</updated><authors><author><keyname>Azusa</keyname><forenames>Yamaguchi</forenames></author></authors><title>Genetic Algorithm for SU(N) gauge theory on a lattice</title><categories>hep-lat cs.NE</categories><comments>rev.tex form, 9 pages, 12 figures</comments><report-no>OCHA-PP-122</report-no><abstract>  An Algorithm is proposed for the simulation of pure SU(N) lattice gauge
theories based on Genetic Algorithms(GAs). Main difference between GAs and
Metropolis methods(MPs) is that GAs treat a population of points at once, while
MPs treat only one point in the searching space. This provides GAs with
information about the assortment as well as the fitness of the evolution
function and producting a better solution. We apply GAs to SU(2) pure gauge
theory on a 2 dimensional lattice and show the results are consistent with
those given by MP and Heatbath methods(HBs). Thermalization speed of GAs is
especially faster than the simple MPs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:hep-lat/9809068</identifier>
 <datestamp>2009-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>hep-lat/9809068</id><created>1998-09-11</created><authors><author><keyname>Yamaguchi</keyname><forenames>A.</forenames></author></authors><title>Genetic Algorithm for SU(2) Gauge Theory on a 2-dimensional Lattice</title><categories>hep-lat cs.NE</categories><comments>3 pages,9 figures,LATTICE98(Algorithm), &quot;Genetic Algorithm for SU(N)
  Gauge Theory on a Lattice&quot;</comments><journal-ref>Nucl.Phys.Proc.Suppl. 73 (1999) 847-849</journal-ref><doi>10.1016/S0920-5632(99)85221-9</doi><abstract>  An algorithm is proposed for the simulation of pure SU(N) lattice gauge
theories based on Genetic Algorithms(GAs). We apply GAs to SU(2) pure gauge
theory on a 2 dimensional lattice and show the results, the action per
plaquette and Wilson loops, are consistent with those by Metropolis method(MP)s
and Heatbath method(HB)s. Thermalization speed of GAs is especially faster than
the simple MPs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:hep-ph/0411100</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>hep-ph/0411100</id><created>2004-11-07</created><updated>2005-04-24</updated><authors><author><keyname>Kalmykov</keyname><forenames>M. Yu.</forenames><affiliation>Dubna, JINR</affiliation></author><author><keyname>Sheplyakov</keyname><forenames>A.</forenames><affiliation>Dubna, JINR</affiliation></author></authors><title>LSJK - a C++ library for arbitrary-precision numeric evaluation of
  the generalized log-sine functions</title><categories>hep-ph cs.MS cs.NA math-ph math.MP math.NA</categories><comments>16 pages,LaTeX; to be published in Comp.Phys.Comm. v.2: typos in
  Eq.(3.1) corrected; new section(3.3) added with detailed description of the
  installation instructions</comments><journal-ref>Comput.Phys.Commun. 172 (2005) 45-59</journal-ref><doi>10.1016/j.cpc.2005.04.013</doi><abstract>  Generalized log-sine functions appear in higher order epsilon-expansion of
different Feynman diagrams. We present an algorithm for numerical evaluation of
these functions of real argument. This algorithm is implemented as C++ library
with arbitrary-precision arithmetics for integer 0 &lt; k &lt; 9 and j &gt; 1. Some new
relations and representations for the generalized log-sine functions are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:hep-ph/0702279</identifier>
 <datestamp>2014-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>hep-ph/0702279</id><created>2007-02-27</created><authors><author><keyname>Tentyukov</keyname><forenames>M.</forenames></author><author><keyname>Vermaseren</keyname><forenames>J. A. M.</forenames></author></authors><title>The Multithreaded version of FORM</title><categories>hep-ph cs.SC</categories><comments>18 pages</comments><report-no>NIKHEF 07-005, SFB/CPP-07-08, TTP07-06</report-no><journal-ref>Comput.Phys.Commun.181:1419-1427,2010</journal-ref><doi>10.1016/j.cpc.2010.04.009</doi><abstract>  We present TFORM, the version of the symbolic manipulation system FORM that
can make simultaneous use of several processors in a shared memory
architecture. The implementation uses Posix threads, also called pthreads, and
is therefore easily portable between various operating systems. Most existing
FORM programs will be able to take advantage of the increased processing power,
without the need for modifications. In some cases some minor additions may be
needed. For a computer with two processors a typical improvement factor in the
running time is 1.7 when compared to the traditional version of FORM. In the
case of computers with 4 processors a typical improvement factor in the
execution time is slightly above 3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:hep-th/0201092</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>hep-th/0201092</id><created>2002-01-14</created><authors><author><keyname>Blaha</keyname><forenames>Stephen</forenames></author></authors><title>A Quantum Computer Foundation for the Standard Model and SuperString
  Theories</title><categories>hep-th cs.PL quant-ph</categories><comments>78 pages, PDF</comments><abstract>  We show the Standard Model and SuperString Theories can be naturally based on
a Quantum Computer foundation. The Standard Model of elementary particles can
be viewed as defining a Quantum Computer Grammar and language. A Quantum
Computer in a certain limit naturally forms a Superspace upon which
Supersymmetry rotations can be defined - a Continuum Quantum Computer. Quantum
high-level computer languages such as Quantum C and Quantum Assembly language
are also discussed. In these new linguistic representations, particles become
literally symbols or letters, and particle interactions become grammar rules.
This view is NOT the same as the often-expressed view that Mathematics is the
language of Physics. Some new developments relating to Quantum Computers and
Quantum Turing Machines are also described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:hep-th/0208218</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>hep-th/0208218</id><created>2002-08-29</created><updated>2003-03-26</updated><authors><author><keyname>Fischbacher</keyname><forenames>Thomas</forenames></author></authors><title>Introducing LambdaTensor1.0 - A package for explicit symbolic and
  numeric Lie algebra and Lie group calculations</title><categories>hep-th cs.MS math-ph math.MP</categories><comments>10 pages; the package's homepage is
  http://www.cip.physik.uni-muenchen.de/~tf/lambdatensor/; to be published in
  &quot;Forschung und wissenschaftliches Rechnen - Beitraege zum Heinz-Billing-Preis
  2002&quot;; replacement reflects the corresponding release of version 1.1, which
  is described briefly in an addendum</comments><report-no>AEI-2002-065</report-no><abstract>  Due to the occurrence of large exceptional Lie groups in supergravity,
calculations involving explicit Lie algebra and Lie group element manipulations
easily become very complicated and hence also error-prone if done by hand.
Research on the extremal structure of maximal gauged supergravity theories in
various dimensions sparked the development of a library for efficient abstract
multilinear algebra calculations involving sparse and non-sparse higher-rank
tensors, which is presented here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:hep-th/0305176</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>hep-th/0305176</id><created>2003-05-20</created><authors><author><keyname>Fischbacher</keyname><forenames>Thomas</forenames></author></authors><title>Mapping the vacuum structure of gauged maximal supergravities: an
  application of high-performance symbolic algebra</title><categories>hep-th cs.SC</categories><comments>PhD thesis, 140 pages, 11 figures</comments><report-no>AEI-2003-046</report-no><abstract>  The analysis of the extremal structure of the scalar potentials of gauged
maximally extended supergravity models in five, four, and three dimensions, and
hence the determination of possible vacuum states of these models is a
computationally challenging task due to the occurrence of the exceptional Lie
groups $E_6$, $E_7$, $E_8$ in the definition of these potentials. At present,
the most promising approach to gain information about nontrivial vacua of these
models is to perform a truncation of the potential to submanifolds of the $G/H$
coset manifold of scalars which are invariant under a subgroup of the gauge
group and of sufficiently low dimension to make an analytic treatment possible.
  New tools are presented which allow a systematic and highly effective study
of these potentials up to a previously unreached level of complexity. Explicit
forms of new truncations of the potentials of four- and three-dimensional
models are given, and for N=16, D=3 supergravities, which are much more rich in
structure than their higher-dimensional cousins, a series of new nontrivial
vacua is identified and analysed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:hep-th/0602072</identifier>
 <datestamp>2008-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>hep-th/0602072</id><created>2006-02-07</created><updated>2006-02-16</updated><authors><author><keyname>Denef</keyname><forenames>Frederik</forenames><affiliation>KU Leuven</affiliation></author><author><keyname>Douglas</keyname><forenames>Michael R.</forenames><affiliation>Rutgers and IHES</affiliation></author></authors><title>Computational complexity of the landscape I</title><categories>hep-th cs.CC</categories><comments>JHEP3 Latex, 53 pp, 2 .eps figures</comments><journal-ref>AnnalsPhys.322:1096-1142,2007</journal-ref><doi>10.1016/j.aop.2006.07.013</doi><abstract>  We study the computational complexity of the physical problem of finding
vacua of string theory which agree with data, such as the cosmological
constant, and show that such problems are typically NP hard. In particular, we
prove that in the Bousso-Polchinski model, the problem is NP complete. We
discuss the issues this raises and the possibility that, even if we were to
find compelling evidence that some vacuum of string theory describes our
universe, we might never be able to find that vacuum explicitly.
  In a companion paper, we apply this point of view to the question of how
early cosmology might select a vacuum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:hep-th/0612240</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>hep-th/0612240</id><created>2006-12-21</created><updated>2007-01-09</updated><authors><author><keyname>Kalmykov</keyname><forenames>M. Yu.</forenames><affiliation>Baylor U. &amp; Dubna, JINR</affiliation></author><author><keyname>Ward</keyname><forenames>B. F. L.</forenames><affiliation>Baylor U.</affiliation></author><author><keyname>Yost</keyname><forenames>S.</forenames><affiliation>Baylor U.</affiliation></author></authors><title>All order epsilon-expansion of Gauss hypergeometric functions with
  integer and half/integer values of parameters</title><categories>hep-th cs.SC hep-ph math-ph math.CA math.MP physics.comp-ph</categories><comments>18 pages, JHEP3.cls The code (FORM) is available via the www
  http://theor.jinr.ru/~kalmykov/hypergeom/hyper.html v2: Appendix and a few
  references added</comments><report-no>BU-HEPP-06-12</report-no><journal-ref>JHEP 0702:040,2007</journal-ref><doi>10.1088/1126-6708/2007/02/040</doi><abstract>  It is proved that the Laurent expansion of the following Gauss hypergeometric
functions,
  2F1(I1+a*epsilon, I2+b*ep; I3+c*epsilon;z),
  2F1(I1+a*epsilon, I2+b*epsilon;I3+1/2+c*epsilon;z),
  2F1(I1+1/2+a*epsilon, I2+b*epsilon; I3+c*epsilon;z),
  2F1(I1+1/2+a*epsilon, I2+b*epsilon; I3+1/2+c*epsilon;z),
  2F1(I1+1/2+a*epsilon,I2+1/2+b*epsilon; I3+1/2+c*epsilon;z), where I1,I2,I3
are an arbitrary integer nonnegative numbers, a,b,c are an arbitrary numbers
and epsilon is an arbitrary small parameters, are expressible in terms of the
harmonic polylogarithms of Remiddi and Vermaseren with polynomial coefficients.
An efficient algorithm for the calculation of the higher-order coefficients of
Laurent expansion is constructed. Some particular cases of Gauss hypergeometric
functions are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math-ph/0201011</identifier>
 <datestamp>2008-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math-ph/0201011</id><created>2002-01-04</created><updated>2002-02-25</updated><authors><author><keyname>Weinzierl</keyname><forenames>Stefan</forenames></author></authors><title>Symbolic Expansion of Transcendental Functions</title><categories>math-ph cs.SC hep-ph math.MP</categories><comments>Latex, 16 pages, minor changes</comments><journal-ref>Comput.Phys.Commun.145:357-370,2002</journal-ref><doi>10.1016/S0010-4655(02)00261-8</doi><abstract>  Higher transcendental function occur frequently in the calculation of Feynman
integrals in quantum field theory. Their expansion in a small parameter is a
non-trivial task. We report on a computer program which allows the systematic
expansion of certain classes of functions. The algorithms are based on the Hopf
algebra of nested sums. The program is written in C++ and uses the GiNaC
library.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math-ph/0211067</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math-ph/0211067</id><created>2002-11-27</created><authors><author><keyname>Golubtsov</keyname><forenames>P. V.</forenames></author><author><keyname>Moskaliuk</keyname><forenames>S. S.</forenames></author></authors><title>Method of Additional Structures on the Objects of a Monoidal Kleisli
  Category as a Background for Information Transformers Theory</title><categories>math-ph cs.MA math.CT math.MP</categories><comments>59 pages, Latex, no figures</comments><journal-ref>Hadronic Journal, V.25, No.2,179-238 (2002)</journal-ref><abstract>  Category theory provides a compact method of encoding mathematical structures
in a uniform way, thereby enabling the use of general theorems on, for example,
equivalence and universal constructions. In this article we develop the method
of additional structures on the objects of a monoidal Kleisli category. It is
proposed to consider any uniform class of information transformers (ITs) as a
family of morphisms of a category that satisfy certain set of axioms. This
makes it possible to study in a uniform way different types of ITs, e.g.,
statistical, multivalued, and fuzzy ITs. Proposed axioms define a category of
ITs as a monoidal category that contains a subcategory (of deterministic ITs)
with finite products. Besides, it is shown that many categories of ITs can be
constructed as Kleisli categories with additional structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math-ph/0407056</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math-ph/0407056</id><created>2004-07-23</created><updated>2004-07-28</updated><authors><author><keyname>Loo</keyname><forenames>Ken</forenames></author></authors><title>Internal Turing Machines</title><categories>math-ph cs.CC math.LO math.MP quant-ph</categories><comments>clarified the Halting problem</comments><abstract>  Using nonstandard analysis, we will extend the classical Turing machines into
the internal Turing machines. The internal Turing machines have the capability
to work with infinite ($*$-finite) number of bits while keeping the finite
combinatoric structures of the classical Turing machines. We will show the
following. The internal deterministic Turing machines can do in $*$-polynomial
time what a classical deterministic Turing machine can do in an arbitrary
finite amount of time. Given an element of $&lt;M;x&gt;\in HALT$ (more precisely, the
$*$-embedding of $HALT$), there is an internal deterministic Turing machine
which will take $&lt;M;x&gt;$ as input and halt in the $&quot;yes&quot;$ state. The language
${}^*Halt$ can not be decided by the internal deterministic Turing machines.
The internal deterministic Turing machines can be viewed as the asymptotic
behavior of finite precision approximation to real number computations. It is
possible to use the internal probabilistic Turing machines to simulate finite
state quantum mechanics with infinite precision. This simulation suggests that
no information can be transmitted instantaneously and at the same time, the
Turing machine model can simulate instantaneous collapse of the wave function.
The internal deterministic Turing machines are powerful, but if $P \neq NP$,
then there are internal problems which the internal deterministic Turing
machines can solve but not in $*$-polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math-ph/0504048</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math-ph/0504048</id><created>2005-04-15</created><updated>2005-07-12</updated><authors><author><keyname>Kornyak</keyname><forenames>Vladimir V.</forenames></author></authors><title>On Compatibility of Discrete Relations</title><categories>math-ph cs.SC math.AC math.MP nlin.CG</categories><comments>13 pages; to be published in the CASC-2005 proceedings; conclusions
  added</comments><journal-ref>CASC 2005, LNCS 3718, pp. 272--284, 2005. Springer-Verlag Berlin
  Heidelberg 2005</journal-ref><abstract>  An approach to compatibility analysis of systems of discrete relations is
proposed. Unlike the Groebner basis technique, the proposed scheme is not based
on the polynomial ring structure. It uses more primitive set-theoretic and
topological concepts and constructions. We illustrate the approach by
application to some two-state cellular automata. In the two-state case the
Groebner basis method is also applicable, and we compare both approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math-ph/0508065</identifier>
 <datestamp>2008-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math-ph/0508065</id><created>2005-08-31</created><updated>2006-06-12</updated><authors><author><keyname>Kosovtsov</keyname><forenames>Yuri N.</forenames></author></authors><title>Finding Liouvillian first integrals of rational ODEs of any order in
  finite terms</title><categories>math-ph cs.SC math.CA math.MP nlin.SI</categories><comments>Published in SIGMA (Symmetry, Integrability and Geometry: Methods and
  Applications) at http://www.emis.de/journals/SIGMA/</comments><msc-class>34A05; 34A34; 34A35</msc-class><journal-ref>SIGMA 2 (2006), 059, 8 pages</journal-ref><doi>10.3842/SIGMA.2006.059</doi><abstract>  It is known, due to Mordukhai-Boltovski, Ritt, Prelle, Singer, Christopher
and others, that if a given rational ODE has a Liouvillian first integral then
the corresponding integrating factor of the ODE must be of a very special form
of a product of powers and exponents of irreducible polynomials. These results
lead to a partial algorithm for finding Liouvillian first integrals. However,
there are two main complications on the way to obtaining polynomials in the
integrating factor form. First of all, one has to find an upper bound for the
degrees of the polynomials in the product above, an unsolved problem, and then
the set of coefficients for each of the polynomials by the
computationally-intensive method of undetermined parameters. As a result, this
approach was implemented in CAS only for first and relatively simple second
order ODEs. We propose an algebraic method for finding polynomials of the
integrating factors for rational ODEs of any order, based on examination of the
resultants of the polynomials in the numerator and the denominator of the
right-hand side of such equation. If both the numerator and the denominator of
the right-hand side of such ODE are not constants, the method can determine in
finite terms an explicit expression of an integrating factor if the ODE permits
integrating factors of the above mentioned form and then the Liouvillian first
integral. The tests of this procedure based on the proposed method, implemented
in Maple in the case of rational integrating factors, confirm the consistence
and efficiency of the method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math-ph/0512026</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math-ph/0512026</id><created>2005-12-08</created><authors><author><keyname>Lamahewa</keyname><forenames>Tharaka A.</forenames></author><author><keyname>Kennedy</keyname><forenames>Rodney A.</forenames></author><author><keyname>Abhayapala</keyname><forenames>Thushara D.</forenames></author><author><keyname>Betlehem</keyname><forenames>Terence</forenames></author></authors><title>MIMO Channel Correlation in General Scattering Environments</title><categories>math-ph cs.IT math.IT math.MP</categories><comments>Australian Communication Theory Workshop Proceedings 2006, Perth
  Western Australia. (accepted)</comments><abstract>  This paper presents an analytical model for the fading channel correlation in
general scattering environments. In contrast to the existing correlation
models, our new approach treats the scattering environment as non-separable and
it is modeled using a bi-angular power distribution. The bi-angular power
distribution is parameterized by the mean departure and arrival angles, angular
spreads of the univariate angular power distributions at the transmitter and
receiver apertures, and a third parameter, the covariance between transmit and
receive angles which captures the statistical interdependency between angular
power distributions at the transmitter and receiver apertures. When this third
parameter is zero, this new model reduces to the well known &quot;Kronecker&quot; model.
Using the proposed model, we show that Kronecker model is a good approximation
to the actual channel when the scattering channel consists of a single
scattering cluster. In the presence of multiple remote scattering clusters we
show that Kronecker model over estimates the performance by artificially
increasing the number of multipaths in the channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math-ph/0603068</identifier>
 <datestamp>2009-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math-ph/0603068</id><created>2006-03-27</created><authors><author><keyname>Budinich</keyname><forenames>Marco</forenames></author><author><keyname>Budinich</keyname><forenames>Paolo</forenames></author></authors><title>A Spinorial Formulation of the Maximum Clique Problem of a Graph</title><categories>math-ph cs.DM math.CO math.MP</categories><journal-ref>J. Math. Phys. 47, 043502 (2006)</journal-ref><doi>10.1063/1.2186256</doi><abstract>  We present a new formulation of the maximum clique problem of a graph in
complex space. We start observing that the adjacency matrix A of a graph can
always be written in the form A = B B where B is a complex, symmetric matrix
formed by vectors of zero length (null vectors) and the maximum clique problem
can be transformed in a geometrical problem for these vectors. This problem, in
turn, is translated in spinorial language and we show that each graph uniquely
identifies a set of pure spinors, that is vectors of the endomorphism space of
Clifford algebras, and the maximum clique problem is formalized in this setting
so that, this much studied problem, may take advantage from recent progresses
of pure spinor geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math-ph/0605049</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math-ph/0605049</id><created>2006-05-16</created><updated>2006-05-25</updated><authors><author><keyname>Segre</keyname><forenames>Gavriel</forenames></author></authors><title>Some elementary rigorous remark about the replica formalism in the
  Statistical Physics' approach to threshold phenomena in Computational
  Complexity Theory</title><categories>math-ph cond-mat.stat-mech cs.CC math.MP</categories><comments>v3: little corrections not changing the substance</comments><abstract>  Some elementary rigorous remark about the replica formalism in the
Statistical Physics' approach to threshold phenomena in Computational
Complexity Theory is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math-ph/0608014</identifier>
 <datestamp>2012-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math-ph/0608014</id><created>2006-08-04</created><updated>2007-06-03</updated><authors><author><keyname>Omerbashich</keyname><forenames>M.</forenames></author></authors><title>Gauss-Vanicek Spectral Analysis of the Sepkoski Compendium: No New Life
  Cycles</title><categories>math-ph cs.NA math.MP physics.data-an q-bio.PE q-bio.QM</categories><comments>Of interest to all sciences. Added a letter containing Errata for a
  figure discolored due to journal error</comments><journal-ref>Computing in Science and Engineering 8, 4:26-30, Jul/Aug 2006.
  Errata in: CiSE 9, 4:5-6, Jul/Aug 2007 (Opposition paper to: R.A. Rohde &amp;
  R.A. Muller (2005) Cycles in fossil diversity, Nature 434:208-210)</journal-ref><doi>10.1109/MCSE.2006.68</doi><abstract>  New periods can emerge from data as a byproduct of incorrect processing or
even the method applied. In one such recent instance, a new life cycle with a
62+-3 Myr period was reportedly found (about trend) in genus variations from
the Sepkoski compendium, the world most complete fossil record. The approach
that led to reporting this period was based on Fourier method of spectral
analysis. I show here that no such period is found when the original data set
is considered rigorously and processed in the Gauss-Vanicek spectral analysis.
I also demonstrate that data altering can boost spectral power up to a nearly
100 percent increase in the signal range, thus introducing artificial, &quot;99
percent significant&quot; periods as seen in the corresponding variance-spectra of
noise. Besides geology and paleontology, virtually all science and engineering
disciplines could benefit from the approach described here. The main general
advantages of the Gauss-Vanicek spectral analysis lay in period detection from
gapped records and in straightforward testing of statistical null hypothesis.
The main advantage of the method for physical sciences is its use as a field
descriptor for accurate simultaneous detection of eigenfrequencies and relative
dynamics. Besides analyzing incomplete records, researchers might also want to
remove less-trustworthy data from any time series before analyzing it with the
Gauss-Vanicek method. This could increase both the accuracy and reliability of
spectral analyses in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math-ph/0610037</identifier>
 <datestamp>2014-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math-ph/0610037</id><created>2006-10-17</created><updated>2010-01-29</updated><authors><author><keyname>Fressengeas</keyname><forenames>Nicolas</forenames><affiliation>LMOPS</affiliation></author><author><keyname>Frezza-Buet</keyname><forenames>Herv&#xe9;</forenames></author></authors><title>Cellular Computing and Least Squares for partial differential problems
  parallel solving</title><categories>math-ph cs.DC math.AP math.MP</categories><journal-ref>Journal of Cellular Automata 9, 1 (2014) 1-21</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper shows how partial differential problems can be solved thanks to
cellular computing and an adaptation of the Least Squares Finite Elements
Method. As cellular computing can be implemented on distributed parallel
architectures, this method allows the distribution of a resource demanding
differential problem over a computer network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math-ph/0701043</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math-ph/0701043</id><created>2007-01-14</created><updated>2009-03-31</updated><authors><author><keyname>Jalsenius</keyname><forenames>Markus</forenames></author></authors><title>Strong Spatial Mixing and Rapid Mixing with Five Colours for the Kagome
  Lattice</title><categories>math-ph cs.DM cs.DS math.MP</categories><comments>34 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider proper 5-colourings of the kagome lattice. Proper q-colourings
correspond to configurations in the zero-temperature q-state anti-ferromagnetic
Potts model. Salas and Sokal have given a computer assisted proof of strong
spatial mixing on the kagome lattice for q&gt;=6 under any temperature, including
zero temperature. It is believed that there is strong spatial mixing for q&gt;=4.
Here we give a computer assisted proof of strong spatial mixing for q=5 and
zero temperature. It is commonly known that strong spatial mixing implies that
there is a unique infinite-volume Gibbs measure and that the Glauber dynamics
is rapidly mixing. We give a proof of rapid mixing of the Glauber dynamics on
any finite subset of the vertices of the kagome lattice, provided that the
boundary is free (not coloured). The Glauber dynamics is not necessarily
irreducible if the boundary is chosen arbitrarily for q=5 colours. The Glauber
dynamics can be used to uniformly sample proper 5-colourings. Thus, a
consequence of rapidly mixing Glauber dynamics is that there is fully
polynomial randomised approximation scheme for counting the number of proper
5-colourings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math-ph/9903036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math-ph/9903036</id><created>1999-03-18</created><updated>1999-03-19</updated><authors><author><keyname>Boutin</keyname><forenames>Mireille</forenames></author></authors><title>Numerically Invariant Signature Curves</title><categories>math-ph cs.CV math.MP</categories><comments>21 pages, amsart, uses verbatim, amsmath, latexsym, amssymb, epsf 55
  pictures</comments><abstract>  Corrected versions of the numerically invariant expressions for the affine
and Euclidean signature of a planar curve proposed by E.Calabi et. al are
presented. The new formulas are valid for fine but otherwise arbitrary
partitions of the curve. We also give numerically invariant expressions for the
four differential invariants parametrizing the three dimensional version of the
Euclidean signature curve, namely the curvature, the torsion and their
derivatives with respect to arc length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0002216</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0002216</id><created>2000-02-25</created><updated>2001-05-23</updated><authors><author><keyname>Gaucher</keyname><forenames>Philippe</forenames></author></authors><title>About the globular homology of higher dimensional automata</title><categories>math.CT cs.OH math.AT</categories><comments>44 pages ; LaTeX2e, 1 figure ; final version to appear in CTGDC</comments><msc-class>55U10; 18G35</msc-class><journal-ref>Cahiers de Topologie et Geometrie Differentielle Categoriques,
  p.107-156, vol XLIII-2 (2002)</journal-ref><abstract>  We introduce a new simplicial nerve of higher dimensional automata whose
homology groups yield a new definition of the globular homology. With this new
definition, the drawbacks noticed with the construction of math.CT/9902151
disappear. Moreover the important morphisms which associate to every globe its
corresponding branching area and merging area of execution paths become
morphisms of simplicial sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0003117</identifier>
 <datestamp>2015-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0003117</id><created>2000-03-20</created><authors><author><keyname>Gacs</keyname><forenames>Peter</forenames></author></authors><title>Reliable Cellular Automata with Self-Organization</title><categories>math.PR cs.DC</categories><comments>166 pages, 17 figures</comments><report-no>1998-002</report-no><msc-class>60K35, 65Q80, 82C22, 37B15</msc-class><journal-ref>J. of Stat. Phys. vol.103 (2001), no. 1/2, 45-267</journal-ref><doi>10.1023/A:1004823720305</doi><abstract>  In a probabilistic cellular automaton in which all local transitions have
positive probability, the problem of keeping a bit of information indefinitely
is nontrivial, even in an infinite automaton. Still, there is a solution in 2
dimensions, and this solution can be used to construct a simple 3-dimensional
discrete-time universal fault-tolerant cellular automaton. This technique does
not help much to solve the following problems: remembering a bit of information
in 1 dimension; computing in dimensions lower than 3; computing in any
dimension with non-synchronized transitions.
  Our more complex technique organizes the cells in blocks that perform a
reliable simulation of a second (generalized) cellular automaton. The cells of
the latter automaton are also organized in blocks, simulating even more
reliably a third automaton, etc. Since all this (a possibly infinite hierarchy)
is organized in ``software'', it must be under repair all the time from damage
caused by errors. A large part of the problem is essentially self-stabilization
recovering from a mess of arbitrary size and content. The present paper
constructs an asynchronous one-dimensional fault-tolerant cellular automaton,
with the further feature of ``self-organization''. The latter means that unless
a large amount of input information must be given, the initial configuration
can be chosen homogeneous.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0005058</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0005058</id><created>2000-05-06</created><updated>2000-05-09</updated><authors><author><keyname>Han</keyname><forenames>Te Sun</forenames></author></authors><title>An information-spectrum approach to joint source-channel coding</title><categories>math.PR cs.IT math.IT</categories><abstract>  Given a general source $\sV=\{V^n\}\noi$ with {\em countably infinite} source
alphabet and a general channel $\sW=\{W^n\}\noi$ with arbitrary {\em abstract}
channel input and output alphabets, we study the joint source-channel coding
problem from the information-spectrum point of view. First, we generalize
Feinstein's lemma (direct part) and Verd\'u-Han's lemma (converse part) so as
to be applicable to the general joint source-channel coding problem. Based on
these lemmas, we establish a sufficient condition as well as a necessary
condition for the source $\sV$ to be reliably transmissible over the channel
$\sW$ with asymptotically vanishing probability of error. It is shown that our
sufficient condition coincides with the sufficient condition derived by Vembu,
Verd\'u and Steinberg, whereas our necessary condition is much stronger than
the necessary condition derived by them. Actually, our necessary condition
coincide with our sufficient condition if we disregard some asymptotically
vanishing terms appearing in those conditions. Also, it is shown that {\em
Separation Theorem} in the generalized sense always holds. In addition, we
demonstrate a sufficient condition as well as a necessary condition for the
$\vep$-transmissibility ($0\le \vep &lt;1$). Finally, the separation theorem of
the traditional standard form is shown to hold for the class of sources and
channels that satisfy the (semi-) strong converse property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0005235</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0005235</id><created>2000-05-23</created><authors><author><keyname>Fill</keyname><forenames>James Allen</forenames><affiliation>Johns Hopkins Univ.</affiliation></author><author><keyname>Janson</keyname><forenames>Svante</forenames><affiliation>Uppsala Univ.</affiliation></author></authors><title>Smoothness and decay properties of the limiting Quicksort density
  function</title><categories>math.PR cs.DS</categories><comments>11 pages. Refereed article, to apppear in a book edited by D. Gardy
  and A. Mokkadem and published in 2000 by Birkhauser</comments><report-no>601, Department of Mathematical Sciences, The Johns Hopkins
  University</report-no><msc-class>68W40 (primary), 68P10, 60E05, 60E10 (secondary)</msc-class><abstract>  Using Fourier analysis, we prove that the limiting distribution of the
standardized random number of comparisons used by Quicksort to sort an array of
n numbers has an everywhere positive and infinitely differentiable density f,
and that each derivative f^{(k)} enjoys superpolynomial decay at plus and minus
infinity. In particular, each f^{(k)} is bounded. Our method is sufficiently
computational to prove, for example, that f is bounded by 16.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0005236</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0005236</id><created>2000-05-23</created><authors><author><keyname>Fill</keyname><forenames>James Allen</forenames><affiliation>Johns Hopkins Univ.</affiliation></author><author><keyname>Janson</keyname><forenames>Svante</forenames><affiliation>Uppsala Univ.</affiliation></author></authors><title>A characterization of the set of fixed points of the Quicksort
  transformation</title><categories>math.PR cs.DS</categories><comments>9 pages. See also http://www.mts.jhu.edu/~fill/ and
  http://www.math.uu.se/~svante/papers . Submitted for publication in May,2000</comments><report-no>606, Department of Mathematical Sciences, The Johns Hopkins
  University</report-no><msc-class>68W40 (primary), 60E05, 60E10, 68P10 (secondary)</msc-class><abstract>  The limiting distribution \mu of the normalized number of key comparisons
required by the Quicksort sorting algorithm is known to be the unique fixed
point of a certain distributional transformation T -- unique, that is, subject
to the constraints of zero mean and finite variance. We show that a
distribution is a fixed point of T if and only if it is the convolution of \mu
with a Cauchy distribution of arbitrary center and scale. In particular,
therefore, \mu is the unique fixed point of T having zero mean.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0005237</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0005237</id><created>2000-05-23</created><updated>2000-05-23</updated><authors><author><keyname>Devroye</keyname><forenames>Luc</forenames><affiliation>McGill Univ.</affiliation></author><author><keyname>Fill</keyname><forenames>James Allen</forenames><affiliation>Johns Hopkins Univ.</affiliation></author><author><keyname>Neininger</keyname><forenames>Ralph</forenames><affiliation>Univ. Freiburg</affiliation></author></authors><title>Perfect simulation from the Quicksort limit distribution</title><categories>math.PR cs.DS</categories><comments>7 pages. See also http://www.mts.jhu.edu/~fill/,
  http://www-cgrl.cs.mcgill.ca/~luc/, and
  http://www.stochastik.uni-freiburg.de/homepages/neininger/ . Submitted for
  publication in May, 2000</comments><report-no>603, Department of Mathematical Sciences, The Johns Hopkins
  University</report-no><msc-class>65C10 (primary), 65C05, 68U20, 11K45 (secondary)</msc-class><abstract>  The weak limit of the normalized number of comparisons needed by the
Quicksort algorithm to sort n randomly permuted items is known to be determined
implicitly by a distributional fixed-point equation. We give an algorithm for
perfect random variate generation from this distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0005281</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0005281</id><created>2000-05-30</created><authors><author><keyname>Rosenthal</keyname><forenames>Joachim</forenames></author></authors><title>Connections between Linear Systems and Convolutional Codes</title><categories>math.OC cs.IT math.IT</categories><comments>28 pages, to appear in IMA volume on Codes, Systems and Graphical
  Models</comments><msc-class>37B10, 93B25, 94B10</msc-class><abstract>  The article reviews different definitions for a convolutional code which can
be found in the literature. The algebraic differences between the definitions
are worked out in detail. It is shown that bi-infinite support systems are dual
to finite-support systems under Pontryagin duality. In this duality the dual of
a controllable system is observable and vice versa. Uncontrollability can occur
only if there are bi-infinite support trajectories in the behavior, so finite
and half-infinite-support systems must be controllable. Unobservability can
occur only if there are finite support trajectories in the behavior, so
bi-infinite and half-infinite-support systems must be observable. It is shown
that the different definitions for convolutional codes are equivalent if one
restricts attention to controllable and observable codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0006067</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0006067</id><created>2000-06-08</created><updated>2000-08-04</updated><authors><author><keyname>Moore</keyname><forenames>Cristopher</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>One-Dimensional Peg Solitaire</title><categories>math.CO cs.GT</categories><journal-ref>MSRI Workshop on Combinatorial Games 2000</journal-ref><abstract>  We solve the problem of one-dimensional peg solitaire. In particular, we show
that the set of configurations that can be reduced to a single peg forms a
regular language, and that a linear-time algorithm exists for reducing any
configuration to the minimum number of pegs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0006233</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0006233</id><created>2000-06-30</created><updated>2001-10-09</updated><authors><author><keyname>Gacs</keyname><forenames>Peter</forenames><affiliation>Boston University</affiliation></author><author><keyname>Tromp</keyname><forenames>John</forenames><affiliation>CWI</affiliation></author><author><keyname>Vitanyi</keyname><forenames>Paul</forenames><affiliation>CWI and University of Amsterdam</affiliation></author></authors><title>Algorithmic Statistics</title><categories>math.ST cs.IT cs.LG math.IT math.PR physics.data-an stat.TH</categories><comments>LaTeX, 22 pages, 1 figure, with correction to the published journal
  version</comments><msc-class>62B05, 62B10, 68Q32, 68Q30, 60AXX, 68T04</msc-class><journal-ref>IEEE Transactions on Information Theory, Vol. 47, No. 6, September
  2001, pp 2443-2463</journal-ref><abstract>  While Kolmogorov complexity is the accepted absolute measure of information
content of an individual finite object, a similarly absolute notion is needed
for the relation between an individual data sample and an individual model
summarizing the information in the data, for example, a finite set (or
probability distribution) where the data sample typically came from. The
statistical theory based on such relations between individual objects can be
called algorithmic statistics, in contrast to classical statistical theory that
deals with relations between probabilistic ensembles. We develop the
algorithmic theory of statistic, sufficient statistic, and minimal sufficient
statistic. This theory is based on two-part codes consisting of the code for
the statistic (the model summarizing the regularity, the meaningful
information, in the data) and the model-to-data code. In contrast to the
situation in probabilistic statistical theory, the algorithmic relation of
(minimal) sufficiency is an absolute relation between the individual model and
the individual data sample. We distinguish implicit and explicit descriptions
of the models. We give characterizations of algorithmic (Kolmogorov) minimal
sufficient statistic for all data samples for both description modes--in the
explicit mode under some constraints. We also strengthen and elaborate earlier
results on the ``Kolmogorov structure function'' and ``absolutely
non-stochastic objects''--those rare objects for which the simplest models that
summarize their relevant information (minimal sufficient statistics) are at
least as complex as the objects themselves. We demonstrate a close relation
between the probabilistic notions and the algorithmic ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0008172</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0008172</id><created>2000-08-22</created><authors><author><keyname>Moore</keyname><forenames>Cristopher</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>One-Dimensional Peg Solitaire, and Duotaire</title><categories>math.CO cs.GT</categories><comments>Partlt presented at the 2000 MSRI Workshop on Combinatorial Games</comments><journal-ref>More Games of No Chance, MSRI Publications 42, 2002, pp. 341-350</journal-ref><abstract>  We solve the problem of one-dimensional Peg Solitaire. In particular, we show
that the set of configurations that can be reduced to a single peg forms a
regular language, and that a linear-time algorithm exists for reducing any
configuration to the minimum number of pegs.
  We then look at the impartial two-player game, proposed by Ravikumar, where
two players take turns making peg moves, and whichever player is left without a
move loses. We calculate some simple nim-values and discuss when the game
separates into a disjunctive sum of smaller games. In the version where a
series of hops can be made in a single move, we show that neither the
P-positions nor the N-positions (i.e. wins for the previous or next player) are
described by a regular or context-free language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0009018</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0009018</id><created>2000-09-01</created><authors><author><keyname>Dembo</keyname><forenames>Amir</forenames></author><author><keyname>Kontoyiannis</keyname><forenames>Ioannis</forenames></author></authors><title>Critical Behavior in Lossy Source Coding</title><categories>math.PR cs.IT math.IT</categories><comments>2 figures</comments><abstract>  The following critical phenomenon was recently discovered. When a memoryless
source is compressed using a variable-length fixed-distortion code, the fastest
convergence rate of the (pointwise) compression ratio to the optimal $R(D)$
bits/symbol is either $O(\sqrt{n})$ or $O(\log n)$. We show it is always
$O(\sqrt{n})$, except for discrete, uniformly distributed sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0010173</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0010173</id><created>2000-10-17</created><updated>2001-06-22</updated><authors><author><keyname>Nigro</keyname><forenames>Noberto M.</forenames></author><author><keyname>Storti</keyname><forenames>Mario A.</forenames></author></authors><title>Hot-pressing process modeling for medium density fiberboard (MDF)</title><categories>math.NA cs.CE</categories><comments>LaTeX, 11 figures. Added references. Fixed some errors. To appear in
  International Journal of Mathematics and Mathematical Sciences,
  http://jam.hindawi.com</comments><report-no>CIMEC - 1/1999, formerly math.SC/0010173</report-no><abstract>  In this paper we present a numerical solution for the mathematical modeling
of the hot-pressing process applied to medium density fiberboard. The model is
based in the work of Humphrey[82], Humphrey and Bolton[89] and Carvalho and
Costa[98], with some modifications and extensions in order to take into account
mainly the convective effects on the phase change term and also a conservative
numerical treatment of the resulting system of partial differential equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0010307</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0010307</id><created>2000-10-30</created><authors><author><keyname>Deolalikar</keyname><forenames>Vinay</forenames></author></authors><title>Fields, towers of function fields meeting asymptotic bounds, and basis
  constructions for algebraic-geometric codes</title><categories>math.NT cs.IT math.IT</categories><comments>74 pages</comments><msc-class>14G05, 14H05, 14G50</msc-class><abstract>  In this work, we use the notion of ``symmetry'' of functions for an extension
$K/L$ of finite fields to produce extensions of a function field $F/K$ in which
almost all places of degree one split completely. Then we introduce the notion
of ``quasi-symmetry'' of functions for $K/L$, and demonstrate its use in
producing extensions of $F/K$ in which all places of degree one split
completely. Using these techniques, we are able to restrict the ramification
either to one chosen rational place, or entirely to non-rational places. We
then apply these methods to the related problem of building asymptotically good
towers of function fields. We construct examples of towers of function fields
in which all rational places split completely throughout the tower. We
construct Abelian towers with this property also.
  Furthermore, all of the above are done explicitly, ie., we give generators
for the extensions, and equations that they satisfy.
  We also construct an integral basis for a set of places in a tower of
function fields meeting the Drinfeld-Vladut bound using the discriminant of the
tower localized at each place. Thus we are able to obtain a basis for a
collection of functions that contains the set of regular functions in this
tower. Regular functions are of interest in the theory of error-correcting
codes as they lead to an explicit description of the code associated to the
tower by providing the code's generator matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0012036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0012036</id><created>2000-12-06</created><authors><author><keyname>Kleiman</keyname><forenames>Howard</forenames><affiliation>Prof. Emer., Queensborough Community Coll.</affiliation></author></authors><title>Hamilton Circuits in Graphs and Directed Graphs</title><categories>math.CO cs.DS</categories><comments>Text in Word 97, Equations in MathType, sent in a PDF file using
  Adobe Acrobat Writer (4.05), no figures</comments><abstract>  We give polynomial-time algorithms for obtaining hamilton circuits in random
graphs, G, and random directed graphs, D. If n is finite, we assume that G or D
contains a hamilton circuit. If G is an arbitrary graph containing a hamilton
circuit, we conjecture that Algorithm G always obtains a hamilton circuit in
polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0012163</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0012163</id><created>2000-12-18</created><updated>2000-12-19</updated><authors><author><keyname>Kuusela</keyname><forenames>Pirkko</forenames><affiliation>Rutgers, The State University of New Jersey, USA</affiliation></author><author><keyname>Ocone</keyname><forenames>Daniel</forenames><affiliation>Rutgers, The State University of New Jersey, USA</affiliation></author><author><keyname>Sontag</keyname><forenames>Eduardo D.</forenames><affiliation>Rutgers, The State University of New Jersey, USA</affiliation></author></authors><title>Learning Complexity Dimensions for a Continuous-Time Control System</title><categories>math.OC cs.LG</categories><comments>33 pages</comments><msc-class>93C05</msc-class><abstract>  This paper takes a computational learning theory approach to a problem of
linear systems identification. It is assumed that input signals have only a
finite number k of frequency components, and systems to be identified have
dimension no greater than n. The main result establishes that the sample
complexity needed for identification scales polynomially with n and
logarithmically with k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0101092</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0101092</id><created>2001-01-10</created><authors><author><keyname>Canogar-Mackenzie</keyname><forenames>Roberto</forenames></author><author><keyname>Martinez-Moro</keyname><forenames>Edgar</forenames></author></authors><title>Structure of $Z^2$ modulo selfsimilar sublattices</title><categories>math.CO cs.IT math.IT</categories><comments>13 pages, submitted to Theoretical Computer Science</comments><msc-class>05E30;52C20;11H71</msc-class><abstract>  In this paper we show the combinatorial structure of $\mathbb{Z}^2$ modulo
sublattices selfsimilar to $\mathbb{Z}^2$. The tool we use for dealing with
this purpose is the notion of association scheme. We classify when the scheme
defined by the lattice is imprimitive and characterize its decomposition in
terms of the decomposition of the gaussian integer defining the lattice. This
arise in the classification of different forms of tiling $\mathbb{Z}^2$ by
lattices of this type.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0103007</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0103007</id><created>2001-03-01</created><authors><author><keyname>Dembo</keyname><forenames>A.</forenames></author><author><keyname>Kontoyiannis</keyname><forenames>I.</forenames></author></authors><title>Source Coding, Large Deviations, and Approximate Pattern Matching</title><categories>math.PR cs.IT math.IT</categories><comments>48 pages, review paper</comments><msc-class>94A15; 60F10; 60G60</msc-class><abstract>  We present a development of parts of rate-distortion theory and pattern-
matching algorithms for lossy data compression, centered around a lossy version
of the Asymptotic Equipartition Property (AEP). This treatment closely
parallels the corresponding development in lossless compression, a point of
view that was advanced in an important paper of Wyner and Ziv in 1989. In the
lossless case we review how the AEP underlies the analysis of the Lempel-Ziv
algorithm by viewing it as a random code and reducing it to the idealized
Shannon code. This also provides information about the redundancy of the
Lempel-Ziv algorithm and about the asymptotic behavior of several relevant
quantities. In the lossy case we give various versions of the statement of the
generalized AEP and we outline the general methodology of its proof via large
deviations. Its relationship with Barron's generalized AEP is also discussed.
The lossy AEP is applied to: (i) prove strengthened versions of Shannon's
source coding theorem and universal coding theorems; (ii) characterize the
performance of mismatched codebooks; (iii) analyze the performance of pattern-
matching algorithms for lossy compression; (iv) determine the first order
asymptotics of waiting times (with distortion) between stationary processes;
(v) characterize the best achievable rate of weighted codebooks as an optimal
sphere-covering exponent. We then present a refinement to the lossy AEP and use
it to: (i) prove second order coding theorems; (ii) characterize which sources
are easier to compress; (iii) determine the second order asymptotics of waiting
times; (iv) determine the precise asymptotic behavior of longest match-lengths.
Extensions to random fields are also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0103011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0103011</id><created>2001-03-02</created><updated>2003-03-01</updated><authors><author><keyname>Gaucher</keyname><forenames>Philippe</forenames></author></authors><title>The branching nerve of HDA and the Kan condition</title><categories>math.AT cs.OH math.CT</categories><comments>Final version ; see http://www.tac.mta.ca/tac/</comments><msc-class>55U10 ; 18G35 ; 68Q85</msc-class><journal-ref>Theory and Applications of Categories, Vol. 11, 2003, No. 3, pp
  75-106</journal-ref><abstract>  One can associate to any strict globular $\omega$-category three augmented
simplicial nerves called the globular nerve, the branching and the merging
semi-cubical nerves. If this strict globular $\omega$-category is freely
generated by a precubical set, then the corresponding homology theories contain
different informations about the geometry of the higher dimensional automaton
modeled by the precubical set. Adding inverses in this $\omega$-category to any
morphism of dimension greater than 2 and with respect to any composition laws
of dimension greater than 1 does not change these homology theories. In such a
framework, the globular nerve always satisfies the Kan condition. On the other
hand, both branching and merging nerves never satisfy it, except in some very
particular and uninteresting situations. In this paper, we introduce two new
nerves (the branching and merging semi-globular nerves) satisfying the Kan
condition and having conjecturally the same simplicial homology as the
branching and merging semi-cubical nerves respectively in such framework. The
latter conjecture is related to the thin elements conjecture already introduced
in our previous papers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0103107</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0103107</id><created>2001-03-16</created><authors><author><keyname>Elkies</keyname><forenames>Noam D.</forenames></author></authors><title>Explicit modular towers</title><categories>math.NT cs.IT math.AG math.IT</categories><comments>10 pages; presented at Allerton 1998 (see Journal-ref field)</comments><msc-class>11G18 (Primary) 14G50 (Seconday)</msc-class><journal-ref>Pages 23-32 in Proceedings of the Thirty-Fifth Annual Allerton
  Conference on Communication, Control and Computing (1997; T.Basar and
  A.Vardy, eds.), Univ. of Illinois at Urbana-Champaign 1998</journal-ref><abstract>  We give a general recipe for explicitly constructing asymptotically optimal
towers of modular curves such as {X_0(l^n): n=1,2,3,...}. We illustrate the
method by giving equations for eight towers with various geometric features. We
conclude by observing that such towers are all of a specific recursive form,
and speculate that perhaps every tower of this form that attains the
Drinfeld-Vladut bound is modular.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0103109</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0103109</id><created>2001-03-16</created><authors><author><keyname>Lundh</keyname><forenames>Torbj&#xf6;rn</forenames></author></authors><title>In search of an evolutionary coding style</title><categories>math.NA cs.IT math.DS math.IT q-bio</categories><comments>14 pages, 7 postscript figures</comments><report-no>Stony Brook IMS 2000/3, formerly math.SC/0103109</report-no><abstract>  In the near future, all the human genes will be identified. But understanding
the functions coded in the genes is a much harder problem. For example, by
using block entropy, one has that the DNA code is closer to a random code then
written text, which in turn is less ordered then an ordinary computer code; see
\cite{schmitt}.
  Instead of saying that the DNA is badly written, using our programming
standards, we might say that it is written in a different style -- an
evolutionary style.
  We will suggest a way to search for such a style in a quantified manner by
using an artificial life program, and by giving a definition of general codes
and a definition of style for such codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0104016</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0104016</id><created>2001-04-02</created><authors><author><keyname>Roychowdhury</keyname><forenames>Vwani P.</forenames></author><author><keyname>Vatan</keyname><forenames>Farrokh</forenames></author></authors><title>Bounds for weight distribution of weakly self-dual codes</title><categories>math.CO cs.IT math.IT quant-ph</categories><comments>9 pages</comments><msc-class>94B65</msc-class><journal-ref>IEEE Transactions on Information Theory, vol. 47, no. 1, Jan.
  2001, pp. 393-396</journal-ref><abstract>  Upper bounds are given for the weight distribution of binary weakly self-dual
codes. To get these new bounds, we introduce a novel method of utilizing
unitary operations on Hilbert spaces. This method is motivated by recent
progress on quantum computing. This new approach leads to much simpler proofs
for such genre of bounds on the weight distributions of certain classes of
codes. Moreover, in some cases, our bounds are improvements on the earlier
bounds. These improvements are achieved, either by extending the range of the
weights over which the bounds apply, or by extending the class of codes
subjected to these bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0104115</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0104115</id><created>2001-04-10</created><authors><author><keyname>Elkies</keyname><forenames>Noam D.</forenames></author></authors><title>Excellent nonlinear codes from modular curves</title><categories>math.NT cs.IT math.AG math.IT</categories><comments>Accepted for STOC-'01; 10 single-spaced twocolumn pages</comments><msc-class>94B27;94B65</msc-class><abstract>  We introduce a new construction of error-correcting codes from algebraic
curves over finite fields. Modular curves of genus g -&gt; infty over a field of
size q0^2 yield nonlinear codes more efficient than the linear Goppa codes
obtained from the same curves. These new codes now have the highest asymptotic
transmission rates known for certain ranges of alphabet size and error rate.
Both the theory and possible practical use of these new record codes require
the development of new tools. On the theoretical side, establishing the
transmission rate depends on an error estimate for a theorem of Schanuel
applied to the function field of an asymptotically optimal curve. On the
computational side, actual use of the codes will hinge on the solution of new
problems in the computational algebraic geometry of curves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0104222</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0104222</id><created>2001-04-24</created><authors><author><keyname>Matsumoto</keyname><forenames>Ryutaroh</forenames></author><author><keyname>Oishi</keyname><forenames>Masakuni</forenames></author></authors><title>Decoding method for generalized algebraic geometry codes</title><categories>math.NT cs.IT math.AG math.IT</categories><comments>LaTeX2e, 8 pages, 1 figure</comments><msc-class>11T71 (Primary) 11G20, 14G50, 94B27 (Secondary)</msc-class><abstract>  We propose a decoding method for the generalized algebraic geometry codes
proposed by Xing et al. To show its practical usefulness, we give an example of
generalized algebraic geometry codes of length 567 over F_8 whose numbers of
correctable errors by the proposed method are larger than the shortened codes
of the primitive BCH codes of length 4095 in the most range of dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0105235</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0105235</id><created>2001-05-28</created><updated>2001-12-02</updated><authors><author><keyname>Komarova</keyname><forenames>Natalia</forenames></author><author><keyname>Rivin</keyname><forenames>Igor</forenames></author></authors><title>Mathematics of learning</title><categories>math.PR cs.LG math.CO math.DS</categories><comments>Minor revisions</comments><msc-class>60E07, 60F15, 60J20, 91E40, 26C10</msc-class><abstract>  We study the convergence properties of a pair of learning algorithms
(learning with and without memory). This leads us to study the dominant
eigenvalue of a class of random matrices. This turns out to be related to the
roots of the derivative of random polynomials (generated by picking their roots
uniformly at random in the interval [0, 1], although our results extend to
other distributions). This, in turn, requires the study of the statistical
behavior of the harmonic mean of random variables as above, which leads us to
delicate question of the rate of convergence to stable laws and tail estimates
for stable laws. The reader can find the proofs of most of the results
announced here in the paper entitled &quot;Harmonic mean, random polynomials, and
random matrices&quot;, by the same authors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0105236</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0105236</id><created>2001-05-28</created><updated>2001-12-02</updated><authors><author><keyname>Komarova</keyname><forenames>Natalia</forenames></author><author><keyname>Rivin</keyname><forenames>Igor</forenames></author></authors><title>Harmonic mean, random polynomials and stochastic matrices</title><categories>math.PR cs.LG math.CA math.CO math.DS</categories><msc-class>60E07, 60F15, 60J20, 91E40, 26C10</msc-class><abstract>  Motivated by a problem in learning theory, we are led to study the dominant
eigenvalue of a class of random matrices. This turns out to be related to the
roots of the derivative of random polynomials (generated by picking their roots
uniformly at random in the interval [0, 1], although our results extend to
other distributions). This, in turn, requires the study of the statistical
behavior of the harmonic mean of random variables as above, and that, in turn,
leads us to delicate question of the rate of convergence to stable laws and
tail estimates for stable laws.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0106089</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0106089</id><created>2001-06-12</created><updated>2001-06-22</updated><authors><author><keyname>van der Geer</keyname><forenames>Gerard</forenames></author><author><keyname>van der Vlugt</keyname><forenames>Marcel</forenames></author></authors><title>The coset weight distributions of certain BCH codes and a family of
  curves</title><categories>math.AG cs.IT math.CO math.IT</categories><comments>Plain Tex, 15 pages; some numerical data added</comments><abstract>  We study the distribution of the number of rational points in a family of
curves over a finite field of characteristic 2. This distribution determines
the coset weight distribution of a certain BCH code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0106120</identifier>
 <datestamp>2009-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0106120</id><created>2001-06-14</created><authors><author><keyname>Berngardt</keyname><forenames>Oleg I.</forenames></author><author><keyname>Voronov</keyname><forenames>Alexander L.</forenames></author></authors><title>Least Sqaure Method for Sum of the Functions Satysfying the Differential
  Equations with Polynomial Coefficients</title><categories>math.NA cs.NA math.OC</categories><comments>9 pages</comments><journal-ref>Analele Universitatii din Timisoara Vol. XXXIX, Fasc. special,
  2001, Seria Matematica/Informatica, pp.21-29</journal-ref><abstract>  We propose a linear algorithm for determining two function parameters by
their linear combination. These functions must satisfy the first order
differential equations with polynomial coefficients and our parameters are the
coefficients of these polynomials. The algorithm consists of sequential
solution by least squares method of two linear problems - first, differential
equation polynomial coefficients determining for linear combination of two
given functions and second - determining functions parameters by these
polynomial coefficients. Numerical modeling carried by this scheme gives an
good accordance under weak normal noise (with dispersion (&lt;5%)).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0108096</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0108096</id><created>2001-08-13</created><authors><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Bolcskei</keyname><forenames>H.</forenames></author></authors><title>Geometrically Uniform Frames</title><categories>math.FA cs.IT math.GR math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory. LaTex, 43 pages</comments><journal-ref>IEEE Trans. Inform. Theory, vol. 49, pp. 993-1006, Apr. 2003.</journal-ref><abstract>  We introduce a new class of frames with strong symmetry properties called
geometrically uniform frames (GU), that are defined over an abelian group of
unitary matrices and are generated by a single generating vector. The notion of
GU frames is then extended to compound GU (CGU) frames which are generated by
an abelian group of unitary matrices using multiple generating vectors.
  The dual frame vectors and canonical tight frame vectors associated with GU
frames are shown to be GU and therefore generated by a single generating
vector, which can be computed very efficiently using a Fourier transform
defined over the generating group of the frame. Similarly, the dual frame
vectors and canonical tight frame vectors associated with CGU frames are shown
to be CGU.
  The impact of removing single or multiple elements from a GU frame is
considered. A systematic method for constructing optimal GU frames from a given
set of frame vectors that are not GU is also developed. Finally, the Euclidean
distance properties of GU frames are discussed and conditions are derived on
the abelian group of unitary matrices to yield GU frames with strictly positive
distance spectrum irrespective of the generating vector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0109195</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0109195</id><created>2001-09-24</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Separating Geometric Thickness from Book Thickness</title><categories>math.CO cs.CG cs.DM</categories><comments>3 pages, 1 figure</comments><msc-class>05C10</msc-class><abstract>  We show that geometric thickness and book thickness are not asymptotically
equivalent: for every t, there exists a graph with geometric thickness two and
book thickness &gt;= t.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0110086</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0110086</id><created>2001-10-08</created><updated>2001-10-10</updated><authors><author><keyname>Vitanyi</keyname><forenames>Paul M. B.</forenames></author></authors><title>Randomness</title><categories>math.PR cs.CR math.ST physics.data-an stat.TH</categories><comments>LaTeX source, 48 pages, Section contributed to `Matematica, Logica,
  Informatica' Volume 12 of the &quot;Storia del XX Secolo&quot;, published by the
  &quot;Instituto della Enciclopedia Italiana&quot; (smal addition in new version)</comments><msc-class>60-02, 60A05, 62-02, 62A01</msc-class><abstract>  Here we present in a single essay a combination and completion of the several
aspects of the problem of randomness of individual objects which of necessity
occur scattered in our texbook &quot;An Introduction to Kolmogorov Complexity and
Its Applications&quot; (M. Li and P. Vitanyi), 2nd Ed., Springer-Verlag, 1997.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0110157</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0110157</id><created>2001-10-15</created><authors><author><keyname>Fryers</keyname><forenames>Michael</forenames></author><author><keyname>Kaminski</keyname><forenames>Jeremy Yirmeyahu</forenames></author><author><keyname>Teicher</keyname><forenames>Mina</forenames></author></authors><title>Some Applications of Algebraic Curves to Computational Vision</title><categories>math.AG cs.IT math.IT</categories><comments>Chapter book in 'Applications of Algebraic Geometry to Coding Theory,
  Physics and Computation'</comments><abstract>  We introduce a new formalism and a number of new results in the context of
geometric computational vision. The classical scope of the research in
geometric computer vision is essentially limited to static configurations of
points and lines in $P^3$ . By using some well known material from algebraic
geometry, we open new branches to computational vision. We introduce algebraic
curves embedded in $P^3$ as the building blocks from which the tensor of a
couple of cameras (projections) can be computed. In the process we address
dimensional issues and as a result establish the minimal number of algebraic
curves required for the tensor variety to be discrete as a function of their
degree and genus. We then establish new results on the reconstruction of an
algebraic curves in $P^3$ from multiple projections on projective planes
embedded in $P^3$ . We address three different presentations of the curve: (i)
definition by a set of equations, for which we show that for a generic
configuration, two projections of a curve of degree d defines a curve in $P^3$
with two irreducible components, one of degree d and the other of degree $d(d -
1)$, (ii) the dual presentation in the dual space $P^{3*}$, for which we derive
a lower bound for the number of projections necessary for linear reconstruction
as a function of the degree and the genus, and (iii) the presentation as an
hypersurface of $P^5$, defined by the set of lines in $P^3$ meeting the curve,
for which we also derive lower bounds for the number of projections necessary
for linear reconstruction as a function of the degree (of the curve). Moreover
we show that the latter representation yields a new and efficient algorithm for
dealing with mixed configurations of static and moving points in $P^3$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0110214</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0110214</id><created>2001-10-19</created><authors><author><keyname>Latapy</keyname><forenames>Matthieu</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Magnien</keyname><forenames>Clemence</forenames><affiliation>LIAFA</affiliation></author></authors><title>Coding Distributive Lattices with Edge Firing Games</title><categories>math.CO cs.IT math-ph math.DS math.IT math.MP</categories><comments>4 pages, 2 figures</comments><abstract>  In this note, we show that any distributive lattice is isomorphic to the set
of reachable configurations of an Edge Firing Game. Together with the result of
James Propp, saying that the set of reachable configurations of any Edge Firing
Game is always a distributive lattice, this shows that the two concepts are
equivalent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0111159</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0111159</id><created>2001-11-13</created><updated>2003-01-22</updated><authors><author><keyname>Agashe</keyname><forenames>Amod</forenames></author><author><keyname>Lauter</keyname><forenames>Kristin</forenames></author><author><keyname>Venkatesan</keyname><forenames>Ramarathnam</forenames></author></authors><title>Constructing elliptic curves with a known number of points over a prime
  field</title><categories>math.NT cs.IT math.AG math.IT</categories><comments>14 pages, complexity analysis redone, several sections rewritten</comments><msc-class>11Y16; 14H52; 11G15; 11Z05</msc-class><abstract>  Elliptic curves with a known number of points over a given prime field with n
elements are often needed for use in cryptography. In the context of primality
proving, Atkin and Morain suggested the use of the theory of complex
multiplication to construct such curves. One of the steps in this method is the
calculation of a root modulo n of the Hilbert class polynomial H(X) for a
fundamental discriminant D. The usual way is to compute H(X) over the integers
and then to find the root modulo n. We present a modified version of the
Chinese remainder theorem (CRT) to compute H(X) modulo n directly from the
knowledge of H(X) modulo enough small primes. Our complexity analysis suggests
that asymptotically our algorithm is an improvement over previously known
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0111309</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0111309</id><created>2001-11-29</created><authors><author><keyname>Kleiman</keyname><forenames>Howard</forenames></author></authors><title>The Floyd-Warshall Algorithm, the AP and the TSP</title><categories>math.CO cs.DS</categories><comments>Text in Word 2000, math in MathType 4.0, sent in a PDF file written
  in Acrobat 5.0, 23 pages</comments><abstract>  We use admissible permutations and a variant of the Floyd-Warshall algorithm
to obtain an optimal solution to the Assignment Problem. Using another variant
of the F-W algorithm, we obtain an approximate solution to the Traveling
Salesman Problem. We also give a sufficient condition for the approximate
solution to be an optimal solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0112052</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0112052</id><created>2001-12-06</created><authors><author><keyname>Kleiman</keyname><forenames>Howard</forenames></author></authors><title>The Floyd-Warshall Algorithm, the AP and the TSP, Part II</title><categories>math.CO cs.DS</categories><comments>Text in Word 2000, math in Math Type 4.0, sent in a PDF file written
  in Acrobat 5.0, 63 pages</comments><abstract>  In math.CO/0111309, we used admissible permutations and a variant of the
Floyd-Warshall Algorithm to obtain an optimal solution to the Assignment
Problem and an approximate solution to the Traveling Salesman Problem. Here we
give a large, detailed illustration of how the algorithms are applied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0112216</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0112216</id><created>2001-12-20</created><authors><author><keyname>Garcia</keyname><forenames>Luis</forenames></author><author><keyname>Jarrah</keyname><forenames>Abdul Salam</forenames></author><author><keyname>Laubenbacher</keyname><forenames>Reinhard</forenames></author></authors><title>Classification of Finite Dynamical Systems</title><categories>math.DS cs.MA math.CO</categories><comments>12 pages, 3 figures</comments><abstract>  This paper is motivated by the theory of sequential dynamical systems,
developed as a basis for a mathematical theory of computer simulation. It
contains a classification of finite dynamical systems on binary strings, which
are obtained by composing functions defined on the coordinates. The
classification is in terms of the dependency relations among the coordinate
functions. It suggests a natural notion of the linearization of a system.
Furthermore, it contains a sharp upper bound on the number of systems in terms
of the dependencies among the coordinate functions. This upper bound
generalizes an upper bound for sequential dynamical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0112257</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0112257</id><created>2001-12-22</created><authors><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>The computational complexity of the local postage stamp problem</title><categories>math.NT cs.CC math.CO</categories><msc-class>11B13 (primary); 11D85; 68Q25; 11Y16 (secondary)</msc-class><abstract>  The well-studied local postage stamp problem (LPSP) is the following: given a
positive integer k, a set of postive integers 1 = a1 &lt; a2 &lt; ... &lt; ak and an
integer h &gt;= 1, what is the smallest positive integer which cannot be
represented as a linear combination x1 a1 + ... + xk ak where x1 + ... + xk &lt;=
h and each xi is a non-negative integer? In this note we prove that LPSP is
NP-hard under Turing reductions, but can be solved in polynomial time if k is
fixed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0201298</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0201298</id><created>2002-01-30</created><authors><author><keyname>Heitzig</keyname><forenames>Jobst</forenames></author></authors><title>Qualitative Visualization of Distance Information</title><categories>math.CO cs.CG</categories><comments>Software can be tested at
  http://www-ifm.math.uni-hannover.de/~heitzig/distance</comments><abstract>  Different types of two- and three-dimensional representations of a finite
metric space are studied that focus on the accurate representation of the
linear order among the distances rather than their actual values. Lower and
upper bounds for representability probabilities are produced by experiments
including random generation, a rubber-band algorithm for accuracy optimization,
and automatic proof generation. It is proved that both farthest neighbour
representations and cluster tree representations always exist in the plane.
Moreover, a measure of order accuracy is introduced, and some lower bound on
the possible accuracy is proved using some clustering method and a result on
maximal cuts in graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0202276</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0202276</id><created>2002-02-26</created><authors><author><keyname>Jacek</keyname><forenames>Leszczynski</forenames></author><author><keyname>Mariusz</keyname><forenames>Ciesielski</forenames></author></authors><title>A numerical method for solution of ordinary differential equations of
  fractional order</title><categories>math.NA cs.CE physics.comp-ph</categories><comments>8 pages, 2 figures, Parallel Processing and Applied Mathematics
  (PPAM2001) Conference, under publishing in Lecture Notes in Computer Science,
  Springer Verlag</comments><msc-class>26A33, 45J05, 65D20, 65L05, 65L70</msc-class><journal-ref>Lecture Notes in Computer Science (LNCS), Springer-Verlag, 2328,
  2001, pp. 675-681</journal-ref><abstract>  In this paper we propose an algorithm for the numerical solution of arbitrary
differential equations of fractional order. The algorithm is obtained by using
the following decomposition of the differential equation into a system of
differential equation of integer order connected with inverse forms of
Abel-integral equations. The algorithm is used for solution of the linear and
non-linear equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0203059</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0203059</id><created>2002-03-06</created><authors><author><keyname>Samorodnitsky</keyname><forenames>Alex</forenames></author></authors><title>On linear programming bounds for spherical codes and designs</title><categories>math.CO cs.IT math.IT math.OC</categories><abstract>  We investigate universal bounds on spherical codes and spherical designs that
could be obtained using Delsarte's linear programming methods. We give a lower
estimate for the LP upper bound on codes, and an upper estimate for the LP
lower bound on designs. Specifically, when the distance of the code is fixed
and the dimension goes to infinity, the LP upper bound on codes is at least as
large as the average of the best known upper and lower bounds. When the
dimension n of the design is fixed, and the strength k goes to infinity, the LP
bound on designs turns out, in conjunction with known lower bounds, to be
proportional to k^{n-1}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0203239</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0203239</id><created>2002-03-22</created><updated>2002-06-10</updated><authors><author><keyname>Kapovich</keyname><forenames>Ilya</forenames></author><author><keyname>Myasnikov</keyname><forenames>Alexei</forenames></author><author><keyname>Schupp</keyname><forenames>Paul</forenames></author><author><keyname>Shpilrain</keyname><forenames>Vladimir</forenames></author></authors><title>Generic-case complexity, decision problems in group theory and random
  walks</title><categories>math.GR cs.CC</categories><comments>Revised version</comments><msc-class>20F</msc-class><abstract>  We give a precise definition of ``generic-case complexity'' and show that for
a very large class of finitely generated groups the classical decision problems
of group theory - the word, conjugacy and membership problems - all have
linear-time generic-case complexity. We prove such theorems by using the theory
of random walks on regular graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0204068</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0204068</id><created>2002-04-05</created><authors><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author><author><keyname>Cortes</keyname><forenames>Jorge</forenames></author><author><keyname>Lewis</keyname><forenames>Andrew D.</forenames></author><author><keyname>Martinez</keyname><forenames>Sonia</forenames></author></authors><title>Computational problems for vector-valued quadratic forms</title><categories>math.AG cs.CC math.OC</categories><comments>6 pages, no figures, submitted to Workshop on Open Problems in
  Mathematical Systems and Control Theory</comments><msc-class>11Exx; 14Pxx; 14Q99; 15A63</msc-class><abstract>  Given two real vector spaces $U$ and $V$, and a symmetric bilinear map $B:
U\times U\to V$, let $Q_B$ be its associated quadratic map $Q_B$. The problems
we consider are as follows: (i) are there necessary and sufficient conditions,
checkable in polynomial-time, for determining when $Q_B$ is surjective?; (ii)
if $Q_B$ is surjective, given $v\in V$ is there a polynomial-time algorithm for
finding a point $u\in Q_B^{-1}(v)$?; (iii) are there necessary and sufficient
conditions, checkable in polynomial-time, for determining when $B$ is
indefinite? We present an alternative formulation of the problem of determining
the image of a vector-valued quadratic form in terms of the unprojectivised
Veronese surface. The relation of these questions with several interesting
problems in Control Theory is illustrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0204252</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0204252</id><created>2002-04-19</created><updated>2003-07-25</updated><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Separating Thickness from Geometric Thickness</title><categories>math.CO cs.CG cs.DM</categories><comments>12 pages, 8 figures. This revision incorporates suggestions of the
  referee and reformats to AMS CONM proceedings style</comments><msc-class>05C10</msc-class><journal-ref>In &quot;Towards a Theory of Geometric Graphs&quot;, J. Pach, ed.,
  Contemporary Math. 342, pp. 75-86, 2004</journal-ref><abstract>  We show that graph-theoretic thickness and geometric thickness are not
asymptotically equivalent: for every t, there exists a graph with thickness
three and geometric thickness &gt;= t.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0205049</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0205049</id><created>2002-05-06</created><authors><author><keyname>Heitzig</keyname><forenames>Jobst</forenames></author></authors><title>The asymptotic complexity of partial sorting -- How to learn large
  posets by pairwise comparisons</title><categories>math.CO cs.CC math.OC</categories><msc-class>06A07; 11Y16</msc-class><abstract>  The expected number of pairwise comparisons needed to learn a partial order
on n elements is shown to be at least n*n/4-o(n*n), and an algorithm is given
that needs only n*n/4+o(n*n) comparisons on average. In addition, the optimal
strategy for learning a poset with four elements is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0205218</identifier>
 <datestamp>2015-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0205218</id><created>2002-05-20</created><updated>2002-06-24</updated><authors><author><keyname>Millar</keyname><forenames>Jessica</forenames></author><author><keyname>Sloane</keyname><forenames>N. J. A.</forenames></author><author><keyname>Young</keyname><forenames>Neal E.</forenames></author></authors><title>A New Operation on Sequences: the Boustrouphedon Transform</title><categories>math.CO cs.IT math.IT</categories><comments>very minor change: corrected typo in author list. June 24 2002:
  correction to a proof; additional references</comments><msc-class>05A15</msc-class><journal-ref>J. Combinatorial Theory, Series A 76(1):44-54 (1996)</journal-ref><doi>10.1006/jcta.1996.0087</doi><abstract>  A generalization of the Seidel-Entringer-Arnold method for calculating the
alternating permutation numbers (or secant-tangent numbers) leads to a new
operation on integer sequences, the Boustrophedon transform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0205299</identifier>
 <datestamp>2014-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0205299</id><created>2002-05-28</created><authors><author><keyname>Rains</keyname><forenames>E. M.</forenames></author><author><keyname>Sloane</keyname><forenames>N. J. A.</forenames></author><author><keyname>Stufken</keyname><forenames>John</forenames></author></authors><title>The Lattice of N-Run Orthogonal Arrays</title><categories>math.CO cs.IT math.IT</categories><comments>28 pages, 4 figures</comments><msc-class>05B15</msc-class><journal-ref>J. Statistical Planning and Inference, Vol. 102 (2002), pp.
  477-500</journal-ref><abstract>  If the number of runs in a (mixed-level) orthogonal array of strength 2 is
specified, what numbers of levels and factors are possible? The collection of
possible sets of parameters for orthogonal arrays with N runs has a natural
lattice structure, induced by the ``expansive replacement'' construction
method. In particular the dual atoms in this lattice are the most important
parameter sets, since any other parameter set for an N-run orthogonal array can
be constructed from them. To get a sense for the number of dual atoms, and to
begin to understand the lattice as a function of N, we investigate the height
and the size of the lattice. It is shown that the height is at most [c(N-1)],
where c= 1.4039... and that there is an infinite sequence of values of N for
which this bound is attained. On the other hand, the number of nodes in the
lattice is bounded above by a superpolynomial function of N (and
superpolynomial growth does occur for certain sequences of values of N). Using
a new construction based on ``mixed spreads'', all parameter sets with 64 runs
are determined. Four of these 64-run orthogonal arrays appear to be new.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0205301</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0205301</id><created>2002-05-28</created><authors><author><keyname>Bernstein</keyname><forenames>Mira</forenames></author><author><keyname>Sloane</keyname><forenames>N. J. A.</forenames></author></authors><title>Some Canonical Sequences of Integers</title><categories>math.CO cs.IT math.IT</categories><comments>18 pages, 2 figures; Dedicated to Professor J. J. Seidel</comments><msc-class>05Axx; 11Bxx</msc-class><journal-ref>Linear Algebra and its Applications, Vol. 226-228 (1995), pp.
  57-72; errata Vol. 320 (2000), p. 210</journal-ref><abstract>  Extending earlier work of R. Donaghey and P. J. Cameron, we investigate some
canonical &quot;eigen-sequences&quot; associated with transformations of integer
sequences. Several known sequences appear in a new setting: for instance the
sequences (such as 1, 3, 11, 49, 257, 1531, ...) studied by T. Tsuzuku, H. O.
Foulkes and A. Kerber in connection with multiply transitive groups are
eigen-sequences for the binomial transform. Many interesting new sequences also
arise, such as 1, 1, 2, 26, 152, 1144, ..., which shifts one place left when
transformed by the Stirling numbers of the second kind, and whose exponential
generating function satisfies A'(x) = A(e^x -1) + 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0205303</identifier>
 <datestamp>2014-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0205303</id><created>2002-05-28</created><authors><author><keyname>Applegate</keyname><forenames>David</forenames></author><author><keyname>Rains</keyname><forenames>E. M.</forenames></author><author><keyname>Sloane</keyname><forenames>N. J. A.</forenames></author></authors><title>On Asymmetric Coverings and Covering Numbers</title><categories>math.CO cs.IT math.IT</categories><comments>11 pages</comments><msc-class>05Bxx, 94B60</msc-class><journal-ref>J. Combinat. Designs 11 (2003), 218-228</journal-ref><abstract>  An asymmetric covering D(n,R) is a collection of special subsets S of an
n-set such that every subset T of the n-set is contained in at least one
special S with |S| - |T| &lt;= R. In this paper we compute the smallest size of
any D(n,1) for n &lt;= 8. We also investigate ``continuous'' and ``banded''
versions of the problem. The latter involves the classical covering numbers
C(n,k,k-1), and we determine the following new values: C(10,5,4) = 51,
C(11,7,6,) =84, C(12,8,7) = 126, C(13,9,8)= 185 and C(14,10,9) = 259. We also
find the number of nonisomorphic minimal covering designs in several cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0206044</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0206044</id><created>2002-06-05</created><authors><author><keyname>Megyesi</keyname><forenames>G&#xe1;bor</forenames><affiliation>UMIST</affiliation></author><author><keyname>Sottile</keyname><forenames>Frank</forenames><affiliation>U Massachusetts, Amherst</affiliation></author><author><keyname>Theobald</keyname><forenames>Thorsten</forenames><affiliation>Technische Universit&#xe4;t M&#xfc;nchen</affiliation></author></authors><title>Common transversals and tangents to two lines and two quadrics in P^3</title><categories>math.AG cs.CG math.AC</categories><comments>26 pages, 9 .eps figures, web page with more pictures and and archive
  of computations: http://www.math.umass.edu/~sottile/pages/2l2s/</comments><msc-class>13P10, 14N10, 14Q15, 51N20, 68U05</msc-class><abstract>  We solve the following geometric problem, which arises in several
three-dimensional applications in computational geometry: For which
arrangements of two lines and two spheres in R^3 are there infinitely many
lines simultaneously transversal to the two lines and tangent to the two
spheres?
  We also treat a generalization of this problem to projective quadrics:
Replacing the spheres in R^3 by quadrics in projective space P^3, and fixing
the lines and one general quadric, we give the following complete geometric
description of the set of (second) quadrics for which the 2 lines and 2
quadrics have infinitely many transversals and tangents: In the
nine-dimensional projective space P^9 of quadrics, this is a curve of degree 24
consisting of 12 plane conics, a remarkably reducible variety.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0206273</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0206273</id><created>2002-06-25</created><updated>2002-08-22</updated><authors><author><keyname>Kapovich</keyname><forenames>Ilya</forenames></author><author><keyname>Myasnikov</keyname><forenames>Alexei</forenames></author><author><keyname>Schupp</keyname><forenames>Paul</forenames></author><author><keyname>Shpilrain</keyname><forenames>Vladimir</forenames></author></authors><title>Average-case complexity and decision problems in group theory</title><categories>math.GR cs.CC math.GT</categories><comments>Some misprints have been corrected</comments><msc-class>20F36</msc-class><abstract>  We investigate the average-case complexity of decision problems for finitely
generated groups, in particular the word and membership problems. Using our
recent results on ``generic-case complexity'' we show that if a finitely
generated group $G$ has the word problem solvable in subexponential time and
has a subgroup of finite index which possesses a non-elementary word-hyperbolic
quotient group, then the average-case complexity of the word problem for $G$ is
linear time, uniformly with respect to the collection of all length-invariant
measures on $G$. For example, the result applies to all braid groups $B_n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0207121</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0207121</id><created>2002-07-15</created><updated>2002-11-20</updated><authors><author><keyname>Bjelakovic</keyname><forenames>Igor</forenames></author><author><keyname>Krueger</keyname><forenames>Tyll</forenames></author><author><keyname>Siegmund-Schultze</keyname><forenames>Rainer</forenames></author><author><keyname>Szkola</keyname><forenames>Arleta</forenames></author></authors><title>The Shannon-McMillan Theorem for Ergodic Quantum Lattice Systems</title><categories>math.DS cs.DS cs.IT math-ph math.IT math.MP math.OA quant-ph</categories><comments>21 pages, extended version concerning subalgebras</comments><msc-class>46L89; 68P30; 81Qxx</msc-class><abstract>  We formulate and prove a quantum Shannon-McMillan theorem. The theorem
demonstrates the significance of the von Neumann entropy for translation
invariant ergodic quantum spin systems on n-dimensional lattices: the entropy
gives the logarithm of the essential number of eigenvectors of the system on
large boxes. The one-dimensional case covers quantum information sources and is
basic for coding theorems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0207135</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0207135</id><created>2002-07-16</created><authors><author><keyname>Babson</keyname><forenames>Eric</forenames></author><author><keyname>Onn</keyname><forenames>Shmuel</forenames></author><author><keyname>Thomas</keyname><forenames>Rekha</forenames></author></authors><title>The Hilbert Zonotope and a Polynomial Time Algorithm for Universal
  Grobner Bases</title><categories>math.CO cs.SC math.AG</categories><journal-ref>Advances in Applied Mathematics, 30:529--544, 2003</journal-ref><abstract>  We provide a polynomial time algorithm for computing the universal Gr\&quot;obner
basis of any polynomial ideal having a finite set of common zeros in fixed
number of variables. One ingredient of our algorithm is an effective
construction of the state polyhedron of any member of the Hilbert scheme
Hilb^d_n of n-long d-variate ideals, enabled by introducing the Hilbert
zonotope H^d_n and showing that it simultaneously refines all state polyhedra
of ideals on Hilb^d_n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0207136</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0207136</id><created>2002-07-16</created><authors><author><keyname>Onn</keyname><forenames>Shmuel</forenames></author></authors><title>Convex Matroid Optimization</title><categories>math.CO cs.DM math.RA</categories><journal-ref>SIAM Journal on Discrete Mathematics, 17:249--253, 2003</journal-ref><abstract>  We consider a problem of optimizing convex functionals over matroid bases. It
is richly expressive and captures certain quadratic assignment and clustering
problems. While generally NP-hard, we show it is polynomial time solvable when
a suitable parameter is restricted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0207146</identifier>
 <datestamp>2014-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0207146</id><created>2002-07-17</created><authors><author><keyname>Sloane</keyname><forenames>N. J. A.</forenames></author><author><keyname>Vaishampayan</keyname><forenames>Vinay A.</forenames></author></authors><title>A Zador-Like Formula for Quantizers Based on Periodic Tilings</title><categories>math.CO cs.IT math.IT</categories><comments>8 pages</comments><msc-class>11H31, 11H06, 52A99, 94A34</msc-class><journal-ref>IEEE Trans. Information Theory 48 (2002), 3138-3140</journal-ref><abstract>  We consider Zador's asymptotic formula for the distortion-rate function for a
variable-rate vector quantizer in the high-rate case. This formula involves the
differential entropy of the source, the rate of the quantizer in bits per
sample, and a coefficient G which depends on the geometry of the quantizer but
is independent of the source. We give an explicit formula for G in the case
when the quantizing regions form a periodic tiling of n-dimensional space, in
terms of the volumes and second moments of the Voronoi cells. As an application
we show, extending earlier work of Kashyap and Neuhoff, that even a
variable-rate three-dimensional quantizer based on the ``A15'' structure is
still inferior to a quantizer based on the body-centered cubic lattice. We also
determine the smallest covering radius of such a structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0207147</identifier>
 <datestamp>2014-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0207147</id><created>2002-07-17</created><authors><author><keyname>Sloane</keyname><forenames>N. J. A.</forenames></author><author><keyname>Beferull-Lozano</keyname><forenames>B.</forenames></author></authors><title>Quantizing Using Lattice Intersections</title><categories>math.CO cs.IT math.IT</categories><comments>26 pages, 9 figures</comments><msc-class>11H31, 11H06, 52A99, 94A34</msc-class><journal-ref>Discrete and Computational Geometry 25 (2003), 799-824</journal-ref><abstract>  The usual quantizer based on an n-dimensional lattice L maps a point x in R^n
to a closest lattice point. Suppose L is the intersection of lattices L_1, ...,
L_r. Then one may instead combine the information obtained by simultaneously
quantizing x with respect to each of the L_i. This corresponds to decomposing
R^n into a honeycomb of cells which are the intersections of the Voronoi cells
for the L_i, and identifying the cell to which x belongs. This paper shows how
to write several standard lattices (the face-centered and body-centered cubic
lattices, the root lattices D_4, E_6*, E_8, the Coxeter-Todd, Barnes-Wall and
Leech lattices, etc.) in a canonical way as intersections of a small number of
simpler, decomposable, lattices. The cells of the honeycombs are given
explicitly and the mean squared quantizing error calculated in the cases when
the intersection lattice is the face-centered or body-centered cubic lattice or
the lattice D_4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0207186</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0207186</id><created>2002-07-21</created><authors><author><keyname>Nebe</keyname><forenames>G.</forenames></author><author><keyname>Rains</keyname><forenames>E. M.</forenames></author><author><keyname>Sloane</keyname><forenames>N. J. A.</forenames></author></authors><title>A Simple Construction for the Barnes-Wall Lattices</title><categories>math.CO cs.IT math.IT</categories><comments>10 pp., 2 figs.; To Dave Forney, on the occasion of his sixtieth
  birthday</comments><msc-class>11H06 (52C99)</msc-class><journal-ref>Codes, Graphs, and Systems: A Celebraton of the Life and Career of
  G. David Forney Jr., ed. R. E. Blahut and R. Koetter, Kluwer, 2002, pp.
  333-342</journal-ref><abstract>  A certain family of orthogonal groups (called &quot;Clifford groups&quot; by G. E.
Wall) has arisen in a variety of different contexts in recent years. These
groups have a simple definition as the automorphism groups of certain
generalized Barnes-Wall lattices. This leads to an especially simple
construction for the usual Barnes-Wall lattices. This is based on the third
author's talk at the Forney-Fest, M.I.T., March 2000, which in turn is based on
our paper &quot;The Invariants of the Clifford Groups&quot;, Designs, Codes, Crypt., 24
(2001), 99--121, to which the reader is referred for further details and
proofs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0207197</identifier>
 <datestamp>2014-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0207197</id><created>2002-07-22</created><authors><author><keyname>Sloane</keyname><forenames>N. J. A.</forenames></author></authors><title>On Single-Deletion-Correcting Codes</title><categories>math.CO cs.IT math.IT</categories><comments>23 pages, 1 figure. Dedicated to Dijen Ray-Chaudhuri on the occasion
  of his 65th birthday</comments><msc-class>94B60, 94A55</msc-class><journal-ref>Codes and Designs, Ohio State University, May 2000 (Ray-Chaudhuri
  Festschrift), K. T. Arasu and A. Seress (editors), Walter de Gruyter, Berlin,
  2002, pp. 273-291</journal-ref><abstract>  This paper gives a brief survey of binary single-deletion-correcting codes.
The Varshamov-Tenengolts codes appear to be optimal, but many interesting
unsolved problems remain. The connections with shift-register sequences also
remain somewhat mysterious.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0207200</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0207200</id><created>2002-07-22</created><authors><author><keyname>De Loera</keyname><forenames>Jesus</forenames></author><author><keyname>Onn</keyname><forenames>Shmuel</forenames></author></authors><title>The Complexity of Three-Way Statistical Tables</title><categories>math.CO cs.DM math.OC</categories><journal-ref>SIAM Journal on Computing, 33:819--836, 2004</journal-ref><abstract>  Multi-way tables with specified marginals arise in a variety of applications
in statistics and operations research. We provide a comprehensive complexity
classification of three fundamental computational problems on tables:
existence, counting and entry-security.
  One major outcome of our work is that each of the following problems is
intractable already for &quot;slim&quot; 3-tables, with constant and smallest possible
number 3 of rows: (1) deciding existence of 3-tables with given consistent
2-marginals; (2) counting all 3-tables with given 2-marginals; (3) finding
whether an integer value is attained in entry (i,j,k) by at least one of the
3-tables satisfying given (feasible) 2-marginals. This implies that a
characterization of feasible marginals for such slim tables, sought by much
recent research, is unlikely to exist.
  Another important consequence of our study is a systematic efficient way of
embedding the set of 3-tables satisfying any given 1-marginals and entry upper
bounds in a set of slim 3-tables satisfying suitable 2-marginals with no entry
bounds. This provides a valuable tool for studying multi-index transportation
problems and multi-index transportation polytopes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0207208</identifier>
 <datestamp>2012-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0207208</id><created>2002-07-23</created><authors><author><keyname>Hammons,</keyname><forenames>A. Roger</forenames><suffix>Jr.</suffix></author><author><keyname>Kumar</keyname><forenames>P. Vijay</forenames></author><author><keyname>Calderbank</keyname><forenames>A. R.</forenames></author><author><keyname>Sloane</keyname><forenames>N. J. A.</forenames></author><author><keyname>Sol&#xe9;</keyname><forenames>Patrick</forenames></author></authors><title>The Z_4-Linearity of Kerdock, Preparata, Goethals and Related Codes</title><categories>math.CO cs.IT math.IT</categories><comments>50 pages, 2 figures</comments><msc-class>94B05 (94B60)</msc-class><journal-ref>IEEE Trans. Inform. Theory, 40 (1994), 301-319</journal-ref><abstract>  Certain notorious nonlinear binary codes contain more codewords than any
known linear code. These include the codes constructed by Nordstrom-Robinson,
Kerdock, Preparata, Goethals, and Delsarte-Goethals. It is shown here that all
these codes can be very simply constructed as binary images under the Gray map
of linear codes over Z_4, the integers mod 4 (although this requires a slight
modification of the Preparata and Goethals codes). The construction implies
that all these binary codes are distance invariant. Duality in the Z_4 domain
implies that the binary images have dual weight distributions. The Kerdock and
&quot;Preparata&quot; codes are duals over Z_4 -- and the Nordstrom-Robinson code is
self-dual -- which explains why their weight distributions are dual to each
other. The Kerdock and &quot;Preparata&quot; codes are Z_4-analogues of first-order
Reed-Muller and extended Hamming codes, respectively. All these codes are
extended cyclic codes over Z_4, which greatly simplifies encoding and decoding.
An algebraic hard-decision decoding algorithm is given for the &quot;Preparata&quot; code
and a Hadamard-transform soft-decision decoding algorithm for the Kerdock code.
Binary first- and second-order Reed-Muller codes are also linear over Z_4, but
extended Hamming codes of length n &gt;= 32 and the Golay code are not. Using
Z_4-linearity, a new family of distance regular graphs are constructed on the
cosets of the &quot;Preparata&quot; code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0207209</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0207209</id><created>2002-07-23</created><authors><author><keyname>Sadjadpour</keyname><forenames>H. R.</forenames></author><author><keyname>Sloane</keyname><forenames>N. J. A.</forenames></author><author><keyname>Salehi</keyname><forenames>M.</forenames></author><author><keyname>Nebe</keyname><forenames>G.</forenames></author></authors><title>Interleaver Design for Turbo Codes</title><categories>math.CO cs.IT math.IT</categories><comments>19 pages, 4 figures</comments><msc-class>94B65 (94B60)</msc-class><journal-ref>IEEE J. Selected Areas Communication, 19 (2001), 831-837</journal-ref><abstract>  The performance of a Turbo code with short block length depends critically on
the interleaver design. There are two major criteria in the design of an
interleaver: the distance spectrum of the code and the correlation between the
information input data and the soft output of each decoder corresponding to its
parity bits. This paper describes a new interleaver design for Turbo codes with
short block length based on these two criteria. A deterministic interleaver
suitable for Turbo codes is also described. Simulation results compare the new
interleaver design to different existing interleavers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0207256</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0207256</id><created>2002-07-26</created><authors><author><keyname>Sloane</keyname><forenames>N. J. A.</forenames></author></authors><title>The Sphere-Packing Problem</title><categories>math.CO cs.IT math.IT</categories><comments>10 pages, 2 figures; invited paper for ICM 1998</comments><msc-class>52C17 (11H31)</msc-class><journal-ref>Documenta Mathematika, Vol. III (1998), 387-396</journal-ref><abstract>  A brief report on recent work on the sphere-packing problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0207291</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0207291</id><created>2002-07-30</created><authors><author><keyname>Edel</keyname><forenames>Yves</forenames></author><author><keyname>Rains</keyname><forenames>E. M.</forenames></author><author><keyname>Sloane</keyname><forenames>N. J. A.</forenames></author></authors><title>On Kissing Numbers in Dimensions 32 to 128</title><categories>math.CO cs.IT math.IT</categories><comments>7 pages</comments><msc-class>94B75, 52C17 (05B40, 11H31, 94B75)</msc-class><journal-ref>Electronic J. Combinatorics, 5 (1), item R22, 1998</journal-ref><abstract>  An elementary construction using binary codes gives new record kissing
numbers in dimensions from 32 to 128.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0208001</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0208001</id><created>2002-07-31</created><authors><author><keyname>Rains</keyname><forenames>E. M.</forenames></author><author><keyname>Sloane</keyname><forenames>N. J. A.</forenames></author></authors><title>Self-Dual Codes</title><categories>math.CO cs.IT math.IT</categories><comments>136 pages</comments><msc-class>94-02 (94B60, 94B65)</msc-class><journal-ref>In Handbook of Coding Theory (ed. V. S. Pless and W. C. Huffman),
  1998, pp. 177-294</journal-ref><abstract>  Self-dual codes are important because many of the best codes known are of
this type and they have a rich mathematical theory. Topics covered in this
survey include codes over F_2, F_3, F_4, F_q, Z_4, Z_m, shadow codes, weight
enumerators, Gleason-Pierce theorem, invariant theory, Gleason theorems,
bounds, mass formulae, enumeration, extremal codes, open problems. There is a
comprehensive bibliography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0208017</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0208017</id><created>2002-08-02</created><authors><author><keyname>Sloane</keyname><forenames>N. J. A.</forenames></author></authors><title>Packing Planes in Four Dimensions and Other Mysteries</title><categories>math.CO cs.IT math.IT</categories><comments>21 pages, 4 figures</comments><msc-class>51E15, 52C17 (51E23, 65Y25)</msc-class><journal-ref>In Algebraic Combinatorics and Related Topics (Yamagata 1997), ed.
  E. Bannai, M. Harada and M. Ozeki, Yamagata University, 1999</journal-ref><abstract>  How should you choose a good set of (say) 48 planes in four dimensions? More
generally, how do you find packings in Grassmannian spaces? In this article I
give a brief introduction to the work that I have been doing on this problem in
collaboration with A. R. Calderbank, J. H. Conway, R. H. Hardin, E. M. Rains
and P. W. Shor. We have found many nice examples of specific packings (70
4-spaces in 8-space, for instance), several general constructions, and an
embedding theorem which shows that a packing in Grassmannian space G(m,n) is a
subset of a sphere in R^D, where D = (m+2)(m-1)/2, and leads to a proof that
many of our packings are optimal. There are a number of interesting unsolved
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0208155</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0208155</id><created>2002-08-21</created><updated>2003-07-30</updated><authors><author><keyname>Joyner</keyname><forenames>David</forenames></author></authors><title>Toric codes over finite fields</title><categories>math.AG cs.IT math.CO math.IT</categories><comments>20 pages, 1 figure Significant revisions to the last 2 sections</comments><msc-class>14M25;94B27</msc-class><abstract>  In this note, a class of error-correcting codes is associated to a toric
variety associated to a fan defined over a finite field $\fff_q$, analogous to
the class of Goppa codes associated to a curve. For such a ``toric code''
satisfying certain additional conditions, we present an efficient decoding
algorithm for the dual of a Goppa code. Many examples are given. For small $q$,
many of these codes have parameters beating the Gilbert-Varshamov bound. In
fact, using toric codes, we construct a $(n,k,d)=(49,11,28)$ code over
$\fff_8$, which is better than any other known code listed in Brouwer's on-line
tables for that $n$ and $k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0209047</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0209047</id><created>2002-09-05</created><authors><author><keyname>Henon</keyname><forenames>Michel</forenames></author></authors><title>A mechanical model for the transportation problem</title><categories>math.OC astro-ph cs.DM cs.NA math.NA</categories><comments>45 pages, 10 figures, 4 tables. This paper was written in 1992, but
  not published (see Addendum for a brief history)</comments><msc-class>65K05 (Primary) 90C08 (Secondary)</msc-class><abstract>  We describe a mechanical device which can be used as an analog computer to
solve the transportation problem. In practice this device is simulated by a
numerical algorithm. Tests show that this algorithm is 60 times faster than a
current subroutine (NAG library) for an average 1000 x 1000 problem. Its
performance is even better for degenerate problems in which the weights take
only a small number of integer values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0209267</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0209267</id><created>2002-09-20</created><updated>2010-10-31</updated><authors><author><keyname>Garber</keyname><forenames>D.</forenames></author><author><keyname>Kaplan</keyname><forenames>S.</forenames></author><author><keyname>Teicher</keyname><forenames>M.</forenames></author><author><keyname>Tsaban</keyname><forenames>B.</forenames></author><author><keyname>Vishne</keyname><forenames>U.</forenames></author></authors><title>Length-based conjugacy search in the Braid group</title><categories>math.GR cs.CR math.AG</categories><comments>Small updates</comments><journal-ref>Contemporary Mathematics 418 (2006), 75--87</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several key agreement protocols are based on the following &quot;Generalized
Conjugacy Search Problem&quot;: Find, given elements b_1,...,b_n and
xb_1x^{-1},...,xb_nx^{-1} in a nonabelian group G, the conjugator x. In the
case of subgroups of the braid group B_N, Hughes and Tannenbaum suggested a
length-based approach to finding x. Since the introduction of this approach,
its effectiveness and successfulness were debated.
  We introduce several effective realizations of this approach. In particular,
a new length function is defined on B_N which possesses significantly better
properties than the natural length associated to the Garside normal form. We
give experimental results concerning the success probability of this approach,
which suggest that very large computational power is required for this method
to successfully solve the Generalized Conjugacy Search Problem when its
parameters are as in existing protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0209316</identifier>
 <datestamp>2010-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0209316</id><created>2002-09-24</created><updated>2004-11-24</updated><authors><author><keyname>Rybnikov</keyname><forenames>Konstantin</forenames><affiliation>University of Massachusetts at Lowell and MSRI</affiliation></author><author><keyname>Zaslavsky</keyname><forenames>Thomas</forenames><affiliation>Binghamton University</affiliation></author></authors><title>Cycle and Circle Tests of Balance in Gain Graphs: Forbidden Minors and
  Their Groups</title><categories>math.CO cs.DM cs.DS</categories><comments>19 pages, 3 figures. Format: Latex2e. Changes: minor. To appear in
  Journal of Graph Theory</comments><msc-class>05C22 (Primary) 05C38 (Secondary)</msc-class><journal-ref>J. Graph Theory, 51 (2006), no. 1, 1--21.</journal-ref><abstract>  We examine two criteria for balance of a gain graph, one based on binary
cycles and one on circles. The graphs for which each criterion is valid depend
on the set of allowed gain groups. The binary cycle test is invalid, except for
forests, if any possible gain group has an element of odd order. Assuming all
groups are allowed, or all abelian groups, or merely the cyclic group of order
3, we characterize, both constructively and by forbidden minors, the graphs for
which the circle test is valid. It turns out that these three classes of groups
have the same set of forbidden minors. The exact reason for the importance of
the ternary cyclic group is not clear.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0209332</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0209332</id><created>2002-09-25</created><authors><author><keyname>Ord</keyname><forenames>Toby</forenames></author></authors><title>Hypercomputation: computing more than the Turing machine</title><categories>math.LO cs.OH math-ph math.MP</categories><comments>57 pages, 9 figures</comments><msc-class>03D10 (Primary) 68Q10, 68Q10, 68Q30 (Secondary)</msc-class><abstract>  Due to common misconceptions about the Church-Turing thesis, it has been
widely assumed that the Turing machine provides an upper bound on what is
computable. This is not so. The new field of hypercomputation studies models of
computation that can compute more than the Turing machine and addresses their
implications. In this report, I survey much of the work that has been done on
hypercomputation, explaining how such non-classical models fit into the
classical theory of computation and comparing their relative powers. I also
examine the physical requirements for such machines to be constructible and the
kinds of hypercomputation that may be possible within the universe. Finally, I
show how the possibility of hypercomputation weakens the impact of Godel's
Incompleteness Theorem and Chaitin's discovery of 'randomness' within
arithmetic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0209407</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0209407</id><created>2002-09-30</created><authors><author><keyname>Anashin</keyname><forenames>Vladimir</forenames><affiliation>Faculty for the Information Security, Russian State University for the Humanities</affiliation></author></authors><title>Uniformly distributed sequences of p-adic integers, II</title><categories>math.NT cs.IT math.DS math.IT</categories><comments>55 pages, no figures, AMSTeX. To appear in Diskretnaya Mathematika
  (Russian), English translation in Diskrete Mathematics (Plenum Publ.)</comments><report-no>IISIS-02-09-01</report-no><msc-class>11K45 (Primary) 37B99; 94A60 (Secondary)</msc-class><journal-ref>Diskret.Mat., vol. 14 (2002), no. 4. pp. 3--64 (Russian); Discrete
  Math. Appl., vol. 12 (2002), no. 6, pp. 527--590 (English translation)</journal-ref><abstract>  The paper describes ergodic (with respect to the Haar measure) functions in
the class of all functions, which are defined on (and take values in) the ring
of p-adic integers, and which satisfy (at least, locally) Lipschitz condition
with coefficient 1. Equiprobable (in particular, measure-preserving) functions
of this class are described also. In some cases (and especially for p=2) the
descriptions are given by explicit formulae. Some of the results may be viewed
as descriptions of ergodic isometric dynamical systems on p-adic unit disk. The
study was motivated by the problem of pseudorandom number generation for
computer simulation and cryptography. From this view the paper describes
nonlinear congruential pseudorandom generators modulo M which produce stricly
periodic uniformly distributed sequences modulo M with maximal possible period
length (i.e., exactly M). Both the state change function and the output
function of these generators could be, e.g., meromorphic functions (in
particular, polynomials with rational, but not necessarily integer
coefficients, or rational functions), or compositions of arithmetical
operations (like addition, multiplication, exponentiation, raising to integer
powers, including negative ones) with standard computer operations, such as
bitwise logical operations (XOR, OR, AND, etc.). The linear complexity of the
produced sequences is also studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0210018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0210018</id><created>2002-10-02</created><authors><author><keyname>Farber</keyname><forenames>Michael</forenames></author><author><keyname>Tabachnikov</keyname><forenames>Serge</forenames></author><author><keyname>Yuzvinsky</keyname><forenames>Sergey</forenames></author></authors><title>Topological robotics: motion planning in projective spaces</title><categories>math.AT cs.RO math.DG</categories><comments>16 pages</comments><abstract>  We study an elementary problem of topological robotics: rotation of a line,
which is fixed by a revolving joint at a base point: one wants to bring the
line from its initial position to a final position by a continuous motion in
the space. The final goal is to construct an algorithm which will perform this
task once the initial and final positions are given.
  Any such motion planning algorithm will have instabilities, which are caused
by topological reasons. A general approach to study instabilities of robot
motion was suggested recently by the first named author. With any
path-connected topological space X one associates a number TC(X), called the
topological complexity of X. This number is of fundamental importance for the
motion planning problem: TC(X) determines character of instabilities which have
all motion planning algorithms in X.
  In the present paper we study the topological complexity of real projective
spaces. In particular we compute TC(RP^n) for all n&lt;24. Our main result is that
(for n distinct from 1, 3, 7) the problem of calculating of TC(RP^n) is
equivalent to finding the smallest k such that RP^n can be immersed into the
Euclidean space R^{k-1}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0210052</identifier>
 <datestamp>2010-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0210052</id><created>2002-10-03</created><updated>2005-01-16</updated><authors><author><keyname>Rybnikov</keyname><forenames>Konstantin</forenames></author><author><keyname>Zaslavsky</keyname><forenames>Thomas</forenames></author></authors><title>Criteria for Balance in Abelian Gain Graphs, with Applications to
  Piecewise-Linear Geometry</title><categories>math.CO cs.CG cs.DM cs.DS math.AT</categories><comments>Changes(28 Dec. 2004): revised title and abstract; shortened, mainly
  by omitting inessentials; minor errors fixed. Changes (16 Jan. 2005):
  ADDED--Appendix with detailes on some proofs and another counterexample with
  picture, a few references. Minor typo and notation fixes. To appear in
  Discrete &amp; Comput. Geometry (without Appendix and extra references)</comments><msc-class>Primary: 05C22, 52C25; Secondary: 05C38, 52C25, 52C22</msc-class><journal-ref>Discrete and Computational Geometry, 34 (2005), no. 2, 251-268.</journal-ref><abstract>  A gain graph is a triple (G,h,H), where G is a connected graph with an
arbitrary, but fixed, orientation of edges, H is a group, and h is a
homomorphism from the free group on the edges of G to H. A gain graph is called
balanced if the h-image of each closed walk on G is the identity.
  Consider a gain graph with abelian gain group having no odd torsion. If there
is a basis of the graph's binary cycle space each of whose members can be
lifted to a closed walk whose gain is the identity, then the gain graph is
balanced, provided that the graph is finite or the group has no nontrivial
infinitely 2-divisible elements. We apply this theorem to deduce a result on
the projective geometry of piecewise-linear realizations of cell-decompositions
of manifolds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0210115</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0210115</id><created>2002-10-08</created><authors><author><keyname>Farber</keyname><forenames>Michael</forenames></author><author><keyname>Yuzvinsky</keyname><forenames>Sergey</forenames></author></authors><title>Topological Robotics: Subspace Arrangements and Collision Free Motion
  Planning</title><categories>math.AT cs.RO math.DG</categories><comments>11 pages</comments><abstract>  We study an elementary problem of the topological robotics: collective motion
of a set of $n$ distinct particles which one has to move from an initial
configuration to a final configuration, with the requirement that no collisions
occur in the process of motion. The ultimate goal is to construct an algorithm
which will perform this task once the initial and the final configurations are
given. This reduces to a topological problem of finding the topological
complexity TC(C_n(\R^m)) of the configutation space C_n(\R^m) of $n$ distinct
ordered particles in \R^m. We solve this problem for m=2 (the planar case) and
for all odd m, including the case m=3 (particles in the three-dimensional
space). We also study a more general motion planning problem in Euclidean space
with a hyperplane arrangement as obstacle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0210408</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0210408</id><created>2002-10-26</created><updated>2004-04-18</updated><authors><author><keyname>Joyner</keyname><forenames>David</forenames></author><author><keyname>Traves</keyname><forenames>Will</forenames></author></authors><title>Representations of finite groups on Riemann-Roch spaces</title><categories>math.AG cs.IT math.GR math.IT</categories><comments>24 pages, significant revision</comments><msc-class>14H37; 20C20; 94B27; 11T71; 05E20</msc-class><abstract>  We study the action of a finite group on the Riemann-Roch space of certain
divisors on a curve. If $G$ is a finite subgroup of the automorphism group of a
projective curve $X$ over an algebraically closed field and $D$ is a divisor on
$X$ left stable by $G$ then we show the irreducible constituents of the natural
representation of $G$ on the Riemann-Roch space $L(D)=L_X(D)$ are of dimension
$\leq d$, where $d$ is the size of the smallest $G$-orbit acting on $X$. We
give an example to show that this is, in general, sharp (i.e., that dimension
$d$ irreducible constituents can occur). Connections with coding theory, in
particular to permutation decoding of AG codes, are discussed in the last
section. Many examples are included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0211040</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0211040</id><created>2002-11-04</created><authors><author><keyname>Gluesing-Luerssen</keyname><forenames>H.</forenames></author><author><keyname>Schmale</keyname><forenames>W.</forenames></author></authors><title>On cyclic convolutional codes</title><categories>math.RA cs.IT math.CO math.IT</categories><comments>50 pages</comments><msc-class>94B10, 94B15, 16S36</msc-class><abstract>  We investigate the notion of cyclicity for convolutional codes as it has been
introduced by Piret and Roos in the seventies. Codes of this type are described
as submodules of the module of all vector polynomials in one variable with some
additional generalized cyclic structure but also as specific left ideals in a
skew polynomial ring. Extending a result of Piret, we show in a purely
algebraic setting that these ideals are always principal. This leads to the
notion of a generator polynomial just like for cyclic block codes. Similarly a
control polynomial can be introduced by considering the right annihilator
ideal. An algorithmic procedure is developed which produces unique reduced
generator and control polynomials. We also show how basic code properties and a
minimal generator matrix can be read off from these objects. A close link
between polynomial and vector description of the codes is provided by certain
generalized circulant matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0211107</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0211107</id><created>2002-11-06</created><authors><author><keyname>Giulietti</keyname><forenames>Massimo</forenames></author></authors><title>On Near-MDS Elliptic Codes</title><categories>math.AG cs.IT math.CO math.IT</categories><comments>Latex 2e, 13 pages</comments><msc-class>51E22;14H52</msc-class><abstract>  The main conjecture on maximum distance separable (MDS) codes states that,
execpt for some special cases, the maximum length of a q-ary linear MDS code is
q+1. This conjecture does not hold true for near maximum distance separable
codes because of the existence of q-ary near MDS elliptic codes having length
bigger than q+1. An interesting related question is whether a near MDS elliptic
code can be extended to a longer near MDS code. Our results are some
non-extendability results and an alternative and simpler construction for
certain known near MDS elliptic codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0211156</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0211156</id><created>2002-11-09</created><authors><author><keyname>Fiedler</keyname><forenames>B.</forenames></author></authors><title>Ideal decompositions and computation of tensor normal forms</title><categories>math.CO cs.SC math.DG</categories><comments>16 pages</comments><msc-class>16D60; 15A72; 05E10; 16D70; 16S50; 05-04</msc-class><journal-ref>Seminaire Lotharingien de Combinatoire, 45 (2001) Article B45g.
  http://www.mat.univie.ac.at/~slc/wpapers/s45fiedler.html</journal-ref><abstract>  Symmetry properties of r-times covariant tensors T can be described by
certain linear subspaces W of the group ring K[S_r] of a symmetric group S_r.
If for a class of tensors T such a W is known, the elements of the orthogonal
subspace W^{\bot} of W within the dual space of K[S_r] yield linear identities
needed for a treatment of the term combination problem for the coordinates of
the T. We give the structure of these W for every situation which appears in
symbolic tensor calculations by computer. Characterizing idempotents of such W
can be determined by means of an ideal decomposition algorithm which works in
every semisimple ring up to an isomorphism. Furthermore, we use tools such as
the Littlewood-Richardson rule, plethysms and discrete Fourier transforms for
S_r to increase the efficience of calculations. All described methods were
implemented in a Mathematica package called PERMS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0211267</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0211267</id><created>2002-11-18</created><authors><author><keyname>Kulesza</keyname><forenames>Kamil</forenames></author><author><keyname>Kotulski</keyname><forenames>Zbigniew</forenames></author><author><keyname>Pieprzyk</keyname><forenames>Joseph</forenames></author></authors><title>On alternative approach for verifiable secret sharing</title><categories>math.CO cs.CR cs.DM</categories><comments>This is poster that was presented on ESORICS2002 conference in
  Zurich. It consists of 4 color pages, with proposal and flowcharts</comments><msc-class>D.4.6; E.4</msc-class><abstract>  Secret sharing allows split/distributed control over the secret (e.g. master
key). Verifiable secret sharing (VSS) is the secret sharing extended by
verification capacity.
 Usually verification comes at the price. We propose &quot;free lunch&quot;, the approach
that allows to overcome this inconvenience.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0211269</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0211269</id><created>2002-11-18</created><updated>2002-11-20</updated><authors><author><keyname>Kulesza</keyname><forenames>Kamil</forenames></author><author><keyname>Kotulski</keyname><forenames>Zbigniew</forenames></author></authors><title>On ASGS framework: general requirements and an example of implementation</title><categories>math.CO cs.CR cs.DM cs.IT math.IT</categories><comments>8 pages paper with 9 pages appendixes. Keywords: cryptography, secret
  sharing, data security, extended capabilities, extended key verification
  protocol</comments><msc-class>D.4.6; E.4</msc-class><abstract>  In the paper we propose general framework for Automatic Secret Generation and
Sharing (ASGS) that should be independent of underlying secret sharing scheme.
ASGS allows to prevent the dealer from knowing the secret or even to eliminate
him at all. Two situations are discussed. First concerns simultaneous
generation and sharing of the random, prior nonexistent secret. Such a secret
remains unknown until it is reconstructed. Next, we propose the framework for
automatic sharing of a known secret. In this case the dealer does not know the
secret and the secret owner does not know the shares. We present opportunities
for joining ASGS with other extended capabilities, with special emphasize on
PVSS and proactive secret sharing. Finally, we illustrate framework with
practical implementation.
  Keywords: cryptography, secret sharing, data security, extended capabilities,
extended key verification protocol
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0211307</identifier>
 <datestamp>2015-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0211307</id><created>2002-11-19</created><updated>2003-02-03</updated><authors><author><keyname>Drakakis</keyname><forenames>Konstantinos</forenames></author><author><keyname>Radulovic</keyname><forenames>Dragan</forenames></author></authors><title>On the multiresolution structure of Internet traffic traces</title><categories>math.PR cs.NI</categories><comments>57 pages, color figures. Figures are of low quality due to space
  considerations</comments><msc-class>60G35</msc-class><doi>10.1117/12.475274</doi><abstract>  Internet traffic on a network link can be modeled as a stochastic process.
After detecting and quantifying the properties of this process, using
statistical tools, a series of mathematical models is developed, culminating in
one that is able to generate ``traffic'' that exhibits --as a key feature-- the
same difference in behavior for different time scales, as observed in real
traffic, and is moreover indistinguishable from real traffic by other
statistical tests as well. Tools inspired from the models are then used to
determine and calibrate the type of activity taking place in each of the time
scales. Surprisingly, the above procedure does not require any detailed
information originating from either the network dynamics, or the decomposition
of the total traffic into its constituent user connections, but rather only the
compliance of these connections to very weak conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0211317</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0211317</id><created>2002-11-20</created><authors><author><keyname>Kulesza</keyname><forenames>Kamil</forenames></author><author><keyname>Kotulski</keyname><forenames>Zbigniew</forenames></author></authors><title>On graph coloring check-digit method</title><categories>math.CO cs.CR cs.DM cs.DS</categories><comments>7 pages, paper sumitted to Applied Mathematics Letters (Elsevier)</comments><msc-class>D.4.6; E.4</msc-class><abstract>  We show a method how to convert any graph into the binary number and vice
versa. We derive upper bound for maximum number of graphs, that, have fixed
number of vertices and can be colored with n colors (n is any given number).
Proof for the result is outlined. Next, graph coloring based check-digit scheme
is proposed. We use quantitative result derived, to show, that feasibility of
the proposed scheme increases with size of the number which digits are checked,
and overall probability of digits errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0211344</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0211344</id><created>2002-11-21</created><authors><author><keyname>Brandenberg</keyname><forenames>R.</forenames><affiliation>Technische Universitaet Muenchen</affiliation></author><author><keyname>Theobald</keyname><forenames>T.</forenames><affiliation>Technische Universitaet Muenchen</affiliation></author></authors><title>Algebraic methods for computing smallest enclosing and circumscribing
  cylinders of simplices</title><categories>math.OC cs.CG</categories><comments>4 figures</comments><msc-class>51N20; 52B55; 68U05; 68W30; 90C90</msc-class><abstract>  We provide an algebraic framework to compute smallest enclosing and smallest
circumscribing cylinders of simplices in Euclidean space $\E^n$. Explicitly,
the computation of a smallest enclosing cylinder in $\mathbb{E}^3$ is reduced
to the computation of a smallest circumscribing cylinder. We improve existing
polynomial formulations to compute the locally extreme circumscribing cylinders
in $\E^3$ and exhibit subclasses of simplices where the algebraic degrees can
be further reduced. Moreover, we generalize these efficient formulations to the
$n$-dimensional case and provide bounds on the number of local extrema. Using
elementary invariant theory, we prove structural results on the direction
vectors of any locally extreme circumscribing cylinder for regular simplices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0212038</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0212038</id><created>2002-12-03</created><authors><author><keyname>Munuera</keyname><forenames>Carlos</forenames></author><author><keyname>Torres</keyname><forenames>Fernando</forenames></author></authors><title>A Goppa-like bound on the trellis state complexity of algebraic
  geometric codes</title><categories>math.AG cs.IT math.IT</categories><comments>LaTeX, 13 pages, IEEE Trans. Inform. Theory: to appear, available at
  http://www.ime.unicamp.br/~ftorres</comments><msc-class>94B05, 94B27, 14G50</msc-class><abstract>  For a linear code $\cC$ of length $n$ and dimension $k$, Wolf noticed that
the trellis state complexity $s(\cC)$ of $\cC$ is upper bounded by
$w(\cC):=\min(k,n-k)$. In this paper we point out some new lower bounds for
$s(\cC)$. In particular, if $\cC$ is an Algebraic Geometric code, then
$s(\cC)\geq w(\cC)-(g-a)$, where $g$ is the genus of the underlying curve and
$a$ is the abundance of the code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0212044</identifier>
 <datestamp>2008-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0212044</id><created>2002-12-03</created><updated>2008-04-18</updated><authors><author><keyname>Sottile</keyname><forenames>Frank</forenames></author></authors><title>Toric ideals, real toric varieties, and the algebraic moment map</title><categories>math.AG cs.CG</categories><comments>Corrected the discussion in the published version about the moment
  map, and changed the title from &quot;Toric ideals, real toric varieties, and the
  moment map&quot;. This should be the definitive version</comments><msc-class>14M25, 14Q99, 13P10, 68U05, 68U07; ACM I.3.5</msc-class><journal-ref>in Topics in Algebraic Geometry and Geometric Modeling, Contemp.
  Math., 334, 2003., pp.225-240</journal-ref><abstract>  This is a tutorial on some aspects of toric varieties related to their
potential use in geometric modeling. We discuss projective toric varieties and
their ideals, as well as real toric varieties and the algebraic moment map. In
particular, we explain the relation between linear precision and the algebraic
moment map. This builds on the introduction to toric varieties by David Cox:
What is a Toric Variety? at http://www.cs.amherst.edu/~dac/lectures/tutorial.ps
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0212212</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0212212</id><created>2002-12-16</created><authors><author><keyname>Cortes</keyname><forenames>J.</forenames></author><author><keyname>Martinez</keyname><forenames>S.</forenames></author><author><keyname>Karatas</keyname><forenames>T.</forenames></author><author><keyname>Bullo</keyname><forenames>F.</forenames></author></authors><title>Coverage control for mobile sensing networks</title><categories>math.OC cs.IT math.IT</categories><comments>13 pages; double column; 6 figures; submitted to IEEE Transactions on
  Robotics and Automation</comments><msc-class>68W15; 49N90; 93B52; 51M20; 70E60</msc-class><journal-ref>IEEE Transactions on Robotics and Automation 20 (2) (2004),
  243-255</journal-ref><abstract>  This paper presents control and coordination algorithms for groups of
vehicles. The focus is on autonomous vehicle networks performing distributed
sensing tasks where each vehicle plays the role of a mobile tunable sensor. The
paper proposes gradient descent algorithms for a class of utility functions
which encode optimal coverage and sensing policies. The resulting closed-loop
behavior is adaptive, distributed, asynchronous, and verifiably correct.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0212278</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0212278</id><created>2002-12-19</created><updated>2002-12-23</updated><authors><author><keyname>Fiedler</keyname><forenames>B.</forenames></author></authors><title>Determination of the structure of algebraic curvature tensors by means
  of Young symmetrizers</title><categories>math.CO cs.SC math.DG</categories><comments>19 pages. To appear Seminaire Lotharingien de Combinatoire:
  http://www.mat.univie.ac.at/~slc/</comments><msc-class>53B20, 15A72, 05E10, 16D60, 05-04</msc-class><journal-ref>Seminaire Lotharingien de Combinatoire, 48 (2003) Article B48d</journal-ref><abstract>  For a positive definite fundamental tensor all known examples of Osserman
algebraic curvature tensors have a typical structure. They can be produced from
a metric tensor and a finite set of skew-symmetric matrices which fulfil
Clifford commutation relations. We show by means of Young symmetrizers and a
theorem of S. A. Fulling, R. C. King, B. G. Wybourne and C. J. Cummins that
every algebraic curvature tensor has a structure which is very similar to that
of the above Osserman curvature tensors. We verify our results by means of the
Littlewood-Richardson rule and plethysms. For certain symbolic calculations we
used the Mathematica packages MathTensor, Ricci and PERMS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0301042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0301042</id><created>2003-01-06</created><authors><author><keyname>Fiedler</keyname><forenames>B.</forenames></author></authors><title>On the symmetry classes of the first covariant derivatives of tensor
  fields</title><categories>math.CO cs.SC math.DG</categories><comments>21 pages. Sent in to Seminaire Lotharingien de Combinatoire:
  http://www.mat.univie.ac.at/~slc/</comments><msc-class>53B20, 15A72, 05E10, 16D60, 05-04</msc-class><journal-ref>Seminaire Lotharingien de Combinatoire, 49 (2003) Article B49f</journal-ref><abstract>  We show that the symmetry classes of torsion-free covariant derivatives
$\nabla T$ of r-times covariant tensor fields T can be characterized by
Littlewood-Richardson products $\sigma [1]$ where $\sigma$ is a representation
of the symmetric group $S_r$ which is connected with the symmetry class of T.
If $\sigma = [\lambda]$ is irreducible then $\sigma [1]$ has a multiplicity
free reduction $[\lambda][1] = \sum [\mu]$ and all primitive idempotents
belonging to that sum can be calculated from a generating idempotent e of the
symmetry class of T by means of the irreducible characters or of a discrete
Fourier transform of $S_{r+1}$. We apply these facts to derivatives $\nabla S$,
$\nabla A$ of symmetric or alternating tensor fields. The symmetry classes of
the differences $\nabla S - sym(\nabla S)$ and $\nabla A - alt(\nabla A)$ are
characterized by Young frames (r, 1) and (2, 1^{r-1}), respectively. However,
while the symmetry class of $\nabla A - alt(\nabla A)$ can be generated by
Young symmetrizers of (2, 1^{r-1}), no Young symmetrizer of (r, 1) generates
the symmetry class of $\nabla S - sym(\nabla S)$. Furthermore we show in the
case r = 2 that $\nabla S - sym(\nabla S)$ and $\nabla A - alt(\nabla A)$ can
be applied in generator formulas of algebraic covariant derivative curvature
tensors. For certain symbolic calculations we used the Mathematica packages
Ricci and PERMS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0301135</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0301135</id><created>2003-01-13</created><authors><author><keyname>Strohmer</keyname><forenames>Thomas</forenames></author><author><keyname>Heath</keyname><forenames>Robert</forenames></author></authors><title>Grassmannian Frames with Applications to Coding and Communication</title><categories>math.FA cs.IT math.IT</categories><comments>Submitted in June 2002 to Appl. Comp. Harm. Anal</comments><proxy>waage</proxy><abstract>  For a given class ${\cal F}$ of uniform frames of fixed redundancy we define
a Grassmannian frame as one that minimizes the maximal correlation $|&lt; f_k,f_l
&gt;|$ among all frames $\{f_k\}_{k \in {\cal I}} \in {\cal F}$. We first analyze
finite-dimensional Grassmannian frames. Using links to packings in Grassmannian
spaces and antipodal spherical codes we derive bounds on the minimal achievable
correlation for Grassmannian frames. These bounds yield a simple condition
under which Grassmannian frames coincide with uniform tight frames. We exploit
connections to graph theory, equiangular line sets, and coding theory in order
to derive explicit constructions of Grassmannian frames. Our findings extend
recent results on uniform tight frames. We then introduce infinite-dimensional
Grassmannian frames and analyze their connection to uniform tight frames for
frames which are generated by group-like unitary systems. We derive an example
of a Grassmannian Gabor frame by using connections to sphere packing theory.
Finally we discuss the application of Grassmannian frames to wireless
communication and to multiple description coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0301211</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0301211</id><created>2003-01-20</created><authors><author><keyname>Raghavendra</keyname><forenames>N.</forenames></author></authors><title>Binary trees and fibred categories</title><categories>math.CO cs.DM math.CT</categories><comments>19 pages</comments><msc-class>05C05 (Primary) 18D30, 05C62, 18B20, 68Q85 (Secondary)</msc-class><abstract>  We develop a purely set-theoretic formalism for binary trees and binary
graphs. We define a category of binary automata, and display it as a fibred
category over the category of binary graphs. We also relate the notion of
binary graphs to transition systems, which arise in the theory of concurrent
computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0301268</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0301268</id><created>2003-01-23</created><authors><author><keyname>Wolpert</keyname><forenames>David</forenames></author><author><keyname>Tumer</keyname><forenames>Kagan</forenames></author><author><keyname>Bandari</keyname><forenames>Esfandiar</forenames></author></authors><title>Improving Search Algorithms by Using Intelligent Coordinates</title><categories>math.OC cond-mat.stat-mech cs.MA nlin.AO</categories><doi>10.1103/PhysRevE.69.017701</doi><abstract>  We consider the problem of designing a set of computational agents so that as
they all pursue their self-interests a global function G of the collective
system is optimized. Three factors govern the quality of such design. The first
relates to conventional exploration-exploitation search algorithms for finding
the maxima of such a global function, e.g., simulated annealing. Game-theoretic
algorithms instead are related to the second of those factors, and the third is
related to techniques from the field of machine learning. Here we demonstrate
how to exploit all three factors by modifying the search algorithm's
exploration stage so that rather than by random sampling, each coordinate of
the underlying search space is controlled by an associated
machine-learning-based ``player'' engaged in a non-cooperative game.
Experiments demonstrate that this modification improves SA by up to an order of
magnitude for bin-packing and for a model of an economic process run over an
underlying network. These experiments also reveal novel small worlds phenomena.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0301274</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0301274</id><created>2003-01-24</created><updated>2003-10-12</updated><authors><author><keyname>Ord</keyname><forenames>Toby</forenames></author><author><keyname>Kieu</keyname><forenames>Tien D.</forenames></author></authors><title>On the existence of a new family of Diophantine equations for $\bf
  \Omega$</title><categories>math.NT cs.CC quant-ph</categories><journal-ref>Fundamenta Informaticae 56 (2003) 273--284</journal-ref><abstract>  We show how to determine the $k$-th bit of Chaitin's algorithmically random
real number $\Omega$ by solving $k$ instances of the halting problem. From this
we then reduce the problem of determining the $k$-th bit of $\Omega$ to
determining whether a certain Diophantine equation with two parameters, $k$ and
$N$, has solutions for an odd or an even number of values of $N$. We also
demonstrate two further examples of $\Omega$ in number theory: an exponential
Diophantine equation with a parameter $k$ which has an odd number of solutions
iff the $k$-th bit of $\Omega$ is 1, and a polynomial of positive integer
variables and a parameter $k$ that takes on an odd number of positive values
iff the $k$-th bit of $\Omega$ is 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0302043</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0302043</id><created>2003-02-04</created><authors><author><keyname>Klein</keyname><forenames>Andreas</forenames></author><author><keyname>Wessler</keyname><forenames>Markus</forenames></author></authors><title>Extended visual cryptography systems</title><categories>math.CO cs.IT math.IT</categories><comments>10 pages</comments><abstract>  Visual cryptography schemes have been introduced in 1994 by Naor and Shamir.
Their idea was to encode a secret image into $n$ shadow images and to give
exactly one such shadow image to each member of a group $P$ of $n$ persons.
Whereas most work in recent years has been done concerning the problem of
qualified and forbidden subsets of $P$ or the question of contrast optimizing,
in this paper we study extended visual cryptography schemes, i.e. shared secret
systems where any subset of $P$ shares its own secret.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0302132</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0302132</id><created>2003-02-11</created><authors><author><keyname>Duursma</keyname><forenames>I. M.</forenames></author><author><keyname>Greferath</keyname><forenames>M.</forenames></author></authors><title>Computing Symmetrized Weight Enumerators for Lifted Quadratic Residue
  Codes</title><categories>math.CO cs.IT math.IT</categories><comments>9 pages</comments><msc-class>94B60</msc-class><abstract>  The paper describes a method to determine symmetrized weight enumerators of
$p^m$-linear codes based on the notion of a disjoint weight enumerator.
Symmetrized weight enumerators are given for the lifted quadratic residue codes
of length 24 modulo $2^m$ and modulo $3^m$, for any positive $m$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0302154</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0302154</id><created>2003-02-12</created><authors><author><keyname>Duursma</keyname><forenames>I. M.</forenames></author></authors><title>Twisted Klein curves modulo 2</title><categories>math.NT cs.IT math.AG math.IT</categories><comments>14 pages</comments><msc-class>14H45</msc-class><abstract>  We give an explicit description of all 168 quartic curves over the field of
two elements that are isomorphic to the Klein curve over an algebraic
extension. Some of the curves have been known for their small class number,
others for attaining the maximal number of rational points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0302172</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0302172</id><created>2003-02-14</created><authors><author><keyname>Duursma</keyname><forenames>I. M.</forenames></author></authors><title>Results on zeta functions for codes</title><categories>math.CO cs.IT math.IT math.NT</categories><comments>12 pages</comments><msc-class>05B35; 14G15; 94B65</msc-class><abstract>  We give a new and short proof of the Mallows-Sloane upper bound for self-dual
codes. We formulate a version of Greene's theorem for normalized weight
enumerators. We relate normalized rank-generating polynomials to two-variable
zeta functions. And we show that a self-dual code has the Clifford property,
but that the same property does not hold in general for formally self-dual
codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0302303</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0302303</id><created>2003-02-25</created><updated>2003-04-07</updated><authors><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author><author><keyname>Wang</keyname><forenames>Ming-wei</forenames></author></authors><title>Cubefree binary words avoiding long squares</title><categories>math.CO cs.DM</categories><comments>PLEASE NOTE: After this paper was prepared, we learned that all our
  results appeared (albeit with different proofs) in a paper of F. M. Dekking,
  On repetitions of blocks in binary sequences, J. Combin. Theory Ser. A 20
  (1976), 292--299</comments><msc-class>68R15</msc-class><abstract>  Entringer, Jackson, and Schatz conjectured in 1974 that every infinite
cubefree binary word contains arbitrarily long squares. In this paper we show
this conjecture is false: there exist infinite cubefree binary words avoiding
all squares xx with |x| &gt;= 4, and the number 4 is best possible. However, the
Entringer-Jackson-Schatz conjecture is true if &quot;cubefree&quot; is replaced with
&quot;overlap-free&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0302315</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0302315</id><created>2003-02-25</created><updated>2003-03-20</updated><authors><author><keyname>Croot</keyname><forenames>Ernie</forenames></author></authors><title>Memory Efficient Arithmetic</title><categories>math.NT cs.DS</categories><comments>Difference between this version and last: Better notation, light
  corrections, and more explanations</comments><msc-class>11Y70</msc-class><abstract>  In this paper we give an algorithm for computing the mth base-b digit (m=1 is
the least significant digit) of an integer n (actually, it finds sharp
approximations to n/b^m mod 1), where n is defined as the last number in a
sequence of integers s1,s2,...,sL=n, where s1=0, s2=1, and each successive si
is either the sum, product, or difference of two previous sj's in the sequence.
In many cases, the algorithm will find this mth digit using far less memory
than it takes to write down all the base-b digits of n, while the number of bit
operations will grow only slighly worse than linear in the number of digits.
  One consequence of this result is that the mth base-10 digit of 2^t can be
found using O(t^{2/3} log^C t) bits of storage (for some C&gt;0), and O(t log^C t)
bit operations.
  The algorithm is also highly parallelizable, and an M-fold reduction in
running time can be achieved using M processors, although the memory required
will then grow by a factor of M.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0303104</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0303104</id><created>2003-03-08</created><authors><author><keyname>Munuera</keyname><forenames>Carlos</forenames></author><author><keyname>Torres</keyname><forenames>Fernando</forenames></author></authors><title>Bounding the trellis state complexity of algebraic geometric codes</title><categories>math.AG cs.IT math.IT</categories><comments>LaTeX, 14 pages, available at http://www.ime.unicamp.br/~ftorres</comments><msc-class>94B05, 94B27, 14G50</msc-class><abstract>  Let C be an algebraic geometric code of dimension k and length n constructed
on a curve X over $F_q$. Let s(C) be the state complexity of C and set
w(C):=min{k,n-k}, the Wolf upper bound on s(C). We introduce a numerical
function R that depends on the gonality sequence of X and show that s(C)\geq
w(C)-R(2g-2), where g is the genus of X. As a matter of fact, R(2g-2)\leq
g-(\gamma_2-2) with \gamma_2 being the gonality over F_q of X, and thus in
particular we have that s(C)\geq w(C)-g+\gamma_2-2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0303254</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0303254</id><created>2003-03-20</created><authors><author><keyname>Gluesing-Luerssen</keyname><forenames>Heide</forenames></author><author><keyname>Rosenthal</keyname><forenames>Joachim</forenames></author><author><keyname>Smarandache</keyname><forenames>Roxana</forenames></author></authors><title>Strongly MDS Convolutional Codes</title><categories>math.RA cs.IT math.IT math.OC</categories><comments>33 pages</comments><msc-class>94B10 (Primary) 94B65, 11T71 (Secondary)</msc-class><abstract>  MDS convolutional codes have the property that their free distance is maximal
among all codes of the same rate and the same degree. In this paper we
introduce a class of MDS convolutional codes whose column distances reach the
generalized Singleton bound at the earliest possible instant. We call these
codes strongly MDS convolutional codes. It is shown that these codes can decode
a maximum number of errors per time interval when compared with other
convolutional codes of the same rate and degree. These codes have also a
maximum or near maximum distance profile. A code has a maximum distance profile
if and only if the dual code has this property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0303386</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0303386</id><created>2003-03-31</created><updated>2004-08-27</updated><authors><author><keyname>Kapovich</keyname><forenames>Ilya</forenames></author><author><keyname>Schupp</keyname><forenames>Paul</forenames></author><author><keyname>Shpilrain</keyname><forenames>Vladimir</forenames></author></authors><title>Generic properties of Whitehead's Algorithm and isomorphism rigidity of
  random one-relator groups</title><categories>math.GR cs.CC math.GT</categories><comments>final revised version, to appear in Pacific J. Math</comments><msc-class>20F36</msc-class><abstract>  We prove that Whitehead's algorithm for solving the automorphism problem in a
fixed free group $F_k$ has strongly linear time generic-case complexity. This
is done by showing that the ``hard'' part of the algorithm terminates in linear
time on an exponentially generic set of input pairs. We then apply these
results to one-relator groups. We obtain a Mostow-type isomorphism rigidity
result for random one-relator groups: If two such groups are isomorphic then
their Cayley graphs on the \emph{given generating sets} are isometric. Although
no nontrivial examples were previously known, we prove that one-relator groups
are generically \emph{complete} groups, that is, they have trivial center and
trivial outer automorphism group. We also prove that the stabilizers of generic
elements of $F_k$ in $Aut(F_k)$ are cyclic groups generated by inner
automorphisms and that $Aut(F_k)$-orbits are uniformly small in the sense of
their growth entropy. We further prove that the number $I_k(n)$ of
\emph{isomorphism types} of $k$-generator one-relator groups with defining
relators of length $n$ satisfies \[ \frac{c_1}{n} (2k-1)^n \le I_k(n)\le
\frac{c_2}{n} (2k-1)^n, \] where $c_1=c_1(k)&gt;0, c_2=c_2(k)&gt;0$ are some
constants independent of $n$. Thus $I_k(n)$ grows in essentially the same
manner as the number of cyclic words of length $n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0304095</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0304095</id><created>2003-04-07</created><authors><author><keyname>Karhumaki</keyname><forenames>Juhani</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>Polynomial versus Exponential Growth in Repetition-Free Binary Words</title><categories>math.CO cs.DM</categories><comments>12 pages</comments><msc-class>68R15</msc-class><abstract>  It is known that the number of overlap-free binary words of length n grows
polynomially, while the number of cubefree binary words grows exponentially. We
show that the dividing line between polynomial and exponential growth is 7/3.
More precisely, there are only polynomially many binary words of length n that
avoid 7/3-powers, but there are exponentially many binary words of length n
that avoid (7/3+)-powers. This answers an open question of Kobayashi from 1986.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0304100</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0304100</id><created>2003-04-07</created><updated>2003-04-09</updated><authors><author><keyname>Rojas</keyname><forenames>J. Maurice</forenames></author></authors><title>A Direct Ultrametric Approach to Additive Complexity and the Shub-Smale
  Tau Conjecture</title><categories>math.NT cs.CC</categories><comments>9 pages, no figures. Submitted for publication</comments><abstract>  The Shub-Smale Tau Conjecture is a hypothesis relating the number of integral
roots of a polynomial f in one variable and the Straight-Line Program (SLP)
complexity of f. A consequence of the truth of this conjecture is that, for the
Blum-Shub-Smale model over the complex numbers, P differs from NP. We prove two
weak versions of the Tau Conjecture and in so doing show that the Tau
Conjecture follows from an even more plausible hypothesis.
  Our results follow from a new p-adic analogue of earlier work relating real
algebraic geometry to additive complexity. For instance, we can show that a
nonzero univariate polynomial of additive complexity s can have no more than
15+s^3(s+1)(7.5)^s s! =O(e^{s\log s}) roots in the 2-adic rational numbers Q_2,
thus dramatically improving an earlier result of the author. This immediately
implies the same bound on the number of ordinary rational roots, whereas the
best previous upper bound via earlier techniques from real algebraic geometry
was a quantity in Omega((22.6)^{s^2}).
  This paper presents another step in the author's program of establishing an
algorithmic arithmetic version of fewnomial theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0304192</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0304192</id><created>2003-04-15</created><authors><author><keyname>Boutin</keyname><forenames>Mireille</forenames></author><author><keyname>Kemper</keyname><forenames>Gregor</forenames></author></authors><title>On reconstructing n-point configurations from the distribution of
  distances or areas</title><categories>math.AC cs.CV cs.SC</categories><comments>21 pages, latex</comments><msc-class>13A50;13-04;68T45</msc-class><abstract>  One way to characterize configurations of points up to congruence is by
considering the distribution of all mutual distances between points. This paper
deals with the question if point configurations are uniquely determined by this
distribution. After giving some counterexamples, we prove that this is the case
for the vast majority of configurations. In the second part of the paper, the
distribution of areas of sub-triangles is used for characterizing point
configurations. Again it turns out that most configurations are reconstructible
from the distribution of areas, though there are counterexamples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0304283</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0304283</id><created>2003-04-20</created><authors><author><keyname>Miasnikov</keyname><forenames>Alexei D.</forenames></author><author><keyname>Myasnikov</keyname><forenames>Alexei G.</forenames></author></authors><title>Whitehead method and Genetic Algorithms</title><categories>math.GR cs.NE cs.SC</categories><comments>29 pages, 7 figures</comments><msc-class>20F28, 68Q17, 68T05</msc-class><abstract>  In this paper we discuss a genetic version (GWA) of the Whitehead's
algorithm, which is one of the basic algorithms in combinatorial group theory.
It turns out that GWA is surprisingly fast and outperforms the standard
Whitehead's algorithm in free groups of rank &gt;= 5. Experimenting with GWA we
collected an interesting numerical data that clarifies the time-complexity of
the Whitehead's Problem in general. These experiments led us to several
mathematical conjectures. If confirmed they will shed light on hidden
mechanisms of Whitehead Method and geometry of automorphic orbits in free
groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0304292</identifier>
 <datestamp>2008-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0304292</id><created>2003-04-21</created><updated>2008-03-24</updated><authors><author><keyname>Little</keyname><forenames>John B.</forenames></author></authors><title>The Ubiquity of Order Domains for the Construction of Error Control
  Codes</title><categories>math.AC cs.IT math.AG math.IT math.RA</categories><comments>21 pages; AMS-LaTeX. The statement of Theorem (3.3) in the original
  version (renumbered to Theorem 2 in this version) omitted a necessary
  hypothesis, which is now added in this version</comments><msc-class>94B27; 13P10; 13A18</msc-class><journal-ref>Advances in Mathematics of Communications 1 (2007), 151-171</journal-ref><abstract>  The order domains are a class of commutative rings introduced by H{\o}holdt,
van Lint, and Pellikaan to simplify the theory of error control codes using
ideas from algebraic geometry. The definition is largely motivated by the
structures utilized in the Berlekamp-Massey-Sakata (BMS) decoding algorithm,
with Feng-Rao majority voting for unknown syndromes, applied to one-point
geometric Goppa codes constructed from curves. However, order domains are much
more general, and O'Sullivan has shown that the BMS algorithm can be applied to
decode all codes constructed from order domains by a suitable generalization of
Goppa's procedure for curves. In this article we will first discuss the
connection between order domains and valuations on function fields over a
finite field. Under some mild conditions, we will see that a general projective
variety over a finite field has projective models which can be used to
construct order domains and Goppa-type codes for which the BMS algorithm is
applicable. We will then give a slightly different interpretation of Geil and
Pellikaan's extrinsic characterization of order domains via the theory of
Gr\&quot;obner bases, and show that their results are related to the existence of
toric deformations of varieties. To illustrate the potential usefulness of
these observations, we present a series of new explicit examples of order
domains associated to varieties with many rational points over finite fields:
Hermitian hypersurfaces, Grassmannians, and flag varieties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0304305</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0304305</id><created>2003-04-21</created><authors><author><keyname>Miasnikov</keyname><forenames>Alexei D.</forenames></author><author><keyname>Myasnikov</keyname><forenames>Alexei G.</forenames></author></authors><title>Balanced presentations of the trivial group on two generators and the
  Andrews-Curtis conjecture</title><categories>math.GR cs.SC</categories><comments>7 pages, no figures</comments><msc-class>20E05, 20F05, 68T05 (Primary), 57M05,57M20. (Secondary)</msc-class><journal-ref>In W.Kantor and A.Seress,editors, Groups and Computation III,
  volume 23, (2001) 257-263, Berlin</journal-ref><abstract>  The Andrews-Curtis conjecture states that every balanced presentation of the
trivial group can be reduced to the standard one by a sequence of the
elementary Nielsen transformations and conjugations. In this paper we describe
all balanced presentations of the trivial group on two generators and with the
total length of relators &lt;= 12. We show that all these presentations satisfy
the Andrews-Curtis conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0304306</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0304306</id><created>2003-04-21</created><authors><author><keyname>Miasnikov</keyname><forenames>Alexei D.</forenames></author></authors><title>Genetic algorithms and the Andrews-Curtis conjecture</title><categories>math.GR cs.NE cs.SC</categories><comments>19 pages</comments><msc-class>20E05, 20F05, 68T05 (Primary) 57M05,57M20</msc-class><journal-ref>International Journal of Algebra and Computation, Vol. 9 No. 6,
  (1999) 671-686</journal-ref><abstract>  The Andrews-Curtis conjecture claims that every balanced presentation of the
trivial group can be transformed into the trivial presentation by a finite
sequence of &quot;elementary transformations&quot; which are Nielsen transformations
together with an arbitrary conjugation of a relator. It is believed that the
Andrews-Curtis conjecture is false; however, not so many possible
counterexamples are known. It is not a trivial matter to verify whether the
conjecture holds for a given balanced presentation or not. The purpose of this
paper is to describe some non-deterministic methods, called Genetic Algorithms,
designed to test the validity of the Andrews-Curtis conjecture. Using such
algorithm we have been able to prove that all known (to us) balanced
presentations of the trivial group where the total length of the relators is at
most 12 satisfy the conjecture. In particular, the Andrews-Curtis conjecture
holds for the presentation &lt;x,y|x y x = y x y, x^2 = y^3&gt; which was one of the
well known potential counterexamples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0304346</identifier>
 <datestamp>2010-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0304346</id><created>2003-04-22</created><updated>2005-02-23</updated><authors><author><keyname>Megyesi</keyname><forenames>G&#xe1;bor</forenames><affiliation>UMIST</affiliation></author><author><keyname>Sottile</keyname><forenames>Frank</forenames><affiliation>Texas A&amp;M University</affiliation></author></authors><title>The envelope of lines meeting a fixed line that are tangent to two
  spheres</title><categories>math.AG cs.CG math.MG</categories><comments>24 pages, 13 .eps pictures</comments><msc-class>68U05, 51N20, 14N10, 14Q15; ACM I.3.5</msc-class><journal-ref>Discrete and Computational Geometry, 33, Number 4, (2005)
  617--644.</journal-ref><abstract>  We study the set of lines that meet a fixed line and are tangent to two
spheres and classify the configurations consisting of a single line and three
spheres for which there are infinitely many lines tangent to the three spheres
that also meet the given line. All such configurations are degenerate. The path
to this result involves the interplay of some beautiful and intricate geometry
of real surfaces in 3-space, complex algebraic geometry, explicit computation
and graphics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0304476</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0304476</id><created>2003-04-29</created><authors><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>Simultaneous avoidance of large squares and fractional powers in
  infinite binary words</title><categories>math.CO cs.DM</categories><msc-class>68R15</msc-class><abstract>  In 1976, Dekking showed that there exists an infinite binary word that
contains neither squares yy with y &gt;= 4 nor cubes xxx. We show that `cube' can
be replaced by any fractional power &gt; 5/2. We also consider the analogous
problem where `4' is replaced by any integer. This results in an interesting
and subtle hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0305121</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0305121</id><created>2003-05-08</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Robust Estimators under the Imprecise Dirichlet Model</title><categories>math.PR cs.IT cs.LG math.IT math.ST stat.TH</categories><comments>16 LaTeX pages</comments><report-no>IDSIA-03-03</report-no><journal-ref>Proc. 3rd International Symposium on Imprecise Probabilities and
  Their Application (ISIPTA-2003), pages 274-289</journal-ref><abstract>  Walley's Imprecise Dirichlet Model (IDM) for categorical data overcomes
several fundamental problems which other approaches to uncertainty suffer from.
Yet, to be useful in practice, one needs efficient ways for computing the
imprecise=robust sets or intervals. The main objective of this work is to
derive exact, conservative, and approximate, robust and credible interval
estimates under the IDM for a large class of statistical estimators, including
the entropy and mutual information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0305135</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0305135</id><created>2003-05-09</created><authors><author><keyname>Gluesing-Luerssen</keyname><forenames>Heide</forenames></author><author><keyname>Schmale</keyname><forenames>Wiland</forenames></author></authors><title>Distance bounds for convolutional codes and some optimal codes</title><categories>math.RA cs.IT math.IT math.OC</categories><comments>22 pages</comments><msc-class>94B10; 94B15; 16S36</msc-class><abstract>  After a discussion of the Griesmer and Heller bound for the distance of a
convolutional code we present several codes with various parameters, over
various fields, and meeting the given distance bounds. Moreover, the Griesmer
bound is used for deriving a lower bound for the field size of an MDS
convolutional code and examples are presented showing that, in most cases, the
lower bound is tight. Most of the examples in this paper are cyclic
convolutional codes in a generalized sense as it has been introduced in the
seventies. A brief introduction to this promising type of cyclicity is given at
the end of the paper in order to make the examples more transparent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0305308</identifier>
 <datestamp>2014-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0305308</id><created>2003-05-21</created><authors><author><keyname>Cloitre</keyname><forenames>Benoit</forenames></author><author><keyname>Sloane</keyname><forenames>N. J. A.</forenames></author><author><keyname>Vandermast</keyname><forenames>Matthew J.</forenames></author></authors><title>Numerical Analogues of Aronson's Sequence</title><categories>math.NT cs.IT math.IT</categories><comments>16 pages</comments><msc-class>11B37</msc-class><journal-ref>J. Integer Sequences, 6 (2003), #03.2.2</journal-ref><abstract>  Aronson's sequence 1, 4, 11, 16, ... is defined by the English sentence ``t
is the first, fourth, eleventh, sixteenth, ... letter of this sentence.'' This
paper introduces some numerical analogues, such as: a(n) is taken to be the
smallest positive integer greater than a(n-1) which is consistent with the
condition ``n is a member of the sequence if and only if a(n) is odd.'' This
sequence can also be characterized by its ``square'', the sequence a^(2)(n) =
a(a(n)), which equals 2n+3 for n &gt;= 1. There are many generalizations of this
sequence, some of which are new, while others throw new light on previously
known sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0306081</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0306081</id><created>2003-06-04</created><authors><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author><author><keyname>Wang</keyname><forenames>Ming-wei</forenames></author></authors><title>Avoiding large squares in infinite binary words</title><categories>math.CO cs.DM</categories><msc-class>68R15</msc-class><abstract>  We consider three aspects of avoiding large squares in infinite binary words.
First, we construct an infinite binary word avoiding both cubes xxx and squares
yy with |y| &gt;= 4; our construction is somewhat simpler than the original
construction of Dekking. Second, we construct an infinite binary word avoiding
all squares except 00, 11, and 0101; our construction is somewhat simpler than
the original construction of Fraenkel and Simpson. In both cases, we also show
how to modify our construction to obtain exponentially many words of length n
with the given avoidance properties. Finally, we answer an open question of
Prodinger and Urbanek from 1979 by demonstrating the existence of two infinite
binary words, each avoiding arbitrarily large squares, such that their perfect
shuffle has arbitrarily large squares.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0306354</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0306354</id><created>2003-06-25</created><authors><author><keyname>Kameyama</keyname><forenames>Atsushi</forenames></author></authors><title>Coding and tiling of Julia sets for subhyperbolic rational maps</title><categories>math.DS cs.IT math.IT</categories><comments>27 pages, 5 figures</comments><msc-class>37F20 (Primary); 28A80 (Secondary)</msc-class><abstract>  Let $f:\hat{C}\to\hat{C}$ be a subhyperbolic rational map of degree $d$. We
construct a set of coding maps $Cod(f)=\{\pi_r:\Sigma\to J\}_r$ of the Julia
set $J$ by geometric coding trees, where the parameter $r$ ranges over mappings
from a certain tree to the Riemann sphere. Using the universal covering space
$\phi:\tilde S\to S$ for the corresponding orbifold, we lift the inverse of $f$
to an iterated function system $I=(g_i)_{i=1,2,...,d}$. For the purpose of
studying the structure of $Cod(f)$, we generalize Kenyon and Lagarias-Wang's
results : If the attractor $K$ of $I$ has positive measure, then $K$ tiles
$\phi^{-1}(J)$, and the multiplicity of $\pi_r$ is well-defined. Moreover, we
see that the equivalence relation induced by $\pi_r$ is described by a finite
directed graph, and give a necessary and sufficient condition for two coding
maps $\pi_r$ and $\pi_{r'}$ to be equal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0306395</identifier>
 <datestamp>2015-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0306395</id><created>2003-06-27</created><authors><author><keyname>Rodier</keyname><forenames>Francois</forenames></author></authors><title>Sur la non-linearite des fonctions booleennes</title><categories>math.NT cs.IT math.IT</categories><proxy>ccsd ccsd-00000454</proxy><msc-class>Primaire: 11T71, secondaire: 06E30, 42A05, 94B75</msc-class><doi>10.4064/aa115-1-1</doi><abstract>  Boolean functions on the space $F_{2}^m$ are not only important in the theory
of error-correcting codes, but also in cryptography, where they occur in
private key systems. In these two cases, the nonlinearity of these function is
a main concept. In this article, I show that the spectral amplitude of boolean
functions, which is linked to their nonlinearity, is of the order of
$2^{m/2}\sqrt{m}$ in mean, whereas its range is bounded by $2^{m/2}$ and $2^m$.
Moreover I examine a conjecture of Patterson and Wiedemann saying that the
minimum of this spectral amplitude is as close as desired to $2^{m/2}$. I also
study a weaker conjecture about the moments of order 4 of their Fourier
transform. This article is inspired by works of Salem, Zygmund, Kahane and
others about the related problem of real polynomials with random coefficients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0306401</identifier>
 <datestamp>2010-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0306401</id><created>2003-06-27</created><authors><author><keyname>Br&#xf6;nnimann</keyname><forenames>Herv&#xe9;</forenames></author><author><keyname>Everett</keyname><forenames>Hazel</forenames></author><author><keyname>Lazard</keyname><forenames>Sylvain</forenames></author><author><keyname>Sottile</keyname><forenames>Frank</forenames></author><author><keyname>Whitesides</keyname><forenames>Sue</forenames></author></authors><title>The number of transversals to line segments in R^3</title><categories>math.MG cs.CG</categories><comments>9 pages, 7.eps pictures in color, abstract to apper in CCCG03</comments><journal-ref>Discrete and Computational Geometry, Volume 34, Number 3, (2005),
  381--390.</journal-ref><abstract>  We completely describe the structure of the connected components of
transversals to a collection of n line segments in R^3. We show that n&gt;2
arbitrary line segments in R^3 admit 0, 1, ..., n or infinitely many line
transversals. In the latter case, the transversals form up to n connected
components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0307064</identifier>
 <datestamp>2014-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0307064</id><created>2003-07-04</created><authors><author><keyname>Sloane</keyname><forenames>N. J. A.</forenames></author><author><keyname>Wieder</keyname><forenames>Thomas</forenames></author></authors><title>The Number of Hierarchical Orderings</title><categories>math.CO cs.IT math.IT</categories><comments>7 pages</comments><msc-class>06A07</msc-class><journal-ref>Order, 21 (2004), 83-89</journal-ref><abstract>  An ordered set-partition (or preferential arrangement) of n labeled elements
represents a single ``hierarchy''; these are enumerated by the ordered Bell
numbers. In this note we determine the number of ``hierarchical orderings'' or
``societies'', where the n elements are first partitioned into m &lt;= n subsets
and a hierarchy is specified for each subset. We also consider the unlabeled
case, where the ordered Bell numbers are replaced by the composition numbers.
If there is only a single hierarchy, we show that the average rank of an
element is asymptotic to n/(4 log 2) in the labeled case and to n/4 in the
unlabeled case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0307196</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0307196</id><created>2003-07-14</created><authors><author><keyname>Hutchinson</keyname><forenames>R.</forenames></author><author><keyname>Rosenthal</keyname><forenames>J.</forenames></author><author><keyname>Smarandache</keyname><forenames>R.</forenames></author></authors><title>Convolutional Codes with Maximum Distance Profile</title><categories>math.OC cs.IT math.IT math.RA</categories><comments>15 pages, submitted to Systems and Control Letters, corrected date</comments><msc-class>94B10</msc-class><abstract>  Maximum distance profile codes are characterized by the property that two
trajectories which start at the same state and proceed to a different state
will have the maximum possible distance from each other relative to any other
convolutional code of the same rate and degree.
  In this paper we use methods from systems theory to characterize maximum
distance profile codes algebraically. Tha main result shows that maximum
distance profile codes form a generic set inside the variety which parametrizes
the set of convolutional codes of a fixed rate and a fixed degree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0308046</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0308046</id><created>2003-08-05</created><authors><author><keyname>Elkies</keyname><forenames>Noam D.</forenames></author></authors><title>Still better nonlinear codes from modular curves</title><categories>math.NT cs.IT math.AG math.IT</categories><comments>10 pages</comments><msc-class>94B27; 94B65</msc-class><abstract>  We give a new construction of nonlinear error-correcting codes over suitable
finite fields k from the geometry of modular curves with many rational points
over k, combining two recent improvements on Goppa's construction. The
resulting codes are asymptotically the best currently known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0308110</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0308110</id><created>2003-08-12</created><updated>2005-09-28</updated><authors><author><keyname>Henkel</keyname><forenames>Oliver</forenames></author></authors><title>Sphere packing bounds in the Grassmann and Stiefel manifolds</title><categories>math.MG cs.IT math.IT</categories><comments>Replaced with final version, 11 pages</comments><journal-ref>IEEE Transactions on Information Theory, vol 51, no 10, (2005),
  3445-3456</journal-ref><doi>10.1109/TIT.2005.855594</doi><abstract>  Applying the Riemann geometric machinery of volume estimates in terms of
curvature, bounds for the minimal distance of packings/codes in the Grassmann
and Stiefel manifolds will be derived and analyzed. In the context of
space-time block codes this leads to a monotonically increasing minimal
distance lower bound as a function of the block length. This advocates large
block lengths for the code design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0308153</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0308153</id><created>2003-08-15</created><authors><author><keyname>Wolff</keyname><forenames>J Gerard</forenames></author></authors><title>Mathematics and Logic as Information Compression by Multiple Alignment,
  Unification and Search</title><categories>math.GM cs.AI math.LO</categories><msc-class>00A30; 03A05</msc-class><abstract>  This article introduces the conjecture that &quot;mathematics, logic and related
disciplines may usefully be understood as information compression (IC) by
'multiple alignment', 'unification' and 'search' (ICMAUS)&quot;.
  As a preparation for the two main sections of the article, concepts of
information and information compression are reviewed. Related areas of research
are also described including IC in brains and nervous systems, and IC in
relation to inductive inference, Minimum Length Encoding and probabilistic
reasoning. The ICMAUS concepts and a computer model in which they are embodied
are briefly described.
  The first of the two main sections describes how many of the commonly-used
forms and structures in mathematics, logic and related disciplines (such as
theoretical linguistics and computer programming) may be seen as devices for
IC. In some cases, these forms and structures may be interpreted in terms of
the ICMAUS framework.
  The second main section describes a selection of examples where processes of
calculation and inference in mathematics, logic and related disciplines may be
understood as IC. In many cases, these examples may be understood more
specifically in terms of the ICMAUS concepts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0309081</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0309081</id><created>2003-09-04</created><authors><author><keyname>Cooper</keyname><forenames>Joshua N.</forenames></author><author><keyname>Ellis</keyname><forenames>Robert B.</forenames></author><author><keyname>Kahng</keyname><forenames>Andrew B.</forenames></author></authors><title>Asymmetric binary covering codes</title><categories>math.CO cs.IT math.IT</categories><comments>16 pages</comments><msc-class>94B75</msc-class><journal-ref>J. Combin. Theory Ser. A 100 (2002), no. 2, 232--249</journal-ref><abstract>  An asymmetric binary covering code of length n and radius R is a subset C of
the n-cube Q_n such that every vector x in Q_n can be obtained from some vector
c in C by changing at most R 1's of c to 0's, where R is as small as possible.
K^+(n,R) is defined as the smallest size of such a code. We show K^+(n,R) is of
order 2^n/n^R for constant R, using an asymmetric sphere-covering bound and
probabilistic methods. We show K^+(n,n-R')=R'+1 for constant coradius R' iff
n&gt;=R'(R'+1)/2. These two results are extended to near-constant R and R',
respectively. Various bounds on K^+ are given in terms of the total number of
0's or 1's in a minimal code. The dimension of a minimal asymmetric linear
binary code ([n,R]^+ code) is determined to be min(0,n-R). We conclude by
discussing open problems and techniques to compute explicit values for K^+,
giving a table of best known bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0309083</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0309083</id><created>2003-09-05</created><authors><author><keyname>Onn</keyname><forenames>Shmuel</forenames></author><author><keyname>Rothblum</keyname><forenames>Uriel G.</forenames></author></authors><title>Convex Combinatorial Optimization</title><categories>math.CO cs.DM math.OC</categories><msc-class>05A; 15A; 51M; 52A; 52B; 52C; 68Q; 68R; 68U; 90B; 90C</msc-class><journal-ref>Discrete and Computational Geometry, 32:549--566, 2004</journal-ref><abstract>  We introduce the convex combinatorial optimization problem, a far reaching
generalization of the standard linear combinatorial optimization problem. We
show that it is strongly polynomial time solvable over any edge-guaranteed
family, and discuss several applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0309120</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0309120</id><created>2003-09-08</created><authors><author><keyname>Harvey</keyname><forenames>Nate</forenames><affiliation>UC Berkeley</affiliation></author><author><keyname>Peres</keyname><forenames>Yuval</forenames><affiliation>UC Berkeley</affiliation></author></authors><title>An invariant of finitary codes with finite expected square root coding
  length</title><categories>math.PR cs.IT math.IT</categories><comments>18 pages</comments><abstract>  Let $p$ and $q$ be probability vectors with the same entropy $h$. Denote by
$B(p)$ the Bernoulli shift indexed by $\Z$ with marginal distribution $p$.
Suppose that $\phi$ is a measure preserving homomorphism from $B(p)$ to $B(q)$.
We prove that if the coding length of $\phi$ has a finite 1/2 moment, then
$\sigma_p^2=\sigma_q^2$, where $\sigma_p^2=\sum_i p_i(-\log p_i-h)^2$ is the
{\dof informational variance} of $p$. In this result, which sharpens a theorem
of Parry (1979), the 1/2 moment cannot be replaced by a lower moment. On the
other hand, for any $\theta&lt;1$, we exhibit probability vectors $p$ and $q$ that
are not permutations of each other, such that there exists a finitary
isomorphism $\Phi$ from $B(p)$ to $B(q)$ where the coding lengths of $\Phi$ and
of its inverse have a finite $\theta$ moment. We also present an extension to
ergodic Markov chains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0309123</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0309123</id><created>2003-09-06</created><authors><author><keyname>Lomont</keyname><forenames>Chris</forenames></author></authors><title>Error Correcting Codes on Algebraic Surfaces</title><categories>math.NT cs.IT math.AG math.IT</categories><comments>This is Chris Lomont's PhD thesis about error correcting codes from
  algebriac surfaces</comments><msc-class>14J60; 14Q10; 94B27</msc-class><abstract>  Error correcting codes are defined and important parameters for a code are
explained. Parameters of new codes constructed on algebraic surfaces are
studied. In particular, codes resulting from blowing up points in $\proj^2$ are
briefly studied, then codes resulting from ruled surfaces are covered. Codes
resulting from ruled surfaces over curves of genus 0 are completely analyzed,
and some codes are discovered that are better than direct product Reed Solomon
codes of similar length. Ruled surfaces over genus 1 curves are also studied,
but not all classes are completely analyzed. However, in this case a family of
codes are found that are comparable in performance to the direct product code
of a Reed Solomon code and a Goppa code. Some further work is done on surfaces
from higher genus curves, but there remains much work to be done in this
direction to understand fully the resulting codes. Codes resulting from blowing
points on surfaces are also studied, obtaining necessary parameters for
constructing infinite families of such codes.
  Also included is a paper giving explicit formulas for curves with more
\field{q}-rational points than were previously known for certain combinations
of field size and genus. Some upper bounds are now known to be optimal from
these examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0309285</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0309285</id><created>2003-09-17</created><updated>2004-04-09</updated><authors><author><keyname>Jackson</keyname><forenames>Brad</forenames></author><author><keyname>Scargle</keyname><forenames>Jeffrey D.</forenames></author><author><keyname>Barnes</keyname><forenames>David</forenames></author><author><keyname>Arabhi</keyname><forenames>Sundararajan</forenames></author><author><keyname>Alt</keyname><forenames>Alina</forenames></author><author><keyname>Gioumousis</keyname><forenames>Peter</forenames></author><author><keyname>Gwin</keyname><forenames>Elyus</forenames></author><author><keyname>Sangtrakulcharoen</keyname><forenames>Paungkaew</forenames></author><author><keyname>Tan</keyname><forenames>Linda</forenames></author><author><keyname>Tsai</keyname><forenames>Tun Tao</forenames></author></authors><title>An Algorithm for Optimal Partitioning of Data on an Interval</title><categories>math.NA astro-ph cs.CE cs.DS cs.IT math.CO math.IT</categories><comments>3 pages, 1 figure, submitted to IEEE Signal Processing Letters,
  revised version with added references</comments><msc-class>65C60</msc-class><abstract>  Many signal processing problems can be solved by maximizing the fitness of a
segmented model over all possible partitions of the data interval. This letter
describes a simple but powerful algorithm that searches the exponentially large
space of partitions of $N$ data points in time $O(N^2)$. The algorithm is
guaranteed to find the exact global optimum, automatically determines the model
order (the number of segments), has a convenient real-time mode, can be
extended to higher dimensional data spaces, and solves a surprising variety of
problems in signal detection and characterization, density estimation, cluster
analysis and classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0309347</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0309347</id><created>2003-09-21</created><authors><author><keyname>Onn</keyname><forenames>Shmuel</forenames></author></authors><title>Nowhere-Zero Flow Polynomials</title><categories>math.CO cs.DM math.AC</categories><msc-class>05C, 05E, 13C, 13P, 68R, 68W, 90C, 94C</msc-class><journal-ref>Journal of Combinatorial Theory Series A, 108:205--215, 2004</journal-ref><abstract>  In this article we introduce the flow polynomial of a digraph and use it to
study nowhere-zero flows from a commutative algebraic perspective. Using
Hilbert's Nullstellensatz, we establish a relation between nowhere-zero flows
and dual flows. For planar graphs this gives a relation between nowhere-zero
flows and flows of their planar duals. It also yields an appealing proof that
every bridgeless triangulated graph has a nowhere-zero four-flow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0309389</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0309389</id><created>2003-09-23</created><updated>2003-12-10</updated><authors><author><keyname>Lagarias</keyname><forenames>J. C.</forenames></author><author><keyname>Sloane</keyname><forenames>N. J. A.</forenames></author></authors><title>Approximate Squaring</title><categories>math.NT cs.IT math.IT</categories><comments>22 pages. Revised Nov 9, 2003: new theorems, including probabilistic
  interpretation of results, also analogs for floor function (24 pages)</comments><msc-class>Primary 26A18; Secondary 11B83, 11K31, 11Y99</msc-class><journal-ref>Experimental Math. 13 (2004), 113--128.</journal-ref><abstract>  We study the ``approximate squaring'' map f(x) := x ceiling(x) and its
behavior when iterated. We conjecture that if f is repeatedly applied to a
rational number r = l/d &gt; 1 then eventually an integer will be reached. We
prove this when d=2, and provide evidence that it is true in general by giving
an upper bound on the density of the ``exceptional set'' of numbers which fail
to reach an integer. We give similar results for a p-adic analogue of f, when
the exceptional set is nonempty, and for iterating the ``approximate
multiplication'' map f_r(x) := r ceiling(x) where r is a fixed rational number.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0309425</identifier>
 <datestamp>2007-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0309425</id><created>2003-09-25</created><updated>2004-08-13</updated><authors><author><keyname>Hoffman</keyname><forenames>Michael E.</forenames></author></authors><title>Algebraic Aspects of Multiple Zeta Values</title><categories>math.QA cs.IT math.IT math.NT</categories><comments>22 pages; for conference &quot;Zeta Functions, Topology and Quantum
  Physics&quot; (Osaka 2003); revision corrects various typos</comments><msc-class>11M06; 16W30; 11B50</msc-class><journal-ref>in Zeta Functions, Topology and Quantum Physics (T. Aoki et. al.,
  eds.), Springer, 2005, pp. 51-74</journal-ref><abstract>  Multiple zeta values have been studied by a wide variety of methods. In this
article we summarize some of the results about them that can be obtained by an
algebraic approach. This involves &quot;coding&quot; the multiple zeta values by
monomials in two noncommuting variables x and y. Multiple zeta values can then
be thought of as defining a map \zeta: H^0 -&gt; R, where H^0 is the graded
rational vector space generated by the &quot;admissible words&quot; of the noncommutative
polynomial algebra Q&lt;x,y&gt;. Now H^0 admits two (commutative) products making
\zeta a homomorphism: the shuffle product and the &quot;harmonic&quot; product. The
latter makes H^0 a subalgebra of the algebra QSym of quasi-symmetric functions.
We also discuss some results about multiple zeta values that can be stated in
terms of derivations and cyclic derivations of Q&lt;x,y&gt;, and define an action of
the Hopf algebra QSym on Q&lt;x,y&gt; that appears useful. Finally, we apply the
algebraic approach to finite partial sums of multiple zeta value series.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0310020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0310020</id><created>2003-10-02</created><authors><author><keyname>Fiedler</keyname><forenames>B.</forenames></author></authors><title>Generators of algebraic covariant derivative curvature tensors and Young
  symmetrizers</title><categories>math.CO cs.SC math.DG</categories><comments>18 pages. Chapter for a book &quot;Progress in Computer Science Research&quot;,
  in preparation by Nova Science Publishers, Inc.:
  http://www.novapublishers.com/</comments><msc-class>53B20; 15A72; 05E10; 16D60; 05-04</msc-class><journal-ref>In: Leading-Edge Computer Science, S. Shannon (ed.), Nova Science
  Publishers, Inc. New York, 2006. pp. 219-239. ISBN: 1-59454-526-X</journal-ref><abstract>  We show that the space of algebraic covariant derivative curvature tensors R'
is generated by Young symmetrized tensor products W*U or U*W, where W and U are
covariant tensors of order 2 and 3 whose symmetry classes are irreducible and
characterized by the following pairs of partitions: {(2),(3)}, {(2),(2 1)} or
{(1 1),(2 1)}. Each of the partitions (2), (3) and (1 1) describes exactly one
symmetry class, whereas the partition (2 1) characterizes an infinite set S of
irreducible symmetry classes. This set S contains exactly one symmetry class
S_0 whose elements U can not play the role of generators of tensors R'. The
tensors U of all other symmetry classes from S\{S_0} can be used as generators
for tensors R'. Foundation of our investigations is a theorem of S. A. Fulling,
R. C. King, B. G. Wybourne and C. J. Cummins about a Young symmetrizer that
generates the symmetry class of algebraic covariant derivative curvature
tensors. Furthermore we apply ideals and idempotents in group rings C[Sr], the
Littlewood-Richardson rule and discrete Fourier transforms for symmetric groups
Sr. For certain symbolic calculations we used the Mathematica packages Ricci
and PERMS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0310109</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0310109</id><created>2003-10-08</created><authors><author><keyname>Romik</keyname><forenames>Dan</forenames></author></authors><title>Shortest paths in the Tower of Hanoi graph and finite automata</title><categories>math.CO cs.DM math.PR</categories><comments>15 pages, 6 figures</comments><msc-class>68W40</msc-class><abstract>  We present efficient algorithms for constructing a shortest path between two
states in the Tower of Hanoi graph, and for computing the length of the
shortest path. The key element is a finite-state machine which decides, after
examining on the average only 63/38 of the largest discs, whether the largest
disc will be moved once or twice. This solves a problem raised by Andreas Hinz,
and results in a better understanding of how the shortest path is determined.
Our algorithm for computing the length of the shortest path is typically about
twice as fast as the existing algorithm. We also use our results to give a new
derivation of the average distance 466/885 between two random points on the
Sierpinski gasket of unit side.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0310144</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0310144</id><created>2003-10-10</created><authors><author><keyname>Ilie</keyname><forenames>Lucian</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>A Generalization of Repetition Threshold</title><categories>math.CO cs.DM</categories><msc-class>68R15</msc-class><abstract>  Brandenburg and (implicitly) Dejean introduced the concept of repetition
threshold: the smallest real number alpha such that there exists an infinite
word over a k-letter alphabet that avoids beta-powers for all beta&gt;alpha. We
generalize this concept to include the lengths of the avoided words. We give
some conjectures supported by numerical evidence and prove one of these
conjectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0310148</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0310148</id><created>2003-10-10</created><authors><author><keyname>Perez</keyname><forenames>J. A. Dominguez</forenames></author><author><keyname>Porras</keyname><forenames>J. M. Mu&#xf1;oz</forenames></author><author><keyname>Sotelo</keyname><forenames>G. Serrano</forenames></author></authors><title>Convolutional Codes of Goppa Type</title><categories>math.OC cs.IT math.AG math.IT</categories><comments>9 pages, submitted to AAECC</comments><msc-class>94B27; 94B10</msc-class><journal-ref>AAECC, 15 (2004), 51-61</journal-ref><abstract>  A new kind of Convolutional Codes generalizing Goppa Codes is proposed. This
provides a systematic method for constructing convolutional codes with prefixed
properties. In particular, examples of Maximum-Distance Separable (MDS)
convolutional codes are obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0310149</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0310149</id><created>2003-10-10</created><authors><author><keyname>Porras</keyname><forenames>J. M. Mu&#xf1;oz</forenames></author><author><keyname>Perez</keyname><forenames>J. A. Dominguez</forenames></author><author><keyname>Curto</keyname><forenames>J. I. Iglesias</forenames></author><author><keyname>Sotelo</keyname><forenames>G. Serrano</forenames></author></authors><title>Convolutional Goppa Codes</title><categories>math.OC cs.IT math.AG math.IT</categories><comments>8 pages, submitted to IEEE Trans. Inform. Theory</comments><msc-class>94B27; 94B10</msc-class><abstract>  We define Convolutional Goppa Codes over algebraic curves and construct their
corresponding dual codes. Examples over the projective line and over elliptic
curves are described, obtaining in particular some Maximum-Distance Separable
(MDS) convolutional codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0310175</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0310175</id><created>2003-10-12</created><authors><author><keyname>Kohout</keyname><forenames>Ladislav J.</forenames></author></authors><title>Defining Homomorphisms and Other Generalized Morphisms of Fuzzy
  Relations in Monoidal Fuzzy Logics by Means of BK-Products</title><categories>math.LO cs.LO math-ph math.MP math.QA</categories><comments>13 pages, 4 figures, 4 tables. Invited and refereed paper presented
  at JCIS 2003 - 7th Joint Conf. on Information Sciences (Subsection: 9th
  Internat. Conf. on Fuzzy Theory and Technology), Cary, North Carolina, USA;
  September 2003</comments><msc-class>04A72; 08A02; 37F05</msc-class><abstract>  The present paper extends generalized morphisms of relations into the realm
of Monoidal Fuzzy Logics by first proving and then using relational
inequalities over pseudo-associative BK-products (compositions) of relations in
these logics.
  In 1977 Bandler and Kohout introduced generalized homomorphism,
proteromorphism, amphimorphism, forward and backward compatibility of
relations, and non-associative and pseudo-associative products (compositions)
of relations into crisp (non-fuzzy Boolean) theory of relations. This was
generalized later by Kohout to relations based on fuzzy Basic Logic systems
(BL) of H\'ajek and also for relational systems based on left-continuous
t-norms.
  The present paper is based on monoidal logics, hence it subsumes as special
cases the theories of generalized morphisms (etc.) based on the following
systems of logics: BL systems (which include the well known Goedel, product
logic systems; Lukasiewicz logic and its extension to MV-algebras related to
quantum logics), intuitionistic logics and linear logics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0310193</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0310193</id><created>2003-10-13</created><updated>2003-10-21</updated><authors><author><keyname>Hajiaghayi</keyname><forenames>MohammadTaghi</forenames></author><author><keyname>Sorkin</keyname><forenames>Gregory B.</forenames></author></authors><title>The Satisfiability Threshold of Random 3-SAT Is at Least 3.52</title><categories>math.CO cs.DM math.PR</categories><abstract>  We prove that a random 3-SAT instance with clause-to-variable density less
than 3.52 is satisfiable with high probability. The proof comes through an
algorithm which selects (and sets) a variable depending on its degree and that
of its complement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0310232</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0310232</id><created>2003-10-15</created><updated>2006-02-24</updated><authors><author><keyname>Goel</keyname><forenames>Ashish</forenames></author><author><keyname>Rai</keyname><forenames>Sanatan</forenames></author><author><keyname>Krishnamachari</keyname><forenames>Bhaskar</forenames></author></authors><title>Monotone properties of random geometric graphs have sharp thresholds</title><categories>math.PR cond-mat.stat-mech cs.DM math.CO</categories><comments>Published at http://dx.doi.org/10.1214/105051605000000575 in the
  Annals of Applied Probability (http://www.imstat.org/aap/) by the Institute
  of Mathematical Statistics (http://www.imstat.org)</comments><report-no>IMS-AAP-AAP0122</report-no><msc-class>60D05 (Primary) 5C80, 90B10 (Secondary)</msc-class><journal-ref>Annals of Applied Probability 2005, Vol. 15, No. 4, 2535-2552</journal-ref><doi>10.1214/105051605000000575</doi><abstract>  Random geometric graphs result from taking $n$ uniformly distributed points
in the unit cube, $[0,1]^d$, and connecting two points if their Euclidean
distance is at most $r$, for some prescribed $r$. We show that monotone
properties for this class of graphs have sharp thresholds by reducing the
problem to bounding the bottleneck matching on two sets of $n$ points
distributed uniformly in $[0,1]^d$. We present upper bounds on the threshold
width, and show that our bound is sharp for $d=1$ and at most a sublogarithmic
factor away for $d\ge2$. Interestingly, the threshold width is much sharper for
random geometric graphs than for Bernoulli random graphs. Further, a random
geometric graph is shown to be a subgraph, with high probability, of another
independently drawn random geometric graph with a slightly larger radius; this
property is shown to have no analogue for Bernoulli random graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0310385</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0310385</id><created>2003-10-23</created><updated>2003-10-28</updated><authors><author><keyname>Chung</keyname><forenames>Fan</forenames></author><author><keyname>Cooper</keyname><forenames>Joshua N.</forenames></author></authors><title>De Bruijn Cycles for Covering Codes</title><categories>math.CO cs.IT math.IT</categories><comments>18 pages, 0 figures, submitted to RSA</comments><msc-class>05B99</msc-class><abstract>  A de Bruijn covering code is a q-ary string S so that every q-ary string is
at most R symbol changes from some n-word appearing consecutively in S. We
introduce these codes and prove that they can have length close to the smallest
possible covering code. The proof employs tools from field theory, probability,
and linear algebra. We also prove a number of ``spectral'' results on de Bruijn
covering codes. Included is a table of the best known bounds on the lengths of
small binary de Bruijn covering codes, up to R=11 and n=13, followed by several
open questions in this area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0311004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0311004</id><created>2003-11-01</created><authors><author><keyname>Boutin</keyname><forenames>Mireille</forenames></author><author><keyname>Kemper</keyname><forenames>Gregor</forenames></author></authors><title>Which Point Configurations are Determined by the Distribution of their
  Pairwise Distances?</title><categories>math.MG cs.CV math.AC math.AG</categories><comments>10 pages</comments><msc-class>68U;14L</msc-class><abstract>  In a previous paper we showed that, for any $n \ge m+2$, most sets of $n$
points in $\RR^m$ are determined (up to rotations, reflections, translations
and relabeling of the points) by the distribution of their pairwise distances.
But there are some exceptional point configurations which are not
reconstructible from the distribution of distances in the above sense. In this
paper, we present a reconstructibility test with running time $O(n^{11})$. The
cases of orientation preserving rigid motions (rotations and translations) and
scalings are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0311046</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0311046</id><created>2003-11-04</created><authors><author><keyname>Nebe</keyname><forenames>Gabriele</forenames></author><author><keyname>Rains</keyname><forenames>E. M.</forenames></author><author><keyname>Sloane</keyname><forenames>N. J. A.</forenames></author></authors><title>Codes and Invariant Theory</title><categories>math.NT cs.IT math.IT</categories><msc-class>94B05, 13A50, 94B60</msc-class><abstract>  The main theorem in this paper is a far-reaching generalization of Gleason's
theorem on the weight enumerators of codes which applies to arbitrary-genus
weight enumerators of self-dual codes defined over a large class of finite
rings and modules. The proof of the theorem uses a categorical approach, and
will be the subject of a forthcoming book. However, the theorem can be stated
and applied without using category theory, and we illustrate it here by
applying it to generalized doubly-even codes over fields of characteristic 2,
doubly-even codes over the integers modulo a power of 2, and self-dual codes
over the noncommutative ring $\F_q + \F_q u$, where $u^2 = 0$..
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0311047</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0311047</id><created>2003-11-04</created><authors><author><keyname>Shpilrain</keyname><forenames>Vladimir</forenames></author></authors><title>Assessing security of some group based cryptosystems</title><categories>math.GR cs.CC cs.CR</categories><comments>10 pages</comments><msc-class>20F36; 68Q17</msc-class><abstract>  One of the possible generalizations of the discrete logarithm problem to
arbitrary groups is the so-called conjugacy search problem (sometimes
erroneously called just the conjugacy problem): given two elements a, b of a
group G and the information that a^x=b for some x \in G, find at least one
particular element x like that. Here a^x stands for xax^{-1}. The computational
difficulty of this problem in some particular groups has been used in several
group based cryptosystems. Recently, a few preprints have been in circulation
that suggested various &quot;neighbourhood search&quot; type heuristic attacks on the
conjugacy search problem. The goal of the present survey is to stress a
(probably well known) fact that these heuristic attacks alone are not a threat
to the security of a cryptosystem, and, more importantly, to suggest a more
credible approach to assessing security of group based cryptosystems. Such an
approach should be necessarily based on the concept of the average case
complexity (or expected running time) of an algorithm.
  These arguments support the following conclusion: although it is generally
feasible to base the security of a cryptosystem on the difficulty of the
conjugacy search problem, the group G itself (the &quot;platform&quot;) has to be chosen
very carefully. In particular, experimental as well as theoretical evidence
collected so far makes it appear likely that braid groups are not a good choice
for the platform. We also reflect on possible replacements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0311129</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0311129</id><created>2003-11-09</created><updated>2005-02-10</updated><authors><author><keyname>Gold</keyname><forenames>Leah</forenames></author><author><keyname>Little</keyname><forenames>John</forenames></author><author><keyname>Schenck</keyname><forenames>Hal</forenames></author></authors><title>Cayley-Bacharach and evaluation codes on complete intersections</title><categories>math.AG cs.IT math.AC math.IT</categories><comments>10 pages. v2: minor expository changes</comments><msc-class>14G50 (Primary) 94B27 (Secondary)</msc-class><journal-ref>J. Pure Applied Algebra 196 (2005) 91-99</journal-ref><abstract>  In recent work, J. Hansen uses cohomological methods to find a lower bound
for the minimum distance of an evaluation code determined by a reduced complete
intersection in the projective plane. In this paper, we generalize Hansen's
results from P^2 to P^m; we also show that the hypotheses in Hansen's work may
be weakened. The proof is succinct and follows by combining the
Cayley-Bacharach theorem and bounds on evaluation codes obtained from reduced
zero-schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0311228</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0311228</id><created>2003-11-13</created><updated>2010-05-21</updated><authors><author><keyname>Cortes</keyname><forenames>C.</forenames></author><author><keyname>Grima</keyname><forenames>C. I.</forenames></author><author><keyname>Hurtado</keyname><forenames>F.</forenames></author><author><keyname>Marquez</keyname><forenames>A.</forenames></author><author><keyname>Santos</keyname><forenames>F.</forenames></author><author><keyname>Valenzuela</keyname><forenames>J.</forenames></author></authors><title>Transforming triangulations on non planar-surfaces</title><categories>math.MG cs.CG</categories><comments>19 pages, 17 figures. This version has been accepted in the SIAM
  Journal on Discrete Mathematics. Keywords: Graph of triangulations,
  triangulations on surfaces, triangulations of polygons, edge flip</comments><msc-class>68U05</msc-class><journal-ref>SIAM J. Discrete Math. 24:3 (2010), 821-840</journal-ref><doi>10.1137/070697987</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider whether any two triangulations of a polygon or a point set on a
non-planar surface with a given metric can be transformed into each other by a
sequence of edge flips. The answer is negative in general with some remarkable
exceptions, such as polygons on the cylinder, and on the flat torus, and
certain configurations of points on the cylinder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0311289</identifier>
 <datestamp>2014-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0311289</id><created>2003-11-17</created><authors><author><keyname>Nebe</keyname><forenames>Gabriele</forenames></author><author><keyname>Quebbemann</keyname><forenames>H. -G.</forenames></author><author><keyname>Rains</keyname><forenames>E. M.</forenames></author><author><keyname>Sloane</keyname><forenames>N. J. A.</forenames></author></authors><title>Complete Weight Enumerators of Generalized Doubly-Even Self-Dual Codes</title><categories>math.NT cs.IT math.IT</categories><msc-class>94B05, 13A50, 94B60</msc-class><journal-ref>Finite Fields Applic. 10 (2004), 540-550</journal-ref><abstract>  For any q which is a power of 2 we describe a finite subgroup of the group of
invertible complex q by q matrices under which the complete weight enumerators
of generalized doubly-even self-dual codes over the field with q elements are
invariant.
  An explicit description of the invariant ring and some applications to
extremality of such codes are obtained in the case q=4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0311319</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0311319</id><created>2003-11-18</created><authors><author><keyname>Calderbank</keyname><forenames>A. R.</forenames></author><author><keyname>Sloane</keyname><forenames>N. J. A.</forenames></author></authors><title>Modular and p-adic cyclic codes</title><categories>math.CO cs.IT math.IT</categories><comments>18 pages</comments><msc-class>94B15, 94B05</msc-class><journal-ref>Designs, Codes and Cryptography, Vol. 6 (1995), 21-35</journal-ref><abstract>  This paper presents some basic theorems giving the structure of cyclic codes
of length n over the ring of integers modulo p^a and over the p-adic numbers,
where p is a prime not dividing n. An especially interesting example is the
2-adic cyclic code of length 7 with generator polynomial X^3 + lambda X^2 +
(lambda - 1) X - 1, where lambda satisfies lambda^2 - lambda + 2 =0. This is
the 2-adic generalization of both the binary Hamming code and the quaternary
octacode (the latter being equivalent to the Nordstrom-Robinson code). Other
examples include the 2-adic Golay code of length 24 and the 3-adic Golay code
of length 12.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0312092</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0312092</id><created>2003-12-03</created><authors><author><keyname>Gluesing-Luerssen</keyname><forenames>Heide</forenames></author><author><keyname>Langfeld</keyname><forenames>Barbara</forenames></author></authors><title>On the Parameters of Convolutional Codes with Cyclic Structure</title><categories>math.RA cs.IT math.CO math.IT</categories><msc-class>94B10; 94B15; 16S36</msc-class><abstract>  In this paper convolutional codes with cyclic structure will be investigated.
These codes can be understood as left principal ideals in a suitable
skew-polynomial ring. It has been shown in [3] that only certain combinations
of the parameters (field size, length, dimension, and Forney indices) can occur
for cyclic codes. We will investigate whether all these combinations can indeed
be realized by a suitable cyclic code and, if so, how to construct such a code.
A complete characterization and construction will be given for minimal cyclic
codes. It is derived from a detailed investigation of the units in the
skew-polynomial ring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0312171</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0312171</id><created>2003-12-08</created><authors><author><keyname>Fiedler</keyname><forenames>Bernd</forenames></author></authors><title>Short formulas for algebraic covariant derivative curvature tensors via
  Algebraic Combinatorics</title><categories>math.CO cs.SC math.DG</categories><comments>38 pages</comments><msc-class>53B20, 15A72, 05E10, 16D60, 05-04</msc-class><abstract>  We consider generators of algebraic covariant derivative curvature tensors R'
which can be constructed by a Young symmetrization of product tensors W*U or
U*W, where W and U are covariant tensors of order 2 and 3. W is a symmetric or
alternating tensor whereas U belongs to a class of the infinite set S of
irreducible symmetry classes characterized by the partition (2,1). Using
Computer Algebra we search for such generators whose coordinate representations
are polynomials with a minimal number of summands. For a generic choice of the
symmetry class of U we obtain lengths of 16 or 20 summands if W is symmetric or
skew-symmetric, respectively. In special cases these numbers can be reduced to
the minima 12 or 10. If these minima occur then U admits an index commutation
symmetry. Furthermore minimal lengths are possible if U is formed from
torsion-free covariant derivatives of symmetric or alternating 2-tensor fields.
Foundation of our investigations is a theorem of S. A. Fulling, R. C. King, B.
G. Wybourne and C. J. Cummins about a Young symmetrizer that generates the
symmetry class of algebraic covariant derivative curvature tensors. Furthermore
we apply ideals and idempotents in group rings C[S_r] and discrete Fourier
transforms for symmetric groups S_r. For symbolic calculations we used the
Mathematica packages Ricci and PERMS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0312397</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0312397</id><created>2003-12-20</created><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>On Simple Characterisations of Sheffer psi- polynomials and Related
  Propositions of the Calculus of Sequences</title><categories>math.CO cs.DM</categories><msc-class>05A40, 81S99</msc-class><journal-ref>Bull. Soc. Sci. Lett. Lodz Ser. Rech. Deform. 52, Ser. Rech.
  Deform. 36 (2002) pp.45-65</journal-ref><abstract>  A calculus of sequences started in 1936 opened the way for future extensions
of umbral calculus in its finite operator form. Because of historically
established notation we call it the psi-calculus.It appears in parts to be
almost automatic extension of the standard classical finite operator calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0312422</identifier>
 <datestamp>2010-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0312422</id><created>2003-12-22</created><updated>2004-04-06</updated><authors><author><keyname>Pastro</keyname><forenames>C. A.</forenames></author></authors><title>\Sigma\Pi-polycategories, additive linear logic, and process semantics</title><categories>math.CT cs.LO math.LO</categories><comments>175 pages, University of Calgary Master's thesis</comments><report-no>Master's thesis, University of Calgary, 2004</report-no><msc-class>18A15, 03F52, 68Q85</msc-class><abstract>  We present a process semantics for the purely additive fragment of linear
logic in which formulas denote protocols and (equivalence classes of) proofs
denote multi-channel concurrent processes. The polycategorical model induced by
this process semantics is shown to be equivalent to the free polycategory based
on the syntax (i.e., it is full and faithfully complete). This establishes that
the additive fragment of linear logic provides a semantics of concurrent
processes. Another property of this semantics is that it gives a canonical
representation of proofs in additive linear logic.
  This arXived version omits Section 1.7.1: &quot;Circuit diagrams for
polycategories&quot; as the Xy-pic diagrams would not compile due to lack of memory.
For a complete version see &quot;http://www.cpsc.ucalgary.ca/~pastroc/&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0401045</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0401045</id><created>2004-01-06</created><authors><author><keyname>Han</keyname><forenames>Guangyue</forenames></author><author><keyname>Rosenthal</keyname><forenames>Joachim</forenames></author></authors><title>Unitary Space Time Constellation Analysis: An Upper Bound for the
  Diversity</title><categories>math.CO cs.IT math.IT</categories><comments>15 pages, 3 figures, submitted to IEEE trans. info</comments><msc-class>68P30, 94A05</msc-class><abstract>  The diversity product and the diversity sum are two very important parameters
for a good-performing unitary space time constellation. A basic question is
what the maximal diversity product (or sum) is. In this paper we are going to
derive general upper bounds on the diversity sum and the diversity product for
unitary constellations of any dimension $n$ and any size $m$ using packing
techniques on the compact Lie group U(n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0401083</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0401083</id><created>2004-01-08</created><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>On extended umbral calculus, oscillator-like algebras and Generalized
  Clifford Algebra</title><categories>math.QA cs.DM</categories><msc-class>05A30</msc-class><journal-ref>Advances in Applied Clifford Algebras 11 No2 267-279 (2001)</journal-ref><abstract>  Some quantum algebras build from deformed oscillator algebras may be
described in terms of a particular case of extended umbral calculus. We give
here an example of a specific relation between such certain quantum algebras
and generalized Clifford algebras also in the context of azimuthal quantization
of angular momentum which was interpreted afterwards as the finite dimensional
quantum mechanics .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0401157</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0401157</id><created>2004-01-14</created><authors><author><keyname>Han</keyname><forenames>Guangyue</forenames></author></authors><title>Generalized PSK in Space Time Coding</title><categories>math.CO cs.IT math.IT math.OC</categories><comments>22 pages, 3 figures, submitted to IEEE transactions on communicatons</comments><msc-class>68P30, 94A05</msc-class><abstract>  A wireless communication system using multiple antennas promises reliable
transmission under Rayleigh flat fading assumptions. Design criteria and
practical schemes have been presented for both coherent and non-coherent
communication channels. In this paper we generalize one dimensional phase shift
keying (PSK) signals and introduce space time constellations from generalized
phase shift keying (GPSK) signals based on the complex and real orthogonal
designs. The resulting space time constellations reallocate the energy for each
transmitting antenna and feature good diversity products, consequently their
performances are better than some of the existing comparable codes. Moreover
since the maximum likelihood (ML) decoding of our proposed codes can be
decomposed to one dimensional PSK signal demodulation, the ML decoding of our
codes can be implemented in a very efficient way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0401279</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0401279</id><created>2004-01-21</created><authors><author><keyname>Andrle</keyname><forenames>M.</forenames></author><author><keyname>Rebollo-Neira</keyname><forenames>L.</forenames></author><author><keyname>Sagianos</keyname><forenames>E.</forenames></author></authors><title>Backward Optimized Orthogonal Matching Pursuit</title><categories>math.GM cs.IT math.IT</categories><comments>Accpeted for publication in IEEE Signal Processing Letters- 15 pages</comments><msc-class>41A45</msc-class><doi>10.1109/LSP.2004.833503</doi><abstract>  A recursive approach for shrinking coefficients of an atomic decomposition is
proposed. The corresponding algorithm evolves so as to provide at each
iteration a) the orthogonal projection of a signal onto a reduced subspace and
b) the index of the coefficient to be disregarded in order to construct a
coarser approximation minimizing the norm of the residual error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0402078</identifier>
 <datestamp>2015-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0402078</id><created>2004-02-05</created><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>Towards psi-extension of Rota`s Finite Operator Calculus</title><categories>math.CO cs.DM</categories><comments>38 pages</comments><msc-class>05A40</msc-class><journal-ref>Reports on Mathematical Physics Vol. 48 No 3 (2001) : 305-342</journal-ref><doi>10.1016/S0034-4877(01)80092-6</doi><abstract>  A class of extended umbral calculi in operator form is presented. Extensions
of all basic theorems of classical Finite Operator Calculus are shown to hold.
The impossibility of straightforward extending of quantum q-plane formulation
of the q-umbral caculus to the general psi-calculus case is demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0402125</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0402125</id><created>2004-02-09</created><updated>2004-02-17</updated><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>Poisson, Dobinski, Rota and coherent states</title><categories>math.CO cs.DM</categories><comments>2 pages</comments><msc-class>05A40, 81S99</msc-class><journal-ref>Bulletin de la Societe des Sciences et des Lettres de
  {\pounds}\'od\^e (54) Serie: Recherches sur les Deformations Vol. 45 (2004)
  17-19</journal-ref><abstract>  New q- Dobinski formula might also be interpreted as the average of specific
q-powers of random variable X with the usual Poisson distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0402254</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0402254</id><created>2004-02-16</created><updated>2004-02-17</updated><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>q-Poisson, q-Dobinski, q-Rota and q-coherent states</title><categories>math.CO cs.DM</categories><comments>4 pages</comments><msc-class>05A40, 81S99</msc-class><journal-ref>Proc. Jangjeon Math. Soc. Vol. 7 (2), 2004 pp. 95-98</journal-ref><abstract>  q- Dobinski formula may be interpreted as the average of powers of a random
variable X_q with the q- Poisson distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0402291</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0402291</id><created>2004-02-17</created><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>Information on Combinatorial Interpretation of Fibonomial Coefficients</title><categories>math.CO cs.DM</categories><msc-class>11Bxx: 11B39</msc-class><journal-ref>Bull. Soc. Sci. Lett. Lodz Ser. Rech. Deform. 53, Ser.
  Rech.Deform. 42 (2002) pp.39-41</journal-ref><abstract>  Fibonomial coefficients count the number of specific finite birth
self-similar subposets of an infinite non-tree poset naturally related to the
Fibonacci tree of rabbits growth process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0402344</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0402344</id><created>2004-02-23</created><updated>2004-10-24</updated><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>More on combinatorial interpretation of the fibonomial coefficients</title><categories>math.CO cs.DM</categories><msc-class>11Bxx: 11B39</msc-class><journal-ref>Bulletin de la Societe des Sciences et des Lettres de
  {\pounds}\'od\^e (54) Serie: Recherches sur les Deformations Vol. 44 (2004)
  23-38</journal-ref><abstract>  Combinatorial interpretation of the fibonomial coefficients as a number of
choices of specific finite subsets of an infinite partially ordered set of not
binomial type is proposed. This partially ordered set is here defined via
characteristic matrix of the corresponding partial order relation . Relevance
of the proposal to more general unification treatment is indicated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0402346</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0402346</id><created>2004-02-21</created><updated>2011-04-14</updated><authors><author><keyname>Saveliev</keyname><forenames>Peter</forenames></author></authors><title>Applications of Lefschetz numbers in control theory</title><categories>math.OC cs.SY math.AT</categories><comments>The paper has been completely rewritten. 15 pages</comments><msc-class>55M20, 55H25, 93B</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop some applications of techniques of the Lefschetz coincidence
theory in control theory. The topics are existence of equilibria and their
robustness, controllability and its robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0403017</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0403017</id><created>2004-02-29</created><updated>2004-03-11</updated><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>Combinatorial interpretation of the recurrence relation for fibonomial
  coefficients</title><categories>math.CO cs.DM</categories><comments>12 pages, 5 figures</comments><msc-class>11Bxx: 11B39</msc-class><journal-ref>Bulletin de la Societe des Sciences et des Lettres de
  {\pounds}\'od\^e (54) Serie: Recherches sur les Deformations Vol. 44 (2004)
  pp. 23-38</journal-ref><abstract>  Combinatorial interpretation of the fibonomial coefficients recently proposed
by the present author results here in combinatorial interpretation of the
recurrence relation for fibonomial coefficients . The presentation is provided
with quite an exhaustive context where apart from plane grid coordinate system
used several figures illustrate the exposition of statements and the derivation
of the recurrence itself.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0403054</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0403054</id><created>2004-03-02</created><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>$\psi$-Poisson, $q$-Cigler, $\psi$-Dobinski, $\psi$-Rota and
  $\psi$-coherent states</title><categories>math.CO cs.DM</categories><comments>6 pages</comments><msc-class>05A40, 81S99</msc-class><journal-ref>Proc. Jangjeon Math. Soc. Vol. 7 (2), 2004 pp. 95-98</journal-ref><abstract>  Cigler simple derivation of usual and extended Dobinski formula is recalled
and it is noted that both may be interpreted as averages of powers of random
variables with the corresponding usual or extended Poisson distributions. In
parallel more general formulas of extended operator umbral calculi origin are
revealed . The formulas encompass both earlier cases as very specific ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0403107</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0403107</id><created>2004-03-05</created><authors><author><keyname>Kwasniewski</keyname><forenames>A. KL.</forenames></author></authors><title>Cauchy type identities and corresponding fermatian matrices via
  non-comuting variables of extended finite operator calculus</title><categories>math.CO cs.DM</categories><comments>5 pages</comments><msc-class>05A40, 81S99</msc-class><journal-ref>Proc. Jangjeon Math. Soc. Vol 8 (2005) no. 2. pp.191-196</journal-ref><abstract>  New family of extended Cauchy type identities is found and related Fermat
type matrices are provided ready for applications in extended scope. This is
achieved due to the use specifically non-commuting variables of extended finite
operator calculus introduced by the author few years ago.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0403123</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0403123</id><created>2004-03-07</created><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>Pascal like matrices - an accessible factory of one source identities
  and resulting applications</title><categories>math.CO cs.DM</categories><comments>8 pages</comments><msc-class>05A40, 81S99</msc-class><journal-ref>Adv. Stud. Contemp. Math. 10 (2005) No. 2, pp. 111-120</journal-ref><abstract>  The extension of pascalian like matrices depending on a variable from any
field of zero characteristics are shown at work for the first time. Their
properties appear to be one source factory of identities and resulting foreseen
applications
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0403139</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0403139</id><created>2004-03-08</created><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>First contact remarks on umbra difference calculus references streams</title><categories>math.CO cs.DM</categories><comments>10 pages</comments><msc-class>05A40, 81S99</msc-class><journal-ref>Bull. Soc. Sci. Lett. Lodz, 60, (2005) pp. 17-25 ArXiv:
  math.CO/0403139</journal-ref><abstract>  The reference links to the modern classical umbral calculus before that known
as blissardian symbolic method are numerous. Rota founded and then extended
finite operator calculus has links to references which are plenty numerous. The
references via links to the difference q calculus umbra way treaded or without
even referring to umbra are giant numerous. These reference links now result in
counting in thousands the relevant papers .
  The purpose of the present attempt is to offer one of the keys to enter the
world of those thousands of references.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0403548</identifier>
 <datestamp>2014-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0403548</id><created>2004-03-31</created><authors><author><keyname>Joyner</keyname><forenames>David</forenames></author><author><keyname>Shokranian</keyname><forenames>Salahoddin</forenames></author></authors><title>Remarks on codes from modular curves: MAGMA applications</title><categories>math.NT cs.IT math.AG math.IT</categories><comments>29 pages</comments><msc-class>14H37, 94B27,20C20,11T71,14G50,05E20,14Q05</msc-class><journal-ref>Algebr. Geom. Topol. 12 (2012) 2259-2286</journal-ref><doi>10.2140/agt.2012.12.2259</doi><abstract>  Expository paper discussing AG or Goppa codes arising from curves, first from
an abstract general perspective then turning to concrete examples associated to
modular curves. We will try to explain these extremely technical ideas using a
special case at a level to a typical graduate student with some background in
modular forms, number theory, group theory, and algebraic geometry. Many
examples using MAGMA are included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0404076</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0404076</id><created>2004-04-05</created><updated>2007-05-17</updated><authors><author><keyname>Garber</keyname><forenames>D.</forenames></author><author><keyname>Kaplan</keyname><forenames>S.</forenames></author><author><keyname>Teicher</keyname><forenames>M.</forenames></author><author><keyname>Tsaban</keyname><forenames>B.</forenames></author><author><keyname>Vishne</keyname><forenames>U.</forenames></author></authors><title>Probabilistic Solutions of Equations in the Braid Group</title><categories>math.GR cs.CR math.GT</categories><comments>Small updates</comments><journal-ref>Advances in Applied Mathematics 35 (2005), 323--334</journal-ref><doi>10.1016/j.aam.2005.03.002</doi><abstract>  Given a system of equations in a &quot;random&quot; finitely generated subgroup of the
braid group, we show how to find a small ordered list of elements in the
subgroup, which contains a solution to the equations with a significant
probability. Moreover, with a significant probability, the solution will be the
first in the list. This gives a probabilistic solution to: The conjugacy
problem, the group membership problem, the shortest representation of an
element, and other combinatorial group-theoretic problems in random subgroups
of the braid group.
  We use a memory-based extension of the standard length-based approach, which
in principle can be applied to any group admitting an efficient, reasonably
behaving length function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0404158</identifier>
 <datestamp>2008-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0404158</id><created>2004-04-07</created><updated>2004-04-28</updated><authors><author><keyname>Krot</keyname><forenames>Ewa</forenames></author></authors><title>A note on mobiusien function and mobiusien inversion formula of
  fibonacci cobweb poset</title><categories>math.CO cs.DM</categories><comments>6 pages</comments><msc-class>11Bxx; 11B39</msc-class><journal-ref>Bulletin de la Societe des Sciences et des Lettres de Lodz (54),
  Serie: Recherches sur les Deformations Vol. 44 (2004), 39-44</journal-ref><abstract>  The explicit formula for mobiusien function of fibonacci cobweb poset P is
given for the first time by the use of definition of P in plane grid coordinate
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0404325</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0404325</id><created>2004-04-18</created><authors><author><keyname>Jiang</keyname><forenames>Tao</forenames></author><author><keyname>Vardy</keyname><forenames>Alexander</forenames></author></authors><title>Asymptotic Improvement of the Gilbert-Varshamov Bound on the Size of
  Binary Codes</title><categories>math.CO cs.IT math.AC math.IT</categories><comments>10 pages, 3 figures; to appear in the IEEE Transactions on
  Information Theory, submitted August 12, 2003, revised March 28, 2004</comments><msc-class>05C90, 94B65 (Primary) 05A16, 05C69 (secondary)</msc-class><journal-ref>IEEE TRANSACTIONS ON INFORMATION THEORY, vol. 50, No. 8, pp.
  1655-1664, August 2004
  (http://www.ieeexplore.ieee.org/iel5/18/29198/01317112.pdf)</journal-ref><doi>10.1109/TIT.2004.831751</doi><abstract>  Given positive integers $n$ and $d$, let $A_2(n,d)$ denote the maximum size
of a binary code of length $n$ and minimum distance $d$. The well-known
Gilbert-Varshamov bound asserts that $A_2(n,d) \geq 2^n/V(n,d-1)$, where
$V(n,d) = \sum_{i=0}^{d} {n \choose i}$ is the volume of a Hamming sphere of
radius $d$. We show that, in fact, there exists a positive constant $c$ such
that $$ A_2(n,d) \geq c \frac{2^n}{V(n,d-1)} \log_2 V(n,d-1) $$ whenever $d/n
\le 0.499$. The result follows by recasting the Gilbert- Varshamov bound into a
graph-theoretic framework and using the fact that the corresponding graph is
locally sparse. Generalizations and extensions of this result are briefly
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0405082</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0405082</id><created>2004-05-05</created><authors><author><keyname>Cheng</keyname><forenames>Qi</forenames></author><author><keyname>Wan</keyname><forenames>Daqing</forenames></author></authors><title>On the List and Bounded Distance Decodibility of the Reed-Solomon Codes</title><categories>math.NT cs.IT math.IT</categories><msc-class>11Y16; 68Q25</msc-class><abstract>  In this paper show that the list and bounded-distance decoding problems of
certain bounds for the Reed-Solomon code are at least as hard as the discrete
logarithm problem over finite fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0405577</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0405577</id><created>2004-05-29</created><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>On $\psi$-basic bernoulli-wardian polynomials</title><categories>math.CO cs.DM</categories><msc-class>05A40, 11B39, 11B137</msc-class><journal-ref>Bulletin de la Societe des Sciences et des Lettres de
  {\pounds}\'od\^e (54) Serie: Recherches sur les Deformations Vol. 45 (2004)
  5-10</journal-ref><abstract>  The wardian solution of any $\psi$-difference linear nonhomogeneous equation
is found in the framework of the generalized finite operator calculus .
Specifications to $q$-calculus case and the new one fibonomial calculus case
are made explicit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0405578</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0405578</id><created>2004-05-29</created><updated>2004-11-13</updated><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>$\psi$-Appell polynomials` solutions of an umbral difference
  nonhomogeneous equation</title><categories>math.CO cs.DM</categories><msc-class>05A40, 11B39, 11B137</msc-class><journal-ref>Bulletin de la Societe des Sciences et des Lettres de
  {\pounds}\'od\^e (54) Serie: Recherches sur les Deformations Vol. 45 (2004)
  11-15</journal-ref><abstract>  One discovers why the solution of generalized umbral calculus difference
nonhomogeneous equation in the form recently proposed by the author extends
here now to generalized appellian delta operator and corresponding polynomials
case almost automatically. The reason for that is just the proper framework of
the generalized finite operator calculus recently being developed by the
present author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0405591</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0405591</id><created>2004-05-31</created><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>Fibonacci q-gaussian sequences</title><categories>math.CO cs.DM</categories><comments>5 pages, 2 figures</comments><msc-class>11B37, 11B39</msc-class><journal-ref>Advanced Studies in Contemporary Mathematics vol. 8 (2004) No2
  pp.121-124</journal-ref><abstract>  The summation formula within pascalian triangle resulting in the fibonacci
sequence is extended to the $q$-binomial coefficients $q$-gaussian triangles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0406006</identifier>
 <datestamp>2009-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0406006</id><created>2004-05-31</created><updated>2009-02-19</updated><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>Fibonomial cumulative connection constants</title><categories>math.CO cs.DM</categories><comments>affiliated to The Internet Gian-Carlo Polish Seminar:
  http://ii.uwb.edu.pl/akk/sem/sem_rota.htm</comments><msc-class>11B37, 11B39</msc-class><journal-ref>Bulletin of the ICA vol. 44 (2005) 81-92</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we present examples of cumulative connection constants included
new fibonomial ones. All examples posses combinatorial interpretation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0406077</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0406077</id><created>2004-06-04</created><authors><author><keyname>Grunwald</keyname><forenames>Peter</forenames></author></authors><title>A tutorial introduction to the minimum description length principle</title><categories>math.ST cs.IT cs.LG math.IT stat.TH</categories><comments>80 pages 5 figures Report with 2 chapters</comments><msc-class>6201; 6801; 68T05; 68T10; 9401</msc-class><abstract>  This tutorial provides an overview of and introduction to Rissanen's Minimum
Description Length (MDL) Principle. The first chapter provides a conceptual,
entirely non-technical introduction to the subject. It serves as a basis for
the technical introduction given in the second chapter, in which all the ideas
of the first chapter are made mathematically precise. The main ideas are
discussed in great conceptual and technical detail. This tutorial is an
extended version of the first two chapters of the collection &quot;Advances in
Minimum Description Length: Theory and Application&quot; (edited by P.Grunwald, I.J.
Myung and M. Pitt, to be published by the MIT Press, Spring 2005).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0406094</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0406094</id><created>2004-06-05</created><authors><author><keyname>Chassaing</keyname><forenames>Philippe</forenames></author><author><keyname>Marchand</keyname><forenames>Regine</forenames></author></authors><title>Merging costs for the additive Marcus-Lushnikov process, and Union-Find
  algorithms</title><categories>math.PR cs.DS math.CO</categories><comments>28 pages, 1 figure</comments><proxy>ccsd ccsd-00001664</proxy><msc-class>68P10 (Primary) 60C05, 60J65, 68R05 (Secondary)</msc-class><abstract>  Starting with a monodisperse configuration with $n$ size-1 particles, an
additive Marcus-Lushnikov process evolves until it reaches its final state (a
unique particle with mass $n$). At each of the $n-1$ steps of its evolution, a
merging cost is incurred, that depends on the sizes of the two particles
involved, and on an independent random factor. This paper deals with the
asymptotic behaviour of the cumulated costs up to the $k$th clustering, under
various regimes for $(n,k)$, with applications to the study of Union--Find
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0406140</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0406140</id><created>2004-06-08</created><updated>2006-06-20</updated><authors><author><keyname>Gagarin</keyname><forenames>Andrei</forenames><affiliation>LaCIM, Universite du Quebec a Montreal</affiliation></author><author><keyname>Labelle</keyname><forenames>Gilbert</forenames><affiliation>LaCIM, Universite du Quebec a Montreal</affiliation></author><author><keyname>Leroux</keyname><forenames>Pierre</forenames><affiliation>LaCIM, Universite du Quebec a Montreal</affiliation></author></authors><title>The structure and labelled enumeration of K_{3,3}-subdivision-free
  projective-planar graphs</title><categories>math.CO cs.DM</categories><comments>Revised version. 20 pages. To appear in Pure Mathematics and
  Applications - Algebra and Theoretical Computer Science</comments><msc-class>05C30, 05C10 (Primary); 68R10 (Secondary)</msc-class><journal-ref>Pure Math. Appl. 16 (2005), no. 3, pp. 267-286</journal-ref><abstract>  We consider the class F of 2-connected non-planar K_{3,3}-subdivision-free
graphs that are embeddable in the projective plane. We show that these graphs
admit a unique decomposition as a graph K_5 (the core) where the edges are
replaced by two-pole networks constructed from 2-connected planar graphs. A
method to enumerate these graphs in the labelled case is described. Moreover,
we enumerate the homeomorphically irreducible graphs in F and homeomorphically
irreducible 2-connected planar graphs. Particular use is made of two-pole
directed series-parallel networks. We also show that the number m of edges of
graphs in F with n vertices satisfies the bound m &lt;=3n-6, for n &gt;= 6.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0406221</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0406221</id><created>2004-06-10</created><authors><author><keyname>Grunwald</keyname><forenames>Peter</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author></authors><title>Suboptimal behaviour of Bayes and MDL in classification under
  misspecification</title><categories>math.ST cs.IT cs.LG math.IT stat.TH</categories><comments>This is a slightly longer version of our paper at the COLT
  (Computational Learning Theory) 2004 Conference, containing two extra pages
  of discussion of the main results</comments><msc-class>62A01; 68T05; 68T10</msc-class><abstract>  We show that forms of Bayesian and MDL inference that are often applied to
classification problems can be *inconsistent*. This means there exists a
learning problem such that for all amounts of data the generalization errors of
the MDL classifier and the Bayes classifier relative to the Bayesian posterior
both remain bounded away from the smallest achievable generalization error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0406258</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0406258</id><created>2004-06-13</created><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>The logarithmic fibbinomial formula</title><categories>math.CO cs.DM</categories><comments>1 figure</comments><msc-class>11B37, 05A40, 81S99</msc-class><journal-ref>Adv. Stud. Contemp. Math. v.9 No.1 (2004) 19-26</journal-ref><abstract>  Roman logarithmic binomial formula analogue has been found . It is presented
here also for the case of fibonomial coefficients which recently have been
given a combinatorial interpretation by the present author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0406353</identifier>
 <datestamp>2012-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0406353</id><created>2004-06-17</created><updated>2007-06-20</updated><authors><author><keyname>Bartal</keyname><forenames>Yair</forenames></author><author><keyname>Linial</keyname><forenames>Nathan</forenames></author><author><keyname>Mendel</keyname><forenames>Manor</forenames></author><author><keyname>Naor</keyname><forenames>Assaf</forenames></author></authors><title>On metric Ramsey-type phenomena</title><categories>math.MG cs.DS</categories><comments>67 pages, published version</comments><msc-class>52C45, 05C55, 54E40, 05C12, 54E40</msc-class><journal-ref>Ann. of Math. (2) 162 (2005), no. 2, 643--709</journal-ref><doi>10.4007/annals.2005.162.643</doi><abstract>  The main question studied in this article may be viewed as a nonlinear
analogue of Dvoretzky's theorem in Banach space theory or as part of Ramsey
theory in combinatorics. Given a finite metric space on n points, we seek its
subspace of largest cardinality which can be embedded with a given distortion
in Hilbert space. We provide nearly tight upper and lower bounds on the
cardinality of this subspace in terms of n and the desired distortion. Our main
theorem states that for any epsilon&gt;0, every n point metric space contains a
subset of size at least n^{1-\epsilon} which is embeddable in Hilbert space
with O(\frac{\log(1/\epsilon)}{\epsilon}) distortion. The bound on the
distortion is tight up to the log(1/\epsilon) factor. We further include a
comprehensive study of various other aspects of this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0406416</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0406416</id><created>2004-06-22</created><updated>2005-12-06</updated><authors><author><keyname>Braverman</keyname><forenames>Mark</forenames></author><author><keyname>Yampolsky</keyname><forenames>Michael</forenames></author></authors><title>Non-computable Julia sets</title><categories>math.DS cs.CC</categories><comments>Updated version, to appear in JAMS</comments><msc-class>37F50, 68Q17</msc-class><abstract>  We show that under the definition of computability which is natural from the
point of view of applications, there exist non-computable quadratic Julia sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0408122</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0408122</id><created>2004-08-09</created><updated>2005-03-06</updated><authors><author><keyname>Erdahl</keyname><forenames>Robert</forenames></author><author><keyname>Ordine</keyname><forenames>Andrei</forenames></author><author><keyname>Rybnikov</keyname><forenames>Konstantin</forenames></author></authors><title>Perfect Delaunay Polytopes and Perfect Inhomogeneous Forms</title><categories>math.NT cs.CC cs.CG math.MG quant-ph</categories><comments>Release 3: 25 pages, 4 diagrams. A number of errors in notation,
  terminology, citations, and cross-references have been fixed. Note that in
  all diagrams kappa should read as k. A reduced 10 page version of this
  article will apear in the proceedings of the 2003 Voronoi Conference held in
  Kiev in September of 2003</comments><msc-class>Primary: 11H50 and 11H55. Secondary: 11H06, 52C07, 52C22</msc-class><abstract>  A lattice Delaunay polytope D is called perfect if it has the property that
there is a unique circumscribing ellipsoid with interior free of lattice
points, and with the surface containing only those lattice points that are the
vertices of D. An inhomogeneous quadratic form is called perfect if it is
determined by such a circumscribing ''empty ellipsoid'' uniquely up to a scale
factor. Perfect inhomogeneous forms are associated with perfect Delaunay
polytopes in much the way that perfect homogeneous forms are associated with
perfect point lattices. We have been able to construct some infinite sequences
of perfect Delaunay polytopes, one perfect polytope in each successive
dimension starting at some initial dimension; we have been able to construct an
infinite number of such infinite sequences. Perfect Delaunay polytopes are
intimately related to the theory of Delaunay polytopes, and to Voronoi's theory
of lattice types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0408146</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0408146</id><created>2004-08-11</created><authors><author><keyname>Dambreville</keyname><forenames>Frederic</forenames><affiliation>DGA/CTA/DT/GIP</affiliation></author></authors><title>Learning a Machine for the Decision in a Partially Observable Markov
  Universe</title><categories>math.GM cs.AI cs.LG</categories><comments>Writing date : July 30 2004 Submitted to the European Journal of
  Operation Research</comments><proxy>ccsd ccsd-00002521</proxy><abstract>  In this paper, we are interested in optimal decisions in a partially
observable Markov universe. Our viewpoint departs from the dynamic programming
viewpoint: we are directly approximating an optimal strategic tree depending on
the observation. This approximation is made by means of a parameterized
probabilistic law. In this paper, a particular family of hidden Markov models,
with input and output, is considered as a learning framework. A method for
optimizing the parameters of these HMMs is proposed and applied. This
optimization method is based on the cross-entropic principle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0408365</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0408365</id><created>2004-08-26</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Kempner</keyname><forenames>Yulia</forenames></author></authors><title>Quasi-concave functions on antimatroids</title><categories>math.CO cs.DM</categories><comments>7 pages</comments><msc-class>05B35 (Primary) 90C27 (Secondary)</msc-class><abstract>  In this paper we consider quasi-concave set functions defined on
antimatroids. There are many equivalent axiomatizations of antimatroids, that
may be separated into two categories: antimatroids defined as set systems and
antimatroids defined as languages. An algorthmic characterization of
antimatroids, that considers them as set systems, was given in (Kempner, Levit
2003). This characterization is based on the idea of optimization using set
functions defined as minimum values of linkages between a set and the elements
from the set complement. Such set functions are quasi-concave. Their behavior
on antimatroids was studied in (Kempner, Muchnik 2003), where they were applied
to constraint clustering. In this work we investigate a duality between
quasi-concave set functions and linkage functions. Our main finding is that
quasi-concave set functions on an antimatroid may be represented as minimum
values of some monotone linkage functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0409429</identifier>
 <datestamp>2011-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0409429</id><created>2004-09-22</created><authors><author><keyname>Roch</keyname><forenames>S.</forenames></author></authors><title>Bounding Fastest Mixing</title><categories>math.PR cs.DM math.CO math.ST stat.TH</categories><comments>20 pages</comments><msc-class>60J10</msc-class><abstract>  In a series of recent works, Boyd, Diaconis, and their co-authors have
introduced a semidefinite programming approach for computing the fastest mixing
Markov chain on a graph of allowed transitions, given a target stationary
distribution. In this paper, we show that standard mixing-time analysis
techniques--variational characterizations, conductance, canonical paths--can be
used to give simple, nontrivial lower and upper bounds on the fastest mixing
time. To test the applicability of this idea, we consider several detailed
examples including the Glauber dynamics of the Ising model--and get sharp
bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0409548</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0409548</id><created>2004-09-28</created><updated>2005-05-16</updated><authors><author><keyname>Zakai</keyname><forenames>Moshe</forenames></author></authors><title>On mutual information, likelihood-ratios and estimation error for the
  additive Gaussian channel</title><categories>math.PR cs.IT math.IT math.ST stat.TH</categories><comments>21 pages, to appear in the IEEE Transactions on Information Theory</comments><msc-class>Primary: 60G35, 60H07; Secondary: 93E10, 93E11, 94A17</msc-class><journal-ref>IEEE Trans. on Information Theory, Vol. 51(9), pp. 3017-3024,
  Sept. 2005</journal-ref><abstract>  This paper considers the model of an arbitrary distributed signal x observed
through an added independent white Gaussian noise w, y=x+w. New relations
between the minimal mean square error of the non-causal estimator and the
likelihood ratio between y and \omega are derived. This is followed by an
extended version of a recently derived relation between the mutual information
I(x;y) and the minimal mean square error. These results are applied to derive
infinite dimensional versions of the Fisher information and the de Bruijn
identity. The derivation of the results is based on the Malliavin calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0410068</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0410068</id><created>2004-10-04</created><authors><author><keyname>Shpilrain</keyname><forenames>Vladimir</forenames></author><author><keyname>Zapata</keyname><forenames>Gabriel</forenames></author></authors><title>Combinatorial group theory and public key cryptography</title><categories>math.GR cs.CR</categories><comments>12 pages</comments><abstract>  After some excitement generated by recently suggested public key exchange
protocols due to Anshel-Anshel-Goldfeld and Ko-Lee et al., it is a prevalent
opinion now that the conjugacy search problem is unlikely to provide sufficient
level of security if a braid group is used as the platform. In this paper we
address the following questions: (1) whether choosing a different group, or a
class of groups, can remedy the situation; (2) whether some other &quot;hard&quot;
problem from combinatorial group theory can be used, instead of the conjugacy
search problem, in a public key exchange protocol. Another question that we
address here, although somewhat vague, is likely to become a focus of the
future research in public key cryptography based on symbolic computation: (3)
whether one can efficiently disguise an element of a given group (or a
semigroup) by using defining relations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0410282</identifier>
 <datestamp>2012-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0410282</id><created>2004-10-11</created><authors><author><keyname>Benjamini</keyname><forenames>Itai</forenames></author><author><keyname>Schramm</keyname><forenames>Oded</forenames></author><author><keyname>Wilson</keyname><forenames>David B.</forenames></author></authors><title>Balanced Boolean functions that can be evaluated so that every input bit
  is unlikely to be read</title><categories>math.PR cs.CC</categories><comments>11 pages</comments><msc-class>60C05, 60J80</msc-class><journal-ref>Proc. 37th ACM Symposium on Theory of Computing (STOC), pages
  244--250, 2005</journal-ref><doi>10.1145/1060590.1060627</doi><abstract>  A Boolean function of n bits is balanced if it takes the value 1 with
probability 1/2. We exhibit a balanced Boolean function with a randomized
evaluation procedure (with probability 0 of making a mistake) so that on
uniformly random inputs, no input bit is read with probability more than
Theta(n^{-1/2} sqrt{log n}). We give a balanced monotone Boolean function for
which the corresponding probability is Theta(n^{-1/3} log n). We then show that
for any randomized algorithm for evaluating a balanced Boolean function, when
the input bits are uniformly random, there is some input bit that is read with
probability at least Theta(n^{-1/2}). For balanced monotone Boolean functions,
there is some input bit that is read with probability at least Theta(n^{-1/3}).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0410317</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0410317</id><created>2004-10-13</created><authors><author><keyname>Gluesing-Luerssen</keyname><forenames>Heide</forenames></author><author><keyname>Schmale</keyname><forenames>Wiland</forenames></author></authors><title>On doubly-cyclic convolutional codes</title><categories>math.RA cs.IT math.IT</categories><msc-class>94B10, 94B15, 16S36</msc-class><abstract>  Cyclicity of a convolutional code (CC) is relying on a nontrivial
automorphism of the algebra F[x]/(x^n-1), where F is a finite field. If this
automorphism itself has certain specific cyclicity properties one is lead to
the class of doubly-cyclic CC's. Within this large class Reed-Solomon and BCH
convolutional codes can be defined. After constructing doubly-cyclic CC's,
basic properties are derived on the basis of which distance properties of
Reed-Solomon convolutional codes are investigated.This shows that some of them
are optimal or near optimal with respect to distance and performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0410550</identifier>
 <datestamp>2008-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0410550</id><created>2004-10-26</created><updated>2004-10-27</updated><authors><author><keyname>Krot</keyname><forenames>Ewa</forenames></author></authors><title>Further developements in finite fibonomial calculus</title><categories>math.CO cs.DM</categories><comments>13 pages</comments><msc-class>11Bxx; 11B39</msc-class><abstract>  Primary definitions, notation and general observations of finite fibonomial
operator calculus (ffoc) are presented. Kwasniewski's combinatorial
interpretation of fibonomial coefficients by the use of fibonacci cobweb poset
is given. Some elements of incidence algebra of fibonacci cobweb poset are
defined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0410574</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0410574</id><created>2004-10-27</created><updated>2005-02-21</updated><authors><author><keyname>Podlubny</keyname><forenames>Igor</forenames></author></authors><title>A note on comparison of scientific impact expressed by the number of
  citations in different fields of science</title><categories>math.ST cs.GL physics.soc-ph stat.TH</categories><comments>5 pages, 1 table</comments><msc-class>00A99</msc-class><journal-ref>Scientometrics, Vol.64, no.1, July 2005, pp.95-99. Journal ISSN:
  0138-9130 (Paper) 1588-2861 (Online)</journal-ref><doi>10.1007/s11192-005-0240-0</doi><abstract>  Citation distributions for 1992, 1994, 1996, 1997, 1999, and 2001, which were
published in the 2004 report of the National Science Foundation, USA, are
analyzed. It is shown that the ratio of the total number of citations of any
two broad fields of science remains close to constant over the analyzed years.
Based on this observation, normalization of total numbers of citations with
respect to the number of citations in mathematics is suggested as a tool for
comparing scientific impact expressed by the number of citations in different
fields of science.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0410580</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0410580</id><created>2004-10-27</created><updated>2006-06-27</updated><authors><author><keyname>Binder</keyname><forenames>I.</forenames></author><author><keyname>Braverman</keyname><forenames>M.</forenames></author><author><keyname>Yampolsky</keyname><forenames>M.</forenames></author></authors><title>Filled Julia sets with empty interior are computable</title><categories>math.DS cs.CC</categories><comments>This is an expanded version, to appear in J. FoCM</comments><msc-class>37F10</msc-class><abstract>  We show that if a polynomial filled Julia set has empty interior, then it is
computable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0410593</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0410593</id><created>2004-10-27</created><authors><author><keyname>B&#xe4;&#xe4;rnhielm</keyname><forenames>Henrik</forenames></author></authors><title>The Schreier-Sims algorithm for matrix groups</title><categories>math.GR cs.DS</categories><comments>The author's MSc thesis. Uses AMS-LaTeX and algorithm2e.sty. For the
  associated source code, see http://matrixss.sourceforge.net/</comments><msc-class>20-04, 20G40, 20H30 (Primary) 68Q25, 68W20, 20B40 (Secondary)</msc-class><abstract>  This is the report of a project with the aim to make a new implementation of
the Schreier-Sims algorithm in GAP, specialized for matrix groups. The standard
Schreier-Sims algorithm is described in some detail, followed by descriptions
of the probabilistic Schreier-Sims algorithm and the Schreier-Todd-Coxeter-Sims
algorithm. Then we discuss our implementation and some optimisations, and
finally we report on the performance of our implementation, as compared to the
existing implementation in GAP, and we give benchmark results. The conclusion
is that our implementation in some cases is faster and consumes much less
memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0411002</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0411002</id><created>2004-10-31</created><updated>2005-10-19</updated><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>On umbral extensions of Stirling numbers and Dobinski-like formulas</title><categories>math.CO cs.DM</categories><comments>40 pages</comments><msc-class>05A40, 11B73, 81S99</msc-class><journal-ref>Adv. Stud. Contemp. Math., Vol 12, no. 1, (2006) 73-100</journal-ref><abstract>  Umbral extensions of the stirling numbers of the second kind are considered
and the resulting dobinski-like various formulas including new ones are
presented. These extensions naturally encompass the two well known
q-extensions. The further consecutive umbral extensions q-stirling numbers are
therefore realized here in a two-fold way. The fact that the umbral q-extended
dobinski formula may also be interpreted as the average of powers of random
variable with the q-poisson distribution singles out the q-extensions which
appear to be a kind of singular point in the domain of umbral extensions as
expressed by corresponding two observations. Other relevant possibilities are
tackled with the paper`s closing down questions and suggestions with respect to
other already existing extensions while a brief limited survey of these other
type extensions is being delivered. There the newton interpolation formula and
divided differences appear helpful and inevitable along with umbra symbolic
language in describing properties of general exponential polynomials of
touchard and their possible generalizations. Exponential structures or
algebraically equivalent prefabs with their exponential formula appear to be
also naturally relevant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0411007</identifier>
 <datestamp>2008-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0411007</id><created>2004-10-31</created><authors><author><keyname>Krot</keyname><forenames>Ewa</forenames></author></authors><title>The First Ascent into the Incidence Algebra of the Fibonacci Cobweb Poset</title><categories>math.CO cs.DM</categories><comments>7 pages</comments><msc-class>11Bxx, 11B39, 06Axx</msc-class><journal-ref>Advanced Studies in Conterporary Mathematics 11 (2005), No. 2,
  179-184</journal-ref><abstract>  The explicite formulas for m\&quot;{o}biusien function and some other important
elements of the incidence algebra are delivered. For that to do one uses
kwa\'sniewski's construction of his fibonacci cobweb poset in the plane grid
coordinate system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0411056</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0411056</id><created>2004-11-02</created><authors><author><keyname>Fiedler</keyname><forenames>Bernd</forenames></author></authors><title>Generators of algebraic curvature tensors based on a (2,1)-symmetry</title><categories>math.DG cs.SC math.CO</categories><comments>16 pages</comments><msc-class>53B20, 15A72, 05E10, 16D60, 05-04</msc-class><abstract>  We consider generators of algebraic curvature tensors R which can be
constructed by a Young symmetrization of product tensors U*w or w*U, where U
and w are covariant tensors of order 3 and 1. We assume that U belongs to a
class of the infinite set S of irreducible symmetry classes characterized by
the partition (2,1). We show that the set S contains exactly one symmetry class
S_0 whose elements U can not play the role of generators of tensors R. The
tensors U of all other symmetry classes from S\{S_0} can be used as generators
for tensors R. Using Computer Algebra we search for such generators whose
coordinate representations are polynomials with a minimal number of summands.
For a generic choice of the symmetry class of U we obtain lengths of 8
summands. In special cases these numbers can be reduced to the minimum 4. If
this minimum occurs then U admits an index commutation symmetry. Furthermore
minimal lengths are possible if U is formed from torsion-free covariant
derivatives of alternating 2-tensor fields. We apply ideals and idempotents of
group rings C[S_r] of symmetric groups S_r, Young symmetrizers, discrete
Fourier transforms and Littlewood-Richardson products. For symbolic
calculations we used the Mathematica packages Ricci and PERMS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0411107</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0411107</id><created>2004-11-04</created><updated>2006-01-23</updated><authors><author><keyname>Bihan</keyname><forenames>Frederic</forenames></author><author><keyname>Rojas</keyname><forenames>J. Maurice</forenames></author><author><keyname>Stella</keyname><forenames>Casey E.</forenames></author></authors><title>First Steps in Algorithmic Fewnomial Theory</title><categories>math.AG cs.CC math.AC</categories><comments>25 pages, 5 figures. MAJOR revision of earlier version: (1) Frederic
  Bihan is a new co-author, (2) Theorem 1 is strengthened with a much sharper
  complexity threshold, (3) bounds on connected components from Theorem 2 are
  dramatically sharpened, (4) Theorem 3 strengthened considerably, (5)
  Corollary 1 removed, but theorem of Karpinski+Shparlinski on univariate
  discriminants is inserted, to clarify complexity comparisons</comments><abstract>  Fewnomial theory began with explicit bounds -- solely in terms of the number
of variables and monomial terms -- on the number of real roots of systems of
polynomial equations. Here we take the next logical step of investigating the
corresponding existence problem: Let FEAS_R denote the problem of deciding
whether a given system of multivariate polynomial equations with integer
coefficients has a real root or not. We describe a phase-transition for when m
is large enough to make FEAS_R be NP-hard, when restricted to inputs consisting
of a single n-variate polynomial with exactly m monomial terms: polynomial-time
for m&lt;=n+2 (for any fixed n) and NP-hardness for m&lt;=n+n^{epsilon} (for n
varying and any fixed epsilon&gt;0). Because of important connections between
FEAS_R and A-discriminants, we then study some new families of A-discriminants
whose signs can be decided within polynomial-time. (A-discriminants contain all
known resultants as special cases, and the latter objects are central in
algorithmic algebraic geometry.) Baker's Theorem from diophantine approximation
arises as a key tool. Along the way, we also derive new quantitative bounds on
the real zero sets of n-variate (n+2)-nomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0411128</identifier>
 <datestamp>2014-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0411128</id><created>2004-11-06</created><authors><author><keyname>Banderier</keyname><forenames>Cyril</forenames><affiliation>LIPN</affiliation></author><author><keyname>Schwer</keyname><forenames>Sylviane</forenames><affiliation>LIPN</affiliation></author></authors><title>Why Delannoy numbers?</title><categories>math.CO cs.DS cs.GT math.HO math.PR math.ST q-bio.GN stat.TH</categories><comments>Presented to the conference &quot;Lattice Paths Combinatorics and Discrete
  Distributions&quot; (Athens, June 5-7, 2002) and to appear in the Journal of
  Statistical Planning and Inferences</comments><proxy>ccsd ccsd-00003233</proxy><journal-ref>Journal of Statistical Planning and Inference 135, 1 (11/2005)
  40-54</journal-ref><doi>10.1016/j.jspi.2005.02.004</doi><abstract>  This article is not a research paper, but a little note on the history of
combinatorics: We present here a tentative short biography of Henri Delannoy,
and a survey of his most notable works. This answers to the question raised in
the title, as these works are related to lattice paths enumeration, to the
so-called Delannoy numbers, and were the first general way to solve Ballot-like
problems. These numbers appear in probabilistic game theory, alignments of DNA
sequences, tiling problems, temporal representation models, analysis of
algorithms and combinatorial structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0411138</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0411138</id><created>2004-11-06</created><authors><author><keyname>Banderier</keyname><forenames>Cyril</forenames><affiliation>LIPN</affiliation></author><author><keyname>Bars</keyname><forenames>Jean-Marie Le</forenames><affiliation>LIPN, GREYC</affiliation></author><author><keyname>Ravelomanana</keyname><forenames>Vlady</forenames><affiliation>LIPN</affiliation></author></authors><title>Generating Functions For Kernels of Digraphs (Enumeration &amp; Asymptotics
  for Nim Games)</title><categories>math.CO cs.DM cs.DS cs.GT math.PR</categories><comments>Presented (as a poster) to the conference Formal Power Series and
  Algebraic Combinatorics (Vancouver, 2004), electronic proceedings</comments><proxy>ccsd ccsd-00003234</proxy><journal-ref>Proceedings of FPSAC'04 (2004) 91-105</journal-ref><abstract>  In this article, we study directed graphs (digraphs) with a coloring
constraint due to Von Neumann and related to Nim-type games. This is equivalent
to the notion of kernels of digraphs, which appears in numerous fields of
research such as game theory, complexity theory, artificial intelligence
(default logic, argumentation in multi-agent systems), 0-1 laws in monadic
second order logic, combinatorics (perfect graphs)... Kernels of digraphs lead
to numerous difficult questions (in the sense of NP-completeness,
#P-completeness). However, we show here that it is possible to use a generating
function approach to get new informations: we use technique of symbolic and
analytic combinatorics (generating functions and their singularities) in order
to get exact and asymptotic results, e.g. for the existence of a kernel in a
circuit or in a unicircuit digraph. This is a first step toward a
generatingfunctionology treatment of kernels, while using, e.g., an approach &quot;a
la Wright&quot;. Our method could be applied to more general &quot;local coloring
constraints&quot; in decomposable combinatorial structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0411145</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0411145</id><created>2004-11-07</created><updated>2005-09-21</updated><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>Information on some recent applications of umbral extensions to
  discrete mathematics</title><categories>math.CO cs.DM</categories><comments>14 pages</comments><msc-class>05A40, 11B73, 81S99</msc-class><journal-ref>Review Bulletin of Calcutta Mathematical Society Vol. 13 (2005)
  1-10</journal-ref><abstract>  At the first part of the paper we show how specific umbral extensions of the
Stirling numbers of the second kind result in new type of Dobinski-like
formulas. In the second part among others one recovers how and why Ward
solution of uncountable family of extended difference calculus nonhomogeneous
equations extends to Ward-Appell polynomials case . Illustrative specifications
to q-calculus case and fibonomial calculus case are made explicit due to the
usage of the so called upside down notation for objects of extended finite
operator calculus .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0411239</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0411239</id><created>2004-11-10</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>Very well-covered graphs with log-concave independence polynomials</title><categories>math.CO cs.DM</categories><comments>8 pages, 4 figures</comments><msc-class>Primary 05C69, 05E99; Secondary 11B83, 05A20</msc-class><abstract>  If for any $k$ the $k$-th coefficient of a polynomial $I(G;x)$ is equal to
the number of stable sets of cardinality $k$ in the graph $G$, then it is
called the independence polynomial of $G$ (Gutman and Harary, 1983). Alavi,
Malde, Schwenk and Erdos (1987) conjectured that $I(G;x)$ is unimodal, whenever
$G$ is a forest, while Brown, Dilcher and Nowakowski (2000) conjectured that
$I(G;x)$ is unimodal for any well-covered graph G. Michael and Traves (2003)
showed that the assertion is false for well-covered graphs with $a(G)$ &gt; 3
($a(G)$ is the size of a maximum stable set of the graph $G$), while for very
well-covered graphs the conjecture is still open. In this paper we give support
to both conjectures by demonstrating that if $a(G)$ &lt; 4, or $G$ belongs to
${K_{1,n}, P_{n}: n &gt; 0}$, then $I(G*;x)$ is log-concave, and, hence, unimodal
(where $G*$ is the very well-covered graph obtained from $G$ by appending a
single pendant edge to each vertex).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0411250</identifier>
 <datestamp>2014-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0411250</id><created>2004-11-11</created><authors><author><keyname>Banderier</keyname><forenames>Cyril</forenames><affiliation>LIPN, ALGO UR-R</affiliation></author><author><keyname>Flajolet</keyname><forenames>Philippe</forenames><affiliation>ALGO UR-R</affiliation></author><author><keyname>Gardy</keyname><forenames>Daniele</forenames><affiliation>PRISM</affiliation></author><author><keyname>Bousquet-Melou</keyname><forenames>Mireille</forenames><affiliation>LABRI</affiliation></author><author><keyname>Denise</keyname><forenames>Alain</forenames><affiliation>LRI</affiliation></author><author><keyname>Gouyou-Beauchamps</keyname><forenames>Dominique</forenames><affiliation>LRI</affiliation></author></authors><title>Generating functions for generating trees</title><categories>math.CO cs.DM cs.DS</categories><comments>This article corresponds, up to minor typo corrections, to the
  article submitted to Discrete Mathematics (Elsevier) in Nov. 1999, and
  published in its vol. 246(1-3), March 2002, pp. 29-55</comments><proxy>ccsd ccsd-00003258</proxy><journal-ref>Discrete Mathematics 246 (1-3) (2002) 29-55</journal-ref><doi>10.1016/S0012-365X(01)00250-3</doi><abstract>  Certain families of combinatorial objects admit recursive descriptions in
terms of generating trees: each node of the tree corresponds to an object, and
the branch leading to the node encodes the choices made in the construction of
the object. Generating trees lead to a fast computation of enumeration
sequences (sometimes, to explicit formulae as well) and provide efficient
random generation algorithms. We investigate the links between the structural
properties of the rewriting rules defining such trees and the rationality,
algebraicity, or transcendence of the corresponding generating function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0411356</identifier>
 <datestamp>2008-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0411356</id><created>2004-11-16</created><authors><author><keyname>Gagarin</keyname><forenames>Andrei</forenames><affiliation>LaCIM, Universite du Quebec a Montreal</affiliation></author><author><keyname>Labelle</keyname><forenames>Gilbert</forenames><affiliation>LaCIM, Universite du Quebec a Montreal</affiliation></author><author><keyname>Leroux</keyname><forenames>Pierre</forenames><affiliation>LaCIM, Universite du Quebec a Montreal</affiliation></author></authors><title>Characterization and enumeration of toroidal K_{3,3}-subdivision-free
  graphs</title><categories>math.CO cs.DM</categories><comments>18 pages, 7 figures and 4 tables</comments><msc-class>05C30, 05C10 (Primary); 68R10 (Secondary)</msc-class><journal-ref>Discrete Math. 307 (2007), no. 23, pp. 2993-3005</journal-ref><doi>10.1016/j.disc.2007.03.083</doi><abstract>  We describe the structure of 2-connected non-planar toroidal graphs with no
K_{3,3}-subdivisions, using an appropriate substitution of planar networks into
the edges of certain graphs called toroidal cores. The structural result is
based on a refinement of the algorithmic results for graphs containing a fixed
K_5-subdivision in [A. Gagarin and W. Kocay, &quot;Embedding graphs containing
K_5-subdivisions'', Ars Combin. 64 (2002), 33-49]. It allows to recognize these
graphs in linear-time and makes possible to enumerate labelled 2-connected
toroidal graphs containing no K_{3,3}-subdivisions and having minimum vertex
degree two or three by using an approach similar to [A. Gagarin, G. Labelle,
and P. Leroux, &quot;Counting labelled projective-planar graphs without a
K_{3,3}-subdivision&quot;, submitted, arXiv:math.CO/0406140, (2004)].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0411378</identifier>
 <datestamp>2008-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0411378</id><created>2004-11-17</created><updated>2005-09-02</updated><authors><author><keyname>Jao</keyname><forenames>David</forenames></author><author><keyname>Miller</keyname><forenames>Stephen D.</forenames></author><author><keyname>Venkatesan</keyname><forenames>Ramarathnam</forenames></author></authors><title>Do All Elliptic Curves of the Same Order Have the Same Difficulty of
  Discrete Log?</title><categories>math.NT cs.CC cs.CR math.AG math.CO</categories><comments>26 pages, revised, to appear in Advances in Cryptology -- Asiacrypt
  2005</comments><journal-ref>Advances in Cryptology -- Asiacrypt 2005, LNCS 3788, pp. 21-40.</journal-ref><doi>10.1007/11593447_2</doi><abstract>  The aim of this paper is to justify the common cryptographic practice of
selecting elliptic curves using their order as the primary criterion. We can
formalize this issue by asking whether the discrete log problem (DLOG) has the
same difficulty for all curves over a given finite field with the same order.
We prove that this is essentially true by showing polynomial time random
reducibility of DLOG among such curves, assuming the Generalized Riemann
Hypothesis (GRH). We do so by constructing certain expander graphs, similar to
Ramanujan graphs, with elliptic curves as nodes and low degree isogenies as
edges.
 The result is obtained from the rapid mixing of random walks on this graph.
Our proof works only for curves with (nearly) the same endomorphism rings.
Without this technical restriction such a DLOG equivalence might be false;
however, in practice the restriction may be moot, because all known polynomial
time techniques for constructing equal order curves produce only curves with
nearly equal endomorphism rings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0411488</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0411488</id><created>2004-11-22</created><updated>2005-09-28</updated><authors><author><keyname>Gagarin</keyname><forenames>Andrei</forenames></author><author><keyname>Myrvold</keyname><forenames>Wendy</forenames></author><author><keyname>Chambers</keyname><forenames>John</forenames></author></authors><title>The obstructions for toroidal graphs with no $K_{3,3}$'s</title><categories>math.CO cs.DM</categories><comments>10 pages, 7 figures, revised version with additional details</comments><journal-ref>Discrete Math. 309 (2009), no. 11, pp. 3625-3631</journal-ref><doi>10.1016/j.disc.2007.12.075</doi><abstract>  Forbidden minors and subdivisions for toroidal graphs are numerous. We
consider the toroidal graphs with no $K_{3,3}$-subdivisions that coincide with
the toroidal graphs with no $K_{3,3}$-minors. These graphs admit a unique
decomposition into planar components and have short lists of obstructions. We
provide the complete lists of four forbidden minors and eleven forbidden
subdivisions for the toroidal graphs with no $K_{3,3}$'s and prove that the
lists are sufficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0411515</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0411515</id><created>2004-11-23</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Fast Non-Parametric Bayesian Inference on Infinite Trees</title><categories>math.ST cs.LG math.PR stat.TH</categories><comments>8 twocolumn pages, 3 figures</comments><report-no>IDSIA-24-04</report-no><msc-class>62G07; 60B10; 68W99</msc-class><journal-ref>Proc. 10th International Conf. on Artificial Intelligence and
  Statistics (AISTATS-2005) 144-151</journal-ref><abstract>  Given i.i.d. data from an unknown distribution, we consider the problem of
predicting future items. An adaptive way to estimate the probability density is
to recursively subdivide the domain to an appropriate data-dependent
granularity. A Bayesian would assign a data-independent prior probability to
&quot;subdivide&quot;, which leads to a prior over infinite(ly many) trees. We derive an
exact, fast, and simple inference algorithm for such a prior, for the data
evidence, the predictive distribution, the effective model dimension, and other
quantities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0411644</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0411644</id><created>2004-11-29</created><authors><author><keyname>Shpilrain</keyname><forenames>Vladimir</forenames></author><author><keyname>Ushakov</keyname><forenames>Alexander</forenames></author></authors><title>The conjugacy search problem in public key cryptography: unnecessary and
  insufficient</title><categories>math.GR cs.CR</categories><comments>4 pages</comments><abstract>  The conjugacy search problem in a group G is the problem of recovering an x
in G from given g in G and h=x^{-1}gx. This problem is in the core of several
recently suggested public key exchange protocols, most notably the one due to
Anshel, Anshel, and Goldfeld, and the one due to Ko, Lee at al.
 In this note, we make two observations that seem to have eluded most people's
attention. The first observation is that solving the conjugacy search problem
is not necessary for an adversary to get the common secret key in the Ko-Lee
protocol. It is sufficient to solve an apparently easier problem of finding x,
y in G such that h=ygx for given g, h in G.
 Another observation is that solving the conjugacy search problem is not
sufficient for an adversary to get the common secret key in the
Anshel-Anshel-Goldfeld protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0412233</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0412233</id><created>2004-12-12</created><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author><author><keyname>Borak</keyname><forenames>E.</forenames></author></authors><title>Extended finite operator calculus as an example of algebraization of
  analysis</title><categories>math.CO cs.DM</categories><comments>25 pages</comments><msc-class>05A40, 81S99</msc-class><abstract>  A wardian calculus of sequences started almost seventy years ago constitutes
the general scheme for extensions of the classical umbral operator calculus
considered by many afterwards . At the same time this calculus is an example of
the algebraization of the analysis here restricted to the algebra of formal
series. This is a review article based on the recent first author
contributions. As the survey article it is supplemented by the short indicatory
glossaries of notation and terms used by prominent contributors to the domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0501388</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0501388</id><created>2005-01-23</created><updated>2007-09-07</updated><authors><author><keyname>Rojas</keyname><forenames>J. Maurice</forenames></author></authors><title>Efficiently Detecting Torsion Points and Subtori</title><categories>math.AG cs.CC math.NT</categories><comments>21 pages, no figures. Final version, with additional commentary and
  references. Also fixes a gap in Theorems 2 (now Theorem 1.3) regarding
  translated subtori</comments><abstract>  Suppose X is the complex zero set of a finite collection of polynomials in
Z[x_1,...,x_n]. We show that deciding whether X contains a point all of whose
coordinates are d_th roots of unity can be done within NP^NP (relative to the
sparse encoding), under a plausible assumption on primes in arithmetic
progression. In particular, our hypothesis can still hold even under certain
failures of the Generalized Riemann Hypothesis, such as the presence of
Siegel-Landau zeroes. Furthermore, we give a similar (but UNconditional)
complexity upper bound for n=1. Finally, letting T be any algebraic subgroup of
(C^*)^n we show that deciding whether X contains T is coNP-complete (relative
to an even more efficient encoding),unconditionally. We thus obtain new
non-trivial families of multivariate polynomial systems where deciding the
existence of complex roots can be done unconditionally in the polynomial
hierarchy -- a family of complexity classes lying between PSPACE and P,
intimately connected with the P=?NP Problem. We also discuss a connection to
Laurent's solution of Chabauty's Conjecture from arithmetic geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0502024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0502024</id><created>2005-02-01</created><authors><author><keyname>Martin</keyname><forenames>Keye</forenames></author></authors><title>The maximum entropy state</title><categories>math.PR cs.LO math-ph math.MP quant-ph</categories><comments>15 pages</comments><msc-class>94A17; 34A45</msc-class><abstract>  We give an algorithm for calculating the maximum entropy state as the least
fixed point of a Scott continuous mapping on the domain of classical states in
their Bayesian order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0502172</identifier>
 <datestamp>2008-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0502172</id><created>2005-02-08</created><updated>2008-01-07</updated><authors><author><keyname>Dumas</keyname><forenames>Jean-Guillaume Luc</forenames><affiliation>LJK</affiliation></author><author><keyname>Rondepierre</keyname><forenames>Aude</forenames><affiliation>MIP</affiliation></author></authors><title>An hybrid system approach to nonlinear optimal control problems</title><categories>math.OC cs.SC</categories><proxy>ccsd ccsd-00004191</proxy><msc-class>49J15</msc-class><abstract>  We consider a nonlinear ordinary differential equation and want to control
its behavior so that it reaches a target by minimizing a cost function. Our
approach is to use hybrid systems to solve this problem: the complex dynamic is
replaced by piecewise affine approximations which allow an analytical
resolution. The sequence of affine models then forms a sequence of states of a
hybrid automaton. Given a sequence of states, we introduce an hybrid
approximation of the nonlinear controllable domain and propose a new algorithm
computing a controllable, piecewise convex approximation. The same way the
nonlinear optimal control problem is replaced by an hybrid piecewise affine
one. Stating a hybrid maximum principle suitable to our hybrid model, we deduce
the global structure of the hybrid optimal control steering the system to the
target.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0502232</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0502232</id><created>2005-02-11</created><authors><author><keyname>Janson</keyname><forenames>Svante</forenames></author></authors><title>Individual displacements in hashing with coalesced chains</title><categories>math.PR cs.DS</categories><comments>17 pages</comments><report-no>U.U.D.M. 2005:4</report-no><msc-class>68P10 (Primary); 60F05, 60G35, 68W40 (Secondary)</msc-class><abstract>  We study the asymptotic distribution of the displacements in hashing with
coalesced chains, for both late-insertion and early-insertion. Asymptotic
formulas for means and variances follow. The method uses Poissonization and
some stochastic calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0502315</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0502315</id><created>2005-02-15</created><authors><author><keyname>Poland</keyname><forenames>Jan</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Strong Asymptotic Assertions for Discrete MDL in Regression and
  Classification</title><categories>math.ST cs.AI cs.IT cs.LG math.IT math.PR stat.TH</categories><comments>6 two-column pages</comments><report-no>IDSIA-02-05</report-no><journal-ref>Proc. 14th Dutch-Belgium Conf. on Machine Learning (Benelearn
  2005) 67-72</journal-ref><abstract>  We study the properties of the MDL (or maximum penalized complexity)
estimator for Regression and Classification, where the underlying model class
is countable. We show in particular a finite bound on the Hellinger losses
under the only assumption that there is a &quot;true&quot; model contained in the class.
This implies almost sure convergence of the predictive distribution to the true
one at a fast rate. It corresponds to Solomonoff's central theorem of universal
induction, however with a bound that is exponentially larger.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0502327</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0502327</id><created>2005-02-15</created><authors><author><keyname>Candes</keyname><forenames>Emmanuel</forenames></author><author><keyname>Tao</keyname><forenames>Terence</forenames></author></authors><title>Decoding by Linear Programming</title><categories>math.MG cs.CR</categories><comments>22 pages, 4 figures, submitted</comments><msc-class>94B05</msc-class><abstract>  This paper considers the classical error correcting problem which is
frequently discussed in coding theory. We wish to recover an input vector $f
\in \R^n$ from corrupted measurements $y = A f + e$. Here, $A$ is an $m$ by $n$
(coding) matrix and $e$ is an arbitrary and unknown vector of errors. Is it
possible to recover $f$ exactly from the data $y$? We prove that under suitable
conditions on the coding matrix $A$, the input $f$ is the unique solution to
the $\ell_1$-minimization problem ($\|x\|_{\ell_1} := \sum_i |x_i|$) $$ \min_{g
\in \R^n} \| y - Ag \|_{\ell_1} $$ provided that the support of the vector of
errors is not too large, $\|e\|_{\ell_0} := |\{i : e_i \neq 0\}| \le \rho \cdot
m$ for some $\rho &gt; 0$. In short, $f$ can be recovered exactly by solving a
simple convex optimization problem (which one can recast as a linear program).
In addition, numerical experiments suggest that this recovery procedure works
unreasonably well; $f$ is recovered exactly even in situations where a
significant fraction of the output is corrupted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0502354</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0502354</id><created>2005-02-16</created><updated>2005-11-07</updated><authors><author><keyname>Binder</keyname><forenames>I.</forenames></author><author><keyname>Braverman</keyname><forenames>M.</forenames></author><author><keyname>Yampolsky</keyname><forenames>M.</forenames></author></authors><title>On computational complexity of Siegel Julia sets</title><categories>math.DS cs.CC</categories><comments>Updated version, to appear in Commun. Math. Phys</comments><msc-class>37F10</msc-class><doi>10.1007/s00220-006-1546-3</doi><abstract>  It has been previously shown by two of the authors that some polynomial Julia
sets are algorithmically impossible to draw with arbitrary magnification. On
the other hand, for a large class of examples the problem of drawing a picture
has polynomial complexity. In this paper we demonstrate the existence of
computable quadratic Julia sets whose computational complexity is arbitrarily
high.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0503210</identifier>
 <datestamp>2008-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0503210</id><created>2005-03-11</created><authors><author><keyname>Krot</keyname><forenames>Ewa</forenames></author></authors><title>An Introduction to Finite Fibonomial Calculus</title><categories>math.CO cs.DM</categories><comments>16 pages</comments><msc-class>11Bxx, 11B39</msc-class><journal-ref>CEJM, 2(5) 2004, 754-766</journal-ref><abstract>  This is an indicatory presentation of main definitions and theorems of
fibonomial calculus which is a special case of psi-extented rota's finite
operator calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0503286</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0503286</id><created>2005-03-14</created><updated>2005-09-25</updated><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>Cobweb posets as noncommutative prefabs</title><categories>math.CO cs.DM</categories><comments>11 pages, 5 figures</comments><msc-class>05C20, 11C08, 17B56</msc-class><journal-ref>Adv. Stud. Contemp. Math. vol. 14 (1) 2007. pp. 37-47</journal-ref><abstract>  A class of new type graded infinite posets with minimal element are
considered. These so called cobweb posets introduced recently by the present
author provide a wide range of new noncommutative prefab combinatorial schema
with characteristic graded subposets as primes. The schema are defined here via
relaxing commutativity and associativity requirements imposed on the
composition of prefabs by the fathers of this fertile concept. The construction
and the very first basic properties of cobweb prefabs are pointed out in what
follows. An another single valued commutative amd associative composision is
also considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0503295</identifier>
 <datestamp>2008-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0503295</id><created>2005-03-15</created><authors><author><keyname>Krot</keyname><forenames>Ewa</forenames></author></authors><title>Characterization of the Fibonacci Cobweb Poset as oDAG</title><categories>math.CO cs.DM</categories><comments>5 pages, 1 figure</comments><msc-class>11Bxx, 11B39, 06Axx</msc-class><abstract>  The characterization of fibonacci cobweb poset as d.a.g. and o.d.a.g. is
given. The dim 2 poset such that its hasse diagram coincide with digraf of
fibonacci cobweb poset is constructed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0503453</identifier>
 <datestamp>2016-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0503453</id><created>2005-03-22</created><authors><author><keyname>Mateus</keyname><forenames>P.</forenames><affiliation>CLC, Dep Math, IST, Lisbon, Portugal</affiliation></author><author><keyname>Sernadas</keyname><forenames>A.</forenames><affiliation>CLC, Dep Math, IST, Lisbon, Portugal</affiliation></author></authors><title>Weakly complete axiomatization of exogenous quantum propositional logic</title><categories>math.LO cs.LO quant-ph</categories><comments>28 pages</comments><msc-class>03G12</msc-class><doi>10.1016/j.ic.2006.02.001</doi><abstract>  A weakly complete finitary axiomatization for EQPL (exogenous quantum
propositional logic) is presented. The proof is carried out using a non trivial
extension of the Fagin-Halpern-Megiddo technique together with three Henkin
style completions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0503503</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0503503</id><created>2005-03-23</created><updated>2005-05-23</updated><authors><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author><author><keyname>O'Donnell</keyname><forenames>Ryan</forenames></author><author><keyname>Oleszkiewicz</keyname><forenames>Krzysztof</forenames></author></authors><title>Noise stability of functions with low influences: invariance and
  optimality</title><categories>math.PR cs.CC math.CO</categories><abstract>  In this paper we study functions with low influences on product probability
spaces. The analysis of boolean functions with low influences has become a
central problem in discrete Fourier analysis. It is motivated by fundamental
questions arising from the construction of probabilistically checkable proofs
in theoretical computer science and from problems in the theory of social
choice in economics.
  We prove an invariance principle for multilinear polynomials with low
influences and bounded degree; it shows that under mild conditions the
distribution of such polynomials is essentially invariant for all product
spaces. Ours is one of the very few known non-linear invariance principles. It
has the advantage that its proof is simple and that the error bounds are
explicit. We also show that the assumption of bounded degree can be eliminated
if the polynomials are slightly ``smoothed''; this extension is essential for
our applications to ``noise stability''-type problems.
  In particular, as applications of the invariance principle we prove two
conjectures: the ``Majority Is Stablest'' conjecture from theoretical computer
science, which was the original motivation for this work, and the ``It Ain't
Over Till It's Over'' conjecture from social choice theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0504037</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0504037</id><created>2005-04-03</created><authors><author><keyname>Houston</keyname><forenames>Robin</forenames></author><author><keyname>Hughes</keyname><forenames>Dominic</forenames></author><author><keyname>Schalk</keyname><forenames>Andrea</forenames></author></authors><title>Modelling Linear Logic Without Units (Preliminary Results)</title><categories>math.CT cs.LO math.LO</categories><comments>23 pages</comments><abstract>  We describe a notion of categorical model for unitless fragments of
(multiplicative) linear logic. The basic definition uses promonoidal
categories, and we also give an equivalent elementary axiomatisation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0504378</identifier>
 <datestamp>2011-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0504378</id><created>2005-04-19</created><updated>2005-09-27</updated><authors><author><keyname>Roch</keyname><forenames>S.</forenames></author></authors><title>A Short Proof that Phylogenetic Tree Reconstruction by Maximum
  Likelihood is Hard</title><categories>math.PR cs.CC cs.CE math.ST q-bio.PE stat.TH</categories><comments>6 pages; Corrected typos and notational problem</comments><abstract>  Maximum likelihood is one of the most widely used techniques to infer
evolutionary histories. Although it is thought to be intractable, a proof of
its hardness has been lacking. Here, we give a short proof that computing the
maximum likelihood tree is NP-hard by exploiting a connection between
likelihood and parsimony observed by Tuffley and Steel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0504522</identifier>
 <datestamp>2008-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0504522</id><created>2005-04-25</created><updated>2006-02-17</updated><authors><author><keyname>Danielsen</keyname><forenames>Lars Eirik</forenames><affiliation>University of Bergen</affiliation></author><author><keyname>Parker</keyname><forenames>Matthew G.</forenames><affiliation>University of Bergen</affiliation></author></authors><title>On the Classification of All Self-Dual Additive Codes over GF(4) of
  Length up to 12</title><categories>math.CO cs.IT math.IT</categories><comments>18 pages, 4 figures</comments><msc-class>94B60 (Primary) 05C90 (Secondary)</msc-class><journal-ref>Journal of Combinatorial Theory, Series A 113(7), pp. 1351-1367,
  2006</journal-ref><doi>10.1016/j.jcta.2005.12.004</doi><abstract>  We consider additive codes over GF(4) that are self-dual with respect to the
Hermitian trace inner product. Such codes have a well-known interpretation as
quantum codes and correspond to isotropic systems. It has also been shown that
these codes can be represented as graphs, and that two codes are equivalent if
and only if the corresponding graphs are equivalent with respect to local
complementation and graph isomorphism. We use these facts to classify all codes
of length up to 12, where previously only all codes of length up to 9 were
known. We also classify all extremal Type II codes of length 14. Finally, we
find that the smallest Type I and Type II codes with trivial automorphism group
have length 9 and 12, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0505418</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0505418</id><created>2005-05-19</created><updated>2005-10-05</updated><authors><author><keyname>Palmgren</keyname><forenames>Erik</forenames></author></authors><title>Internalising modified realisability in constructive type theory</title><categories>math.LO cs.LO</categories><comments>7 pages</comments><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 1, Issue 2 (October 5,
  2005) lmcs:711</journal-ref><doi>10.2168/LMCS-1(2:2)2005</doi><abstract>  A modified realisability interpretation of infinitary logic is formalised and
proved sound in constructive type theory (CTT). The logic considered subsumes
first order logic. The interpretation makes it possible to extract programs
with simplified types and to incorporate and reason about them in CTT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0505487</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0505487</id><created>2005-05-23</created><authors><author><keyname>Shpilrain</keyname><forenames>Vladimir</forenames></author><author><keyname>Ushakov</keyname><forenames>Alexander</forenames></author></authors><title>Thompson's group and public key cryptography</title><categories>math.GR cs.CR</categories><comments>14 pages</comments><abstract>  Recently, several public key exchange protocols based on symbolic computation
in non-commutative (semi)groups were proposed as a more efficient alternative
to well established protocols based on numeric computation. Notably, the
protocols due to Anshel-Anshel-Goldfeld and Ko-Lee et al. exploited the
conjugacy search problem in groups, which is a ramification of the discrete
logarithm problem. However, it is a prevalent opinion now that the conjugacy
search problem alone is unlikely to provide sufficient level of security no
matter what particular group is chosen as a platform.
 In this paper we employ another problem (we call it the decomposition
problem), which is more general than the conjugacy search problem, and we
suggest to use R. Thompson's group as a platform. This group is well known in
many areas of mathematics, including algebra, geometry, and analysis. It also
has several properties that make it fit for cryptographic purposes. In
particular, we show here that the word problem in Thompson's group is solvable
in almost linear time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0505617</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0505617</id><created>2005-05-27</created><updated>2007-02-05</updated><authors><author><keyname>Binder</keyname><forenames>Ilia</forenames></author><author><keyname>Braverman</keyname><forenames>Mark</forenames></author><author><keyname>Yampolsky</keyname><forenames>Michael</forenames></author></authors><title>On computational complexity of Riemann mapping</title><categories>math.CV cs.CC</categories><msc-class>30C35</msc-class><abstract>  In this paper we consider the computational complexity of uniformizing a
domain with a given computable boundary. We give nontrivial upper and lower
bounds in two settings: when the approximation of boundary is given either as a
list of pixels, or by a Turing Machine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0506082</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0506082</id><created>2005-06-04</created><authors><author><keyname>Morikawa</keyname><forenames>Naoto</forenames></author></authors><title>Discrete differential geometry of proteins: a new method for encoding
  three-dimensional structures of proteins</title><categories>math.CO cs.DM math.MG q-bio.GN</categories><comments>10 pages, 6 figures, 3 tables. Submitted</comments><msc-class>52B99, 92D20 (primary)</msc-class><abstract>  In nature the three-dimensional structure of a protein is encoded in the
corresponding gene. In this paper we describe a new method for encoding the
three-dimensional structure of a protein into a binary sequence. The feature of
the method is the correspondence between protein-folding and ``integration''. A
protein is approximated by a folded tetrahedron sequence. And the binary code
of a protein is obtained as the ``second derivative'' of the shape of the
folded tetrahedron sequence. With this method at hand, we can extract static
structural information of a protein from its gene. And we can describe the
distribution of three-dimensional structures of proteins without any subjective
hierarchical classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0506180</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0506180</id><created>2005-06-10</created><authors><author><keyname>Grigoriev</keyname><forenames>Dimitri</forenames><affiliation>IRMAR</affiliation></author><author><keyname>Ponomarenko</keyname><forenames>Ilia</forenames></author></authors><title>Constructions in public-key cryptography over matrix groups</title><categories>math.GR cs.CR math-ph math.MP</categories><proxy>ccsd ccsd-00005317</proxy><report-no>2005-19</report-no><abstract>  The purpose of the paper is to give new key agreement protocols (a
multi-party extension of the protocol due to Anshel-Anshel-Goldfeld and a
generalization of the Diffie-Hellman protocol from abelian to solvable groups)
and a new homomorphic public-key cryptosystem. They rely on difficulty of the
conjugacy and membership problems for subgroups of a given group. To support
these and other known cryptographic schemes we present a general technique to
produce a family of instances being matrix groups (over finite commutative
rings) which play a role for these schemes similar to the groups $Z\_n^*$ in
the existing cryptographic constructions like RSA or discrete logarithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0506475</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0506475</id><created>2005-06-23</created><updated>2005-09-29</updated><authors><author><keyname>Srinivasan</keyname><forenames>Radhakrishnan</forenames></author><author><keyname>Raghunandan</keyname><forenames>H. P.</forenames></author></authors><title>Foundations of real analysis and computability theory in
  non-Aristotelian finitary logic</title><categories>math.LO cs.LO math.GM</categories><comments>An error corrected in the equation of Remark 9. Other comments of
  Version 2: 25 pages, nine references added, typos corrected. Appendix B,
  giving details of the formal systems, has been added. Substantially improved
  presentation with more details, especially in Sec. 4 on real analysis, which
  can be read more or less independently of other sections</comments><abstract>  This paper outlines new paradigms for real analysis and computability theory
in the recently proposed non-Aristotelian finitary logic (NAFL). Constructive
real analysis in NAFL (NRA) is accomplished by a translation of diagrammatic
concepts from Euclidean geometry into an extension (NPAR) of the NAFL version
of Peano Arithmetic (NPA). Such a translation is possible because NPA proves
the existence of every infinite proper class of natural numbers that is
definable in the language of NPA. Infinite sets are not permitted in NPAR and
quantification over proper classes is banned; hence Cantor's diagonal argument
cannot be legally formulated in NRA, and there is no `cardinality' for any
collection (`super-class') of real numbers. Many of the useful aspects of
classical real analysis, such as, the calculus of Newton and Leibniz, are
justifiable in NRA. But the paradoxes, such as, Zeno's paradoxes of motion and
the Banach-Tarski paradox, are resolved because NRA admits only closed
super-classes of real numbers; in particular, open/semi-open intervals of real
numbers are not permitted. The NAFL version of computability theory (NCT)
rejects Turing's argument for the undecidability of the halting problem and
permits hypercomputation. Important potential applications of NCT are in the
areas of quantum and autonomic computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0506538</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0506538</id><created>2005-06-27</created><authors><author><keyname>Micheli</keyname><forenames>Anne</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Rossin</keyname><forenames>Dominique</forenames><affiliation>LIAFA</affiliation></author></authors><title>Edit Distance between Unlabeled Ordered Trees</title><categories>math.CO cs.DM</categories><comments>Algorithmique et Combinatoire</comments><proxy>ccsd ccsd-00005569</proxy><msc-class>05C12,05C05,05A05,05A15</msc-class><abstract>  There exists a bijection between one stack sortable permutations
--permutations which avoid the pattern 231-- and planar trees. We define an
edit distance between permutations which is coherent with the standard edit
distance between trees. This one-to-one correspondence yields a polynomial
algorithm for the subpermutation problem for $(231)$ avoiding permutations.
Moreover, we obtain the generating function of the edit distance between
ordered trees and some special ones. For the general case we show that the mean
edit distance between a planar tree and all other planar trees is at least
$n/ln(n)$. Some results can be extended to labeled trees considering colored
Dyck paths or equivalently colored one stack sortable permutations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0506553</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0506553</id><created>2005-06-27</created><updated>2005-12-23</updated><authors><author><keyname>Japaridze</keyname><forenames>Giorgi</forenames></author></authors><title>Introduction to Cirquent Calculus and Abstract Resource Semantics</title><categories>math.LO cs.LO</categories><comments>To appear in Journal of Logic and Computation</comments><msc-class>03B47 (primary) 03B70, 68Q10, 68T27, 68T15 (secondary)</msc-class><journal-ref>Journal of Logic and Computation 16 (2006), pp. 489-532</journal-ref><doi>10.1093/logcom/exl005</doi><abstract>  This paper introduces a refinement of the sequent calculus approach called
cirquent calculus. While in Gentzen-style proof trees sibling (or cousin, etc.)
sequents are disjoint sequences of formulas, in cirquent calculus they are
permitted to share elements. Explicitly allowing or disallowing shared
resources and thus taking to a more subtle level the resource-awareness
intuitions underlying substructural logics, cirquent calculus offers much
greater flexibility and power than sequent calculus does. A need for
substantially new deductive tools came with the birth of computability logic
(see http://www.cis.upenn.edu/~giorgi/cl.html) - the semantically constructed
formal theory of computational resources, which has stubbornly resisted any
axiomatization attempts within the framework of traditional syntactic
approaches. Cirquent calculus breaks the ice. Removing contraction from the
full collection of its rules yields a sound and complete system for the basic
fragment CL5 of computability logic. Doing the same in sequent calculus, on the
other hand, throws out the baby with the bath water, resulting in the strictly
weaker affine logic. An implied claim of computability logic is that it is CL5
rather than affine logic that adequately materializes the resource philosophy
traditionally associated with the latter. To strengthen this claim, the paper
further introduces an abstract resource semantics and shows the soundness and
completeness of CL5 with respect to it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0507032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0507032</id><created>2005-07-02</created><authors><author><keyname>Duchamp</keyname><forenames>G&#xe9;rard Henry Edmond</forenames><affiliation>LIPN</affiliation></author><author><keyname>Luque</keyname><forenames>Jean-Gabriel</forenames><affiliation>IGM</affiliation></author><author><keyname>Deboysson-Flouret</keyname><forenames>Marianne</forenames><affiliation>LIH</affiliation></author></authors><title>Transitive Hall sets</title><categories>math.CO cs.DM</categories><proxy>ccsd ccsd-00005781</proxy><msc-class>05E99</msc-class><abstract>  We give the definition of Lazard and Hall sets in the context of transitive
factorizations of free monoids. The equivalence of the two properties is
proved. This allows to build new effective bases of free partially commutative
Lie algebras. The commutation graphs for which such sets exist are completely
characterized and we explicit, in this context, the classical PBW rewriting
process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0507041</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0507041</id><created>2005-07-04</created><updated>2007-05-17</updated><authors><author><keyname>Holland</keyname><forenames>W. Charles</forenames></author><author><keyname>Tsaban</keyname><forenames>Boaz</forenames></author></authors><title>The conjugacy problem and related problems in lattice-ordered groups</title><categories>math.GR cs.CC math.GN</categories><comments>Small updates</comments><journal-ref>International Journal of Algebra and Computation 15 (2005),
  395-404</journal-ref><doi>10.1142/S0218196705002232</doi><abstract>  We study, from a constructive computational point of view, the techniques
used to solve the conjugacy problem in the &quot;generic&quot; lattice-ordered group
Aut(R) of order automorphisms of the real line. We use these techniques in
order to show that for each choice of parameters f,g in Aut(R), the equation
xfx=g is effectively solvable in Aut(R).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0507235</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0507235</id><created>2005-07-12</created><updated>2006-04-03</updated><authors><author><keyname>Han</keyname><forenames>Guangyue</forenames></author><author><keyname>Marcus</keyname><forenames>Brian</forenames></author></authors><title>Analyticity of Entropy Rate of Hidden Markov Chains</title><categories>math.PR cs.IT math.IT</categories><comments>The title has been changed. The new main theorem now combines the old
  main theorem and the remark following the old main theorem. A new section is
  added as an introduction to complex analysis. General principle and an
  example to determine the domain of analyticity of entropy rate have been
  added. Relaxed conditions for analyticity of entropy rate and the
  corresponding examples are added. The section about binary markov chain
  corrupted by binary symmetric noise is taken out (to be part of another
  paper)</comments><abstract>  We prove that under mild positivity assumptions the entropy rate of a hidden
Markov chain varies analytically as a function of the underlying Markov chain
parameters. A general principle to determine the domain of analyticity is
stated. An example is given to estimate the radius of convergence for the
entropy rate. We then show that the positivity assumptions can be relaxed, and
examples are given for the relaxed conditions. We study a special class of
hidden Markov chains in more detail: binary hidden Markov chains with an
unambiguous symbol, and we give necessary and sufficient conditions for
analyticity of the entropy rate for this case. Finally, we show that under the
positivity assumptions the hidden Markov chain {\em itself} varies
analytically, in a strong sense, as a function of the underlying Markov chain
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0507410</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0507410</id><created>2005-07-20</created><authors><author><keyname>Fiedler</keyname><forenames>Bernd</forenames></author></authors><title>Methods for the construction of generators of algebraic curvature
  tensors</title><categories>math.CO cs.SC math.DG</categories><comments>11 pages</comments><msc-class>53B20; 15A72; 05E10; 16D60; 05-04</msc-class><abstract>  We demonstrate the use of several tools from Algebraic Combinatorics such as
Young tableaux, symmetry operators, the Littlewood-Richardson rule and discrete
Fourier transforms of symmetric groups in investigations of algebraic curvature
tensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0508171</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0508171</id><created>2005-08-09</created><updated>2006-02-04</updated><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author><author><keyname>Agaev</keyname><forenames>Rafig</forenames></author></authors><title>Matrices of Forests and the Analysis of Digraphs</title><categories>math.CO cs.CV cs.NI</categories><comments>18 pages</comments><msc-class>05C50; 05C05; 15A51</msc-class><abstract>  The matrices of spanning rooted forests are studied as a tool for analysing
the structure of digraphs and measuring their characteristics. The problems of
revealing the basis bicomponents, measuring vertex proximity, and ranking from
preference relations / sports competitions are considered. It is shown that the
vertex accessibility measure based on spanning forests has a number of
desirable properties. An interpretation for the normalized matrix of
out-forests in terms of information dissemination is given.
  Keywords: Laplacian matrix, spanning forest, matrix-forest theorem, proximity
measure, bicomponent, ranking, incomplete tournament, paired comparisons
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0508183</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0508183</id><created>2005-08-10</created><authors><author><keyname>Chebotarev</keyname><forenames>P. Yu.</forenames></author><author><keyname>Shamis</keyname><forenames>E. V.</forenames></author></authors><title>On a Duality between Metrics and $\Sigma$-Proximities</title><categories>math.MG cs.DS math.CO</categories><comments>5 pages</comments><msc-class>46F10; 54E40; 15A51</msc-class><journal-ref>Automation and Remote Control 59 (1998) 608--612</journal-ref><abstract>  : In studies of discrete structures, functions are frequently used that
express proximity, but are not metrics. We consider a class of such functions
that is characterized by a normalization condition and an inequality that plays
the same role as the triangle inequality does for metrics. We show that the
introduced functions, named $\Sigma$-proximities, are in a definite sense dual
to metrics: there exists a natural one-to-one correspondence between metrics
and $\Sigma$-proximities defined on the same finite set; in contrast to
metrics, $\Sigma$-proximities measure {\it comparative} proximity; the closer
the objects, the greater the $\Sigma$-proximity; diagonal entries of the
$\Sigma$-proximity matrix characterize the ``centrality'' of elements. The
results are extended to arbitrary infinite sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0508199</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0508199</id><created>2005-08-11</created><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author></authors><title>Extending Utility Representations of Partial Orders</title><categories>math.OC cs.DS math.FA</categories><comments>15 pages</comments><msc-class>91B16; 26B40; 51M04</msc-class><abstract>  The problem is considered as to whether a monotone function defined on a
subset P of a Euclidean space can be strictly monotonically extended to the
whole space. It is proved that this is the case if and only if the function is
{\em separably increasing}. Explicit formulas are given for a class of
extensions which involves an arbitrary bounded increasing function. Similar
results are obtained for monotone functions that represent strict partial
orders on arbitrary abstract sets X. The special case where P is a Pareto
subset is considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0508212</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0508212</id><created>2005-08-11</created><updated>2005-08-27</updated><authors><author><keyname>Kleiman</keyname><forenames>Howard</forenames></author></authors><title>The Symmetric Traveling Salesman Problem</title><categories>math.CO cs.DS</categories><comments>A new theorem has been added</comments><msc-class>05</msc-class><abstract>  Let M be an nXn symetric matrix, n, even, T, an upper bound for T_OPT, an
optimal tour, sigma_T, the smaller-valued perfect matching obtained from
alternate edges of T expressed as a product of 2-cycles. Applying the modified
Floyd-Warshall algorithm to (sigma_T)^-1M^-, we construct acceptable and
2-circuit cycles some sets of which may yield circuits that can be patched into
tours. We obtain necessary and sufficient conditions for a set, S, of cycles to
yield circuits that may be patched into a tour.Assume that the following
(Condition A)is valid: If (sigma_T)s = T*, |T*|&lt;T, then all cycles of s have
values less than |T| - |sigma_T|.Let SFWOPT),S(OPT)be the respective sets of
cycles yielding T_FWOPT, T_OPT. Given Condition(A), using F-W, we can always
obtain S(FWOPT). Using Condition A but not F-W, S_OPT is always obtainable from
a subset of the cycles obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0508319</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0508319</id><created>2005-08-17</created><authors><author><keyname>Ortner</keyname><forenames>Ronald</forenames></author></authors><title>Combinations and Mixtures of Optimal Policies in Unichain Markov
  Decision Processes are Optimal</title><categories>math.CO cs.DM cs.LG math.OC math.PR</categories><comments>9 pages</comments><msc-class>90C40</msc-class><abstract>  We show that combinations of optimal (stationary) policies in unichain Markov
decision processes are optimal. That is, let M be a unichain Markov decision
process with state space S, action space A and policies \pi_j^*: S -&gt; A (1\leq
j\leq n) with optimal average infinite horizon reward. Then any combination \pi
of these policies, where for each state i in S there is a j such that
\pi(i)=\pi_j^*(i), is optimal as well. Furthermore, we prove that any mixture
of optimal policies, where at each visit in a state i an arbitrary action
\pi_j^*(i) of an optimal policy is chosen, yields optimal average reward, too.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0508320</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0508320</id><created>2005-08-17</created><authors><author><keyname>Ortner</keyname><forenames>Ronald</forenames></author></authors><title>Embeddability of Arrangements of Pseudocircles into the Sphere</title><categories>math.CO cs.CG math.GT</categories><comments>13 pages</comments><msc-class>52C35; 52C40; 05C10</msc-class><abstract>  An arrangement of pseudocircles is a finite set of oriented closed Jordan
curves each two of which cross each other in exactly two points. To describe
the combinatorial structure of arrangements on closed orientable surfaces, in
(Linhart, Ortner 2004) so-called *intersection schemes* were introduced.
Building up on results about the latter, we first clarify the notion of
embedding of an arrangement. Once this is done it is shown how the
embeddability of an arrangement depends on the embeddability of its
subarrangements. The main result presented is that an arrangement of
pseudocircles can be embedded into the sphere if and only if all of its
subarrangements of four pseudocircles are embeddable into the sphere as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0508350</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0508350</id><created>2005-08-18</created><updated>2006-01-18</updated><authors><author><keyname>Demmel</keyname><forenames>James</forenames></author><author><keyname>Dumitriu</keyname><forenames>Ioana</forenames></author><author><keyname>Holtz</keyname><forenames>Olga</forenames></author></authors><title>Toward accurate polynomial evaluation in rounded arithmetic</title><categories>math.NA cs.CC</categories><comments>54 pages, 6 figures; refereed version; to appear in Foundations of
  Computational Mathematics: Santander 2005, Cambridge University Press, March
  2006</comments><msc-class>65Y20, 68Q05, 68Q25, 65F30, 68W40, 68W25</msc-class><journal-ref>in Foundations of Computational Mathematics: Santander 2005 (L.
  Pardo et al, eds.) Cambridge University Press, 2006, pp. 36-105</journal-ref><abstract>  Given a multivariate real (or complex) polynomial $p$ and a domain $\cal D$,
we would like to decide whether an algorithm exists to evaluate $p(x)$
accurately for all $x \in {\cal D}$ using rounded real (or complex) arithmetic.
Here ``accurately'' means with relative error less than 1, i.e., with some
correct leading digits. The answer depends on the model of rounded arithmetic:
We assume that for any arithmetic operator $op(a,b)$, for example $a+b$ or $a
\cdot b$, its computed value is $op(a,b) \cdot (1 + \delta)$, where $| \delta
|$ is bounded by some constant $\epsilon$ where $0 &lt; \epsilon \ll 1$, but
$\delta$ is otherwise arbitrary. This model is the traditional one used to
analyze the accuracy of floating point algorithms.Our ultimate goal is to
establish a decision procedure that, for any $p$ and $\cal D$, either exhibits
an accurate algorithm or proves that none exists. In contrast to the case where
numbers are stored and manipulated as finite bit strings (e.g., as floating
point numbers or rational numbers) we show that some polynomials $p$ are
impossible to evaluate accurately. The existence of an accurate algorithm will
depend not just on $p$ and $\cal D$, but on which arithmetic operators and
which constants are are available and whether branching is permitted. Toward
this goal, we present necessary conditions on $p$ for it to be accurately
evaluable on open real or complex domains ${\cal D}$. We also give sufficient
conditions, and describe progress toward a complete decision procedure. We do
present a complete decision procedure for homogeneous polynomials $p$ with
integer coefficients, ${\cal D} = \C^n$, and using only the arithmetic
operations $+$, $-$ and $\cdot$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0508533</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0508533</id><created>2005-08-26</created><authors><author><keyname>Manita</keyname><forenames>Anatoli</forenames></author><author><keyname>Simonot</keyname><forenames>Francois</forenames></author></authors><title>On the cascade rollback synchronization</title><categories>math.PR cs.DC</categories><comments>24 pages, 4 figures</comments><msc-class>60J27 (Primary); 68M14, 68M20 (Secondary)</msc-class><abstract>  We consider a cascade model of $N$ different processors performing a
distributed parallel simulation. The main goal of the study is to show that the
long-time dynamics of the system has a cluster behavior. To attack this problem
we combine two methods: stochastic comparison and Foster-Lyapunov functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0509004</identifier>
 <datestamp>2008-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0509004</id><created>2005-08-31</created><updated>2006-09-24</updated><authors><author><keyname>Gagarin</keyname><forenames>Andrei</forenames><affiliation>LaCIM, Universite du Quebec a Montreal</affiliation></author><author><keyname>Labelle</keyname><forenames>Gilbert</forenames><affiliation>LaCIM, Universite du Quebec a Montreal</affiliation></author><author><keyname>Leroux</keyname><forenames>Pierre</forenames><affiliation>LaCIM, Universite du Quebec a Montreal</affiliation></author></authors><title>Counting unlabelled toroidal graphs with no K33-subdivisions</title><categories>math.CO cs.DM</categories><comments>25 pages (some corrections), 4 figures (one figure added), 3 tables</comments><msc-class>05A15, 05C30 (Primary); 05C70, 05C75, 05C38 (Secondary)</msc-class><journal-ref>Adv. in Appl. Math. 39 (2007), no. 1, pp. 51-75</journal-ref><doi>10.1016/j.aam.2006.05.006</doi><abstract>  We provide a description of unlabelled enumeration techniques, with complete
proofs, for graphs that can be canonically obtained by substituting 2-pole
networks for the edges of core graphs. Using structure theorems for toroidal
and projective-planar graphs containing no K33-subdivisions, we apply these
techniques to obtain their unlabelled enumeration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0509248</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0509248</id><created>2005-09-12</created><authors><author><keyname>Dambreville</keyname><forenames>Frederic</forenames><affiliation>DGA/CEP/GIP/SRO</affiliation></author></authors><title>Deterministic modal Bayesian Logic: derive the Bayesian within the
  modal logic T</title><categories>math.LO cs.LO math.PR</categories><comments>The revised version of &quot;Definition of a Deterministic Bayesian
  Logic&quot;. The formalism, proofs, and models have been enhanced and simplified</comments><proxy>ccsd ccsd-00008611</proxy><abstract>  In this paper a conditional logic is defined and studied. This conditional
logic, DmBL, is constructed as close as possible to the Bayesian and is
unrestricted, that is one is able to use any operator without restriction. A
notion of logical independence is also defined within the logic itself. This
logic is shown to be non trivial and is not reduced to classical propositions.
A model is constructed for the logic. Completeness results are proved. It is
shown that any unconditioned probability can be extended to the whole logic
DmBL. The Bayesian is then recovered from the probabilistic DmBL. At last, it
is shown why DmBL is compliant with Lewis triviality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0509325</identifier>
 <datestamp>2009-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0509325</id><created>2005-09-14</created><updated>2009-10-05</updated><authors><author><keyname>Krotov</keyname><forenames>Denis</forenames><affiliation>Sobolev Institute of Mathematics, Novosibirsk, Russia</affiliation></author></authors><title>On $Z_{2^k}$-Dual Binary Codes</title><categories>math.CO cs.IT math.IT</categories><comments>English: 10pp, Russian: 14pp; V.1 title: Z_{2^k}-duality,
  Z_{2^k}-linear Hadamard codes, and co-Z_{2^k}-linear 1-perfect codes; V.2:
  revised; V.3: minor revision, references updated, Russian translation added</comments><msc-class>94B05</msc-class><journal-ref>IEEE Trans. Inf. Theory 53(4) 2007, 1532-1537</journal-ref><doi>10.1109/TIT.2007.892787</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new generalization of the Gray map is introduced. The new generalization
$\Phi: Z_{2^k}^n \to Z_{2}^{2^{k-1}n}$ is connected with the known generalized
Gray map $\phi$ in the following way: if we take two dual linear
$Z_{2^k}$-codes and construct binary codes from them using the generalizations
$\phi$ and $\Phi$ of the Gray map, then the weight enumerators of the binary
codes obtained will satisfy the MacWilliams identity. The classes of
$Z_{2^k}$-linear Hadamard codes and co-$Z_{2^k}$-linear extended 1-perfect
codes are described, where co-$Z_{2^k}$-linearity means that the code can be
obtained from a linear $Z_{2^k}$-code with the help of the new generalized Gray
map. Keywords: Gray map, Hadamard codes, MacWilliams identity, perfect codes,
$Z_{2^k}$-linearity
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0509358</identifier>
 <datestamp>2008-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0509358</id><created>2005-09-15</created><updated>2007-01-18</updated><authors><author><keyname>Krotov</keyname><forenames>Denis</forenames><affiliation>Sobolev Institute of Mathematics, Novosibirsk, Russia</affiliation></author></authors><title>On decomposability of 4-ary distance 2 MDS codes, double-codes, and
  n-quasigroups of order 4</title><categories>math.CO cs.IT math.IT</categories><comments>19 pages. V2: revised, general case q=2t is added. Submitted to
  Discr. Math</comments><msc-class>05B99; 20N15; 94B25</msc-class><journal-ref>Discrete Math. 308(15) 2008, 3322-3334</journal-ref><doi>10.1016/j.disc.2007.06.038</doi><abstract>  A subset $S$ of $\{0,1,...,2t-1\}^n$ is called a $t$-fold MDS code if every
line in each of $n$ base directions contains exactly $t$ elements of $S$. The
adjacency graph of a $t$-fold MDS code is not connected if and only if the
characteristic function of the code is the repetition-free sum of the
characteristic functions of $t$-fold MDS codes of smaller lengths.
  In the case $t=2$, the theory has the following application. The union of two
disjoint $(n,4^{n-1},2)$ MDS codes in $\{0,1,2,3\}^n$ is a double-MDS-code. If
the adjacency graph of the double-MDS-code is not connected, then the
double-code can be decomposed into double-MDS-codes of smaller lengths. If the
graph has more than two connected components, then the MDS codes are also
decomposable. The result has an interpretation as a test for reducibility of
$n$-quasigroups of order 4. Keywords: MDS codes, n-quasigroups,
decomposability, reducibility, frequency hypercubes, latin hypercubes
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0509478</identifier>
 <datestamp>2008-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0509478</id><created>2005-09-21</created><updated>2006-04-26</updated><authors><author><keyname>Bose</keyname><forenames>Prosenjit</forenames></author><author><keyname>Czyzowicz</keyname><forenames>Jurek</forenames></author><author><keyname>Gao</keyname><forenames>Zhicheng</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author><author><keyname>Wood</keyname><forenames>David R.</forenames></author></authors><title>Simultaneous Diagonal Flips in Plane Triangulations</title><categories>math.CO cs.CG</categories><comments>A short version of this paper will be presented at SODA 2006</comments><msc-class>05C10</msc-class><journal-ref>J. Graph Theory 54(4):307-330, 2007</journal-ref><doi>10.1002/jgt.20214</doi><abstract>  Simultaneous diagonal flips in plane triangulations are investigated. It is
proved that every $n$-vertex triangulation with at least six vertices has a
simultaneous flip into a 4-connected triangulation, and that it can be computed
in O(n) time. It follows that every triangulation has a simultaneous flip into
a Hamiltonian triangulation. This result is used to prove that for any two
$n$-vertex triangulations, there exists a sequence of $O(\log n)$ simultaneous
flips to transform one into the other. The total number of edges flipped in
this sequence is O(n). The maximum size of a simultaneous flip is then studied.
It is proved that every triangulation has a simultaneous flip of at least
${1/3}(n-2)$ edges. On the other hand, every simultaneous flip has at most
$n-2$ edges, and there exist triangulations with a maximum simultaneous flip of
${6/7}(n-2)$ edges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0509523</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0509523</id><created>2005-09-22</created><updated>2005-12-01</updated><authors><author><keyname>Li</keyname><forenames>Shujun</forenames></author></authors><title>Permutation Polynomials modulo m</title><categories>math.NT cs.CR</categories><comments>21 pages, with 2 open problems</comments><abstract>  This paper mainly studies problems about so called &quot;permutation polynomials
modulo $m$&quot;, polynomials with integer coefficients that can induce bijections
over Z_m={0,...,m-1}. The necessary and sufficient conditions of permutation
polynomials are given, and the number of all permutation polynomials of given
degree and the number induced bijections are estimated. A method is proposed to
determine all equivalent polynomials from the induced polynomial function,
which can be used to determine all equivalent polynomials that induce a given
bijection. A few problems have not been solved yet in this paper and left for
open study.
  Note: After finishing the first draft, we noticed that some results obtained
in this paper can be proved in other ways (see Remark 2). In this case, this
work gives different and independent proofs of related results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0509575</identifier>
 <datestamp>2011-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0509575</id><created>2005-09-23</created><updated>2009-07-27</updated><authors><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author><author><keyname>Roch</keyname><forenames>Sebastien</forenames></author></authors><title>Evolutionary Trees and the Ising Model on the Bethe Lattice: a Proof of
  Steel's Conjecture</title><categories>math.PR cs.CE cs.DS math.CA math.CO math.ST q-bio.PE stat.TH</categories><comments>Second major revision. Updated proofs and statements</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A major task of evolutionary biology is the reconstruction of phylogenetic
trees from molecular data. The evolutionary model is given by a Markov chain on
a tree. Given samples from the leaves of the Markov chain, the goal is to
reconstruct the leaf-labelled tree.
  It is well known that in order to reconstruct a tree on $n$ leaves, sample
sequences of length $\Omega(\log n)$ are needed. It was conjectured by M. Steel
that for the CFN/Ising evolutionary model, if the mutation probability on all
edges of the tree is less than $p^{\ast} = (\sqrt{2}-1)/2^{3/2}$, then the tree
can be recovered from sequences of length $O(\log n)$. The value $p^{\ast}$ is
given by the transition point for the extremality of the free Gibbs measure for
the Ising model on the binary tree. Steel's conjecture was proven by the second
author in the special case where the tree is &quot;balanced.&quot; The second author also
proved that if all edges have mutation probability larger than $p^{\ast}$ then
the length needed is $n^{\Omega(1)}$. Here we show that Steel's conjecture
holds true for general trees by giving a reconstruction algorithm that recovers
the tree from $O(\log n)$-length sequences when the mutation probabilities are
discretized and less than $p^\ast$. Our proof and results demonstrate that
extremality of the free Gibbs measure on the infinite binary tree, which has
been studied before in probability, statistical physics and computer science,
determines how distinguishable are Gibbs measures on finite binary trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0509620</identifier>
 <datestamp>2009-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0509620</id><created>2005-09-27</created><updated>2009-08-03</updated><authors><author><keyname>Krotov</keyname><forenames>Denis</forenames><affiliation>Sobolev Institute of Mathematics, Novosibirsk, Russia</affiliation></author></authors><title>On diameter perfect constant-weight ternary codes</title><categories>math.CO cs.IT math.IT</categories><comments>15 pages, 2 figures; presented at 2004 Com2MaC Conference on
  Association Schemes, Codes and Designs; submitted to Discrete Mathematics</comments><msc-class>94B25; 05C70</msc-class><journal-ref>Discrete Math. 308(14) 2008, 3104-3114</journal-ref><doi>10.1016/j.disc.2007.08.037</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  From cosets of binary Hamming codes we construct diameter perfect
constant-weight ternary codes with weight $n-1$ (where $n$ is the code length)
and distances 3 and 5. The class of distance 5 codes has parameters unknown
before. Keywords: constant-weight codes, ternary codes, perfect codes, diameter
perfect codes, perfect matchings, Preparata codes
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0510013</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0510013</id><created>2005-10-01</created><updated>2005-10-03</updated><authors><author><keyname>Chua</keyname><forenames>David B.</forenames></author><author><keyname>Kolaczyk</keyname><forenames>Eric D.</forenames></author><author><keyname>Crovella</keyname><forenames>Mark</forenames></author></authors><title>Network Kriging</title><categories>math.ST cs.NI stat.TH</categories><comments>16 pages, 9 figures, single-spaced</comments><abstract>  Network service providers and customers are often concerned with aggregate
performance measures that span multiple network paths. Unfortunately, forming
such network-wide measures can be difficult, due to the issues of scale
involved. In particular, the number of paths grows too rapidly with the number
of endpoints to make exhaustive measurement practical. As a result, it is of
interest to explore the feasibility of methods that dramatically reduce the
number of paths measured in such situations while maintaining acceptable
accuracy.
  We cast the problem as one of statistical prediction--in the spirit of the
so-called `kriging' problem in spatial statistics--and show that end-to-end
network properties may be accurately predicted in many cases using a
surprisingly small set of carefully chosen paths. More precisely, we formulate
a general framework for the prediction problem, propose a class of linear
predictors for standard quantities of interest (e.g., averages, totals,
differences) and show that linear algebraic methods of subset selection may be
used to effectively choose which paths to measure. We characterize the
performance of the resulting methods, both analytically and numerically. The
success of our methods derives from the low effective rank of routing matrices
as encountered in practice, which appears to be a new observation in its own
right with potentially broad implications on network measurement generally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0510027</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0510027</id><created>2005-10-03</created><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>Prefab posets` Whitney numbers</title><categories>math.CO cs.DM</categories><comments>8 pages, 5 figures</comments><msc-class>05C20, 11C08, 17B56</msc-class><journal-ref>Bull. Soc. Sci. Lett. Lodz, vol 60, (2005). 25-33</journal-ref><abstract>  We introduce a natural partial order in structurally natural finite subsets
the cobweb prefabs sets recently constructed by the present author. Whitney
numbers of the second kind of the corresponding subposet which constitute
Stirling-like numbers` triangular array are then calculated and the explicit
formula for them is provided. Next - in the second construction - we endow the
set sums of prefabiants with such an another partial order that their their
bell like numbers include fibonacci triad sequences introduced recently by the
present author in order to extend famous relation between binomial newton
coefficients and fibonacci numbers onto the infinity of their relatives among
which there are also the fibonacci triad sequences and binomial-like
coefficients (incidence coefficients included).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0510263</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0510263</id><created>2005-10-12</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Cubic Partial Cubes from Simplicial Arrangements</title><categories>math.CO cs.CG math.MG</categories><comments>11 pages, 10 figures</comments><msc-class>05C12 (Primary) 05C78, 52C30 (Secondary)</msc-class><journal-ref>Electronic J. Combinatorics 13(1, R79):1\^a?&quot;14, Sep 2006</journal-ref><abstract>  We show how to construct a cubic partial cube from any simplicial arrangement
of lines or pseudolines in the projective plane. As a consequence, we find nine
new infinite families of cubic partial cubes as well as many sporadic examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0510264</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0510264</id><created>2005-10-12</created><authors><author><keyname>Samorodnitsky</keyname><forenames>Alex</forenames></author><author><keyname>Trevisan</keyname><forenames>Luca</forenames></author></authors><title>Gowers Uniformity, Influence of Variables, and PCPs</title><categories>math.CO cs.CC</categories><abstract>  Gowers introduced, for d\geq 1, the notion of dimension-d uniformity U^d(f)
of a function f: G -&gt; \C, where G is a finite abelian group and \C are the
complex numbers. Roughly speaking, if U^d(f) is small, then f has certain
&quot;pseudorandomness&quot; properties.
  We prove the following property of functions with large U^d(f). Write G=G_1 x
&gt;... x G_n as a product of groups. If a bounded balanced function f:G_1 x ... x
G_n -&gt; \C is such that U^{d} (f) &gt; epsilon, then one of the coordinates of f
has influence at least epsilon/2^{O(d)}.
  The Gowers inner product of a collection of functions is a related notion of
pseudorandomness. We prove that if a collection of bounded functions has large
Gowers inner product, and at least one function in the collection is balanced,
then there is a variable that has high influence for at least four of the
functions in the collection.
  Finally, we relate the acceptance probability of the &quot;hypergraph long-code
test&quot; proposed by Samorodnitsky and Trevisan to the Gowers inner product of the
functions being tested and we deduce applications to the construction of
Probabilistically Checkable Proofs and to hardness of approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0510276</identifier>
 <datestamp>2008-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0510276</id><created>2005-10-13</created><updated>2007-09-13</updated><authors><author><keyname>Gill</keyname><forenames>Richard D.</forenames><affiliation>Leiden University</affiliation></author><author><keyname>Grunwald</keyname><forenames>Peter D.</forenames><affiliation>CWI Amsterdam</affiliation></author></authors><title>An algorithmic and a geometric characterization of Coarsening At Random</title><categories>math.ST cs.AI stat.ME stat.TH</categories><comments>16 pages; accepted in this form for publication by Annals of
  Statistics</comments><msc-class>62A01 (Primary); 62N01,60A99,68T37 (Secondary)</msc-class><abstract>  We show that the class of conditional distributions satisfying the coarsening
at Random (CAR) property for discrete data has a simple and robust algorithmic
description based on randomized uniform multicovers: combinatorial objects
generalizing the notion of partition of a set. However, the complexity of a
given CAR mechanism can be large: the maximal &quot;height&quot; of the needed
multicovers can be exponential in the number of points in the sample space. The
results stem from a geometric interpretation of the set of CAR distributions as
a convex polytope and a characterization of its extreme points. The hierarchy
of CAR models defined in this way could be useful in parsimonious statistical
modelling of CAR mechanisms, though the results also raise doubts in applied
work as to the meaningfulness of the CAR assumption in its full generality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0510304</identifier>
 <datestamp>2014-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0510304</id><created>2005-10-14</created><authors><author><keyname>Fiedler</keyname><forenames>Bernd</forenames></author></authors><title>Stationary or static space-times and Young tableaux</title><categories>math.DG cs.SC gr-qc math.CO</categories><comments>11 pages</comments><msc-class>53B20; 83C20; 05E10; 16D60; 05-04</msc-class><journal-ref>J.Phys.Conf.Ser.30:152-162,2006</journal-ref><doi>10.1088/1742-6596/30/1/018</doi><abstract>  Algebraic curvature tensors possess generators which can be formed from
symmetric or alternating tensors S, A or tensors \theta with an irreducible
(2,1)-symmetry. In differential geometry examples of curvature formulas are
known which contain generators on the basis of S or A realized by
differentiable tensor fields in a natural way. We show that certain curvature
formulas for stationary or static space-times contain such differentiable
realizations of generators based on \theta. The tensor \theta is connected with
the timelike Killing vector field of the space-time. \theta lies in a special
symmetry class from the infinite family of irreducible (2,1)-symmetry classes.
We determine characteristics of this class. In particular, this class allows a
maximal reduction of the length of the curvature formulas. We use a projection
formalism by Vladimirov, Young symmetrizers and Littlewood-Richardson products.
Computer calculations were carried out by means of the packages Ricci and
PERMS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0510520</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0510520</id><created>2005-10-24</created><updated>2006-04-26</updated><authors><author><keyname>Cattani</keyname><forenames>Eduardo</forenames></author><author><keyname>Dickenstein</keyname><forenames>Alicia</forenames></author></authors><title>Counting Solutions to Binomial Complete Intersections</title><categories>math.AC cs.CC math.CO</categories><comments>Several minor improvements. Final version to appear in the J. of
  Complexity</comments><abstract>  We study the problem of counting the total number of affine solutions of a
system of n binomials in n variables over an algebraically closed field of
characteristic zero. We show that we may decide in polynomial time if that
number is finite. We give a combinatorial formula for computing the total
number of affine solutions (with or without multiplicity) from which we deduce
that this counting problem is #P-complete. We discuss special cases in which
this formula may be computed in polynomial time; in particular, this is true
for generic exponent vectors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0510521</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0510521</id><created>2005-10-24</created><updated>2009-04-01</updated><authors><author><keyname>Nguyen</keyname><forenames>XuanLong</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author><author><keyname>Jordan</keyname><forenames>Michael I.</forenames></author></authors><title>On surrogate loss functions and $f$-divergences</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>Published in at http://dx.doi.org/10.1214/08-AOS595 the Annals of
  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</comments><report-no>IMS-AOS-AOS595</report-no><msc-class>62G10, 68Q32, 62K05 (Primary)</msc-class><journal-ref>Annals of Statistics 2009, Vol. 37, No. 2, 876-904</journal-ref><doi>10.1214/08-AOS595</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of binary classification is to estimate a discriminant function
$\gamma$ from observations of covariate vectors and corresponding binary
labels. We consider an elaboration of this problem in which the covariates are
not available directly but are transformed by a dimensionality-reducing
quantizer $Q$. We present conditions on loss functions such that empirical risk
minimization yields Bayes consistency when both the discriminant function and
the quantizer are estimated. These conditions are stated in terms of a general
correspondence between loss functions and a class of functionals known as
Ali-Silvey or $f$-divergence functionals. Whereas this correspondence was
established by Blackwell [Proc. 2nd Berkeley Symp. Probab. Statist. 1 (1951)
93--102. Univ. California Press, Berkeley] for the 0--1 loss, we extend the
correspondence to the broader class of surrogate loss functions that play a key
role in the general theory of Bayes consistency for binary classification. Our
result makes it possible to pick out the (strict) subset of surrogate loss
functions that yield Bayes consistency for joint estimation of the discriminant
function and the quantizer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0510573</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0510573</id><created>2005-10-26</created><authors><author><keyname>Friedland</keyname><forenames>Shmuel</forenames></author><author><keyname>Kaveh</keyname><forenames>Mostafa</forenames></author><author><keyname>Niknejad</keyname><forenames>Amir</forenames></author><author><keyname>Zare</keyname><forenames>Hossein</forenames></author></authors><title>Fast Monte-Carlo Low Rank Approximations for Matrices</title><categories>math.NA cs.DS</categories><abstract>  In many applications, it is of interest to approximate data, given by mxn
matrix A, by a matrix B of at most rank k, which is much smaller than m and n.
The best approximation is given by singular value decomposition, which is too
time consuming for very large m and n. We present here a Monte Carlo algorithm
for iteratively computing a k-rank approximation to the data consisting of mxn
matrix A. Each iteration involves the reading of O(k) of columns or rows of A.
The complexity of our algorithm is O(kmn). Our algorithm, distinguished from
other known algorithms, guarantees that each iteration is a better k-rank
approximation than the previous iteration. We believe that this algorithm will
have many applications in data mining, data storage and data analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0511343</identifier>
 <datestamp>2009-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0511343</id><created>2005-11-14</created><updated>2008-12-17</updated><authors><author><keyname>Ben-Shimon</keyname><forenames>Sonny</forenames></author><author><keyname>Krivelevich</keyname><forenames>Michael</forenames></author></authors><title>Random regular graphs of non-constant degree: Concentration of the
  chromatic number</title><categories>math.CO cs.DM math.PR</categories><comments>18 pages</comments><msc-class>68R05; 05C80</msc-class><journal-ref>Discrete Mathematics, 309(12):4149--4161, 2009</journal-ref><doi>10.1016/j.disc.2008.12.014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we show that with high probability the chromatic number of a
graph sampled from the random regular graph model $\Gnd$ for $d=o(n^{1/5})$ is
concentrated in two consecutive values, thus extending a previous result of
Achlioptas and Moore. This concentration phenomena is very similar to that of
the binomial random graph model $\Gnp$ with $p=\frac{d}{n}$. Our proof is
largely based on ideas of Alon and Krivelevich who proved this two-point
concentration result for $\Gnp$ for $p=n^{-\delta}$ where $\delta&gt;1/2$. The
main tool used to derive such a result is a careful analysis of the
distribution of edges in $\Gnd$, relying both on the switching technique and on
bounding the probability of exponentially small events in the configuration
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0512110</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0512110</id><created>2005-12-05</created><updated>2006-03-07</updated><authors><author><keyname>Taylor</keyname><forenames>Paul</forenames></author></authors><title>Computably Based Locally Compact Spaces</title><categories>math.GN cs.LO math.CT</categories><comments>70pp, LaTeX2e, uses diagrams.sty; Accepted for &quot;Logical Methods in
  Computer Science&quot; LMCS-2004-19; see http://www.cs.man.ac.uk/~pt/ASD for
  related papers. ACM-class: F.4.1</comments><msc-class>54D45, 03D45 (Primary), 06B35, 54D30, 68N18 (Secondary)</msc-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 1 (March 7,
  2006) lmcs:1182</journal-ref><doi>10.2168/LMCS-1(4:1)2006</doi><abstract>  ASD (Abstract Stone Duality) is a re-axiomatisation of general topology in
which the topology on a space is treated, not as an infinitary lattice, but as
an exponential object of the same category as the original space, with an
associated lambda-calculus. In this paper, this is shown to be equivalent to a
notion of computable basis for locally compact sober spaces or locales,
involving a family of open subspaces and accompanying family of compact ones.
This generalises Smyth's effectively given domains and Jung's strong proximity
lattices. Part of the data for a basis is the inclusion relation of compact
subspaces within open ones, which is formulated in locale theory as the
way-below relation on a continuous lattice. The finitary properties of this
relation are characterised here, including the Wilker condition for the cover
of a compact space by two open ones. The real line is used as a running
example, being closely related to Scott's domain of intervals. ASD does not use
the category of sets, but the full subcategory of overt discrete objects plays
this role; it is an arithmetic universe (pretopos with lists). In particular,
we use this subcategory to translate computable bases for classical spaces into
objects in the ASD calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0512140</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0512140</id><created>2005-12-06</created><authors><author><keyname>Shpilrain</keyname><forenames>Vladimir</forenames></author><author><keyname>Ushakov</keyname><forenames>Alexander</forenames></author></authors><title>A new key exchange protocol based on the decomposition problem</title><categories>math.GR cs.CR</categories><comments>7 pages</comments><abstract>  In this paper we present a new key establishment protocol based on the
decomposition problem in non-commutative groups which is: given two elements
$w, w_1$ of the platform group $G$ and two subgroups $A, B \subseteq G$ (not
necessarily distinct), find elements $a \in A, b \in B$ such that $w_1 = a w
b$. Here we introduce two new ideas that improve the security of key
establishment protocols based on the decomposition problem. In particular, we
conceal (i.e., do not publish explicitly) one of the subgroups $A, B$, thus
introducing an additional computationally hard problem for the adversary,
namely, finding the centralizer of a given finitely generated subgroup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0512263</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0512263</id><created>2005-12-13</created><authors><author><keyname>De Micheli</keyname><forenames>Enrico</forenames></author><author><keyname>Viano</keyname><forenames>Giovanni Alberto</forenames></author></authors><title>Metric and probabilistic information associated with Fredholm integral
  equations of the first kind</title><categories>math.CA cs.IT math.IT</categories><comments>19 pages</comments><msc-class>45B05; 45Q05; 94A15; 94A17</msc-class><journal-ref>J. Integral Equations Appl. 14 (2002), 283-310</journal-ref><abstract>  The problem of evaluating the information associated with Fredholm integral
equations of the first kind, when the integral operator is self-adjoint and
compact, is considered here. The data function is assumed to be perturbed
gently by an additive noise so that it still belongs to the range of the
operator. First we estimate upper and lower bounds for the epsilon-capacity
(and then for the metric information), and explicit computations in some
specific cases are given; then the problem is reformulated from a probabilistic
viewpoint and use is made of the probabilistic information theory. The results
obtained by these two approaches are then compared.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0512578</identifier>
 <datestamp>2009-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0512578</id><created>2005-12-26</created><updated>2009-01-19</updated><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>On cobweb posets and their combinatorially admissible sequences</title><categories>math.CO cs.DM</categories><comments>16 pages, 9 figures, affiliated to The Internet Gian Carlo Rota
  Polish Seminar: 16 pages, 9 figures, affiliated to The Internet Gian Carlo
  Rota Polish Seminar http://ii.uwb.edu.pl/akk/sem/sem_rota.htm</comments><msc-class>05C20, 11C08, 17B56</msc-class><journal-ref>Adv. Studies Contemp. Math. Vol. 18 No 1, 2009 17-32</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main purpose of this article is to pose three problems which are easy to
be formulated in an elementary way. These problems which are specifically
important also for the new class of partially ordered sets seem to be not yet
solved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0601487</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0601487</id><created>2006-01-20</created><authors><author><keyname>Freeman</keyname><forenames>David</forenames></author></authors><title>Constructing pairing-friendly elliptic curves with embedding degree 10</title><categories>math.NT cs.CR</categories><msc-class>14H52; 11G20; 94A60</msc-class><abstract>  We present a general framework for constructing families of elliptic curves
of prime order with prescribed embedding degree. We demonstrate this method by
constructing curves with embedding degree k = 10, which solves an open problem
posed by Boneh, Lynn, and Shacham. We show that our framework incorporates
existing constructions for k = 3, 4, 6, and 12, and we give evidence that the
method is unlikely to produce infinite families of curves with embedding degree
k &gt; 12.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0601624</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0601624</id><created>2006-01-25</created><authors><author><keyname>Labarbe</keyname><forenames>Jean-Maxime</forenames><affiliation>LM-Versailles</affiliation></author><author><keyname>Marckert</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>LaBRI</affiliation></author></authors><title>Asymptotics of Bernoulli random walks, bridges, excursions and meanders
  with a given number of peaks</title><categories>math.PR cs.DM</categories><proxy>ccsd ccsd-00017872</proxy><abstract>  A Bernoulli random walk is a random trajectory starting from 0 and having
i.i.d. increments, each of them being $+1$ or -1, equally likely. The other
families cited in the title are Bernoulli random walks under various
conditionings. A peak in a trajectory is a local maximum. In this paper, we
condition the families of trajectories to have a given number of peaks. We show
that, asymptotically, the main effect of setting the number of peaks is to
change the order of magnitude of the trajectories. The counting process of the
peaks, that encodes the repartition of the peaks in the trajectories, is also
studied. It is shown that suitably normalized, it converges to a Brownian
bridge which is independent of the limiting trajectory. Applications in terms
of plane trees and parallelogram polyominoes are also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0601755</identifier>
 <datestamp>2008-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0601755</id><created>2006-01-31</created><authors><author><keyname>Bajguz</keyname><forenames>Wieslaw</forenames></author></authors><title>Graph and Union of Graphs Compositions</title><categories>math.CO cs.DM</categories><comments>5 pages</comments><msc-class>05A18, 05C05, 05C30, 11B37</msc-class><abstract>  Knopfmacher et all [1] was introduced the graph compositions` notion. In this
note we add to these a new construction of tree-like graphs where nodes are
graphs themselves. The first examples of these tree-like compositions, a
corresponding theorem and resulting conclusions are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0602053</identifier>
 <datestamp>2010-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0602053</id><created>2006-02-02</created><updated>2010-06-10</updated><authors><author><keyname>Yanofsky</keyname><forenames>Noson S.</forenames></author></authors><title>Towards a Definition of an Algorithm</title><categories>math.LO cs.LO math.CT</categories><comments>38 pages. Fixed typos. Added Refs</comments><msc-class>68W01, 03D20</msc-class><journal-ref>Journal of Logic and Computation 2010;</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define an algorithm to be the set of programs that implement or express
that algorithm. The set of all programs is partitioned into equivalence
classes. Two programs are equivalent if they are essentially the same program.
The set of equivalence classes forms the category of algorithms. Although the
set of programs does not even form a category, the set of algorithms form a
category with extra structure. The conditions we give that describe when two
programs are essentially the same turn out to be coherence relations that
enrich the category of algorithms with extra structure. Universal properties of
the category of algorithms are proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0602059</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0602059</id><created>2006-02-03</created><updated>2006-02-04</updated><authors><author><keyname>Agaev</keyname><forenames>Rafig</forenames></author><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author></authors><title>The Matrix of Maximum Out Forests of a Digraph and Its Applications</title><categories>math.CO cs.DS math.AG</categories><comments>27 pages, 3 figures</comments><msc-class>05C50; 05C05; 15A51</msc-class><journal-ref>Automation and Remote Control 61 (2000) 1424--1450</journal-ref><abstract>  We study the maximum out forests of a (weighted) digraph and the matrix of
maximum out forests. A maximum out forest of a digraph G is a spanning subgraph
of G that consists of disjoint diverging trees and has the maximum possible
number of arcs. If a digraph contains any out arborescences, then maximum out
forests coincide with them. We provide a new proof to the Markov chain tree
theorem saying that the matrix of Ces`aro limiting probabilities of an
arbitrary stationary finite Markov chain coincides with the normalized matrix
of maximum out forests of the weighted digraph that corresponds to the Markov
chain. We discuss the applications of the matrix of maximum out forests and its
transposition, the matrix of limiting accessibilities of a digraph, to the
problems of preference aggregation, measuring the vertex proximity, and
uncovering the structure of a digraph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0602061</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0602061</id><created>2006-02-03</created><authors><author><keyname>Agaev</keyname><forenames>Rafig</forenames></author><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author></authors><title>Spanning Forests of a Digraph and Their Applications</title><categories>math.CO cs.DM math.RA</categories><comments>24 pages</comments><msc-class>05C50; 05C05; 15A51</msc-class><journal-ref>Automation and Remote Control 62 (2001) No.3 443-466</journal-ref><doi>10.1023/A:1002862312617</doi><abstract>  We study spanning diverging forests of a digraph and related matrices. It is
shown that the normalized matrix of out forests of a digraph coincides with the
transition matrix in a specific observation model for Markov chains related to
the digraph. Expression are given for the Moore-Penrose generalized inverse and
the group inverse of the Kirchhoff (Laplacian) matrix. These expressions
involve the matrix of maximum out forest of the digraph. Every matrix of out
forests with a fixed number of arcs and the normalized matrix of out forests
are represented as polynomials in the Kirchhoff matrix; with the help of these
identities new proofs are given for the matrix-forest theorem and some other
statements. A connection is specified between the forest dimension of a digraph
and the degree of an annihilating polynomial for the Kirchhoff (Laplacian)
matrix. Some accessibility measures for digraph vertices are considered. These
are based on the enumeration of spanning forests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0602070</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0602070</id><created>2006-02-04</created><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author><author><keyname>Shamis</keyname><forenames>Elena</forenames></author></authors><title>The Matrix-Forest Theorem and Measuring Relations in Small Social Groups</title><categories>math.CO cs.IR math.AG</categories><comments>10 pages</comments><msc-class>05C50; 05C05; 15A51</msc-class><journal-ref>Automation and Remote Control 58 (1997) No. 9 1505-1514</journal-ref><abstract>  We propose a family of graph structural indices related to the Matrix-forest
theorem. The properties of the basic index that expresses the mutual
connectivity of two vertices are studied in detail. The derivative indices that
measure &quot;dissociation,&quot; &quot;solitariness,&quot; and &quot;provinciality&quot; of vertices are
also considered. A nonstandard metric on the set of vertices is introduced,
which is determined by their connectivity. The application of these indices in
sociometry is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0602073</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0602073</id><created>2006-02-05</created><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author><author><keyname>Shamis</keyname><forenames>Elena</forenames></author></authors><title>On Proximity Measures for Graph Vertices</title><categories>math.CO cs.DS cs.NI math.MG</categories><comments>17 pages, 3 figures</comments><msc-class>05C50; 05C05; 15A09; 15A51</msc-class><journal-ref>Automation and Remote Control 59 (1998), No. 10, Part 2 1443-1459.
  Erratum: 60 (1999), No. 2, Part 2 297</journal-ref><abstract>  We study the properties of several proximity measures for the vertices of
weighted multigraphs and multidigraphs. Unlike the classical distance for the
vertices of connected graphs, these proximity measures are applicable to
weighted structures and take into account not only the shortest, but also all
other connections, which is desirable in many applications. To apply these
proximity measures to unweighted structures, every edge should be assigned the
same weight which determines the proportion of taking account of two routes,
from which one is one edge longer than the other. Among the proximity measures
we consider path accessibility, route accessibility, relative forest
accessibility along with its components, accessibility via dense forests, and
connection reliability. A number of characteristic conditions is introduced and
employed to characterize the proximity measures. A topological interpretation
is obtained for the Moore-Penrose generalized inverse of the Laplacian matrix
of a weighted multigraph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0602154</identifier>
 <datestamp>2009-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0602154</id><created>2006-02-08</created><updated>2007-03-13</updated><authors><author><keyname>Gadiyar</keyname><forenames>H. Gopalkrishna</forenames></author><author><keyname>Maini</keyname><forenames>K M Sangeeta</forenames></author><author><keyname>Padma</keyname><forenames>R.</forenames></author><author><keyname>Romsy</keyname><forenames>Mario</forenames></author></authors><title>What is the Inverse of Repeated Square and Multiply Algorithm?</title><categories>math.NT cs.CR</categories><comments>15 pages</comments><msc-class>11Y16</msc-class><journal-ref>Colloq. Math. 116 (2009) 1-14</journal-ref><abstract>  It is well known that the repeated square and multiply algorithm is an
efficient way of modular exponentiation. The obvious question to ask is if this
algorithm has an inverse which would calculate the discrete logarithm
efficiently. The technical hitch is in fixing the right sign of the square root
and this is the heart of the discrete logarithm problem over finite fields of
characteristic not equal to 2. In this paper a couple of probabilistic
algorithms to compute the discrete logarithm over finite fields are given by
bypassing this difficulty. One of the algorithms was inspired by the famous
3x+1 problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0602171</identifier>
 <datestamp>2011-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0602171</id><created>2006-02-08</created><updated>2006-04-20</updated><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author><author><keyname>Shamis</keyname><forenames>Elena</forenames></author></authors><title>Preference fusion when the number of alternatives exceeds two: indirect
  scoring procedures</title><categories>math.OC cs.MA math.CO</categories><comments>26 pages, 5 figures One typo fixed</comments><msc-class>91B08, 91B10, 91B12, 62J15</msc-class><journal-ref>Journal of the Franklin Institute, 336 (1999), No.2, 205-226.
  Erratum: 336 (1999) No.4, 747-748
  (http://dx.doi.org/10.1016/S0016-0032(99)00004-6)</journal-ref><doi>10.1016/S0016-0032(98)00017-9</doi><abstract>  We consider the problem of aggregation of incomplete preferences represented
by arbitrary binary relations or incomplete paired comparison matrices. For a
number of indirect scoring procedures we examine whether or not they satisfy
the axiom of self-consistent monotonicity. The class of {\em win-loss combining
scoring procedures} is introduced which contains a majority of known scoring
procedures. Two main results are established. According to the first one, every
win-loss combining scoring procedure breaks self-consistent monotonicity. The
second result provides a sufficient condition of satisfying self-consistent
monotonicity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0602282</identifier>
 <datestamp>2007-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0602282</id><created>2006-02-13</created><updated>2007-10-18</updated><authors><author><keyname>Mahalanobis</keyname><forenames>Ayan</forenames></author></authors><title>The Diffie-Hellman Key Exchange Protocol and non-abelian nilpotent
  groups</title><categories>math.GR cs.CR</categories><comments>Finally got accepted. The final version. To appear, Israel Journal of
  Mathematics</comments><msc-class>94a62, 20d15</msc-class><abstract>  In this paper we study a key exchange protocol similar to Diffie-Hellman key
exchange protocol using abelian subgroups of the automorphism group of a
non-abelian nilpotent group. We also generalize group no.92 of Hall-Senior
table \cite{halltable}, for arbitrary prime $p$ and show that for those groups,
the group of central automorphisms commute. We use these for the key exchange
we are studying.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0602493</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0602493</id><created>2006-02-22</created><updated>2006-05-27</updated><authors><author><keyname>Graczy&#x144;ska</keyname><forenames>Ewa</forenames></author><author><keyname>Schweigert</keyname><forenames>Dietmar</forenames></author></authors><title>The dimension of a variety</title><categories>math.LO cs.LO math.GM</categories><comments>The results of the paper were presented at the workshop AAA71 and
  CYA21 at B\c{e}dlewo, Poland on February 11, 2006. the paper is submitted to
  Discussiones Mathematicae Algebra and Stochastc Methods, special issue</comments><msc-class>08B99, 08A40</msc-class><journal-ref>published in Discussiones Mathematicae, General Algebra and
  Applications, 27, 2007, pp. 35--47</journal-ref><abstract>  We invent the notion of a {\it dimension of a variety} $V$ as the cardinality
of all its proper {\it derived} subvarieties (of the same type). The dimensions
of varieties of lattices, varieties of regular bands and other general
algebraic structures are determined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0602505</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0602505</id><created>2006-02-22</created><authors><author><keyname>Poland</keyname><forenames>Jan</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>MDL Convergence Speed for Bernoulli Sequences</title><categories>math.ST cs.IT cs.LG math.IT math.PR stat.TH</categories><comments>28 pages</comments><report-no>IDSIA-04-06</report-no><journal-ref>Statistics and Computing, 16 (2006) pages 161-175</journal-ref><doi>10.1007/s11222-006-6746-3</doi><abstract>  The Minimum Description Length principle for online sequence
estimation/prediction in a proper learning setup is studied. If the underlying
model class is discrete, then the total expected square loss is a particularly
interesting performance measure: (a) this quantity is finitely bounded,
implying convergence with probability one, and (b) it additionally specifies
the convergence speed. For MDL, in general one can only have loss bounds which
are finite but exponentially larger than those for Bayes mixtures. We show that
this is even the case if the model class contains only Bernoulli distributions.
We derive a new upper bound on the prediction error for countable Bernoulli
classes. This implies a small bound (comparable to the one for Bayes mixtures)
for certain important model classes. We discuss the application to Machine
Learning tasks such as classification and hypothesis testing, and
generalization to countable classes of i.i.d. models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0602522</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0602522</id><created>2006-02-23</created><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author><author><keyname>Shamis</keyname><forenames>Elena</forenames></author></authors><title>Characterizations of scoring methods for preference aggregation</title><categories>math.OC cs.MA math.FA</categories><comments>33 pages; with tables and figures</comments><msc-class>91B08; 91B10; 91B12; 91B16</msc-class><journal-ref>Annals of Operations Research, 1998. V. 80. P.299-332</journal-ref><abstract>  The paper surveys more than forty characterizations of scoring methods for
preference aggregation and contains one new result. A general scoring operator
is {\it self-consistent} if alternative $i$ is assigned a greater score than
$j$ whenever $i$ gets no worse (better) results of comparisons and its
`opponents' are assigned respectively greater (no smaller) scores than those of
$j$. We prove that self-consistency is satisfied if and only if the application
of a scoring operator reduces to the solution of a homogeneous system of
algebraic equations with a monotone function on the left-hand side.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0602552</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0602552</id><created>2006-02-24</created><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author><author><keyname>Shamis</keyname><forenames>Elena</forenames></author></authors><title>From Incomplete Preferences to Ranking via Optimization</title><categories>math.OC cs.MA math.CO</categories><comments>25 pages, 6 figures</comments><msc-class>91B10; 90C35; 90C27; 91B08; 90B80</msc-class><journal-ref>A version of this paper was published as: P.Yu.Chebotarev,
  E.V.Shamis. Constructing an objective function for aggregating incomplete
  preferences, In: A.Tangian and J.Gruber, eds. Econometric Decision Models:
  Constructing Scalar-Valued Objective Functions. Lecture Notes in Economics
  and Mathematical Systems, Springer-Verlag, 1997, P.100-124</journal-ref><abstract>  We consider methods for aggregating preferences that are based on the
resolution of discrete optimization problems. The preferences are represented
by arbitrary binary relations (possibly weighted) or incomplete paired
comparison matrices. This incomplete case remains practically unexplored so
far. We examine the properties of several known methods and propose one new
method. In particular, we test whether these methods obey a new axiom referred
to as {\it Self-Consistent Monotonicity}. Some results are established that
characterize solutions of the related optimization problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0602573</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0602573</id><created>2006-02-25</created><updated>2011-04-28</updated><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author><author><keyname>Shamis</keyname><forenames>Elena</forenames></author></authors><title>The Forest Metrics for Graph Vertices</title><categories>math.CO cs.NI math.MG</categories><comments>14 pages, 19 ref</comments><msc-class>05C50, 05C05, 05C12, 15A51</msc-class><journal-ref>Electronic Notes in Discrete Mathematics 11 (July 2002) 98-107</journal-ref><doi>10.1016/S1571-0653(04)00058-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new graph metric and study its properties. In contrast to the
standard distance in connected graphs, it takes into account all paths between
vertices. Formally, it is defined as d(i,j)=q_{ii}+q_{jj}-q_{ij}-q_{ji}, where
q_{ij} is the (i,j)-entry of the {\em relative forest accessibility matrix}
Q(\epsilon)=(I+\epsilon L)^{-1}, L is the Laplacian matrix of the (weighted)
(multi)graph, and \epsilon is a positive parameter. By the matrix-forest
theorem, the (i,j)-entry of the relative forest accessibility matrix of a graph
provides the specific number of spanning rooted forests such that i and j
belong to the same tree rooted at i. Extremely simple formulas express the
modification of the proposed distance under the basic graph transformations. We
give a topological interpretation of d(i,j) in terms of the probability of
unsuccessful linking i and j in a model of random links. The properties of this
metric are compared with those of some other graph metrics. An application of
this metric is related to clustering procedures such as &quot;centered partition.&quot;
In another procedure, the relative forest accessibility and the corresponding
distance serve to choose the centers of the clusters and to assign a cluster to
each non-central vertex. The notion of cumulative weight of connections between
two vertices is proposed. The reasoning involves a reciprocity principle for
weighted multigraphs. Connections between the resistance distance and the
forest distance are established.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0602575</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0602575</id><created>2006-02-25</created><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author><author><keyname>Shamis</keyname><forenames>Elena</forenames></author></authors><title>Matrix-Forest Theorems</title><categories>math.CO cs.DM math.RA</categories><comments>Unpublished manuscript (1995); 10 pages</comments><msc-class>05C50; 05C05; 15A51</msc-class><abstract>  The Laplacian matrix of a graph G is L(G)=D(G)-A(G), where A(G) is the
adjacency matrix and D(G) is the diagonal matrix of vertex degrees. According
to the Matrix-Tree Theorem, the number of spanning trees in G is equal to any
cofactor of an entry of L(G). A rooted forest is a union of disjoint rooted
trees. We consider the matrix W(G)=I+L(G) and prove that the (i,j)-cofactor of
W(G) is equal to the number of spanning rooted forests of G, in which the
vertices i and j belong to the same tree rooted at i. The determinant of W(G)
equals the total number of spanning rooted forests, therefore the (i,j)-entry
of the matrix W^{-1}(G) can be considered as a measure of relative
''forest-accessibility'' of the vertex i from j (or j from i). These results
follow from somewhat more general theorems we prove, which concern weighted
multigraphs. The analogous theorems for (multi)digraphs are established. These
results provide a graph-theoretic interpretation for the adjugate to the
Laplacian characteristic matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0603024</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0603024</id><created>2006-03-01</created><updated>2006-05-18</updated><authors><author><keyname>Podlubny</keyname><forenames>Igor</forenames></author><author><keyname>Kassayova</keyname><forenames>Katarina</forenames></author></authors><title>Towards a better list of citation superstars: compiling a
  multidisciplinary list of highly cited researchers</title><categories>math.ST cs.GL physics.soc-ph stat.TH</categories><comments>15 pages, 4 tables</comments><msc-class>00A99</msc-class><journal-ref>Research Evaluation, vol. 15, no. 3, December 2006, pp. 154-162</journal-ref><abstract>  A new approach to producing multidisciplinary lists of highly cited
researchers is described and used for compiling a multidisciplinary list of
highly cited researchers. This approach is essentially related to the recently
discovered law of the constant ratios (Podlubny, 2004) and gives a
better-balanced representation of different scientific fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0603155</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0603155</id><created>2006-03-07</created><updated>2007-12-21</updated><authors><author><keyname>Fliess</keyname><forenames>Michel</forenames><affiliation>INRIA Futurs, LIX</affiliation></author><author><keyname>Join</keyname><forenames>C&#xe9;dric</forenames><affiliation>INRIA Futurs, CRAN</affiliation></author><author><keyname>Mboup</keyname><forenames>Mamadou</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Sira-Ramirez</keyname><forenames>Hebertt</forenames></author></authors><title>Vers une commande multivariable sans mod\`ele</title><categories>math.OC cs.CE cs.RO physics.class-ph</categories><proxy>ccsd inria-00001139</proxy><journal-ref>Dans Conf\'erence internationale francophone d'automatique (CIFA
  2006) (2006)</journal-ref><abstract>  A control strategy without any precise mathematical model is derived for
linear or nonlinear systems which are assumed to be finite-dimensional. Two
convincing numerical simulations are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0603207</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0603207</id><created>2006-03-08</created><updated>2006-12-07</updated><authors><author><keyname>Demmel</keyname><forenames>James</forenames></author><author><keyname>Dumitriu</keyname><forenames>Ioana</forenames></author><author><keyname>Holtz</keyname><forenames>Olga</forenames></author><author><keyname>Kleinberg</keyname><forenames>Robert</forenames></author></authors><title>Fast matrix multiplication is stable</title><categories>math.NA cs.CC cs.DS math.GR</categories><comments>19 pages; final version, expanded and updated to reflect referees'
  remarks; to appear in Numerische Mathematik</comments><msc-class>65Y20, 65F30, 65G50, 68Q17, 68W40, 20C05, 20K01, 16S34, 43A30, 65T50</msc-class><journal-ref>Numer. Math. 106 (2007), no. 2, 199-224</journal-ref><doi>10.1007/s00211-007-0061-6</doi><abstract>  We perform forward error analysis for a large class of recursive matrix
multiplication algorithms in the spirit of [D. Bini and G. Lotti, Stability of
fast algorithms for matrix multiplication, Numer. Math. 36 (1980), 63--72]. As
a consequence of our analysis, we show that the exponent of matrix
multiplication (the optimal running time) can be achieved by numerically stable
algorithms. We also show that new group-theoretic algorithms proposed in [H.
Cohn, and C. Umans, A group-theoretic approach to fast matrix multiplication,
FOCS 2003, 438--449] and [H. Cohn, R. Kleinberg, B. Szegedy and C. Umans,
Group-theoretic algorithms for matrix multiplication, FOCS 2005, 379--388] are
all included in the class of algorithms to which our analysis applies, and are
therefore numerically stable. We perform detailed error analysis for three
specific fast group-theoretic algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0603248</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0603248</id><created>2006-03-10</created><authors><author><keyname>Basu</keyname><forenames>Saugata</forenames></author><author><keyname>Pollack</keyname><forenames>Richard</forenames></author><author><keyname>Roy</keyname><forenames>Marie-Francoise</forenames></author></authors><title>Computing the First Betti Numberand Describing the Connected Components
  of Semi-algebraic Sets</title><categories>math.AG cs.SC math.AT</categories><msc-class>14P10 ; 14P25</msc-class><abstract>  In this paper we describe a singly exponential algorithm for computing the
first Betti number of a given semi-algebraic set. Singly exponential algorithms
for computing the zero-th Betti number, and the Euler-Poincar\'e
characteristic, were known before. No singly exponential algorithm was known
for computing any of the individual Betti numbers other than the zero-th one.
We also give algorithms for obtaining semi-algebraic descriptions of the
semi-algebraically connected components of any given real algebraic or
semi-algebraic set in single-exponential time improving on previous results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0603256</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0603256</id><created>2006-03-10</created><updated>2009-07-14</updated><authors><author><keyname>Basu</keyname><forenames>Saugata</forenames></author><author><keyname>Pollack</keyname><forenames>Richard</forenames></author><author><keyname>Roy</keyname><forenames>Marie-Francoise</forenames></author></authors><title>An asymptotically tight bound on the number of semi-algebraically
  connected components of realizable sign conditions</title><categories>math.CO cs.CG math.AG</categories><comments>19 pages. Bibliography has been updated and a few more references
  have been added. This is the final version of this paper which will appear in
  Combinatorica</comments><msc-class>14P10; 14P25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove an asymptotically tight bound (asymptotic with respect to the number
of polynomials for fixed degrees and number of variables) on the number of
semi-algebraically connected components of the realizations of all realizable
sign conditions of a family of real polynomials. More precisely, we prove that
the number of semi-algebraically connected components of the realizations of
all realizable sign conditions of a family of $s$ polynomials in
$\R[X_1,...,X_k]$ whose degrees are at most $d$ is bounded by \[
\frac{(2d)^k}{k!}s^k + O(s^{k-1}). \] This improves the best upper bound known
previously which was \[ {1/2}\frac{(8d)^k}{k!}s^k + O(s^{k-1}). \] The new
bound matches asymptotically the lower bound obtained for families of
polynomials each of which is a product of generic polynomials of degree one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0603262</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0603262</id><created>2006-03-10</created><updated>2007-02-22</updated><authors><author><keyname>Basu</keyname><forenames>Saugata</forenames></author></authors><title>Computing the Top Betti Numbers of Semi-algebraic Sets Defined by
  Quadratic Inequalities in Polynomial Time</title><categories>math.AG cs.CC math.LO</categories><comments>Some more details added in Sections 6 and 7</comments><doi>10.1007/s10208-005-0208-8</doi><abstract>  For any $\ell &gt; 0$, we present an algorithm which takes as input a
semi-algebraic set, $S$, defined by $P_1 \leq 0,...,P_s \leq 0$, where each
$P_i \in \R[X_1,...,X_k]$ has degree $\leq 2,$ and computes the top $\ell$
Betti numbers of $S$, $b_{k-1}(S), ..., b_{k-\ell}(S),$ in polynomial time. The
complexity of the algorithm, stated more precisely, is $ \sum_{i=0}^{\ell+2} {s
\choose i} k^{2^{O(\min(\ell,s))}}. $ For fixed $\ell$, the complexity of the
algorithm can be expressed as $s^{\ell+2} k^{2^{O(\ell)}},$ which is polynomial
in the input parameters $s$ and $k$. To our knowledge this is the first
polynomial time algorithm for computing non-trivial topological invariants of
semi-algebraic sets in $\R^k$ defined by polynomial inequalities, where the
number of inequalities is not fixed and the polynomials are allowed to have
degree greater than one. For fixed $s$, we obtain by letting $\ell = k$, an
algorithm for computing all the Betti numbers of $S$ whose complexity is
$k^{2^{O(s)}}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0603263</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0603263</id><created>2006-03-10</created><authors><author><keyname>Basu</keyname><forenames>Saugata</forenames></author></authors><title>Computing the First Few Betti Numbers of Semi-algebraic Sets in Single
  Exponential Time</title><categories>math.AG cs.SC</categories><msc-class>14P10 ; 14P25</msc-class><abstract>  In this paper we describe an algorithm that takes as input a description of a
semi-algebraic set $S \subset \R^k$, defined by a Boolean formula with atoms of
the form $P &gt; 0, P &lt; 0, P=0$ for $P \in {\mathcal P} \subset \R[X_1,...,X_k],$
and outputs the first $\ell+1$ Betti numbers of $S$, $b_0(S),...,b_\ell(S).$
The complexity of the algorithm is $(sd)^{k^{O(\ell)}},$ where where $s =
#({\mathcal P})$ and $d = \max_{P\in {\mathcal P}}{\rm deg}(P),$ which is
singly exponential in $k$ for $\ell$ any fixed constant. Previously, singly
exponential time algorithms were known only for computing the Euler-Poincar\'e
characteristic, the zero-th and the first Betti numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0603606</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0603606</id><created>2006-03-26</created><authors><author><keyname>Denisenko</keyname><forenames>P. N.</forenames></author></authors><title>Lanczos $\tau$-method optimal algorithm in APS for approximating the
  mathematical functions</title><categories>math.NA cs.MS math.CA</categories><comments>10 pages. Based on a talk given at the Workshop on Symbolic
  Calculations and Exact Methods in Mathematical Physics, Kiev, June 20-26,
  2005</comments><proxy>sigma</proxy><abstract>  A new procedure is constructed by means of APS in APLAN language. The
procedure solves the initial-value problem for linear differential equations of
order $k$ with polynomial coefficients and regular singularity in the
initialization point in the interval $[a, b]$ and computes the algebraic
polynomial $y_n$ of given order $n$. A new algorithm of Lanczos $\tau$-method
is built for this procedure, the solution existence $y_n$ of the initial-value
problem proved on this algorithm and also is proved the optimality by precision
of order $k$ derivative of the initial-value problem solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0603727</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0603727</id><created>2006-03-31</created><updated>2006-04-21</updated><authors><author><keyname>Miller</keyname><forenames>Stephen D.</forenames></author><author><keyname>Venkatesan</keyname><forenames>Ramarathnam</forenames></author></authors><title>Spectral Analysis of Pollard Rho Collisions</title><categories>math.NT cs.CR cs.DM math.CO</categories><comments>To appear in Proceedings of ANTS VII</comments><abstract>  We show that the classical Pollard rho algorithm for discrete logarithms
produces a collision in expected time O(sqrt(n)(log n)^3). This is the first
nontrivial rigorous estimate for the collision probability for the unaltered
Pollard rho graph, and is close to the conjectured optimal bound of O(sqrt(n)).
The result is derived by showing that the mixing time for the random walk on
this graph is O((log n)^3); without the squaring step in the Pollard rho
algorithm, the mixing time would be exponential in log n. The technique
involves a spectral analysis of directed graphs, which captures the effect of
the squaring step.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0604226</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0604226</id><created>2006-04-10</created><authors><author><keyname>Yeh</keyname><forenames>Hong-Gwa</forenames></author></authors><title>A Dynamic View of Circular Colorings</title><categories>math.CO cs.DC cs.DM</categories><comments>23 pages</comments><msc-class>05C15 (Primary) 68R05, 90B35, 68M14, 68M20(Secondary)</msc-class><abstract>  The main contributions of this paper are three-fold. First, we use a dynamic
approach based on Reiter's pioneering work on Karp-Miller computation graphs to
give a new and short proof of Mohar's Minty-type Theorem. Second, we bridge
circular colorings and discrete event dynamic systems to show that the Barbosa
and Gafni's results on circular chromatic number can be generalized to
edge-weighted symmetric directed graphs. Third, we use the above-mentioned
dynamic view of circular colorings to construct new improved lower bounds on
the circular chromatic number of a graph. We show as an example that the
circular chromatic number of the line graph of the Petersen graph can be
determined very easily by using these bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0604233</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0604233</id><created>2006-04-11</created><authors><author><keyname>Rigollet</keyname><forenames>Philippe</forenames><affiliation>PMA</affiliation></author></authors><title>Generalization error bounds in semi-supervised classification under the
  cluster assumption</title><categories>math.ST cs.LG stat.TH</categories><proxy>ccsd ccsd-00022528</proxy><abstract>  We consider semi-supervised classification when part of the available data is
unlabeled. These unlabeled data can be useful for the classification problem
when we make an assumption relating the behavior of the regression function to
that of the marginal distribution. Seeger (2000) proposed the well-known
&quot;cluster assumption&quot; as a reasonable one. We propose a mathematical formulation
of this assumption and a method based on density level sets estimation that
takes advantage of it to achieve fast rates of convergence both in the number
of unlabeled examples and the number of labeled examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0604331</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0604331</id><created>2006-04-14</created><authors><author><keyname>Akhavi</keyname><forenames>Ali</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Marckert</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Rouault</keyname><forenames>Alain</forenames><affiliation>LM-Versailles</affiliation></author></authors><title>On the reduction of a random basis</title><categories>math.PR cs.DS</categories><proxy>ccsd ccsd-00022848</proxy><abstract>  For $g &lt; n$, let $b\_1,...,b\_{n-g}$ be $n - g$ independent vectors in
$\mathbb{R}^n$ with a common distribution invariant by rotation. Considering
these vectors as a basis for the Euclidean lattice they generate, the aim of
this paper is to provide asymptotic results when $n\to +\infty$ concerning the
property that such a random basis is reduced in the sense of {\sc Lenstra,
Lenstra &amp; Lov\'asz}. The proof passes by the study of the process
$(r\_{g+1}^{(n)},r\_{g+2}^{(n)},...,r\_{n-1}^{(n)})$ where $r\_j^{(n)}$ is the
ratio of lengths of two consecutive vectors $b^*\_{n-j+1}$ and $b^*\_{n-j}$
built from $(b\_1,...,b\_{n-g})$ by the Gram--Schmidt orthogonalization
procedure, which we believe to be interesting in its own. We show that, as
$n\to+\infty$, the process $(r\_j^{(n)}-1)\_j$ tends in distribution in some
sense to an explicit process $({\mathcal R}\_j -1)\_j$; some properties of this
latter are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0604366</identifier>
 <datestamp>2011-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0604366</id><created>2006-04-17</created><authors><author><keyname>Borgs</keyname><forenames>Christian</forenames></author><author><keyname>Chayes</keyname><forenames>Jennifer</forenames></author><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author><author><keyname>Roch</keyname><forenames>Sebastien</forenames></author></authors><title>The Kesten-Stigum Reconstruction Bound Is Tight for Roughly Symmetric
  Binary Channels</title><categories>math.PR cs.CC q-bio.PE</categories><abstract>  We establish the exact threshold for the reconstruction problem for a binary
asymmetric channel on the b-ary tree, provided that the asymmetry is
sufficiently small. This is the first exact reconstruction threshold obtained
in roughly a decade. We discuss the implications of our result for Glauber
dynamics, phylogenetic reconstruction, and so-called ``replica symmetry
breaking'' in spin glasses and random satisfiability problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0604367</identifier>
 <datestamp>2011-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0604367</id><created>2006-04-17</created><updated>2009-07-27</updated><authors><author><keyname>Bhamidi</keyname><forenames>Shankar</forenames></author><author><keyname>Rajagopal</keyname><forenames>Ram</forenames></author><author><keyname>Roch</keyname><forenames>Sebastien</forenames></author></authors><title>Network Delay Inference from Additive Metrics</title><categories>math.PR cs.DS cs.NI math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate the use of computational phylogenetic techniques to solve a
central problem in inferential network monitoring. More precisely, we design a
novel algorithm for multicast-based delay inference, i.e. the problem of
reconstructing the topology and delay characteristics of a network from
end-to-end delay measurements on network paths. Our inference algorithm is
based on additive metric techniques widely used in phylogenetics. It runs in
polynomial time and requires a sample of size only $\poly(\log n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0604371</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0604371</id><created>2006-04-17</created><authors><author><keyname>Braverman</keyname><forenames>Mark</forenames></author><author><keyname>Yampolsky</keyname><forenames>Michael</forenames></author></authors><title>Constructing Non-Computable Julia Sets</title><categories>math.DS cs.CC</categories><msc-class>37F50</msc-class><abstract>  We completely characterize the conformal radii of Siegel disks in the family
$$P_\theta(z)=e^{2\pi i\theta}z+z^2,$$ corresponding to {\bf computable}
parameters $\theta$. As a consequence, we constructively produce quadratic
polynomials with {\bf non-computable} Julia sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0604584</identifier>
 <datestamp>2011-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0604584</id><created>2006-04-27</created><authors><author><keyname>Burton</keyname><forenames>Benjamin A.</forenames></author></authors><title>Enumeration of non-orientable 3-manifolds using face pairing graphs and
  union-find</title><categories>math.GT cs.CG math.CO</categories><comments>37 pages, 34 figures</comments><msc-class>57N10, 68W05 (Primary) 57M04, 57M15 (Secondary)</msc-class><journal-ref>Discrete and Computational Geometry 38 (2007), no. 3, 527-571</journal-ref><doi>10.1007/s00454-007-1307-x</doi><abstract>  Drawing together techniques from combinatorics and computer science, we
improve the census algorithm for enumerating closed minimal P^2-irreducible
3-manifold triangulations. In particular, new constraints are proven for face
pairing graphs, and pruning techniques are improved using a modification of the
union-find algorithm. Using these results we catalogue all 136 closed
non-orientable P^2-irreducible 3-manifolds that can be formed from at most ten
tetrahedra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0604611</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0604611</id><created>2006-04-27</created><updated>2006-05-10</updated><authors><author><keyname>Gagen</keyname><forenames>Michael J.</forenames></author><author><keyname>Nemoto</keyname><forenames>Kae</forenames></author></authors><title>Variational optimization of probability measure spaces resolves the
  chain store paradox</title><categories>math.OC cond-mat.stat-mech cs.GT</categories><comments>11 pages, 5 figures. Replaced for minor notational correction</comments><msc-class>49J52; 49K27; 91A20</msc-class><abstract>  In game theory, players have continuous expected payoff functions and can use
fixed point theorems to locate equilibria. This optimization method requires
that players adopt a particular type of probability measure space. Here, we
introduce alternate probability measure spaces altering the dimensionality,
continuity, and differentiability properties of what are now the game's
expected payoff functionals. Optimizing such functionals requires generalized
variational and functional optimization methods to locate novel equilibria.
These variational methods can reconcile game theoretic prediction and observed
human behaviours, as we illustrate by resolving the chain store paradox. Our
generalized optimization analysis has significant implications for economics,
artificial intelligence, complex system theory, neurobiology, and biological
evolution and development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0605232</identifier>
 <datestamp>2008-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0605232</id><created>2006-05-09</created><updated>2008-05-02</updated><authors><author><keyname>Rodier</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>IML</affiliation></author></authors><title>Borne sur le degr\'e des polyn\^omes presque parfaitement
  non-lin\'eaires</title><categories>math.AG cs.CR</categories><comments>19 pages</comments><proxy>ccsd ccsd-00067968</proxy><msc-class>94A60, 11T71, 14G50,</msc-class><abstract>  The vectorial Boolean functions are employed in cryptography to build block
coding algorithms. An important criterion on these functions is their
resistance to the differential cryptanalysis. Nyberg defined the notion of
almost perfect non-linearity (APN) to study resistance to the differential
attacks. Up to now, the study of functions APN was especially devoted to power
functions. Recently, Budaghyan and al. showed that certain quadratic
polynomials were APN. Here, we will give a criterion so that a function is not
almost perfectly non-linear. H. Janwa showed, by using Weil's bound, that
certain cyclic codes could not correct two errors. A. Canteaut showed by using
the same method that the functions powers were not APN for a too large value of
the exponent. We use Lang and Weil's bound and a result of P. Deligne on the
Weil's conjectures (or more exactly improvements given by Ghorpade and Lachaud)
about surfaces on finite fields to generalize this result to all the
polynomials. We show therefore that a polynomial cannot be APN if its degree is
too large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0605242</identifier>
 <datestamp>2008-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0605242</id><created>2006-05-09</created><authors><author><keyname>De Loera</keyname><forenames>Jes&#xfa;s A.</forenames></author><author><keyname>Hemmecke</keyname><forenames>Raymond</forenames></author><author><keyname>Onn</keyname><forenames>Shmuel</forenames></author><author><keyname>Weismantel</keyname><forenames>Robert</forenames></author></authors><title>N-Fold Integer Programming</title><categories>math.OC cs.CC cs.DM math.CO</categories><msc-class>05A; 15A; 51M; 52A; 52B; 52C; 68Q; 68R; 68U; 90B; 90C</msc-class><journal-ref>Discrete Optimization, 5:231--241, 2008</journal-ref><abstract>  In this article we study a broad class of integer programming problems in
variable dimension. We show that these so-termed {\em n-fold integer
programming problems} are polynomial time solvable. Our proof involves two
heavy ingredients discovered recently: the equivalence of linear optimization
and so-called directed augmentation, and the stabilization of certain Graver
bases.
  We discuss several applications of our algorithm to multiway transportation
problems and to packing problems. One important consequence of our results is a
polynomial time algorithm for the $d$-dimensional integer transportation
problem for long multiway tables. Another interesting application is a new
algorithm for the classical cutting stock problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0605334</identifier>
 <datestamp>2008-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0605334</id><created>2006-05-12</created><authors><author><keyname>Gerdt</keyname><forenames>Vladimir P.</forenames></author><author><keyname>Blinkov</keyname><forenames>Yuri A.</forenames></author><author><keyname>Mozzhilkin</keyname><forenames>Vladimir V.</forenames></author></authors><title>Gr\&quot;obner Bases and Generation of Difference Schemes for Partial
  Differential Equations</title><categories>math.RA cs.NA cs.SC math.NA</categories><comments>Published in SIGMA (Symmetry, Integrability and Geometry: Methods and
  Applications) at http://www.emis.de/journals/SIGMA/</comments><proxy>sigma</proxy><journal-ref>SIGMA 2 (2006), 051, 26 pages</journal-ref><doi>10.3842/SIGMA.2006.051</doi><abstract>  In this paper we present an algorithmic approach to the generation of fully
conservative difference schemes for linear partial differential equations. The
approach is based on enlargement of the equations in their integral
conservation law form by extra integral relations between unknown functions and
their derivatives, and on discretization of the obtained system. The structure
of the discrete system depends on numerical approximation methods for the
integrals occurring in the enlarged system. As a result of the discretization,
a system of linear polynomial difference equations is derived for the unknown
functions and their partial derivatives. A difference scheme is constructed by
elimination of all the partial derivatives. The elimination can be achieved by
selecting a proper elimination ranking and by computing a Gr\&quot;obner basis of
the linear difference ideal generated by the polynomials in the discrete
system. For these purposes we use the difference form of Janet-like Gr\&quot;obner
bases and their implementation in Maple. As illustration of the described
methods and algorithms, we construct a number of difference schemes for Burgers
and Falkowich-Karman equations and discuss their numerical properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0605472</identifier>
 <datestamp>2015-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0605472</id><created>2006-05-17</created><updated>2009-07-11</updated><authors><author><keyname>Pouyanne</keyname><forenames>Nicolas</forenames><affiliation>LM-Versailles</affiliation></author></authors><title>An algebraic approach to Polya processes</title><categories>math.CO cs.DM cs.DS math.PR</categories><proxy>ccsd ccsd-00004597</proxy><msc-class>05D40; 60F15; 60F25; 60J05</msc-class><journal-ref>Annales de l'IHP - Probabilit\'es et Statistiques (2008) Vol. 44,
  No. 2, 293-323</journal-ref><doi>10.1214/07-AIHP130</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  P\'olya processes are natural generalization of P\'olya-Eggenberger urn
models. This article presents a new approach of their asymptotic behaviour {\it
via} moments, based on the spectral decomposition of a suitable finite
difference operator on polynomial functions. Especially, it provides new
results for {\it large} processes (a P\'olya process is called {\it small} when
1 is simple eigenvalue of its replacement matrix and when any other eigenvalue
has a real part $\leq 1/2$; otherwise, it is called large).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0605498</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0605498</id><created>2006-05-18</created><authors><author><keyname>Dambreville</keyname><forenames>Frederic</forenames><affiliation>DGA/CTA/DT/GIP</affiliation></author></authors><title>Cross-Entropic Learning of a Machine for the Decision in a Partially
  Observable Universe</title><categories>math.OC cs.AI cs.LG cs.NE cs.RO math.ST stat.TH</categories><comments>Submitted to EJOR</comments><proxy>ccsd ccsd-00069493</proxy><abstract>  Revision of the paper previously entitled &quot;Learning a Machine for the
Decision in a Partially Observable Markov Universe&quot; In this paper, we are
interested in optimal decisions in a partially observable universe. Our
approach is to directly approximate an optimal strategic tree depending on the
observation. This approximation is made by means of a parameterized
probabilistic law. A particular family of hidden Markov models, with input
\emph{and} output, is considered as a model of policy. A method for optimizing
the parameters of these HMMs is proposed and applied. This optimization is
based on the cross-entropic principle for rare events simulation developed by
Rubinstein.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0605610</identifier>
 <datestamp>2008-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0605610</id><created>2006-05-23</created><authors><author><keyname>Berstein</keyname><forenames>Yael</forenames></author><author><keyname>Onn</keyname><forenames>Shmuel</forenames></author></authors><title>Nonlinear Bipartite Matching</title><categories>math.OC cs.CC cs.DM math.CO</categories><msc-class>05A; 15A; 51M; 52A; 52B; 52C; 68Q; 68R; 68U; 90B; 90C</msc-class><journal-ref>Discrete Optimization, 5:53--65, 2008</journal-ref><abstract>  We study the problem of optimizing nonlinear objective functions over
bipartite matchings. While the problem is generally intractable, we provide
several efficient algorithms for it, including a deterministic algorithm for
maximizing convex objectives, approximative algorithms for norm minimization
and maximization, and a randomized algorithm for optimizing arbitrary
objectives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0605740</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0605740</id><created>2006-05-30</created><authors><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author></authors><title>Sharp thresholds for high-dimensional and noisy recovery of sparsity</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>Appeared as Technical Report 708, Department of Statistics, UC
  Berkeley</comments><abstract>  The problem of consistently estimating the sparsity pattern of a vector
$\betastar \in \real^\mdim$ based on observations contaminated by noise arises
in various contexts, including subset selection in regression, structure
estimation in graphical models, sparse approximation, and signal denoising. We
analyze the behavior of $\ell_1$-constrained quadratic programming (QP), also
referred to as the Lasso, for recovering the sparsity pattern. Our main result
is to establish a sharp relation between the problem dimension $\mdim$, the
number $\spindex$ of non-zero elements in $\betastar$, and the number of
observations $\numobs$ that are required for reliable recovery. For a broad
class of Gaussian ensembles satisfying mutual incoherence conditions, we
establish existence and compute explicit values of thresholds $\ThreshLow$ and
$\ThreshUp$ with the following properties: for any $\epsilon &gt; 0$, if $\numobs
&gt; 2 (\ThreshUp + \epsilon) \log (\mdim - \spindex) + \spindex + 1$, then the
Lasso succeeds in recovering the sparsity pattern with probability converging
to one for large problems, whereas for $\numobs &lt; 2 (\ThreshLow - \epsilon)
\log (\mdim - \spindex) + \spindex + 1$, then the probability of successful
recovery converges to zero. For the special case of the uniform Gaussian
ensemble, we show that $\ThreshLow = \ThreshUp = 1$, so that the threshold is
sharp and exactly determined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0606022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0606022</id><created>2006-06-01</created><updated>2006-06-12</updated><authors><author><keyname>Caranti</keyname><forenames>A.</forenames></author><author><keyname>Volta</keyname><forenames>F. Dalla</forenames></author><author><keyname>Sala</keyname><forenames>M.</forenames></author><author><keyname>Villani</keyname><forenames>F.</forenames></author></authors><title>Imprimitive permutations groups generated by the round functions of
  key-alternating block ciphers and truncated differential cryptanalysis</title><categories>math.GR cs.CR</categories><comments>9 pages - corrected embarrassing typo in the title</comments><msc-class>20B15</msc-class><abstract>  We answer a question of Paterson, showing that all block systems for the
group generated by the round functions of a key-alternating block cipher are
the translates of a linear subspace. Following up remarks of Paterson and
Shamir, we exhibit a connection to truncated differential cryptanalysis.
  We also give a condition that guarantees that the group generated by the
round functions of a key-alternating block cipher is primitive. This applies in
particular to AES.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0606122</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0606122</id><created>2006-06-05</created><updated>2007-01-25</updated><authors><author><keyname>Bell</keyname><forenames>George I.</forenames></author></authors><title>Diagonal Peg Solitaire</title><categories>math.CO cs.DM cs.DS</categories><comments>20 pages, 11 figures</comments><msc-class>00A08; 97A20</msc-class><journal-ref>INTEGERS: Electronic Journal of Combinatorial Number Theory 7
  (2007) #G01</journal-ref><abstract>  We study the classical game of peg solitaire when diagonal jumps are allowed.
We prove that on many boards, one can begin from a full board with one peg
missing, and finish with one peg anywhere on the board. We then consider the
problem of finding solutions that minimize the number of moves (where a move is
one or more jumps by the same peg), and find the shortest solution to the
&quot;central game&quot;, which begins and ends at the center. In some cases we can prove
analytically that our solutions are the shortest possible, in other cases we
apply A* or bidirectional search heuristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0606315</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0606315</id><created>2006-06-13</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Bayesian Regression of Piecewise Constant Functions</title><categories>math.ST cs.LG math.PR stat.TH</categories><comments>27 pages, 18 figures, 1 table, 3 algorithms</comments><report-no>IDSIA-14-05</report-no><abstract>  We derive an exact and efficient Bayesian regression algorithm for piecewise
constant functions of unknown segment number, boundary location, and levels. It
works for any noise and segment level prior, e.g. Cauchy which can handle
outliers. We derive simple but good estimates for the in-segment variance. We
also propose a Bayesian regression curve as a better way of smoothing data
without blurring boundaries. The Bayesian approach also allows straightforward
determination of the evidence, break probabilities and error estimates, useful
for model selection and significance and robustness studies. We discuss the
performance on synthetic and real-world examples. Many possible extensions will
be discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0606643</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0606643</id><created>2006-06-26</created><updated>2006-07-18</updated><authors><author><keyname>Kanhouche</keyname><forenames>Rami</forenames><affiliation>CMLA</affiliation></author></authors><title>Entropy And Vision</title><categories>math.PR cs.CV cs.DB cs.DM cs.LG math.CO</categories><proxy>ccsd ccsd-00081913</proxy><msc-class>I.2.10 Vision and Scene Understanding</msc-class><abstract>  In vector quantization the number of vectors used to construct the codebook
is always an undefined problem, there is always a compromise between the number
of vectors and the quantity of information lost during the compression. In this
text we present a minimum of Entropy principle that gives solution to this
compromise and represents an Entropy point of view of signal compression in
general. Also we present a new adaptive Object Quantization technique that is
the same for the compression and the perception.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0606734</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0606734</id><created>2006-06-28</created><updated>2007-03-21</updated><authors><author><keyname>Barg</keyname><forenames>Alexander</forenames></author><author><keyname>Musin</keyname><forenames>Oleg R.</forenames></author></authors><title>Codes in spherical caps</title><categories>math.MG cs.IT math.IT</categories><journal-ref>Advances in Mathematics of Communications, vol. 1, no. 1, 2007,
  131-149</journal-ref><abstract>  We consider bounds on codes in spherical caps and related problems in
geometry and coding theory. An extension of the Delsarte method is presented
that relates upper bounds on the size of spherical codes to upper bounds on
codes in caps. Several new upper bounds on codes in caps are derived.
Applications of these bounds to estimates of the kissing numbers and one-sided
kissing numbers are considered.
  It is proved that the maximum size of codes in spherical caps for large
dimensions is determined by the maximum size of spherical codes, so these
problems are asymptotically equivalent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0606771</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0606771</id><created>2006-06-29</created><updated>2006-07-23</updated><authors><author><keyname>Mironov</keyname><forenames>Ilya</forenames></author><author><keyname>Mityagin</keyname><forenames>Anton</forenames></author><author><keyname>Nissim</keyname><forenames>Kobbi</forenames></author></authors><title>Hard Instances of the Constrained Discrete Logarithm Problem</title><categories>math.NT cs.CR</categories><msc-class>11B50 (primary) 11B13, 05B40, 51A30, 94A60 (secondary)</msc-class><journal-ref>In proceedings of 7th Algorithmic Number Theory Symposium (ANTS
  VII), pages 582--598, 2006</journal-ref><abstract>  The discrete logarithm problem (DLP) generalizes to the constrained DLP,
where the secret exponent $x$ belongs to a set known to the attacker. The
complexity of generic algorithms for solving the constrained DLP depends on the
choice of the set. Motivated by cryptographic applications, we study sets with
succinct representation for which the constrained DLP is hard. We draw on
earlier results due to Erd\&quot;os et al. and Schnorr, develop geometric tools such
as generalized Menelaus' theorem for proving lower bounds on the complexity of
the constrained DLP, and construct sets with succinct representation with
provable non-trivial lower bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0607051</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0607051</id><created>2006-07-03</created><authors><author><keyname>Morikawa</keyname><forenames>Naoto</forenames></author></authors><title>Discrete differential geometry of triangle tiles and algebra of closed
  trajectories</title><categories>math.CO cs.DM math.MG</categories><comments>15 pages, 6 figures</comments><msc-class>52B99; 92D20</msc-class><abstract>  This paper proposes a new mathematical framework that can be applied to
biological problems such as analysis of the structures of proteins and protein
complexes. In particular, it gives a new method for encoding the
three-dimensional structure of a protein into a binary sequence, where proteins
are approximated by a folded tetrahedron sequence. It also gives a new
algebraic framework for describing molecular complexes and their interactions.
  For simplicity, we shall explain the framework in the case of two-dimensional
objects. Then, the binary code of a plane curve is obtained as the ``second
derivative'' of the curve and ``fusion and fission'' of closed trajectories is
described algebraically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0607071</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0607071</id><created>2006-07-04</created><authors><author><keyname>Li</keyname><forenames>Xueliang</forenames></author><author><keyname>Tu</keyname><forenames>Jianhua</forenames></author></authors><title>NP-completeness of 4-incidence colorability of semi-cubic graphs</title><categories>math.CO cs.CC</categories><comments>11 pages</comments><msc-class>05C15; 68Q17</msc-class><abstract>  The incidence coloring conjecture, proposed by Brualdi and Massey in 1993,
states that the incidence coloring number of every graph is at most ${\it
\Delta}+2$, where ${\it \Delta}$ is the maximum degree of a graph. The
conjecture was shown to be false in general by Guiduli in 1997, following the
work of Algor and Alon. However, in 2005 Maydanskiy proved that the conjecture
holds for any graph with ${\it \Delta}\leq 3$. It is easily deduced that the
incidence coloring number of a semi-cubic graph is 4 or 5. In this paper, we
show that it is already NP-complete to determine if a semi-cubic graph is
4-incidence colorable, and therefore it is NP-complete to determine if a
general graph is $k$-incidence colorable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0607088</identifier>
 <datestamp>2011-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0607088</id><created>2006-07-04</created><authors><author><keyname>Letchford</keyname><forenames>Adam N.</forenames></author><author><keyname>Theis</keyname><forenames>Dirk Oliver</forenames></author></authors><title>Odd minimum cut sets and b-matchings revisited</title><categories>math.OC cs.DM</categories><comments>6 pages. An extended abstract of an earlier version appeared in Proc.
  IPCO X (2004)</comments><msc-class>90C27; 90C35; 90C57</msc-class><abstract>  The famous Padberg-Rao separation algorithm for b-matching polyhedra can be
implemented to run in O(n^2m log(n^2/m)) time in the uncapacitated case, and in
O(nm^2 log(n^2/m)) time in the capacitated case (where n is the number of
vertices and m is the number of edges of the underlying graph). We give a new
and simple algorithm for the capacitated case which can be implemented to run
in O(n^2m log(n^2/m)) time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0607243</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0607243</id><created>2006-07-10</created><authors><author><keyname>Abraham</keyname><forenames>Isabelle</forenames><affiliation>DCRE</affiliation></author><author><keyname>Abraham</keyname><forenames>Romain</forenames><affiliation>MAPMO</affiliation></author><author><keyname>Bergounioux</keyname><forenames>Maitine</forenames><affiliation>MAPMO</affiliation></author></authors><title>An active curve approach for tomographic reconstruction of binary
  radially symmetric objects</title><categories>math.OC cs.CV</categories><proxy>ccsd ccsd-00084855</proxy><abstract>  This paper deals with a method of tomographic reconstruction of radially
symmetric objects from a single radiograph, in order to study the behavior of
shocked material. The usual tomographic reconstruction algorithms such as
generalized inverse or filtered back-projection cannot be applied here because
data are very noisy and the inverse problem associated to single view
tomographic reconstruction is highly unstable. In order to improve the
reconstruction, we propose here to add some a priori assumptions on the looked
after object. One of these assumptions is that the object is binary and
consequently, the object may be described by the curves that separate the two
materials. We present a model that lives in BV space and leads to a non local
Hamilton-Jacobi equation, via a level set strategy. Numerical experiments are
performed (using level sets methods) on synthetic objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0607368</identifier>
 <datestamp>2012-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0607368</id><created>2006-07-16</created><authors><author><keyname>Sturmfels</keyname><forenames>Bernd</forenames></author><author><keyname>Tevelev</keyname><forenames>Jenia</forenames></author><author><keyname>Yu</keyname><forenames>Josephine</forenames></author></authors><title>The Newton Polytope of the Implicit Equation</title><categories>math.CO cs.SC math.AG</categories><comments>18 pages, 3 figures</comments><msc-class>13P10, 14Q99, 52B20, 68W30</msc-class><journal-ref>Moscow Mathematical Journal 7 (2007), no. 2, 327--346, 351</journal-ref><abstract>  We apply tropical geometry to study the image of a map defined by Laurent
polynomials with generic coefficients. If this image is a hypersurface then our
approach gives a construction of its Newton polytope.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0607411</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0607411</id><created>2006-07-18</created><authors><author><keyname>Duchamp</keyname><forenames>G&#xe9;rard</forenames><affiliation>LIPN</affiliation></author><author><keyname>Laugerotte</keyname><forenames>Eric</forenames><affiliation>LIFAR EA2655</affiliation></author><author><keyname>Luque</keyname><forenames>Jean-Gabriel</forenames><affiliation>IGM-LabInfo</affiliation></author></authors><title>Extending the scalars of minimizations</title><categories>math.CO cs.DS cs.SC</categories><proxy>ccsd ccsd-00085307</proxy><journal-ref>SCI, \'{E}tats-Unis d'Am\'{e}rique (2001)</journal-ref><abstract>  In the classical theory of formal languages, finite state automata allow to
recognize the words of a rational subset of $\Sigma^*$ where $\Sigma$ is a set
of symbols (or the alphabet). Now, given a semiring $(\K,+,.)$, one can
construct $\K$-subsets of $\Sigma^*$ in the sense of Eilenberg, that are
alternatively called noncommutative formal power series for which a framework
very similar to language theory has been constructed Particular noncommutative
formal power series, which are called rational series, are the behaviour of a
family of weighted automata (or $\K$-automata). In order to get an efficient
encoding, it may be interesting to point out one of them with the smallest
number of states. Minimization processes of $\K$-automata already exist for
$\K$ being: {\bf a)} a field, {\bf b)} a noncommutative field, {\bf c)} a PID .
When $\K$ is the bolean semiring, such a minimization process (with
isomorphisms of minimal objects) is known within the category of deterministic
automata. Minimal automata have been proved to be isomorphic in cases {\bf (a)}
and {\bf (b)}. But the proof given for (b) is not constructive. In fact, it
lays on the existence of a basis for a submodule of $\K^n$. Here we give an
independent algorithm which reproves this fact and an example of a pair of
nonisomorphic minimal automata. Moreover, we examine the possibility of
extending {\bf (c)}. To this end, we provide an {\em Effective Minimization
Process} (or {\em EMP}) which can be used for more general sets of
coefficients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0607412</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0607412</id><created>2006-07-18</created><authors><author><keyname>Duchamp</keyname><forenames>G&#xe9;rard</forenames><affiliation>LIPN</affiliation></author><author><keyname>Flouret</keyname><forenames>Marianne</forenames><affiliation>LIH EA3219</affiliation></author><author><keyname>Laugerotte</keyname><forenames>Eric</forenames><affiliation>LIFAR EA2655</affiliation></author><author><keyname>Luque</keyname><forenames>Jean-Gabriel</forenames><affiliation>IGM-LabInfo</affiliation></author></authors><title>Direct and dual laws for automata with multiplicities</title><categories>math.CO cs.DM cs.SC</categories><proxy>ccsd ccsd-00085316</proxy><journal-ref>Theoretical Computer Science 267 (2001) 105-120</journal-ref><abstract>  We present here theoretical results coming from the implementation of the
package called AMULT (automata with multiplicities in several noncommutative
variables). We show that classical formulas are ``almost every time'' optimal,
characterize the dual laws preserving rationality and also relators that are
compatible with these laws.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0607420</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0607420</id><created>2006-07-18</created><authors><author><keyname>Luque</keyname><forenames>Jean-Gabriel</forenames><affiliation>IGM-LabInfo</affiliation></author><author><keyname>Duchamp</keyname><forenames>G&#xe9;rard Henry Edmond</forenames><affiliation>LIPN</affiliation></author></authors><title>Transitive factorizations of free partially commutative monoids and Lie
  algebras</title><categories>math.CO cs.DM cs.SC math.GM</categories><proxy>ccsd ccsd-00086323</proxy><journal-ref>Discrete Mathematics 246, Issue 1-3 (2002) 83 - 97</journal-ref><abstract>  Let $\M(A,\theta)$ be a free partially commutative monoid. We give here a
necessary and sufficient condition on a subalphabet $B\subset A$ such that the
right factor of a bisection $\M(A,\theta)=\M(B,\theta\_B).T$ be also partially
commutative free. This extends strictly the (classical) elimination theory on
partial commutations and allows to construct new factorizations of
$\M(A,\theta)$ and associated bases of $L\_K(A,\theta)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0607462</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0607462</id><created>2006-07-19</created><authors><author><keyname>Tabareau</keyname><forenames>Nicolas</forenames><affiliation>PPS</affiliation></author></authors><title>De l'oprateur de trace dans les jeux de Conway</title><categories>math.CT cs.PL</categories><proxy>ccsd ccsd-00086635</proxy><abstract>  In this report, we propose a game semantics model of intuitionistic linear
logic with a notion of brackets and a trace operator. This model is a revised
version of Conway games augmented with an algebraicly defined gain which enable
to describe well bracketed strategies. We then show the existence of a free
cocommutative comonoid in the category of Conway. To conclude, we propose a new
model of an Algol-like language with higher-order using the presence of a trace
operator in our model to describe the memorial aspect of the language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0607507</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0607507</id><created>2006-07-20</created><updated>2006-12-04</updated><authors><author><keyname>Litvak</keyname><forenames>N.</forenames></author><author><keyname>Scheinhardt</keyname><forenames>W. R. W.</forenames></author><author><keyname>Volkovich</keyname><forenames>Y.</forenames></author></authors><title>In-Degree and PageRank of Web pages: Why do they follow similar power
  laws?</title><categories>math.PR cs.IR</categories><comments>20 pages, 3 figures; typos added; reference added</comments><report-no>Memorandum 1807, Dept. of Applied. Mathematics, University of Twente</report-no><msc-class>90B15, 68P10, 40E05</msc-class><abstract>  The PageRank is a popularity measure designed by Google to rank Web pages.
Experiments confirm that the PageRank obeys a `power law' with the same
exponent as the In-Degree. This paper presents a novel mathematical model that
explains this phenomenon. The relation between the PageRank and In-Degree is
modelled through a stochastic equation, which is inspired by the original
definition of the PageRank, and is analogous to the well-known distributional
identity for the busy period in the M/G/1 queue. Further, we employ the theory
of regular variation and Tauberian theorems to analytically prove that the tail
behavior of the PageRank and the In-Degree differ only by a multiplicative
factor, for which we derive a closed-form expression. Our analytical results
are in good agreement with experimental data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0607597</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0607597</id><created>2006-07-24</created><authors><author><keyname>Coquerelle</keyname><forenames>Mathieu</forenames><affiliation>LMC - Imag, Gravir - Imag</affiliation></author><author><keyname>Allard</keyname><forenames>J&#xe9;r&#xe9;mie</forenames><affiliation>GRAVIR - Imag</affiliation></author><author><keyname>Cottet</keyname><forenames>Georges-Henri</forenames><affiliation>LMC - Imag</affiliation></author><author><keyname>Cani</keyname><forenames>Marie-Paule</forenames><affiliation>GRAVIR - Imag</affiliation></author></authors><title>A Vortex Method for Bi-phasic Fluids Interacting with Rigid Bodies</title><categories>math.NA cs.GR</categories><proxy>ccsd ccsd-00087126</proxy><msc-class>ACM I.3.7 ACM I.3.5</msc-class><abstract>  We present an accurate Lagrangian method based on vortex particles,
level-sets, and immersed boundary methods, for animating the interplay between
two fluids and rigid solids. We show that a vortex method is a good choice for
simulating bi-phase flow, such as liquid and gas, with a good level of realism.
Vortex particles are localized at the interfaces between the two fluids and
within the regions of high turbulence. We gain local precision and efficiency
from the stable advection permitted by the vorticity formulation. Moreover, our
numerical method straightforwardly solves the two-way coupling problem between
the fluids and animated rigid solids. This new approach is validated through
numerical comparisons with reference experiments from the computational fluid
community. We also show that the visually appealing results obtained in the CG
community can be reproduced with increased efficiency and an easier
implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0607648</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0607648</id><created>2006-07-25</created><authors><author><keyname>Lim</keyname><forenames>Lek-Heng</forenames></author></authors><title>Singular Values and Eigenvalues of Tensors: A Variational Approach</title><categories>math.SP cs.IR cs.NA math.NA math.OC</categories><report-no>SCCM Technical Report 05-10</report-no><msc-class>15A18, 15A48, 15A69, 15A72, 65F15, 65K10</msc-class><journal-ref>Proceedings of the IEEE International Workshop on Computational
  Advances in Multi-Sensor Adaptive Processing (CAMSAP '05), Vol. 1 (2005), pp.
  129--132</journal-ref><abstract>  We propose a theory of eigenvalues, eigenvectors, singular values, and
singular vectors for tensors based on a constrained variational approach much
like the Rayleigh quotient for symmetric matrix eigenvalues. These notions are
particularly useful in generalizing certain areas where the spectral theory of
matrices has traditionally played an important role. For illustration, we will
discuss a multilinear generalization of the Perron-Frobenius theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0608116</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0608116</id><created>2006-08-04</created><authors><author><keyname>Dambreville</keyname><forenames>Frederic</forenames><affiliation>DGA/CEP/GIP/SRO</affiliation></author></authors><title>Conflict Free Rule for Combining Evidences</title><categories>math.LO cs.LO math.ST stat.TH</categories><comments>Submitted to DSmT book Vol. 2, F. Smarandache and J. Dezert editors</comments><proxy>ccsd ccsd-00088699</proxy><abstract>  Recent works have investigated the problem of the conflict redistribution in
the fusion rules of evidence theories. As a consequence of these works, many
new rules have been proposed. Now, there is not a clear theoretical criterion
for a choice of a rule instead another. The present chapter proposes a new
theoretically grounded rule, based on a new concept of sensor independence.
This new rule avoids the conflict redistribution, by an adaptive combination of
the beliefs. Both the logical grounds and the algorithmic implementation are
considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0608210</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0608210</id><created>2006-08-08</created><authors><author><keyname>B&#xe4;&#xe4;rnhielm</keyname><forenames>Henrik</forenames></author></authors><title>Recognising the Suzuki groups in their natural representations</title><categories>math.GR cs.DS</categories><msc-class>20H30, 68Q25, 68W20 (Primary) 20P05, 20C33, 20C40 (Secondary)</msc-class><journal-ref>J. Algebra 300 (1), 171-198, 2006</journal-ref><doi>10.1016/j.jalgebra.2006.02.010</doi><abstract>  Under the assumption of a certain conjecture, for which there exists strong
experimental evidence, we produce an efficient algorithm for constructive
membership testing in the Suzuki groups Sz(q), where q = 2^{2m + 1} for some m
&gt; 0, in their natural representations of degree 4. It is a Las Vegas algorithm
with running time O{log(q)} field operations, and a preprocessing step with
running time O{log(q) loglog(q)} field operations. The latter step needs an
oracle for the discrete logarithm problem in GF(q).
  We also produce a recognition algorithm for Sz(q) = &lt;X&gt;. This is a Las Vegas
algorithm with running time O{|X|^2} field operations.
  Finally, we give a Las Vegas algorithm that, given &lt;X&gt;^h = Sz(q) for some h
in GL(4, q), finds some g such that &lt;X&gt;^g = Sz(q). The running time is O{log(q)
loglog(q) + |X|} field operations.
  Implementations of the algorithms are available for the computer system
MAGMA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0608522</identifier>
 <datestamp>2007-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0608522</id><created>2006-08-21</created><updated>2007-06-27</updated><authors><author><keyname>Hein</keyname><forenames>Matthias</forenames></author><author><keyname>Audibert</keyname><forenames>Jean-Yves</forenames></author><author><keyname>von Luxburg</keyname><forenames>Ulrike</forenames></author></authors><title>Graph Laplacians and their convergence on random neighborhood graphs</title><categories>math.ST cs.LG stat.TH</categories><comments>Improved presentation, typos corrected, to appear in JMLR</comments><msc-class>62H12 (Primary) 62H30, 62G99 (Secondary)</msc-class><abstract>  Given a sample from a probability measure with support on a submanifold in
Euclidean space one can construct a neighborhood graph which can be seen as an
approximation of the submanifold. The graph Laplacian of such a graph is used
in several machine learning methods like semi-supervised learning,
dimensionality reduction and clustering. In this paper we determine the
pointwise limit of three different graph Laplacians used in the literature as
the sample size increases and the neighborhood size approaches zero. We show
that for a uniform measure on the submanifold all graph Laplacians have the
same limit up to constants. However in the case of a non-uniform measure on the
submanifold only the so called random walk graph Laplacian converges to the
weighted Laplace-Beltrami operator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0608556</identifier>
 <datestamp>2008-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0608556</id><created>2006-08-22</created><updated>2008-11-26</updated><authors><author><keyname>Nguyen</keyname><forenames>XuanLong</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author><author><keyname>Jordan</keyname><forenames>Michael I.</forenames></author></authors><title>On optimal quantization rules for some problems in sequential
  decentralized detection</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>Published as IEEE Transactions on Information Theory, Vol. 54(7),
  3285-3295, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the design of systems for sequential decentralized detection, a
problem that entails several interdependent choices: the choice of a stopping
rule (specifying the sample size), a global decision function (a choice between
two competing hypotheses), and a set of quantization rules (the local decisions
on the basis of which the global decision is made). This paper addresses an
open problem of whether in the Bayesian formulation of sequential decentralized
detection, optimal local decision functions can be found within the class of
stationary rules. We develop an asymptotic approximation to the optimal cost of
stationary quantization rules and exploit this approximation to show that
stationary quantizers are not optimal in a broad class of settings. We also
consider the class of blockwise stationary quantizers, and show that
asymptotically optimal quantizers are likelihood-based threshold rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0608571</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0608571</id><created>2006-08-23</created><authors><author><keyname>Muskens</keyname><forenames>Reinhard</forenames></author></authors><title>Intensional Models for the Theory of Types</title><categories>math.LO cs.AI</categories><comments>25 pages</comments><msc-class>03B15</msc-class><abstract>  In this paper we define intensional models for the classical theory of types,
thus arriving at an intensional type logic ITL. Intensional models generalize
Henkin's general models and have a natural definition. As a class they do not
validate the axiom of Extensionality. We give a cut-free sequent calculus for
type theory and show completeness of this calculus with respect to the class of
intensional models via a model existence theorem. After this we turn our
attention to applications. Firstly, it is argued that, since ITL is truly
intensional, it can be used to model ascriptions of propositional attitude
without predicting logical omniscience. In order to illustrate this a small
fragment of English is defined and provided with an ITL semantics. Secondly, it
is shown that ITL models contain certain objects that can be identified with
possible worlds. Essential elements of modal logic become available within
classical type theory once the axiom of Extensionality is given up.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0608603</identifier>
 <datestamp>2007-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0608603</id><created>2006-08-24</created><updated>2007-09-27</updated><authors><author><keyname>Balkova</keyname><forenames>Lubomira</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Pelantova</keyname><forenames>Edita</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Steiner</keyname><forenames>Wolfgang</forenames><affiliation>LIAFA</affiliation></author></authors><title>Sequences with constant number of return words</title><categories>math.CO cs.DM</categories><abstract>  An infinite word has the property $R_m$ if every factor has exactly $m$
return words. Vuillon showed that $R_2$ characterizes Sturmian words. We prove
that a word satisfies $R_m$ if its complexity function is $(m-1)n+1$ and if it
contains no weak bispecial factor. These conditions are necessary for $m=3$,
whereas for $m=4$ the complexity function need not be $3n+1$. New examples of
words satisfying $R_m$ are given by words related to digital expansions in real
bases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0608713</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0608713</id><created>2006-08-29</created><authors><author><keyname>Blanchard</keyname><forenames>Gilles</forenames><affiliation>FHG FIRST.IDA</affiliation></author><author><keyname>Fleuret</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>EPFL -- CVLAB</affiliation></author></authors><title>Occam's hammer: a link between randomized learning and multiple testing
  FDR control</title><categories>math.ST cs.LG stat.TH</categories><comments>13 pages -- conference communication type format</comments><proxy>ccsd ccsd-00090244</proxy><abstract>  We establish a generic theoretical tool to construct probabilistic bounds for
algorithms where the output is a subset of objects from an initial pool of
candidates (or more generally, a probability distribution on said pool). This
general device, dubbed &quot;Occam's hammer'', acts as a meta layer when a
probabilistic bound is already known on the objects of the pool taken
individually, and aims at controlling the proportion of the objects in the set
output not satisfying their individual bound. In this regard, it can be seen as
a non-trivial generalization of the &quot;union bound with a prior'' (&quot;Occam's
razor''), a familiar tool in learning theory. We give applications of this
principle to randomized classifiers (providing an interesting alternative
approach to PAC-Bayes bounds) and multiple testing (where it allows to retrieve
exactly and extend the so-called Benjamini-Yekutieli testing procedure).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0608733</identifier>
 <datestamp>2009-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0608733</id><created>2006-08-29</created><authors><author><keyname>Bubenik</keyname><forenames>Peter</forenames></author></authors><title>Context for models of concurrency</title><categories>math.AT cs.DC</categories><comments>18 pages, to appear in Electronic Notes in Theoretical Computer
  Science, preliminary version in Proceedings of the Workshop on Geometry and
  Topology in Concurrency and Distributed Computing, BRICS Notes NS-04-2,
  pp.33-49</comments><journal-ref>Electron. Notes Theor. Comput. Sci. 230 (2009) 3-21</journal-ref><doi>10.1016/j.entcs.2009.02.014</doi><abstract>  Many categories have been used to model concurrency. Using any of these, the
challenge is to reduce a given model to a smaller representation which
nevertheless preserves the relevant computer-scientific information. That is,
one wants to replace a given model with a simpler model with the same directed
homotopy-type. Unfortunately, the obvious definition of directed homotopy
equivalence is too coarse. This paper introduces the notion of context to
refine this definition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0608789</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0608789</id><created>2006-08-31</created><updated>2006-11-11</updated><authors><author><keyname>Malesevic</keyname><forenames>Branko J.</forenames></author></authors><title>One method for proving inequalities by computer</title><categories>math.CA cs.GR cs.MS cs.NA math.GM math.NA</categories><comments>Accepted in Journal of Inequalities and Applications</comments><msc-class>26Dxx, 33F05, 41A20</msc-class><abstract>  In this article we consider a method for proving a class of analytical
inequalities via minimax rational approximations. All numerical calculations in
this paper are given by Maple computer program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0609360</identifier>
 <datestamp>2007-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0609360</id><created>2006-09-13</created><updated>2007-01-24</updated><authors><author><keyname>Gerbracht</keyname><forenames>Eberhard H. -A.</forenames></author></authors><title>Minimal Polynomials for the Coordinates of the Harborth Graph</title><categories>math.CO cs.SC</categories><comments>v1: documentclass amsart, 16 pages, 4 figures. v2: same as v1, but
  now has 18 pages, with a final section (&quot;Coda&quot;) on the consequences to the
  structure of the Harborth graph and some references added; some typos
  corrected. v3: minor change to the introduction (re: history of the Harborth
  Graph); one reference added; some more typos corrected</comments><msc-class>05C62 (Primary); 05C10, 13P10 (Secondary)</msc-class><abstract>  The Harborth graph is the smallest known example of a 4-regular planar
unit-distance graph. In this paper we give an analytical description of the
coordinates of its vertices for a particular embedding in the Euclidean plane.
More precisely, we show, how to calculate the minimal polynomials of the
coordinates of its vertices (with the help of a computer algebra system), and
list those. Furthermore some algebraic properties of these polynomials, and
consequences to the structure of the Harborth graph are determined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0609461</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0609461</id><created>2006-09-16</created><authors><author><keyname>Dambreville</keyname><forenames>Frederic</forenames><affiliation>DGA/CTA/DT/GIP</affiliation></author></authors><title>Cross-Entropy method: convergence issues for extended implementation</title><categories>math.OC cs.LG cs.NE math.ST stat.TH</categories><comments>Paper written for the workshop &quot;Rare Event SIMulation 2006&quot;, Bamberg,
  Germany</comments><proxy>ccsd ccsd-00095545</proxy><abstract>  The cross-entropy method (CE) developed by R. Rubinstein is an elegant
practical principle for simulating rare events. The method approximates the
probability of the rare event by means of a family of probabilistic models. The
method has been extended to optimization, by considering an optimal event as a
rare event. CE works rather good when dealing with deterministic function
optimization. Now, it appears that two conditions are needed for a good
convergence of the method. First, it is necessary to have a family of models
sufficiently flexible for discriminating the optimal events. Indirectly, it
appears also that the function to be optimized should be deterministic. The
purpose of this paper is to consider the case of partially discriminating model
family, and of stochastic functions. It will be shown on simple examples that
the CE could fail when relaxing these hypotheses. Alternative improvements of
the CE method are investigated and compared on random examples in order to
handle this issue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0609562</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0609562</id><created>2006-09-20</created><updated>2008-02-21</updated><authors><author><keyname>Joyner</keyname><forenames>David</forenames></author></authors><title>On quadratic residue codes and hyperelliptic curves</title><categories>math.CO cs.IT math.AG math.IT math.NT</categories><comments>18 pages, no figures</comments><msc-class>94B40, 11T71, 14G15, 14G50</msc-class><abstract>  A long standing problem has been to develop &quot;good&quot; binary linear codes to be
used for error-correction. This paper investigates in some detail an attack on
this problem using a connection between quadratic residue codes and
hyperelliptic curves. One question which coding theory is used to attack is:
Does there exist a c&lt;2 such that, for all sufficiently large $p$ and all
subsets S of GF(p), we have |X_S(GF(p))| &lt; cp?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0610067</identifier>
 <datestamp>2009-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0610067</id><created>2006-10-02</created><authors><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author></authors><title>On the context-freeness of the set of words containing overlaps</title><categories>math.CO cs.FL</categories><comments>8 pages</comments><msc-class>68R15</msc-class><abstract>  We show that the set of binary words containing overlaps is not unambiguously
context-free and that the set of ternary words containing overlaps is not
context-free. We also show that the set of binary words that are not subwords
of the Thue-Morse word is not unambiguously context-free.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0610121</identifier>
 <datestamp>2007-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0610121</id><created>2006-10-03</created><updated>2007-08-22</updated><authors><author><keyname>Salem</keyname><forenames>Fatima K. Abu</forenames><affiliation>Computer Science Department, American University of Beirut</affiliation></author><author><keyname>Khuri-Makdisi</keyname><forenames>Kamal</forenames><affiliation>Center for Advanced Mathematical Sciences, American University of Beirut</affiliation></author></authors><title>Fast Jacobian group operations for C_{3,4} curves over a large finite
  field</title><categories>math.NT cs.SC math.AG</categories><comments>25 pages, identical to version 2 except for a remark about the
  published version of the article, which includes Magma code for the
  algorithms</comments><msc-class>14Q05, 14H40, 14H45, 11Y16, 68W30</msc-class><journal-ref>LMS J. Comput. Math. 10 (2007) 307-328, may be downloaded from
  http://www.lms.ac.uk/jcm/10/lms2006-049/</journal-ref><abstract>  Let C be an arbitrary smooth algebraic curve of genus g over a large finite
field K. We revisit fast addition algorithms in the Jacobian of C due to
Khuri-Makdisi (math.NT/0409209, to appear in Math. Comp.). The algorithms,
which reduce to linear algebra in vector spaces of dimension O(g) once |K| &gt;&gt;
g, and which asymptotically require O(g^{2.376}) field operations using fast
linear algebra, are shown to perform efficiently even for certain low genus
curves. Specifically, we provide explicit formulae for performing the group law
on Jacobians of C_{3,4} curves of genus 3. We show that, typically, the
addition of two distinct elements in the Jacobian of a C_{3,4} curve requires
117 multiplications and 2 inversions in K, and an element can be doubled using
129 multiplications and 2 inversions in K. This represents an improvement of
approximately 20% over previous methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0610184</identifier>
 <datestamp>2007-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0610184</id><created>2006-10-05</created><authors><author><keyname>Bayraktar</keyname><forenames>Erhan</forenames></author><author><keyname>Dayanik</keyname><forenames>Savas</forenames></author><author><keyname>Karatzas</keyname><forenames>Ioannis</forenames></author></authors><title>Adaptive Poisson disorder problem</title><categories>math.PR cs.IT math.IT math.ST stat.TH</categories><comments>Published at http://dx.doi.org/10.1214/105051606000000312 in the
  Annals of Applied Probability (http://www.imstat.org/aap/) by the Institute
  of Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AAP-AAP0171</report-no><msc-class>62L10 (Primary) 62L15, 62C10, 60G40 (Secondary)</msc-class><journal-ref>Annals of Applied Probability 2006, Vol. 16, No. 3, 1190-1261</journal-ref><doi>10.1214/105051606000000312</doi><abstract>  We study the quickest detection problem of a sudden change in the arrival
rate of a Poisson process from a known value to an unknown and unobservable
value at an unknown and unobservable disorder time. Our objective is to design
an alarm time which is adapted to the history of the arrival process and
detects the disorder time as soon as possible. In previous solvable versions of
the Poisson disorder problem, the arrival rate after the disorder has been
assumed a known constant. In reality, however, we may at most have some prior
information about the likely values of the new arrival rate before the disorder
actually happens, and insufficient estimates of the new rate after the disorder
happens. Consequently, we assume in this paper that the new arrival rate after
the disorder is a random variable. The detection problem is shown to admit a
finite-dimensional Markovian sufficient statistic, if the new rate has a
discrete distribution with finitely many atoms. Furthermore, the detection
problem is cast as a discounted optimal stopping problem with running cost for
a finite-dimensional piecewise-deterministic Markov process. This optimal
stopping problem is studied in detail in the special case where the new arrival
rate has Bernoulli distribution. This is a nontrivial optimal stopping problem
for a two-dimensional piecewise-deterministic Markov process driven by the same
point process. Using a suitable single-jump operator, we solve it fully,
describe the analytic properties of the value function and the stopping region,
and present methods for their numerical calculation. We provide a concrete
example where the value function does not satisfy the smooth-fit principle on a
proper subset of the connected, continuously differentiable optimal stopping
boundary, whereas it does on the complement of this set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0610680</identifier>
 <datestamp>2015-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0610680</id><created>2006-10-23</created><updated>2006-10-23</updated><authors><author><keyname>Schreiber</keyname><forenames>T.</forenames></author><author><keyname>Penrose</keyname><forenames>Mathew D.</forenames></author><author><keyname>Yukich</keyname><forenames>J. E.</forenames></author></authors><title>Gaussian limits for multidimensional random sequential packing at
  saturation (extended version)</title><categories>math.PR cs.OH</categories><comments>31 pages</comments><msc-class>Primary 60F05. Secondary 60D05, 60K35</msc-class><doi>10.1007/s00220-007-0218-2</doi><abstract>  Consider the random sequential packing model with infinite input and in any
dimension. When the input consists of non-zero volume convex solids we show
that the total number of solids accepted over cubes of volume $\lambda$ is
asymptotically normal as $\lambda \to \infty$. We provide a rate of
approximation to the normal and show that the finite dimensional distributions
of the packing measures converge to those of a mean zero generalized Gaussian
field. The method of proof involves showing that the collection of accepted
solids satisfies the weak spatial dependence condition known as stabilization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0611194</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0611194</id><created>2006-11-07</created><authors><author><keyname>Borgne</keyname><forenames>Yvan Le</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Marckert</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>LaBRI</affiliation></author></authors><title>Directed animals in the gas</title><categories>math.PR cs.DM</categories><proxy>ccsd hal-00112181</proxy><abstract>  In this paper, we revisit the enumeration of directed animals using gas
models. We show that there exists a natural construction of random directed
animals on any directed graph together with a particle system that explains at
the level of objects the formal link known between the density of the gas model
and the generating function of directed animals counted according to the area.
This provides some new methods to compute the generating function of directed
animals counted according to area, and leads in the particular case of the
square lattice to new combinatorial results and questions. A model of gas
related to directed animals counted according to area and perimeter on any
directed graph is also exhibited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0611422</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0611422</id><created>2006-11-14</created><authors><author><keyname>Cottrell</keyname><forenames>Marie</forenames><affiliation>MATISSE, Samos</affiliation></author><author><keyname>Ibbou</keyname><forenames>Sma&#xcf;l</forenames><affiliation>MATISSE, Samos</affiliation></author><author><keyname>Letr&#xe9;my</keyname><forenames>Patrick</forenames><affiliation>MATISSE, Samos</affiliation></author><author><keyname>Rousset</keyname><forenames>Patrick</forenames><affiliation>CEREQ</affiliation></author></authors><title>Cartes auto-organis\'{e}es pour l'analyse exploratoire de donn\'{e}es et
  la visualisation</title><categories>math.ST cs.NE nlin.AO stat.TH</categories><comments>Article de synth\`{e}se sur les applications de l'algorithme de
  Kohonen pour la visualisation et l'analyse de donn\'{e}es</comments><proxy>ccsd hal-00113754</proxy><journal-ref>Journal de la Soci\'{e}t\'{e} Fran\c{c}aise de Statistique 144
  n&amp;deg;4 (2003) 67-106</journal-ref><abstract>  This paper shows how to use the Kohonen algorithm to represent
multidimensional data, by exploiting the self-organizing property. It is
possible to get such maps as well for quantitative variables as for qualitative
ones, or for a mixing of both. The contents of the paper come from various
works by SAMOS-MATISSE members, in particular by E. de Bodt, B. Girard, P.
Letr\'{e}my, S. Ibbou, P. Rousset. Most of the examples have been studied with
the computation routines written by Patrick Letr\'{e}my, with the language
IML-SAS, which are available on the WEB page http://samos.univ-paris1.fr.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0611433</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0611433</id><created>2006-11-14</created><authors><author><keyname>Letr&#xe9;my</keyname><forenames>Patrick</forenames><affiliation>SAMOS</affiliation></author><author><keyname>Cottrell</keyname><forenames>Marie</forenames><affiliation>SAMOS</affiliation></author></authors><title>Working times in atypical forms of employment: the special case of
  part-time work</title><categories>math.ST cs.NE stat.TH</categories><comments>Chapitre 5, \`{a} la suite de la conf\'{e}rence ACSEG 2001 \`{a}
  Rennes</comments><proxy>ccsd hal-00113848</proxy><journal-ref>Connectionist Approaches in Economics and Management Sciences
  Kluwer (Ed.) (2003) 111-129</journal-ref><abstract>  In the present article, we attempt to devise a typology of forms of part-time
employment by applying a widely used neuronal methodology called Kohonen maps.
Starting out with data that we describe using category-specific variables, we
show how it is possible to represent observations and the modalities of the
variables that define them simultaneously, on a single map. This allows us to
ascertain, and to try to describe, the main categories of part-time employment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0611666</identifier>
 <datestamp>2009-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0611666</id><created>2006-11-21</created><updated>2007-06-26</updated><authors><author><keyname>Berger</keyname><forenames>Noam</forenames></author><author><keyname>Biskup</keyname><forenames>Marek</forenames></author><author><keyname>Hoffman</keyname><forenames>Christopher E.</forenames></author><author><keyname>Kozma</keyname><forenames>Gady</forenames></author></authors><title>Anomalous heat-kernel decay for random walk among bounded random
  conductances</title><categories>math.PR cs.DM math-ph math.MP</categories><comments>22 pages. Includes a self-contained proof of isoperimetric inequality
  for supercritical percolation clusters. Version to appear in AIHP +
  additional corrections</comments><msc-class>60G50; 58J35; 80A20</msc-class><journal-ref>Ann. Inst. H. Poincare Probab. Statist. 274 (2008), no. 2, 374-392</journal-ref><doi>10.1214/07-AIHP126</doi><abstract>  We consider the nearest-neighbor simple random walk on $\Z^d$, $d\ge2$,
driven by a field of bounded random conductances $\omega_{xy}\in[0,1]$. The
conductance law is i.i.d. subject to the condition that the probability of
$\omega_{xy}&gt;0$ exceeds the threshold for bond percolation on $\Z^d$. For
environments in which the origin is connected to infinity by bonds with
positive conductances, we study the decay of the $2n$-step return probability
$P_\omega^{2n}(0,0)$. We prove that $P_\omega^{2n}(0,0)$ is bounded by a random
constant times $n^{-d/2}$ in $d=2,3$, while it is $o(n^{-2})$ in $d\ge5$ and
$O(n^{-2}\log n)$ in $d=4$. By producing examples with anomalous heat-kernel
decay approaching $1/n^2$ we prove that the $o(n^{-2})$ bound in $d\ge5$ is the
best possible. We also construct natural $n$-dependent environments that
exhibit the extra $\log n$ factor in $d=4$. See also math.PR/0701248.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:math/0611679</identifier>
 <datestamp>2014-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>math/0611679</id><created>2006-11-22</created><authors><author><keyname>Rossin</keyname><forenames>Dominique</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Bouvel</keyname><forenames>Mathilde</forenames><affiliation>LIAFA</affiliation></author></authors><title>Longest Common Pattern between two Permutations</title><categories>math.CO cs.DM cs.DS</categories><proxy>ccsd hal-00115598</proxy><msc-class>05A05; 05C12; 05C85; 05C05; 90C39</msc-class><journal-ref>Algebr. Geom. Topol. 7 (2007) 829-843</journal-ref><doi>10.2140/agt.2007.7.829</doi><abstract>  In this paper, we give a polynomial (O(n^8)) algorithm for finding a longest
common pattern between two permutations of size n given that one is separable.
We also give an algorithm for general permutations whose complexity depends on
the length of the longest simple permutation involved in one of our
permutations.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="101000" completeListSize="102538">1122234|102001</resumptionToken>
</ListRecords>
</OAI-PMH>
