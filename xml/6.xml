<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:38:29Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|5001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4929</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4929</id><created>2008-09-29</created><authors><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Liu</keyname><forenames>Liping</forenames></author><author><keyname>Ma</keyname><forenames>Longhua</forenames></author><author><keyname>Sun</keyname><forenames>Youxian</forenames></author><author><keyname>Dong</keyname><forenames>Jinxiang</forenames></author></authors><title>Performance-Aware Power Management in Embedded Controllers with
  Multiple-Voltage Processors</title><categories>cs.OH</categories><comments>4 figures</comments><acm-class>C.3</acm-class><journal-ref>Information Technology Journal, 7(6): 942-947, 2008</journal-ref><doi>10.3923/itj.2008.942.947</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this work is to minimize the energy dissipation of embedded
controllers without jeopardizing the quality of control (QoC). Taking advantage
of the dynamic voltage scaling (DVS) technology, this paper develops a
performance-aware power management scheme for embedded controllers with
processors that allow multiple voltage levels. The periods of control tasks are
adapted online with respect to the current QoC, thus facilitating additional
energy reduction over standard DVS. To avoid the waste of CPU resources as a
result of the discrete voltage levels, a resource reclaiming mechanism is
employed to maximize the CPU utilization and also to improve the QoC.
Simulations are conducted to evaluate the performance of the proposed scheme.
Compared with the optimal standard DVS scheme, the proposed scheme is shown to
be able to save remarkably more energy while maintaining comparable QoC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4983</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4983</id><created>2008-09-29</created><authors><author><keyname>Butin</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>ICJ</affiliation></author></authors><title>Poisson Homology in Degree 0 for some Rings of Symplectic Invariants</title><categories>math-ph cs.SC math.MP math.RA</categories><comments>24 pages</comments><proxy>ccsd hal-00325594</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\go{g}$ be a finite-dimensional semi-simple Lie algebra, $\go{h}$ a
Cartan subalgebra of $\go{g}$, and $W$ its Weyl group. The group $W$ acts
diagonally on $V:=\go{h}\oplus\go{h}^*$, as well as on $\mathbb{C}[V]$. The
purpose of this article is to study the Poisson homology of the algebra of
invariants $\mathbb{C}[V]^W$ endowed with the standard symplectic bracket. To
begin with, we give general results about the Poisson homology space in degree
0, denoted by $HP_0(\mathbb{C}[V]^W)$, in the case where $\go{g}$ is of type
$B_n-C_n$ or $D_n$, results which support Alev's conjecture. Then we are
focusing the interest on the particular cases of ranks 2 and 3, by computing
the Poisson homology space in degree 0 in the cases where $\go{g}$ is of type
$B_2$ ($\go{so}_5$), $D_2$ ($\go{so}_4$), then $B_3$ ($\go{so}_7$), and
$D_3=A_3$ ($\go{so}_6\simeq\go{sl}_4$). In order to do this, we make use of a
functional equation introduced by Y. Berest, P. Etingof and V. Ginzburg. We
recover, by a different method, the result established by J. Alev and L.
Foissy, according to which the dimension of $HP_0(\mathbb{C}[V]^W)$ equals 2
for $B_2$. Then we calculate the dimension of this space and we show that it is
equal to 1 for $D_2$. We also calculate it for the rank 3 cases, we show that
it is equal to 3 for $B_3-C_3$ and 1 for $D_3=A_3$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4985</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4985</id><created>2008-09-29</created><authors><author><keyname>Nasser</keyname><forenames>Youssef</forenames><affiliation>IETR</affiliation></author><author><keyname>H&#xe9;lard</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>IETR</affiliation></author><author><keyname>Crussi&#xe8;re</keyname><forenames>Matthieu</forenames><affiliation>IETR</affiliation></author></authors><title>On the Influence of Carrier Frequency Offset and Sampling Frequency
  Offset in MIMO-OFDM Systems for Future Digital TV</title><categories>cs.NI</categories><proxy>ccsd hal-00325514</proxy><journal-ref>International Symposium on Wireless and Pervasive Computing,
  Gr\`ece (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the impact of carrier frequency offset (CFO) and
sampling frequency offset (SFO) on the performance of different MIMO-OFDM
schemes with high spectral efficiency for next generation of terrestrial
digital TV. We analyze particularly orthogonal Alamouti scheme, and
non-orthogonal (NO) schemes like VBLAST, linear dispersion (LD) code and Golden
code. This analysis gives a global view on the best suitable MIMO-OFDM scheme
with respect to CFO and SFO. We show that for high spectral efficiency,
Alamouti is more sensitive to CFO and SFO. Moreover, we show that all studied
MIMO-OFDM schemes are sensitive to CFO when it is greater than 1% of
inter-carrier spacing. Their sensitivity due to SFO is less than that due to
CFO.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4986</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4986</id><created>2008-09-29</created><authors><author><keyname>Nasser</keyname><forenames>Youssef</forenames><affiliation>IETR</affiliation></author><author><keyname>H&#xe9;lard</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>IETR</affiliation></author><author><keyname>Crussi&#xe8;re</keyname><forenames>Matthieu</forenames><affiliation>IETR</affiliation></author><author><keyname>Pasquero</keyname><forenames>Oudomsack</forenames><affiliation>IETR</affiliation></author></authors><title>Efficient MIMO-OFDM Schemes for Future Terrestrial Digital TV with
  Unequal Received Powers</title><categories>cs.NI</categories><proxy>ccsd hal-00325507</proxy><journal-ref>IEEE International Conference on Communications, Chine (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article investigates the effect of equal and unequal received powers on
the performances of different MIMO-OFDM schemes for terrestrial digital TV.
More precisely, we focus on three types of non-orthogonal schemes: the BLAST
scheme, the Linear Dispersion (LD) code and the Golden code, and we compare
their performances to that of Alamouti scheme. Using two receiving antennas, we
show that for moderate attenuation on the second antenna and high spectral
efficiency, Golden code outperforms other schemes. However, Alamouti scheme
presents the best performance for low spectral efficiency and equal received
powers or when one antenna is dramatically damaged. When three antennas are
used, we show that Golden code offers the highest robustness to power unbalance
at the receiving side
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4987</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4987</id><created>2008-09-29</created><authors><author><keyname>Nasser</keyname><forenames>Youssef</forenames><affiliation>IETR</affiliation></author><author><keyname>H&#xe9;lard</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>IETR</affiliation></author><author><keyname>Crussi&#xe8;re</keyname><forenames>Matthieu</forenames><affiliation>IETR</affiliation></author><author><keyname>Pasquero</keyname><forenames>Oudomsack</forenames><affiliation>IETR</affiliation></author></authors><title>Efficient 3D Space Time Space Block Code for Future Terrestrial Digital
  TV</title><categories>cs.NI</categories><proxy>ccsd hal-00325501</proxy><journal-ref>Symposium on Signal Processing Advances in Wireless
  Communications, Recife : Br\'esil (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article introduces a 3D space-time-space block code for future
terrestrial digital TV in single frequency networks. The proposed 3D code is
based on a double layer structure designed for inter-cell and intra-cell space
time coded transmissions. We show that this new structure is particularly
efficient for SFN environments regardless of the location of the receiver. It
is then suitable for fixed, portable and mobile receptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4989</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4989</id><created>2008-09-29</created><authors><author><keyname>Nasser</keyname><forenames>Youssef</forenames><affiliation>IETR</affiliation></author><author><keyname>H&#xe9;lard</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>IETR</affiliation></author><author><keyname>Crussi&#xe8;re</keyname><forenames>Matthieu</forenames><affiliation>IETR</affiliation></author></authors><title>Bit Error Rate Prediction of Coded MIMO-OFDM Systems</title><categories>cs.NI</categories><proxy>ccsd hal-00325497</proxy><journal-ref>IEEE Symposium on Signal Processing Advances in Wireless
  Communications, Recife : Br\'esil (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bit error rate (BER) prediction over channel realisations has emerged as an
active research area. In this paper, we give analytical signal to interference
and noise ratio (SINR) evaluation of MIMO-OFDM systems using an iterative
receiver. Using this analytical SINR expression, we propose an accurate BER
prediction method based on effective exponential SINR mapping (EESM) method. We
show by simulations that our method is independent of the channel realisation
and of the MIMO scheme. It is only dependent on the modulation and coding
scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5005</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5005</id><created>2008-09-29</created><authors><author><keyname>Xu</keyname><forenames>Yi-Chun</forenames></author><author><keyname>Xiao</keyname><forenames>Ren-Bin</forenames></author><author><keyname>Amos</keyname><forenames>Martyn</forenames></author></authors><title>Simulated annealing for weighted polygon packing</title><categories>cs.CG cs.AI</categories><comments>Submitted to Engineering Optimization. 13 pages, 7 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a new algorithm for a layout optimization problem:
this concerns the placement of weighted polygons inside a circular container,
the two objectives being to minimize imbalance of mass and to minimize the
radius of the container. This problem carries real practical significance in
industrial applications (such as the design of satellites), as well as being of
significant theoretical interest. Previous work has dealt with circular or
rectangular objects, but here we deal with the more realistic case where
objects may be represented as polygons and the polygons are allowed to rotate.
We present a solution based on simulated annealing and first test it on
instances with known optima. Our results show that the algorithm obtains
container radii that are close to optimal. We also compare our method with
existing algorithms for the (special) rectangular case. Experimental results
show that our approach out-performs these methods in terms of solution quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5008</identifier>
 <datestamp>2009-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5008</id><created>2008-09-29</created><updated>2009-12-23</updated><authors><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Weber</keyname><forenames>Steven</forenames></author></authors><title>Multi-Antenna Communication in Ad Hoc Networks: Achieving MIMO Gains
  with SIMO Transmission</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Communications. (Extended version of
  earlier conference paper)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The benefit of multi-antenna receivers is investigated in wireless ad hoc
networks, and the main finding is that network throughput can be made to scale
linearly with the number of receive antennas nR even if each transmitting node
uses only a single antenna. This is in contrast to a large body of prior work
in single-user, multiuser, and ad hoc wireless networks that have shown linear
scaling is achievable when multiple receive and transmit antennas (i.e., MIMO
transmission) are employed, but that throughput increases logarithmically or
sublinearly with nR when only a single transmit antenna (i.e., SIMO
transmission) is used. The linear gain is achieved by using the receive degrees
of freedom to simultaneously suppress interference and increase the power of
the desired signal, and exploiting the subsequent performance benefit to
increase the density of simultaneous transmissions instead of the transmission
rate. This result is proven in the transmission capacity framework, which
presumes single-hop transmissions in the presence of randomly located
interferers, but it is also illustrated that the result holds under several
relaxations of the model, including imperfect channel knowledge, multihop
transmission, and regular networks (i.e., interferers are deterministically
located on grids).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5009</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5009</id><created>2008-09-29</created><authors><author><keyname>Lee</keyname><forenames>Juyul</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author></authors><title>Delay Constrained Scheduling over Fading Channels: Optimal Policies for
  Monomial Energy-Cost Functions</title><categories>cs.IT math.IT</categories><comments>submitted to the IEEE ICC 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A point-to-point discrete-time scheduling problem of transmitting $B$
information bits within $T$ hard delay deadline slots is considered assuming
that the underlying energy-bit cost function is a convex monomial. The
scheduling objective is to minimize the expected energy expenditure while
satisfying the deadline constraint based on information about the unserved
bits, channel state/statistics, and the remaining time slots to the deadline.
At each time slot, the scheduling decision is made without knowledge of future
channel state, and thus there is a tension between serving many bits when the
current channel is good versus leaving too many bits for the deadline. Under
the assumption that no other packet is scheduled concurrently and no outage is
allowed, we derive the optimal scheduling policy. Furthermore, we also
investigate the dual problem of maximizing the number of transmitted bits over
$T$ time slots when subject to an energy constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5016</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5016</id><created>2008-09-29</created><authors><author><keyname>Nasser</keyname><forenames>Youssef</forenames><affiliation>IETR</affiliation></author><author><keyname>H&#xe9;lard</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>IETR</affiliation></author><author><keyname>Crussi&#xe8;re</keyname><forenames>Matthieu</forenames><affiliation>IETR</affiliation></author></authors><title>Robustness of MIMO-OFDM Schemes for Future Digital TV to Carrier
  Frequency Offset</title><categories>cs.NI</categories><proxy>ccsd hal-00325587</proxy><journal-ref>IEEE Broadband Multimedia Symposium, \'Etats-Unis d'Am\'erique
  (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the impact of carrier frequency offset (CFO) on the
performance of different MIMO-OFDM schemes with high spectral efficiency for
next generation of terrestrial digital TV. We show that all studied MIMO-OFDM
schemes are sensitive to CFO when it is greater than 1% of inter-carrier
spacing. We show also that the Alamouti scheme is the most sensitive MIMO
scheme to CFO
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5022</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5022</id><created>2008-09-29</created><authors><author><keyname>Sundararajan</keyname><forenames>Jay Kumar</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Barros</keyname><forenames>Joao</forenames></author></authors><title>Network coding meets TCP</title><categories>cs.NI cs.IT math.IT</categories><comments>9 pages, 9 figures, submitted to IEEE INFOCOM 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a mechanism that incorporates network coding into TCP with only
minor changes to the protocol stack, thereby allowing incremental deployment.
In our scheme, the source transmits random linear combinations of packets
currently in the congestion window. At the heart of our scheme is a new
interpretation of ACKs - the sink acknowledges every degree of freedom (i.e., a
linear combination that reveals one unit of new information) even if it does
not reveal an original packet immediately. Such ACKs enable a TCP-like
sliding-window approach to network coding. Our scheme has the nice property
that packet losses are essentially masked from the congestion control
algorithm. Our algorithm therefore reacts to packet drops in a smooth manner,
resulting in a novel and effective approach for congestion control over
networks involving lossy links such as wireless links. Our experiments show
that our algorithm achieves higher throughput compared to TCP in the presence
of lossy wireless links. We also establish the soundness and fairness
properties of our algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5023</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5023</id><created>2008-09-29</created><authors><author><keyname>Bordenave</keyname><forenames>Charles</forenames></author><author><keyname>McDonald</keyname><forenames>David</forenames></author><author><keyname>Proutiere</keyname><forenames>Alexandre</forenames></author></authors><title>Asymptotic stability region of slotted-Aloha</title><categories>cs.IT math.IT</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the stability of standard, buffered, slotted-Aloha systems.
Specifically, we consider a set of $N$ users, each equipped with an infinite
buffer. Packets arrive into user $i$'s buffer according to some stationary
ergodic Markovian process of intensity $\lambda_i$. At the beginning of each
slot, if user $i$ has packets in its buffer, it attempts to transmit a packet
with fixed probability $p_i$ over a shared resource / channel. The transmission
is successful only when no other user attempts to use the channel. The
stability of such systems has been open since their very first analysis in 1979
by Tsybakov and Mikhailov. In this paper, we propose an approximate stability
condition, that is provably exact when the number of users $N$ grows large. We
provide theoretical evidence and numerical experiments to explain why the
proposed approximate stability condition is extremely accurate even for systems
with a restricted number of users (even two or three). We finally extend the
results to the case of more efficient CSMA systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5087</identifier>
 <datestamp>2008-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5087</id><created>2008-09-29</created><authors><author><keyname>Chen</keyname><forenames>Yuhua</forenames></author><author><keyname>Kak</keyname><forenames>Subhash</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author></authors><title>Hybrid Neural Network Architecture for On-Line Learning</title><categories>cs.NE</categories><comments>19 pages, 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Approaches to machine intelligence based on brain models have stressed the
use of neural networks for generalization. Here we propose the use of a hybrid
neural network architecture that uses two kind of neural networks
simultaneously: (i) a surface learning agent that quickly adapt to new modes of
operation; and, (ii) a deep learning agent that is very accurate within a
specific regime of operation. The two networks of the hybrid architecture
perform complementary functions that improve the overall performance. The
performance of the hybrid architecture has been compared with that of
back-propagation perceptrons and the CC and FC networks for chaotic time-series
prediction, the CATS benchmark test, and smooth function approximation. It has
been shown that the hybrid architecture provides a superior performance based
on the RMS error criterion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5096</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5096</id><created>2008-09-29</created><updated>2009-02-02</updated><authors><author><keyname>Park</keyname><forenames>Hong Ju</forenames></author><author><keyname>Ayanoglu</keyname><forenames>Ender</forenames></author></authors><title>Diversity Analysis of Bit-Interleaved Coded Multiple Beamforming</title><categories>cs.IT math.IT</categories><comments>The maximum achievable diversity order from given convolutional code
  with any interleaver is shown by using the Singleton bound</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, diversity analysis of bit-interleaved coded multiple
beamforming (BICMB) is extended to the case of general spatial interleavers,
removing a condition on their previously known design criteria and quantifying
the resulting diversity order. The diversity order is determined by a parameter
Qmax which is inherited from the convolutional code and the spatial
de-multiplexer used in BICMB. We introduce a method to find this parameter by
employing a transfer function approach as in finding the weight spectrum of a
convolutional code. By using this method, several Qmax values are shown and
verified to be identical with the results from a computer search. The diversity
analysis and the method to find the parameter are supported by simulation
results. By using the Singleton bound, we also show that Qmax is lower bounded
by the product of the number of streams and the code rate of an encoder. The
design rule of the spatial de-multiplexer for a given convolutional code is
proposed to meet the condition on the maximum achievable diversity order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5145</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5145</id><created>2008-09-30</created><authors><author><keyname>Nasser</keyname><forenames>Youssef</forenames><affiliation>IETR</affiliation></author><author><keyname>H&#xe9;lard</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>IETR</affiliation></author><author><keyname>Crussi&#xe8;re</keyname><forenames>Matthieu</forenames><affiliation>IETR</affiliation></author></authors><title>3D MIMO Scheme for Broadcasting Future Digital TV in Single Frequency
  Networks</title><categories>cs.NI</categories><proxy>ccsd hal-00325605</proxy><journal-ref>Electronics Letters / IEE Electronics Letters 44, 13 (2008)
  829-830</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter introduces a 3D space-time-space block code for future digital TV
systems. The code is based on a double layer structure for inter-cell and
intra-cell transmission mode in single frequency networks. Without increasing
the complexity of the receiver, the proposed code is very efficient for
different transmission scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5153</identifier>
 <datestamp>2008-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5153</id><created>2008-09-30</created><authors><author><keyname>Kounchev</keyname><forenames>Ognyan</forenames></author><author><keyname>Render</keyname><forenames>Hermann</forenames></author></authors><title>On a new multivariate sampling paradigm and a polyspline Shannon
  function</title><categories>math.NA cs.IT math.IT</categories><comments>Submitted to the conference proceedings of SAMPTA07 held in
  Thessaloniki, Greece, 2007</comments><msc-class>32A50, 60G35, 68U10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the monograph Kounchev, O. I., Multivariate Polysplines. Applications to
Numerical and Wavelet Analysis, Academic Press, San Diego-London, 2001, and in
the paper Kounchev O., Render, H., Cardinal interpolation with polysplines on
annuli, Journal of Approximation Theory 137 (2005) 89--107, we have introduced
and studied a new paradigm for cardinal interpolation which is related to the
theory of multivariate polysplines. In the present paper we show that this is
related to a new sampling paradigm in the multivariate case, whereas we obtain
a Shannon type function $S(x) $ and the following Shannon type formula:
$f(r\theta) =\sum_{j=-\infty}^{\infty}\int_{\QTR{Bbb}{S}^{n-1}}S(e^{-j}r\theta
) f(e^{j}\theta) d\theta .$ This formula relies upon infinitely many Shannon
type formulas for the exponential splines arising from the radial part of the
polyharmonic operator $\Delta ^{p}$ for fixed $p\geq 1$. Acknowledgement. The
first and the second author have been partially supported by the Institutes
partnership project with the Alexander von Humboldt Foundation. The first has
been partially sponsored by the Greek-Bulgarian bilateral project BGr-17, and
the second author by Grant MTM2006-13000-C03-03 of the D.G.I. of Spain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5154</identifier>
 <datestamp>2008-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5154</id><created>2008-09-30</created><authors><author><keyname>Mik&#xe1;c</keyname><forenames>Jan</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG Laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Roisin</keyname><forenames>C&#xe9;cile</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG Laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Duc</keyname><forenames>Bao Le</forenames><affiliation>UPMC</affiliation></author></authors><title>An Export Architecture for a Multimedia Authoring Environment</title><categories>cs.MM</categories><proxy>ccsd inria-00325692</proxy><journal-ref>Dans DocEng'08 (2008) 28-31</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an export architecture that provides a clear
separation of authoring services from publication services. We illustrate this
architecture with the LimSee3 authoring tool and several standard publication
formats: Timesheets, SMIL, and XHTML.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5173</identifier>
 <datestamp>2009-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5173</id><created>2008-09-30</created><updated>2009-10-22</updated><authors><author><keyname>Goze</keyname><forenames>Nicolas</forenames></author><author><keyname>Remm</keyname><forenames>Elisabeth</forenames></author></authors><title>An algebraic approach to the set of intervals (a new approach of
  arithmetic of intervals)</title><categories>cs.NA</categories><acm-class>G.1.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present the set of intervals as a normed vector space. We
define also a four-dimensional associative algebra whose product gives the
product of intervals in any cases. This approach allows to give a notion of
divisibility and in some cases an euclidian division. We introduce differential
calculus and give some applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5182</identifier>
 <datestamp>2008-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5182</id><created>2008-09-30</created><authors><author><keyname>Fertl</keyname><forenames>Peter</forenames></author><author><keyname>Hottinen</keyname><forenames>Ari</forenames></author><author><keyname>Matz</keyname><forenames>Gerald</forenames></author></authors><title>Perturbation-based Distributed Beamforming for Wireless Relay Networks</title><categories>cs.IT math.IT</categories><comments>5 pages, 5 figures; accepted at IEEE GLOBECOM 2008, New Orleans, LA,
  Nov 30 - Dec 4, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with distributed beamforming techniques for wireless
networks with half-duplex amplify-and-forward relays. Existing schemes optimize
the beamforming weights based on the assumption that channel state information
(CSI) is available at the relays. We propose to use adaptive beamforming based
on deterministic perturbations and limited feedback (1-bit) from the
destination to the relays in order to avoid CSI at the relays. Two scalable
perturbation schemes are considered and practical implementation aspects are
addressed. Simulation results confirm that the proposed techniques closely
approach optimum performance and have satisfactory tracking properties in
time-varying environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5188</identifier>
 <datestamp>2008-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5188</id><created>2008-09-30</created><authors><author><keyname>Liu</keyname><forenames>Ming</forenames><affiliation>IETR</affiliation></author><author><keyname>Crussi&#xe8;re</keyname><forenames>Matthieu</forenames><affiliation>IETR</affiliation></author><author><keyname>H&#xe9;lard</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>IETR</affiliation></author><author><keyname>Pasquero</keyname><forenames>Oudomsack</forenames><affiliation>IETR</affiliation></author></authors><title>Analysis and Performance Comparison of DVB-T and DTMB Systems for
  Terrestrial Digital TV</title><categories>cs.NI</categories><proxy>ccsd hal-00325824</proxy><journal-ref>IEEE International Conference on Communications Systems (ICCS
  2008), Guangzhou : Chine (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Orthogonal frequency-division multiplexing (OFDM) is the most popular
transmission technology in digital terrestrial broadcasting (DTTB), adopted by
many DTTB standards. In this paper, the bit error rate (BER) performance of two
DTTB systems, namely cyclic prefix OFDM (CP-OFDM) based DVB-T and time domain
synchronous OFDM (TDS-OFDM) based DTMB, is evaluated in different channel
conditions. Spectrum utilization and power efficiency are also discussed to
demonstrate the transmission overhead of both systems. Simulation results show
that the performances of the two systems are much close. Given the same ratio
of guard interval (GI), the DVB-T outperforms DTMB in terms of signal to noise
ratio (SNR) in Gaussian and Ricean channels, while DTMB behaves better
performance in Rayleigh channel in higher code rates and higher orders of
constellation thanks to its efficient channel coding and interleaving scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5189</identifier>
 <datestamp>2008-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5189</id><created>2008-09-30</created><authors><author><keyname>Pasquero</keyname><forenames>Oudomsack Pierre</forenames><affiliation>IETR</affiliation></author><author><keyname>Crussi&#xe8;re</keyname><forenames>Matthieu</forenames><affiliation>IETR</affiliation></author><author><keyname>Nasser</keyname><forenames>Youssef</forenames><affiliation>IETR</affiliation></author><author><keyname>H&#xe9;lard</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>IETR</affiliation></author></authors><title>A novel channel estimation based on spread pilots for terrestrial
  digital video broadcasting</title><categories>cs.NI</categories><proxy>ccsd hal-00325758</proxy><journal-ref>Broadband Multimedia Systems and Broadcasting, Las Vegas :
  \'Etats-Unis d'Am\'erique (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel channel estimation technique based on
spread pilots for digital video broadcasting. This technique consists in adding
a linear preceding function before the OFDM modulation and dedicating one of
the preceding sequence to transmit the pilot symbols for the channel
estimation. The merits of this technique are its simplicity, its flexibility,
and the gains in terms of spectral efficiency and useful bit rate obtained
compared to the classical pilot based estimation schemes used in DVB standards.
The performance evaluated over realistic channel models, shows the efficiency
of this technique which turns out to be a promising channel estimation
technique for the future terrestrial video broadcasting systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5191</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5191</id><created>2008-09-30</created><authors><author><keyname>Muhammad</keyname><forenames>Fahad Syed</forenames><affiliation>IETR</affiliation></author><author><keyname>Baudais</keyname><forenames>Jean-Yves</forenames><affiliation>IETR</affiliation></author><author><keyname>H&#xe9;lard</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>IETR</affiliation></author><author><keyname>Crussi&#xe8;re</keyname><forenames>Matthieu</forenames><affiliation>IETR</affiliation></author></authors><title>A Coded Bit-Loading Linear Precoded Discrete Multitone Solution for
  Power Line Communication</title><categories>cs.IT math.IT</categories><proxy>ccsd hal-00325790</proxy><journal-ref>International Workshop on Signal Processing Advances in Wireless
  Communications, Recife, Pernambuco : Brazil (2008)</journal-ref><doi>10.1109/SPAWC.2008.4641669</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear precoded discrete multitone modulation (LP-DMT) system has been
already proved advantageous with adaptive resource allocation algorithm in a
power line communication (PLC) context. In this paper, we investigate the bit
and energy allocation algorithm of an adaptive LP-DMT system taking into
account the channel coding scheme. A coded adaptive LP-DMT system is presented
in the PLC context with a loading algorithm which ccommodates the channel
coding gains in bit and energy calculations. The performance of a concatenated
channel coding scheme, consisting of an inner Wei's 4-dimensional 16-states
trellis code and an outer Reed-Solomon code, in combination with the roposed
algorithm is analyzed. Simulation results are presented for a fixed target bit
error rate in a multicarrier scenario under power spectral density constraint.
Using a multipath model of PLC channel, it is shown that the proposed coded
adaptive LP-DMT system performs better than classical coded discrete multitone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5192</identifier>
 <datestamp>2008-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5192</id><created>2008-09-30</created><authors><author><keyname>Pasquero</keyname><forenames>Oudomsack Pierre</forenames><affiliation>IETR</affiliation></author><author><keyname>Crussi&#xe8;re</keyname><forenames>Matthieu</forenames><affiliation>IETR</affiliation></author><author><keyname>Nasser</keyname><forenames>Youssef</forenames><affiliation>IETR</affiliation></author><author><keyname>H&#xe9;lard</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>IETR</affiliation></author></authors><title>2D Linear Precoded OFDM for future mobile Digital Video Broadcasting</title><categories>cs.NI</categories><proxy>ccsd hal-00325766</proxy><journal-ref>Signal Processing Advances in Wireless Communications, Recife :
  Br\'esil (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel channel estimation technique based on 2D
spread pilots. The merits of this technique are its simplicity, its flexibility
regarding the transmission scenarios, and the spectral efficiency gain obtained
compared to the classical pilot based estimation schemes used in DVB standards.
We derive the analytical expression of the mean square error of the estimator
and show it is a function of the autocorrelation of the channel in both time
and frequency domains. The performance evaluated over a realistic channel model
shows the efficiency of this technique which turns out to be a promising
channel estimation for the future mobile video broadcasting systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5204</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5204</id><created>2008-09-30</created><updated>2009-11-03</updated><authors><author><keyname>B&#xf6;cherer</keyname><forenames>Georg</forenames></author><author><keyname>de Baynast</keyname><forenames>Alexandre</forenames></author></authors><title>A Distributed MAC Protocol for Cooperation in Random Access Networks</title><categories>cs.IT math.IT</categories><comments>5 pages, improved presentation compared to previous version v1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  WLAN is one of the most successful applications of wireless communications in
daily life because of low cost and ease of deployment. The enabling technique
for this success is the use of random access schemes for the wireless channel.
Random access requires minimal coordination between the nodes, which
considerably reduces the cost of the infrastructure. Recently, cooperative
communication in wireless networks has been of increasing interest because it
promises higher rates and reliability. An additional MAC overhead is necessary
to coordinate the nodes to allow cooperation and this overhead can possibly
cancel out the cooperative benefits. In this work, a completely distributed
protocol is proposed that allows nodes in the network to cooperate via Two-Hop
and Decode-and-Forward for transmitting their data to a common gateway node. It
is shown that high throughput gains are obtained in terms of the individual
throughput that can be guaranteed to any node in the network. These results are
validated by Monte Carlo simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5212</identifier>
 <datestamp>2008-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5212</id><created>2008-09-30</created><authors><author><keyname>Jeon</keyname><forenames>Hyoungsuk</forenames></author><author><keyname>Kim</keyname><forenames>Namshik</forenames></author><author><keyname>Kim</keyname><forenames>Minki</forenames></author><author><keyname>Lee</keyname><forenames>Hyuckjae</forenames></author><author><keyname>Ha</keyname><forenames>Jeongseok</forenames></author></authors><title>Secrecy Capacity over Correlated Ergodic Fading Channel</title><categories>cs.IT math.IT</categories><comments>18 pages, 5 figures, submitted to IEEE Transaction on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the secrecy capacity of an ergodic fading wiretap channel in
which the main channel is correlated with the eavesdropper channel. In this
study, the full Channel State Information (CSI) is assumed, and thus the
transmitter knows the channel gains of the legitimate receiver and the
eavesdropper. By analyzing the resulting secrecy capacity we quantify the loss
of the secrecy capacity due to the correlation. In addition, we study the
asymptotic behavior of the secrecy capacity as Signal-to-Noise Ratio (SNR)
tends to infinity. The capacity of an ordinary fading channel logarithmically
increases with SNR. On the contrary, the secrecy capacity converges into a
limit which can be an upper bound on the secrecy capacity over the fading
wiretap channel. We find a closed form of the upper bound for the correlated
Rayleigh wiretap channel which also includes the independent case as a special
one. Our work shows that the upper bound is determined by only two channel
parameters; the correlation coefficient and the ratio of the main to the
eavesdropper channel gains that will be called PCC and CGR respectively. The
analysis of the upper bound tells how the two channel parameters affect the
secrecy capacity and leads to the conclusion that the excessively large signal
power does not provide any advantage in the secrecy capacity, and the loss due
to the correlation is especially serious in low CGR regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5217</identifier>
 <datestamp>2008-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5217</id><created>2008-09-30</created><authors><author><keyname>Abbe</keyname><forenames>Emmanuel</forenames></author><author><keyname>Zheng</keyname><forenames>Lizhong</forenames></author></authors><title>Linear Universal Decoding for Compound Channels: a Local to Global
  Geometric Approach</title><categories>cs.IT math.IT math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over discrete memoryless channels (DMC), linear decoders (maximizing additive
metrics) afford several nice properties. In particular, if suitable encoders
are employed, the use of decoding algorithm with manageable complexities is
permitted. Maximum likelihood is an example of linear decoder. For a compound
DMC, decoders that perform well without the channel's knowledge are required in
order to achieve capacity. Several such decoders have been studied in the
literature. However, there is no such known decoder which is linear. Hence, the
problem of finding linear decoders achieving capacity for compound DMC is
addressed, and it is shown that under minor concessions, such decoders exist
and can be constructed. This paper also develops a &quot;local geometric analysis&quot;,
which allows in particular, to solve the above problem. By considering very
noisy channels, the original problem is reduced, in the limit, to an inner
product space problem, for which insightful solutions can be found. The local
setting can then provide counterexamples to disproof claims, but also, it is
shown how in this problem, results proven locally can be &quot;lifted&quot; to results
proven globally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5238</identifier>
 <datestamp>2008-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5238</id><created>2008-09-30</created><authors><author><keyname>N&#xe9;lis</keyname><forenames>Vincent</forenames></author><author><keyname>Goossens</keyname><forenames>Jo&#xeb;l</forenames></author></authors><title>Mode Change Protocol for Multi-Mode Real-Time Systems upon Identical
  Multiprocessors</title><categories>cs.OS</categories><comments>4 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a synchronous protocol without periodicity for
scheduling multi-mode real-time systems upon identical multiprocessor
platforms. Our proposal can be considered to be a multiprocessor extension of
the uniprocessor protocol called &quot;Minimal Single Offset protocol&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5250</identifier>
 <datestamp>2008-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5250</id><created>2008-09-30</created><authors><author><keyname>Lariviere</keyname><forenames>Vincent</forenames></author><author><keyname>Gingras</keyname><forenames>Yves</forenames></author><author><keyname>Archambault</keyname><forenames>Eric</forenames></author></authors><title>The decline in the concentration of citations, 1900-2007</title><categories>physics.soc-ph cs.DL</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper challenges recent research (Evans, 2008) reporting that the
concentration of cited scientific literature increases with the online
availability of articles and journals. Using Thomson Reuters' Web of Science,
the present paper analyses changes in the concentration of citations received
(two- and five-year citation windows) by papers published between 1900 and
2005. Three measures of concentration are used: the percentage of papers that
received at least one citation (cited papers); the percentage of papers needed
to account for 20, 50 and 80 percent of the citations; and, the
Herfindahl-Hirschman index. These measures are used for four broad disciplines:
natural sciences and engineering, medical fields, social sciences, and the
humanities. All these measures converge and show that, contrary to what was
reported by Evans, the dispersion of citations is actually increasing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5266</identifier>
 <datestamp>2008-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5266</id><created>2008-09-30</created><authors><author><keyname>Gowadia</keyname><forenames>Vaibhav</forenames></author><author><keyname>Farkas</keyname><forenames>Csilla</forenames></author><author><keyname>Kudo</keyname><forenames>Michiharu</forenames></author></authors><title>Checking Security Policy Compliance</title><categories>cs.CR</categories><comments>23 pages; submitted to TKDE; original submission 15 mar 2007; revised
  20 jan 2008</comments><acm-class>H.1.1; H.2.0.a; I.2.2.e; I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ensuring compliance of organizations to federal regulations is a growing
concern. This paper presents a framework and methods to verify whether an
implemented low-level security policy is compliant to a high-level security
policy. Our compliance checking framework is based on organizational and
security metadata to support refinement of high-level concepts to
implementation specific instances. Our work uses the results of refinement
calculus to express valid refinement patterns and their properties.
Intuitively, a low-level security policy is compliant to a high-level security
policy if there is a valid refinement path from the high-level security policy
to the low-level security policy. Our model is capable of detecting violations
of security policies, failures to meet obligations, and capability and modal
conflicts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5275</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5275</id><created>2008-09-30</created><authors><author><keyname>Muhammad</keyname><forenames>Fahad Syed</forenames><affiliation>IETR</affiliation></author><author><keyname>Baudais</keyname><forenames>Jean-Yves</forenames><affiliation>IETR</affiliation></author><author><keyname>H&#xe9;lard</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>IETR</affiliation></author><author><keyname>Crussi&#xe8;re</keyname><forenames>Matthieu</forenames><affiliation>IETR</affiliation></author></authors><title>Coded Adaptive Linear Precoded Discrete Multitone Over PLC Channel</title><categories>cs.IT math.IT</categories><proxy>ccsd hal-00325789</proxy><journal-ref>International Symposium on Power-Line Communications and Its
  Applications, Jeju Island : Cor\'ee, R\'epublique de (2008)</journal-ref><doi>10.1109/ISPLC.2008.4510410</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discrete multitone modulation (DMT) systems exploit the capabilities of
orthogonal subcarriers to cope efficiently with narrowband interference, high
frequency attenuations and multipath fadings with the help of simple
equalization filters. Adaptive linear precoded discrete multitone (LP-DMT)
system is based on classical DMT, combined with a linear precoding component.
In this paper, we investigate the bit and energy allocation algorithm of an
adaptive LP-DMT system taking into account the channel coding scheme. A coded
adaptive LPDMT system is presented in the power line communication (PLC)
context with a loading algorithm which accommodates the channel coding gains in
bit and energy calculations. The performance of a concatenated channel coding
scheme, consisting of an inner Wei's 4-dimensional 16-states trellis code and
an outer Reed-Solomon code, in combination with the proposed algorithm is
analyzed. Theoretical coding gains are derived and simulation results are
presented for a fixed target bit error rate in a multicarrier scenario under
power spectral density constraint. Using a multipath model of PLC channel, it
is shown that the proposed coded adaptive LP-DMT system performs better than
coded DMT and can achieve higher throughput for PLC applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0033</identifier>
 <datestamp>2009-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0033</id><created>2008-09-30</created><updated>2009-06-16</updated><authors><author><keyname>Freedman</keyname><forenames>M.</forenames></author></authors><title>Complexity Classes as Mathematical Axioms</title><categories>cs.CC math.GT</categories><comments>Some minor changes and one more reference. To appear in Ann. Math</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Treating a conjecture, P^#P != NP, on the separation of complexity classes as
an axiom, an implication is found in three manifold topology with little
obvious connection to complexity theory. This is reminiscent of Harvey
Friedman's work on finitistic interpretations of large cardinal axioms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0052</identifier>
 <datestamp>2009-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0052</id><created>2008-09-30</created><updated>2009-02-05</updated><authors><author><keyname>Fischer</keyname><forenames>Matthias</forenames></author><author><keyname>Hilbig</keyname><forenames>Matthias</forenames></author><author><keyname>J&#xe4;hn</keyname><forenames>Claudius</forenames></author><author><keyname>der Heide</keyname><forenames>Friedhelm Meyer auf</forenames></author><author><keyname>Ziegler</keyname><forenames>Martin</forenames></author></authors><title>Planar Visibility Counting</title><categories>cs.CG cs.DS</categories><comments>added Section 4: Implementation and Empirical Evaluation</comments><acm-class>I.3.5; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a fixed virtual scene (=collection of simplices) S and given observer
position p, how many elements of S are weakly visible (i.e. not fully occluded
by others) from p? The present work explores the trade-off between query time
and preprocessing space for these quantities in 2D: exactly, in the approximate
deterministic, and in the probabilistic sense. We deduce the EXISTENCE of an
O(m^2/n^2) space data structure for S that, given p and time O(log n), allows
to approximate the ratio of occluded segments up to arbitrary constant absolute
error; here m denotes the size of the Visibility Graph--which may be quadratic,
but typically is just linear in the size n of the scene S. On the other hand,
we present a data structure CONSTRUCTIBLE in O(n*log(n)+m^2*polylog(n)/k)
preprocessing time and space with similar approximation properties and query
time O(k*polylog n), where k&lt;n is an arbitrary parameter. We describe an
implementation of this approach and demonstrate the practical benefit of the
parameter k to trade memory for query time in an empirical evaluation on three
classes of benchmark scenes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0068</identifier>
 <datestamp>2008-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0068</id><created>2008-09-30</created><authors><author><keyname>Rouayheb</keyname><forenames>Salim Y. El</forenames></author><author><keyname>Sprintson</keyname><forenames>Alex</forenames></author><author><keyname>Georghiades</keyname><forenames>Costas N.</forenames></author></authors><title>On the Index Coding Problem and its Relation to Network Coding and
  Matroid Theory</title><categories>cs.IT math.IT</categories><comments>submitted to transactions on information theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The \emph{index coding} problem has recently attracted a significant
attention from the research community due to its theoretical significance and
applications in wireless ad-hoc networks. An instance of the index coding
problem includes a sender that holds a set of information messages
$X=\{x_1,...,x_k\}$ and a set of receivers $R$. Each receiver $\rho=(x,H)\in R$
needs to obtain a message $x\in X$ and has prior \emph{side information}
comprising a subset $H$ of $X$. The sender uses a noiseless communication
channel to broadcast encoding of messages in $X$ to all clients. The objective
is to find an encoding scheme that minimizes the number of transmissions
required to satisfy the receivers' demands with \emph{zero error}.
  In this paper, we analyze the relation between the index coding problem, the
more general network coding problem and the problem of finding a linear
representation of a matroid. In particular, we show that any instance of the
network coding and matroid representation problems can be efficiently reduced
to an instance of the index coding problem. Our reduction implies that many
important properties of the network coding and matroid representation problems
carry over to the index coding problem. Specifically, we show that \emph{vector
linear codes} outperform scalar linear codes and that vector linear codes are
insufficient for achieving the optimum number of transmissions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0075</identifier>
 <datestamp>2008-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0075</id><created>2008-10-01</created><authors><author><keyname>Salas</keyname><forenames>Alvaro</forenames><affiliation>Universidad de Caldas, Universidad Nacional de Colombia, sede Manizales</affiliation></author></authors><title>Acerca del Algoritmo de Dijkstra</title><categories>cs.DS</categories><comments>In spanish, the paper contains illustrations</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we prove the correctness of Dijkstra's algorithm. We also
discuss it and at the end we show an application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0135</identifier>
 <datestamp>2008-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0135</id><created>2008-10-01</created><authors><author><keyname>Alanyali</keyname><forenames>Murat</forenames></author><author><keyname>Dashouk</keyname><forenames>Maxim</forenames></author></authors><title>Occupancy distributions of homogeneous queueing systems under
  opportunistic scheduling</title><categories>cs.PF cs.NI</categories><comments>Submitted for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze opportunistic schemes for transmission scheduling from one of $n$
homogeneous queues whose channel states fluctuate independently. Considered
schemes consist of the LCQ policy, which transmits from a longest connected
queue in the entire system, and its low-complexity variants that transmit from
a longest queue within a randomly chosen subset of connected queues. A
Markovian model is studied where mean packet transmission time is $n^{-1}$ and
packet arrival rate is $\lambda&lt;1$ per queue. Transient and equilibrium
distributions of queue occupancies are obtained in the limit as the system size
$n$ tends to infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0139</identifier>
 <datestamp>2008-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0139</id><created>2008-10-01</created><authors><author><keyname>Wong</keyname><forenames>Wilson</forenames></author><author><keyname>Liu</keyname><forenames>Wei</forenames></author><author><keyname>Bennamoun</keyname><forenames>Mohammed</forenames></author></authors><title>Determining the Unithood of Word Sequences using a Probabilistic
  Approach</title><categories>cs.AI</categories><comments>More information is available at
  http://explorer.csse.uwa.edu.au/reference/</comments><journal-ref>3rd International Joint Conference on Natural Language Processing
  (IJCNLP), 2008, pages 103-110</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most research related to unithood were conducted as part of a larger effort
for the determination of termhood. Consequently, novelties are rare in this
small sub-field of term extraction. In addition, existing work were mostly
empirically motivated and derived. We propose a new probabilistically-derived
measure, independent of any influences of termhood, that provides dedicated
measures to gather linguistic evidence from parsed text and statistical
evidence from Google search engine for the measurement of unithood. Our
comparative study using 1,825 test cases against an existing
empirically-derived function revealed an improvement in terms of precision,
recall and accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0154</identifier>
 <datestamp>2008-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0154</id><created>2008-10-01</created><authors><author><keyname>Kitagawa</keyname><forenames>Koichiro</forenames></author><author><keyname>Tanaka</keyname><forenames>Toshiyuki</forenames></author></authors><title>Optimization of sequences in CDMA systems: a statistical-mechanics
  approach</title><categories>cs.IT math.IT</categories><comments>17pages, submitted to Special Issue on Interdisciplinary Paradigms
  for Networking in International Journal of Computer and Telecommunications
  Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statistical mechanics approach is useful not only in analyzing macroscopic
system performance of wireless communication systems, but also in discussing
design problems of wireless communication systems. In this paper, we discuss a
design problem of spreading sequences in code-division multiple-access (CDMA)
systems, as an example demonstrating the usefulness of statistical mechanics
approach. We analyze, via replica method, the average mutual information
between inputs and outputs of a randomly-spread CDMA channel, and discuss the
optimization problem with the average mutual information as a measure of
optimization. It has been shown that the average mutual information is
maximized by orthogonally-invariant random Welch bound equality (WBE) spreading
sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0156</identifier>
 <datestamp>2008-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0156</id><created>2008-10-01</created><authors><author><keyname>Wong</keyname><forenames>Wilson</forenames></author><author><keyname>Liu</keyname><forenames>Wei</forenames></author><author><keyname>Bennamoun</keyname><forenames>Mohammed</forenames></author></authors><title>Determining the Unithood of Word Sequences using Mutual Information and
  Independence Measure</title><categories>cs.AI</categories><comments>More information is available at
  http://explorer.csse.uwa.edu.au/reference/</comments><report-no>CSSE-WWONG-13</report-no><journal-ref>10th Conference of the Pacific Association for Computational
  Linguistics (PACLING), 2007, pages 246-254</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Most works related to unithood were conducted as part of a larger effort for
the determination of termhood. Consequently, the number of independent research
that study the notion of unithood and produce dedicated techniques for
measuring unithood is extremely small. We propose a new approach, independent
of any influences of termhood, that provides dedicated measures to gather
linguistic evidence from parsed text and statistical evidence from Google
search engine for the measurement of unithood. Our evaluations revealed a
precision and recall of 98.68% and 91.82% respectively with an accuracy at
95.42% in measuring the unithood of 1005 test cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0200</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0200</id><created>2008-10-01</created><authors><author><keyname>Rovenchak</keyname><forenames>Andrij</forenames></author><author><keyname>Ma&#x10d;utek</keyname><forenames>J&#xe1;n</forenames></author><author><keyname>Riley</keyname><forenames>Charles</forenames></author></authors><title>Distribution of complexities in the Vai script</title><categories>cs.CL</categories><comments>13 pages</comments><journal-ref>Glottometrics 18, 1-12 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the paper, we analyze the distribution of complexities in the Vai script,
an indigenous syllabic writing system from Liberia. It is found that the
uniformity hypothesis for complexities fails for this script. The models using
Poisson distribution for the number of components and hyper-Poisson
distribution for connections provide good fits in the case of the Vai script.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0264</identifier>
 <datestamp>2008-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0264</id><created>2008-10-01</created><authors><author><keyname>Musser</keyname><forenames>David R.</forenames></author><author><keyname>Nishanov</keyname><forenames>Gor V.</forenames></author></authors><title>A Fast Generic Sequence Matching Algorithm</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A string matching -- and more generally, sequence matching -- algorithm is
presented that has a linear worst-case computing time bound, a low worst-case
bound on the number of comparisons (2n), and sublinear average-case behavior
that is better than that of the fastest versions of the Boyer-Moore algorithm.
The algorithm retains its efficiency advantages in a wide variety of sequence
matching problems of practical interest, including traditional string matching;
large-alphabet problems (as in Unicode strings); and small-alphabet,
long-pattern problems (as in DNA searches). Since it is expressed as a generic
algorithm for searching in sequences over an arbitrary type T, it is well
suited for use in generic software libraries such as the C++ Standard Template
Library. The algorithm was obtained by adding to the Knuth-Morris-Pratt
algorithm one of the pattern-shifting techniques from the Boyer-Moore
algorithm, with provision for use of hashing in this technique. In situations
in which a hash function or random access to the sequences is not available,
the algorithm falls back to an optimized version of the Knuth-Morris-Pratt
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0322</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0322</id><created>2008-10-01</created><updated>2009-06-18</updated><authors><author><keyname>Nakshatrala</keyname><forenames>K. B.</forenames></author><author><keyname>Valocchi</keyname><forenames>A. J.</forenames></author></authors><title>Non-negative mixed finite element formulations for a tensorial diffusion
  equation</title><categories>cs.NA</categories><comments>40 pages using amsart style file, and 15 figures</comments><doi>10.1016/j.jcp.2009.05.039</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the tensorial diffusion equation, and address the discrete
maximum-minimum principle of mixed finite element formulations. In particular,
we address non-negative solutions (which is a special case of the
maximum-minimum principle) of mixed finite element formulations. The discrete
maximum-minimum principle is the discrete version of the maximum-minimum
principle.
  In this paper we present two non-negative mixed finite element formulations
for tensorial diffusion equations based on constrained optimization techniques
(in particular, quadratic programming). These proposed mixed formulations
produce non-negative numerical solutions on arbitrary meshes for low-order
(i.e., linear, bilinear and trilinear) finite elements. The first formulation
is based on the Raviart-Thomas spaces, and is obtained by adding a non-negative
constraint to the variational statement of the Raviart-Thomas formulation. The
second non-negative formulation based on the variational multiscale
formulation.
  For the former formulation we comment on the affect of adding the
non-negative constraint on the local mass balance property of the
Raviart-Thomas formulation. We also study the performance of the active set
strategy for solving the resulting constrained optimization problems. The
overall performance of the proposed formulation is illustrated on three
canonical test problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0326</identifier>
 <datestamp>2008-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0326</id><created>2008-10-01</created><updated>2008-10-03</updated><authors><author><keyname>Lu</keyname><forenames>Lu</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author><author><keyname>Zhang</keyname><forenames>Shengli</forenames></author></authors><title>Collision Resolution by Exploiting Symbol Misalignment</title><categories>cs.NI cs.IT math.IT</categories><comments>conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents CRESM, a novel collision resolution method for decoding
collided packets in random-access wireless networks. In a collision,
overlapping signals from several sources are received simultaneously at a
receiver. CRESM exploits symbol misalignment among the overlapping signals to
recover the individual packets. CRESM can be adopted in 802.11 networks without
modification of the transmitter design; only a simple DSP technique is needed
at the receiver to decode the overlapping signals. Our simulations indicate
that CRESM has better BER performance than the simplistic Successive
Interference Cancellation (SIC) technique that treats interference as noise,
for almost all SNR regimes. The implication of CRESM for random-access
networking is significant: in general, using CRESM to resolve collisions of up
to n packets, network throughput can be boosted by more than n times if the
transmitters are allowed to transmit more aggressively in the MAC protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0328</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0328</id><created>2008-10-01</created><updated>2011-12-26</updated><authors><author><keyname>Chan</keyname><forenames>Aldar C-F.</forenames></author></authors><title>Efficient Defence against Misbehaving TCP Receiver DoS Attacks</title><categories>cs.CR cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The congestion control algorithm of TCP relies on correct feedback from the
receiver to determine the rate at which packets should be sent into the
network. Hence, correct receiver feedback (in the form of TCP acknowledgements)
is essential to the goal of sharing the scarce bandwidth resources fairly and
avoiding congestion collapse in the Internet. However, the assumption that a
TCP receiver can always be trusted (to generate feedback correctly) no longer
holds as there are plenty of incentives for a receiver to deviate from the
protocol. In fact, it has been shown that a misbehaving receiver (whose aim is
to bring about congestion collapse) can easily generate acknowledgements to
conceal packet loss, so as to drive a number of honest, innocent senders
arbitrarily fast to create a significant number of non-responsive packet flows,
leading to denial of service to other Internet users. We give the first formal
treatment to this problem. We also give an efficient, provably secure mechanism
to force a receiver to generate feedback correctly; any incorrect
acknowledgement will be detected at the sender and cheating TCP receivers would
be identified. The idea is as follows: for each packet sent, the sender
generates a tag using a secret key (known to himself only); the receiver could
generate a proof using the packet and the tag alone, and send it to the sender;
the sender can then verify the proof using the secret key; an incorrect proof
would indicate a cheating receiver. The scheme is very efficient in the sense
that the TCP sender does not need to store the packet or the tag, and the
proofs for multiple packets can be aggregated at the receiver. The scheme is
based on an aggregate authenticator. In addition, the proposed solution can be
applied to network-layer rate-limiting architectures requiring correct
feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0332</identifier>
 <datestamp>2008-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0332</id><created>2008-10-01</created><authors><author><keyname>Wong</keyname><forenames>Wilson</forenames></author><author><keyname>Liu</keyname><forenames>Wei</forenames></author><author><keyname>Bennamoun</keyname><forenames>Mohammed</forenames></author></authors><title>Enhanced Integrated Scoring for Cleaning Dirty Texts</title><categories>cs.AI</categories><comments>More information is available at
  http://explorer.csse.uwa.edu.au/reference/</comments><journal-ref>IJCAI Workshop on Analytics for Noisy Unstructured Text Data
  (AND), 2007, pages 55-62</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An increasing number of approaches for ontology engineering from text are
gearing towards the use of online sources such as company intranet and the
World Wide Web. Despite such rise, not much work can be found in aspects of
preprocessing and cleaning dirty texts from online sources. This paper presents
an enhancement of an Integrated Scoring for Spelling error correction,
Abbreviation expansion and Case restoration (ISSAC). ISSAC is implemented as
part of a text preprocessing phase in an ontology engineering system. New
evaluations performed on the enhanced ISSAC using 700 chat records reveal an
improved accuracy of 98% as compared to 96.5% and 71% based on the use of only
basic ISSAC and of Aspell, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0372</identifier>
 <datestamp>2008-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0372</id><created>2008-10-02</created><authors><author><keyname>Cabecinhas</keyname><forenames>Filipe</forenames></author><author><keyname>Lopes</keyname><forenames>Nuno</forenames></author><author><keyname>Crisostomo</keyname><forenames>Renato</forenames></author><author><keyname>Veiga</keyname><forenames>Luis</forenames></author></authors><title>Optimizing Binary Code Produced by Valgrind (Project Report on Virtual
  Execution Environments Course - AVExe)</title><categories>cs.PL cs.OS</categories><comments>Technical report from INESC-ID Lisboa describing optimizations to
  code generation of the Valgring execution environment. Work developed in the
  context of a Virtual Execution Environments course (AVExe) at IST/Technical
  university of Lisbon</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Valgrind is a widely used framework for dynamic binary instrumentation and
its mostly known by its memcheck tool. Valgrind's code generation module is far
from producing optimal code. In addition it has many backends for different CPU
architectures, which difficults code optimization in an architecture
independent way. Our work focused on identifying sub-optimal code produced by
Valgrind and optimizing it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0394</identifier>
 <datestamp>2008-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0394</id><created>2008-10-02</created><authors><author><keyname>Fulop</keyname><forenames>Peter</forenames></author><author><keyname>Kovacs</keyname><forenames>Benedek</forenames></author><author><keyname>Imre</keyname><forenames>Sandor</forenames></author></authors><title>Mobility Management Framework</title><categories>cs.PF cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates mobility management strategies from the point of view
of their need of signalling and processing resources on the backbone network
and load on the air interface. A method is proposed to model the serving
network and mobile node mobility in order to be able to compare the different
types of mobility management algorithms. To obtain a good description of the
network we calculate descriptive parameters from given topologies. Most
mobility approaches derived from existing protocols are analyzed and their
performances are numerically compared in various network and mobility
scenarios. We developed a mobility management framework that is able to give
general designing guidelines for the next generation mobility managements on
given network, technology and mobility properties. With our model an operator
can design the network and tune the parameters to obtain the optimal
implementation of course revising existing systems is also possible. We present
a vertical handover decision method as a special application of our model
framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0486</identifier>
 <datestamp>2008-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0486</id><created>2008-10-02</created><authors><author><keyname>Sobkowicz</keyname><forenames>Pawel</forenames></author></authors><title>Peer-review in the Internet age</title><categories>physics.soc-ph cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The importance of peer-review in the scientific process can not be
overestimated. Yet, due to increasing pressures of research and exponentially
growing number of publications the task faced by the referees becomes ever more
difficult. We discuss here a few possible improvements that would enable more
efficient review of the scientific literature, using the growing Internet
connectivity. In particular, a practical automated model for providing the
referees with references to papers that might have strong relationship with the
work under review, based on general network properties of citations is
proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0503</identifier>
 <datestamp>2009-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0503</id><created>2008-10-02</created><updated>2009-01-01</updated><authors><author><keyname>Jafarian</keyname><forenames>Amin</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>On the Capacity of One-sided Two user Gaussian Fading Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>Accepted for publication at Globecom Communications Conference 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate upper and lower bounds on the capacity of
two-user fading broadcast channels where one of the users has a constant
(non-fading) channel. We use the Costa entropy power inequality (EPI) along
with an optimization framework to derive upper bounds on the sum-capacity and
superposition coding to obtain lower bounds on the sum-rate for this channel.
For this fading broadcast channel where one channel is constant, we find that
the upper and lower bounds meet under special cases, and in general, we show
that the achievable sum-rate comes within a constant of the outer bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0532</identifier>
 <datestamp>2008-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0532</id><created>2008-10-02</created><updated>2008-10-17</updated><authors><author><keyname>de Keijzer</keyname><forenames>Bart</forenames></author></authors><title>Three New Complexity Results for Resource Allocation Problems</title><categories>cs.MA cs.AI cs.CC cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove the following results for task allocation of indivisible resources:
  - The problem of finding a leximin-maximal resource allocation is in P if the
agents have max-utility functions and atomic demands.
  - Deciding whether a resource allocation is Pareto-optimal is coNP-complete
for agents with (1-)additive utility functions.
  - Deciding whether there exists a Pareto-optimal and envy-free resource
allocation is Sigma_2^p-complete for agents with (1-)additive utility
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0558</identifier>
 <datestamp>2008-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0558</id><created>2008-10-02</created><authors><author><keyname>Goel</keyname><forenames>Ashish</forenames></author><author><keyname>Khanna</keyname><forenames>Sanjeev</forenames></author><author><keyname>Null</keyname><forenames>Brad</forenames></author></authors><title>The Ratio Index for Budgeted Learning, with Applications</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the budgeted learning problem, we are allowed to experiment on a set of
alternatives (given a fixed experimentation budget) with the goal of picking a
single alternative with the largest possible expected payoff. Approximation
algorithms for this problem were developed by Guha and Munagala by rounding a
linear program that couples the various alternatives together. In this paper we
present an index for this problem, which we call the ratio index, which also
guarantees a constant factor approximation. Index-based policies have the
advantage that a single number (i.e. the index) can be computed for each
alternative irrespective of all other alternatives, and the alternative with
the highest index is experimented upon. This is analogous to the famous Gittins
index for the discounted multi-armed bandit problem.
  The ratio index has several interesting structural properties. First, we show
that it can be computed in strongly polynomial time. Second, we show that with
the appropriate discount factor, the Gittins index and our ratio index are
constant factor approximations of each other, and hence the Gittins index also
gives a constant factor approximation to the budgeted learning problem.
Finally, we show that the ratio index can be used to create an index-based
policy that achieves an O(1)-approximation for the finite horizon version of
the multi-armed bandit problem. Moreover, the policy does not require any
knowledge of the horizon (whereas we compare its performance against an optimal
strategy that is aware of the horizon). This yields the following surprising
result: there is an index-based policy that achieves an O(1)-approximation for
the multi-armed bandit problem, oblivious to the underlying discount factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0567</identifier>
 <datestamp>2008-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0567</id><created>2008-10-03</created><authors><author><keyname>Thangaraj</keyname><forenames>Andrew</forenames></author><author><keyname>Raj</keyname><forenames>Safitha J</forenames></author></authors><title>Reed-Solomon Subcodes with Nontrivial Traces: Distance Properties and
  Soft-Decision Decoding</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reed-Solomon (RS) codes over GF$(2^m)$ have traditionally been the most
popular non-binary codes in almost all practical applications. The distance
properties of RS codes result in excellent performance under hard-decision
bounded-distance decoding. However, efficient and implementable soft decoding
for high-rate (about 0.9) RS codes over large fields (GF(256), say) continues
to remain a subject of research with a promise of further coding gains. In this
work, our objective is to propose and investigate $2^m$-ary codes with
non-trivial binary trace codes as an alternative to RS codes. We derive bounds
on the rate of a $2^m$-ary code with a non-trivial binary trace code. Then we
construct certain subcodes of RS codes over GF($2^m$) that have a non-trivial
binary trace with distances and rates meeting the derived bounds. The
properties of these subcodes are studied and low-complexity hard-decision and
soft-decision decoders are proposed. The decoders are analyzed, and their
performance is compared with that of comparable RS codes. Our results suggest
that these subcodes of RS codes could be viable alternatives for RS codes in
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0674</identifier>
 <datestamp>2008-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0674</id><created>2008-10-03</created><authors><author><keyname>Barman</keyname><forenames>Siddharth</forenames></author><author><keyname>Chawla</keyname><forenames>Shuchi</forenames></author></authors><title>Packing multiway cuts in capacitated graphs</title><categories>cs.DS</categories><comments>The conference version of this paper is to appear at SODA 2009. This
  is the full version</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following &quot;multiway cut packing&quot; problem in undirected
graphs: we are given a graph G=(V,E) and k commodities, each corresponding to a
set of terminals located at different vertices in the graph; our goal is to
produce a collection of cuts {E_1,...,E_k} such that E_i is a multiway cut for
commodity i and the maximum load on any edge is minimized. The load on an edge
is defined to be the number of cuts in the solution crossing the edge. In the
capacitated version of the problem the goal is to minimize the maximum relative
load on any edge--the ratio of the edge's load to its capacity. Multiway cut
packing arises in the context of graph labeling problems where we are given a
partial labeling of a set of items and a neighborhood structure over them, and,
informally, the goal is to complete the labeling in the most consistent way.
This problem was introduced by Rabani, Schulman, and Swamy (SODA'08), who
developed an O(log n/log log n) approximation for it in general graphs, as well
as an improved O(log^2 k) approximation in trees. Here n is the number of nodes
in the graph. We present the first constant factor approximation for this
problem in arbitrary undirected graphs. Our approach is based on the
observation that every instance of the problem admits a near-optimal laminar
solution (that is, one in which no pair of cuts cross each other).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0693</identifier>
 <datestamp>2008-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0693</id><created>2008-10-03</created><authors><author><keyname>Ito</keyname><forenames>Tsuyoshi</forenames></author><author><keyname>Kobayashi</keyname><forenames>Hirotada</forenames></author><author><keyname>Matsumoto</keyname><forenames>Keiji</forenames></author></authors><title>Oracularization and Two-Prover One-Round Interactive Proofs against
  Nonlocal Strategies</title><categories>quant-ph cs.CC cs.CR</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A central problem in quantum computational complexity is how to prevent
entanglement-assisted cheating in multi-prover interactive proof systems. It is
well-known that the standard oracularization technique completely fails in some
proof systems under the existence of prior entanglement. This paper studies two
constructions of two-prover one-round interactive proof systems based on
oracularization. First, it is proved that the two-prover one-round interactive
proof system for PSPACE by Cai, Condon, and Lipton still achieves exponentially
small soundness error in the existence of prior entanglement between dishonest
provers (and more strongly, even if dishonest provers are allowed to use
arbitrary no-signaling strategies). It follows that, unless the polynomial-time
hierarchy collapses to the second level, two-prover systems are still
advantageous to single-prover systems even when only malicious provers can use
quantum information. Second, it is proved that the two-prover one-round
interactive proof system obtained by oracularizing a three-query
probabilistically checkable proof system becomes sound in a weak sense even
against dishonest entangled provers with the help of a dummy question. As a
consequence, every language in NEXP has a two-prover one-round interactive
proof system of perfect completeness, albeit with exponentially small gap
between completeness and soundness, in which each prover responds with only two
bits. In other words, it is NP-hard to approximate within an inverse-polynomial
the value of a classical two-prover one-round game, even when provers are
entangled and each sends a two-bit answer to a verifier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0745</identifier>
 <datestamp>2009-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0745</id><created>2008-10-04</created><updated>2009-05-30</updated><authors><author><keyname>Park</keyname><forenames>Jaeok</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Stackelberg Contention Games in Multiuser Networks</title><categories>cs.GT cs.NI</categories><comments>30 pages, 5 figures</comments><journal-ref>EURASIP Journal on Advances in Signal Processing, vol. 2009,
  Article ID 305978, 15 pages, 2009</journal-ref><doi>10.1155/2009/305978</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interactions among selfish users sharing a common transmission channel can be
modeled as a non-cooperative game using the game theory framework. When selfish
users choose their transmission probabilities independently without any
coordination mechanism, Nash equilibria usually result in a network collapse.
We propose a methodology that transforms the non-cooperative game into a
Stackelberg game. Stackelberg equilibria of the Stackelberg game can overcome
the deficiency of the Nash equilibria of the original game. A particular type
of Stackelberg intervention is constructed to show that any positive payoff
profile feasible with independent transmission probabilities can be achieved as
a Stackelberg equilibrium payoff profile. We discuss criteria to select an
operating point of the network and informational requirements for the
Stackelberg game. We relax the requirements and examine the effects of
relaxation on performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0747</identifier>
 <datestamp>2008-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0747</id><created>2008-10-04</created><authors><author><keyname>Tandon</keyname><forenames>Ravi</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>A New Upper Bound on the Capacity of a Class of Primitive Relay Channels</title><categories>cs.IT cs.AI math.IT</categories><comments>To appear in Proceedings of 46th Annual Allerton Conference on
  Communication, Control and Computing, Sept. 2008</comments><acm-class>H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We obtain a new upper bound on the capacity of a class of discrete memoryless
relay channels. For this class of relay channels, the relay observes an i.i.d.
sequence $T$, which is independent of the channel input $X$. The channel is
described by a set of probability transition functions $p(y|x,t)$ for all
$(x,t,y)\in \mathcal{X}\times \mathcal{T}\times \mathcal{Y}$. Furthermore, a
noiseless link of finite capacity $R_{0}$ exists from the relay to the
receiver. Although the capacity for these channels is not known in general, the
capacity of a subclass of these channels, namely when $T=g(X,Y)$, for some
deterministic function $g$, was obtained in [1] and it was shown to be equal to
the cut-set bound. Another instance where the capacity was obtained was in [2],
where the channel output $Y$ can be written as $Y=X\oplus Z$, where $\oplus$
denotes modulo-$m$ addition, $Z$ is independent of $X$,
$|\mathcal{X}|=|\mathcal{Y}|=m$, and $T$ is some stochastic function of $Z$.
The compress-and-forward (CAF) achievability scheme [3] was shown to be
capacity achieving in both cases.
  Using our upper bound we recover the capacity results of [1] and [2]. We also
obtain the capacity of a class of channels which does not fall into either of
the classes studied in [1] and [2]. For this class of channels, CAF scheme is
shown to be optimal but capacity is strictly less than the cut-set bound for
certain values of $R_{0}$. We also evaluate our outer bound for a particular
relay channel with binary multiplicative states and binary additive noise for
which the channel is given as $Y=TX+N$. We show that our upper bound is
strictly better than the cut-set upper bound for certain values of $R_{0}$ but
it lies strictly above the rates yielded by the CAF achievability scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0753</identifier>
 <datestamp>2008-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0753</id><created>2008-10-04</created><authors><author><keyname>Soffia</keyname><forenames>Stefano</forenames></author></authors><title>Definition and Implementation of a Points-To Analysis for C-like
  Languages</title><categories>cs.PL</categories><comments>135 pages</comments><acm-class>F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The points-to problem is the problem of determining the possible run-time
targets of pointer variables and is usually considered part of the more general
aliasing problem, which consists in establishing whether and when different
expressions can refer to the same memory address. Aliasing information is
essential to every tool that needs to reason about the semantics of programs.
However, due to well-known undecidability results, for all interesting
languages that admit aliasing, the exact solution of nontrivial aliasing
problems is not generally computable. This work focuses on approximated
solutions to this problem by presenting a store-based, flow-sensitive points-to
analysis, for applications in the field of automated software verification. In
contrast to software testing procedures, which heuristically check the program
against a finite set of executions, the methods considered in this work are
static analyses, where the computed results are valid for all the possible
executions of the analyzed program. We present a simplified programming
language and its execution model; then an approximated execution model is
developed using the ideas of abstract interpretation theory. Finally, the
soundness of the approximation is formally proved. The aim of developing a
realistic points-to analysis is pursued by presenting some extensions to the
initial simplified model and discussing the correctness of their formulation.
This work contains original contributions to the issue of points-to analysis,
as it provides a formulation of a filter operation on the points-to abstract
domain and a formal proof of the soundness of the defined abstract operations:
these, as far as we now, are lacking from the previous literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0763</identifier>
 <datestamp>2008-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0763</id><created>2008-10-04</created><authors><author><keyname>Pad</keyname><forenames>Pedram</forenames></author><author><keyname>Soltanolkotabi</keyname><forenames>Mahdi</forenames></author><author><keyname>Hadikhanlou</keyname><forenames>Saeed</forenames></author><author><keyname>Enayati</keyname><forenames>Arash</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>Errorless Codes for Over-loaded CDMA with Active User Detection</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a new class of codes for over-loaded synchronous
wireless CDMA systems which increases the number of users for a fixed number of
chips without introducing any errors. In addition these codes support active
user detection. We derive an upper bound on the number of users with a fixed
spreading factor. Also we propose an ML decoder for a subclass of these codes
that is computationally implementable. Although for our simulations we consider
a scenario that is worse than what occurs in practice, simulation results
indicate that this coding/decoding scheme is robust against additive noise. As
an example, for 64 chips and 88 users we propose a coding/decoding scheme that
can obtain an arbitrary small probability of error which is computationally
feasible and can detect active users. Furthermore, we prove that for this to be
possible the number of users cannot be beyond 230.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0764</identifier>
 <datestamp>2009-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0764</id><created>2008-10-04</created><updated>2009-03-07</updated><authors><author><keyname>Faraji</keyname><forenames>Mohammad Javad</forenames></author><author><keyname>Pad</keyname><forenames>Pedram</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>A New Method for Constructing Large Size WBE Codes with Low Complexity
  ML Decoder</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we wish to introduce a method to reconstruct large size Welch
Bound Equality (WBE) codes from small size WBE codes. The advantage of these
codes is that the implementation of ML decoder for the large size codes is
reduced to implementation of ML decoder for the core codes. This leads to a
drastic reduction of the computational cost of ML decoder. Our method can also
be used for constructing large Binary WBE (BWBE) codes from smaller ones.
Additionally, we explain that although WBE codes are maximizing the sum channel
capacity when the inputs are real valued, they are not necessarily appropriate
when the input alphabet is binary. The discussion shows that when the input
alphabet is binary, the Total Squared Correlation (TSC) of codes is not a
proper figure of merit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0785</identifier>
 <datestamp>2008-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0785</id><created>2008-10-04</created><authors><author><keyname>Fertonani</keyname><forenames>Dario</forenames></author><author><keyname>Duman</keyname><forenames>Tolga M.</forenames></author></authors><title>Novel Bounds on the Capacity of the Binary Deletion Channel</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present novel bounds on the capacity of the independent and identically
distributed binary deletion channel. Four upper bounds are obtained by
providing the transmitter and the receiver with genie-aided information on
suitably-defined random processes. Since some of the proposed bounds involve
infinite series, we also introduce provable inequalities that lead to more
manageable results. For most values of the deletion probability, these bounds
improve the existing ones and significantly narrow the gap with the available
lower bounds. Exploiting the same auxiliary processes, we also derive, as a
by-product, a couple of very simple lower bounds on the channel capacity,
which, for low values of the deletion probability, are almost as good as the
best existing lower bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0800</identifier>
 <datestamp>2008-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0800</id><created>2008-10-05</created><authors><author><keyname>Chen</keyname><forenames>Zizhong</forenames></author><author><keyname>Dongarra</keyname><forenames>Jack</forenames></author></authors><title>Condition Numbers of Gaussian Random Matrices</title><categories>cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $G_{m \times n}$ be an $m \times n$ real random matrix whose elements are
independent and identically distributed standard normal random variables, and
let $\kappa_2(G_{m \times n})$ be the 2-norm condition number of $G_{m \times
n}$. We prove that, for any $m \geq 2$, $n \geq 2$ and $x \geq |n-m|+1$,
$\kappa_2(G_{m \times n})$ satisfies $
  \frac{1}{\sqrt{2\pi}} ({c}/{x})^{|n-m|+1} &lt; P(\frac{\kappa_2(G_{m \times n})}
{{n}/{(|n-m|+1)}}&gt; x) &lt;
  \frac{1}{\sqrt{2\pi}} ({C}/{x})^{|n-m|+1}, $ where $0.245 \leq c \leq 2.000$
and $ 5.013 \leq C \leq 6.414$ are universal positive constants independent of
$m$, $n$ and $x$. Moreover, for any $m \geq 2$ and $n \geq 2$, $
E(\log\kappa_2(G_{m \times n})) &lt; \log \frac{n}{|n-m|+1} + 2.258. $ A similar
pair of results for complex Gaussian random matrices is also established.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0830</identifier>
 <datestamp>2008-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0830</id><created>2008-10-05</created><authors><author><keyname>Pashkevich</keyname><forenames>Anatoly</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Stiffness Analysis Of Multi-Chain Parallel Robotic Systems</title><categories>cs.RO physics.class-ph</categories><proxy>ccsd hal-00326672</proxy><journal-ref>9th IFAC Workshop on Intelligent Manufacturing Systems, France
  (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents a new stiffness modelling method for multi-chain parallel
robotic manipulators with flexible links and compliant actuating joints. In
contrast to other works, the method involves a FEA-based link stiffness
evaluation and employs a new solution strategy of the kinetostatic equations,
which allows computing the stiffness matrix for singular postures and to take
into account influence of the internal forces. The advantages of the developed
technique are confirmed by application examples, which deal with stiffness
analysis of the Orthoglide manipulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0852</identifier>
 <datestamp>2008-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0852</id><created>2008-10-05</created><authors><author><keyname>Keller</keyname><forenames>Joseph B.</forenames></author></authors><title>Evaluation of Authors and Journals</title><categories>math.HO cs.IR physics.soc-ph</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method is presented for evaluating authors on the basis of citations. It
assigns to each author a citation score which depends upon the number of times
he is cited, and upon the scores of the citers. The scores are found to be the
components of an eigenvector of a normalized citation matrix. The same method
can be applied to citation of journals by other journals, to evaluating teams
in a league [1], etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0870</identifier>
 <datestamp>2010-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0870</id><created>2008-10-05</created><updated>2009-05-19</updated><authors><author><keyname>Lin</keyname><forenames>Pin-Hsun</forenames></author><author><keyname>Lin</keyname><forenames>Shih-Chun</forenames></author><author><keyname>Lee</keyname><forenames>Chung-Pi</forenames></author><author><keyname>Su</keyname><forenames>Hsuan-Jung</forenames></author></authors><title>Cognitive Radio with Partial Channel State Information at the
  Transmitter</title><categories>cs.IT math.IT</categories><comments>resubmitted to IEEE Transaction on Wireless Communications, May 2009</comments><journal-ref>IEEE Transactions on Wireless Communications, vol. 9, no. 11, pp.
  3402-3413, Nov. 2010</journal-ref><doi>10.1109/TWC.2010.092410.090725</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the cognitive radio system design with partial
channel state information known at the transmitter (CSIT).We replace the dirty
paper coding (DPC) used in the cognitive radio with full CSIT by the linear
assignment Gel'fand-Pinsker coding (LA-GPC), which can utilize the limited
knowledge of the channel more efficiently. Based on the achievable rate derived
from the LA-GPC, two optimization problems under the fast and slow fading
channels are formulated. We derive semianalytical solutions to find the
relaying ratios and precoding coefficients. The critical observation is that
the complex rate functions in these problems are closely related to ratios of
quadratic form. Simulation results show that the proposed semi-analytical
solutions perform close to the optimal solutions found by brute-force search,
and outperform the systems based on naive DPC. Asymptotic analysis also shows
that these solutions converge to the optimal ones solved with full CSIT when
the K-factor of Rician channel approaches infinity. Moreover, a new coding
scheme is proposed to implement the LA-GPC in practice. Simulation results show
that the proposed practical coding scheme can efficiently reach the theoretical
rate performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0874</identifier>
 <datestamp>2009-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0874</id><created>2008-10-06</created><updated>2009-03-13</updated><authors><author><keyname>Sorudeykin</keyname><forenames>Kirill A</forenames></author></authors><title>Software Engineering &amp; Systems Design Nature</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main problems of Software Engineering appear as a result of
incompatibilities. For example, the quality of organization of the production
process depends on correspondence with existent resources and on a common
understanding of project goals by all team members. Software design is another
example. Its successfulness rides on the architecture's conformity with a
project's concepts. This is a point of great nicety. All elements should create
a single space of interaction. And if the laws of such a space are imperfect,
missequencing comes and the concept of a software system fails. We must do our
best for this not to happen. To that end, having a subtle perception of systems
structures is essential. Such knowledge can be based only on a fresh approach
to the logical law.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0877</identifier>
 <datestamp>2008-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0877</id><created>2008-10-06</created><authors><author><keyname>Rajnarayan</keyname><forenames>Dev</forenames></author><author><keyname>Wolpert</keyname><forenames>David</forenames></author></authors><title>Bias-Variance Techniques for Monte Carlo Optimization: Cross-validation
  for the CE Method</title><categories>cs.NA cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we examine the CE method in the broad context of Monte Carlo
Optimization (MCO) and Parametric Learning (PL), a type of machine learning. A
well-known overarching principle used to improve the performance of many PL
algorithms is the bias-variance tradeoff. This tradeoff has been used to
improve PL algorithms ranging from Monte Carlo estimation of integrals, to
linear estimation, to general statistical estimation. Moreover, as described
by, MCO is very closely related to PL. Owing to this similarity, the
bias-variance tradeoff affects MCO performance, just as it does PL performance.
  In this article, we exploit the bias-variance tradeoff to enhance the
performance of MCO algorithms. We use the technique of cross-validation, a
technique based on the bias-variance tradeoff, to significantly improve the
performance of the Cross Entropy (CE) method, which is an MCO algorithm. In
previous work we have confirmed that other PL techniques improve the perfomance
of other MCO algorithms. We conclude that the many techniques pioneered in PL
could be investigated as ways to improve MCO algorithms in general, and the CE
method in particular.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0882</identifier>
 <datestamp>2008-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0882</id><created>2008-10-06</created><authors><author><keyname>Hwang</keyname><forenames>Chien-Hwa</forenames></author></authors><title>Asymptotic Eigenvalue Moments of Wishart-Type Random Matrix Without
  Ergodicity in One Channel Realization</title><categories>cs.IT math.IT</categories><comments>36 pages, 6 figures, submitted to IEEE Transactions on Information
  Theory, Oct. 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a random matrix whose variance profile is random. This random matrix
is ergodic in one channel realization if, for each column and row, the
empirical distribution of the squared magnitudes of elements therein converges
to a nonrandom distribution. In this paper, noncrossing partition theory is
employed to derive expressions for several asymptotic eigenvalue moments (AEM)
related quantities of a large Wishart-type random matrix $\bb H\bb H^\dag$ when
$\bb H$ has a random variance profile and is nonergodic in one channel
realization. It is known the empirical eigenvalue moments of $\bb H\bb H^\dag$
are dependent (or independent) on realizations of the variance profile of $\bb
H$ when $\bb H$ is nonergodic (or ergodic) in one channel realization. For
nonergodic $\bb H$, the AEM can be obtained by i) deriving the expression of
AEM in terms of the variance profile of $\bb H$, and then ii) averaging the
derived quantity over the ensemble of variance profiles. Since the AEM are
independent of the variance profile if $\bb H$ is ergodic, the expression
obtained in i) can also serve as the AEM formula for ergodic $\bb H$ when any
realization of variance profile is available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0883</identifier>
 <datestamp>2009-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0883</id><created>2008-10-06</created><updated>2009-02-18</updated><authors><author><keyname>Kumar</keyname><forenames>K. Raj</forenames></author><author><keyname>Caire</keyname><forenames>G.</forenames></author><author><keyname>Moustakas</keyname><forenames>A. L.</forenames></author></authors><title>Asymptotic Performance of Linear Receivers in MIMO Fading Channels</title><categories>cs.IT math.IT</categories><comments>48 pages, Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear receivers are an attractive low-complexity alternative to optimal
processing for multi-antenna MIMO communications. In this paper we characterize
the information-theoretic performance of MIMO linear receivers in two different
asymptotic regimes. For fixed number of antennas, we investigate the limit of
error probability in the high-SNR regime in terms of the Diversity-Multiplexing
Tradeoff (DMT). Following this, we characterize the error probability for fixed
SNR in the regime of large (but finite) number of antennas.
  As far as the DMT is concerned, we report a negative result: we show that
both linear Zero-Forcing (ZF) and linear Minimum Mean-Square Error (MMSE)
receivers achieve the same DMT, which is largely suboptimal even in the case
where outer coding and decoding is performed across the antennas. We also
provide an approximate quantitative analysis of the markedly different behavior
of the MMSE and ZF receivers at finite rate and non-asymptotic SNR, and show
that while the ZF receiver achieves poor diversity at any finite rate, the MMSE
receiver error curve slope flattens out progressively, as the coding rate
increases.
  When SNR is fixed and the number of antennas becomes large, we show that the
mutual information at the output of a MMSE or ZF linear receiver has
fluctuations that converge in distribution to a Gaussian random variable, whose
mean and variance can be characterized in closed form. This analysis extends to
the linear receiver case a well-known result previously obtained for the
optimal receiver. Simulations reveal that the asymptotic analysis captures
accurately the outage behavior of systems even with a moderate number of
antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0906</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0906</id><created>2008-10-06</created><updated>2010-11-24</updated><authors><author><keyname>Hasunuma</keyname><forenames>Toru</forenames></author><author><keyname>Ishii</keyname><forenames>Toshimasa</forenames></author><author><keyname>Ono</keyname><forenames>Hirotaka</forenames></author><author><keyname>Uno</keyname><forenames>Yushi</forenames></author></authors><title>A linear time algorithm for L(2,1)-labeling of trees</title><categories>cs.DS</categories><comments>23 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An L(2,1)-labeling of a graph $G$ is an assignment $f$ from the vertex set
$V(G)$ to the set of nonnegative integers such that $|f(x)-f(y)|\ge 2$ if $x$
and $y$ are adjacent and $|f(x)-f(y)|\ge 1$ if $x$ and $y$ are at distance 2,
for all $x$ and $y$ in $V(G)$. A $k$-L(2,1)-labeling is an assignment
$f:V(G)\to\{0,..., k\}$, and the L(2,1)-labeling problem asks the minimum $k$,
which we denote by $\lambda(G)$, among all possible assignments. It is known
that this problem is NP-hard even for graphs of treewidth 2, and tree is one of
a very few classes for which the problem is polynomially solvable. The running
time of the best known algorithm for trees had been $\mO(\Delta^{4.5} n)$ for
more than a decade, however, an $\mO(n^{1.75})$-time algorithm has been
proposed recently, which substantially improved the previous one, where
$\Delta$ is the maximum degree of $T$ and $n=|V(T)|$. In this paper, we finally
establish a linear time algorithm for L(2,1)-labeling of trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1018</identifier>
 <datestamp>2008-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1018</id><created>2008-10-06</created><authors><author><keyname>Moore</keyname><forenames>Cristopher</forenames></author><author><keyname>Russell</keyname><forenames>Alexander</forenames></author></authors><title>A simple constant-probability RP reduction from NP to Parity P</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The proof of Toda's celebrated theorem that the polynomial hierarchy is
contained in $\P^{# P}$ relies on the fact that, under mild technical
conditions on the complexity class $C$, we have $\exists C \subset BP \cdot
\oplus C$. More concretely, there is a randomized reduction which transforms
nonempty sets and the empty set, respectively, into sets of odd or even size.
The customary method is to invoke Valiant's and Vazirani's randomized reduction
from NP to UP, followed by amplification of the resulting success probability
from $1/\poly(n)$ to a constant by combining the parities of $\poly(n)$ trials.
Here we give a direct algebraic reduction which achieves constant success
probability without the need for amplification. Our reduction is very simple,
and its analysis relies on well-known properties of the Legendre symbol in
finite fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1103</identifier>
 <datestamp>2009-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1103</id><created>2008-10-07</created><authors><author><keyname>Chaporkar</keyname><forenames>Prasanna</forenames></author><author><keyname>Kansanen</keyname><forenames>Kimmo</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Ralf R.</forenames></author></authors><title>Channel and Multiuser Diversities in Wireless Systems: Delay-Energy
  Tradeoff</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a communication system with multi-access fading channel. Each
user in the system requires certain rate guarantee. Our main contribution is to
devise a scheduling scheme called &quot;Opportunistic Super-position Coding&quot; that
satisfies the users' rate requirements. Using mean-field analysis, i.e., when
the number of users go to infinity, we analytically show that the energy
required to guarantee the required user rate can be made as small as required
at the cost of a higher delay (&quot;delay-energy tradeoff&quot;). We explicitly compute
the delay under the proposed scheduling policy and discuss how delay
differentiation can be achieved. We extend the results to multi-band
multi-access channel. Finally, all the results can be generalized in a
straightforward fashion to broadcast channel due to the AWGN
multiaccess-broadcast duality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1105</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1105</id><created>2008-10-07</created><authors><author><keyname>Chilappagari</keyname><forenames>Shashi Kiran</forenames></author><author><keyname>Krishnan</keyname><forenames>Anantha Raman</forenames></author><author><keyname>Vasic</keyname><forenames>Bane</forenames></author><author><keyname>Marcellin</keyname><forenames>Michael W.</forenames></author></authors><title>Low-Density Parity-Check Codes Which Can Correct Three Errors Under
  Iterative Decoding</title><categories>cs.IT math.IT</categories><comments>25 pages. 11 Figures. Part of the work was presented at the
  Information Theory Workshop (ITW), May 5-9 2008, Porto, Portugal. submitted
  to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we give necessary and sufficient conditions for low-density
parity-check (LDPC) codes with column-weight three to correct three errors when
decoded using hard-decision message-passing decoding. Additionally, we give
necessary and sufficient conditions for column-weight-four codes to correct
three errors in four iterations of hard-decision message-passing decoding. We
then give a construction technique which results in codes satisfying these
conditions. We also provide numerical assessment of code performance via
simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1106</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1106</id><created>2008-10-07</created><updated>2009-01-13</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>On the expressiveness of single-pass instruction sequences</title><categories>cs.PL</categories><comments>14 pages; error corrected, acknowledgement added; another error
  corrected, another acknowledgement added</comments><report-no>PRG0813</report-no><acm-class>D.1.4; D.3.3; F.1.1; F.3.3</acm-class><journal-ref>Theory of Computing Systems, 50(2):313--328, 2012</journal-ref><doi>10.1007/s00224-010-9301-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We perceive programs as single-pass instruction sequences. A single-pass
instruction sequence under execution is considered to produce a behaviour to be
controlled by some execution environment. Threads as considered in basic thread
algebra model such behaviours. We show that all regular threads, i.e. threads
that can only be in a finite number of states, can be produced by single-pass
instruction sequences without jump instructions if use can be made of Boolean
registers. We also show that, in the case where goto instructions are used
instead of jump instructions, a bound to the number of labels restricts the
expressiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1119</identifier>
 <datestamp>2008-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1119</id><created>2008-10-07</created><authors><author><keyname>Shental</keyname><forenames>Ori</forenames></author><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author><author><keyname>Wolf</keyname><forenames>Jack K.</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author></authors><title>Gaussian Belief Propagation for Solving Systems of Linear Equations:
  Theory and Application</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><acm-class>E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The canonical problem of solving a system of linear equations arises in
numerous contexts in information theory, communication theory, and related
fields. In this contribution, we develop a solution based upon Gaussian belief
propagation (GaBP) that does not involve direct matrix inversion. The iterative
nature of our approach allows for a distributed message-passing implementation
of the solution algorithm. We address the properties of the GaBP solver,
including convergence, exactness, computational complexity, message-passing
efficiency and its relation to classical solution methods. We use numerical
examples and applications, like linear detection, to illustrate these
properties through the use of computer simulations. This empirical study
demonstrates the attractiveness (e.g., faster convergence rate) of the proposed
GaBP solver in comparison to conventional linear-algebraic iterative solution
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1132</identifier>
 <datestamp>2008-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1132</id><created>2008-10-07</created><authors><author><keyname>Maimour</keyname><forenames>Moufida</forenames><affiliation>CRAN</affiliation></author></authors><title>Maximally Radio-Disjoint Multipath Routing for Wireless Multimedia
  Sensor Networks</title><categories>cs.NI</categories><proxy>ccsd hal-00327037</proxy><journal-ref>Fourth ACM International Workshop on Wireless Multimedia
  Networking and erformance Modeling, Vancouver : Canada (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In wireless sensor networks, bandwidth is one of precious resources to
multimedia applications. To get more bandwidth, multipath routing is one
appropriate solution provided that inter-path interferences are minimized. In
this paper, we address the problem of interfering paths in the context of
wireless multimedia sensor networks and consider both intra-session as well as
inter-session interferences. Our main objective is to provide necessary
bandwidth to multimedia applications through non-interfering paths while
increasing the network lifetime. To do so, we adopt an incremental approach
where for a given session, only one path is built at once. Additional paths are
built when required, typically in case of congestion or bandwidth shortage.
Interference awareness and energy saving are achieved by switching a subset of
sensor nodes in a {\em passive state} in which they do not take part in the
routing process. Despite the routing overhead introduced by the incremental
approach we adopt, our simulations show that this can be compensated by the
overall achieved throughput and the amount of consumed energy per correctly
received packet especially for relatively long sessions such as multimedia
ones. This is mainly due to the fact that a small number of non-interfering
paths allows for better performances than a large number of interfering ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1139</identifier>
 <datestamp>2009-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1139</id><created>2008-10-07</created><authors><author><keyname>Maimour</keyname><forenames>Moufida</forenames><affiliation>CRAN</affiliation></author><author><keyname>Pham</keyname><forenames>Congduc</forenames><affiliation>LIUPPA</affiliation></author><author><keyname>Amelot</keyname><forenames>Julien</forenames><affiliation>CRAN</affiliation></author></authors><title>Load Repartition for Congestion Control in Multimedia Wireless Sensor
  Networks with Multipath Routing</title><categories>cs.NI</categories><proxy>ccsd hal-00288132</proxy><journal-ref>3rd International Symposium on Wireless Pervasive Computing, ISWPC
  2008, Santorini : Gr\`ece (2008)</journal-ref><doi>10.1109/ISWPC.2008.4556156</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor networks hold a great potential in the deployment of several
applications of a paramount importance in our daily life. Video sensors are
able to improve a number of these applications where new approaches adapted to
both wireless sensor networks and video transport specific characteristics are
required. The aim of this work is to provide the necessary bandwidth and to
alleviate the congestion problem to video streaming. In this paper, we
investigate various load repartition strategies for congestion control
mechanism on top of a multipath routing feature. Simulations are performed in
order to get insight into the performances of our proposals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1151</identifier>
 <datestamp>2013-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1151</id><created>2008-10-07</created><updated>2013-04-16</updated><authors><author><keyname>Bergstra</keyname><forenames>Jan A.</forenames></author><author><keyname>Ponse</keyname><forenames>Alban</forenames></author></authors><title>Periodic Single-Pass Instruction Sequences</title><categories>cs.PL</categories><comments>16 pages, 3 tables, New title</comments><acm-class>D.3.1; F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A program is a finite piece of data that produces a (possibly infinite)
sequence of primitive instructions. From scratch we develop a linear notation
for sequential, imperative programs, using a familiar class of primitive
instructions and so-called repeat instructions, a particular type of control
instructions. The resulting mathematical structure is a semigroup. We relate
this set of programs to program algebra (PGA) and show that a particular
subsemigroup is a carrier for PGA by providing axioms for single-pass
congruence, structural congruence, and thread extraction. This subsemigroup
characterizes periodic single-pass instruction sequences and provides a direct
basis for PGA's toolset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1186</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1186</id><created>2008-10-07</created><updated>2012-07-05</updated><authors><author><keyname>Chen</keyname><forenames>Hubie</forenames></author><author><keyname>Gimenez</keyname><forenames>Omer</forenames></author></authors><title>On-the-fly Macros</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a domain-independent algorithm that computes macros in a novel
way. Our algorithm computes macros &quot;on-the-fly&quot; for a given set of states and
does not require previously learned or inferred information, nor prior domain
knowledge. The algorithm is used to define new domain-independent tractable
classes of classical planning that are proved to include \emph{Blocksworld-arm}
and \emph{Towers of Hanoi}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1187</identifier>
 <datestamp>2008-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1187</id><created>2008-10-07</created><authors><author><keyname>Koyluoglu</keyname><forenames>Onur Ozan</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author><author><keyname>Lai</keyname><forenames>Lifeng</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Interference Alignment for Secrecy</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the frequency/time selective $K$-user Gaussian
interference channel with secrecy constraints. Two distinct models, namely the
interference channel with confidential messages and the one with an external
eavesdropper, are analyzed. The key difference between the two models is the
lack of channel state information (CSI) about the external eavesdropper. Using
interference alignment along with secrecy pre-coding, it is shown that each
user can achieve non-zero secure Degrees of Freedom (DoF) for both cases. More
precisely, the proposed coding scheme achieves $\frac{K-2}{2K-2}$ secure DoF
{\em with probability one} per user in the confidential messages model. For the
external eavesdropper scenario, on the other hand, it is shown that each user
can achieve $\frac{K-2}{2K}$ secure DoF {\em in the ergodic setting}.
Remarkably, these results establish the {\em positive impact} of interference
on the secrecy capacity region of wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1197</identifier>
 <datestamp>2008-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1197</id><created>2008-10-07</created><authors><author><keyname>Paolini</keyname><forenames>E.</forenames></author><author><keyname>Chiani</keyname><forenames>M.</forenames></author></authors><title>Construction of Near-Optimum Burst Erasure Correcting Low-Density
  Parity-Check Codes</title><categories>cs.IT math.IT</categories><comments>15 pages, 4 figures. IEEE Trans. on Communications, accepted
  (submitted in Feb. 2007)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a simple, general-purpose and effective tool for the design of
low-density parity-check (LDPC) codes for iterative correction of bursts of
erasures is presented. The design method consists in starting from the
parity-check matrix of an LDPC code and developing an optimized parity-check
matrix, with the same performance on the memory-less erasure channel, and
suitable also for the iterative correction of single bursts of erasures. The
parity-check matrix optimization is performed by an algorithm called pivot
searching and swapping (PSS) algorithm, which executes permutations of
carefully chosen columns of the parity-check matrix, after a local analysis of
particular variable nodes called stopping set pivots. This algorithm can be in
principle applied to any LDPC code. If the input parity-check matrix is
designed for achieving good performance on the memory-less erasure channel,
then the code obtained after the application of the PSS algorithm provides good
joint correction of independent erasures and single erasure bursts. Numerical
results are provided in order to show the effectiveness of the PSS algorithm
when applied to different categories of LDPC codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1199</identifier>
 <datestamp>2008-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1199</id><created>2008-10-07</created><authors><author><keyname>Vaillant</keyname><forenames>Pascal</forenames></author></authors><title>Une grammaire formelle du cr\'eole martiniquais pour la g\'en\'eration
  automatique</title><categories>cs.CL</categories><comments>In French. 10 pages, 4 figures, LaTeX 2e using EPSF and custom
  package Taln2003.sty (JC/PZ, ATALA). Proceedings of the 10th annual
  French-speaking conference on Natural Language Processing: `Traitement
  Automatique des Langues Naturelles' (TALN 2003), Batz-sur-mer, France, 10-14
  June 2003</comments><acm-class>I.2.7</acm-class><journal-ref>Actes de la 10eme conference annuelle sur le Traitement
  Automatique des Langues Naturelles (TALN 2003), p. 255-264. Batz-sur-mer,
  France, 10-14 juin 2003</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, some first elements of a computational modelling of the
grammar of the Martiniquese French Creole dialect are presented. The sources of
inspiration for the modelling is the functional description given by Damoiseau
(1984), and Pinalie's &amp; Bernabe's (1999) grammar manual. Based on earlier works
in text generation (Vaillant, 1997), a unification grammar formalism, namely
Tree Adjoining Grammars (TAG), and a modelling of lexical functional categories
based on syntactic and semantic properties, are used to implement a grammar of
Martiniquese Creole which is used in a prototype of text generation system. One
of the main applications of the system could be its use as a tool software
supporting the task of learning Creole as a second language. -- Nous
pr\'esenterons dans cette communication les premiers travaux de mod\'elisation
informatique d'une grammaire de la langue cr\'eole martiniquaise, en nous
inspirant des descriptions fonctionnelles de Damoiseau (1984) ainsi que du
manuel de Pinalie &amp; Bernab\'e (1999). Prenant appui sur des travaux
ant\'erieurs en g\'en\'eration de texte (Vaillant, 1997), nous utilisons un
formalisme de grammaires d'unification, les grammaires d'adjonction d'arbres
(TAG d'apr\`es l'acronyme anglais), ainsi qu'une mod\'elisation de cat\'egories
lexicales fonctionnelles \`a base syntaxico-s\'emantique, pour mettre en oeuvre
une grammaire du cr\'eole martiniquais utilisable dans une maquette de
syst\`eme de g\'en\'eration automatique. L'un des int\'er\^ets principaux de ce
syst\`eme pourrait \^etre son utilisation comme logiciel outil pour l'aide \`a
l'apprentissage du cr\'eole en tant que langue seconde.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1207</identifier>
 <datestamp>2008-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1207</id><created>2008-10-07</created><authors><author><keyname>Vaillant</keyname><forenames>Pascal</forenames></author></authors><title>A Layered Grammar Model: Using Tree-Adjoining Grammars to Build a Common
  Syntactic Kernel for Related Dialects</title><categories>cs.CL</categories><comments>8 pages, 3 figures, 2 tables. LaTeX 2e using the coling08 style (and
  standard packages like epsf, amssymb, multirow, url...). Proceedings of the
  9th International Workshop on Tree Adjoining Grammars and Related Formalisms.
  Tuebingen, Baden-Wurttemberg, Germany, 6-8 June 2008</comments><acm-class>I.2.7</acm-class><journal-ref>Proceedings of the Ninth International Workshop on Tree Adjoining
  Grammars and Related Formalisms (TAG+9 2008), p. 157-164. Tuebingen,
  Baden-Wurttemberg, Germany, 6-8 June 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article describes the design of a common syntactic description for the
core grammar of a group of related dialects. The common description does not
rely on an abstract sub-linguistic structure like a metagrammar: it consists in
a single FS-LTAG where the actual specific language is included as one of the
attributes in the set of attribute types defined for the features. When the
lang attribute is instantiated, the selected subset of the grammar is
equivalent to the grammar of one dialect. When it is not, we have a model of a
hybrid multidialectal linguistic system. This principle is used for a group of
creole languages of the West-Atlantic area, namely the French-based Creoles of
Haiti, Guadeloupe, Martinique and French Guiana.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1212</identifier>
 <datestamp>2008-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1212</id><created>2008-10-07</created><authors><author><keyname>Vaillant</keyname><forenames>Pascal</forenames></author><author><keyname>Nock</keyname><forenames>Richard</forenames></author><author><keyname>Henry</keyname><forenames>Claudia</forenames></author></authors><title>Analyse spectrale des textes: d\'etection automatique des fronti\`eres
  de langue et de discours</title><categories>cs.CL cs.IR</categories><comments>In French. 10 pages, 5 figures, LaTeX 2e using EPSF and custom
  package taln2006.sty (designed by Pierre Zweigenbaum, ATALA). Proceedings of
  the 13th annual French-speaking conference on Natural Language Processing:
  `Traitement Automatique des Langues Naturelles' (TALN 2006), Louvain
  (Leuven), Belgium, 10-13 April 2003</comments><acm-class>H.3.3; I.2.7</acm-class><journal-ref>Verbum ex machina: Actes de la 13eme conference annuelle sur le
  Traitement Automatique des Langues Naturelles (TALN 2006), p. 619-629.
  Louvain (Leuven), Belgique, 10-13 avril 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a theoretical framework within which information on the vocabulary
of a given corpus can be inferred on the basis of statistical information
gathered on that corpus. Inferences can be made on the categories of the words
in the vocabulary, and on their syntactical properties within particular
languages. Based on the same statistical data, it is possible to build matrices
of syntagmatic similarity (bigram transition matrices) or paradigmatic
similarity (probability for any pair of words to share common contexts). When
clustered with respect to their syntagmatic similarity, words tend to group
into sublanguage vocabularies, and when clustered with respect to their
paradigmatic similarity, into syntactic or semantic classes. Experiments have
explored the first of these two possibilities. Their results are interpreted in
the frame of a Markov chain modelling of the corpus' generative processe(s): we
show that the results of a spectral analysis of the transition matrix can be
interpreted as probability distributions of words within clusters. This method
yields a soft clustering of the vocabulary into sublanguages which contribute
to the generation of heterogeneous corpora. As an application, we show how
multilingual texts can be visually segmented into linguistically homogeneous
segments. Our method is specifically useful in the case of related languages
which happened to be mixed in corpora.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1226</identifier>
 <datestamp>2008-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1226</id><created>2008-10-07</created><authors><author><keyname>Fekete</keyname><forenames>Attila</forenames></author></authors><title>Traffic Dynamics of Computer Networks</title><categories>cs.NI cond-mat.stat-mech</categories><comments>phd thesis (135 pages, 62 figures)</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Two important aspects of the Internet, namely the properties of its topology
and the characteristics of its data traffic, have attracted growing attention
of the physics community. My thesis has considered problems of both aspects.
First I studied the stochastic behavior of TCP, the primary algorithm governing
traffic in the current Internet, in an elementary network scenario consisting
of a standalone infinite-sized buffer and an access link. The effect of the
fast recovery and fast retransmission (FR/FR) algorithms is also considered. I
showed that my model can be extended further to involve the effect of link
propagation delay, characteristic of WAN. I continued my thesis with the
investigation of finite-sized semi-bottleneck buffers, where packets can be
dropped not only at the link, but also at the buffer. I demonstrated that the
behavior of the system depends only on a certain combination of the parameters.
Moreover, an analytic formula was derived that gives the ratio of packet loss
rate at the buffer to the total packet loss rate. This formula makes it
possible to treat buffer-losses as if they were link-losses. Finally, I studied
computer networks from a structural perspective. I demonstrated through fluid
simulations that the distribution of resources, specifically the link
bandwidth, has a serious impact on the global performance of the network. Then
I analyzed the distribution of edge betweenness in a growing scale-free tree
under the condition that a local property, the in-degree of the &quot;younger&quot; node
of an arbitrary edge, is known in order to find an optimum distribution of link
capacity. The derived formula is exact even for finite-sized networks. I also
calculated the conditional expectation of edge betweenness, rescaled for
infinite networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1234</identifier>
 <datestamp>2008-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1234</id><created>2008-10-07</created><authors><author><keyname>ParandehGheibi</keyname><forenames>Ali</forenames></author><author><keyname>Eryilmaz</keyname><forenames>Atilla</forenames></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>On Resource Allocation in Fading Multiple Access Channels - An Efficient
  Approximate Projection Approach</title><categories>cs.IT cs.NI math.IT math.OC</categories><comments>32 pages, Submitted to IEEE Trans. on Information Theory</comments><report-no>LIDS report 2787</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of rate and power allocation in a multiple-access
channel. Our objective is to obtain rate and power allocation policies that
maximize a general concave utility function of average transmission rates on
the information theoretic capacity region of the multiple-access channel. Our
policies does not require queue-length information. We consider several
different scenarios. First, we address the utility maximization problem in a
nonfading channel to obtain the optimal operating rates, and present an
iterative gradient projection algorithm that uses approximate projection. By
exploiting the polymatroid structure of the capacity region, we show that the
approximate projection can be implemented in time polynomial in the number of
users. Second, we consider resource allocation in a fading channel. Optimal
rate and power allocation policies are presented for the case that power
control is possible and channel statistics are available. For the case that
transmission power is fixed and channel statistics are unknown, we propose a
greedy rate allocation policy and provide bounds on the performance difference
of this policy and the optimal policy in terms of channel variations and
structure of the utility function. We present numerical results that
demonstrate superior convergence rate performance for the greedy policy
compared to queue-length based policies. In order to reduce the computational
complexity of the greedy policy, we present approximate rate allocation
policies which track the greedy policy within a certain neighborhood that is
characterized in terms of the speed of fading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1248</identifier>
 <datestamp>2008-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1248</id><created>2008-10-07</created><authors><author><keyname>ParandehGheibi</keyname><forenames>Ali</forenames></author><author><keyname>Eryilmaz</keyname><forenames>Atilla</forenames></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>Resource Allocation in Multiple Access Channels</title><categories>cs.IT cs.NI math.IT math.OC</categories><comments>5 pages, In proc. of ACSSC 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of rate allocation in a Gaussian multiple-access
channel, with the goal of maximizing a utility function over transmission
rates. In contrast to the literature which focuses on linear utility functions,
we study general concave utility functions. We present a gradient projection
algorithm for this problem. Since the constraint set of the problem is
described by exponentially many constraints, methods that use exact projections
are computationally intractable. Therefore, we develop a new method that uses
approximate projections. We use the polymatroid structure of the capacity
region to show that the approximate projection can be implemented by a
recursive algorithm in time polynomial in the number of users. We further
propose another algorithm for implementing the approximate projections using
rate-splitting and show improved bounds on its convergence time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1253</identifier>
 <datestamp>2008-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1253</id><created>2008-10-07</created><authors><author><keyname>ParandehGheibi</keyname><forenames>Ali</forenames></author><author><keyname>Eryilmaz</keyname><forenames>Atilla</forenames></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>Dynamic Rate Allocation in Fading Multiple-access Channels</title><categories>cs.IT cs.NI math.IT math.OC</categories><comments>9 pages, In proc. of ITA 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of rate allocation in a fading Gaussian
multiple-access channel (MAC) with fixed transmission powers. Our goal is to
maximize a general concave utility function of transmission rates over the
throughput capacity region. In contrast to earlier works in this context that
propose solutions where a potentially complex optimization problem must be
solved in every decision instant, we propose a low-complexity approximate rate
allocation policy and analyze the effect of temporal channel variations on its
utility performance. To the best of our knowledge, this is the first work that
studies the tracking capabilities of an approximate rate allocation scheme
under fading channel conditions. We build on an earlier work to present a new
rate allocation policy for a fading MAC that implements a low-complexity
approximate gradient projection iteration for each channel measurement, and
explicitly characterize the effect of the speed of temporal channel variations
on the tracking neighborhood of our policy. We further improve our results by
proposing an alternative rate allocation policy for which tighter bounds on the
size of the tracking neighborhood are derived. These proposed rate allocation
policies are computationally efficient in our setting since they implement a
single gradient projection iteration per channel measurement and each such
iteration relies on approximate projections which has polynomial-complexity in
the number of users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1260</identifier>
 <datestamp>2008-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1260</id><created>2008-10-07</created><authors><author><keyname>ParandehGheibi</keyname><forenames>Ali</forenames></author><author><keyname>Eryilmaz</keyname><forenames>Atilla</forenames></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>Rate and Power Allocation in Fading Multiple Access Channels</title><categories>cs.IT cs.NI math.IT math.OC</categories><comments>6 pages, In proc. of WiOpt 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of rate and power allocation in a fading
multiple-access channel. Our objective is to obtain rate and power allocation
policies that maximize a utility function defined over average transmission
rates. In contrast with the literature, which focuses on the linear case, we
present results for general concave utility functions. We consider two cases.
In the first case, we assume that power control is possible and channel
statistics are known. In this case, we show that the optimal policies can be
obtained greedily by maximizing a linear utility function at each channel
state. In the second case, we assume that power control is not possible and
channel statistics are not available. In this case, we define a greedy rate
allocation policy and provide upper bounds on the performance difference
between the optimal and the greedy policy. Our bounds highlight the dependence
of the performance difference on the channel variations and the structure of
the utility function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1261</identifier>
 <datestamp>2008-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1261</id><created>2008-10-07</created><authors><author><keyname>Nock</keyname><forenames>Richard</forenames></author><author><keyname>Vaillant</keyname><forenames>Pascal</forenames></author><author><keyname>Nielsen</keyname><forenames>Frank</forenames></author><author><keyname>Henry</keyname><forenames>Claudia</forenames></author></authors><title>Soft Uncoupling of Markov Chains for Permeable Language Distinction: A
  New Algorithm</title><categories>cs.CL cs.IR</categories><comments>6 pages, 7 embedded figures, LaTeX 2e using the ecai2006.cls document
  class and the algorithm2e.sty style file (+ standard packages like epsfig,
  amsmath, amssymb, amsfonts...). Extends the short version contained in the
  ECAI 2006 proceedings</comments><acm-class>H.3.3; I.2.7</acm-class><journal-ref>ECAI 2006: 17th European Conference on Artificial Intelligence.
  Riva del Garda, Italy, 29 August - 1st September 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Without prior knowledge, distinguishing different languages may be a hard
task, especially when their borders are permeable. We develop an extension of
spectral clustering -- a powerful unsupervised classification toolbox -- that
is shown to resolve accurately the task of soft language distinction. At the
heart of our approach, we replace the usual hard membership assignment of
spectral clustering by a soft, probabilistic assignment, which also presents
the advantage to bypass a well-known complexity bottleneck of the method.
Furthermore, our approach relies on a novel, convenient construction of a
Markov chain out of a corpus. Extensive experiments with a readily available
system clearly display the potential of the method, which brings a visually
appealing soft distinction of languages that may define altogether a whole
corpus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1267</identifier>
 <datestamp>2008-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1267</id><created>2008-10-07</created><authors><author><keyname>ParandehGheibi</keyname><forenames>Ali</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames></author><author><keyname>Eryilmaz</keyname><forenames>Atilla</forenames></author></authors><title>Information Theory vs. Queueing Theory for Resource Allocation in
  Multiple Access Channels</title><categories>cs.IT cs.NI math.IT math.OC</categories><comments>5 pages. In proc. of PIMRC 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of rate allocation in a fading Gaussian
multiple-access channel with fixed transmission powers. The goal is to maximize
a general concave utility function of the expected achieved rates of the users.
There are different approaches to this problem in the literature. From an
information theoretic point of view, rates are allocated only by using the
channel state information. The queueing theory approach utilizes the global
queue-length information for rate allocation to guarantee throughput optimality
as well as maximizing a utility function of the rates. In this work, we make a
connection between these two approaches by showing that the information
theoretic capacity region of a multiple-access channel and its stability region
are equivalent. Moreover, our numerical results show that a simple greedy
policy which does not use the queue-length information can outperform
queue-length based policies in terms of convergence rate and fairness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1268</identifier>
 <datestamp>2010-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1268</id><created>2008-10-07</created><updated>2010-09-09</updated><authors><author><keyname>Kim</keyname><forenames>Sang Joon</forenames></author><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author><author><keyname>Tarokh</keyname><forenames>Vahid</forenames></author></authors><title>Bi-directional half-duplex protocols with multiple relays</title><categories>cs.IT math.IT</categories><comments>44 pages, 17 figures, Submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a bi-directional relay channel, two nodes wish to exchange independent
messages over a shared wireless half-duplex channel with the help of relays.
Recent work has considered information theoretic limits of the bi-directional
relay channel with a single relay. In this work we consider bi-directional
relaying with multiple relays. We derive achievable rate regions and outer
bounds for half-duplex protocols with multiple decode and forward relays and
compare these to the same protocols with amplify and forward relays in an
additive white Gaussian noise channel. We consider three novel classes of
half-duplex protocols: the (m,2) 2 phase protocol with m relays, the (m,3) 3
phase protocol with m relays, and general (m, t) Multiple Hops and Multiple
Relays (MHMR) protocols, where m is the total number of relays and 3&lt;t&lt; m+3 is
the number of temporal phases in the protocol. The (m,2) and (m,3) protocols
extend previous bi-directional relaying protocols for a single m=1 relay, while
the new (m,t) protocol efficiently combines multi-hop routing with
message-level network coding. Finally, we provide a comprehensive treatment of
the MHMR protocols with decode and forward relaying and amplify and forward
relaying in the Gaussian noise, obtaining their respective achievable rate
regions, outer bounds and relative performance under different SNRs and relay
geometries, including an analytical comparison on the protocols at low and high
SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1316</identifier>
 <datestamp>2008-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1316</id><created>2008-10-07</created><authors><author><keyname>Yodaiken</keyname><forenames>Victor</forenames></author></authors><title>The meaning of concurrent programs</title><categories>cs.DM cs.OS</categories><comments>Technical report on using recursive functions for the low level
  semantics of concurrent systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The semantics of assignment and mutual exclusion in concurrent and
multi-core/multi-processor systems is presented with attention to low level
architectural features in an attempt to make the presentation realistic.
Recursive functions on event sequences are used to define state dependent
functions and variables in ordinary (non-formal-method) algebra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1319</identifier>
 <datestamp>2008-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1319</id><created>2008-10-07</created><authors><author><keyname>Ghany</keyname><forenames>Mohamed Abdel</forenames></author><author><keyname>Sultan</keyname><forenames>Ahmed</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>ARQ-Based Secret Key Sharing</title><categories>cs.IT cs.CR math.IT</categories><report-no>WINC-TR-1002</report-no><acm-class>H.1.1; E.4; K.4.4; K.6.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a novel framework for sharing secret keys using existing
Automatic Repeat reQuest (ARQ) protocols. Our approach exploits the multi-path
nature of the wireless environment to hide the key from passive eavesdroppers.
The proposed framework does not assume the availability of any prior channel
state information (CSI) and exploits only the one bit ACK/NACK feedback from
the legitimate receiver. Compared with earlier approaches, the main innovation
lies in the distribution of key bits among multiple ARQ frames. Interestingly,
this idea allows for achieving a positive secrecy rate even when the
eavesdropper experiences more favorable channel conditions, on average, than
the legitimate receiver. In the sequel, we characterize the information
theoretic limits of the proposed schemes, develop low complexity explicit
implementations, and conclude with numerical results that validate our
theoretical claims.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1355</identifier>
 <datestamp>2008-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1355</id><created>2008-10-08</created><authors><author><keyname>Leskovec</keyname><forenames>Jure</forenames></author><author><keyname>Lang</keyname><forenames>Kevin J.</forenames></author><author><keyname>Dasgupta</keyname><forenames>Anirban</forenames></author><author><keyname>Mahoney</keyname><forenames>Michael W.</forenames></author></authors><title>Community Structure in Large Networks: Natural Cluster Sizes and the
  Absence of Large Well-Defined Clusters</title><categories>cs.DS physics.data-an physics.soc-ph</categories><comments>66 pages, a much expanded version of our WWW 2008 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A large body of work has been devoted to defining and identifying clusters or
communities in social and information networks. We explore from a novel
perspective several questions related to identifying meaningful communities in
large social and information networks, and we come to several striking
conclusions. We employ approximation algorithms for the graph partitioning
problem to characterize as a function of size the statistical and structural
properties of partitions of graphs that could plausibly be interpreted as
communities. In particular, we define the network community profile plot, which
characterizes the &quot;best&quot; possible community--according to the conductance
measure--over a wide range of size scales. We study over 100 large real-world
social and information networks. Our results suggest a significantly more
refined picture of community structure in large networks than has been
appreciated previously. In particular, we observe tight communities that are
barely connected to the rest of the network at very small size scales; and
communities of larger size scales gradually &quot;blend into&quot; the expander-like core
of the network and thus become less &quot;community-like.&quot; This behavior is not
explained, even at a qualitative level, by any of the commonly-used network
generation models. Moreover, it is exactly the opposite of what one would
expect based on intuition from expander graphs, low-dimensional or
manifold-like graphs, and from small social networks that have served as
testbeds of community detection algorithms. We have found that a generative
graph model, in which new edges are added via an iterative &quot;forest fire&quot;
burning process, is able to produce graphs exhibiting a network community
profile plot similar to what we observe in our network datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1368</identifier>
 <datestamp>2008-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1368</id><created>2008-10-08</created><authors><author><keyname>Khaleghi</keyname><forenames>Ali</forenames><affiliation>IETR</affiliation></author><author><keyname>Zein</keyname><forenames>Gha&#xef;s El</forenames><affiliation>IETR</affiliation></author><author><keyname>Naqvi</keyname><forenames>Ijaz Haider</forenames><affiliation>IETR</affiliation></author></authors><title>Demonstration of Time-Reversal in Indoor Ultra-Wideband Communication:
  Time Domain Measurement</title><categories>cs.NI</categories><proxy>ccsd hal-00327074</proxy><journal-ref>IEEE International Symposium on Wireless Communication Systems
  2007, Trondheim : Norv\`ege (2007)</journal-ref><doi>10.1109/ISWCS.2007.4392383</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using time domain measurements, we assess the feasibility of time-reversal
technique in ultra-wideband (UWB) communication. A typical indoor propagation
channel is selected for the exploration. The channel response between receive
and transmit antenna pairs is measured using time domain equipments which
include an arbitrary wave generator (AWG) and a digital storage oscilloscope
(DSO). The time-reversed version of the channel response is constructed with
AWG and re-transmitted in the channel. The equivalent time reversed channel
response is recorded. The properties of the time reversal technique in the line
of sight (LOS) co-polar and cross-polar scenarios are measured.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1383</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1383</id><created>2008-10-08</created><updated>2009-07-24</updated><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>Est&#xe9;vez-Fern&#xe1;ndez</keyname><forenames>Arantza</forenames></author></authors><title>Sequential pivotal mechanisms for public project problems</title><categories>cs.GT</categories><comments>19 pages. The version without the appendix will appear in the Proc.
  2nd International Symposium on Algorithmic Game Theory, 2009</comments><doi>10.1007/978-3-642-04645-2_9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well-known that for several natural decision problems no budget
balanced Groves mechanisms exist. This has motivated recent research on
designing variants of feasible Groves mechanisms (termed as `redistribution of
VCG (Vickrey-Clarke-Groves) payments') that generate reduced deficit. With this
in mind, we study sequential mechanisms and consider optimal strategies that
could reduce the deficit resulting under the simultaneous mechanism. We show
that such strategies exist for the sequential pivotal mechanism of the
well-known public project problem. We also exhibit an optimal strategy with the
property that a maximal social welfare is generated when each player follows
it. Finally, we show that these strategies can be achieved by an implementation
in Nash equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1424</identifier>
 <datestamp>2008-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1424</id><created>2008-10-08</created><authors><author><keyname>Dey</keyname><forenames>Bikash Kumar</forenames></author><author><keyname>Jaggi</keyname><forenames>Sidharth</forenames></author><author><keyname>Langberg</keyname><forenames>Michael</forenames></author></authors><title>&quot;Real&quot; Slepian-Wolf Codes</title><categories>cs.IT math.IT</categories><comments>20 pages. Preliminary version presented at ISIT 2008, Toronto, Canada</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a novel achievability proof of the Slepian-Wolf theorem for i.i.d.
sources over finite alphabets. We demonstrate that random codes that are linear
over the real field achieve the classical Slepian-Wolf rate-region. For finite
alphabets we show that typicality decoding is equivalent to solving an integer
program. Minimum entropy decoding is also shown to achieve exponentially small
probability of error. The techniques used may be of independent interest for
code design for a wide class of information theory problems, and for the field
of compressed sensing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1430</identifier>
 <datestamp>2008-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1430</id><created>2008-10-08</created><authors><author><keyname>Mehanna</keyname><forenames>Omar</forenames></author><author><keyname>Sultan</keyname><forenames>Ahmed</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>Blind Cognitive MAC Protocols</title><categories>cs.NI cs.LG</categories><comments>5 pages, submitted to ICC'09</comments><acm-class>C.2.2; I.2.6; I.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the design of cognitive Medium Access Control (MAC) protocols
enabling an unlicensed (secondary) transmitter-receiver pair to communicate
over the idle periods of a set of licensed channels, i.e., the primary network.
The objective is to maximize data throughput while maintaining the
synchronization between secondary users and avoiding interference with licensed
(primary) users. No statistical information about the primary traffic is
assumed to be available a-priori to the secondary user. We investigate two
distinct sensing scenarios. In the first, the secondary transmitter is capable
of sensing all the primary channels, whereas it senses one channel only in the
second scenario. In both cases, we propose MAC protocols that efficiently learn
the statistics of the primary traffic online. Our simulation results
demonstrate that the proposed blind protocols asymptotically achieve the
throughput obtained when prior knowledge of primary traffic statistics is
available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1481</identifier>
 <datestamp>2009-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1481</id><created>2008-10-08</created><updated>2008-12-30</updated><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author><author><keyname>Geldart</keyname><forenames>Joe</forenames></author></authors><title>An Evidential Path Logic for Multi-Relational Networks</title><categories>cs.LO cs.SC</categories><report-no>LA-UR-08-06397</report-no><acm-class>I.2.4</acm-class><journal-ref>Proceedings of the Association for the Advancement of Artificial
  Intelligence Spring Symposium: Technosocial Predictive Analytics, volume
  SS-09-09, pages 114-119, ISBN:978-1-57735-416-1, AAAI Press, Stanford
  University, March 2009.</journal-ref><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Multi-relational networks are used extensively to structure knowledge.
Perhaps the most popular instance, due to the widespread adoption of the
Semantic Web, is the Resource Description Framework (RDF). One of the primary
purposes of a knowledge network is to reason; that is, to alter the topology of
the network according to an algorithm that uses the existing topological
structure as its input. There exist many such reasoning algorithms. With
respect to the Semantic Web, the bivalent, monotonic reasoners of the RDF
Schema (RDFS) and the Web Ontology Language (OWL) are the most prevalent.
However, nothing prevents other forms of reasoning from existing in the
Semantic Web. This article presents a non-bivalent, non-monotonic, evidential
logic and reasoner that is an algebraic ring over a multi-relational network
equipped with two binary operations that can be composed to execute various
forms of inference. Given its multi-relational grounding, it is possible to use
the presented evidential framework as another method for structuring knowledge
and reasoning in the Semantic Web. The benefits of this framework are that it
works with arbitrary, partial, and contradictory knowledge while, at the same
time, it supports a tractable approximate reasoning process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1499</identifier>
 <datestamp>2008-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1499</id><created>2008-10-08</created><updated>2008-12-04</updated><authors><author><keyname>Zdeborov&#xe1;</keyname><forenames>Lenka</forenames></author><author><keyname>M&#xe9;zard</keyname><forenames>Marc</forenames></author></authors><title>Constraint satisfaction problems with isolated solutions are hard</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.CC cs.DS</categories><comments>19 pages, 12 figures</comments><journal-ref>J. Stat. Mech. (2008) P12004</journal-ref><doi>10.1088/1742-5468/2008/12/P12004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the phase diagram and the algorithmic hardness of the random
`locked' constraint satisfaction problems, and compare them to the commonly
studied 'non-locked' problems like satisfiability of boolean formulas or graph
coloring. The special property of the locked problems is that clusters of
solutions are isolated points. This simplifies significantly the determination
of the phase diagram, which makes the locked problems particularly appealing
from the mathematical point of view. On the other hand we show empirically that
the clustered phase of these problems is extremely hard from the algorithmic
point of view: the best known algorithms all fail to find solutions. Our
results suggest that the easy/hard transition (for currently known algorithms)
in the locked problems coincides with the clustering transition. These should
thus be regarded as new benchmarks of really hard constraint satisfaction
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1506</identifier>
 <datestamp>2008-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1506</id><created>2008-10-08</created><authors><author><keyname>Naqvi</keyname><forenames>Ijaz Haider</forenames><affiliation>IETR</affiliation></author><author><keyname>Khaleghi</keyname><forenames>Ali</forenames><affiliation>IETR</affiliation></author><author><keyname>Zein</keyname><forenames>Gha&#xef;s El</forenames><affiliation>IETR</affiliation></author></authors><title>Performance Enhancement of Multiuser Time Reversal UWB Communication
  System</title><categories>cs.NI</categories><proxy>ccsd hal-00327076</proxy><journal-ref>IEEE International Symposium on Wireless Communication Systems
  2007, Trondheim : Norv\`ege (2007)</journal-ref><doi>10.1109/ISWCS.2007.4392404</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  UWB communication is a recent research area for indoor propagation channels.
Time Reversal (TR) communication in UWB has shown promising results for
improving the system performance. In multiuser environment, the system
performance is significantly degraded due to the interference among different
users. TR reduces the interference caused by multiusers due to its spatial
focusing property. The performance of a multiuser TR communication system is
further improved if the TR filter is modified. In this paper, multiuser TR in
UWB communication is investigated using simple TR filter and a modified TR
filter with circular shift operation. The concept of circular shift in TR is
analytically studied. Thereafter, the channel impulse responses (CIR) of a
typical indoor laboratory environment are measured. The measured CIRs are used
to analyze the received signal peak power and signal to interference ratio
(SIR) with and without performing the circular shift operation in a multiuser
environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1513</identifier>
 <datestamp>2008-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1513</id><created>2008-10-08</created><authors><author><keyname>Naqvi</keyname><forenames>Ijaz Haider</forenames><affiliation>IETR</affiliation></author><author><keyname>P&#xe9;rennou</keyname><forenames>Tanguy</forenames><affiliation>LAAS</affiliation></author></authors><title>A DCCP Congestion Control Mechanism for Wired- cum-Wireless Environments</title><categories>cs.NI</categories><proxy>ccsd hal-00327080</proxy><journal-ref>IEEE Wireless Communications and Networking Conference, Hong-Kong
  (2007)</journal-ref><doi>10.1109/WCNC.2007.715</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing transport protocols, be it TCP, SCTP or DCCP, do not provide an
efficient congestion control mechanism for heterogeneous wired-cum-wireless
networks. Solutions involving implicit loss discrimination schemes have been
proposed but were never implemented. Appropriate mechanisms can dramatically
improve bandwidth usage over the Internet, especially for multimedia transport
based on partial reliability. In this paper we have implemented and evaluated a
congestion control mechanism that implicitly discriminates congestion and
wireless losses in the datagram congestion control protocol (DCCP) congestion
control identification (CCID) framework. The new CCID was implemented as a NS-2
module. Comparisons were made with the TCP-like CCID and showed that the
bandwidth utilization was improved by more than 30% and up to 50% in
significant setups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1571</identifier>
 <datestamp>2010-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1571</id><created>2008-10-09</created><authors><author><keyname>Bakhshi</keyname><forenames>Rena</forenames></author><author><keyname>Gavidia</keyname><forenames>Daniela</forenames></author><author><keyname>Fokkink</keyname><forenames>Wan</forenames></author><author><keyname>van Steen</keyname><forenames>Maarten</forenames></author></authors><title>An Analytical Model of Information Dissemination for a Gossip-based
  Protocol</title><categories>cs.DC cs.DM cs.IT cs.PF math.IT</categories><comments>20 pages, 8 figures, technical report</comments><doi>10.1016/j.comnet.2009.03.017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop an analytical model of information dissemination for a gossiping
protocol that combines both pull and push approaches. With this model we
analyse how fast an item is replicated through a network, and how fast the item
spreads in the network, and how fast the item covers the network. We also
determine the optimal size of the exchange buffer, to obtain fast replication.
Our results are confirmed by large-scale simulation experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1574</identifier>
 <datestamp>2008-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1574</id><created>2008-10-09</created><authors><author><keyname>Feng</keyname><forenames>Ruyong</forenames></author><author><keyname>Singer</keyname><forenames>Michael F.</forenames></author><author><keyname>Wu</keyname><forenames>Min</forenames></author></authors><title>Liouvillian Solutions of Difference-Differential Equations</title><categories>cs.SC math.CA</categories><comments>53 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a field k$with an automorphism \sigma and a derivation \delta, we
introduce the notion of liouvillian solutions of linear difference-differential
systems {\sigma(Y) = AY, \delta(Y) = BY} over k and characterize the existence
of liouvillian solutions in terms of the Galois group of the systems. We will
give an algorithm to decide whether such a system has liouvillian solutions
when k = C(x,t), \sigma(x) = x+1, \delta = d/dt$ and the size of the system is
a prime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1624</identifier>
 <datestamp>2008-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1624</id><created>2008-10-09</created><authors><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Bezman</keyname><forenames>Genia</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author><author><keyname>Pinkas</keyname><forenames>Benny</forenames></author></authors><title>Peer-to-Peer Secure Multi-Party Numerical Computation</title><categories>cs.CR cs.DC</categories><comments>10 pages, 2 figures, appeared in the 8th IEEE Peer-to-Peer Computing,
  Aachen, Germany, Sept. 2008</comments><acm-class>C.2.4</acm-class><journal-ref>The 8th IEEE Peer-to-Peer Computing (P2P 2008), Aachen, Germany,
  Sept. 2008</journal-ref><doi>10.1109/P2P.2008.22</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an efficient framework for enabling secure multi-party numerical
computations in a Peer-to-Peer network. This problem arises in a range of
applications such as collaborative filtering, distributed computation of trust
and reputation, monitoring and numerous other tasks, where the computing nodes
would like to preserve the privacy of their inputs while performing a joint
computation of a certain function.
  Although there is a rich literature in the field of distributed systems
security concerning secure multi-party computation, in practice it is hard to
deploy those methods in very large scale Peer-to-Peer networks. In this work,
we examine several possible approaches and discuss their feasibility. Among the
possible approaches, we identify a single approach which is both scalable and
theoretically secure.
  An additional novel contribution is that we show how to compute the
neighborhood based collaborative filtering, a state-of-the-art collaborative
filtering algorithm, winner of the Netflix progress prize of the year 2007. Our
solution computes this algorithm in a Peer-to-Peer network, using a privacy
preserving computation, without loss of accuracy.
  Using extensive large scale simulations on top of real Internet topologies,
we demonstrate the applicability of our approach. As far as we know, we are the
first to implement such a large scale secure multi-party simulation of networks
of millions of nodes and hundreds of millions of edges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1628</identifier>
 <datestamp>2009-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1628</id><created>2008-10-09</created><authors><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Shental</keyname><forenames>Ori</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author></authors><title>Distributed Kalman Filter via Gaussian Belief Propagation</title><categories>cs.IT math.IT</categories><comments>8 pages, 3 figures, appeared in the 46th Annual Allerton Conference
  on Communication, Control and Computing, Allerton House, Illinois, Sept. 2008</comments><acm-class>E.5</acm-class><journal-ref>The 46th Annual Allerton Conference on Communication, Control and
  Computing, Allerton House, Illinois, Sept. 2008</journal-ref><doi>10.1109/ALLERTON.2008.4797617</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent result shows how to compute distributively and efficiently the linear
MMSE for the multiuser detection problem, using the Gaussian BP algorithm. In
the current work, we extend this construction, and show that operating this
algorithm twice on the matching inputs, has several interesting
interpretations. First, we show equivalence to computing one iteration of the
Kalman filter. Second, we show that the Kalman filter is a special case of the
Gaussian information bottleneck algorithm, when the weight parameter $\beta =
1$. Third, we discuss the relation to the Affine-scaling interior-point method
and show it is a special case of Kalman filter.
  Besides of the theoretical interest of this linking estimation,
compression/clustering and optimization, we allow a single distributed
implementation of those algorithms, which is a highly practical and important
task in sensor and mobile ad-hoc networks. Application to numerous problem
domains includes collaborative signal processing and distributed allocation of
resources in a communication network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1631</identifier>
 <datestamp>2009-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1631</id><created>2008-10-09</created><authors><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Tock</keyname><forenames>Yoav</forenames></author><author><keyname>Shental</keyname><forenames>Ori</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author></authors><title>Polynomial Linear Programming with Gaussian Belief Propagation</title><categories>cs.IT math.IT</categories><comments>7 pages, 1 figure, appeared in the 46th Annual Allerton Conference on
  Communication, Control and Computing, Allerton House, Illinois, Sept. 2008</comments><acm-class>E.5</acm-class><journal-ref>The 46th Annual Allerton Conference on Communication, Control and
  Computing, Allerton House, Illinois, Sept. 2008</journal-ref><doi>10.1109/ALLERTON.2008.4797652</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interior-point methods are state-of-the-art algorithms for solving linear
programming (LP) problems with polynomial complexity. Specifically, the
Karmarkar algorithm typically solves LP problems in time O(n^{3.5}), where $n$
is the number of unknown variables. Karmarkar's celebrated algorithm is known
to be an instance of the log-barrier method using the Newton iteration. The
main computational overhead of this method is in inverting the Hessian matrix
of the Newton iteration. In this contribution, we propose the application of
the Gaussian belief propagation (GaBP) algorithm as part of an efficient and
distributed LP solver that exploits the sparse and symmetric structure of the
Hessian matrix and avoids the need for direct matrix inversion. This approach
shifts the computation from realm of linear algebra to that of probabilistic
inference on graphical models, thus applying GaBP as an efficient inference
engine. Our construction is general and can be used for any interior-point
algorithm which uses the Newton method, including non-linear program solvers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1639</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1639</id><created>2008-10-09</created><authors><author><keyname>Istrate</keyname><forenames>Gabriel</forenames></author></authors><title>Identifying almost sorted permutations from TCP buffer dynamics</title><categories>cs.DS cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Associate to each sequence $A$ of integers (intending to represent packet
IDs) a sequence of positive integers of the same length ${\mathcal M}(A)$. The
$i$'th entry of ${\mathcal M}(A)$ is the size (at time $i$) of the smallest
buffer needed to hold out-of-order packets, where space is accounted for
unreceived packets as well. Call two sequences $A$, $B$ {\em equivalent}
(written $A\equiv_{FB} B$) if ${\mathcal M}(A)={\mathcal M}(B)$.
  We prove the following result: any two permutations $A,B$ of the same length
with $SUS(A)$, $SUS(B)\leq 3$ (where SUS is the {\em shuffled-up-sequences}
reordering measure), and such that $A\equiv_{FB} B$ are identical.
  The result (which is no longer valid if we replace the upper bound 3 by 4)
was motivated by RESTORED, a receiver-oriented model of network traffic we have
previously introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1648</identifier>
 <datestamp>2008-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1648</id><created>2008-10-09</created><authors><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Yom-Tov</keyname><forenames>Elad</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author></authors><title>A Gaussian Belief Propagation Solver for Large Scale Support Vector
  Machines</title><categories>cs.LG cs.IT math.IT</categories><comments>12 pages, 1 figure, appeared in the 5th European Complex Systems
  Conference, Jerusalem, Sept. 2008</comments><acm-class>I.2.6</acm-class><journal-ref>The 5th European Complex Systems Conference (ECCS 2008),
  Jerusalem, Sept. 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Support vector machines (SVMs) are an extremely successful type of
classification and regression algorithms. Building an SVM entails solving a
constrained convex quadratic programming problem, which is quadratic in the
number of training samples. We introduce an efficient parallel implementation
of an support vector regression solver, based on the Gaussian Belief
Propagation algorithm (GaBP).
  In this paper, we demonstrate that methods from the complex system domain
could be utilized for performing efficient distributed computation. We compare
the proposed algorithm to previously proposed distributed and single-node SVM
solvers. Our comparison shows that the proposed algorithm is just as accurate
as these solvers, while being significantly faster, especially for large
datasets. We demonstrate scalability of the proposed algorithm to up to 1,024
computing nodes and hundreds of thousands of data points using an IBM Blue Gene
supercomputer. As far as we know, our work is the largest parallel
implementation of belief propagation ever done, demonstrating the applicability
of this algorithm for large scale distributed computing systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1650</identifier>
 <datestamp>2008-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1650</id><created>2008-10-09</created><authors><author><keyname>Agnetis</keyname><forenames>Alessandro</forenames></author><author><keyname>Grande</keyname><forenames>Enrico</forenames></author><author><keyname>Pacifici</keyname><forenames>Andrea</forenames></author></authors><title>Demand allocation with latency cost functions</title><categories>cs.DM cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the exact resolution of a MINLP model where resources can be
activated in order to satisfy a demand (a partitioning constraint) while
minimizing total cost. Cost functions are convex latency functions plus a fixed
activation cost. A branch and bound algorithm is devised, featuring three
important characteristics. First, the lower bound (therefore each subproblem)
can be computed in O(nlog n). Second, to break symmetries resulting in improved
efficiency, the branching scheme is n-ary (instead of the &quot;classical&quot; binary).
Third, a very affective heuristic is used to compute a good upper bound at the
root node of the enumeration tree. All three features lead to a successful
comparison against CPLEX MIPQ, which is the fastest among several commercial
and open-source solvers: computational results showing this fact are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1655</identifier>
 <datestamp>2008-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1655</id><created>2008-10-09</created><authors><author><keyname>Burkhart</keyname><forenames>Martin</forenames></author><author><keyname>Brauckhoff</keyname><forenames>Daniela</forenames></author><author><keyname>May</keyname><forenames>Martin</forenames></author></authors><title>On the Utility of Anonymized Flow Traces for Anomaly Detection</title><categories>cs.NI</categories><journal-ref>Proceedings of the 19th ITC Specialist Seminar on Network Usage
  and Traffic (ITC SS 19), October 2008, Berlin, Germany</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sharing of network traces is an important prerequisite for the
development and evaluation of efficient anomaly detection mechanisms.
Unfortunately, privacy concerns and data protection laws prevent network
operators from sharing these data. Anonymization is a promising solution in
this context; however, it is unclear if the sanitization of data preserves the
traffic characteristics or introduces artifacts that may falsify traffic
analysis results. In this paper, we examine the utility of anonymized flow
traces for anomaly detection. We quantitatively evaluate the impact of IP
address anonymization, namely variations of permutation and truncation, on the
detectability of large-scale anomalies. Specifically, we analyze three weeks of
un-sampled and non-anonymized network traces from a medium-sized backbone
network. We find that all anonymization techniques, except prefix-preserving
permutation, degrade the utility of data for anomaly detection. We show that
the degree of degradation depends to a large extent on the nature and mix of
anomalies present in a trace. Moreover, we present a case study that
illustrates how traffic characteristics of individual hosts are distorted by
anonymization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1729</identifier>
 <datestamp>2009-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1729</id><created>2008-10-09</created><authors><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author><author><keyname>Shental</keyname><forenames>Ori</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author><author><keyname>Wolf</keyname><forenames>Jack K.</forenames></author></authors><title>Gaussian Belief Propagation Based Multiuser Detection</title><categories>cs.IT math.IT</categories><comments>6 pages, 1 figures, appeared in the 2008 IEEE International Symposium
  on Information Theory, Toronto, July 2008</comments><acm-class>E.5</acm-class><journal-ref>The 2008 IEEE International Symposium on Information Theory (ISIT
  2008), Toronto, July 2008</journal-ref><doi>10.1109/ISIT.2008.4595314</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we present a novel construction for solving the linear
multiuser detection problem using the Gaussian Belief Propagation algorithm.
Our algorithm yields an efficient, iterative and distributed implementation of
the MMSE detector. We compare our algorithm's performance to a recent result
and show an improved memory consumption, reduced computation steps and a
reduction in the number of sent messages. We prove that recent work by
Montanari et al. is an instance of our general algorithm, providing new
convergence results for both algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1732</identifier>
 <datestamp>2008-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1732</id><created>2008-10-09</created><authors><author><keyname>Frenz</keyname><forenames>Christopher M.</forenames></author></authors><title>Introduction to Searching with Regular Expressions</title><categories>cs.IR</categories><comments>13 pages. From the Proceedings of the 2008 Trenton Computer Festival</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The explosive rate of information growth and availability often makes it
increasingly difficult to locate information pertinent to your needs. These
problems are often compounded when keyword based search methodologies are not
adequate for describing the information you seek. In many instances,
information such as Web site URLs, phone numbers, etc. can often be better
identified through the use of a textual pattern than by keyword. For example,
many more phone numbers could be picked up by a search for the pattern (XXX)
XXX-XXXX, where X could be any digit, than would be by a search for any
specific phone number (i.e. the keyword approach). Programming languages
typically allow for the matching of textual patterns via the usage of regular
expressions. This tutorial will provide an introduction to the basics of
programming regular expressions as well as provide an introduction to how
regular expressions can be applied to data processing tasks such as information
extraction and search refinement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1735</identifier>
 <datestamp>2008-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1735</id><created>2008-10-09</created><authors><author><keyname>Kim</keyname><forenames>MinJi</forenames></author><author><keyname>Sundararajan</keyname><forenames>Jay Kumar</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Eryilmaz</keyname><forenames>Atilla</forenames></author><author><keyname>Koetter</keyname><forenames>Ralf</forenames></author></authors><title>Network Coding in a Multicast Switch</title><categories>cs.NI cs.IT math.IT</categories><comments>26 pages, 27 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of serving multicast flows in a crossbar switch is considered.
Intra-flow linear network coding is shown to achieve a larger rate region than
the case without coding. A traffic pattern is presented which is achievable
with coding but requires a switch speedup when coding is not allowed. The rate
region with coding can be characterized in a simple graph-theoretic manner, in
terms of the stable set polytope of the &quot;enhanced conflict graph&quot;. No such
graph-theoretic characterization is known for the case of fanout splitting
without coding.
  The minimum speedup needed to achieve 100% throughput with coding is shown to
be upper bounded by the imperfection ratio of the enhanced conflict graph. When
applied to KxN switches with unicasts and broadcasts only, this gives a bound
of min{(2K-1)/K,2N/(N+1)} on the speedup. This shows that speedup, which is
usually implemented in hardware, can often be substituted by network coding,
which can be done in software.
  Computing an offline schedule (using prior knowledge of the flow rates) is
reduced to fractional weighted graph coloring. A graph-theoretic online
scheduling algorithm (using only queue occupancy information) is also proposed,
that stabilizes the queues for all rates within the rate region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1736</identifier>
 <datestamp>2009-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1736</id><created>2008-10-09</created><authors><author><keyname>Shental</keyname><forenames>Ori</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author><author><keyname>Wolf</keyname><forenames>Jack K.</forenames></author><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author></authors><title>Gaussian Belief Propagation Solver for Systems of Linear Equations</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, appeared in the 2008 IEEE International Symposium
  on Information Theory, Toronto, July 2008</comments><acm-class>E.5</acm-class><journal-ref>The 2008 IEEE International Symposium on Information Theory (ISIT
  2008), Toronto, July 2008</journal-ref><doi>10.1109/ISIT.2008.4595311</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The canonical problem of solving a system of linear equations arises in
numerous contexts in information theory, communication theory, and related
fields. In this contribution, we develop a solution based upon Gaussian belief
propagation (GaBP) that does not involve direct matrix inversion. The iterative
nature of our approach allows for a distributed message-passing implementation
of the solution algorithm. We also address some properties of the GaBP solver,
including convergence, exactness, its max-product version and relation to
classical solution methods. The application example of decorrelation in CDMA is
used to demonstrate the faster convergence rate of the proposed solver in
comparison to conventional linear-algebraic iterative solution methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1756</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1756</id><created>2008-10-09</created><updated>2012-02-13</updated><authors><author><keyname>Bradonjic</keyname><forenames>Milan</forenames></author><author><keyname>Kohler</keyname><forenames>Eddie</forenames></author><author><keyname>Ostrovsky</keyname><forenames>Rafail</forenames></author></authors><title>Near-Optimal Radio Use For Wireless Network Synchronization</title><categories>cs.DS cs.DM</categories><comments>23 pages</comments><doi>10.1016/j.tcs.2011.09.026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the model of communication where wireless devices can either
switch their radios off to save energy, or switch their radios on and engage in
communication. We distill a clean theoretical formulation of this problem of
minimizing radio use and present near-optimal solutions. Our base model ignores
issues of communication interference, although we also extend the model to
handle this requirement. We assume that nodes intend to communicate
periodically, or according to some time-based schedule. Clearly, perfectly
synchronized devices could switch their radios on for exactly the minimum
periods required by their joint schedules. The main challenge in the deployment
of wireless networks is to synchronize the devices' schedules, given that their
initial schedules may be offset relative to one another (even if their clocks
run at the same speed). We significantly improve previous results, and show
optimal use of the radio for two processors and near-optimal use of the radio
for synchronization of an arbitrary number of processors. In particular, for
two processors we prove deterministically matching $\Theta(\sqrt{n})$ upper and
lower bounds on the number of times the radio has to be on, where $n$ is the
discretized uncertainty period of the clock shift between the two processors.
(In contrast, all previous results for two processors are randomized.) For
$m=n^\beta$ processors (for any $\beta &lt; 1$) we prove $\Omega(n^{(1-\beta)/2})$
is the lower bound on the number of times the radio has to be switched on (per
processor), and show a nearly matching (in terms of the radio use)
$\~{O}(n^{(1-\beta)/2})$ randomized upper bound per processor, with failure
probability exponentially close to 0. For $\beta \geq 1$ our algorithm runs
with at most $poly-log(n)$ radio invocations per processor. Our bounds also
hold in a radio-broadcast model where interference must be taken into account.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1773</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1773</id><created>2008-10-09</created><authors><author><keyname>Sayag</keyname><forenames>Eitan</forenames></author><author><keyname>Leshem</keyname><forenames>Amir</forenames></author><author><keyname>Sidiropoulos</keyname><forenames>Nikolaos D.</forenames></author></authors><title>Finite Word Length Effects on Transmission Rate in Zero Forcing Linear
  Precoding for Multichannel DSL</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2009.2012889</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crosstalk interference is the limiting factor in transmission over copper
lines. Crosstalk cancelation techniques show great potential for enabling the
next leap in DSL transmission rates. An important issue when implementing
crosstalk cancelation techniques in hardware is the effect of finite world
length on performance. In this paper we provide an analysis of the performance
of linear zero-forcing precoders, used for crosstalk compensation, in the
presence of finite word length errors. We quantify analytically the trade off
between precoder word length and transmission rate degradation. More
specifically, we prove a simple formula for the transmission rate loss as a
function of the number of bits used for precoding, the signal to noise ratio,
and the standard line parameters. We demonstrate, through simulations on real
lines, the accuracy of our estimates. Moreover, our results are stable in the
presence of channel estimation errors. Finally, we show how to use these
estimates as a design tool for DSL linear crosstalk precoders. For example, we
show that for standard VDSL2 precoded systems, 14 bits representation of the
precoder entries results in capacity loss below 1% for lines over 300m.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1808</identifier>
 <datestamp>2008-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1808</id><created>2008-10-10</created><authors><author><keyname>Kammoun</keyname><forenames>Abla</forenames><affiliation>LTCI</affiliation></author><author><keyname>Kharouf</keyname><forenames>Malika</forenames><affiliation>LTCI</affiliation></author><author><keyname>Hachem</keyname><forenames>Walid</forenames><affiliation>LTCI</affiliation></author><author><keyname>Najim</keyname><forenames>Jamal</forenames><affiliation>LTCI</affiliation></author></authors><title>A Central Limit Theorem for the SINR at the LMMSE Estimator Output for
  Large Dimensional Signals</title><categories>cs.IT math.IT</categories><proxy>ccsd hal-00328163</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is devoted to the performance study of the Linear Minimum Mean
Squared Error estimator for multidimensional signals in the large dimension
regime. Such an estimator is frequently encountered in wireless communications
and in array processing, and the Signal to Interference and Noise Ratio (SINR)
at its output is a popular performance index. The SINR can be modeled as a
random quadratic form which can be studied with the help of large random matrix
theory, if one assumes that the dimension of the received and transmitted
signals go to infinity at the same pace. This paper considers the asymptotic
behavior of the SINR for a wide class of multidimensional signal models that
includes general multi-antenna as well as spread spectrum transmission models.
  The expression of the deterministic approximation of the SINR in the large
dimension regime is recalled and the SINR fluctuations around this
deterministic approximation are studied. These fluctuations are shown to
converge in distribution to the Gaussian law in the large dimension regime, and
their variance is shown to decrease as the inverse of the signal dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1823</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1823</id><created>2008-10-10</created><updated>2011-04-18</updated><authors><author><keyname>Gioan</keyname><forenames>Emeric</forenames></author><author><keyname>Paul</keyname><forenames>Christophe</forenames></author></authors><title>Split decomposition and graph-labelled trees: characterizations and
  fully-dynamic algorithms for totally decomposable graphs</title><categories>cs.DM cs.DS</categories><comments>extended abstract appeared in ISAAC 2007: Dynamic distance hereditary
  graphs using split decompositon. In International Symposium on Algorithms and
  Computation - ISAAC. Number 4835 in Lecture Notes, pages 41-51, 2007</comments><acm-class>G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we revisit the split decomposition of graphs and give new
combinatorial and algorithmic results for the class of totally decomposable
graphs, also known as the distance hereditary graphs, and for two non-trivial
subclasses, namely the cographs and the 3-leaf power graphs. Precisely, we give
strutural and incremental characterizations, leading to optimal fully-dynamic
recognition algorithms for vertex and edge modifications, for each of these
classes. These results rely on a new framework to represent the split
decomposition, namely the graph-labelled trees, which also captures the modular
decomposition of graphs and thereby unify these two decompositions techniques.
The point of the paper is to use bijections between these graph classes and
trees whose nodes are labelled by cliques and stars. Doing so, we are also able
to derive an intersection model for distance hereditary graphs, which answers
an open problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1851</identifier>
 <datestamp>2008-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1851</id><created>2008-10-10</created><authors><author><keyname>Berman</keyname><forenames>Piotr</forenames></author><author><keyname>Karpinski</keyname><forenames>Marek</forenames></author><author><keyname>Zelikovsky</keyname><forenames>Alex</forenames></author></authors><title>1.25 Approximation Algorithm for the Steiner Tree Problem with Distances
  One and Two</title><categories>cs.CC cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a 1.25 approximation algorithm for the Steiner Tree Problem with
distances one and two, improving on the best known bound for that problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1858</identifier>
 <datestamp>2008-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1858</id><created>2008-10-10</created><authors><author><keyname>Berbain</keyname><forenames>Come</forenames><affiliation>FT R&amp;D</affiliation></author><author><keyname>Billet</keyname><forenames>Olivier</forenames><affiliation>FT R&amp;D</affiliation></author><author><keyname>Canteaut</keyname><forenames>Anne</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Courtois</keyname><forenames>Nicolas</forenames><affiliation>FT R&amp;D</affiliation></author><author><keyname>Gilbert</keyname><forenames>Henri</forenames><affiliation>FT R&amp;D</affiliation></author><author><keyname>Goubin</keyname><forenames>Louis</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Gouget</keyname><forenames>Aline</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Granboulan</keyname><forenames>Louis</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Lauradoux</keyname><forenames>Cedric</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Minier</keyname><forenames>Marine</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Pornin</keyname><forenames>Thomas</forenames></author><author><keyname>Sibert</keyname><forenames>Herve</forenames></author></authors><title>SOSEMANUK: a fast software-oriented stream cipher</title><categories>cs.CR</categories><proxy>ccsd hal-00328825</proxy><journal-ref>New Stream Cipher Designs - The eSTREAM finalists (2008) 98-118</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sosemanuk is a new synchronous software-oriented stream cipher, corresponding
to Profile 1 of the ECRYPT call for stream cipher primitives. Its key length is
variable between 128 and 256 bits. It ac- commodates a 128-bit initial value.
Any key length is claimed to achieve 128-bit security. The Sosemanuk cipher
uses both some basic design principles from the stream cipher SNOW 2.0 and some
transformations derived from the block cipher SERPENT. Sosemanuk aims at
improv- ing SNOW 2.0 both from the security and from the efficiency points of
view. Most notably, it uses a faster IV-setup procedure. It also requires a
reduced amount of static data, yielding better performance on several
architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1904</identifier>
 <datestamp>2008-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1904</id><created>2008-10-10</created><authors><author><keyname>Gebauer</keyname><forenames>Heidi</forenames></author></authors><title>Unsatisfiable (k,(4*2^k/k))-CNF formulas</title><categories>cs.DM cs.GT</categories><comments>3 pages, 1 figure</comments><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A boolean formula in a conjuctive normal form is called a (k,s)-formula if
every clause contains exactly k variables and every variable occurs in at most
s clauses. We prove the existence of a (k, 4 * (2^k/k))-CNF formula which is
unsatisfiable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1973</identifier>
 <datestamp>2008-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1973</id><created>2008-10-10</created><authors><author><keyname>Jana</keyname><forenames>Soumya</forenames></author></authors><title>Alphabet Sizes of Auxiliary Variables in Canonical Inner Bounds</title><categories>cs.IT math.IT</categories><comments>20 pages, no figures, explanation of a part of impending IEEE IT
  submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alphabet size of auxiliary random variables in our canonical description is
derived. Our analysis improves upon estimates known in special cases, and
generalizes to an arbitrary multiterminal setup. The salient steps include
decomposition of constituent rate polytopes into orthants, translation of a
hyperplane till it becomes tangent to the achievable region at an extreme
point, and derivation of minimum auxiliary alphabet sizes based on
Caratheodory's theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1980</identifier>
 <datestamp>2008-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1980</id><created>2008-10-10</created><authors><author><keyname>Etkin</keyname><forenames>Raul</forenames></author><author><keyname>Merhav</keyname><forenames>Neri</forenames></author><author><keyname>Ordentlich</keyname><forenames>Erik</forenames></author></authors><title>Error Exponents of Optimum Decoding for the Interference Channel</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, Oct 7, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Exponential error bounds for the finite-alphabet interference channel (IFC)
with two transmitter-receiver pairs, are investigated under the random coding
regime. Our focus is on optimum decoding, as opposed to heuristic decoding
rules that have been used in previous works, like joint typicality decoding,
decoding based on interference cancellation, and decoding that considers the
interference as additional noise. Indeed, the fact that the actual interfering
signal is a codeword and not an i.i.d. noise process complicates the
application of conventional techniques to the performance analysis of the
optimum decoder. Using analytical tools rooted in statistical physics, we
derive a single letter expression for error exponents achievable under optimum
decoding and demonstrate strict improvement over error exponents obtainable
using suboptimal decoding rules, but which are amenable to more conventional
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1981</identifier>
 <datestamp>2008-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1981</id><created>2008-10-10</created><authors><author><keyname>Gebauer</keyname><forenames>Heidi</forenames></author></authors><title>Disproving the Neighborhood Conjecture</title><categories>cs.GT cs.DM</categories><comments>14 pages, 3 figures</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the following Maker/Breaker game. Maker and Breaker take turns in
choosing vertices from a given n-uniform hypergraph F, with Maker going first.
Maker's goal is to completely occupy a hyperedge and Breaker tries to avoid
this. Beck conjectures that if the maximum neighborhood size of F is at most
2^(n-1) then Breaker has a winning strategy. We disprove this conjecture by
establishing an n-uniform hypergraph with maximum neighborhood size 3*2^(n-3)
where Maker has a winning strategy. Moreover, we show how to construct an
n-uniform hypergraph with maximum degree 2^(n-1)/n where Maker has a winning
strategy. Finally we show that each n-uniform hypergraph with maximum degree at
most 2^(n-2)/(en) has a proper halving 2-coloring, which solves another open
problem posed by Beck related to the Neighborhood Conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1991</identifier>
 <datestamp>2008-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1991</id><created>2008-10-10</created><authors><author><keyname>Boldt</keyname><forenames>Axel</forenames></author><author><keyname>Janich</keyname><forenames>Michael</forenames></author></authors><title>A global physician-oriented medical information system</title><categories>cs.CY cs.AI cs.DB</categories><comments>8 pages</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  We propose to improve medical decision making and reduce global health care
costs by employing a free Internet-based medical information system with two
main target groups: practicing physicians and medical researchers. After
acquiring patients' consent, physicians enter medical histories, physiological
data and symptoms or disorders into the system; an integrated expert system can
then assist in diagnosis and statistical software provides a list of the most
promising treatment options and medications, tailored to the patient.
Physicians later enter information about the outcomes of the chosen treatments,
data the system uses to optimize future treatment recommendations. Medical
researchers can analyze the aggregate data to compare various drugs or
treatments in defined patient populations on a large scale.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1997</identifier>
 <datestamp>2008-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1997</id><created>2008-10-12</created><updated>2008-11-05</updated><authors><author><keyname>Gao</keyname><forenames>Heping</forenames></author><author><keyname>Sitharam</keyname><forenames>Meera</forenames></author></authors><title>Characterizing 1-Dof Henneberg-I graphs with efficient configuration
  spaces</title><categories>cs.CG cs.RO cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define and study exact, efficient representations of realization spaces of
a natural class of underconstrained 2D Euclidean Distance Constraint
Systems(EDCS) or Frameworks based on 1-dof Henneberg-I graphs. Each
representation corresponds to a choice of parameters and yields a different
parametrized configuration space. Our notion of efficiency is based on the
algebraic complexities of sampling the configuration space and of obtaining a
realization from the sample (parametrized) configuration. Significantly, we
give purely combinatorial characterizations that capture (i) the class of
graphs that have efficient configuration spaces and (ii) the possible choices
of representation parameters that yield efficient configuration spaces for a
given graph. Our results automatically yield an efficient algorithm for
sampling realizations, without missing extreme or boundary realizations. In
addition, our results formally show that our definition of efficient
configuration space is robust and that our characterizations are tight. We
choose the class of 1-dof Henneberg-I graphs in order to take the next step in
a systematic and graded program of combinatorial characterizations of efficient
configuration spaces. In particular, the results presented here are the first
characterizations that go beyond graphs that have connected and convex
configuration spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2021</identifier>
 <datestamp>2008-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2021</id><created>2008-10-13</created><authors><author><keyname>Moreira</keyname><forenames>Pedro Miguel</forenames></author><author><keyname>Reis</keyname><forenames>Lu&#xed;s Paulo</forenames></author><author><keyname>de Sousa</keyname><forenames>Ant&#xf3;nio Augusto</forenames></author></authors><title>Visualization Optimization : Application to the RoboCup Rescue Domain</title><categories>cs.GR cs.AI</categories><comments>1+4 pages, 3 Figures</comments><acm-class>I.3.7; I.2.8</acm-class><journal-ref>Proceedings SIACG 2006 - Ibero American Symposyum in Computer
  Graphics, Santiago de Compostela, Spain, 5-7 July 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we demonstrate the use of intelligent optimization
methodologies on the visualization optimization of virtual / simulated
environments. The problem of automatic selection of an optimized set of views,
which better describes an on-going simulation over a virtual environment is
addressed in the context of the RoboCup Rescue Simulation domain. A generic
architecture for optimization is proposed and described. We outline the
possible extensions of this architecture and argue on how several problems
within the fields of Interactive Rendering and Visualization can benefit from
it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2046</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2046</id><created>2008-10-11</created><authors><author><keyname>Owladeghaffari</keyname><forenames>Hamed</forenames></author><author><keyname>Pedrycz</keyname><forenames>Witold</forenames></author><author><keyname>Sharifzadeh</keyname><forenames>Mostafa</forenames></author></authors><title>Modeling of Social Transitions Using Intelligent Systems</title><categories>cs.AI</categories><doi>10.1109/CANS.2008.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, we reproduce two new hybrid intelligent systems, involve three
prominent intelligent computing and approximate reasoning methods: Self
Organizing feature Map (SOM), Neruo-Fuzzy Inference System and Rough Set Theory
(RST),called SONFIS and SORST. We show how our algorithms can be construed as a
linkage of government-society interactions, where government catches various
states of behaviors: solid (absolute) or flexible. So, transition of society,
by changing of connectivity parameters (noise) from order to disorder is
inferred.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2061</identifier>
 <datestamp>2008-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2061</id><created>2008-10-12</created><authors><author><keyname>Hirschkoff</keyname><forenames>Daniel</forenames><affiliation>LIP</affiliation></author><author><keyname>Pous</keyname><forenames>Damien</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG Laboratoire d'Informatique de Grenoble</affiliation></author></authors><title>On characterising strong bisimilarity in a fragment of CCS with
  replication</title><categories>cs.LO</categories><proxy>ccsd hal-00329468</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a characterisation of strong bisimilarity in a fragment of CCS
that contains only prefix, parallel composition, synchronisation and a limited
form of replication. The characterisation is not an axiomatisation, but is
instead presented as a rewriting system. We discuss how our method allows us to
derive a new congruence result in the $\pi$-calculus: congruence holds in the
sub-calculus that does not include restriction nor sum, and features a limited
form of replication. We have not formalised the latter result in all details.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2063</identifier>
 <datestamp>2008-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2063</id><created>2008-10-11</created><authors><author><keyname>Li</keyname><forenames>Chunxi</forenames></author><author><keyname>Chen</keyname><forenames>Changjia</forenames></author></authors><title>Initial Offset Placement in p2p Live Streaming Systems</title><categories>cs.MM</categories><comments>12 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Initial offset placement in p2p streaming systems is studied in this paper.
Proportional placement (PP) scheme is proposed. In this scheme, peer places the
initial offset as the offset reported by other reference peer with a shift
proportional to the buffer width or offset lag of this reference peer. This
will introduce a stable placement that supports larger buffer width for peers
and small buffer width for tracker. Real deployed placement method in PPLive is
studied through measurement. It shows that, instead of based on offset lag, the
placement is based on buffer width of the reference peer to facilitate the
initial chunk fetching. We will prove that, such a PP scheme may not be stable
under arbitrary buffer occupation in the reference peer. The required average
buffer width then is derived. A simple good peer selection mechanism to check
the buffer occupation of reference peer is proposed for a stable PP scheme
based on buffer width
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2067</identifier>
 <datestamp>2009-01-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2067</id><created>2008-10-11</created><updated>2009-01-01</updated><authors><author><keyname>Naccache</keyname><forenames>David</forenames></author><author><keyname>Shparlinski</keyname><forenames>Igor E.</forenames></author></authors><title>Divisibility, Smoothness and Cryptographic Applications</title><categories>math.NT cs.CC cs.CR</categories><msc-class>11N25; 11Y16; 9460</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with products of moderate-size primes, familiarly known as
smooth numbers. Smooth numbers play a crucial role in information theory,
signal processing and cryptography.
  We present various properties of smooth numbers relating to their
enumeration, distribution and occurrence in various integer sequences. We then
turn our attention to cryptographic applications in which smooth numbers play a
pivotal role.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2133</identifier>
 <datestamp>2008-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2133</id><created>2008-10-12</created><authors><author><keyname>Pawar</keyname><forenames>Sameer</forenames></author><author><keyname>Avestimehr</keyname><forenames>Amir Salman</forenames></author><author><keyname>Tse</keyname><forenames>David N. C.</forenames></author></authors><title>Diversity-Multiplexing Tradeoff of the Half-Duplex Relay Channel</title><categories>cs.IT math.IT</categories><comments>8 pages, 6 figures, appeared in the 46th annual Allerton conference,
  September 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the diversity-multiplexing tradeoff of a half-duplex
single-relay channel with identically distributed Rayleigh fading channel gains
meets the 2 by 1 MISO bound. We generalize the result to the case when there
are N non-interfering relays and show that the diversity-multiplexing tradeoff
is equal to the N + 1 by 1 MISO bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2134</identifier>
 <datestamp>2008-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2134</id><created>2008-10-12</created><authors><author><keyname>Li</keyname><forenames>Chunxi</forenames></author><author><keyname>Chen</keyname><forenames>Changjia</forenames></author></authors><title>Fetching Strategy in the Startup Stage of p2p Live Streaming</title><categories>cs.NI</categories><comments>9 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A protocol named Threshold Bipolar (TB) is proposed as a fetching strategy at
the startup stage of p2p live streaming systems. In this protocol, chunks are
fetched consecutively from buffer head at the beginning. After the buffer is
filled into a threshold, chunks at the buffer tail will be fetched first while
keeping the contiguously filled part in the buffer above the threshold even
when the buffer is drained at a playback rate. High download rate, small
startup latency and natural strategy handover can be reached at the same time
by this protocol. Important parameters in this protocol are identified. The
buffer progress under this protocol is then expressed as piecewise lines
specified by those parameters. Startup traces of peers measured from PPLive are
studied to show the real performance of TB protocol in a real system. A simple
design model of TB protocol is proposed to reveal important considerations in a
practical design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2144</identifier>
 <datestamp>2008-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2144</id><created>2008-10-12</created><authors><author><keyname>Han</keyname><forenames>Guangyue</forenames></author><author><keyname>Marcus</keyname><forenames>Brian</forenames></author></authors><title>Asymptotics of Entropy Rate in Special Families of Hidden Markov Chains</title><categories>cs.IT math.IT</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive an asymptotic formula for entropy rate of a hidden Markov chain
around a &quot;weak Black Hole&quot;. We also discuss applications of the asymptotic
formula to the asymptotic behaviors of certain channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2150</identifier>
 <datestamp>2012-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2150</id><created>2008-10-13</created><updated>2012-04-30</updated><authors><author><keyname>Task</keyname><forenames>Christine</forenames></author><author><keyname>Chauhan</keyname><forenames>Arun</forenames></author></authors><title>A Model for Communication in Clusters of Multi-core Machines</title><categories>cs.DC cs.DS</categories><comments>This paper has been withdrawn by the author because it was basically
  a short-hand write-up of an incompletely formed idea from her Masters, and
  she'd like to start using her ArXiv account for her formal PhD research</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A common paradigm for scientific computing is distributed message-passing
systems, and a common approach to these systems is to implement them across
clusters of high-performance workstations. As multi-core architectures become
increasingly mainstream, these clusters are very likely to include multi-core
machines. However, the theoretical models which are currently used to develop
communication algorithms across these systems do not take into account the
unique properties of processes running on shared-memory architectures,
including shared external network connections and communication via shared
memory locations. Because of this, existing algorithms are far from optimal for
modern clusters. Additionally, recent attempts to adapt these algorithms to
multicore systems have proceeded without the introduction of a more accurate
formal model and have generally neglected to capitalize on the full power these
systems offer. We propose a new model which simply and effectively captures the
strengths of multi-core machines in collective communications patterns and
suggest how it could be used to properly optimize these patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2164</identifier>
 <datestamp>2008-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2164</id><created>2008-10-13</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>Joint source-channel coding via statistical mechanics: thermal
  equilibrium between the source and the channel</title><categories>cs.IT math.IT</categories><comments>24 pages; submitted to IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the classical joint source--channel coding problem from the
viewpoint of statistical physics and demonstrate that in the random coding
regime, the posterior probability distribution of the source given the channel
output is dominated by source sequences, which exhibit a behavior that is
highly parallel to that of thermal equilibrium between two systems of particles
that exchange energy, where one system corresponds to the source and the other
corresponds to the channel. The thermodynamical entopies of the dual physical
problem are analogous to conditional and unconditional Shannon entropies of the
source, and so, their balance in thermal equilibrium yields a simple formula
for the mutual information between the source and the channel output, that is
induced by the typical code in an ensemble of joint source--channel codes under
certain conditions. We also demonstrate how our results can be used in
applications, like the wiretap channel, and how can it be extended to multiuser
scenarios, like that of the multiple access channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2175</identifier>
 <datestamp>2009-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2175</id><created>2008-10-13</created><authors><author><keyname>Polishchuk</keyname><forenames>Valentin</forenames></author><author><keyname>Suomela</keyname><forenames>Jukka</forenames></author></authors><title>A simple local 3-approximation algorithm for vertex cover</title><categories>cs.DC</categories><comments>6 pages, 1 figure</comments><journal-ref>Information Processing Letters 109 (2009) 642-645</journal-ref><doi>10.1016/j.ipl.2009.02.017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a local algorithm (constant-time distributed algorithm) for
finding a 3-approximate vertex cover in bounded-degree graphs. The algorithm is
deterministic, and no auxiliary information besides port numbering is required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2179</identifier>
 <datestamp>2008-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2179</id><created>2008-10-13</created><updated>2008-10-20</updated><authors><author><keyname>Bertot</keyname><forenames>Yves</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Structural abstract interpretation, A formal study using Coq</title><categories>cs.LO</categories><proxy>ccsd inria-00329572</proxy><journal-ref>Dans LERNET Summer School (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  interpreters are tools to compute approximations for behaviors of a program.
These approximations can then be used for optimisation or for error detection.
In this paper, we show how to describe an abstract interpreter using the
type-theory based theorem prover Coq, using inductive types for syntax and
structural recursive programming for the abstract interpreter's kernel. The
abstract interpreter can then be proved correct with respect to a Hoare logic
for the programming language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2208</identifier>
 <datestamp>2008-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2208</id><created>2008-10-13</created><authors><author><keyname>Koch</keyname><forenames>Tobias</forenames></author><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author></authors><title>Multipath Channels of Unbounded Capacity</title><categories>cs.IT math.IT</categories><comments>To be presented at the 2008 IEEE 25-th Convention of Electrical and
  Electronics Engineers in Israel</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity of discrete-time, noncoherent, multipath fading channels is
considered. It is shown that if the variances of the path gains decay faster
than exponentially, then capacity is unbounded in the transmit power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2226</identifier>
 <datestamp>2008-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2226</id><created>2008-10-13</created><authors><author><keyname>Nicolae</keyname><forenames>Bogdan</forenames><affiliation>IRISA</affiliation></author><author><keyname>Antoniu</keyname><forenames>Gabriel</forenames><affiliation>IRISA</affiliation></author><author><keyname>Boug&#xe9;</keyname><forenames>Luc</forenames><affiliation>IRISA</affiliation></author></authors><title>Enabling Lock-Free Concurrent Fine-Grain Access to Massive Distributed
  Data: Application to Supernovae Detection</title><categories>cs.DC</categories><proxy>ccsd inria-00329698</proxy><journal-ref>Dans IEEE Cluster 2008 - Poster Session (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of efficiently managing massive data in a large-scale
distributed environment. We consider data strings of size in the order of
Terabytes, shared and accessed by concurrent clients. On each individual
access, a segment of a string, of the order of Megabytes, is read or modified.
Our goal is to provide the clients with efficient fine-grain access the data
string as concurrently as possible, without locking the string itself. This
issue is crucial in the context of applications in the field of astronomy,
databases, data mining and multimedia. We illustrate these requiremens with the
case of an application for searching supernovae. Our solution relies on
distributed, RAM-based data storage, while leveraging a DHT-based, parallel
metadata management scheme. The proposed architecture and algorithms have been
validated through a software prototype and evaluated in a cluster environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2227</identifier>
 <datestamp>2008-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2227</id><created>2008-10-13</created><authors><author><keyname>Nicolae</keyname><forenames>Bogdan</forenames><affiliation>IRISA</affiliation></author><author><keyname>Antoniu</keyname><forenames>Gabriel</forenames><affiliation>IRISA</affiliation></author><author><keyname>Boug&#xe9;</keyname><forenames>Luc</forenames><affiliation>IRISA</affiliation></author></authors><title>Distributed Management of Massive Data: an Efficient Fine-Grain Data
  Access Scheme</title><categories>cs.DC</categories><proxy>ccsd inria-00323248</proxy><journal-ref>Dans VECPAR 2008 (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of efficiently storing and accessing massive
data blocks in a large-scale distributed environment, while providing efficient
fine-grain access to data subsets. This issue is crucial in the context of
applications in the field of databases, data mining and multimedia. We propose
a data sharing service based on distributed, RAM-based storage of data, while
leveraging a DHT-based, natively parallel metadata management scheme. As
opposed to the most commonly used grid storage infrastructures that provide
mechanisms for explicit data localization and transfer, we provide a
transparent access model, where data are accessed through global identifiers.
Our proposal has been validated through a prototype implementation whose
preliminary evaluation provides promising results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2263</identifier>
 <datestamp>2009-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2263</id><created>2008-10-13</created><updated>2008-12-18</updated><authors><author><keyname>Camps</keyname><forenames>Rosa</forenames></author><author><keyname>Mora</keyname><forenames>Xavier</forenames></author><author><keyname>Saumell</keyname><forenames>Laia</forenames></author></authors><title>A continuous rating method for preferential voting</title><categories>math.OC cs.GT</categories><comments>v2: a comment has been added in section 18 about monotonicity</comments><msc-class>05C20, 91B12, 91B14, 91C15, 91C20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method is given for quantitatively rating the social acceptance of
different options which are the matter of a preferential vote. The proposed
method is proved to satisfy certain desirable conditions, among which there is
a majority principle, a property of clone consistency, and the continuity of
the rates with respect to the data. One can view this method as a quantitative
complement for a qualitative method introduced in 1997 by Markus Schulze. It is
also related to certain methods of one-dimensional scaling or cluster analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2279</identifier>
 <datestamp>2010-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2279</id><created>2008-10-13</created><updated>2010-03-05</updated><authors><author><keyname>Shtrakov</keyname><forenames>Slavcho</forenames></author><author><keyname>Koppitz</keyname><forenames>Joerg</forenames></author></authors><title>On finite functions with non-trivial arity gap</title><categories>cs.DM cs.CC</categories><comments>17 pages, Int. Conf. Algebraic and Combinatorial Coding Theory,
  ACCT2008, June 16 - Sunday 22, 2008, Pamporovo, BULGARIA</comments><acm-class>G.2.0</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Given an $n$-ary
  $k-$valued function $f$, $gap(f)$ denotes the minimal number of essential
variables in $f$ which become fictive when identifying any two distinct
essential variables in $f$.
  We particularly solve a problem concerning the explicit determination of
$n$-ary
  $k-$valued functions $f$ with $2\leq gap(f)\leq n\leq k$. Our methods yield
new combinatorial results about the number of such functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2311</identifier>
 <datestamp>2009-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2311</id><created>2008-10-13</created><updated>2009-04-22</updated><authors><author><keyname>Vasiloglou</keyname><forenames>Nikolaos</forenames></author><author><keyname>Gray</keyname><forenames>Alexander G.</forenames></author><author><keyname>Anderson</keyname><forenames>David V.</forenames></author></authors><title>Non-Negative Matrix Factorization, Convexity and Isometry</title><categories>cs.AI cs.CV</categories><comments>accpepted in SIAM Data Mining 2009, 12 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we explore avenues for improving the reliability of
dimensionality reduction methods such as Non-Negative Matrix Factorization
(NMF) as interpretive exploratory data analysis tools. We first explore the
difficulties of the optimization problem underlying NMF, showing for the first
time that non-trivial NMF solutions always exist and that the optimization
problem is actually convex, by using the theory of Completely Positive
Factorization. We subsequently explore four novel approaches to finding
globally-optimal NMF solutions using various ideas from convex optimization. We
then develop a new method, isometric NMF (isoNMF), which preserves
non-negativity while also providing an isometric embedding, simultaneously
achieving two properties which are helpful for interpretation. Though it
results in a more difficult optimization problem, we show experimentally that
the resulting method is scalable and even achieves more compact spectra than
standard NMF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2323</identifier>
 <datestamp>2008-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2323</id><created>2008-10-13</created><authors><author><keyname>Loyka</keyname><forenames>Sergey</forenames></author><author><keyname>Gagnon</keyname><forenames>Francois</forenames></author></authors><title>On Outage and Error Rate Analysis of the Ordered V-BLAST</title><categories>cs.IT math.IT</categories><comments>accepted by IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Outage and error rate performance of the ordered BLAST with more than 2
transmit antennas is evaluated for i.i.d. Rayleigh fading channels. A number of
lower and upper bounds on the 1st step outage probability at any SNR are
derived, which are further used to obtain accurate approximations to average
block and total error rates. For m Tx antennas, the effect of the optimal
ordering at the first step is an m-fold SNR gain. As m increases to infinity,
the BLER decreases to zero, which is a manifestation of the space-time
autocoding effect in the V-BLAST. While the sub-optimal ordering (based on the
before-projection SNR) suffers a few dB SNR penalty compared to the optimal
one, it has a lower computational complexity and a 3 dB SNR gain compared to
the unordered V-BLAST and can be an attractive solution for
low-complexity/low-energy systems. Uncoded D-BLAST exhibits the same outage and
error rate performance as that of the V-BLAST. An SNR penalty of the linear
receiver interfaces compared to the BLAST is also evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2336</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2336</id><created>2008-10-13</created><updated>2010-07-30</updated><authors><author><keyname>Vance</keyname><forenames>Stephanie</forenames></author></authors><title>A Mordell Inequality for Lattices over Maximal Orders</title><categories>math.MG cs.IT math.IT math.NT</categories><comments>13 pages</comments><journal-ref>Trans. Amer. Math. Soc. 362 (2010), no. 7, 3827-3839</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we prove an analogue of Mordell's inequality for lattices in
finite-dimensional complex or quaternionic Hermitian space that are modules
over a maximal order in an imaginary quadratic number field or a totally
definite rational quaternion algebra. This inequality implies that the
16-dimensional Barnes-Wall lattice has optimal density among all 16-dimensional
lattices with Hurwitz structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2352</identifier>
 <datestamp>2008-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2352</id><created>2008-10-13</created><authors><author><keyname>Liu</keyname><forenames>Nan</forenames></author><author><keyname>Gunduz</keyname><forenames>Deniz</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea J.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Interference Channels with Correlated Receiver Side Information</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of joint source-channel coding in transmitting independent
sources over interference channels with correlated receiver side information is
studied. When each receiver has side information correlated with its own
desired source, it is shown that source-channel code separation is optimal.
When each receiver has side information correlated with the interfering source,
sufficient conditions for reliable transmission are provided based on a joint
source-channel coding scheme using the superposition encoding and partial
decoding idea of Han and Kobayashi. When the receiver side information is a
deterministic function of the interfering source, source-channel code
separation is again shown to be optimal. As a special case, for a class of
Z-interference channels, when the side information of the receiver facing
interference is a deterministic function of the interfering source, necessary
and sufficient conditions for reliable transmission are provided in the form of
single letter expressions. As a byproduct of these joint source-channel coding
results, the capacity region of a class of Z-channels with degraded message
sets is also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2390</identifier>
 <datestamp>2008-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2390</id><created>2008-10-14</created><updated>2008-10-15</updated><authors><author><keyname>Faro</keyname><forenames>Simone</forenames></author><author><keyname>Lecroq</keyname><forenames>Thierry</forenames></author></authors><title>Efficient Pattern Matching on Binary Strings</title><categories>cs.DS cs.IR</categories><comments>12 pages</comments><acm-class>F.2.2; H.3.3; E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The binary string matching problem consists in finding all the occurrences of
a pattern in a text where both strings are built on a binary alphabet. This is
an interesting problem in computer science, since binary data are omnipresent
in telecom and computer network applications. Moreover the problem finds
applications also in the field of image processing and in pattern matching on
compressed texts. Recently it has been shown that adaptations of classical
exact string matching algorithms are not very efficient on binary data. In this
paper we present two efficient algorithms for the problem adapted to completely
avoid any reference to bits allowing to process pattern and text byte by byte.
Experimental results show that the new algorithms outperform existing solutions
in most cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2434</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2434</id><created>2008-10-14</created><authors><author><keyname>Rosten</keyname><forenames>Edward</forenames></author><author><keyname>Porter</keyname><forenames>Reid</forenames></author><author><keyname>Drummond</keyname><forenames>Tom</forenames></author></authors><title>Faster and better: a machine learning approach to corner detection</title><categories>cs.CV cs.LG</categories><comments>35 pages, 11 figures</comments><report-no>07-3912</report-no><journal-ref>IEEE Trans. PAMI, 32 (2010), 105--119</journal-ref><doi>10.1109/TPAMI.2008.275</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The repeatability and efficiency of a corner detector determines how likely
it is to be useful in a real-world application. The repeatability is importand
because the same scene viewed from different positions should yield features
which correspond to the same real-world 3D locations [Schmid et al 2000]. The
efficiency is important because this determines whether the detector combined
with further processing can operate at frame rate.
  Three advances are described in this paper. First, we present a new heuristic
for feature detection, and using machine learning we derive a feature detector
from this which can fully process live PAL video using less than 5% of the
available processing time. By comparison, most other detectors cannot even
operate at frame rate (Harris detector 115%, SIFT 195%). Second, we generalize
the detector, allowing it to be optimized for repeatability, with little loss
of efficiency. Third, we carry out a rigorous comparison of corner detectors
based on the above repeatability criterion applied to 3D scenes. We show that
despite being principally constructed for speed, on these stringent tests, our
heuristic detector significantly outperforms existing feature detectors.
Finally, the comparison demonstrates that using machine learning produces
significant improvements in repeatability, yielding a detector that is both
very fast and very high quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2486</identifier>
 <datestamp>2008-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2486</id><created>2008-10-14</created><authors><author><keyname>Meunier</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Wagner</keyname><forenames>Nicolas</forenames></author></authors><title>Dynamic assignment: there is an equilibrium !</title><categories>cs.GT</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a network with a continuum of users at some origins, suppose that the
users wish to reach specific destinations, but that they are not indifferent to
the time needed to reach their destination. They may have several possibilities
(of routes or deparure time), but their choices modify the travel times on the
network. Hence, each user faces the following problem: given a pattern of
travel times for the different possible routes that reach the destination, find
a shortest path. The situation in a context of perfect information is a
so-called Nash equilibrium, and the question whether there is such an
equilibrium and of finding it if it exists is the so-called equilibrium
assignment problem. It arises for various kind of networks, such as computers,
communication or transportation network. When each user occupies permanently
the whole route from the origin to its destination, we call it the static
assignment problem, which has been extensively studied with pioneers works by
Wardrop or Beckmann. A less studied, but more realistic, and maybe more
difficult, problem is when the time needed to reach an arc is taken into
account. We speak then of a dynamic assignment problem. Several models have
been proposed. For some of them, the existence of an equilibrium has been
proved, but always under some technical assumptions or in a very special case
(a network with one arc for the case when the users may chose their departure
time). The present paper proposes a compact model, with minimal and natural
assumptions. For this model, we prove that there is always an equilibrium. To
our knowledge, this imply all previous results about existence of an
equilibrium for the dynamic assignment problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2513</identifier>
 <datestamp>2011-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2513</id><created>2008-10-14</created><updated>2011-06-21</updated><authors><author><keyname>Sarwate</keyname><forenames>Anand D.</forenames></author><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author></authors><title>The Impact of Mobility on Gossip Algorithms</title><categories>cs.NI cs.DC cs.IT math.IT</categories><comments>Revised version submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The influence of node mobility on the convergence time of averaging gossip
algorithms in networks is studied. It is shown that a small number of fully
mobile nodes can yield a significant decrease in convergence time. A method is
developed for deriving lower bounds on the convergence time by merging nodes
according to their mobility pattern. This method is used to show that if the
agents have one-dimensional mobility in the same direction the convergence time
is improved by at most a constant. Upper bounds are obtained on the convergence
time using techniques from the theory of Markov chains and show that simple
models of mobility can dramatically accelerate gossip as long as the mobility
paths significantly overlap. Simulations verify that different mobility
patterns can have significantly different effects on the convergence of
distributed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2529</identifier>
 <datestamp>2008-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2529</id><created>2008-10-14</created><authors><author><keyname>Abouei</keyname><forenames>Jamshid</forenames></author><author><keyname>Bayesteh</keyname><forenames>Alireza</forenames></author><author><keyname>Ebrahimi</keyname><forenames>Masoud</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>On the Throughput Maximization in Dencentralized Wireless Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A distributed single-hop wireless network with $K$ links is considered, where
the links are partitioned into a fixed number ($M$) of clusters each operating
in a subchannel with bandwidth $\frac{W}{M}$. The subchannels are assumed to be
orthogonal to each other. A general shadow-fading model, described by
parameters $(\alpha,\varpi)$, is considered where $\alpha$ denotes the
probability of shadowing and $\varpi$ ($\varpi \leq 1$) represents the average
cross-link gains. The main goal of this paper is to find the maximum network
throughput in the asymptotic regime of $K \to \infty$, which is achieved by: i)
proposing a distributed and non-iterative power allocation strategy, where the
objective of each user is to maximize its best estimate (based on its local
information, i.e., direct channel gain) of the average network throughput, and
ii) choosing the optimum value for $M$. In the first part of the paper, the
network hroughput is defined as the \textit{average sum-rate} of the network,
which is shown to scale as $\Theta (\log K)$. Moreover, it is proved that in
the strong interference scenario, the optimum power allocation strategy for
each user is a threshold-based on-off scheme. In the second part, the network
throughput is defined as the \textit{guaranteed sum-rate}, when the outage
probability approaches zero. In this scenario, it is demonstrated that the
on-off power allocation scheme maximizes the throughput, which scales as
$\frac{W}{\alpha \varpi} \log K$. Moreover, the optimum spectrum sharing for
maximizing the average sum-rate and the guaranteed sum-rate is achieved at M=1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2598</identifier>
 <datestamp>2009-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2598</id><created>2008-10-15</created><updated>2008-11-02</updated><authors><author><keyname>Carnahan</keyname><forenames>J.</forenames></author><author><keyname>Honkanen</keyname><forenames>H.</forenames></author><author><keyname>Liuti</keyname><forenames>S.</forenames></author><author><keyname>Loitiere</keyname><forenames>Y.</forenames></author><author><keyname>Reynolds</keyname><forenames>P. R.</forenames></author></authors><title>New avenue to the Parton Distribution Functions: Self-Organizing Maps</title><categories>hep-ph cs.CE</categories><comments>34 pages, 17 figures, minor revisions, 2 figures updated</comments><journal-ref>Phys.Rev.D79:034022,2009</journal-ref><doi>10.1103/PhysRevD.79.034022</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural network algorithms have been recently applied to construct Parton
Distribution Function (PDF) parametrizations which provide an alternative to
standard global fitting procedures. We propose a technique based on an
interactive neural network algorithm using Self-Organizing Maps (SOMs). SOMs
are a class of clustering algorithms based on competitive learning among
spatially-ordered neurons. Our SOMs are trained on selections of stochastically
generated PDF samples. The selection criterion for every optimization iteration
is based on the features of the clustered PDFs. Our main goal is to provide a
fitting procedure that, at variance with the standard neural network
approaches, allows for an increased control of the systematic bias by enabling
user interaction in the various stages of the process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2653</identifier>
 <datestamp>2008-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2653</id><created>2008-10-15</created><authors><author><keyname>Sofronie-Stokkermans</keyname><forenames>Viorica</forenames></author></authors><title>On combinations of local theory extensions</title><categories>cs.LO cs.AI</categories><comments>22 pages, no figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study possibilities of efficient reasoning in combinations
of theories over possibly non-disjoint signatures. We first present a class of
theory extensions (called local extensions) in which hierarchical reasoning is
possible, and give several examples from computer science and mathematics in
which such extensions occur in a natural way. We then identify situations in
which combinations of local extensions of a theory are again local extensions
of that theory. We thus obtain criteria both for recognizing wider classes of
local theory extensions, and for modular reasoning in combinations of theories
over non-disjoint signatures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2659</identifier>
 <datestamp>2009-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2659</id><created>2008-10-15</created><updated>2009-03-07</updated><authors><author><keyname>Elamvazhuthi</keyname><forenames>P. S.</forenames><affiliation>Indian Institute of Technology Bombay, Mumbai, India</affiliation><affiliation>Cognizant Technology Solutions India Pvt. Ltd., Chennai, India</affiliation></author><author><keyname>Kulkarni</keyname><forenames>P. S.</forenames><affiliation>Indian Institute of Technology Bombay, Mumbai, India</affiliation><affiliation>Juniper Networks Inc., Bengaluru, India</affiliation></author><author><keyname>Dey</keyname><forenames>B. K.</forenames><affiliation>Indian Institute of Technology Bombay, Mumbai, India</affiliation></author></authors><title>DSTC Layering Protocols in Wireless Cooperative Networks</title><categories>cs.NI</categories><comments>39 pages, 20 figures. Part of this paper is submitted to IEEE 70th
  Vehicular Technology Conference: VTC2009-Fall for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a radio network with single source-destination pair and some relays, a
link between any two nodes is considered to have same or zero path loss.
However in practice some links may have considerably high path loss than others
but still being useful. In this report, we take into account signals received
from these links also. \indent Our system model consists of a
source-destination pair with two layers of relays in which weaker links between
source and second layer and between the first layer and destination are also
considered. We propose some protocols in this system model, run simulations
under optimum power allocation, and compare these protocols. We show that under
reasonable channel strength of these weaker links, the proposed protocols
perform ($ \approx 2$ dB) better than the existing basic protocol. As expected,
the degree of improvement increases with the strength of the weaker links. We
also show that with the receive channel knowledge in relays, the reliability
and data rate are improved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2665</identifier>
 <datestamp>2008-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2665</id><created>2008-10-15</created><updated>2008-10-22</updated><authors><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Path Planner for Objects, Robots and Mannequins by Multi-Agents Systems
  or Motion Captures</title><categories>cs.RO</categories><proxy>ccsd hal-00330776</proxy><journal-ref>International Conference on Digital Enterprise Technology, Nantes
  : France (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to optimise the costs and time of design of the new products while
improving their quality, concurrent engineering is based on the digital model
of these products. However, in order to be able to avoid definitively physical
model without loss of information, new tools must be available. Especially, a
tool making it possible to check simply and quickly the maintainability of
complex mechanical sets using the numerical model is necessary. Since one
decade, the MCM team of IRCCyN works on the creation of tools for the
generation and the analysis of trajectories of virtual mannequins. The
simulation of human tasks can be carried out either by robot-like simulation or
by simulation by motion capture. This paper presents some results on the both
two methods. The first method is based on a multi-agent system and on a digital
mock-up technology, to assess an efficient path planner for a manikin or a
robot for access and visibility task taking into account ergonomic constraints
or joint limits. The human operator is integrated in the process optimisation
to contribute to a global perception of the environment. This operator
cooperates, in real-time, with several automatic local elementary agents. In
the second method, we worked with the CEA and EADS/CCR to solve the constraints
related to the evolution of human virtual in its environment on the basis of
data resulting from motion capture system. An approach using of the virtual
guides was developed to allow to the user the realization of precise trajectory
in absence of force feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2666</identifier>
 <datestamp>2008-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2666</id><created>2008-10-15</created><authors><author><keyname>Paccot</keyname><forenames>Flavien</forenames><affiliation>LASMEA</affiliation></author><author><keyname>Lemoine</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Andreff</keyname><forenames>Nicolas</forenames><affiliation>LASMEA</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Martinet</keyname><forenames>Philippe</forenames><affiliation>LASMEA</affiliation></author></authors><title>A Vision-based Computed Torque Control for Parallel Kinematic Machines</title><categories>cs.RO</categories><proxy>ccsd hal-00330762</proxy><journal-ref>IEEE International Conference on Robotics and Automation, Pasadena
  : \'Etats-Unis d'Am\'erique (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel approach for parallel kinematic machine control
relying on a fast exteroceptive measure is implemented and validated on the
Orthoglide robot. This approach begins with rewriting the robot models as a
function of the only end-effector pose. It is shown that such an operation
reduces the model complexity. Then, this approach uses a classical Cartesian
space computed torque control with a fast exteroceptive measure, reducing the
control schemes complexity. Simulation results are given to show the expected
performance improvements and experiments prove the practical feasibility of the
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2697</identifier>
 <datestamp>2008-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2697</id><created>2008-10-15</created><authors><author><keyname>Chandran</keyname><forenames>L. Sunil</forenames></author><author><keyname>Das</keyname><forenames>Anita</forenames></author><author><keyname>Sivadasan</keyname><forenames>Naveen</forenames></author></authors><title>On the cubicity of bipartite graphs</title><categories>cs.DM</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  {\it A unit cube in $k$-dimension (or a $k$-cube) is defined as the cartesian
product $R_1 \times R_2 \times ... \times R_k$, where each $R_i$ is a closed
interval on the real line of the form $[a_i, a_i+1]$. The {\it cubicity} of
$G$, denoted as $cub(G)$, is the minimum $k$ such that $G$ is the intersection
graph of a collection of $k$-cubes. Many NP-complete graph problems can be
solved efficiently or have good approximation ratios in graphs of low cubicity.
In most of these cases the first step is to get a low dimensional cube
representation of the given graph.
  It is known that for a graph $G$, $cub(G) \leq \lfloor\frac{2n}{3}\rfloor$.
Recently it has been shown that for a graph $G$, $cub(G) \leq 4(\Delta + 1)\ln
n$, where $n$ and $\Delta$ are the number of vertices and maximum degree of
$G$, respectively. In this paper, we show that for a bipartite graph $G = (A
\cup B, E)$ with $|A| = n_1$, $|B| = n_2$, $n_1 \leq n_2$, and $\Delta' =
\min\{\Delta_A, \Delta_B\}$, where $\Delta_A = {max}_{a \in A}d(a)$ and
$\Delta_B = {max}_{b \in B}d(b)$, $d(a)$ and $d(b)$ being the degree of $a$ and
$b$ in $G$ respectively, $cub(G) \leq 2(\Delta'+2) \lceil \ln n_2 \rceil$. We
also give an efficient randomized algorithm to construct the cube
representation of $G$ in $3(\Delta'+2)\lceil \ln n_2 \rceil$ dimensions. The
reader may note that in general $\Delta'$ can be much smaller than $\Delta$.}
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2717</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2717</id><created>2008-10-15</created><updated>2011-01-18</updated><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author></authors><title>A Class of Graph-Geodetic Distances Generalizing the Shortest-Path and
  the Resistance Distances</title><categories>math.CO cs.DM math.MG</categories><comments>14 pages. Discrete Applied Mathematics</comments><msc-class>05C12, 05C50, 05C05, 15A48</msc-class><journal-ref>Discrete Applied Mathematics 159(2011) No. 5. 295-302</journal-ref><doi>10.1016/j.dam.2010.11.017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new class of distances for graph vertices is proposed. This class contains
parametric families of distances which reduce to the shortest-path, weighted
shortest-path, and the resistance distances at the limiting values of the
family parameters. The main property of the class is that all distances it
comprises are graph-geodetic: $d(i,j)+d(j,k)=d(i,k)$ if and only if every path
from $i$ to $k$ passes through $j$. The construction of the class is based on
the matrix forest theorem and the transition inequality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2746</identifier>
 <datestamp>2008-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2746</id><created>2008-10-15</created><authors><author><keyname>Yi</keyname><forenames>Zhihang</forenames></author><author><keyname>Kim</keyname><forenames>Il-Min</forenames></author></authors><title>Finite-SNR Diversity-Multiplexing Tradeoff and Optimum Power Allocation
  in Bidirectional Cooperative Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on analog network coding (ANC) and time division
broadcasting (TDBC) which are two major protocols used in bidirectional
cooperative networks. Lower bounds of the outage probabilities of those two
protocols are derived first. Those lower bounds are extremely tight in the
whole signal-to-noise ratio (SNR) range irrespective of the values of channel
variances. Based on those lower bounds, finite-SNR diversity-multiplexing
tradeoffs of the ANC and TDBC protocols are obtained. Secondly, we investigate
how to efficiently use channel state information (CSI) in those two protocols.
Specifically, an optimum power allocation scheme is proposed for the ANC
protocol. It simultaneously minimizes the outage probability and maximizes the
total mutual information of this protocol. For the TDBC protocol, an optimum
method to combine the received signals at the relay terminal is developed under
an equal power allocation assumption. This method minimizes the outage
probability and maximizes the total mutual information of the TDBC protocol at
the same time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2764</identifier>
 <datestamp>2008-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2764</id><created>2008-10-15</created><authors><author><keyname>Ailon</keyname><forenames>Nir</forenames></author></authors><title>A Simple Linear Ranking Algorithm Using Query Dependent Intercept
  Variables</title><categories>cs.IR cs.LG</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The LETOR website contains three information retrieval datasets used as a
benchmark for testing machine learning ideas for ranking. Algorithms
participating in the challenge are required to assign score values to search
results for a collection of queries, and are measured using standard IR ranking
measures (NDCG, precision, MAP) that depend only the relative score-induced
order of the results. Similarly to many of the ideas proposed in the
participating algorithms, we train a linear classifier. In contrast with other
participating algorithms, we define an additional free variable (intercept, or
benchmark) for each query. This allows expressing the fact that results for
different queries are incomparable for the purpose of determining relevance.
The cost of this idea is the addition of relatively few nuisance parameters.
Our approach is simple, and we used a standard logistic regression library to
test it. The results beat the reported participating algorithms. Hence, it
seems promising to combine our approach with other more complex ideas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2781</identifier>
 <datestamp>2008-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2781</id><created>2008-10-15</created><authors><author><keyname>Lu</keyname><forenames>Jin</forenames></author><author><keyname>Moura</keyname><forenames>Jos&#xe9; M. F.</forenames></author></authors><title>Linear Time Encoding of LDPC Codes</title><categories>cs.IT math.IT</categories><comments>36 pages, 13 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, we propose a linear complexity encoding method for arbitrary
LDPC codes. We start from a simple graph-based encoding method
``label-and-decide.'' We prove that the ``label-and-decide'' method is
applicable to Tanner graphs with a hierarchical structure--pseudo-trees-- and
that the resulting encoding complexity is linear with the code block length.
Next, we define a second type of Tanner graphs--the encoding stopping set. The
encoding stopping set is encoded in linear complexity by a revised
label-and-decide algorithm--the ``label-decide-recompute.'' Finally, we prove
that any Tanner graph can be partitioned into encoding stopping sets and
pseudo-trees. By encoding each encoding stopping set or pseudo-tree
sequentially, we develop a linear complexity encoding method for general LDPC
codes where the encoding complexity is proved to be less than $4 \cdot M \cdot
(\overline{k} - 1)$, where $M$ is the number of independent rows in the parity
check matrix and $\overline{k}$ represents the mean row weight of the parity
check matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2837</identifier>
 <datestamp>2008-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2837</id><created>2008-10-15</created><authors><author><keyname>Levesque</keyname><forenames>Martin</forenames></author><author><keyname>Elbiaze</keyname><forenames>Halima</forenames></author><author><keyname>Aly</keyname><forenames>Wael Hosny Fouad</forenames></author></authors><title>Adaptive Hybrid Deflection and Retransmission Routing for Optical
  Burst-Switched Networks</title><categories>cs.NI</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Burst contention is a well known challenging problem in Optical Burst
Switching (OBS) networks. Deflection routing is used to resolve contention.
Burst retransmission is used to reduce the Burst Loss Ratio (BLR) by
retransmitting dropped bursts. Previous works show that combining deflection
and retransmission outperforms both pure deflection and pure retransmission
approaches. This paper proposes a new Adaptive Hybrid Deflection and
Retransmission (AHDR) approach that dynamically combines deflection and
retransmission approaches based on network conditions such as BLR and link
utilization. Network Simulator 2 (ns-2) is used to simulate the proposed
approach on different network topologies. Simulation results show that the
proposed approach outperforms static approaches in terms of BLR and goodput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2861</identifier>
 <datestamp>2008-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2861</id><created>2008-10-16</created><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>Rossi</keyname><forenames>Francesca</forenames></author><author><keyname>Venable</keyname><forenames>K. Brent</forenames></author></authors><title>A comparison of the notions of optimality in soft constraints and
  graphical games</title><categories>cs.AI cs.GT</categories><comments>18 pages. To appear in Recent Advances in Constraints, (F. Fages, S.
  Soliman and F. Rossi, eds.) Springer Lecture Notes in Artificial Intelligence
  5129, 2008</comments><acm-class>I.2.11; D.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of optimality naturally arises in many areas of applied
mathematics and computer science concerned with decision making. Here we
consider this notion in the context of two formalisms used for different
purposes and in different research areas: graphical games and soft constraints.
We relate the notion of optimality used in the area of soft constraint
satisfaction problems (SCSPs) to that used in graphical games, showing that for
a large class of SCSPs that includes weighted constraints every optimal
solution corresponds to a Nash equilibrium that is also a Pareto efficient
joint strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2865</identifier>
 <datestamp>2008-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2865</id><created>2008-10-16</created><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>Conitzer</keyname><forenames>Vincent</forenames></author><author><keyname>Guo</keyname><forenames>Mingyu</forenames></author><author><keyname>Markakis</keyname><forenames>Evangelos</forenames></author></authors><title>Welfare Undominated Groves Mechanisms</title><categories>cs.GT</categories><comments>12 pages. To appear in Proceedings of the 4th International Workshop
  On Internet And Network Economics (WINE 2008). Springer Lecture Notes in
  Computer Science, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A common objective in mechanism design is to choose the outcome (for example,
allocation of resources) that maximizes the sum of the agents' valuations,
without introducing incentives for agents to misreport their preferences. The
class of Groves mechanisms achieves this; however, these mechanisms require the
agents to make payments, thereby reducing the agents' total welfare.
  In this paper we introduce a measure for comparing two mechanisms with
respect to the final welfare they generate. This measure induces a partial
order on mechanisms and we study the question of finding minimal elements with
respect to this partial order. In particular, we say a non-deficit Groves
mechanism is welfare undominated if there exists no other non-deficit Groves
mechanism that always has a smaller or equal sum of payments. We focus on two
domains: (i) auctions with multiple identical units and unit-demand bidders,
and (ii) mechanisms for public project problems. In the first domain we
analytically characterize all welfare undominated Groves mechanisms that are
anonymous and have linear payment functions, by showing that the family of
optimal-in-expectation linear redistribution mechanisms, which were introduced
in [6] and include the Bailey-Cavallo mechanism [1,2], coincides with the
family of welfare undominated Groves mechanisms that are anonymous and linear
in the setting we study. In the second domain we show that the classic VCG
(Clarke) mechanism is welfare undominated for the class of public project
problems with equal participation costs, but is not undominated for a more
general class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2877</identifier>
 <datestamp>2008-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2877</id><created>2008-10-16</created><authors><author><keyname>Sofronie-Stokkermans</keyname><forenames>Viorica</forenames></author></authors><title>Sheaves and geometric logic and applications to the modular verification
  of complex systems</title><categories>cs.LO</categories><comments>30 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we show that states, transitions and behavior of concurrent
systems can often be modeled as sheaves over a suitable topological space. In
this context, geometric logic can be used to describe which local properties
(i.e. properties of individual systems) are preserved, at a global level, when
interconnecting the systems. The main area of application is to modular
verification of complex systems. We illustrate the ideas by means of an example
involving a family of interacting controllers for trains on a rail track.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2891</identifier>
 <datestamp>2008-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2891</id><created>2008-10-16</created><updated>2008-10-17</updated><authors><author><keyname>Lago</keyname><forenames>Ugo Dal</forenames></author><author><keyname>Roversi</keyname><forenames>Luca</forenames></author><author><keyname>Vercelli</keyname><forenames>Luca</forenames></author></authors><title>Taming Modal Impredicativity: Superlazy Reduction</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pure, or type-free, Linear Logic proof nets are Turing complete once
cut-elimination is considered as computation. We introduce modal
impredicativity as a new form of impredicativity causing the complexity of
cut-elimination to be problematic from a complexity point of view. Modal
impredicativity occurs when, during reduction, the conclusion of a residual of
a box b interacts with a node that belongs to the proof net inside another
residual of b. Technically speaking, superlazy reduction is a new notion of
reduction that allows to control modal impredicativity. More specifically,
superlazy reduction replicates a box only when all its copies are opened. This
makes the overall cost of reducing a proof net finite and predictable.
Specifically, superlazy reduction applied to any pure proof nets takes
primitive recursive time. Moreover, any primitive recursive function can be
computed by a pure proof net via superlazy reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2924</identifier>
 <datestamp>2008-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2924</id><created>2008-10-16</created><authors><author><keyname>Kammoun</keyname><forenames>Abla</forenames></author><author><keyname>Kharouf</keyname><forenames>Malika</forenames></author><author><keyname>Hachem</keyname><forenames>Walid</forenames></author><author><keyname>Najim</keyname><forenames>Jamal</forenames></author></authors><title>BER and Outage Probability Approximations for LMMSE Detectors on
  Correlated MIMO Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is devoted to the study of the performance of the Linear Minimum
Mean-Square Error receiver for (receive) correlated Multiple-Input
Multiple-Output systems. By the random matrix theory, it is well-known that the
Signal-to-Noise Ratio (SNR) at the output of this receiver behaves
asymptotically like a Gaussian random variable as the number of receive and
transmit antennas converge to +$\infty$ at the same rate. However, this
approximation being inaccurate for the estimation of some performance metrics
such as the Bit Error Rate and the outage probability, especially for small
system dimensions, Li et al. proposed convincingly to assume that the SNR
follows a generalized Gamma distribution which parameters are tuned by
computing the first three asymptotic moments of the SNR. In this article, this
technique is generalized to (receive) correlated channels, and closed-form
expressions for the first three asymptotic moments of the SNR are provided. To
obtain these results, a random matrix theory technique adapted to matrices with
Gaussian elements is used. This technique is believed to be simple, efficient,
and of broad interest in wireless communications. Simulations are provided, and
show that the proposed technique yields in general a good accuracy, even for
small system dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2953</identifier>
 <datestamp>2008-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2953</id><created>2008-10-16</created><authors><author><keyname>Koyluoglu</keyname><forenames>Onur Ozan</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>On Power Control and Frequency Reuse in the Two User Cognitive Channel</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communications (revised on
  October 16, 2008)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the generalized cognitive radio channel where the
secondary user is allowed to reuse the frequency during both the idle and
active periods of the primary user, as long as the primary rate remains the
same. In this setting, the optimal power allocation policy with single-input
single-output (SISO) primary and secondary channels is explored. Interestingly,
the offered gain resulting from the frequency reuse during the active periods
of the spectrum is shown to disappear in both the low and high signal-to-noise
ratio (SNR) regimes. We then argue that this drawback in the high SNR region
can be avoided by equipping both the primary and secondary transmitters with
multiple antennas. Finally, the scenario consisting of SISO primary and
multi-input multi-output (MIMO) secondary channels is investigated. Here, a
simple Zero-Forcing approach is shown to significantly outperform the
celebrated Decoding-Forwarding-Dirty Paper Coding strategy (especially in the
high SNR regime).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3023</identifier>
 <datestamp>2008-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3023</id><created>2008-10-16</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Pass</keyname><forenames>Rafael</forenames></author></authors><title>Iterated Regret Minimization: A More Realistic Solution Concept</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For some well-known games, such as the Traveler's Dilemma or the Centipede
Game, traditional game-theoretic solution concepts--and most notably Nash
equilibrium--predict outcomes that are not consistent with empirical
observations. In this paper, we introduce a new solution concept, iterated
regret minimization, which exhibits the same qualitative behavior as that
observed in experiments in many games of interest, including Traveler's
Dilemma, the Centipede Game, Nash bargaining, and Bertrand competition. As the
name suggests, iterated regret minimization involves the iterated deletion of
strategies that do not minimize regret.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3058</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3058</id><created>2008-10-17</created><authors><author><keyname>Tsolis</keyname><forenames>Dimitrios K.</forenames></author><author><keyname>Sioutas</keyname><forenames>Spyros</forenames></author><author><keyname>Papatheodorou</keyname><forenames>Theodore S.</forenames></author></authors><title>Watermarking Digital Images Based on a Content Based Image Retrieval
  Technique</title><categories>cs.DS cs.CR</categories><comments>18 pages, 4 figures, 4 tables, submitted to Multimedia Tools and
  Applications Journal, Springer</comments><acm-class>C.3; F.2.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The current work is focusing on the implementation of a robust watermarking
algorithm for digital images, which is based on an innovative spread spectrum
analysis algorithm for watermark embedding and on a content-based image
retrieval technique for watermark detection. The highly robust watermark
algorithms are applying &quot;detectable watermarks&quot; for which a detection mechanism
checks if the watermark exists or no (a Boolean decision) based on a
watermarking key. The problem is that the detection of a watermark in a digital
image library containing thousands of images means that the watermark detection
algorithm is necessary to apply all the keys to the digital images. This
application is non-efficient for very large image databases. On the other hand
&quot;readable&quot; watermarks may prove weaker but easier to detect as only the
detection mechanism is required. The proposed watermarking algorithm combine's
the advantages of both &quot;detectable&quot; and &quot;readable&quot; watermarks. The result is a
fast and robust watermarking algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3076</identifier>
 <datestamp>2008-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3076</id><created>2008-10-17</created><authors><author><keyname>Kuhn</keyname><forenames>Tobias</forenames></author></authors><title>Combining Semantic Wikis and Controlled Natural Language</title><categories>cs.HC cs.AI</categories><acm-class>H.5.2; I.2.4</acm-class><journal-ref>In Proceedings of the Poster and Demonstration Session at the 7th
  International Semantic Web Conference (ISWC2008), CEUR Workshop Proceedings,
  Volume 401, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate AceWiki that is a semantic wiki using the controlled natural
language Attempto Controlled English (ACE). The goal is to enable easy creation
and modification of ontologies through the web. Texts in ACE can automatically
be translated into first-order logic and other languages, for example OWL.
Previous evaluation showed that ordinary people are able to use AceWiki without
being instructed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3093</identifier>
 <datestamp>2009-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3093</id><created>2008-10-17</created><updated>2008-11-03</updated><authors><author><keyname>Shen</keyname><forenames>Huawei</forenames></author><author><keyname>Cheng</keyname><forenames>Xueqi</forenames></author><author><keyname>Cai</keyname><forenames>Kai</forenames></author><author><keyname>Hu</keyname><forenames>Mao-Bin</forenames></author></authors><title>Detect overlapping and hierarchical community structure in networks</title><categories>cs.CY physics.soc-ph</categories><comments>7 pages, 5 figures</comments><journal-ref>Physica A 388 (2009) 1706-1712</journal-ref><doi>10.1016/j.physa.2008.12.021</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clustering and community structure is crucial for many network systems and
the related dynamic processes. It has been shown that communities are usually
overlapping and hierarchical. However, previous methods investigate these two
properties of community structure separately. This paper proposes an algorithm
(EAGLE) to detect both the overlapping and hierarchical properties of complex
community structure together. This algorithm deals with the set of maximal
cliques and adopts an agglomerative framework. The quality function of
modularity is extended to evaluate the goodness of a cover. The examples of
application to real world networks give excellent results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3125</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3125</id><created>2008-10-17</created><updated>2011-02-07</updated><authors><author><keyname>D\kebowski</keyname><forenames>\Lukasz</forenames></author></authors><title>On the Vocabulary of Grammar-Based Codes and the Logical Consistency of
  Texts</title><categories>cs.IT cs.CL math.IT</categories><comments>24 pages, no figures</comments><msc-class>94A29, 60G10, 94A17</msc-class><acm-class>E.4; G.3; I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article presents a new interpretation for Zipf-Mandelbrot's law in
natural language which rests on two areas of information theory. Firstly, we
construct a new class of grammar-based codes and, secondly, we investigate
properties of strongly nonergodic stationary processes. The motivation for the
joint discussion is to prove a proposition with a simple informal statement: If
a text of length $n$ describes $n^\beta$ independent facts in a repetitive way
then the text contains at least $n^\beta/\log n$ different words, under
suitable conditions on $n$. In the formal statement, two modeling postulates
are adopted. Firstly, the words are understood as nonterminal symbols of the
shortest grammar-based encoding of the text. Secondly, the text is assumed to
be emitted by a finite-energy strongly nonergodic source whereas the facts are
binary IID variables predictable in a shift-invariant way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3136</identifier>
 <datestamp>2013-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3136</id><created>2008-10-17</created><updated>2010-09-06</updated><authors><author><keyname>Greco</keyname><forenames>Gianluigi</forenames></author><author><keyname>Malizia</keyname><forenames>Enrico</forenames></author><author><keyname>Palopoli</keyname><forenames>Luigi</forenames></author><author><keyname>Scarcello</keyname><forenames>Francesco</forenames></author></authors><title>On the Complexity of Core, Kernel, and Bargaining Set</title><categories>cs.GT cs.AI cs.CC</categories><comments>30 pages, 6 figures</comments><acm-class>F.2; J.4</acm-class><journal-ref>Artif. Intell. 175(12-13): 1877-1910 (2011)</journal-ref><doi>10.1016/j.artint.2011.06.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coalitional games are mathematical models suited to analyze scenarios where
players can collaborate by forming coalitions in order to obtain higher worths
than by acting in isolation. A fundamental problem for coalitional games is to
single out the most desirable outcomes in terms of appropriate notions of worth
distributions, which are usually called solution concepts. Motivated by the
fact that decisions taken by realistic players cannot involve unbounded
resources, recent computer science literature reconsidered the definition of
such concepts by advocating the relevance of assessing the amount of resources
needed for their computation in terms of their computational complexity. By
following this avenue of research, the paper provides a complete picture of the
complexity issues arising with three prominent solution concepts for
coalitional games with transferable utility, namely, the core, the kernel, and
the bargaining set, whenever the game worth-function is represented in some
reasonable compact form (otherwise, if the worths of all coalitions are
explicitly listed, the input sizes are so large that complexity problems
are---artificially---trivial). The starting investigation point is the setting
of graph games, about which various open questions were stated in the
literature. The paper gives an answer to these questions, and in addition
provides new insights on the setting, by characterizing the computational
complexity of the three concepts in some relevant generalizations and
specializations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3150</identifier>
 <datestamp>2009-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3150</id><created>2008-10-17</created><updated>2009-12-16</updated><authors><author><keyname>Laraki</keyname><forenames>Rida</forenames><affiliation>CECO</affiliation></author><author><keyname>Lasserre</keyname><forenames>Jean B.</forenames><affiliation>LAAS</affiliation></author></authors><title>Semidefinite Programming for Min-Max Problems and Games</title><categories>math.OC cs.GT</categories><comments>21 pages</comments><proxy>ccsd hal-00331529</proxy><report-no>Rapport LAAS 08582</report-no><msc-class>91A06, 91A25, 90C22, 47N10, 65K05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce two min-max problems: the first problem is to minimize the
supremum of finitely many rational functions over a compact basic
semi-algebraic set whereas the second problem is a 2-player zero-sum polynomial
game in randomized strategies and with compact basic semi-algebraic pure
strategy sets. It is proved that their optimal solution can be approximated by
solving a hierarchy of semidefinite relaxations, in the spirit of the moment
approach developed in Lasserre. This provides a unified approach and a class of
algorithms to approximate all Nash equilibria and min-max strategies of many
static and dynamic games. Each semidefinite relaxation can be solved in time
which is polynomial in its input size and practice from global optimization
suggests that very often few relaxations are needed for a good approximation
(and sometimes even finite convergence).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3162</identifier>
 <datestamp>2008-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3162</id><created>2008-10-17</created><authors><author><keyname>Luo</keyname><forenames>Zhaohua</forenames></author></authors><title>Clone Theory: Its Syntax and Semantics, Applications to Universal
  Algebra, Lambda Calculus and Algebraic Logic</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The primary goal of this paper is to present a unified way to transform the
syntax of a logic system into certain initial algebraic structure so that it
can be studied algebraically. The algebraic structures which one may choose for
this purpose are various clones over a full subcategory of a category. We show
that the syntax of equational logic, lambda calculus and first order logic can
be represented as clones or right algebras of clones over the set of positive
integers. The semantics is then represented by structures derived from left
algebras of these clones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3163</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3163</id><created>2008-10-17</created><updated>2009-05-14</updated><authors><author><keyname>Briand</keyname><forenames>Emmanuel</forenames><affiliation>Universidad de Sevilla</affiliation></author><author><keyname>Orellana</keyname><forenames>Rosa</forenames><affiliation>Darmouth College</affiliation></author><author><keyname>Rosas</keyname><forenames>Mercedes</forenames><affiliation>Universidad de Sevilla</affiliation></author></authors><title>Reduced Kronecker coefficients and counter-examples to Mulmuley's strong
  saturation conjecture SH</title><categories>math.CO cs.CC math.RT</categories><comments>25 pages. With an appendix by Ketan Mulmuley. To appear in
  Computational Complexity. See also
  http://emmanuel.jean.briand.free.fr/publications/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide counter-examples to Mulmuley's strong saturation conjecture
(strong SH) for the Kronecker coefficients. This conjecture was proposed in the
setting of Geometric Complexity Theory to show that deciding whether or not a
Kronecker coefficient is zero can be done in polynomial time. We also provide a
short proof of the #P-hardness of computing the Kronecker coefficients. Both
results rely on the connections between the Kronecker coefficients and another
family of structural constants in the representation theory of the symmetric
groups: Murnaghan's reduced Kronecker coefficients.
  An appendix by Mulmuley introduces a relaxed form of the saturation
hypothesis SH, still strong enough for the aims of Geometric Complexity Theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3182</identifier>
 <datestamp>2008-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3182</id><created>2008-10-17</created><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>Markakis</keyname><forenames>Vangelis</forenames></author></authors><title>Optimal Strategies in Sequential Bidding</title><categories>cs.GT</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are interested in mechanisms that maximize social welfare. In [1] this
problem was studied for multi-unit auctions with unit demand bidders and for
the public project problem, and in each case social welfare undominated
mechanisms in the class of feasible and incentive compatible mechanisms were
identified. One way to improve upon these optimality results is by allowing the
players to move sequentially. With this in mind, we study here sequential
versions of two feasible Groves mechanisms used for single item auctions: the
Vickrey auction and the Bailey-Cavallo mechanism. Because of the absence of
dominant strategies in this sequential setting, we focus on a weaker concept of
an optimal strategy. For each mechanism we introduce natural optimal strategies
and observe that in each mechanism these strategies exhibit different
behaviour. However, we then show that among all optimal strategies, the one we
introduce for each mechanism maximizes the social welfare when each player
follows it. The resulting social welfare can be larger than the one obtained in
the simultaneous setting. Finally, we show that, when interpreting both
mechanisms as simultaneous ones, the vectors of the proposed strategies form a
Pareto optimal Nash equilibrium in the class of optimal strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3199</identifier>
 <datestamp>2008-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3199</id><created>2008-10-17</created><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>Arbab</keyname><forenames>Farhad</forenames></author><author><keyname>Ma</keyname><forenames>Huiye</forenames></author></authors><title>A Distributed Platform for Mechanism Design</title><categories>cs.GT cs.DC</categories><comments>6 pages. To appear in the Proc. of International Conference on
  Computational Intelligence for Modelling, Control and Automation, IEEE
  Society</comments><acm-class>C.2.4; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a structured system for distributed mechanism design. It consists
of a sequence of layers. The lower layers deal with the operations relevant for
distributed computing only, while the upper layers are concerned only with
communication among players, including broadcasting and multicasting, and
distributed decision making. This yields a highly flexible distributed system
whose specific applications are realized as instances of its top layer.
  This design supports fault-tolerance, prevents manipulations and makes it
possible to implement distributed policing. The system is implemented in Java.
We illustrate it by discussing a number of implemented examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3203</identifier>
 <datestamp>2008-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3203</id><created>2008-10-17</created><authors><author><keyname>Harvey</keyname><forenames>David</forenames></author></authors><title>A cache-friendly truncated FFT</title><categories>cs.SC cs.DS</categories><comments>14 pages, 11 figures, uses algorithm2e package</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a cache-friendly version of van der Hoeven's truncated FFT and
inverse truncated FFT, focusing on the case of `large' coefficients, such as
those arising in the Schonhage--Strassen algorithm for multiplication in Z[x].
We describe two implementations and examine their performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3226</identifier>
 <datestamp>2008-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3226</id><created>2008-10-17</created><authors><author><keyname>Xie</keyname><forenames>Bike</forenames></author><author><keyname>Griot</keyname><forenames>Miguel</forenames></author><author><keyname>Casado</keyname><forenames>Andres I. Vila</forenames></author><author><keyname>Wesel</keyname><forenames>Richard D.</forenames></author></authors><title>Optimal Transmission Strategy and Explicit Capacity Region for Broadcast
  Z Channels</title><categories>cs.IT math.IT</categories><comments>9 pages, 14 figures, published in IEEE Transactions on Information
  Theory, Vol. 53, No. 9, pp 4296-4304, September 2008</comments><msc-class>94A15</msc-class><journal-ref>IEEE Transactions on Information Theory, Vol. 53, No. 9, pp
  4296-4304, September 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides an explicit expression for the capacity region of the
two-user broadcast Z channel and proves that the optimal boundary can be
achieved by independent encoding of each user. Specifically, the information
messages corresponding to each user are encoded independently and the OR of
these two encoded streams is transmitted. Nonlinear turbo codes that provide a
controlled distribution of ones and zeros are used to demonstrate a
low-complexity scheme that operates close to the optimal boundary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3227</identifier>
 <datestamp>2008-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3227</id><created>2008-10-17</created><authors><author><keyname>Kennedy</keyname><forenames>Oliver</forenames></author><author><keyname>Koch</keyname><forenames>Christoph</forenames></author><author><keyname>Demers</keyname><forenames>Al</forenames></author></authors><title>Dynamic Approaches to In-Network Aggregation</title><categories>cs.DC cs.DB cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collaboration between small-scale wireless devices hinges on their ability to
infer properties shared across multiple nearby nodes. Wireless-enabled mobile
devices in particular create a highly dynamic environment not conducive to
distributed reasoning about such global properties. This paper addresses a
specific instance of this problem: distributed aggregation. We present
extensions to existing unstructured aggregation protocols that enable
estimation of count, sum, and average aggregates in highly dynamic
environments. With the modified protocols, devices with only limited
connectivity can maintain estimates of the aggregate, despite
\textit{unexpected} peer departures and arrivals. Our analysis of these
aggregate maintenance extensions demonstrates their effectiveness in
unstructured environments despite high levels of node mobility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3283</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3283</id><created>2008-10-17</created><updated>2008-10-25</updated><authors><author><keyname>Dong</keyname><forenames>Daoyi</forenames></author><author><keyname>Chen</keyname><forenames>Chunlin</forenames></author><author><keyname>Zhang</keyname><forenames>Chenbin</forenames></author><author><keyname>Chen</keyname><forenames>Zonghai</forenames></author></authors><title>Quantum robot: structure, algorithms and applications</title><categories>cs.RO cs.AI quant-ph</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3294</identifier>
 <datestamp>2014-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3294</id><created>2008-10-18</created><updated>2014-01-30</updated><authors><author><keyname>Bergstra</keyname><forenames>Jan A.</forenames></author><author><keyname>Burgess</keyname><forenames>Mark</forenames></author></authors><title>A static theory of promises</title><categories>cs.MA cs.SE</categories><comments>36 pages. Revision of v4. In v5 some remarks about the institution of
  promising in the philosophy of Law have been included as well as a comment
  concerning the anthropology of promising. Several minor mistakes were found
  and remedied</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss for the concept of promises within a framework that can be applied
to either humans or technology. We compare promises to the more established
notion of obligations and find promises to be both simpler and more effective
at reducing uncertainty in behavioural outcomes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3332</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3332</id><created>2008-10-18</created><authors><author><keyname>Dragoi</keyname><forenames>Cezara</forenames></author><author><keyname>Stefanescu</keyname><forenames>Gheorghe</forenames></author></authors><title>A sound spatio-temporal Hoare logic for the verification of structured
  interactive programs with registers and voices</title><categories>cs.PL cs.LO</categories><comments>21 pages, 8 figures, Invited submission for WADT'08 LNCS Proceedings</comments><acm-class>F.1.2; F.3; D.2.4; D.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interactive systems with registers and voices (shortly, &quot;rv-systems&quot;) are a
model for interactive computing obtained closing register machines with respect
to a space-time duality transformation (&quot;voices&quot; are the time-dual counterparts
of &quot;registers&quot;). In the same vain, AGAPIA v0.1, a structured programming
language for rv-systems, is the space-time dual closure of classical while
programs (over a specific type of data). Typical AGAPIA programs describe open
processes located at various sites and having their temporal windows of
adequate reaction to the environment. The language naturally supports process
migration, structured interaction, and deployment of components on
heterogeneous machines.
  In this paper a sound Hoare-like spatio-temporal logic for the verification
of AGAPIA v0.1 programs is introduced. As a case study, a formal verification
proof of a popular distributed termination detection protocol is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3345</identifier>
 <datestamp>2008-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3345</id><created>2008-10-18</created><updated>2008-10-25</updated><authors><author><keyname>Zhang</keyname><forenames>Xiaowen</forenames></author><author><keyname>Zhang</keyname><forenames>Zhanyang</forenames></author><author><keyname>Wei</keyname><forenames>Xinzhou</forenames></author></authors><title>Enhancements to A Lightweight RFID Authentication Protocol</title><categories>cs.CR</categories><comments>9 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vajda and Buttyan (VB) proposed a set of five lightweight RFID authentication
protocols. Defend, Fu, and Juels (DFJ) did cryptanalysis on two of them - XOR
and SUBSET. To the XOR protocol, DFJ proposed repeated keys attack and nibble
attack. In this paper, we identify the vulnerability existed in the original
VB's successive session key permutation algorithm. We propose three
enhancements to prevent DFJ's attacks and make XOR protocol stronger without
introducing extra resource cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3356</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3356</id><created>2008-10-18</created><authors><author><keyname>Burjorjee</keyname><forenames>Keki</forenames></author></authors><title>The Fundamental Problem with the Building Block Hypothesis</title><categories>cs.NE</categories><comments>Preliminary version. 26 pages, 1 figure</comments><acm-class>I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Skepticism of the building block hypothesis (BBH) has previously been
expressed on account of the weak theoretical foundations of this hypothesis and
the anomalies in the empirical record of the simple genetic algorithm. In this
paper we hone in on a more fundamental cause for skepticism--the extraordinary
strength of some of the assumptions that undergird the BBH. Specifically, we
focus on assumptions made about the distribution of fitness over the genome
set, and argue that these assumptions are unacceptably strong. As most of these
assumptions have been embraced by the designers of so-called &quot;competent&quot;
genetic algorithms, our critique is relevant to an appraisal of such algorithms
as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3357</identifier>
 <datestamp>2009-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3357</id><created>2008-10-18</created><updated>2009-03-31</updated><authors><author><keyname>Burjorjee</keyname><forenames>Keki M.</forenames></author></authors><title>Two Remarkable Computational Competencies of the Simple Genetic
  Algorithm</title><categories>cs.NE</categories><comments>Sharpened motivation, improved notation</comments><acm-class>I.2.8; F.2.m</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the inception of genetic algorithmics the identification of
computational efficiencies of the simple genetic algorithm (SGA) has been an
important goal. In this paper we distinguish between a computational competency
of the SGA--an efficient, but narrow computational ability--and a computational
proficiency of the SGA--a computational ability that is both efficient and
broad. Till date, attempts to deduce a computational proficiency of the SGA
have been unsuccessful. It may, however, be possible to inductively infer a
computational proficiency of the SGA from a set of related computational
competencies that have been deduced. With this in mind we deduce two
computational competencies of the SGA. These competencies, when considered
together, point toward a remarkable computational proficiency of the SGA. This
proficiency is pertinent to a general problem that is closely related to a
well-known statistical problem at the cutting edge of computational genetics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3416</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3416</id><created>2008-10-19</created><authors><author><keyname>Koroutchev</keyname><forenames>K.</forenames></author><author><keyname>Korutcheva</keyname><forenames>E.</forenames></author></authors><title>Text as Statistical Mechanics Object</title><categories>cs.CL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we present a model of human written text based on statistical
mechanics approach by deriving the potential energy for different parts of the
text using large text corpus. We have checked the results numerically and found
that the specific heat parameter effectively separates the closed class words
from the specific terms used in the text.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3418</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3418</id><created>2008-10-19</created><authors><author><keyname>Koroutchev</keyname><forenames>K.</forenames></author><author><keyname>Korutcheva</keyname><forenames>E.</forenames></author></authors><title>Detecting the Most Unusual Part of a Digital Image</title><categories>cs.CV cs.GR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this paper is to introduce an algorithm that can detect the
most unusual part of a digital image. The most unusual part of a given shape is
defined as a part of the image that has the maximal distance to all non
intersecting shapes with the same form.
  The method can be used to scan image databases with no clear model of the
interesting part or large image databases, as for example medical databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3422</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3422</id><created>2008-10-19</created><authors><author><keyname>Kliewer</keyname><forenames>Joerg</forenames></author><author><keyname>Zigangirov</keyname><forenames>Kamil S.</forenames></author><author><keyname>Koller</keyname><forenames>Christian</forenames></author><author><keyname>Costello</keyname><forenames>Daniel J.</forenames><suffix>Jr</suffix></author></authors><title>Coding Theorems for Repeat Multiple Accumulate Codes</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the ensemble of codes formed by a serial concatenation of a
repetition code with multiple accumulators connected through random
interleavers is considered. Based on finite length weight enumerators for these
codes, asymptotic expressions for the minimum distance and an arbitrary number
of accumulators larger than one are derived using the uniform interleaver
approach. In accordance with earlier results in the literature, it is first
shown that the minimum distance of repeat-accumulate codes can grow, at best,
sublinearly with block length. Then, for repeat-accumulate-accumulate codes and
rates of 1/3 or less, it is proved that these codes exhibit asymptotically
linear distance growth with block length, where the gap to the
Gilbert-Varshamov bound can be made vanishingly small by increasing the number
of accumulators beyond two. In order to address larger rates, random puncturing
of a low-rate mother code is introduced. It is shown that in this case the
resulting ensemble of repeat-accumulate-accumulate codes asymptotically
achieves linear distance growth close to the Gilbert-Varshamov bound. This
holds even for very high rate codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3434</identifier>
 <datestamp>2011-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3434</id><created>2008-10-19</created><updated>2011-08-31</updated><authors><author><keyname>Hirani</keyname><forenames>Anil N.</forenames></author><author><keyname>Nakshatrala</keyname><forenames>Kalyana B.</forenames></author><author><keyname>Chaudhry</keyname><forenames>Jehanzeb H.</forenames></author></authors><title>Numerical method for Darcy flow derived using Discrete Exterior Calculus</title><categories>math.NA cs.NA math.DG</categories><comments>Added numerical experiment for flow on a surface. Other small changes
  in meshing related comments</comments><report-no>UIUCDCS-R-2008-2937</report-no><msc-class>65N30, 76S05 (Primary), 53-04, 55-04 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive a numerical method for Darcy flow, hence also for Poisson's
equation in mixed (first order) form, based on discrete exterior calculus
(DEC). Exterior calculus is a generalization of vector calculus to smooth
manifolds and DEC is one of its discretizations on simplicial complexes such as
triangle and tetrahedral meshes. DEC is a coordinate invariant discretization,
in that it does not depend on the embedding of the simplices or the whole mesh.
We start by rewriting the governing equations of Darcy flow using the language
of exterior calculus. This yields a formulation in terms of flux differential
form and pressure. The numerical method is then derived by using the framework
provided by DEC for discretizing differential forms and operators that act on
forms. We also develop a discretization for spatially dependent Hodge star that
varies with the permeability of the medium. This also allows us to address
discontinuous permeability. The matrix representation for our discrete
non-homogeneous Hodge star is diagonal, with positive diagonal entries. The
resulting linear system of equations for flux and pressure are saddle type,
with a diagonal matrix as the top left block. The performance of the proposed
numerical method is illustrated on many standard test problems. These include
patch tests in two and three dimensions, comparison with analytically known
solution in two dimensions, layered medium with alternating permeability
values, and a test with a change in permeability along the flow direction. We
also show numerical evidence of convergence of the flux and the pressure. A
convergence experiment is also included for Darcy flow on a surface. A short
introduction to the relevant parts of smooth and discrete exterior calculus is
included in this paper. We also include a discussion of the boundary condition
in terms of exterior calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3438</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3438</id><created>2008-10-19</created><authors><author><keyname>Bhosle</keyname><forenames>Amit M</forenames></author><author><keyname>Gonzalez</keyname><forenames>Teofilo F</forenames></author></authors><title>Efficient Algorithms and Routing Protocols for Handling Transient Single
  Node Failures</title><categories>cs.DS</categories><comments>6 pages, 2 columns, 3 figures. To appear in: Proceedings of the 20th
  IASTED International Conference on Parallel and Distributed Computing and
  Systems (Nov 16-18, 2008, Orlando, FL, USA)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single node failures represent more than 85% of all node failures in the
today's large communication networks such as the Internet. Also, these node
failures are usually transient. Consequently, having the routing paths globally
recomputed does not pay off since the failed nodes recover fairly quickly, and
the recomputed routing paths need to be discarded. Instead, we develop
algorithms and protocols for dealing with such transient single node failures
by suppressing the failure (instead of advertising it across the network), and
routing messages to the destination via alternate paths that do not use the
failed node. We compare our solution to that of Ref. [11] wherein the authors
have presented a &quot;Failure Insensitive Routing&quot; protocol as a proactive recovery
scheme for handling transient node failures. We show that our algorithms are
faster by an order of magnitude while our paths are equally good. We show via
simulation results that our paths are usually within 15% of the optimal for
randomly generated graph with 100-1000 nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3442</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3442</id><created>2008-10-19</created><updated>2009-11-21</updated><authors><author><keyname>Lipowski</keyname><forenames>Adam</forenames></author><author><keyname>Lipowska</keyname><forenames>Dorota</forenames></author></authors><title>Language structure in the n-object naming game</title><categories>cs.CL cs.MA physics.soc-ph</categories><comments>minor changes</comments><journal-ref>Phys. Rev. E 80, 056107 (2009)</journal-ref><doi>10.1103/PhysRevE.80.056107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine a naming game with two agents trying to establish a common
vocabulary for n objects. Such efforts lead to the emergence of language that
allows for an efficient communication and exhibits some degree of homonymy and
synonymy. Although homonymy reduces the communication efficiency, it seems to
be a dynamical trap that persists for a long, and perhaps indefinite, time. On
the other hand, synonymy does not reduce the efficiency of communication, but
appears to be only a transient feature of the language. Thus, in our model the
role of synonymy decreases and in the long-time limit it becomes negligible. A
similar rareness of synonymy is observed in present natural languages. The role
of noise, that distorts the communicated words, is also examined. Although, in
general, the noise reduces the communication efficiency, it also regroups the
words so that they are more evenly distributed within the available &quot;verbal&quot;
space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3451</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3451</id><created>2008-10-19</created><authors><author><keyname>Szita</keyname><forenames>Istv&#xe1;n</forenames></author><author><keyname>L&#x151;rincz</keyname><forenames>Andr&#xe1;s</forenames></author></authors><title>The many faces of optimism - Extended version</title><categories>cs.AI cs.CC cs.LG</categories><comments>Extended version of the homonymous ICML'08 paper, with proofs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The exploration-exploitation dilemma has been an intriguing and unsolved
problem within the framework of reinforcement learning. &quot;Optimism in the face
of uncertainty&quot; and model building play central roles in advanced exploration
methods. Here, we integrate several concepts and obtain a fast and simple
algorithm. We show that the proposed algorithm finds a near-optimal policy in
polynomial time, and give experimental evidence that it is robust and efficient
compared to its ascendants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3453</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3453</id><created>2008-10-19</created><authors><author><keyname>Benjamin</keyname><forenames>Douglas P.</forenames></author></authors><title>Grid Computing in the Collider Detector at Fermilab (CDF) scientific
  experiment</title><categories>cs.DC hep-ex physics.data-an</categories><comments>ICHEP08</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The computing model for the Collider Detector at Fermilab (CDF) scientific
experiment has evolved since the beginning of the experiment. Initially CDF
computing was comprised of dedicated resources located in computer farms around
the world. With the wide spread acceptance of grid computing in High Energy
Physics, CDF computing has migrated to using grid computing extensively. CDF
uses computing grids around the world. Each computing grid has required
different solutions. The use of portals as interfaces to the collaboration
computing resources has proven to be an extremely useful technique allowing the
CDF physicists transparently migrate from using dedicated computer farm to
using computing located in grid farms often away from Fermilab. Grid computing
at CDF continues to evolve as the grid standards and practices change.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3468</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3468</id><created>2008-10-20</created><authors><author><keyname>Annamalai</keyname><forenames>Muthiah</forenames></author><author><keyname>Velusamy</keyname><forenames>Leela</forenames></author></authors><title>A Call-Graph Profiler for GNU Octave</title><categories>cs.PF cs.PL cs.SE</categories><comments>6 pages, 2 figures, 1 table. Fix typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report the design and implementation of a call-graph profiler for GNU
Octave, a numerical computing platform. GNU Octave simplifies matrix
computation for use in modeling or simulation. Our work provides a call-graph
profiler, which is an improvement on the flat profiler. We elaborate design
constraints of building a profiler for numerical computation, and benchmark the
profiler by comparing it to the rudimentary timer start-stop (tic-toc)
measurements, for a similar set of programs. The profiler code provides clean
interfaces to internals of GNU Octave, for other (newer) profiling tools on GNU
Octave.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3474</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3474</id><created>2008-10-20</created><authors><author><keyname>Marivate</keyname><forenames>Vukosi N.</forenames></author><author><keyname>Marwala</keyname><forenames>Tshilidzi</forenames></author></authors><title>Social Learning Methods in Board Games</title><categories>cs.AI cs.MA</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses the effects of social learning in training of game
playing agents. The training of agents in a social context instead of a
self-play environment is investigated. Agents that use the reinforcement
learning algorithms are trained in social settings. This mimics the way in
which players of board games such as scrabble and chess mentor each other in
their clubs. A Round Robin tournament and a modified Swiss tournament setting
are used for the training. The agents trained using social settings are
compared to self play agents and results indicate that more robust agents
emerge from the social training setting. Higher state space games can benefit
from such settings as diverse set of agents will have multiple strategies that
increase the chances of obtaining more experienced players at the end of
training. The Social Learning trained agents exhibit better playing experience
than self play agents. The modified Swiss playing style spawns a larger number
of better playing agents as the population size increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3484</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3484</id><created>2008-10-20</created><authors><author><keyname>Ochoa</keyname><forenames>Gabriela</forenames><affiliation>ISI</affiliation></author><author><keyname>Tomassini</keyname><forenames>Marco</forenames><affiliation>ISI</affiliation></author><author><keyname>Verel</keyname><forenames>S&#xe9;bastien</forenames><affiliation>I3S</affiliation></author><author><keyname>Darabos</keyname><forenames>Christian</forenames><affiliation>ISI</affiliation></author></authors><title>A Study of NK Landscapes' Basins and Local Optima Networks</title><categories>cs.NE</categories><comments>best paper nomination</comments><proxy>ccsd hal-00331868</proxy><journal-ref>Genetic And Evolutionary Computation Conference, Atlanta :
  \'Etats-Unis d'Am\'erique (2008)</journal-ref><doi>10.1145/1389095.1389204</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a network characterization of combinatorial fitness landscapes by
adapting the notion of inherent networks proposed for energy surfaces (Doye,
2002). We use the well-known family of $NK$ landscapes as an example. In our
case the inherent network is the graph where the vertices are all the local
maxima and edges mean basin adjacency between two maxima. We exhaustively
extract such networks on representative small NK landscape instances, and show
that they are 'small-worlds'. However, the maxima graphs are not random, since
their clustering coefficients are much larger than those of corresponding
random graphs. Furthermore, the degree distributions are close to exponential
instead of Poissonian. We also describe the nature of the basins of attraction
and their relationship with the local maxima network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3492</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3492</id><created>2008-10-20</created><authors><author><keyname>Verel</keyname><forenames>S&#xe9;bastien</forenames><affiliation>I3S</affiliation></author><author><keyname>Ochoa</keyname><forenames>Gabriela</forenames><affiliation>ISI</affiliation></author><author><keyname>Tomassini</keyname><forenames>Marco</forenames><affiliation>ISI</affiliation></author></authors><title>The Connectivity of NK Landscapes' Basins: A Network Analysis</title><categories>cs.NE</categories><comments>Artificial Life XI, Winchester : France (2008)</comments><proxy>ccsd hal-00331864</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a network characterization of combinatorial fitness landscapes by
adapting the notion of inherent networks proposed for energy surfaces. We use
the well-known family of NK landscapes as an example. In our case the inherent
network is the graph where the vertices represent the local maxima in the
landscape, and the edges account for the transition probabilities between their
corresponding basins of attraction. We exhaustively extracted such networks on
representative small NK landscape instances, and performed a statistical
characterization of their properties. We found that most of these network
properties can be related to the search difficulty on the underlying NK
landscapes with varying values of K.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3525</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3525</id><created>2008-10-20</created><authors><author><keyname>Masisi</keyname><forenames>L.</forenames></author><author><keyname>Nelwamondo</keyname><forenames>V.</forenames></author><author><keyname>Marwala</keyname><forenames>T.</forenames></author></authors><title>The use of entropy to measure structural diversity</title><categories>cs.LG cs.AI q-bio.QM</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper entropy based methods are compared and used to measure
structural diversity of an ensemble of 21 classifiers. This measure is mostly
applied in ecology, whereby species counts are used as a measure of diversity.
The measures used were Shannon entropy, Simpsons and the Berger Parker
diversity indexes. As the diversity indexes increased so did the accuracy of
the ensemble. An ensemble dominated by classifiers with the same structure
produced poor accuracy. Uncertainty rule from information theory was also used
to further define diversity. Genetic algorithms were used to find the optimal
ensemble by using the diversity indices as the cost function. The method of
voting was used to aggregate the decisions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3564</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3564</id><created>2008-10-20</created><authors><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author><author><keyname>Shapiro</keyname><forenames>Jeffrey H.</forenames></author><author><keyname>Venkatesan</keyname><forenames>Vinodh</forenames></author><author><keyname>Wang</keyname><forenames>Ligong</forenames></author></authors><title>The Poisson Channel at Low Input Powers</title><categories>cs.IT math.IT</categories><comments>To be presented at IEEEI 2008, December 3-5 2008, Eilat, Israel</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The asymptotic capacity at low input powers of an average-power limited or an
average- and peak-power limited discrete-time Poisson channel is considered.
For a Poisson channel whose dark current is zero or decays to zero linearly
with its average input power $E$, capacity scales like $E\log\frac{1}{E}$ for
small $E$. For a Poisson channel whose dark current is a nonzero constant,
capacity scales, to within a constant, like $E\log\log\frac{1}{E}$ for small
$E$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3579</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3579</id><created>2008-10-20</created><authors><author><keyname>Dup&#xe9;</keyname><forenames>Fran&#xe7;ois-Xavier</forenames><affiliation>GREYC</affiliation></author><author><keyname>Brun</keyname><forenames>Luc</forenames><affiliation>GREYC</affiliation></author></authors><title>Hierarchical Bag of Paths for Kernel Based Shape Classification</title><categories>cs.CV</categories><proxy>ccsd hal-00332317</proxy><journal-ref>Joint IAPR International Workshops on Structural and Syntactic
  Pattern Recognition (SSPR 2008), Orlando : \'Etats-Unis d'Am\'erique (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph kernels methods are based on an implicit embedding of graphs within a
vector space of large dimension. This implicit embedding allows to apply to
graphs methods which where until recently solely reserved to numerical data.
Within the shape classification framework, graphs are often produced by a
skeletonization step which is sensitive to noise. We propose in this paper to
integrate the robustness to structural noise by using a kernel based on a bag
of path where each path is associated to a hierarchy encoding successive
simplifications of the path. Several experiments prove the robustness and the
flexibility of our approach compared to alternative shape classification
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3581</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3581</id><created>2008-10-20</created><updated>2008-11-11</updated><authors><author><keyname>Etessami</keyname><forenames>Kousha</forenames></author><author><keyname>Yannakakis</keyname><forenames>Mihalis</forenames></author></authors><title>Recursive Concurrent Stochastic Games</title><categories>cs.GT cs.CC</categories><comments>21 pages, 2 figures</comments><acm-class>G.3; F.2; F.1.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 4 (November
  11, 2008) lmcs:1196</journal-ref><doi>10.2168/LMCS-4(4:7)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study Recursive Concurrent Stochastic Games (RCSGs), extending our recent
analysis of recursive simple stochastic games to a concurrent setting where the
two players choose moves simultaneously and independently at each state. For
multi-exit games, our earlier work already showed undecidability for basic
questions like termination, thus we focus on the important case of single-exit
RCSGs (1-RCSGs).
  We first characterize the value of a 1-RCSG termination game as the least
fixed point solution of a system of nonlinear minimax functional equations, and
use it to show PSPACE decidability for the quantitative termination problem. We
then give a strategy improvement technique, which we use to show that player 1
(maximizer) has \epsilon-optimal randomized Stackless &amp; Memoryless (r-SM)
strategies for all \epsilon &gt; 0, while player 2 (minimizer) has optimal r-SM
strategies. Thus, such games are r-SM-determined. These results mirror and
generalize in a strong sense the randomized memoryless determinacy results for
finite stochastic games, and extend the classic Hoffman-Karp strategy
improvement approach from the finite to an infinite state setting. The proofs
in our infinite-state setting are very different however, relying on subtle
analytic properties of certain power series that arise from studying 1-RCSGs.
  We show that our upper bounds, even for qualitative (probability 1)
termination, can not be improved, even to NP, without a major breakthrough, by
giving two reductions: first a P-time reduction from the long-standing
square-root sum problem to the quantitative termination decision problem for
finite concurrent stochastic games, and then a P-time reduction from the latter
problem to the qualitative termination problem for 1-RCSGs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3605</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3605</id><created>2008-10-20</created><updated>2010-04-10</updated><authors><author><keyname>Ortega</keyname><forenames>Pedro A.</forenames></author><author><keyname>Braun</keyname><forenames>Daniel A.</forenames></author></authors><title>A Minimum Relative Entropy Principle for Learning and Acting</title><categories>cs.AI cs.LG</categories><comments>36 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a method to construct an adaptive agent that is universal
with respect to a given class of experts, where each expert is an agent that
has been designed specifically for a particular environment. This adaptive
control problem is formalized as the problem of minimizing the relative entropy
of the adaptive agent from the expert that is most suitable for the unknown
environment. If the agent is a passive observer, then the optimal solution is
the well-known Bayesian predictor. However, if the agent is active, then its
past actions need to be treated as causal interventions on the I/O stream
rather than normal probability conditions. Here it is shown that the solution
to this new variational problem is given by a stochastic controller called the
Bayesian control rule, which implements adaptive behavior as a mixture of
experts. Furthermore, it is shown that under mild assumptions, the Bayesian
control rule converges to the control law of the most suitable expert.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3626</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3626</id><created>2008-10-20</created><updated>2008-10-20</updated><authors><author><keyname>Annamalai</keyname><forenames>Muthiah</forenames></author><author><keyname>Shrestha</keyname><forenames>Darshan</forenames></author><author><keyname>Tjuatja</keyname><forenames>Saibun</forenames></author></authors><title>Experimental Study of Application Specific Source Coding for Wireless
  Sensor Networks</title><categories>cs.NI cs.DC</categories><comments>7 pages, 7 figures, 8 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The energy bottleneck in Wireless Sensor Network(WSN) can be reduced by
limiting communication overhead. Application specific source coding schemes for
the sensor networks provide fewer bits to represent the same amount of
information exploiting the redundancy present in the source model, network
architecture and the physical process. This paper reports the performance of
representative codes from various families of source coding schemes (lossless,
lossy, constant bit-rate, variable bit-rate, distributed and joint
encoding/decoding) in terms of energy consumed, bit-rate achieved,
quantization-error/reconstruction-error, latency and complexity of
encoder-decoder(codec). A reusable frame work for testing source codes is
provided. Finally we propose a set of possible applications and suitable source
codes in terms of these parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3631</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3631</id><created>2008-10-20</created><authors><author><keyname>Tian</keyname><forenames>Chao</forenames></author><author><keyname>Mohajer</keyname><forenames>Soheil</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas N.</forenames></author></authors><title>Approximating the Gaussian Multiple Description Rate Region Under
  Symmetric Distortion Constraints</title><categories>cs.IT math.IT</categories><comments>46 pages, 5 figures, submitted to IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider multiple description coding for the Gaussian source with K
descriptions under the symmetric mean squared error distortion constraints, and
provide an approximate characterization of the rate region. We show that the
rate region can be sandwiched between two polytopes, between which the gap can
be upper bounded by constants dependent on the number of descriptions, but
independent of the exact distortion constraints. Underlying this result is an
exact characterization of the lossless multi-level diversity source coding
problem: a lossless counterpart of the MD problem. This connection provides a
polytopic template for the inner and outer bounds to the rate region. In order
to establish the outer bound, we generalize Ozarow's technique to introduce a
strategic expansion of the original probability space by more than one random
variables. For the symmetric rate case with any number of descriptions, we show
that the gap between the upper bound and the lower bound for the individual
description rate is no larger than 0.92 bit. The results developed in this work
also suggest the &quot;separation&quot; approach of combining successive refinement
quantization and lossless multi-level diversity coding is a competitive one,
since it is only a constant away from the optimum. The results are further
extended to general sources under the mean squared error distortion measure,
where a similar but looser bound on the gap holds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3641</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3641</id><created>2008-10-20</created><authors><author><keyname>Duchamp</keyname><forenames>G&#xe9;rard Henry Edmond</forenames><affiliation>LIPN</affiliation></author><author><keyname>Goodenough</keyname><forenames>Silvia</forenames><affiliation>LIPN</affiliation></author><author><keyname>Penson</keyname><forenames>Karol A.</forenames><affiliation>LPTMC</affiliation></author></authors><title>Rational Hadamard products via Quantum Diagonal Operators</title><categories>cs.SC math-ph math.CO math.MP</categories><proxy>ccsd hal-00332398</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use the remark that, through Bargmann-Fock representation, diagonal
operators of the Heisenberg-Weyl algebra are scalars for the Hadamard product
to give some properties (like the stability of periodic fonctions) of the
Hadamard product by a rational fraction. In particular, we provide through this
way explicit formulas for the multiplication table of the Hadamard product in
the algebra of rational functions in $\C[[z]]$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3671</identifier>
 <datestamp>2008-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3671</id><created>2008-10-20</created><authors><author><keyname>Golding</keyname><forenames>Dan</forenames></author><author><keyname>Wilson</keyname><forenames>Linda</forenames></author><author><keyname>Marwala</keyname><forenames>Tshilidzi</forenames></author></authors><title>Emergency Centre Organization and Automated Triage System</title><categories>cs.CY</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The excessive rate of patients arriving at accident and emergency centres is
a major problem facing South African hospitals. Patients are prioritized for
medical care through a triage process. Manual systems allow for inconsistency
and error. This paper proposes a novel system to automate accident and
emergency centre triage and uses this triage score along with an artificial
intelligence estimate of patient-doctor time to optimize the queue order. A
fuzzy inference system is employed to triage patients and a similar system
estimates the time but adapts continuously through fuzzy Q-learning. The
optimal queue order is found using a novel procedure based on genetic
algorithms. These components are integrated in a simple graphical user
interface. Live tests could not be performed but simulations reveal that the
average waiting time can be reduced by 48 minutes and priority is given to
urgent patients
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3695</identifier>
 <datestamp>2013-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3695</id><created>2008-10-20</created><authors><author><keyname>Krovi</keyname><forenames>Hari</forenames></author><author><keyname>Roetteler</keyname><forenames>Martin</forenames></author></authors><title>An Efficient Quantum Algorithm for the Hidden Subgroup Problem over
  Weyl-Heisenberg Groups</title><categories>quant-ph cs.CC</categories><comments>20 pages, 1 figure</comments><journal-ref>Proceedings of Mathematical Methods in Computer Science,
  (MMICS'08), pp.70-88, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many exponential speedups that have been achieved in quantum computing are
obtained via hidden subgroup problems (HSPs). We show that the HSP over
Weyl-Heisenberg groups can be solved efficiently on a quantum computer. These
groups are well-known in physics and play an important role in the theory of
quantum error-correcting codes. Our algorithm is based on non-commutative
Fourier analysis of coset states which are quantum states that arise from a
given black-box function. We use Clebsch-Gordan decompositions to combine and
reduce tensor products of irreducible representations. Furthermore, we use a
new technique of changing labels of irreducible representations to obtain
low-dimensional irreducible representations in the decomposition process. A
feature of the presented algorithm is that in each iteration of the algorithm
the quantum computer operates on two coset states simultaneously. This is an
improvement over the previously best known quantum algorithm for these groups
which required four coset states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3708</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3708</id><created>2008-10-21</created><updated>2008-10-29</updated><authors><author><keyname>Deng</keyname><forenames>Yuxin</forenames></author><author><keyname>Hennessy</keyname><forenames>Matthew</forenames></author><author><keyname>van Glabbeek</keyname><forenames>Rob</forenames></author><author><keyname>Morgan</keyname><forenames>Carroll</forenames></author></authors><title>Characterising Testing Preorders for Finite Probabilistic Processes</title><categories>cs.LO</categories><comments>33 pages</comments><acm-class>F.3.2; D.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 4 (October
  28, 2008) lmcs:694</journal-ref><doi>10.2168/LMCS-4(4:4)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1992 Wang &amp; Larsen extended the may- and must preorders of De Nicola and
Hennessy to processes featuring probabilistic as well as nondeterministic
choice. They concluded with two problems that have remained open throughout the
years, namely to find complete axiomatisations and alternative
characterisations for these preorders. This paper solves both problems for
finite processes with silent moves. It characterises the may preorder in terms
of simulation, and the must preorder in terms of failure simulation. It also
gives a characterisation of both preorders using a modal logic. Finally it
axiomatises both preorders over a probabilistic version of CSP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3715</identifier>
 <datestamp>2008-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3715</id><created>2008-10-20</created><authors><author><keyname>Fischione</keyname><forenames>Carlo</forenames></author><author><keyname>Speranzon</keyname><forenames>Alberto</forenames></author><author><keyname>Johansson</keyname><forenames>Karl H.</forenames></author><author><keyname>Sangiovanni-Vincentelli</keyname><forenames>Alberto</forenames></author></authors><title>Distributed Estimation over Wireless Sensor Networks with Packet Losses</title><categories>cs.DC</categories><comments>23 Pages, 7 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A distributed adaptive algorithm to estimate a time-varying signal, measured
by a wireless sensor network, is designed and analyzed. One of the major
features of the algorithm is that no central coordination among the nodes needs
to be assumed. The measurements taken by the nodes of the network are affected
by noise, and the communication among the nodes is subject to packet losses.
Nodes exchange local estimates and measurements with neighboring nodes. Each
node of the network locally computes adaptive weights that minimize the
estimation error variance. Decentralized conditions on the weights, needed for
the convergence of the estimation error throughout the overall network, are
presented. A Lipschitz optimization problem is posed to guarantee stability and
the minimization of the variance. An efficient strategy to distribute the
computation of the optimal solution is investigated. A theoretical performance
analysis of the distributed algorithm is carried out both in the presence of
perfect and lossy links. Numerical simulations illustrate performance for
various network topologies and packet loss probabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3729</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3729</id><created>2008-10-20</created><updated>2010-03-22</updated><authors><author><keyname>Kim</keyname><forenames>Hyun Kwang</forenames></author><author><keyname>Lee</keyname><forenames>Joon Yop</forenames></author><author><keyname>Oh</keyname><forenames>Dong Yeol</forenames></author></authors><title>Optimal codes in deletion and insertion metric</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>19 pages,The material of this paper was presented in part at the 10th
  International Workshop on Algebraic and Combinatorial Coding Theory,
  Zvenigorod, Russia, September 2006</comments><msc-class>94B60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We improve the upper bound of Levenshtein for the cardinality of a code of
length 4 capable of correcting single deletions over an alphabet of even size.
We also illustrate that the new upper bound is sharp. Furthermore we will
construct an optimal perfect code capable of correcting single deletions for
the same parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3776</identifier>
 <datestamp>2008-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3776</id><created>2008-10-21</created><authors><author><keyname>Maiti</keyname><forenames>Deepyaman</forenames></author><author><keyname>Biswas</keyname><forenames>Sagnik</forenames></author><author><keyname>Konar</keyname><forenames>Amit</forenames></author></authors><title>Design of a Fractional Order PID Controller Using Particle Swarm
  Optimization Technique</title><categories>cs.OH</categories><comments>2nd National Conference on Recent Trends in Information Systems
  (ReTIS-08) 5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Particle Swarm Optimization technique offers optimal or suboptimal solution
to multidimensional rough objective functions. In this paper, this optimization
technique is used for designing fractional order PID controllers that give
better performance than their integer order counterparts. Controller synthesis
is based on required peak overshoot and rise time specifications. The
characteristic equation is minimized to obtain an optimum set of controller
parameters. Results show that this design method can effectively tune the
parameters of the fractional order controller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3783</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3783</id><created>2008-10-21</created><updated>2010-09-07</updated><authors><author><keyname>Wei</keyname><forenames>Fei</forenames></author><author><keyname>Yang</keyname><forenames>Huazhong</forenames></author></authors><title>Directed Transmission Method, A Fully Asynchronous approach to Solve
  Sparse Linear Systems in Parallel</title><categories>math.NA cs.DC</categories><comments>v1: poster presented in SPAA'08; v2: full paper; v3: rename EVS to
  GNBT; v4: reuse EVS. More info, see my web page at
  http://weifei00.googlepages.com</comments><msc-class>65F10, 65F50, 68M14</msc-class><doi>10.1145/1378533.1378598</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new distributed algorithm, called Directed
Transmission Method (DTM). DTM is a fully asynchronous and continuous-time
iterative algorithm to solve SPD sparse linear system. As an architecture-aware
algorithm, DTM could be freely running on all kinds of heterogeneous parallel
computer. We proved that DTM is convergent by making use of the final-value
theorem of Laplacian Transformation. Numerical experiments show that DTM is
stable and efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3787</identifier>
 <datestamp>2014-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3787</id><created>2008-10-21</created><updated>2009-04-08</updated><authors><author><keyname>Guenther</keyname><forenames>Annika</forenames></author><author><keyname>Nebe</keyname><forenames>Gabriele</forenames></author></authors><title>Automorphisms of doubly-even self-dual binary codes</title><categories>math.NT cs.IT math.IT</categories><comments>Added a new proof for the main result</comments><msc-class>94B05; 20G25; 11E95</msc-class><doi>10.1112/blms/bdp026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The automorphism group of a binary doubly-even self-dual code is always
contained in the alternating group. On the other hand, given a permutation
group $G$ of degree $n$ there exists a doubly-even self-dual $G$-invariant code
if and only if $n$ is a multiple of 8, every simple self-dual $\F_2G$-module
occurs with even multiplicity in $\F_2^n$, and $G$ is contained in the
alternating group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3827</identifier>
 <datestamp>2008-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3827</id><created>2008-10-21</created><authors><author><keyname>Shaqfeh</keyname><forenames>Mohamed</forenames></author><author><keyname>Goertz</keyname><forenames>Norbert</forenames></author></authors><title>Comments on the Boundary of the Capacity Region of Multiaccess Fading
  Channels</title><categories>cs.IT math.IT</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A modification is proposed for the formula known from the literature that
characterizes the boundary of the capacity region of Gaussian multiaccess
fading channels. The modified version takes into account potentially negative
arguments of the cumulated density function that would affect the accuracy of
the numerical capacity results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3828</identifier>
 <datestamp>2008-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3828</id><created>2008-10-21</created><authors><author><keyname>Dong</keyname><forenames>Daoyi</forenames></author><author><keyname>Chen</keyname><forenames>Chunlin</forenames></author><author><keyname>Li</keyname><forenames>Hanxiong</forenames></author><author><keyname>Tarn</keyname><forenames>Tzyh-Jong</forenames></author></authors><title>Quantum reinforcement learning</title><categories>quant-ph cs.AI cs.LG</categories><comments>13 pages, 7 figures, Latex</comments><journal-ref>IEEE Transactions on Systems Man and Cybernetics Part B:
  Cybernetics, Vol. 38, No. 5, pp.1207-1220, 2008</journal-ref><doi>10.1109/TSMCB.2008.925743</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The key approaches for machine learning, especially learning in unknown
probabilistic environments are new representations and computation mechanisms.
In this paper, a novel quantum reinforcement learning (QRL) method is proposed
by combining quantum theory and reinforcement learning (RL). Inspired by the
state superposition principle and quantum parallelism, a framework of value
updating algorithm is introduced. The state (action) in traditional RL is
identified as the eigen state (eigen action) in QRL. The state (action) set can
be represented with a quantum superposition state and the eigen state (eigen
action) can be obtained by randomly observing the simulated quantum state
according to the collapse postulate of quantum measurement. The probability of
the eigen action is determined by the probability amplitude, which is
parallelly updated according to rewards. Some related characteristics of QRL
such as convergence, optimality and balancing between exploration and
exploitation are also analyzed, which shows that this approach makes a good
tradeoff between exploration and exploitation using the probability amplitude
and can speed up learning through the quantum parallelism. To evaluate the
performance and practicability of QRL, several simulated experiments are given
and the results demonstrate the effectiveness and superiority of QRL algorithm
for some complex problems. The present work is also an effective exploration on
the application of quantum computation to artificial intelligence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3836</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3836</id><created>2008-10-21</created><updated>2010-10-11</updated><authors><author><keyname>Ducourthial</keyname><forenames>Bertrand</forenames><affiliation>HEUDIASYC</affiliation></author><author><keyname>Khalfallah</keyname><forenames>Sofiane</forenames><affiliation>HEUDIASYC</affiliation></author><author><keyname>Petit</keyname><forenames>Franck</forenames><affiliation>LIP6</affiliation></author></authors><title>Best-effort Group Service in Dynamic Networks</title><categories>cs.DC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a group membership service for dynamic ad hoc networks. It
maintains as long as possible the existing groups and ensures that each group
diameter is always smaller than a constant, fixed according to the application
using the groups. The proposed protocol is self-stabilizing and works in
dynamic distributed systems. Moreover, it ensures a kind of continuity in the
service offer to the application while the system is converging, except if too
strong topology changes happen. Such a best effort behavior allows applications
to rely on the groups while the stabilization has not been reached, which is
very useful in dynamic ad hoc networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3851</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3851</id><created>2008-10-21</created><authors><author><keyname>Hogg</keyname><forenames>David W.</forenames><affiliation>NYU</affiliation></author><author><keyname>Lang</keyname><forenames>Dustin</forenames><affiliation>Toronto</affiliation></author></authors><title>Astronomical imaging: The theory of everything</title><categories>astro-ph cs.CV physics.data-an</categories><comments>a talk given at &quot;Classification and Discovery in Large Astronomical
  Surveys&quot;, Ringberg Castle, 2008-10-16</comments><doi>10.1063/1.3059072</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are developing automated systems to provide homogeneous calibration
meta-data for heterogeneous imaging data, using the pixel content of the image
alone where necessary. Standardized and complete calibration meta-data permit
generative modeling: A good model of the sky through wavelength and time--that
is, a model of the positions, motions, spectra, and variability of all stellar
sources, plus an intensity map of all cosmological sources--could synthesize or
generate any astronomical image ever taken at any time with any equipment in
any configuration. We argue that the best-fit or highest likelihood model of
the data is also the best possible astronomical catalog constructed from those
data. A generative model or catalog of this form is the best possible platform
for automated discovery, because it is capable of identifying informative
failures of the model in new data at the pixel level, or as statistical
anomalies in the joint distribution of residuals from many images. It is also,
in some sense, an astronomer's &quot;theory of everything&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3865</identifier>
 <datestamp>2008-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3865</id><created>2008-10-21</created><authors><author><keyname>Musehane</keyname><forenames>R.</forenames></author><author><keyname>Netshiongolwe</keyname><forenames>F.</forenames></author><author><keyname>Nelwamondo</keyname><forenames>F. V.</forenames></author><author><keyname>Masisi</keyname><forenames>L.</forenames></author><author><keyname>Marwala</keyname><forenames>T.</forenames></author></authors><title>Relationship between Diversity and Perfomance of Multiple Classifiers
  for Decision Support</title><categories>cs.AI</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents the investigation and implementation of the relationship
between diversity and the performance of multiple classifiers on classification
accuracy. The study is critical as to build classifiers that are strong and can
generalize better. The parameters of the neural network within the committee
were varied to induce diversity; hence structural diversity is the focus for
this study. The hidden nodes and the activation function are the parameters
that were varied. The diversity measures that were adopted from ecology such as
Shannon and Simpson were used to quantify diversity. Genetic algorithm is used
to find the optimal ensemble by using the accuracy as the cost function. The
results observed shows that there is a relationship between structural
diversity and accuracy. It is observed that the classification accuracy of an
ensemble increases as the diversity increases. There was an increase of 3%-6%
in the classification accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3869</identifier>
 <datestamp>2009-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3869</id><created>2008-10-21</created><updated>2009-05-13</updated><authors><author><keyname>Chandrasekhar</keyname><forenames>Vikram</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Muharemovic</keyname><forenames>Tarik</forenames></author><author><keyname>Shen</keyname><forenames>Zukang</forenames></author><author><keyname>Gatherer</keyname><forenames>Alan</forenames></author></authors><title>Power Control in Two-Tier Femtocell Networks</title><categories>cs.NI</categories><comments>29 pages, 10 figures, Revised and resubmitted to the IEEE
  Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a two tier cellular network -- comprised of a central macrocell underlaid
with shorter range femtocell hotspots -- cross-tier interference limits overall
capacity with universal frequency reuse. To quantify near-far effects with
universal frequency reuse, this paper derives a fundamental relation providing
the largest feasible cellular Signal-to-Interference-Plus-Noise Ratio (SINR),
given any set of feasible femtocell SINRs. We provide a link budget analysis
which enables simple and accurate performance insights in a two-tier network. A
distributed utility-based SINR adaptation at femtocells is proposed in order to
alleviate cross-tier interference at the macrocell from cochannel femtocells.
The Foschini-Miljanic (FM) algorithm is a special case of the adaptation. Each
femtocell maximizes their individual utility consisting of a SINR based reward
less an incurred cost (interference to the macrocell). Numerical results show
greater than 30% improvement in mean femtocell SINRs relative to FM. In the
event that cross-tier interference prevents a cellular user from obtaining its
SINR target, an algorithm is proposed that reduces transmission powers of the
strongest femtocell interferers. The algorithm ensures that a cellular user
achieves its SINR target even with 100 femtocells/cell-site, and requires a
worst case SINR reduction of only 16% at femtocells. These results motivate
design of power control schemes requiring minimal network overhead in two-tier
networks with shared spectrum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3891</identifier>
 <datestamp>2008-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3891</id><created>2008-10-21</created><authors><author><keyname>Ahmed</keyname><forenames>N. U.</forenames></author><author><keyname>Rezaei</keyname><forenames>F.</forenames></author><author><keyname>Loyka</keyname><forenames>S.</forenames></author></authors><title>Control Theoretic Formulation of Capacity of Dynamic Electro Magnetic
  Channels</title><categories>cs.IT math.IT</categories><comments>accepted by Communications in Applied Analysis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper nonhomogeneous deterministic and stochastic Maxwell equations
are used to rigorously formulate the capacity of electromagnetic channels such
as wave guides (cavities, coaxial cables etc). Both distributed, but localized,
and Dirichlet boundary data are considered as the potential input sources. We
prove the existence of a source measure, satisfying certain second order
constraints (equivalent to power constraints), at which the channel capacity is
attained. Further, necessary and sufficient conditions for optimality are
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3900</identifier>
 <datestamp>2008-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3900</id><created>2008-10-21</created><updated>2008-10-21</updated><authors><author><keyname>Vaze</keyname><forenames>Rahul</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>On the Capacity and Diversity-Multiplexing Tradeoff of the Two-Way Relay
  Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a multiple input multiple output (MIMO) two-way relay
channel, where two nodes want to exchange data with each other using multiple
relays. An iterative algorithm is proposed to achieve the optimal achievable
rate region, when each relay employs an amplify and forward (AF) strategy.
  The iterative algorithm solves a power minimization problem at every step,
subject to minimum signal-to-interference-and-noise ratio constraints, which is
non-convex, however, for which the Karush Kuhn Tuker conditions are sufficient
for optimality. The optimal AF strategy assumes global channel state
information (CSI) at each relay. To simplify the CSI requirements, a simple
amplify and forward strategy, called dual channel matching, is also proposed,
that requires only local channel state information, and whose achievable rate
region is close to that of the optimal AF strategy. In the asymptotic regime of
large number of relays, we show that the achievable rate region of the dual
channel matching and an upper bound differ by only a constant term and
establish the capacity scaling law of the two-way relay channel. Relay
strategies achieving optimal diversity-multiplexing tradeoff are also
considered with a single relay node. A compress and forward strategy is shown
to be optimal for achieving diversity multiplexing tradeoff for the full-duplex
case, in general, and for the half-duplex case in some cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3935</identifier>
 <datestamp>2008-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3935</id><created>2008-10-21</created><authors><author><keyname>Hsu</keyname><forenames>Wei-jen</forenames></author><author><keyname>Spyropoulos</keyname><forenames>Thrasyvoulos</forenames></author><author><keyname>Psounis</keyname><forenames>Konstantinos</forenames></author><author><keyname>Helmy</keyname><forenames>Ahmed</forenames></author></authors><title>Modeling Spatial and Temporal Dependencies of User Mobility in Wireless
  Mobile Networks</title><categories>cs.NI</categories><comments>14 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Realistic mobility models are fundamental to evaluate the performance of
protocols in mobile ad hoc networks. Unfortunately, there are no mobility
models that capture the non-homogeneous behaviors in both space and time
commonly found in reality, while at the same time being easy to use and
analyze. Motivated by this, we propose a time-variant community mobility model,
referred to as the TVC model, which realistically captures spatial and temporal
correlations. We devise the communities that lead to skewed location visiting
preferences, and time periods that allow us to model time dependent behaviors
and periodic re-appearances of nodes at specific locations.
  To demonstrate the power and flexibility of the TVC model, we use it to
generate synthetic traces that match the characteristics of a number of
qualitatively different mobility traces, including wireless LAN traces,
vehicular mobility traces, and human encounter traces. More importantly, we
show that, despite the high level of realism achieved, our TVC model is still
theoretically tractable. To establish this, we derive a number of important
quantities related to protocol performance, such as the average node degree,
the hitting time, and the meeting time, and provide examples of how to utilize
this theory to guide design decisions in routing protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3990</identifier>
 <datestamp>2008-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3990</id><created>2008-10-22</created><authors><author><keyname>Cessac</keyname><forenames>Bruno</forenames></author><author><keyname>Rostro-Gonz&#xe1;lez</keyname><forenames>Horacio</forenames></author><author><keyname>Vasquez</keyname><forenames>Juan-Carlos</forenames></author><author><keyname>Vi&#xe9;ville</keyname><forenames>Thierry</forenames></author></authors><title>To which extend is the &quot;neural code&quot; a metric ?</title><categories>physics.bio-ph cs.NE physics.data-an q-bio.NC</categories><comments>5 pages 5 figures Proceeding of the conference NeuroComp2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Here is proposed a review of the different choices to structure spike trains,
using deterministic metrics. Temporal constraints observed in biological or
computational spike trains are first taken into account. The relation with
existing neural codes (rate coding, rank coding, phase coding, ..) is then
discussed. To which extend the &quot;neural code&quot; contained in spike trains is
related to a metric appears to be a key point, a generalization of the
Victor-Purpura metric family being proposed for temporal constrained causal
spike trains
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3992</identifier>
 <datestamp>2009-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3992</id><created>2008-10-22</created><updated>2009-03-20</updated><authors><author><keyname>Cessac</keyname><forenames>Bruno</forenames></author><author><keyname>Rochel</keyname><forenames>Olivier</forenames></author><author><keyname>Vi&#xe9;ville</keyname><forenames>Thierry</forenames></author></authors><title>Introducing numerical bounds to improve event-based neural network
  simulation</title><categories>nlin.AO cs.NE nlin.CD q-bio.NC</categories><comments>submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although the spike-trains in neural networks are mainly constrained by the
neural dynamics itself, global temporal constraints (refractoriness, time
precision, propagation delays, ..) are also to be taken into account. These
constraints are revisited in this paper in order to use them in event-based
simulation paradigms.
  We first review these constraints, and discuss their consequences at the
simulation level, showing how event-based simulation of time-constrained
networks can be simplified in this context: the underlying data-structures are
strongly simplified, while event-based and clock-based mechanisms can be easily
mixed. These ideas are applied to punctual conductance-based generalized
integrate-and-fire neural networks simulation, while spike-response model
simulations are also revisited within this framework.
  As an outcome, a fast minimal complementary alternative with respect to
existing simulation event-based methods, with the possibility to simulate
interesting neuron models is implemented and experimented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4000</identifier>
 <datestamp>2009-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4000</id><created>2008-10-22</created><updated>2009-03-19</updated><authors><author><keyname>Lebreton</keyname><forenames>Victor</forenames><affiliation>CES</affiliation></author></authors><title>Le trading algorithmique</title><categories>q-fin.TR cs.GL</categories><proxy>ccsd hal-00332823</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The algorithmic trading comes from digitalisation of the processing of
trading assets on financial markets. Since 1980 the computerization of the
stock market offers real time processing of financial information. This
technological revolution has offered processes and mathematic methods to
identify best return on transactions. Current research relates to autonomous
transaction systems programmed in certain periods and some algorithms. This
offers return opportunities where traders can not intervene. There are about
thirty algorithms to assist the traders, the best known are the VWAP, the TWAP,
TVOL. The algorithms offer the latest strategies and decision-making are the
subject of much research. These advances in modeling decision-making autonomous
agent can envisage a rich future for these technologies, the players already in
use for more than 30% of their trading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4002</identifier>
 <datestamp>2008-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4002</id><created>2008-10-22</created><authors><author><keyname>Allali</keyname><forenames>Julien</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Sagot</keyname><forenames>Marie-France</forenames><affiliation>ENS Lyon / Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author></authors><title>A new distance for high level RNA secondary structure comparison</title><categories>cs.DS q-bio.QM</categories><proxy>ccsd hal-00306658</proxy><journal-ref>IEEE/ACM Transactions on Computational Biology and Bioinformatics
  2 (2005) 3--14</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an algorithm for comparing two RNA secondary structures coded in
the form of trees that introduces two new operations, called node fusion and
edge fusion, besides the tree edit operations of deletion, insertion, and
relabeling classically used in the literature. This allows us to address some
serious limitations of the more traditional tree edit operations when the trees
represent RNAs and what is searched for is a common structural core of two
RNAs. Although the algorithm complexity has an exponential term, this term
depends only on the number of successive fusions that may be applied to a same
node, not on the total number of fusions. The algorithm remains therefore
efficient in practice and is used for illustrative purposes on ribosomal as
well as on other types of RNAs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4015</identifier>
 <datestamp>2009-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4015</id><created>2008-10-22</created><updated>2009-10-07</updated><authors><author><keyname>Helleseth</keyname><forenames>Tor</forenames></author><author><keyname>Kholosha</keyname><forenames>Alexander</forenames></author></authors><title>On the Equation $x^{2^l+1}+x+a=0$ over $\mathrm{GF}(2^k)$ (Extended
  Version)</title><categories>cs.DM</categories><comments>Extended version of the paper with the same title which earlier
  appeared in Finite Fields and their applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the polynomials $P_a(x)=x^{2^l+1}+x+a$ with
$a\in\mathrm{GF}(2^k)$ are studied. New criteria for the number of zeros of
$P_a(x)$ in $\mathrm{GF}(2^k)$ are proved. In particular, a criterion for
$P_a(x)$ to have exactly one zero in $\mathrm{GF}(2^k)$ when $\gcd(l,k)=1$ is
formulated in terms of the values of permutation polynomials introduced by
Dobbertin. We also study the affine polynomial $a^{2^l}x^{2^{2l}}+x^{2^l}+ax+1$
which is closely related to $P_a(x)$. In many cases, explicit expressions for
calculating zeros of these polynomials are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4058</identifier>
 <datestamp>2009-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4058</id><created>2008-10-22</created><updated>2009-08-31</updated><authors><author><keyname>Mukherjee</keyname><forenames>Satyam</forenames></author><author><keyname>Gupte</keyname><forenames>Neelima</forenames></author><author><keyname>Mukherjee</keyname><forenames>Gautam</forenames></author></authors><title>Statistical Characterizers of Transport in a Communication Network</title><categories>physics.soc-ph cond-mat.stat-mech cs.NI</categories><comments>Submitted to Phys. Rev. E (Rapid)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We identify the statistical characterizers of congestion and decongestion for
message transport in model communication lattices. These turn out to be the
travel time distributions, which are Gaussian in the congested phase, and
log-normal in the decongested phase. Our results are demonstrated for two
dimensional lattices, such the Waxman graph, and for lattices with local
clustering and geographic separations, gradient connections, as well as for a
1-d ring lattice with random assortative connections. The behavior of the
distribution identifies the congested and decongested phase correctly for these
distinct network topologies and decongestion strategies. The waiting time
distributions of the systems also show identical signatures of the congested
and decongested phases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4059</identifier>
 <datestamp>2008-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4059</id><created>2008-10-22</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author><author><keyname>Kamal</keyname><forenames>Ahmed E.</forenames></author></authors><title>Network Coding-based Protection Strategies Against a Single Link Failure
  in Optical Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>6 pages, 3 figures, ICCES '08</comments><journal-ref>Proc. of IEEE ICCES '08, Cairo, EG, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we develop network protection strategies against a single link
failure in optical networks. The motivation behind this work is the fact that
$%70$ of all available links in an optical network suffers from a single link
failure. In the proposed protection strategies, denoted NPS-I and NPS-II, we
deploy network coding and reduced capacity on the working paths to provide a
backup protection path that will carry encoded data from all sources. In
addition, we provide implementation aspects and how to deploy the proposed
strategies in case of an optical network with $n$ disjoint working paths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4061</identifier>
 <datestamp>2008-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4061</id><created>2008-10-22</created><authors><author><keyname>Orponen</keyname><forenames>Pekka</forenames></author><author><keyname>Schaeffer</keyname><forenames>Satu Elisa</forenames></author><author><keyname>Gayt&#xe1;n</keyname><forenames>Vanesa Avalos</forenames></author></authors><title>Locally computable approximations for spectral clustering and absorption
  times of random walks</title><categories>cs.DM cs.DS</categories><comments>21 pages, 8 figures</comments><acm-class>G.2.2; G.3; H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of determining a natural local neighbourhood or
&quot;cluster&quot; associated to a given seed vertex in an undirected graph. We
formulate the task in terms of absorption times of random walks from other
vertices to the vertex of interest, and observe that these times are well
approximated by the components of the principal eigenvector of the
corresponding fundamental matrix of the graph's adjacency matrix. We further
present a locally computable gradient-descent method to estimate this
Dirichlet-Fiedler vector, based on minimising the respective Rayleigh quotient.
Experimental evaluation shows that the approximations behave well and yield
well-defined local clusters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4112</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4112</id><created>2008-10-22</created><authors><author><keyname>Couvreur</keyname><forenames>Alain</forenames></author></authors><title>Sums of residues on algebraic surfaces and application to coding theory</title><categories>math.AG cs.IT math.IT</categories><comments>31 pages</comments><msc-class>14J99, 14J20, 14G50, 94B27</msc-class><journal-ref>Journal of Pure and Applied Algebra, vol 213 number 12, pages
  2201-2223, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study residues of differential 2-forms on a smooth
algebraic surface over an arbitrary field and give several statements about
sums of residues. Afterwards, using these results we construct
algebraic-geometric codes which are an extension to surfaces of the well-known
differential codes on curves. We also study some properties of these codes and
extend to them some known properties for codes on curves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4171</identifier>
 <datestamp>2008-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4171</id><created>2008-10-22</created><authors><author><keyname>Harmsen</keyname><forenames>Jeremiah J.</forenames></author><author><keyname>Pearlman</keyname><forenames>William A.</forenames></author></authors><title>Capacity of Steganographic Channels</title><categories>cs.CR cs.IT math.IT</categories><acm-class>H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work investigates a central problem in steganography, that is: How much
data can safely be hidden without being detected? To answer this question, a
formal definition of steganographic capacity is presented. Once this has been
defined, a general formula for the capacity is developed. The formula is
applicable to a very broad spectrum of channels due to the use of an
information-spectrum approach. This approach allows for the analysis of
arbitrary steganalyzers as well as non-stationary, non-ergodic encoder and
attack channels.
  After the general formula is presented, various simplifications are applied
to gain insight into example hiding and detection methodologies. Finally, the
context and applications of the work are summarized in a general discussion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4182</identifier>
 <datestamp>2008-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4182</id><created>2008-10-22</created><authors><author><keyname>Dubiner</keyname><forenames>Moshe</forenames></author></authors><title>Bucketing Coding and Information Theory for the Statistical High
  Dimensional Nearest Neighbor Problem</title><categories>cs.IT math.IT</categories><comments>Manuscript submitted to IEEE Transactions on Information Theory on
  March 3, 2007; revised August 27, 2007</comments><msc-class>68P30, 94A24 (Primary) 68Q17 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the problem of finding high dimensional approximate nearest
neighbors, where the data is generated by some known probabilistic model. We
will investigate a large natural class of algorithms which we call bucketing
codes. We will define bucketing information, prove that it bounds the
performance of all bucketing codes, and that the bucketing information bound
can be asymptotically attained by randomly constructed bucketing codes.
  For example suppose we have n Bernoulli(1/2) very long (length d--&gt;infinity)
sequences of bits. Let n-2m sequences be completely independent, while the
remaining 2m sequences are composed of m independent pairs. The interdependence
within each pair is that their bits agree with probability 1/2&lt;p&lt;=1. It is well
known how to find most pairs with high probability by performing order of
n^{\log_{2}2/p} comparisons. We will see that order of n^{1/p+\epsilon}
comparisons suffice, for any \epsilon&gt;0. Moreover if one sequence out of each
pair belongs to a a known set of n^{(2p-1)^{2}-\epsilon} sequences, than
pairing can be done using order n comparisons!
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4187</identifier>
 <datestamp>2010-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4187</id><created>2008-10-22</created><authors><author><keyname>Kaltenbrunner</keyname><forenames>Andreas</forenames></author><author><keyname>Meza</keyname><forenames>Rodrigo</forenames></author><author><keyname>Grivolla</keyname><forenames>Jens</forenames></author><author><keyname>Codina</keyname><forenames>Joan</forenames></author><author><keyname>Banchs</keyname><forenames>Rafael</forenames></author></authors><title>Bicycle cycles and mobility patterns - Exploring and characterizing data
  from a community bicycle program</title><categories>cs.CY cs.HC</categories><comments>10 pages, 8 figures</comments><acm-class>G.3; H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides an analysis of human mobility data in an urban area using
the amount of available bikes in the stations of the community bicycle program
Bicing in Barcelona. The data was obtained by periodic mining of a KML-file
accessible through the Bicing website. Although in principle very noisy, after
some preprocessing and filtering steps the data allows to detect temporal
patterns in mobility as well as identify residential, university, business and
leisure areas of the city. The results lead to a proposal for an improvement of
the bicing website, including a prediction of the number of available bikes in
a certain station within the next minutes/hours. Furthermore a model for
identifying the most probable routes between stations is briefly sketched.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4188</identifier>
 <datestamp>2008-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4188</id><created>2008-10-22</created><authors><author><keyname>Dubiner</keyname><forenames>Moshe</forenames></author></authors><title>A Heterogeneous High Dimensional Approximate Nearest Neighbor Algorithm</title><categories>cs.IT math.IT</categories><msc-class>68P10, 68W20 (Primary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding high dimensional approximate nearest
neighbors. Suppose there are d independent rare features, each having its own
independent statistics. A point x will have x_{i}=0 denote the absence of
feature i, and x_{i}=1 its existence. Sparsity means that usually x_{i}=0.
Distance between points is a variant of the Hamming distance. Dimensional
reduction converts the sparse heterogeneous problem into a lower dimensional
full homogeneous problem. However we will see that the converted problem can be
much harder to solve than the original problem. Instead we suggest a direct
approach. It consists of T tries. In try t we rearrange the coordinates in
decreasing order of (1-r_{t,i})\frac{p_{i,11}}{p_{i,01}+p_{i,10}}
\ln\frac{1}{p_{i,1*}} where 0&lt;r_{t,i}&lt;1 are uniform pseudo-random numbers, and
the p's are the coordinate's statistical parameters. The points are
lexicographically ordered, and each is compared to its neighbors in that order.
  We analyze a generalization of this algorithm, show that it is optimal in
some class of algorithms, and estimate the necessary number of tries to
success. It is governed by an information like function, which we call
bucketing forest information. Any doubts whether it is &quot;information&quot; are
dispelled by another paper, where unrestricted bucketing information is
defined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4196</identifier>
 <datestamp>2008-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4196</id><created>2008-10-22</created><authors><author><keyname>Edmonson</keyname><forenames>W. W.</forenames></author><author><keyname>van Emden</keyname><forenames>M. H.</forenames></author></authors><title>Interval Semantics for Standard Floating-Point Arithmetic</title><categories>cs.NA cs.AR</categories><comments>10 pages</comments><report-no>DCS-323-IR</report-no><acm-class>G.1.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  If the non-zero finite floating-point numbers are interpreted as point
intervals, then the effect of rounding can be interpreted as computing one of
the bounds of the result according to interval arithmetic. We give an interval
interpretation for the signed zeros and infinities, so that the undefined
operations 0*inf, inf - inf, inf/inf, and 0/0 become defined.
  In this way no operation remains that gives rise to an error condition.
Mathematically questionable features of the floating-point standard become
well-defined sets of reals. Interval semantics provides a basis for the
verification of numerical algorithms. We derive the results of the newly
defined operations and consider the implications for hardware implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4201</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4201</id><created>2008-10-22</created><updated>2008-12-09</updated><authors><author><keyname>Fluke</keyname><forenames>C. J.</forenames></author><author><keyname>Barnes</keyname><forenames>D. G.</forenames></author><author><keyname>Jones</keyname><forenames>N. T.</forenames></author></authors><title>Interchanging Interactive 3-d Graphics for Astronomy</title><categories>astro-ph cs.GR</categories><comments>10 pages, 7 figures, submitted to Publications of the Astronomical
  Society of Australia. v2. Revised title, revised figure 1, fixed typos, minor
  additions to future work section</comments><doi>10.1071/AS08025</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate how interactive, three-dimensional (3-d) scientific
visualizations can be efficiently interchanged between a variety of mediums.
Through the use of an appropriate interchange format, and a unified interaction
interface, we minimize the effort to produce visualizations appropriate for
undertaking knowledge discovery at the astronomer's desktop, as part of
conference presentations, in digital publications or as Web content. We use
examples from cosmological visualization to address some of the issues of
interchange, and to describe our approach to adapting S2PLOT desktop
visualizations to the Web.
  Supporting demonstrations are available at
http://astronomy.swin.edu.au/s2plot/interchange/
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4249</identifier>
 <datestamp>2008-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4249</id><created>2008-10-23</created><authors><author><keyname>Kuhlmann</keyname><forenames>Marco</forenames></author></authors><title>Ogden's Lemma for Regular Tree Languages</title><categories>cs.CC</categories><acm-class>F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We motivate and prove a strong pumping lemma for regular tree languages. The
new lemma can be seen as the natural correspondent of Ogden's lemma for
context-free string languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4341</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4341</id><created>2008-10-23</created><authors><author><keyname>Allahverdyan</keyname><forenames>Armen E.</forenames></author></authors><title>Entropy of Hidden Markov Processes via Cycle Expansion</title><categories>cs.IT cond-mat.other math.IT physics.data-an</categories><comments>24 pages, 5 figures, published in Journal of Statistical Physics</comments><doi>10.1007/s10955-008-9613-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hidden Markov Processes (HMP) is one of the basic tools of the modern
probabilistic modeling. The characterization of their entropy remains however
an open problem. Here the entropy of HMP is calculated via the cycle expansion
of the zeta-function, a method adopted from the theory of dynamical systems.
For a class of HMP this method produces exact results both for the entropy and
the moment-generating function. The latter allows to estimate, via the Chernoff
bound, the probabilities of large deviations for the HMP. More generally, the
method offers a representation of the moment-generating function and of the
entropy via convergent series.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4366</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4366</id><created>2008-10-23</created><authors><author><keyname>Astaneh</keyname><forenames>Saeed Akhavan</forenames></author><author><keyname>Gazor</keyname><forenames>Saeed</forenames></author></authors><title>Resource Allocation and Relay Selection for Collaborative Communications</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the relay selection problem for a decode and forward
collaborative network. Users are able to collaborate; decode messages of each
other, re-encode and forward along with their own messages. We study the
performance obtained from collaboration in terms of 1) increasing the
achievable rate, 2) saving the transmit energy and 3) reducing the resource
requirement (resource means time-bandwidth). To ensure fairness, we fix the
transmit-energy-to-rate ratio among all users. We allocate resource optimally
for the collaborative protocol (CP), and compare the result with the
non-collaborative protocol (NCP) where users transmits their messages directly.
The collaboration gain is a function of the channel gain and available energies
and allows us 1) to decide to collaborate or not, 2) to select one relay among
the possible relay users, and 3) to determine the involved gain and loss of
possible collaboration. A considerable gain can be obtained if the direct
source-destination channel gain is significantly smaller than those of
alternative involved links. We demonstrate that a rate and energy improvement
of up to $(1+\sqrt[\eta]{\frac{k}{k+1}})^\eta$ can be obtained, where $\eta$ is
the environment path loss exponent and $k$ is the ratio of the rates of
involved users. The gain is maximum for low
transmit-energy-to-received-noise-ratio (TERN) and in a high TERN environment
the NCP is preferred.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4401</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4401</id><created>2008-10-24</created><updated>2008-12-17</updated><authors><author><keyname>Schraudolph</keyname><forenames>Nicol N.</forenames></author><author><keyname>Kamenetsky</keyname><forenames>Dmitry</forenames></author></authors><title>Efficient Exact Inference in Planar Ising Models</title><categories>cs.LG cs.CV stat.ML</categories><comments>Fixed a number of bugs in v1; added 10 pages of additional figures,
  explanations, proofs, and experiments</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give polynomial-time algorithms for the exact computation of lowest-energy
(ground) states, worst margin violators, log partition functions, and marginal
edge probabilities in certain binary undirected graphical models. Our approach
provides an interesting alternative to the well-known graph cut paradigm in
that it does not impose any submodularity constraints; instead we require
planarity to establish a correspondence with perfect matchings (dimer
coverings) in an expanded dual graph. We implement a unified framework while
delegating complex but well-understood subproblems (planar embedding,
maximum-weight perfect matching) to established algorithms for which efficient
implementations are freely available. Unlike graph cut methods, we can perform
penalized maximum-likelihood as well as maximum-margin parameter estimation in
the associated conditional random fields (CRFs), and employ marginal posterior
probabilities as well as maximum a posteriori (MAP) states for prediction.
Maximum-margin CRF parameter estimation on image denoising and segmentation
problems shows our approach to be efficient and effective. A C++ implementation
is available from http://nic.schraudolph.org/isinf/
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4404</identifier>
 <datestamp>2008-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4404</id><created>2008-10-24</created><authors><author><keyname>Savin</keyname><forenames>Valentin</forenames></author></authors><title>Non binary LDPC codes over the binary erasure channel: density evolution
  analysis</title><categories>cs.IT math.IT</categories><comments>ISABEL'08</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a thorough analysis of non binary LDPC codes over
the binary erasure channel. First, the decoding of non binary LDPC codes is
investigated. The proposed algorithm performs on-the-fly decoding, i.e. it
starts decoding as soon as the first symbols are received, which generalizes
the erasure decoding of binary LDPC codes. Next, we evaluate the asymptotical
performance of ensembles of non binary LDPC codes, by using the density
evolution method. Density evolution equations are derived by taking into
consideration both the irregularity of the bipartite graph and the probability
distribution of the graph edge labels. Finally, infinite-length performance of
some ensembles of non binary LDPC codes for different edge label distributions
are shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4419</identifier>
 <datestamp>2009-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4419</id><created>2008-10-24</created><updated>2009-06-08</updated><authors><author><keyname>Hirschowitz</keyname><forenames>Tom</forenames><affiliation>LAMA</affiliation></author><author><keyname>Pardon</keyname><forenames>Aur&#xe9;lien</forenames><affiliation>LIP</affiliation></author></authors><title>Binding bigraphs as symmetric monoidal closed theories</title><categories>cs.LO cs.PL</categories><comments>17 pages, uses Paul Taylor's diagrams</comments><proxy>ccsd hal-00333753</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Milner's bigraphs are a general framework for reasoning about distributed and
concurrent programming languages. Notably, it has been designed to encompass
both the pi-calculus and the Ambient calculus. This paper is only concerned
with bigraphical syntax: given what we here call a bigraphical signature K,
Milner constructs a (pre-) category of bigraphs BBig(K), whose main features
are (1) the presence of relative pushouts (RPOs), which makes them well-behaved
w.r.t. bisimulations, and that (2) the so-called structural equations become
equalities. Examples of the latter include, e.g., in pi and Ambient, renaming
of bound variables, associativity and commutativity of parallel composition, or
scope extrusion for restricted names. Also, bigraphs follow a scoping
discipline ensuring that, roughly, bound variables never escape their scope.
Here, we reconstruct bigraphs using a standard categorical tool: symmetric
monoidal closed (SMC) theories. Our theory enforces the same scoping discipline
as bigraphs, as a direct property of SMC structure. Furthermore, it elucidates
the slightly mysterious status of so-called links in bigraphs. Finally, our
category is also considerably larger than the category of bigraphs, notably
encompassing in the same framework terms and a flexible form of higher-order
contexts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4420</identifier>
 <datestamp>2009-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4420</id><created>2008-10-24</created><updated>2009-06-08</updated><authors><author><keyname>Garner</keyname><forenames>Richard</forenames><affiliation>LAMA</affiliation></author><author><keyname>Hirschowitz</keyname><forenames>Tom</forenames><affiliation>LAMA</affiliation></author><author><keyname>Pardon</keyname><forenames>Aur&#xe9;lien</forenames><affiliation>LIP</affiliation></author></authors><title>Graphical Presentations of Symmetric Monoidal Closed Theories</title><categories>cs.LO math.CT</categories><comments>Uses Paul Taylor's diagrams</comments><proxy>ccsd hal-00333750</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a notion of symmetric monoidal closed (SMC) theory, consisting of a
SMC signature augmented with equations, and describe the classifying categories
of such theories in terms of proof nets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4423</identifier>
 <datestamp>2013-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4423</id><created>2008-10-24</created><updated>2013-01-01</updated><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author></authors><title>Efficient Algorithmic Techniques for Several Multidimensional Geometric
  Data Management and Analysis Problems</title><categories>cs.CG cs.DM cs.DS</categories><comments>The algorithmic techniques presented in this paper were later used by
  the author in developing solutions for algorithmic tasks in several contests
  in which the author participated (see the attached zip archive for some
  examples of task statements and solutions). Knowledge Management - Projects,
  Systems and Technologies, Bucharest : Romania (2008)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper I present several novel, efficient, algorithmic techniques for
solving some multidimensional geometric data management and analysis problems.
The techniques are based on several data structures from computational geometry
(e.g. segment tree and range tree) and on the well-known sweep-line method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4426</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4426</id><created>2008-10-24</created><updated>2009-01-04</updated><authors><author><keyname>Rosten</keyname><forenames>Edward</forenames></author><author><keyname>Loveland</keyname><forenames>Rohan</forenames></author></authors><title>Camera distortion self-calibration using the plumb-line constraint and
  minimal Hough entropy</title><categories>cs.CV</categories><comments>9 pages, 5 figures Corrected errors in equation 18</comments><report-no>08-2665</report-no><doi>10.1007/s00138-009-0196-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a simple and robust method for self-correction of
camera distortion using single images of scenes which contain straight lines.
Since the most common distortion can be modelled as radial distortion, we
illustrate the method using the Harris radial distortion model, but the method
is applicable to any distortion model. The method is based on transforming the
edgels of the distorted image to a 1-D angular Hough space, and optimizing the
distortion correction parameters which minimize the entropy of the
corresponding normalized histogram. Properly corrected imagery will have fewer
curved lines, and therefore less spread in Hough space. Since the method does
not rely on any image structure beyond the existence of edgels sharing some
common orientations and does not use edge fitting, it is applicable to a wide
variety of image types. For instance, it can be applied equally well to images
of texture with weak but dominant orientations, or images with strong vanishing
points. Finally, the method is performed on both synthetic and real data
revealing that it is particularly robust to noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4431</identifier>
 <datestamp>2008-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4431</id><created>2008-10-24</created><authors><author><keyname>Huang</keyname><forenames>Weidong</forenames></author></authors><title>An Eye Tracking Study into the Effects of Graph Layout</title><categories>cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graphs are typically visualized as node-link diagrams. Although there is a
fair amount of research focusing on crossing minimization to improve
readability, little attention has been paid on how to handle crossings when
they are an essential part of the final visualizations. This requires us to
understand how people read graphs and how crossings affect reading performance.
  As an initial step to this end, a preliminary eye tracking experiment was
conducted. The specific purpose of this experiment was to test the effects of
crossing angles and geometric-path tendency on eye movements and performance.
Sixteen subjects performed both path search and node locating tasks with six
drawings. The results showed that small angles can slow down and trigger extra
eye movements, causing delays for path search tasks, whereas crossings have
little impact on node locating tasks. Geometric-path tendency indicates that a
path between two nodes can become harder to follow when many branches of the
path go toward the target node. The insights obtained are discussed with a view
to further confirmation in future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4440</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4440</id><created>2008-10-24</created><authors><author><keyname>Dolev</keyname><forenames>Shlomi</forenames></author><author><keyname>Tzachar</keyname><forenames>Nir</forenames></author></authors><title>Randomization Adaptive Self-Stabilization</title><categories>cs.DC</categories><doi>10.1007/978-3-642-05118-0_57</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a scheme to convert self-stabilizing algorithms that use
randomization during and following convergence to self-stabilizing algorithms
that use randomization only during convergence. We thus reduce the number of
random bits from an infinite number to a bounded number. The scheme is
applicable to the cases in which there exits a local predicate for each node,
such that global consistency is implied by the union of the local predicates.
We demonstrate our scheme over the token circulation algorithm of Herman and
the recent constant time Byzantine self-stabilizing clock synchronization
algorithm by Ben-Or, Dolev and Hoch. The application of our scheme results in
the first constant time Byzantine self-stabilizing clock synchronization
algorithm that uses a bounded number of random bits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4442</identifier>
 <datestamp>2008-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4442</id><created>2008-10-24</created><authors><author><keyname>Abrardo</keyname><forenames>Andrea</forenames></author><author><keyname>Detti</keyname><forenames>Paolo</forenames></author><author><keyname>Moretti</keyname><forenames>Marco</forenames></author></authors><title>Message passing resource allocation for the uplink of multicarrier
  systems</title><categories>cs.IT math.IT</categories><comments>6 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel distributed resource allocation scheme for the up-link of
a cellular multi-carrier system based on the message passing (MP) algorithm. In
the proposed approach each transmitter iteratively sends and receives
information messages to/from the base station with the goal of achieving an
optimal resource allocation strategy. The exchanged messages are the solution
of small distributed allocation problems. To reduce the computational load, the
MP problems at the terminals follow a dynamic programming formulation. The
advantage of the proposed scheme is that it distributes the computational
effort among all the transmitters in the cell and it does not require the
presence of a central controller that takes all the decisions. Numerical
results show that the proposed approach is an excellent solution to the
resource allocation problem for cellular multi-carrier systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4451</identifier>
 <datestamp>2008-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4451</id><created>2008-10-24</created><authors><author><keyname>Paulino</keyname><forenames>Herve</forenames></author><author><keyname>Lopes</keyname><forenames>Luis</forenames></author></authors><title>The Mob core language and abstract machine (rev 0.2)</title><categories>cs.PL cs.DC</categories><comments>33 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most current mobile agent systems are based on programming languages whose
semantics are difficult to prove correct as they lack an adequate underlying
formal theory. In recent years, the development of the theory of concurrent
systems, namely of process calculi, has allowed for the first time the modeling
of mobile agent systems.Languages directly based on process calculi are,
however, very low-level and it is desirable to provide the programmer with
higher level abstractions, while keeping the semantics of the base calculus.
  In this technical report we present the syntax and the semantics of a
scripting language for programming mobile agents called Mob. We describe the
language's syntax and semantics. Mob is service-oriented, meaning that agents
act both as servers and as clients of services and that this coupling is done
dynamically at run-time. The language is implemented on top of a process
calculus which allows us to prove that the framework is sound by encoding its
semantics into the underlying calculus. This provides a form of language
security not available to other mobile agent languages developed using a more
ah-doc approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4460</identifier>
 <datestamp>2014-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4460</id><created>2008-10-24</created><updated>2014-05-24</updated><authors><author><keyname>Geneves</keyname><forenames>Pierre</forenames></author></authors><title>Logics for XML</title><categories>cs.PL cs.DB cs.LO</categories><comments>Ph.D. dissertation, defended on December 4th, 2006</comments><acm-class>D.3.0; D.3.1; D.3.4; E.1; F.3.1; F.3.2; F.4.1; F.4.3; H.2.3; I.2.4;
  I.7.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis describes the theoretical and practical foundations of a system
for the static analysis of XML processing languages. The system relies on a
fixpoint temporal logic with converse, derived from the mu-calculus, where
models are finite trees. This calculus is expressive enough to capture regular
tree types along with multi-directional navigation in trees, while having a
single exponential time complexity. Specifically the decidability of the logic
is proved in time 2^O(n) where n is the size of the input formula.
  Major XML concepts are linearly translated into the logic: XPath navigation
and node selection semantics, and regular tree languages (which include DTDs
and XML Schemas). Based on these embeddings, several problems of major
importance in XML applications are reduced to satisfiability of the logic.
These problems include XPath containment, emptiness, equivalence, overlap,
coverage, in the presence or absence of regular tree type constraints, and the
static type-checking of an annotated query.
  The focus is then given to a sound and complete algorithm for deciding the
logic, along with a detailed complexity analysis, and crucial implementation
techniques for building an effective solver. Practical experiments using a full
implementation of the system are presented. The system appears to be efficient
in practice for several realistic scenarios.
  The main application of this work is a new class of static analyzers for
programming languages using both XPath expressions and XML type annotations
(input and output). Such analyzers allow to ensure at compile-time valuable
properties such as type-safety and optimizations, for safer and more efficient
XML processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4576</identifier>
 <datestamp>2011-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4576</id><created>2008-10-25</created><updated>2008-10-29</updated><authors><author><keyname>Itoh</keyname><forenames>Toshiya</forenames></author><author><keyname>Suzuki</keyname><forenames>Yasuhiro</forenames></author></authors><title>New Constructions for Query-Efficient Locally Decodable Codes of
  Subexponential Length</title><categories>cs.CC cs.CR</categories><comments>13 pages, 1 figure, 2 tables</comments><acm-class>F.1.2; F.2.2; G.2.1</acm-class><journal-ref>IEICE Trans. on Inf. and Syst. E93-D(2), pp.263-270, 2010</journal-ref><doi>10.1587/transinf.E93.D.263</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A $(k,\delta,\epsilon)$-locally decodable code $C: F_{q}^{n} \to F_{q}^{N}$
is an error-correcting code that encodes each message
$\vec{x}=(x_{1},x_{2},...,x_{n}) \in F_{q}^{n}$ to $C(\vec{x}) \in F_{q}^{N}$
and has the following property: For any $\vec{y} \in {\bf F}_{q}^{N}$ such that
$d(\vec{y},C(\vec{x})) \leq \delta N$ and each $1 \leq i \leq n$, the symbol
$x_{i}$ of $\vec{x}$ can be recovered with probability at least $1-\epsilon$ by
a randomized decoding algorithm looking only at $k$ coordinates of $\vec{y}$.
The efficiency of a $(k,\delta,\epsilon)$-locally decodable code $C: F_{q}^{n}
\to F_{q}^{N}$ is measured by the code length $N$ and the number $k$ of
queries. For any $k$-query locally decodable code $C: F_{q}^{n} \to F_{q}^{N}$,
the code length $N$ is conjectured to be exponential of $n$, however, this was
disproved. Yekhanin [In Proc. of STOC, 2007] showed that there exists a 3-query
locally decodable code $C: F_{2}^{n} \to F_{2}^{N}$ such that
$N=\exp(n^{(1/\log \log n)})$ assuming that the number of Mersenne primes is
infinite. For a 3-query locally decodable code $C: F_{q}^{n} \to F_{q}^{N}$,
Efremenko [ECCC Report No.69, 2008] reduced the code length further to
$N=\exp(n^{O((\log \log n/ \log n)^{1/2})})$, and also showed that for any
integer $r&gt;1$, there exists a $k$-query locally decodable code $C: F_{q}^{n}
\to F_{q}^{N}$ such that $k \leq 2^{r}$ and $N=\exp(n^{O((\log \log n/ \log
n)^{1-1/r})})$. In this paper, we present a query-efficient locally decodable
code and show that for any integer $r&gt;1$, there exists a $k$-query locally
decodable code $C: F_{q}^{n} \to F_{q}^{N}$ such that $k \leq 3 \cdot 2^{r-2}$
and $N=\exp(n^{O((\log \log n/ \log n)^{1-1/r})})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4611</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4611</id><created>2008-10-25</created><updated>2009-04-15</updated><authors><author><keyname>Vasiloglou</keyname><forenames>Nikolaos</forenames></author><author><keyname>Gray</keyname><forenames>Alexander G.</forenames></author><author><keyname>Anderson</keyname><forenames>David V.</forenames></author></authors><title>Learning Isometric Separation Maps</title><categories>cs.LG</categories><comments>Submitted to the NIPS workshop on Kernel Learning:Automatic Selection
  Of Kernels and now presented in MLSP 2009</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Maximum Variance Unfolding (MVU) and its variants have been very successful
in embedding data-manifolds in lower dimensional spaces, often revealing the
true intrinsic dimension. In this paper we show how to also incorporate
supervised class information into an MVU-like method without breaking its
convexity. We call this method the Isometric Separation Map and we show that
the resulting kernel matrix can be used as a binary/multiclass Support Vector
Machine-like method in a semi-supervised (transductive) framework. We also show
that the method always finds a kernel matrix that linearly separates the
training data exactly without projecting them in infinite dimensional spaces.
In traditional SVMs we choose a kernel and hope that the data become linearly
separable in the kernel space. In this paper we show how the hyperplane can be
chosen ad-hoc and the kernel is trained so that data are always linearly
separable. Comparisons with Large Margin SVMs show comparable performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4616</identifier>
 <datestamp>2008-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4616</id><created>2008-10-25</created><authors><author><keyname>Brucks</keyname><forenames>Claudine</forenames></author><author><keyname>Schommer</keyname><forenames>Christoph</forenames></author></authors><title>Assembling Actor-based Mind-Maps from Text Stream</title><categories>cs.CL cs.DL</categories><comments>12 pages, 8 Figures</comments><acm-class>I.2.4; H.3.1</acm-class><journal-ref>Summary of the Master Thesis &quot;Actor-based Mind-map learning from
  Text Streams&quot;. Dept. of Computer Science and Communication, University of
  Luxembourg, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For human beings, the processing of text streams of unknown size leads
generally to problems because e.g. noise must be selected out, information be
tested for its relevance or redundancy, and linguistic phenomenon like
ambiguity or the resolution of pronouns be advanced. Putting this into
simulation by using an artificial mind-map is a challenge, which offers the
gate for a wide field of applications like automatic text summarization or
punctual retrieval. In this work we present a framework that is a first step
towards an automatic intellect. It aims at assembling a mind-map based on
incoming text streams and on a subject-verb-object strategy, having the verb as
an interconnection between the adjacent nouns. The mind-map's performance is
enriched by a pronoun resolution engine that bases on the work of D. Klein, and
C. D. Manning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4617</identifier>
 <datestamp>2009-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4617</id><created>2008-10-25</created><updated>2009-07-27</updated><authors><author><keyname>Kokiopoulou</keyname><forenames>Effrosyni</forenames></author><author><keyname>Frossard</keyname><forenames>Pascal</forenames></author></authors><title>Graph-based classification of multiple observation sets</title><categories>cs.CV</categories><comments>New content added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of classification of an object given multiple
observations that possibly include different transformations. The possible
transformations of the object generally span a low-dimensional manifold in the
original signal space. We propose to take advantage of this manifold structure
for the effective classification of the object represented by the observation
set. In particular, we design a low complexity solution that is able to exploit
the properties of the data manifolds with a graph-based algorithm. Hence, we
formulate the computation of the unknown label matrix as a smoothing process on
the manifold under the constraint that all observations represent an object of
one single class. It results into a discrete optimization problem, which can be
solved by an efficient and low complexity algorithm. We demonstrate the
performance of the proposed graph-based algorithm in the classification of sets
of multiple images. Moreover, we show its high potential in video-based face
recognition, where it outperforms state-of-the-art solutions that fall short of
exploiting the manifold structure of the face image data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4657</identifier>
 <datestamp>2008-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4657</id><created>2008-10-26</created><authors><author><keyname>Rezaei</keyname><forenames>Seyed Saeed Changiz</forenames></author><author><keyname>Gharan</keyname><forenames>Shahab Oveis</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>Cooperative Strategies for the Half-Duplex Gaussian Parallel Relay
  Channel: Simultaneous Relaying versus Successive Relaying</title><categories>cs.IT math.IT</categories><comments>37 pages, 10 figures, submitted to IEEE transaction on Information
  Theory in October 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study investigates the problem of communication for a network composed
of two half-duplex parallel relays with additive white Gaussian noise. Two
protocols, i.e., \emph{Simultaneous} and \emph{Successive} relaying, associated
with two possible relay orderings are proposed. The simultaneous relaying
protocol is based on \emph{Dynamic Decode and Forward (DDF)} scheme. For the
successive relaying protocol: (i) a \emph{Non-Cooperative} scheme based on the
\emph{Dirty Paper Coding (DPC)}, and (ii) a \emph{Cooperative} scheme based on
the \emph{Block Markov Encoding (BME)} are considered. Furthermore, the
composite scheme of employing BME at one relay and DPC at another always
achieves a better rate when compared to the \emph{Cooperative} scheme. A
\emph{&quot;Simultaneous-Successive Relaying based on Dirty paper coding scheme&quot;
(SSRD)} is also proposed. The optimum ordering of the relays and hence the
capacity of the half-duplex Gaussian parallel relay channel in the low and high
signal-to-noise ratio (SNR) scenarios is derived. In the low SNR scenario, it
is revealed that under certain conditions for the channel coefficients, the
ratio of the achievable rate of the simultaneous relaying based on DDF to the
cut-set bound tends to be 1. On the other hand, as SNR goes to infinity, it is
proved that successive relaying, based on the DPC, asymptotically achieves the
capacity of the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4658</identifier>
 <datestamp>2008-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4658</id><created>2008-10-25</created><updated>2008-11-12</updated><authors><author><keyname>Liu</keyname><forenames>Keqin</forenames></author><author><keyname>Zhao</keyname><forenames>Qing</forenames></author></authors><title>Indexability of Restless Bandit Problems and Optimality of Whittle's
  Index for Dynamic Multichannel Access</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a class of restless multi-armed bandit problems (RMBP) that
arises in dynamic multichannel access, user/server scheduling, and optimal
activation in multi-agent systems. For this class of RMBP, we establish the
indexability and obtain Whittle's index in closed-form for both discounted and
average reward criteria. These results lead to a direct implementation of
Whittle's index policy with remarkably low complexity. When these Markov chains
are stochastically identical, we show that Whittle's index policy is optimal
under certain conditions. Furthermore, it has a semi-universal structure that
obviates the need to know the Markov transition probabilities. The optimality
and the semi-universal structure result from the equivalency between Whittle's
index policy and the myopic policy established in this work. For non-identical
channels, we develop efficient algorithms for computing a performance upper
bound given by Lagrangian relaxation. The tightness of the upper bound and the
near-optimal performance of Whittle's index policy are illustrated with
simulation examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4668</identifier>
 <datestamp>2008-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4668</id><created>2008-10-26</created><authors><author><keyname>Zeng</keyname><forenames>Yi</forenames></author><author><keyname>Zhong</keyname><forenames>Ning</forenames></author></authors><title>On Granular Knowledge Structures</title><categories>cs.AI cs.DL</categories><comments>6 pages, 7 figures, Proceedings of 2008 International Conference on
  Advanced Intelligence</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowledge plays a central role in human and artificial intelligence. One of
the key characteristics of knowledge is its structured organization. Knowledge
can be and should be presented in multiple levels and multiple views to meet
people's needs in different levels of granularities and from different
perspectives. In this paper, we stand on the view point of granular computing
and provide our understanding on multi-level and multi-view of knowledge
through granular knowledge structures (GKS). Representation of granular
knowledge structures, operations for building granular knowledge structures and
how to use them are investigated. As an illustration, we provide some examples
through results from an analysis of proceeding papers. Results show that
granular knowledge structures could help users get better understanding of the
knowledge source from set theoretical, logical and visual point of views. One
may consider using them to meet specific needs or solve certain kinds of
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4711</identifier>
 <datestamp>2008-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4711</id><created>2008-10-26</created><updated>2008-11-18</updated><authors><author><keyname>Bahi</keyname><forenames>Jacques M.</forenames></author><author><keyname>Guyeux</keyname><forenames>Christophe</forenames></author></authors><title>A topological chaos framework for hash functions</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new procedure of generating hash functions which can be
evaluated using some mathematical tools. This procedure is based on discrete
chaotic iterations.
  First, it is mathematically proven, that these discrete chaotic iterations
can be considered as a \linebreak particular case of topological chaos. Then,
the process of generating hash function based on the \linebreak topological
chaos is detailed. Finally it is shown how some tools coming from the domain of
\linebreak topological chaos can be used to measure quantitatively and
qualitatively some desirable properties for hash functions. An illustration
example is detailed in order to show how one can create hash functions using
our theoretical study.
  Key-words : Discrete chaotic iterations. Topological chaos. Hash function
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4713</identifier>
 <datestamp>2008-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4713</id><created>2008-10-26</created><authors><author><keyname>Bahi</keyname><forenames>Jacques M.</forenames></author><author><keyname>Guyeux</keyname><forenames>Christophe</forenames></author></authors><title>A watermarking algorithm satisfying topological chaos properties</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new watermarking algorithm is given, it is based on the so-called chaotic
iterations and on the choice of some coefficients which are deduced from the
description of the carrier medium. After defining these coefficients, chaotic
discrete iterations are used to encrypt the watermark and to embed it in the
carrier medium. This procedure generates a topological chaos and ensures that
the required properties of a watermarking algorithm are satisfied.
  Key-words: Watermarking, Encryption, Chaotic iterations, Topological chaos,
Information hiding
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4727</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4727</id><created>2008-10-26</created><updated>2008-11-10</updated><authors><author><keyname>Chen</keyname><forenames>Xinjia</forenames></author></authors><title>Robust Estimation of Mean Values</title><categories>math.ST cs.SY math.PR stat.CO stat.TH</categories><comments>12 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop a computational approach for estimating the mean
value of a quantity in the presence of uncertainty. We demonstrate that, under
some mild assumptions, the upper and lower bounds of the mean value are
efficiently computable via a sample reuse technique, of which the computational
complexity is shown to posses a Poisson distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4741</identifier>
 <datestamp>2008-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4741</id><created>2008-10-27</created><authors><author><keyname>Huang</keyname><forenames>Chiachi</forenames></author><author><keyname>Cadambe</keyname><forenames>Viveck R.</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>On the Capacity and Generalized Degrees of Freedom of the X Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the capacity and generalized degrees of freedom of the two-user
Gaussian X channel, i.e. a generalization of the 2 user interference channel
where there is an independent message from each transmitter to each receiver.
There are three main results in this paper. First, we characterize the sum
capacity of the deterministic X channel model under a symmetric setting.
Second, we characterize the generalized degrees of freedom of the Gaussian X
channel under a similar symmetric model. Third, we extend the noisy
interference capacity characterization previously obtained for the interference
channel to the X channel. Specifically, we show that the X channel associated
with noisy (very weak) interference channel has the same sum capacity as the
noisy interference channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4796</identifier>
 <datestamp>2008-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4796</id><created>2008-10-27</created><updated>2008-11-06</updated><authors><author><keyname>Fernau</keyname><forenames>Henning</forenames></author><author><keyname>Fomin</keyname><forenames>Fedor V.</forenames></author><author><keyname>Lokshtanov</keyname><forenames>Daniel</forenames></author><author><keyname>Raible</keyname><forenames>Daniel</forenames></author><author><keyname>Saurabh</keyname><forenames>Saket</forenames></author><author><keyname>Villanger</keyname><forenames>Yngve</forenames></author></authors><title>Kernel(s) for Problems With no Kernel: On Out-Trees With Many Leaves</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The {\sc $k$-Leaf Out-Branching} problem is to find an out-branching (i.e. a
rooted oriented spanning tree) with at least $k$ leaves in a given digraph. The
problem has recently received much attention from the viewpoint of
parameterized algorithms {alonLNCS4596,AlonFGKS07fsttcs,BoDo2,KnLaRo}. In this
paper we step aside and take a kernelization based approach to the {\sc
$k$-Leaf-Out-Branching} problem. We give the first polynomial kernel for {\sc
Rooted $k$-Leaf-Out-Branching}, a variant of {\sc $k$-Leaf-Out-Branching} where
the root of the tree searched for is also a part of the input. Our kernel has
cubic size and is obtained using extremal combinatorics.
  For the {\sc $k$-Leaf-Out-Branching} problem we show that no polynomial
kernel is possible unless polynomial hierarchy collapses to third level
%$PH=\Sigma_p^3$ by applying a recent breakthrough result by Bodlaender et al.
{BDFH08} in a non-trivial fashion. However our positive results for {\sc Rooted
$k$-Leaf-Out-Branching} immediately imply that the seemingly intractable the
{\sc $k$-Leaf-Out-Branching} problem admits a data reduction to $n$ independent
$O(k^3)$ kernels. These two results, tractability and intractability side by
side, are the first separating {\it many-to-one kernelization} from {\it Turing
kernelization}. This answers affirmatively an open problem regarding &quot;cheat
kernelization&quot; raised in {IWPECOPEN08}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4809</identifier>
 <datestamp>2008-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4809</id><created>2008-10-27</created><authors><author><keyname>Grust</keyname><forenames>T.</forenames></author><author><keyname>Mayr</keyname><forenames>M.</forenames></author><author><keyname>Rittinger</keyname><forenames>J.</forenames></author></authors><title>XQuery Join Graph Isolation</title><categories>cs.DB</categories><comments>extended version of a paper published in the ICDE 2009 proceedings
  (13 pages, 13 figures, 9 tables)</comments><acm-class>H.2.3; H.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A purely relational account of the true XQuery semantics can turn any
relational database system into an XQuery processor. Compiling nested
expressions of the fully compositional XQuery language, however, yields odd
algebraic plan shapes featuring scattered distributions of join operators that
currently overwhelm commercial SQL query optimizers.
  This work rewrites such plans before submission to the relational database
back-end. Once cast into the shape of join graphs, we have found off-the-shelf
relational query optimizers--the B-tree indexing subsystem and join tree
planner, in particular--to cope and even be autonomously capable of
&quot;reinventing&quot; advanced processing strategies that have originally been devised
specifically for the XQuery domain, e.g., XPath step reordering, axis reversal,
and path stitching. Performance assessments provide evidence that relational
query engines are among the most versatile and efficient XQuery processors
readily available today.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4812</identifier>
 <datestamp>2008-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4812</id><created>2008-10-27</created><updated>2008-10-29</updated><authors><author><keyname>Moser</keyname><forenames>Robin A.</forenames></author></authors><title>A constructive proof of the Lovasz Local Lemma</title><categories>cs.DS</categories><comments>11 pages; minor corrections</comments><acm-class>F.2; G.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Lovasz Local Lemma [EL75] is a powerful tool to prove the existence of
combinatorial objects meeting a prescribed collection of criteria. The
technique can directly be applied to the satisfiability problem, yielding that
a k-CNF formula in which each clause has common variables with at most 2^(k-2)
other clauses is always satisfiable. All hitherto known proofs of the Local
Lemma are non-constructive and do thus not provide a recipe as to how a
satisfying assignment to such a formula can be efficiently found. In his
breakthrough paper [Bec91], Beck demonstrated that if the neighbourhood of each
clause be restricted to O(2^(k/48)), a polynomial time algorithm for the search
problem exists. Alon simplified and randomized his procedure and improved the
bound to O(2^(k/8)) [Alo91]. Srinivasan presented in [Sri08] a variant that
achieves a bound of essentially O(2^(k/4)). In [Mos08], we improved this to
O(2^(k/2)). In the present paper, we give a randomized algorithm that finds a
satisfying assignment to every k-CNF formula in which each clause has a
neighbourhood of at most the asymptotic optimum of 2^(k-5)-1 other clauses and
that runs in expected time polynomial in the size of the formula, irrespective
of k. If k is considered a constant, we can also give a deterministic variant.
In contrast to all previous approaches, our analysis does not anymore invoke
the standard non-constructive versions of the Local Lemma and can therefore be
considered an alternative, constructive proof of it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4884</identifier>
 <datestamp>2008-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4884</id><created>2008-10-27</created><updated>2008-11-11</updated><authors><author><keyname>Alicea</keyname><forenames>Bradly</forenames></author></authors><title>The adaptability of physiological systems optimizes performance: new
  directions in augmentation</title><categories>cs.HC cs.NE</categories><comments>12 pages, 7 figures, 1 table (review, theoretical overview paper)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper contributes to the human-machine interface community in two ways:
as a critique of the closed-loop AC (augmented cognition) approach, and as a
way to introduce concepts from complex systems and systems physiology into the
field. Of particular relevance is a comparison of the inverted-U (or Gaussian)
model of optimal performance and multidimensional fitness landscape model.
Hypothetical examples will be given from human physiology and learning and
memory. In particular, a four-step model will be introduced that is proposed as
a better means to characterize multivariate systems during behavioral processes
with complex dynamics such as learning. Finally, the alternate approach
presented herein is considered as a preferable design alternate in
human-machine systems. It is within this context that future directions are
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4904</identifier>
 <datestamp>2008-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4904</id><created>2008-10-27</created><authors><author><keyname>Chen</keyname><forenames>Taolue</forenames></author><author><keyname>Fokkink</keyname><forenames>Wan</forenames></author><author><keyname>van Glabbeek</keyname><forenames>Rob</forenames></author></authors><title>On Finite Bases for Weak Semantics: Failures versus Impossible Futures</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a finite basis for the (in)equational theory of the process
algebra BCCS modulo the weak failures preorder and equivalence. We also give
positive and negative results regarding the axiomatizability of BCCS modulo
weak impossible futures semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4916</identifier>
 <datestamp>2009-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4916</id><created>2008-10-27</created><updated>2009-06-25</updated><authors><author><keyname>Aldroubi</keyname><forenames>Akram</forenames></author><author><keyname>Wang</keyname><forenames>Haichao</forenames></author><author><keyname>Zarringhalam</keyname><forenames>Kourosh</forenames></author></authors><title>Sequential adaptive compressed sampling via Huffman codes</title><categories>cs.IT math.IT</categories><comments>4 figures, 13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are two main approaches in compressed sensing: the geometric approach
and the combinatorial approach. In this paper we introduce an information
theoretic approach and use results from the theory of Huffman codes to
construct a sequence of binary sampling vectors to determine a sparse signal.
Unlike other approaches, our approach is adaptive in the sense that each
sampling vector depends on the previous sample. The number of measurements we
need for a k-sparse vector in n-dimensional space is no more than O(k log n)
and the reconstruction is O(k).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4934</identifier>
 <datestamp>2008-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4934</id><created>2008-10-27</created><authors><author><keyname>Cygan</keyname><forenames>Marek</forenames></author><author><keyname>Kowalik</keyname><forenames>Lukasz</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Marcin</forenames></author><author><keyname>Wykurz</keyname><forenames>Mateusz</forenames></author></authors><title>Exponential-Time Approximation of Hard Problems</title><categories>cs.DS</categories><acm-class>F.2.2; F.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study optimization problems that are neither approximable in polynomial
time (at least with a constant factor) nor fixed parameter tractable, under
widely believed complexity assumptions. Specifically, we focus on Maximum
Independent Set, Vertex Coloring, Set Cover, and Bandwidth.
  In recent years, many researchers design exact exponential-time algorithms
for these and other hard problems. The goal is getting the time complexity
still of order $O(c^n)$, but with the constant $c$ as small as possible. In
this work we extend this line of research and we investigate whether the
constant $c$ can be made even smaller when one allows constant factor
approximation. In fact, we describe a kind of approximation schemes --
trade-offs between approximation factor and the time complexity.
  We study two natural approaches. The first approach consists of designing a
backtracking algorithm with a small search tree. We present one result of that
kind: a $(4r-1)$-approximation of Bandwidth in time $O^*(2^{n/r})$, for any
positive integer $r$.
  The second approach uses general transformations from exponential-time exact
algorithms to approximations that are faster but still exponential-time. For
example, we show that for any reduction rate $r$, one can transform any
$O^*(c^n)$-time algorithm for Set Cover into a $(1+\ln r)$-approximation
algorithm running in time $O^*(c^{n/r})$. We believe that results of that kind
extend the applicability of exact algorithms for NP-hard problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4946</identifier>
 <datestamp>2009-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4946</id><created>2008-10-27</created><updated>2009-08-18</updated><authors><author><keyname>Daligault</keyname><forenames>Jean</forenames></author><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Kim</keyname><forenames>Eun Jung</forenames></author><author><keyname>Yeo</keyname><forenames>Anders</forenames></author></authors><title>FPT Algorithms and Kernels for the Directed $k$-Leaf Problem</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A subgraph $T$ of a digraph $D$ is an {\em out-branching} if $T$ is an
oriented spanning tree with only one vertex of in-degree zero (called the {\em
root}). The vertices of $T$ of out-degree zero are {\em leaves}. In the {\sc
Directed $k$-Leaf} Problem, we are given a digraph $D$ and an integral
parameter $k$, and we are to decide whether $D$ has an out-branching with at
least $k$ leaves. Recently, Kneis et al. (2008) obtained an algorithm for the
problem of running time $4^{k}\cdot n^{O(1)}$. We describe a new algorithm for
the problem of running time $3.72^{k}\cdot n^{O(1)}$. In {\sc Rooted Directed
$k$-Leaf} Problem, apart from $D$ and $k$, we are given a vertex $r$ of $D$ and
we are to decide whether $D$ has an out-branching rooted at $r$ with at least
$k$ leaves. Very recently, Fernau et al. (2008) found an $O(k^3)$-size kernel
for {\sc Rooted Directed $k$-Leaf}. In this paper, we obtain an $O(k)$ kernel
for {\sc Rooted Directed $k$-Leaf} restricted to acyclic digraphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4952</identifier>
 <datestamp>2009-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4952</id><created>2008-10-27</created><authors><author><keyname>Lipowski</keyname><forenames>Adam</forenames></author><author><keyname>Lipowska</keyname><forenames>Dorota</forenames></author></authors><title>Computational modelling of evolution: ecosystems and language</title><categories>q-bio.PE cs.CL physics.soc-ph</categories><comments>37 pages, proceedings of the conference &quot;From Genetics to
  Mathematics&quot; (Zbaszyn, Poland, October-2007)</comments><journal-ref>Series on Advances in Mathematics for Applied Sciences - vol.79
  (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, computational modelling became a very important research tool that
enables us to study problems that for decades evaded scientific analysis.
Evolutionary systems are certainly examples of such problems: they are composed
of many units that might reproduce, diffuse, mutate, die, or in some cases for
example communicate. These processes might be of some adaptive value, they
influence each other and occur on various time scales. That is why such systems
are so difficult to study. In this paper we briefly review some computational
approaches, as well as our contributions, to the evolution of ecosystems and
language. We start from Lotka-Volterra equations and the modelling of simple
two-species prey-predator systems. Such systems are canonical example for
studying oscillatory behaviour in competitive populations. Then we describe
various approaches to study long-term evolution of multi-species ecosystems. We
emphasize the need to use models that take into account both ecological and
evolutionary processes. Finally, we address the problem of the emergence and
development of language. It is becoming more and more evident that any theory
of language origin and development must be consistent with darwinian principles
of evolution. Consequently, a number of techniques developed for modelling
evolution of complex ecosystems are being applied to the problem of language.
We briefly review some of these approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4993</identifier>
 <datestamp>2008-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4993</id><created>2008-10-28</created><authors><author><keyname>Rifa</keyname><forenames>J.</forenames></author><author><keyname>Zinoviev</keyname><forenames>V. A.</forenames></author></authors><title>New completely regular q-ary codes based on Kronecker products</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>Submitted to IT-IEEE. Theorem 1 in Section III was presented at the
  2nd International Castle Meeting on Coding Theory and Applications (2ICMCTA),
  Medina del Campo, Spain, September 2008.}}</comments><msc-class>94B25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For any integer $\rho \geq 1$ and for any prime power q, the explicit
construction of a infinite family of completely regular (and completely
transitive) q-ary codes with d=3 and with covering radius $\rho$ is given. The
intersection array is also computed. Under the same conditions, the explicit
construction of an infinite family of q-ary uniformly packed codes (in the wide
sense) with covering radius $\rho$, which are not completely regular, is also
given. In both constructions the Kronecker product is the basic tool that has
been used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4998</identifier>
 <datestamp>2008-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4998</id><created>2008-10-28</created><authors><author><keyname>Kuske</keyname><forenames>Dietrich</forenames></author><author><keyname>Lohrey</keyname><forenames>Markus</forenames></author></authors><title>Automatic structures of bounded degree revisited</title><categories>cs.LO cs.CC</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first-order theory of a string automatic structure is known to be
decidable, but there are examples of string automatic structures with
nonelementary first-order theories. We prove that the first-order theory of a
string automatic structure of bounded degree is decidable in doubly exponential
space (for injective automatic presentations, this holds even uniformly). This
result is shown to be optimal since we also present a string automatic
structure of bounded degree whose first-order theory is hard for 2EXPSPACE. We
prove similar results also for tree automatic structures. These findings close
the gaps left open in a previous paper of the second author by improving both,
the lower and the upper bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5056</identifier>
 <datestamp>2009-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5056</id><created>2008-10-28</created><updated>2009-07-13</updated><authors><author><keyname>Tarnlund</keyname><forenames>Sten-Ake</forenames></author></authors><title>P is not equal to NP</title><categories>cs.CC cs.LO</categories><comments>In the 2nd printing the proof, in the 1st printing, of theorem 1 is
  divided into three parts a new lemma 4, a new corollary 8, and the remaining
  part of the original proof. The 2nd printing contains some simplifications,
  more explanations, but no error has been corrected</comments><acm-class>D.1.6; F.1.3; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  SAT is not in P, is true and provable in a simply consistent extension B' of
a first order theory B of computing, with a single finite axiom characterizing
a universal Turing machine. Therefore, P is not equal to NP, is true and
provable in a simply consistent extension B&quot; of B.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5057</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5057</id><created>2008-10-28</created><updated>2009-10-20</updated><authors><author><keyname>Fran&#xe7;ois</keyname><forenames>Claire</forenames><affiliation>INIST</affiliation></author><author><keyname>Lamirel</keyname><forenames>Jean-Charles</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Shehabi</keyname><forenames>Shadi Al</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Combining Advanced Visualization and Automatized Reasoning for
  Webometrics: A Test Study</title><categories>cs.IR cs.DL</categories><proxy>ccsd hal-00334682</proxy><journal-ref>COLLNET 2006, France (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a first attempt at performing a precise and automatic
identification of the linking behaviour in a scientific domain through the
analysis of the communication of the related academic institutions on the web.
The proposed approach is based on the paradigm of multiple viewpoint data
analysis (MVDA) than can be fruitfully exploited to highlight relationships
between data, like websites, carrying several kinds of description. It uses the
MultiSOM clustering and mapping method. The domain that has been chosen for
this study is the domain of Computer Science in Germany. The analysis is
conduced on a set of 438 websites of this domain using all together, thematic,
geographic and linking information. It highlights interesting results
concerning both global and local linking behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5064</identifier>
 <datestamp>2008-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5064</id><created>2008-10-28</created><authors><author><keyname>Gagie</keyname><forenames>Travis</forenames></author></authors><title>A New Algorithm for Building Alphabetic Minimax Trees</title><categories>cs.IT cs.DS math.IT</categories><comments>in preparation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to build an alphabetic minimax tree for a sequence (W = w_1,
&gt;..., w_n) of real weights in (O (n d \log \log n)) time, where $d$ is the
number of distinct integers (\lceil w_i \rceil). We apply this algorithm to
building an alphabetic prefix code given a sample.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5090</identifier>
 <datestamp>2008-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5090</id><created>2008-10-28</created><authors><author><keyname>Oyman</keyname><forenames>Ozgur</forenames></author><author><keyname>Win</keyname><forenames>Moe Z.</forenames></author></authors><title>Power-Bandwidth Tradeoff in Multiuser Relay Channels with Opportunistic
  Scheduling</title><categories>cs.IT math.IT</categories><comments>7 pages, to appear in Proc. of 46th Annual Allerton Conference on
  Communication, Control and Computing, Monticello, IL, U.S.A., Sep. 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this paper is to understand the key merits of multihop relaying
techniques jointly in terms of their energy efficiency and spectral efficiency
advantages in the presence of multiuser diversity gains from opportunistic
(i.e., channel-aware) scheduling and identify the regimes and conditions in
which relay-assisted multiuser communication provides a clear advantage over
direct multiuser communication. For this purpose, we use Shannon-theoretic
tools to analyze the tradeoff between energy efficiency and spectral efficiency
(known as the power-bandwidth tradeoff) over a fading multiuser relay channel
with $K$ users in the asymptotic regime of large (but finite) number of users
(i.e., dense network). Benefiting from the extreme-value theoretic results of
\cite{Oyman_isit07}, we characterize the power-bandwidth tradeoff and the
associated energy and spectral efficiency measures of the bandwidth-limited
high signal-to-noise ratio (SNR) and power-limited low SNR regimes, and utilize
them in investigating the large system behavior of the multiuser relay channel
as a function of the number of users and physical channel SNRs. Our analysis
results in very accurate closed-form formulas in the large (but finite) $K$
regime that quantify energy and spectral efficiency performance, and provides
insights on the impact of multihop relaying and multiuser diversity techniques
on the power-bandwidth tradeoff.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5098</identifier>
 <datestamp>2008-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5098</id><created>2008-10-28</created><authors><author><keyname>Oyman</keyname><forenames>Ozgur</forenames></author></authors><title>Reliability Bounds for Delay-Constrained Multi-hop Networks</title><categories>cs.IT math.IT</categories><comments>7 pages</comments><journal-ref>Proc. of 44th Annual Allerton Conference on Communication, Control
  and Computing, Monticello, IL, U.S.A., Sep. 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a linear multi-hop network composed of multi-state discrete-time
memoryless channels over each hop, with orthogonal time-sharing across hops
under a half-duplex relaying protocol. We analyze the probability of error and
associated reliability function \cite{Gallager68} over the multi-hop network;
with emphasis on random coding and sphere packing bounds, under the assumption
of point-to-point coding over each hop. In particular, we define the system
reliability function for the multi-hop network and derive lower and upper
bounds on this function to specify the reliability-optimal operating conditions
of the network under an end-to-end constraint on the total number of channel
uses. Moreover, we apply the reliability analysis to bound the expected
end-to-end latency of multi-hop communication under the support of an automatic
repeat request (ARQ) protocol. Considering an additive white Gaussian noise
(AWGN) channel model over each hop, we evaluate and compare these bounds to
draw insights on the role of multi-hopping toward enhancing the end-to-end
rate-reliability-delay tradeoff.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5148</identifier>
 <datestamp>2008-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5148</id><created>2008-10-28</created><authors><author><keyname>Ny</keyname><forenames>Jerome Le</forenames></author><author><keyname>Feron</keyname><forenames>Eric</forenames></author><author><keyname>Dahleh</keyname><forenames>Munther A.</forenames></author></authors><title>Scheduling Kalman Filters in Continuous Time</title><categories>math.OC cs.IT math.IT</categories><comments>30 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A set of N independent Gaussian linear time invariant systems is observed by
M sensors whose task is to provide the best possible steady-state causal
minimum mean square estimate of the state of the systems, in addition to
minimizing a steady-state measurement cost. The sensors can switch between
systems instantaneously, and there are additional resource constraints, for
example on the number of sensors which can observe a given system
simultaneously. We first derive a tractable relaxation of the problem, which
provides a bound on the achievable performance. This bound can be computed by
solving a convex program involving linear matrix inequalities. Exploiting the
additional structure of the sites evolving independently, we can decompose this
program into coupled smaller dimensional problems. In the scalar case with
identical sensors, we give an analytical expression of an index policy proposed
in a more general context by Whittle. In the general case, we develop open-loop
periodic switching policies whose performance matches the bound arbitrarily
closely.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5157</identifier>
 <datestamp>2013-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5157</id><created>2008-10-28</created><authors><author><keyname>Pawling</keyname><forenames>Alec</forenames></author><author><keyname>Yan</keyname><forenames>Ping</forenames></author><author><keyname>Candia</keyname><forenames>Juli&#xe1;n</forenames></author><author><keyname>Schoenharl</keyname><forenames>Tim</forenames></author><author><keyname>Madey</keyname><forenames>Greg</forenames></author></authors><title>Anomaly Detection in Streaming Sensor Data</title><categories>physics.data-an cs.NI physics.comp-ph</categories><comments>35 pages. Book chapter to appear in &quot;Intelligent Techniques for
  Warehousing and Mining Sensor Network Data&quot; (IGI Global), edited by A.
  Cuzzocrea</comments><doi>10.4018/978-1-60566-328-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this chapter we consider a cell phone network as a set of automatically
deployed sensors that records movement and interaction patterns of the
population. We discuss methods for detecting anomalies in the streaming data
produced by the cell phone network. We motivate this discussion by describing
the Wireless Phone Based Emergency Response (WIPER) system, a proof-of-concept
decision support system for emergency response managers. We also discuss some
of the scientific work enabled by this type of sensor data and the related
privacy issues. We describe scientific studies that use the cell phone data set
and steps we have taken to ensure the security of the data. We describe the
overall decision support system and discuss three methods of anomaly detection
that we have applied to the data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5203</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5203</id><created>2008-10-29</created><updated>2009-05-24</updated><authors><author><keyname>Yu</keyname><forenames>Yaming</forenames></author></authors><title>Monotonic Convergence in an Information-Theoretic Law of Small Numbers</title><categories>cs.IT math.IT math.PR</categories><comments>minor changes; references added</comments><journal-ref>IEEE Transactions on Information Theory 55 (2009) 5412--5422</journal-ref><doi>10.1109/TIT.2009.2032727</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An &quot;entropy increasing to the maximum&quot; result analogous to the entropic
central limit theorem (Barron 1986; Artstein et al. 2004) is obtained in the
discrete setting. This involves the thinning operation and a Poisson limit.
Monotonic convergence in relative entropy is established for general discrete
distributions, while monotonic increase of Shannon entropy is proved for the
special class of ultra-log-concave distributions. Overall we extend the
parallel between the information-theoretic central limit theorem and law of
small numbers explored by Kontoyiannis et al. (2005) and Harremo\&quot;es et al.\
(2007, 2008). Ingredients in the proofs include convexity, majorization, and
stochastic orders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5263</identifier>
 <datestamp>2008-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5263</id><created>2008-10-29</created><authors><author><keyname>Sami</keyname><forenames>Rahul</forenames></author><author><keyname>Twigg</keyname><forenames>Andy</forenames></author></authors><title>Lower bounds for distributed markov chain problems</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the worst-case communication complexity of distributed algorithms
computing a path problem based on stationary distributions of random walks in a
network $G$ with the caveat that $G$ is also the communication network. The
problem is a natural generalization of shortest path lengths to expected path
lengths, and represents a model used in many practical applications such as
pagerank and eigentrust as well as other problems involving Markov chains
defined by networks.
  For the problem of computing a single stationary probability, we prove an
$\Omega(n^2 \log n)$ bits lower bound; the trivial centralized algorithm costs
$O(n^3)$ bits and no known algorithm beats this. We also prove lower bounds for
the related problems of approximately computing the stationary probabilities,
computing only the ranking of the nodes, and computing the node with maximal
rank. As a corollary, we obtain lower bounds for labelling schemes for the
hitting time between two nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5308</identifier>
 <datestamp>2009-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5308</id><created>2008-10-29</created><updated>2009-02-16</updated><authors><author><keyname>Mimura</keyname><forenames>Kazushi</forenames></author></authors><title>Typical Performance of Irregular Low-Density Generator-Matrix Codes for
  Lossy Compression</title><categories>cond-mat.dis-nn cs.IT math.IT</categories><comments>12 pages, 8 figures</comments><journal-ref>J. Phys. A: Math. Theor., 42, 13, 135002 (2009)</journal-ref><doi>10.1088/1751-8113/42/13/135002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We evaluate typical performance of irregular low-density generator-matrix
(LDGM) codes, which is defined by sparse matrices with arbitrary irregular bit
degree distribution and arbitrary check degree distribution, for lossy
compression. We apply the replica method under one-step replica symmetry
breaking (1RSB) ansatz to this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5325</identifier>
 <datestamp>2008-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5325</id><created>2008-10-29</created><authors><author><keyname>Llonch</keyname><forenames>R. Sala</forenames></author><author><keyname>Kokiopoulou</keyname><forenames>E.</forenames></author><author><keyname>Tosic</keyname><forenames>I.</forenames></author><author><keyname>Frossard</keyname><forenames>P.</forenames></author></authors><title>3D Face Recognition with Sparse Spherical Representations</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of 3D face recognition using simultaneous
sparse approximations on the sphere. The 3D face point clouds are first aligned
with a novel and fully automated registration process. They are then
represented as signals on the 2D sphere in order to preserve depth and geometry
information. Next, we implement a dimensionality reduction process with
simultaneous sparse approximations and subspace projection. It permits to
represent each 3D face by only a few spherical functions that are able to
capture the salient facial characteristics, and hence to preserve the
discriminant facial information. We eventually perform recognition by effective
matching in the reduced space, where Linear Discriminant Analysis can be
further activated for improved recognition performance. The 3D face recognition
algorithm is evaluated on the FRGC v.1.0 data set, where it is shown to
outperform classical state-of-the-art solutions that work with depth images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5351</identifier>
 <datestamp>2008-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5351</id><created>2008-10-29</created><authors><author><keyname>Colantonio</keyname><forenames>Alessandro</forenames></author><author><keyname>Di Pietro</keyname><forenames>Roberto</forenames></author><author><keyname>Ocello</keyname><forenames>Alberto</forenames></author></authors><title>An Activity-Based Model for Separation of Duty</title><categories>cs.CR</categories><acm-class>D.4.6; K.6.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper offers several contributions for separation of duty (SoD)
administration in role-based access control (RBAC) systems. We first introduce
a new formal framework, based on business perspective, where SoD constraints
are analyzed introducing the activity concept. This notion helps organizations
define SoD constraints in terms of business requirements and reduces management
complexity in large-scale RBAC systems. The model enables the definition of a
wide taxonomy of conflict types. In particular, object-based SoD is introduced
using the SoD domain concept, namely the set of data in which transaction
conflicts may occur. Together with the formalization of the above properties,
in this paper we also show the effectiveness of our proposal: we have applied
the model to a large, existing organization; results highlight the benefits of
adopting the proposed model in terms of reduced administration cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5399</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5399</id><created>2008-10-29</created><updated>2010-12-26</updated><authors><author><keyname>Furuichi</keyname><forenames>Shigeru</forenames></author></authors><title>An axiomatic characterization of a two-parameter extended relative
  entropy</title><categories>cond-mat.stat-mech cs.IT math.IT</categories><comments>11 pages</comments><journal-ref>J. Math. Phys. Vol.51 (2010), 123302 (10 pages)</journal-ref><doi>10.1063/1.3525917</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The uniqueness theorem for a two-parameter extended relative entropy is
proven. This result extends our previous one, the uniqueness theorem for a
one-parameter extended relative entropy, to a two-parameter case. In addition,
the properties of a two-parameter extended relative entropy are studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5407</identifier>
 <datestamp>2008-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5407</id><created>2008-10-29</created><authors><author><keyname>Stojmirovic</keyname><forenames>Aleksandar</forenames></author></authors><title>Quasi-metrics, Similarities and Searches: aspects of geometry of protein
  datasets</title><categories>cs.IR math.GN q-bio.QM</categories><comments>299 pages, 44 figures, 10 tables, 9 algorithms. PhD thesis in
  mathematics defended in May 2005 at the Victoria University of Wellington,
  Wellington, New Zealand (supervisors: Prof. Vladimir Pestov and Dr. Bill
  Jordan)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A quasi-metric is a distance function which satisfies the triangle inequality
but is not symmetric: it can be thought of as an asymmetric metric. The central
result of this thesis, developed in Chapter 3, is that a natural correspondence
exists between similarity measures between biological (nucleotide or protein)
sequences and quasi-metrics.
  Chapter 2 presents basic concepts of the theory of quasi-metric spaces and
introduces a new examples of them: the universal countable rational
quasi-metric space and its bicompletion, the universal bicomplete separable
quasi-metric space. Chapter 4 is dedicated to development of a notion of the
quasi-metric space with Borel probability measure, or pq-space. The main result
of this chapter indicates that `a high dimensional quasi-metric space is close
to being a metric space'.
  Chapter 5 investigates the geometric aspects of the theory of database
similarity search in the context of quasi-metrics. The results about
$pq$-spaces are used to produce novel theoretical bounds on performance of
indexing schemes.
  Finally, the thesis presents some biological applications. Chapter 6
introduces FSIndex, an indexing scheme that significantly accelerates
similarity searches of short protein fragment datasets. Chapter 7 presents the
prototype of the system for discovery of short functional protein motifs called
PFMFind, which relies on FSIndex for similarity searches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5428</identifier>
 <datestamp>2010-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5428</id><created>2008-10-30</created><updated>2010-05-19</updated><authors><author><keyname>Bagchi</keyname><forenames>Amitabha</forenames></author><author><keyname>Lahoti</keyname><forenames>Garima</forenames></author></authors><title>Relating Web pages to enable information-gathering tasks</title><categories>cs.IR cs.DS</categories><comments>In Proceedings of ACM Hypertext 2009</comments><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We argue that relationships between Web pages are functions of the user's
intent. We identify a class of Web tasks - information-gathering - that can be
facilitated by a search engine that provides links to pages which are related
to the page the user is currently viewing. We define three kinds of intentional
relationships that correspond to whether the user is a) seeking sources of
information, b) reading pages which provide information, or c) surfing through
pages as part of an extended information-gathering process. We show that these
three relationships can be productively mined using a combination of textual
and link information and provide three scoring mechanisms that correspond to
them: {\em SeekRel}, {\em FactRel} and {\em SurfRel}. These scoring mechanisms
incorporate both textual and link information. We build a set of capacitated
subnetworks - each corresponding to a particular keyword - that mirror the
interconnection structure of the World Wide Web. The scores are computed by
computing flows on these subnetworks. The capacities of the links are derived
from the {\em hub} and {\em authority} values of the nodes they connect,
following the work of Kleinberg (1998) on assigning authority to pages in
hyperlinked environments. We evaluated our scoring mechanism by running
experiments on four data sets taken from the Web. We present user evaluations
of the relevance of the top results returned by our scoring mechanisms and
compare those to the top results returned by Google's Similar Pages feature,
and the {\em Companion} algorithm proposed by Dean and Henzinger (1999).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5439</identifier>
 <datestamp>2008-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5439</id><created>2008-10-30</created><authors><author><keyname>Tr&#xf6;ger</keyname><forenames>Peter</forenames><affiliation>Blekinge Institute Of Technology</affiliation></author></authors><title>The Multi-Core Era - Trends and Challenges</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the very beginning of hardware development, computer processors were
invented with ever-increasing clock frequencies and sophisticated in-build
optimization strategies. Due to physical limitations, this 'free lunch' of
speedup has come to an end.
  The following article gives a summary and bibliography for recent trends and
challenges in CMP architectures. It discusses how 40 years of parallel
computing research need to be considered in the upcoming multi-core era. We
argue that future research must be driven from two sides - a better expression
of hardware structures, and a domain-specific understanding of software
parallelism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5477</identifier>
 <datestamp>2008-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5477</id><created>2008-10-30</created><authors><author><keyname>Twigg</keyname><forenames>Andrew</forenames></author></authors><title>Worst-case time decremental connectivity and k-edge witness</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a simple algorithm for decremental graph connectivity that handles
edge deletions in worst-case time $O(k \log n)$ and connectivity queries in
$O(\log k)$, where $k$ is the number of edges deleted so far, and uses
worst-case space $O(m^2)$. We use this to give an algorithm for $k$-edge
witness (``does the removal of a given set of $k$ edges disconnect two vertices
$u,v$?'') with worst-case time $O(k^2 \log n)$ and space $O(k^2 n^2)$. For $k =
o(\sqrt{n})$ these improve the worst-case $O(\sqrt{n})$ bound for deletion due
to Eppstein et al. We also give a decremental connectivity algorithm using
$O(n^2 \log n / \log \log n)$ space, whose time complexity depends on the
toughness and independence number of the input graph. Finally, we show how to
construct a distributed data structure for \kvw by giving a labeling scheme.
This is the first data structure for \kvw that can efficiently distributed
without just giving each vertex a copy of the whole structure. Its complexity
depends on being able to construct a linear layout with good properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5482</identifier>
 <datestamp>2008-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5482</id><created>2008-10-30</created><authors><author><keyname>Richard</keyname><forenames>Adrien</forenames></author></authors><title>On the length of attractors in boolean networks with an interaction
  graph by layers</title><categories>cs.DM</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a boolean network whose interaction graph has no circuit of
length &gt;1. Under this hypothesis, we establish an upper bound on the length of
the attractors of the network which only depends on its interaction graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5484</identifier>
 <datestamp>2008-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5484</id><created>2008-10-30</created><authors><author><keyname>Li</keyname><forenames>Qiang</forenames></author><author><keyname>He</keyname><forenames>Yan</forenames></author><author><keyname>Jiang</keyname><forenames>Jing-ping</forenames></author></authors><title>A Novel Clustering Algorithm Based on a Modified Model of Random Walk</title><categories>cs.LG cs.AI cs.MA</categories><comments>21 pages, 13 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We introduce a modified model of random walk, and then develop two novel
clustering algorithms based on it. In the algorithms, each data point in a
dataset is considered as a particle which can move at random in space according
to the preset rules in the modified model. Further, this data point may be also
viewed as a local control subsystem, in which the controller adjusts its
transition probability vector in terms of the feedbacks of all data points, and
then its transition direction is identified by an event-generating function.
Finally, the positions of all data points are updated. As they move in space,
data points collect gradually and some separating parts emerge among them
automatically. As a consequence, data points that belong to the same class are
located at a same position, whereas those that belong to different classes are
away from one another. Moreover, the experimental results have demonstrated
that data points in the test datasets are clustered reasonably and efficiently,
and the comparison with other algorithms also provides an indication of the
effectiveness of the proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5516</identifier>
 <datestamp>2008-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5516</id><created>2008-10-30</created><authors><author><keyname>Bekker</keyname><forenames>Wilmari</forenames></author><author><keyname>Goranko</keyname><forenames>Valentin</forenames></author></authors><title>Symbolic model checking of tense logics on rational Kripke models</title><categories>cs.LO</categories><comments>To appear in: Proceedings of the International Conference on Infinity
  in Logic and Computation ILC'2007, Springer LNAI</comments><acm-class>D.2.4; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the class of rational Kripke models and study symbolic model
checking of the basic tense logic Kt and some extensions of it in models from
that class. Rational Kripke models are based on (generally infinite) rational
graphs, with vertices labeled by the words in some regular language and
transitions recognized by asynchronous two-head finite automata, also known as
rational transducers. Every atomic proposition in a rational Kripke model is
evaluated in a regular set of states. We show that every formula of Kt has an
effectively computable regular extension in every rational Kripke model, and
therefore local model checking and global model checking of Kt in rational
Kripke models are decidable. These results are lifted to a number of extensions
of Kt. We study and partly determine the complexity of the model checking
procedures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5517</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5517</id><created>2008-10-30</created><updated>2010-01-18</updated><authors><author><keyname>Demri</keyname><forenames>Stephane</forenames></author><author><keyname>Lazic</keyname><forenames>Ranko</forenames></author><author><keyname>Sangnier</keyname><forenames>Arnaud</forenames></author></authors><title>Model checking memoryful linear-time logics over one-counter automata</title><categories>cs.LO</categories><comments>Substantially revised and extended version of &quot;Model checking freeze
  LTL over one-counter automata&quot; by the same authors in FoSSaCS 2008</comments><acm-class>F.1.1; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study complexity of the model-checking problems for LTL with registers
(also known as freeze LTL) and for first-order logic with data equality tests
over one-counter automata. We consider several classes of one-counter automata
(mainly deterministic vs. nondeterministic) and several logical fragments
(restriction on the number of registers or variables and on the use of
propositional variables for control locations). The logics have the ability to
store a counter value and to test it later against the current counter value.
We show that model checking over deterministic one-counter automata is
PSPACE-complete with infinite and finite accepting runs. By constrast, we prove
that model checking freeze LTL in which the until operator is restricted to the
eventually operator over nondeterministic one-counter automata is undecidable
even if only one register is used and with no propositional variable. As a
corollary of our proof, this also holds for first-order logic with data
equality tests restricted to two variables. This makes a difference with the
facts that several verification problems for one-counter automata are known to
be decidable with relatively low complexity, and that finitary satisfiability
for the two logics are decidable. Our results pave the way for model-checking
memoryful (linear-time) logics over other classes of operational models, such
as reversal-bounded counter machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5535</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5535</id><created>2008-10-30</created><authors><author><keyname>Borowczyk</keyname><forenames>Henryk</forenames></author></authors><title>A Combinatorial-Probabilistic Diagnostic Entropy and Information</title><categories>cs.IT math.IT</categories><comments>Sent to IEEE Transactions on Information Theory (september 2008)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new combinatorial-probabilistic diagnostic entropy has been introduced. It
describes the pair-wise sum of probabilities of system conditions that have to
be distinguished during the diagnosing process. The proposed measure describes
the uncertainty of the system conditions, and at the same time complexity of
the diagnosis problem. Treating the assumed combinatorial-diagnostic entropy as
a primary notion, the information delivered by the symptoms has been defined.
The relationships have been derived to facilitate explicit, quantitative
assessment of the information of a single symptom as well as that of a symptoms
set. It has been proved that the combinatorial-probabilistic information shows
the property of additivity. The presented measures are focused on diagnosis
problem, but they can be easily applied to other disciplines such as decision
theory and classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5551</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5551</id><created>2008-10-30</created><updated>2008-11-10</updated><authors><author><keyname>Chen</keyname><forenames>Xinjia</forenames></author></authors><title>A Theory of Truncated Inverse Sampling</title><categories>math.ST cs.LG math.PR stat.ME stat.TH</categories><comments>31 pages, no figure, revised proofs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we have established a new framework of truncated inverse
sampling for estimating mean values of non-negative random variables such as
binomial, Poisson, hyper-geometrical, and bounded variables. We have derived
explicit formulas and computational methods for designing sampling schemes to
ensure prescribed levels of precision and confidence for point estimators.
Moreover, we have developed interval estimation methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5573</identifier>
 <datestamp>2008-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5573</id><created>2008-10-30</created><authors><author><keyname>Ris</keyname><forenames>Marcelo</forenames></author><author><keyname>Barrera</keyname><forenames>Junior</forenames></author><author><keyname>Martins</keyname><forenames>David C.</forenames><suffix>Jr</suffix></author></authors><title>A branch-and-bound feature selection algorithm for U-shaped cost
  functions</title><categories>cs.CV cs.DS cs.LG</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper presents the formulation of a combinatorial optimization problem
with the following characteristics: i.the search space is the power set of a
finite set structured as a Boolean lattice; ii.the cost function forms a
U-shaped curve when applied to any lattice chain. This formulation applies for
feature selection in the context of pattern recognition. The known approaches
for this problem are branch-and-bound algorithms and heuristics, that explore
partially the search space. Branch-and-bound algorithms are equivalent to the
full search, while heuristics are not. This paper presents a branch-and-bound
algorithm that differs from the others known by exploring the lattice structure
and the U-shaped chain curves of the search space. The main contribution of
this paper is the architecture of this algorithm that is based on the
representation and exploration of the search space by new lattice properties
proven here. Several experiments, with well known public data, indicate the
superiority of the proposed method to SFFS, which is a popular heuristic that
gives good results in very short computational time. In all experiments, the
proposed method got better or equal results in similar or even smaller
computational time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5575</identifier>
 <datestamp>2008-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5575</id><created>2008-10-30</created><authors><author><keyname>Nuriyev</keyname><forenames>R.</forenames></author></authors><title>Detection of parallel steps in programs with arrays</title><categories>cs.PL</categories><comments>13 pages, 5 figurers</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of detecting of information and logically independent (DILD)
steps in programs is a key for equivalent program transformations. Here we are
considering the problem of independence of loop iterations, the concentration
of massive data processing and hence the most challenge construction for
parallelizing. We introduced a separated form of loops when loop's body is a
sequence of procedures each of them are used array's elements selected in a
previous procedure. We prove that any loop may be algorithmically represented
in this form and number of such procedures is invariant. We show that for this
form of loop the steps connections are determined with some integer equations
and hence the independence problem is algorithmically unsolvable if index
expressions are more complex than cubical. We suggest a modification of index
semantics that made connection equations trivial and loops iterations can be
executed in parallel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5578</identifier>
 <datestamp>2008-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5578</id><created>2008-10-30</created><authors><author><keyname>Feder</keyname><forenames>Tomas</forenames></author><author><keyname>Nabar</keyname><forenames>Shubha U.</forenames></author><author><keyname>Terzi</keyname><forenames>Evimaria</forenames></author></authors><title>Anonymizing Graphs</title><categories>cs.DB cs.DS</categories><comments>15 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by recently discovered privacy attacks on social networks, we study
the problem of anonymizing the underlying graph of interactions in a social
network. We call a graph (k,l)-anonymous if for every node in the graph there
exist at least k other nodes that share at least l of its neighbors. We
consider two combinatorial problems arising from this notion of anonymity in
graphs. More specifically, given an input graph we ask for the minimum number
of edges to be added so that the graph becomes (k,l)-anonymous. We define two
variants of this minimization problem and study their properties. We show that
for certain values of k and l the problems are polynomial-time solvable, while
for others they become NP-hard. Approximation algorithms for the latter cases
are also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5582</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5582</id><created>2008-10-31</created><updated>2008-11-03</updated><authors><author><keyname>Motwani</keyname><forenames>Rajeev</forenames></author><author><keyname>Nabar</keyname><forenames>Shubha U.</forenames></author></authors><title>Anonymizing Unstructured Data</title><categories>cs.DB cs.DS</categories><comments>9 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of anonymizing datasets in which each
individual is associated with a set of items that constitute private
information about the individual. Illustrative datasets include market-basket
datasets and search engine query logs. We formalize the notion of k-anonymity
for set-valued data as a variant of the k-anonymity model for traditional
relational datasets. We define an optimization problem that arises from this
definition of anonymity and provide O(klogk) and O(1)-approximation algorithms
for the same. We demonstrate applicability of our algorithms to the America
Online query log dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5596</identifier>
 <datestamp>2008-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5596</id><created>2008-10-30</created><authors><author><keyname>Nuriyev</keyname><forenames>R.</forenames></author></authors><title>Programming languages with algorithmically parallelizing problem</title><categories>cs.DC</categories><comments>57 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study consists of two parts. Objective of the first part is modern
language constructions responsible for algorithmically insolvability of
parallelizing problem. Second part contains several ways to modify the
constructions to make the problem algorithmically solvable
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5631</identifier>
 <datestamp>2008-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5631</id><created>2008-10-31</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author><author><keyname>Legg</keyname><forenames>Shane</forenames></author></authors><title>Temporal Difference Updating without a Learning Rate</title><categories>cs.LG cs.AI</categories><comments>12 pages, 6 figures</comments><journal-ref>Advances in Neural Information Processing Systems 20 (NIPS 2008)
  pages 705-712</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive an equation for temporal difference learning from statistical
principles. Specifically, we start with the variational principle and then
bootstrap to produce an updating rule for discounted state value estimates. The
resulting equation is similar to the standard equation for temporal difference
learning with eligibility traces, so called TD(lambda), however it lacks the
parameter alpha that specifies the learning rate. In the place of this free
parameter there is now an equation for the learning rate that is specific to
each state transition. We experimentally test this new learning rule against
TD(lambda) and find that it offers superior performance in various settings.
Finally, we make some preliminary investigations into how to extend our new
temporal difference algorithm to reinforcement learning. To do this we combine
our update equation with both Watkins' Q(lambda) and Sarsa(lambda) and find
that it again offers superior performance without a learning rate parameter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5633</identifier>
 <datestamp>2009-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5633</id><created>2008-10-31</created><updated>2009-02-12</updated><authors><author><keyname>Mogilnykh</keyname><forenames>Ivan Yu.</forenames></author><author><keyname>&#xd6;sterg&#xe5;rd</keyname><forenames>Patric R. J.</forenames></author><author><keyname>Pottonen</keyname><forenames>Olli</forenames></author><author><keyname>Solov'eva</keyname><forenames>Faina I.</forenames></author></authors><title>Reconstructing Extended Perfect Binary One-Error-Correcting Codes from
  Their Minimum Distance Graphs</title><categories>cs.IT math.CO math.IT</categories><comments>4 pages. Accepted for publication in IEEE Transactions on Information
  Theory</comments><journal-ref>IEEE Trans. Inform. Theory 55 (2009) 2622-2625</journal-ref><doi>10.1109/TIT.2009.2018338</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The minimum distance graph of a code has the codewords as vertices and edges
exactly when the Hamming distance between two codewords equals the minimum
distance of the code. A constructive proof for reconstructibility of an
extended perfect binary one-error-correcting code from its minimum distance
graph is presented. Consequently, inequivalent such codes have nonisomorphic
minimum distance graphs. Moreover, it is shown that the automorphism group of a
minimum distance graph is isomorphic to that of the corresponding code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5636</identifier>
 <datestamp>2009-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5636</id><created>2008-10-31</created><authors><author><keyname>Ryabko</keyname><forenames>Daniil</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>On the Possibility of Learning in Reactive Environments with Arbitrary
  Dependence</title><categories>cs.LG cs.AI cs.IT math.IT</categories><comments>20 pages</comments><report-no>IDSIA-08-08</report-no><journal-ref>Theoretical Computer Science, 405:3 (2008) pages 274-284</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of reinforcement learning in which observations may
exhibit an arbitrary form of stochastic dependence on past observations and
actions, i.e. environments more general than (PO)MDPs. The task for an agent is
to attain the best possible asymptotic reward where the true generating
environment is unknown but belongs to a known countable family of environments.
We find some sufficient conditions on the class of environments under which an
agent exists which attains the best asymptotic reward for any environment in
the class. We analyze how tight these conditions are and how they relate to
different probabilistic assumptions known in reinforcement learning and related
fields, such as Markov Decision Processes and mixing conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5647</identifier>
 <datestamp>2008-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5647</id><created>2008-10-31</created><authors><author><keyname>Villard</keyname><forenames>Gilles</forenames><affiliation>LIP</affiliation></author></authors><title>Kaltofen's division-free determinant algorithm differentiated for matrix
  adjoint computation</title><categories>cs.SC cs.CC</categories><proxy>ccsd ensl-00335918</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kaltofen has proposed a new approach in 1992 for computing matrix
determinants without divisions. The algorithm is based on a baby steps/giant
steps construction of Krylov subspaces, and computes the determinant as the
constant term of a characteristic polynomial. For matrices over an abstract
ring, by the results of Baur and Strassen, the determinant algorithm, actually
a straight-line program, leads to an algorithm with the same complexity for
computing the adjoint of a matrix. However, the latter adjoint algorithm is
obtained by the reverse mode of automatic differentiation, hence somehow is not
&quot;explicit&quot;. We present an alternative (still closely related) algorithm for the
adjoint thatcan be implemented directly, we mean without resorting to an
automatic transformation. The algorithm is deduced by applying program
differentiation techniques &quot;by hand&quot; to Kaltofen's method, and is completely
decribed. As subproblem, we study the differentiation of programs that compute
minimum polynomials of lineraly generated sequences, and we use a lazy
polynomial evaluation mechanism for reducing the cost of Strassen's avoidance
of divisions in our case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5663</identifier>
 <datestamp>2010-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5663</id><created>2008-10-31</created><authors><author><keyname>Ay</keyname><forenames>Nihat</forenames></author><author><keyname>Mueller</keyname><forenames>Markus</forenames></author><author><keyname>Szkola</keyname><forenames>Arleta</forenames></author></authors><title>Effective Complexity and its Relation to Logical Depth</title><categories>cs.IT math.IT</categories><comments>14 pages, 2 figures</comments><journal-ref>IEEE Trans. Inf. Th., Vol. 56/9 pp. 4593-4607 (2010)</journal-ref><doi>10.1109/TIT.2010.2053892</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Effective complexity measures the information content of the regularities of
an object. It has been introduced by M. Gell-Mann and S. Lloyd to avoid some of
the disadvantages of Kolmogorov complexity, also known as algorithmic
information content. In this paper, we give a precise formal definition of
effective complexity and rigorous proofs of its basic properties. In
particular, we show that incompressible binary strings are effectively simple,
and we prove the existence of strings that have effective complexity close to
their lengths. Furthermore, we show that effective complexity is related to
Bennett's logical depth: If the effective complexity of a string $x$ exceeds a
certain explicit threshold then that string must have astronomically large
depth; otherwise, the depth can be arbitrarily small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5685</identifier>
 <datestamp>2010-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5685</id><created>2008-10-31</created><updated>2010-08-23</updated><authors><author><keyname>Giesbrecht</keyname><forenames>Mark</forenames></author><author><keyname>Roche</keyname><forenames>Daniel S.</forenames></author></authors><title>Interpolation of Shifted-Lacunary Polynomials</title><categories>cs.SC cs.DS cs.MS</categories><comments>22 pages, to appear in Computational Complexity</comments><msc-class>68W30 (Primary), 12Y05 (Secondary)</msc-class><journal-ref>Computational Complexity, Vol. 19, No 3., pp. 333-354, 2010</journal-ref><doi>10.1007/s00037-010-0294-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a &quot;black box&quot; function to evaluate an unknown rational polynomial f in
Q[x] at points modulo a prime p, we exhibit algorithms to compute the
representation of the polynomial in the sparsest shifted power basis. That is,
we determine the sparsity t, the shift s (a rational), the exponents 0 &lt;= e1 &lt;
e2 &lt; ... &lt; et, and the coefficients c1,...,ct in Q\{0} such that f(x) =
c1(x-s)^e1+c2(x-s)^e2+...+ct(x-s)^et. The computed sparsity t is absolutely
minimal over any shifted power basis. The novelty of our algorithm is that the
complexity is polynomial in the (sparse) representation size, and in particular
is logarithmic in deg(f). Our method combines previous celebrated results on
sparse interpolation and computing sparsest shifts, and provides a way to
handle polynomials with extremely high degree which are, in some sense, sparse
in information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5717</identifier>
 <datestamp>2008-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5717</id><created>2008-10-31</created><authors><author><keyname>Niepert</keyname><forenames>Mathias</forenames></author><author><keyname>Van Gucht</keyname><forenames>Dirk</forenames></author><author><keyname>Gyssens</keyname><forenames>Marc</forenames></author></authors><title>On the Conditional Independence Implication Problem: A Lattice-Theoretic
  Approach</title><categories>cs.AI cs.DM</categories><journal-ref>Proceedings of the 24th Conference on Uncertainty in Artificial
  Intelligence, 2008, pages 435-443</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A lattice-theoretic framework is introduced that permits the study of the
conditional independence (CI) implication problem relative to the class of
discrete probability measures. Semi-lattices are associated with CI statements
and a finite, sound and complete inference system relative to semi-lattice
inclusions is presented. This system is shown to be (1) sound and complete for
saturated CI statements, (2) complete for general CI statements, and (3) sound
and complete for stable CI statements. These results yield a criterion that can
be used to falsify instances of the implication problem and several heuristics
are derived that approximate this &quot;lattice-exclusion&quot; criterion in polynomial
time. Finally, we provide experimental results that relate our work to results
obtained from other existing inference algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5725</identifier>
 <datestamp>2008-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5725</id><created>2008-10-31</created><updated>2008-11-01</updated><authors><author><keyname>Haesevoets</keyname><forenames>Sofie</forenames></author><author><keyname>Kuijpers</keyname><forenames>Bart</forenames></author></authors><title>A triangle-based logic for affine-invariant querying of spatial and
  spatio-temporal data</title><categories>cs.LO cs.DB</categories><comments>43 pages, 11 figures</comments><acm-class>H.2.3; H.2.8; F.4.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In spatial databases, incompatibilities often arise due to different choices
of origin or unit of measurement (e.g., centimeters versus inches). By
representing and querying the data in an affine-invariant manner, we can avoid
these incompatibilities.
  In practice, spatial (resp., spatio-temporal) data is often represented as a
finite union of triangles (resp., moving triangles). As two arbitrary triangles
are equal up to a unique affinity of the plane, they seem perfect candidates as
basic units for an affine-invariant query language.
  We propose a so-called &quot;triangle logic&quot;, a query language that is
affine-generic and has triangles as basic elements. We show that this language
has the same expressive power as the affine-generic fragment of first-order
logic over the reals on triangle databases. We illustrate that the proposed
language is simple and intuitive. It can also serve as a first step towards a
&quot;moving-triangle logic&quot; for spatio-temporal data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5728</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5728</id><created>2008-10-31</created><updated>2008-11-11</updated><authors><author><keyname>Etessami</keyname><forenames>Kousha</forenames></author><author><keyname>Kwiatkowska</keyname><forenames>Marta</forenames></author><author><keyname>Vardi</keyname><forenames>Moshe Y.</forenames></author><author><keyname>Yannakakis</keyname><forenames>Mihalis</forenames></author></authors><title>Multi-Objective Model Checking of Markov Decision Processes</title><categories>cs.LO cs.CC cs.GT</categories><comments>21 pages, 2 figures</comments><acm-class>G.3; F.2; F.3.1; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 4 (November
  12, 2008) lmcs:990</journal-ref><doi>10.2168/LMCS-4(4:8)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study and provide efficient algorithms for multi-objective model checking
problems for Markov Decision Processes (MDPs). Given an MDP, M, and given
multiple linear-time (\omega -regular or LTL) properties \varphi\_i, and
probabilities r\_i \epsilon [0,1], i=1,...,k, we ask whether there exists a
strategy \sigma for the controller such that, for all i, the probability that a
trajectory of M controlled by \sigma satisfies \varphi\_i is at least r\_i. We
provide an algorithm that decides whether there exists such a strategy and if
so produces it, and which runs in time polynomial in the size of the MDP. Such
a strategy may require the use of both randomization and memory. We also
consider more general multi-objective \omega -regular queries, which we
motivate with an application to assume-guarantee compositional reasoning for
probabilistic systems.
  Note that there can be trade-offs between different properties: satisfying
property \varphi\_1 with high probability may necessitate satisfying \varphi\_2
with low probability. Viewing this as a multi-objective optimization problem,
we want information about the &quot;trade-off curve&quot; or Pareto curve for maximizing
the probabilities of different properties. We show that one can compute an
approximate Pareto curve with respect to a set of \omega -regular properties in
time polynomial in the size of the MDP.
  Our quantitative upper bounds use LP methods. We also study qualitative
multi-objective model checking problems, and we show that these can be analysed
by purely graph-theoretic methods, even though the strategies may still require
both randomization and memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5732</identifier>
 <datestamp>2008-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5732</id><created>2008-10-31</created><authors><author><keyname>Nuriyev</keyname><forenames>R.</forenames></author></authors><title>Practical language based on systems of definitions</title><categories>cs.DC</categories><comments>10 pages, 2 references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article suggests a description of a system of tables with a set of
special lists absorbing a semantics of data and reflects a fullness of data. It
shows how their parallel processing can be constructed based on the
descriptions. The approach also might be used for definition intermediate
targets for data mining and unstructured data processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5758</identifier>
 <datestamp>2008-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5758</id><created>2008-10-31</created><authors><author><keyname>Nuriyev</keyname><forenames>Renat</forenames></author></authors><title>Non procedural language for parallel programs</title><categories>cs.DC</categories><comments>20 pages, will be printed in &quot;Programming&quot; magazine of RAS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probably building non procedural languages is the most prospective way for
parallel programming just because non procedural means no fixed way for
execution. The article consists of 3 parts. In first part we consider formal
systems for definition a named datasets and studying an expression power of
different subclasses. In the second part we consider a complexity of algorithms
of building sets by the definitions. In third part we consider a fullness and
flexibility of the class of program based data set definitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5763</identifier>
 <datestamp>2008-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5763</id><created>2008-10-31</created><authors><author><keyname>Fierens</keyname><forenames>Pablo Ignacio</forenames></author></authors><title>Number of wireless sensors needed to detect a wildfire</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The lack of extensive research in the application of inexpensive wireless
sensor nodes for the early detection of wildfires motivated us to investigate
the cost of such a network. As a first step, in this paper we present several
results which relate the time to detection and the burned area to the number of
sensor nodes in the region which is protected. We prove that the probability
distribution of the burned area at the moment of detection is approximately
exponential, given that some hypotheses hold: the positions of the sensor nodes
are independent random variables uniformly distributed and the number of sensor
nodes is large. This conclusion depends neither on the number of ignition
points nor on the propagation model of the fire.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5770</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5770</id><created>2008-10-31</created><updated>2011-02-25</updated><authors><author><keyname>Levin</keyname><forenames>George</forenames></author><author><keyname>Loyka</keyname><forenames>Sergey</forenames></author></authors><title>From Multi-Keyholes to Measure of Correlation and Power Imbalance in
  MIMO Channels: Outage Capacity Analysis</title><categories>cs.IT math.IT</categories><comments>accepted by IEEE IT Trans., 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An information-theoretic analysis of a multi-keyhole channel, which includes
a number of statistically independent keyholes with possibly different
correlation matrices, is given. When the number of keyholes or/and the number
of Tx/Rx antennas is large, there is an equivalent Rayleigh-fading channel such
that the outage capacities of both channels are asymptotically equal. In the
case of a large number of antennas and for a broad class of fading
distributions, the instantaneous capacity is shown to be asymptotically
Gaussian in distribution, and compact, closed-form expressions for the mean and
variance are given. Motivated by the asymptotic analysis, a simple,
full-ordering scalar measure of spatial correlation and power imbalance in MIMO
channels is introduced, which quantifies the negative impact of these two
factors on the outage capacity in a simple and well-tractable way. It does not
require the eigenvalue decomposition, and has the full-ordering property. The
size-asymptotic results are used to prove Telatar's conjecture for
semi-correlated multi-keyhole and Rayleigh channels. Since the keyhole channel
model approximates well the relay channel in the amplify-and-forward mode in
certain scenarios, these results also apply to the latter
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0037</identifier>
 <datestamp>2010-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0037</id><created>2008-10-31</created><updated>2010-01-01</updated><authors><author><keyname>Dyer</keyname><forenames>Martin</forenames></author><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author><author><keyname>Jerrum</keyname><forenames>Mark</forenames></author></authors><title>A complexity dichotomy for hypergraph partition functions</title><categories>cs.CC cs.DM</categories><comments>21 pages</comments><acm-class>F.2.2; F.4.1; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the complexity of counting homomorphisms from an $r$-uniform
hypergraph $G$ to a symmetric $r$-ary relation $H$. We give a dichotomy theorem
for $r&gt;2$, showing for which $H$ this problem is in FP and for which $H$ it is
#P-complete. This generalises a theorem of Dyer and Greenhill (2000) for the
case $r=2$, which corresponds to counting graph homomorphisms. Our dichotomy
theorem extends to the case in which the relation $H$ is weighted, and the goal
is to compute the \emph{partition function}, which is the sum of weights of the
homomorphisms. This problem is motivated by statistical physics, where it
arises as computing the partition function for particle models in which certain
combinations of $r$ sites interact symmetrically. In the weighted case, our
dichotomy theorem generalises a result of Bulatov and Grohe (2005) for graphs,
where $r=2$. When $r=2$, the polynomial time cases of the dichotomy correspond
simply to rank-1 weights. Surprisingly, for all $r&gt;2$ the polynomial time cases
of the dichotomy have rather more structure. It turns out that the weights must
be superimposed on a combinatorial structure defined by solutions of an
equation over an Abelian group. Our result also gives a dichotomy for a closely
related constraint satisfaction problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0048</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0048</id><created>2008-10-31</created><authors><author><keyname>Su</keyname><forenames>Yi</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Conjectural Equilibrium in Water-filling Games</title><categories>cs.GT cs.MA</categories><comments>29 pages, 7 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper considers a non-cooperative game in which competing users sharing
a frequency-selective interference channel selfishly optimize their power
allocation in order to improve their achievable rates. Previously, it was shown
that a user having the knowledge of its opponents' channel state information
can make foresighted decisions and substantially improve its performance
compared with the case in which it deploys the conventional iterative
water-filling algorithm, which does not exploit such knowledge. This paper
discusses how a foresighted user can acquire this knowledge by modeling its
experienced interference as a function of its own power allocation. To
characterize the outcome of the multi-user interaction, the conjectural
equilibrium is introduced, and the existence of this equilibrium for the
investigated water-filling game is proved. Interestingly, both the Nash
equilibrium and the Stackelberg equilibrium are shown to be special cases of
the generalization of conjectural equilibrium. We develop practical algorithms
to form accurate beliefs and search desirable power allocation strategies.
Numerical simulations indicate that a foresighted user without any a priori
knowledge of its competitors' private information can effectively learn the
required information, and induce the entire system to an operating point that
improves both its own achievable rate as well as the rates of the other
participants in the water-filling game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0063</identifier>
 <datestamp>2009-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0063</id><created>2008-11-01</created><authors><author><keyname>Dujella</keyname><forenames>Andrej</forenames></author></authors><title>A variant of Wiener's attack on RSA</title><categories>cs.CR</categories><comments>9 pages</comments><journal-ref>Computing 85 (2009), 77-83.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wiener's attack is a well-known polynomial-time attack on a RSA cryptosystem
with small secret decryption exponent d, which works if d&lt;n^{0.25}, where n=pq
is the modulus of the cryptosystem. Namely, in that case, d is the denominator
of some convergent p_m/q_m of the continued fraction expansion of e/n, and
therefore d can be computed efficiently from the public key (n,e).
  There are several extensions of Wiener's attack that allow the RSA
cryptosystem to be broken when d is a few bits longer than n^{0.25}. They all
have the run-time complexity (at least) O(D^2), where d=Dn^{0.25}. Here we
propose a new variant of Wiener's attack, which uses results on Diophantine
approximations of the form |\alpha - p/q| &lt; c/q^2, and &quot;meet-in-the-middle&quot;
variant for testing the candidates (of the form rq_{m+1} + sq_m) for the secret
exponent. This decreases the run-time complexity of the attack to O(D log(D))
(with the space complexity O(D)).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0071</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0071</id><created>2008-11-03</created><authors><author><keyname>Roux</keyname><forenames>St&#xe9;phane Le</forenames><affiliation>LIP</affiliation></author><author><keyname>Lescanne</keyname><forenames>Pierre</forenames><affiliation>LIP</affiliation></author><author><keyname>Vestergaard</keyname><forenames>Ren&#xe9;</forenames></author></authors><title>Conversion/Preference Games</title><categories>cs.GT</categories><proxy>ccsd ensl-00333708</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the concept of Conversion/Preference Games, or CP games for
short. CP games generalize the standard notion of strategic games. First we
exemplify the use of CP games. Second we formally introduce and define the
CP-games formalism. Then we sketch two `real-life' applications, namely a
connection between CP games and gene regulation networks, and the use of CP
games to formalize implied information in Chinese Wall security. We end with a
study of a particular fixed-point construction over CP games and of the
resulting existence of equilibria in possibly infinite games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0077</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0077</id><created>2008-11-01</created><authors><author><keyname>Maiti</keyname><forenames>Deepyaman</forenames></author><author><keyname>Konar</keyname><forenames>Amit</forenames></author></authors><title>Approximation of a Fractional Order System by an Integer Order Model
  Using Particle Swarm Optimization Technique</title><categories>cs.OH</categories><comments>IEEE Sponsored Conference on Computational Intelligence, Control And
  Computer Vision In Robotics &amp; Automation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  System identification is a necessity in control theory. Classical control
theory usually considers processes with integer order transfer functions. Real
processes are usually of fractional order as opposed to the ideal integral
order models. A simple and elegant scheme is presented for approximation of
such a real world fractional order process by an ideal integral order model. A
population of integral order process models is generated and updated by PSO
technique, the fitness function being the sum of squared deviations from the
set of observations obtained from the actual fractional order process. Results
show that the proposed scheme offers a high degree of accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0078</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0078</id><created>2008-11-01</created><authors><author><keyname>Maiti</keyname><forenames>Deepyaman</forenames></author><author><keyname>Acharya</keyname><forenames>Ayan</forenames></author><author><keyname>Konar</keyname><forenames>Amit</forenames></author></authors><title>A Swarm Intelligence Based Scheme for Complete and Fault-tolerant
  Identification of a Dynamical Fractional Order Process</title><categories>cs.OH</categories><comments>2008 IEEE Region 10 Colloquium and the Third ICIIS, Kharagpur, INDIA.
  Paper Identification Number 239</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  System identification refers to estimation of process parameters and is a
necessity in control theory. Physical systems usually have varying parameters.
For such processes, accurate identification is particularly important. Online
identification schemes are also needed for designing adaptive controllers. Real
processes are usually of fractional order as opposed to the ideal integral
order models. In this paper, we propose a simple and elegant scheme of
estimating the parameters for such a fractional order process. A population of
process models is generated and updated by particle swarm optimization (PSO)
technique, the fitness function being the sum of squared deviations from the
actual set of observations. Results show that the proposed scheme offers a high
degree of accuracy even when the observations are corrupted to a significant
degree. Additional schemes to improve the accuracy still further are also
proposed and analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0079</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0079</id><created>2008-11-01</created><authors><author><keyname>Chakraborty</keyname><forenames>Mithun</forenames></author><author><keyname>Maiti</keyname><forenames>Deepyaman</forenames></author><author><keyname>Konar</keyname><forenames>Amit</forenames></author></authors><title>The Application of Stochastic Optimization Algorithms to the Design of a
  Fractional-order PID Controller</title><categories>cs.OH</categories><comments>2008 IEEE Region 10 Colloquium and the Third ICIIS, Kharagpur, INDIA.
  Paper Identification Number: 396</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Proportional-Integral-Derivative Controller is widely used in industries
for process control applications. Fractional-order PID controllers are known to
outperform their integer-order counterparts. In this paper, we propose a new
technique of fractional-order PID controller synthesis based on peak overshoot
and rise-time specifications. Our approach is to construct an objective
function, the optimization of which yields a possible solution to the design
problem. This objective function is optimized using two popular bio-inspired
stochastic search algorithms, namely Particle Swarm Optimization and
Differential Evolution. With the help of a suitable example, the superiority of
the designed fractional-order PID controller to an integer-order PID controller
is affirmed and a comparative study of the efficacy of the two above algorithms
in solving the optimization problem is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0080</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0080</id><created>2008-11-01</created><authors><author><keyname>Acharya</keyname><forenames>Ayan</forenames></author><author><keyname>Maiti</keyname><forenames>Deepyaman</forenames></author><author><keyname>Konar</keyname><forenames>Amit</forenames></author><author><keyname>Janarthanan</keyname><forenames>Ramadoss</forenames></author></authors><title>A Deterministic Model for Analyzing the Dynamics of Ant System Algorithm
  and Performance Amelioration through a New Pheromone Deposition Approach</title><categories>cs.OH</categories><comments>4th IEEE International Conference on Information and Automation for
  Sustainability, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ant Colony Optimization (ACO) is a metaheuristic for solving difficult
discrete optimization problems. This paper presents a deterministic model based
on differential equation to analyze the dynamics of basic Ant System algorithm.
Traditionally, the deposition of pheromone on different parts of the tour of a
particular ant is always kept unvarying. Thus the pheromone concentration
remains uniform throughout the entire path of an ant. This article introduces
an exponentially increasing pheromone deposition approach by artificial ants to
improve the performance of basic Ant System algorithm. The idea here is to
introduce an additional attracting force to guide the ants towards destination
more easily by constructing an artificial potential field identified by
increasing pheromone concentration towards the goal. Apart from carrying out
analysis of Ant System dynamics with both traditional and the newly proposed
deposition rules, the paper presents an exhaustive set of experiments performed
to find out suitable parameter ranges for best performance of Ant System with
the proposed deposition approach. Simulations reveal that the proposed
deposition rule outperforms the traditional one by a large extent both in terms
of solution quality and algorithm convergence. Thus, the contributions of the
article can be presented as follows: i) it introduces differential equation and
explores a novel method of analyzing the dynamics of ant system algorithms, ii)
it initiates an exponentially increasing pheromone deposition approach by
artificial ants to improve the performance of algorithm in terms of solution
quality and convergence time, iii) exhaustive experimentation performed
facilitates the discovery of an algebraic relationship between the parameter
set of the algorithm and feature of the problem environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0083</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0083</id><created>2008-11-01</created><authors><author><keyname>Maiti</keyname><forenames>Deepyaman</forenames></author><author><keyname>Acharya</keyname><forenames>Ayan</forenames></author><author><keyname>Chakraborty</keyname><forenames>Mithun</forenames></author><author><keyname>Konar</keyname><forenames>Amit</forenames></author><author><keyname>Janarthanan</keyname><forenames>Ramadoss</forenames></author></authors><title>Tuning PID and FOPID Controllers using the Integral Time Absolute Error
  Criterion</title><categories>cs.OH</categories><comments>4th IEEE International Conference on Information and Automation for
  Sustainability, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Particle swarm optimization (PSO) is extensively used for real parameter
optimization in diverse fields of study. This paper describes an application of
PSO to the problem of designing a fractional-order
proportional-integral-derivative (FOPID) controller whose parameters comprise
proportionality constant, integral constant, derivative constant, integral
order (lambda) and derivative order (delta). The presence of five optimizable
parameters makes the task of designing a FOPID controller more challenging than
conventional PID controller design. Our design method focuses on minimizing the
Integral Time Absolute Error (ITAE) criterion. The digital realization of the
deigned system utilizes the Tustin operator-based continued fraction expansion
scheme. We carry out a simulation that illustrates the effectiveness of the
proposed approach especially for realizing fractional-order plants. This paper
also attempts to study the behavior of fractional PID controller vis-a-vis that
of its integer order counterpart and demonstrates the superiority of the former
to the latter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0113</identifier>
 <datestamp>2012-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0113</id><created>2008-11-01</created><updated>2010-07-11</updated><authors><author><keyname>Martins</keyname><forenames>Andre C. R.</forenames></author></authors><title>A Bayesian Framework for Opinion Updates</title><categories>physics.soc-ph cs.MA nlin.AO</categories><comments>20 pages; major expansion and detailing</comments><report-no>In Liu Yijun and Zhou Tao, editors, Social Physics Catena (No.3),
  pages 146-157. Science Press, Beijing</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Opinion Dynamics lacks a theoretical basis. In this article, I propose to use
a decision-theoretic framework, based on the updating of subjective
probabilities, as that basis. We will see we get a basic tool for a better
understanding of the interaction between the agents in Opinion Dynamics
problems and for creating new models. I will review the few existing
applications of Bayesian update rules to both discrete and continuous opinion
problems and show that several traditional models can be obtained as special
cases or approximations from these Bayesian models. The empirical basis and
useful properties of the framework will be discussed and examples of how the
framework can be used to describe different problems given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0123</identifier>
 <datestamp>2008-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0123</id><created>2008-11-01</created><updated>2008-11-12</updated><authors><author><keyname>Turkia</keyname><forenames>Mika</forenames></author></authors><title>A computational model of affects</title><categories>cs.AI cs.MA</categories><comments>A pre-print version; final version published in D. Dietrich et al.
  (Eds.): Simulating the Mind. Springer 2009, see
  http://www.springer.com/springerwiennewyork/computer+science/book/978-3-211-09450-1
  . 7 pages, 2 figures</comments><acm-class>I.2.11; J.4</acm-class><journal-ref>Dietrich, D.; Fodor, G.; Zucker, G.; Bruckner, D. (Eds.):
  Simulating the Mind. A Technical Neuropsychoanalytical Approach. Springer
  2009, pp. 277-289</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article provides a simple logical structure, in which affective concepts
(i.e. concepts related to emotions and feelings) can be defined. The set of
affects defined is similar to the set of emotions covered in the OCC model
(Ortony A., Collins A., and Clore G. L.: The Cognitive Structure of Emotions.
Cambridge University Press, 1988), but the model presented in this article is
fully computationally defined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0131</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0131</id><created>2008-11-02</created><authors><author><keyname>Acharya</keyname><forenames>Ayan</forenames></author><author><keyname>Maiti</keyname><forenames>Deepyaman</forenames></author><author><keyname>Banerjee</keyname><forenames>Aritra</forenames></author><author><keyname>Konar</keyname><forenames>Amit</forenames></author></authors><title>Balancing Exploration and Exploitation by an Elitist Ant System with
  Exponential Pheromone Deposition Rule</title><categories>cs.AI</categories><comments>2008 IEEE Region 10 Colloquium and the Third ICIIS, Kharagpur, INDIA.
  Paper ID: 250</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents an exponential pheromone deposition rule to modify the
basic ant system algorithm which employs constant deposition rule. A stability
analysis using differential equation is carried out to find out the values of
parameters that make the ant system dynamics stable for both kinds of
deposition rule. A roadmap of connected cities is chosen as the problem
environment where the shortest route between two given cities is required to be
discovered. Simulations performed with both forms of deposition approach using
Elitist Ant System model reveal that the exponential deposition approach
outperforms the classical one by a large extent. Exhaustive experiments are
also carried out to find out the optimum setting of different controlling
parameters for exponential deposition approach and an empirical relationship
between the major controlling parameters of the algorithm and some features of
problem environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0133</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0133</id><created>2008-11-02</created><authors><author><keyname>Chakraborty</keyname><forenames>Mithun</forenames></author><author><keyname>Maiti</keyname><forenames>Deepyaman</forenames></author><author><keyname>Konar</keyname><forenames>Amit</forenames></author><author><keyname>Janarthanan</keyname><forenames>Ramadoss</forenames></author></authors><title>A Study of the Grunwald-Letnikov Definition for Minimizing the Effects
  of Random Noise on Fractional Order Differential Equations</title><categories>cs.OH</categories><comments>4th IEEE International Conference on Information and Automation for
  Sustainability, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Of the many definitions for fractional order differintegral, the
Grunwald-Letnikov definition is arguably the most important one. The necessity
of this definition for the description and analysis of fractional order systems
cannot be overstated. Unfortunately, the Fractional Order Differential Equation
(FODE) describing such a systems, in its original form, highly sensitive to the
effects of random noise components inevitable in a natural environment. Thus
direct application of the definition in a real-life problem can yield erroneous
results. In this article, we perform an in-depth mathematical analysis the
Grunwald-Letnikov definition in depth and, as far as we know, we are the first
to do so. Based on our analysis, we present a transformation scheme which will
allow us to accurately analyze generalized fractional order systems in presence
of significant quantities of random errors. Finally, by a simple experiment, we
demonstrate the high degree of robustness to noise offered by the said
transformation and thus validate our scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0134</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0134</id><created>2008-11-02</created><authors><author><keyname>Maiti</keyname><forenames>Deepyaman</forenames></author><author><keyname>Acharya</keyname><forenames>Ayan</forenames></author><author><keyname>Konar</keyname><forenames>Amit</forenames></author><author><keyname>Ramadoss</keyname><forenames>Janarthanan</forenames></author></authors><title>A Novel Parser Design Algorithm Based on Artificial Ants</title><categories>cs.AI</categories><comments>4th IEEE International Conference on Information and Automation for
  Sustainability, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents a unique design for a parser using the Ant Colony
Optimization algorithm. The paper implements the intuitive thought process of
human mind through the activities of artificial ants. The scheme presented here
uses a bottom-up approach and the parsing program can directly use ambiguous or
redundant grammars. We allocate a node corresponding to each production rule
present in the given grammar. Each node is connected to all other nodes
(representing other production rules), thereby establishing a completely
connected graph susceptible to the movement of artificial ants. Each ant tries
to modify this sentential form by the production rule present in the node and
upgrades its position until the sentential form reduces to the start symbol S.
Successful ants deposit pheromone on the links that they have traversed
through. Eventually, the optimum path is discovered by the links carrying
maximum amount of pheromone concentration. The design is simple, versatile,
robust and effective and obviates the calculation of the above mentioned sets
and precedence relation tables. Further advantages of our scheme lie in i)
ascertaining whether a given string belongs to the language represented by the
grammar, and ii) finding out the shortest possible path from the given string
to the start symbol S in case multiple routes exist.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0135</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0135</id><created>2008-11-02</created><authors><author><keyname>Maiti</keyname><forenames>Deepyaman</forenames></author><author><keyname>Acharya</keyname><forenames>Ayan</forenames></author><author><keyname>Janarthanan</keyname><forenames>R.</forenames></author><author><keyname>Konar</keyname><forenames>Amit</forenames></author></authors><title>Complete Identification of a Dynamic Fractional Order System Under
  Non-ideal Conditions Using Fractional Differintegral Definitions</title><categories>cs.OH</categories><comments>16th IEEE International Conference on Advanced Computing and
  Communication, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This contribution deals with identification of fractional-order dynamical
systems. System identification, which refers to estimation of process
parameters, is a necessity in control theory. Real processes are usually of
fractional order as opposed to the ideal integral order models. A simple and
elegant scheme of estimating the parameters for such a fractional order process
is proposed. This method employs fractional calculus theory to find equations
relating the parameters that are to be estimated, and then estimates the
process parameters after solving the simultaneous equations. The data used for
the calculations are intentionally corrupted to simulate real-life conditions.
Results show that the proposed scheme offers a very high degree of accuracy
even for erroneous data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0136</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0136</id><created>2008-11-02</created><authors><author><keyname>Acharya</keyname><forenames>Ayan</forenames></author><author><keyname>Maiti</keyname><forenames>Deepyaman</forenames></author><author><keyname>Banerjee</keyname><forenames>Aritra</forenames></author><author><keyname>Janarthanan</keyname><forenames>R.</forenames></author><author><keyname>Konar</keyname><forenames>Amit</forenames></author></authors><title>Extension of Max-Min Ant System with Exponential Pheromone Deposition
  Rule</title><categories>cs.AI</categories><comments>16th IEEE International Conference on Advanced Computing and
  Communication, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents an exponential pheromone deposition approach to improve
the performance of classical Ant System algorithm which employs uniform
deposition rule. A simplified analysis using differential equations is carried
out to study the stability of basic ant system dynamics with both exponential
and constant deposition rules. A roadmap of connected cities, where the
shortest path between two specified cities are to be found out, is taken as a
platform to compare Max-Min Ant System model (an improved and popular model of
Ant System algorithm) with exponential and constant deposition rules. Extensive
simulations are performed to find the best parameter settings for non-uniform
deposition approach and experiments with these parameter settings revealed that
the above approach outstripped the traditional one by a large extent in terms
of both solution quality and convergence time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0137</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0137</id><created>2008-11-02</created><authors><author><keyname>Maiti</keyname><forenames>Deepyaman</forenames></author><author><keyname>Chakraborty</keyname><forenames>Mithun</forenames></author><author><keyname>Konar</keyname><forenames>Amit</forenames></author></authors><title>A Novel Approach for Complete Identification of Dynamic Fractional Order
  Systems Using Stochastic Optimization Algorithms and Fractional Calculus</title><categories>cs.OH</categories><comments>5th IEEE International Conference on Electrical &amp; Computer
  Engineering, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This contribution deals with identification of fractional-order dynamical
systems. System identification, which refers to estimation of process
parameters, is a necessity in control theory. Real processes are usually of
fractional order as opposed to the ideal integral order models. A simple and
elegant scheme of estimating the parameters for such a fractional order process
is proposed. This method employs fractional calculus theory to find equations
relating the parameters that are to be estimated, and then estimates the
process parameters after solving the simultaneous equations. The said
simultaneous equations are generated and updated using particle swarm
optimization (PSO) technique, the fitness function being the sum of squared
deviations from the actual set of observations. The data used for the
calculations are intentionally corrupted to simulate real-life conditions.
Results show that the proposed scheme offers a very high degree of accuracy
even for erroneous data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0139</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0139</id><created>2008-11-02</created><authors><author><keyname>Jaeger</keyname><forenames>Stefan</forenames></author></authors><title>Entropy, Perception, and Relativity</title><categories>cs.LG</categories><report-no>LAMP-TR-131/CAR-TR-1012/CS-TR-4799/UMIACS-TR-2006-20</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, I expand Shannon's definition of entropy into a new form of
entropy that allows integration of information from different random events.
Shannon's notion of entropy is a special case of my more general definition of
entropy. I define probability using a so-called performance function, which is
de facto an exponential distribution. Assuming that my general notion of
entropy reflects the true uncertainty about a probabilistic event, I understand
that our perceived uncertainty differs. I claim that our perception is the
result of two opposing forces similar to the two famous antagonists in Chinese
philosophy: Yin and Yang. Based on this idea, I show that our perceived
uncertainty matches the true uncertainty in points determined by the golden
ratio. I demonstrate that the well-known sigmoid function, which we typically
employ in artificial neural networks as a non-linear threshold function,
describes the actual performance. Furthermore, I provide a motivation for the
time dilation in Einstein's Special Relativity, basically claiming that
although time dilation conforms with our perception, it does not correspond to
reality. At the end of the paper, I show how to apply this theoretical
framework to practical applications. I present recognition rates for a pattern
recognition problem, and also propose a network architecture that can take
advantage of general entropy to solve complex decision problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0146</identifier>
 <datestamp>2009-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0146</id><created>2008-11-02</created><updated>2009-05-14</updated><authors><author><keyname>Lifchitz</keyname><forenames>Alain</forenames><affiliation>LIP6</affiliation></author><author><keyname>Jhean-Larose</keyname><forenames>Sandra</forenames><affiliation>LPC</affiliation></author><author><keyname>Denhi&#xe8;re</keyname><forenames>Guy</forenames><affiliation>LPC</affiliation></author></authors><title>Effect of Tuned Parameters on a LSA MCQ Answering Model</title><categories>cs.LG cs.AI stat.ML</categories><comments>9 pages</comments><proxy>ccsd hal-00336126</proxy><journal-ref>Behavior Research Methods, 41 (4), p. 1201-1209, November 2009</journal-ref><doi>10.3758/BRM.41.4.1201</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the current state of a work in progress, whose objective
is to better understand the effects of factors that significantly influence the
performance of Latent Semantic Analysis (LSA). A difficult task, which consists
in answering (French) biology Multiple Choice Questions, is used to test the
semantic properties of the truncated singular space and to study the relative
influence of main parameters. A dedicated software has been designed to fine
tune the LSA semantic space for the Multiple Choice Questions task. With
optimal parameters, the performances of our simple model are quite surprisingly
equal or superior to those of 7th and 8th grades students. This indicates that
semantic spaces were quite good despite their low dimensions and the small
sizes of training data sets. Besides, we present an original entropy global
weighting of answers' terms of each question of the Multiple Choice Questions
which was necessary to achieve the model's success.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0152</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0152</id><created>2008-11-02</created><authors><author><keyname>Li</keyname><forenames>Lianlin</forenames></author><author><keyname>Xiang</keyname><forenames>Yin</forenames></author><author><keyname>Li</keyname><forenames>Fang</forenames></author></authors><title>Theoretical Analysis of Compressive Sensing via Random Filter</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the theoretical analysis of compressive sensing via random
filter, firstly outlined by J. Romberg [compressive sensing by random
convolution, submitted to SIAM Journal on Imaging Science on July 9, 2008], has
been refined or generalized to the design of general random filter used for
compressive sensing. This universal CS measurement consists of two parts: one
is from the convolution of unknown signal with a random waveform followed by
random time-domain subsampling; the other is from the directly time-domain
subsampling of the unknown signal. It has been shown that the proposed approach
is a universally efficient data acquisition strategy, which means that the
n-dimensional signal which is S sparse in any sparse representation can be
exactly recovered from Slogn measurements with overwhelming probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0166</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0166</id><created>2008-11-02</created><authors><author><keyname>Monniaux</keyname><forenames>David</forenames><affiliation>VERIMAG - Imag</affiliation></author></authors><title>Automatic Modular Abstractions for Linear Constraints</title><categories>cs.PL cs.LO</categories><proxy>ccsd hal-00336144</proxy><acm-class>F.3.1; F.3.2; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method for automatically generating abstract transformers for
static analysis by abstract interpretation. The method focuses on linear
constraints on programs operating on rational, real or floating-point variables
and containing linear assignments and tests. In addition to loop-free code, the
same method also applies for obtaining least fixed points as functions of the
precondition, which permits the analysis of loops and recursive functions. Our
algorithms are based on new quantifier elimination and symbolic manipulation
techniques. Given the specification of an abstract domain, and a program block,
our method automatically outputs an implementation of the corresponding
abstract transformer. It is thus a form of program transformation. The
motivation of our work is data-flow synchronous programming languages, used for
building control-command embedded systems, but it also applies to imperative
and functional programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0174</identifier>
 <datestamp>2009-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0174</id><created>2008-11-02</created><authors><author><keyname>Yu</keyname><forenames>Yaming</forenames></author></authors><title>A Bit of Information Theory, and the Data Augmentation Algorithm
  Converges</title><categories>cs.IT math.IT stat.CO</categories><journal-ref>IEEE Transactions on Information Theory 54 (2008) 5186--5188</journal-ref><doi>10.1109/TIT.2008.929918</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The data augmentation (DA) algorithm is a simple and powerful tool in
statistical computing. In this note basic information theory is used to prove a
nontrivial convergence theorem for the DA algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0196</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0196</id><created>2008-11-02</created><authors><author><keyname>Chen</keyname><forenames>Ning</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>Reduced-Complexity Reed--Solomon Decoders Based on Cyclotomic FFTs</title><categories>cs.IT math.IT</categories><comments>15 pages, shortened version submitted to IEEE Signal Processing
  Letters</comments><doi>10.1109/LSP.2009.2014292</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we reduce the computational complexities of partial and dual
partial cyclotomic FFTs (CFFTs), which are discrete Fourier transforms where
spectral and temporal components are constrained, based on their properties as
well as a common subexpression elimination algorithm. Our partial CFFTs achieve
smaller computational complexities than previously proposed partial CFFTs.
Utilizing our CFFTs in both transform- and time-domain Reed--Solomon decoders,
we achieve significant complexity reductions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0210</identifier>
 <datestamp>2009-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0210</id><created>2008-11-02</created><updated>2009-03-02</updated><authors><author><keyname>Ma</keyname><forenames>Xudong</forenames></author></authors><title>Novel Blind Signal Classification Method Based on Data Compression</title><categories>cs.IT math.IT</categories><comments>Camera ready version, accepted for publication in Proc. the 6th
  International Conference on Information Technology : New Generations, ITNG
  2009, Las Vegas, Nevada, USA. Typos in the reference list have been fixed</comments><journal-ref>Proceeding of the 6th International Conference on Information
  Technology : New Generations, Las Vegas, Nevada, April 27-29, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel algorithm for signal classification problems. We
consider a non-stationary random signal, where samples can be classified into
several different classes, and samples in each class are identically
independently distributed with an unknown probability distribution. The problem
to be solved is to estimate the probability distributions of the classes and
the correct membership of the samples to the classes. We propose a signal
classification method based on the data compression principle that the accurate
estimation in the classification problems induces the optimal signal models for
data compression. The method formulates the classification problem as an
optimization problem, where a so called {&quot;classification gain&quot;} is maximized.
In order to circumvent the difficulties in integer optimization, we propose a
continuous relaxation based algorithm. It is proven in this paper that
asymptotically vanishing optimality loss is incurred by the continuous
relaxation. We show by simulation results that the proposed algorithm is
effective, robust and has low computational complexity. The proposed algorithm
can be applied to solve various multimedia signal segmentation, analysis, and
pattern recognition problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0241</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0241</id><created>2008-11-03</created><updated>2008-11-04</updated><authors><author><keyname>Ma</keyname><forenames>P.</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Wang</keyname><forenames>W.</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Zhao</keyname><forenames>X.</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Zheng</keyname><forenames>K.</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author></authors><title>Joint Transmitter-Receiver Design for the Downlink Multiuser Spatial
  Multiplexing MIMO System</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, Appeared in IEEE ICC'08 WCS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a joint transmitter-receiver design to minimize the
weighted sum power under the post-processing signal-to-interference-and-noise
ratio (post-SINR) constraints for all subchannels. Simulation results
demonstrate that the algorithm can not only satisfy the post-SINR constraints
but also easily adjust the power distribution among the users by changing the
weights accordingly. Hence the algorithm can be used to alleviates the adjacent
cell interference by reducing the transmitting power to the edge users without
performance penalty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0254</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0254</id><created>2008-11-03</created><authors><author><keyname>Adnan</keyname><forenames>Muhammad Abdullah</forenames></author><author><keyname>Hasan</keyname><forenames>Masud</forenames></author></authors><title>Characterizing Graphs of Zonohedra</title><categories>cs.CG cs.DM cs.DS</categories><comments>13 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A classic theorem by Steinitz states that a graph G is realizable by a convex
polyhedron if and only if G is 3-connected planar. Zonohedra are an important
subclass of convex polyhedra having the property that the faces of a zonohedron
are parallelograms and are in parallel pairs. In this paper we give
characterization of graphs of zonohedra. We also give a linear time algorithm
to recognize such a graph. In our quest for finding the algorithm, we prove
that in a zonohedron P both the number of zones and the number of faces in each
zone is O(square root{n}), where n is the number of vertices of P.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0273</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0273</id><created>2008-11-03</created><authors><author><keyname>Sharma</keyname><forenames>Vinod</forenames></author><author><keyname>Mukherji</keyname><forenames>Utpal</forenames></author><author><keyname>Joseph</keyname><forenames>Vinay</forenames></author></authors><title>Efficient Energy Management Policies for Networks with Energy Harvesting
  Sensor Nodes</title><categories>cs.NI</categories><comments>Keywords: Optimal energy management policies, energy harvesting,
  sensor networks, MAC protocols</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study sensor networks with energy harvesting nodes. The generated energy
at a node can be stored in a buffer. A sensor node periodically senses a random
field and generates a packet. These packets are stored in a queue and
transmitted using the energy available at that time at the node. For such
networks we develop efficient energy management policies. First, for a single
node, we obtain policies that are throughput optimal, i.e., the data queue
stays stable for the largest possible data rate. Next we obtain energy
management policies which minimize the mean delay in the queue. We also compare
performance of several easily implementable suboptimal policies. A greedy
policy is identified which, in low SNR regime, is throughput optimal and also
minimizes mean delay. Next using the results for a single node, we develop
efficient MAC policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0285</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0285</id><created>2008-11-03</created><authors><author><keyname>Rai</keyname><forenames>Brijesh Kumar</forenames></author><author><keyname>Dey</keyname><forenames>Bikash Kumar</forenames></author><author><keyname>Karandikar</keyname><forenames>Abhay</forenames></author></authors><title>Some results on communicating the sum of sources over a network</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of communicating the sum of $m$ sources to $n$
terminals in a directed acyclic network. Recently, it was shown that for a
network of unit capacity links with either $m=2$ or $n=2$, the sum of the
sources can be communicated to the terminals if and only if every
source-terminal pair is connected in the network. We show in this paper that
for any finite set of primes, there exists a network where the sum of the
sources can be communicated to the terminals only over finite fields of
characteristic belonging to that set. As a corollary, this gives networks where
the sum can not be communicated over any finite field even though every source
is connected to every terminal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0310</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0310</id><created>2008-11-03</created><authors><author><keyname>Badra</keyname><forenames>Fadi</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>D'Aquin</keyname><forenames>Mathieu</forenames><affiliation>KMI</affiliation></author><author><keyname>Lieber</keyname><forenames>Jean</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Meilender</keyname><forenames>Thomas</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Edhibou: a Customizable Interface for Decision Support in a Semantic
  Portal</title><categories>cs.AI cs.HC</categories><comments>ISWC (2008)</comments><proxy>ccsd inria-00336330</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Semantic Web is becoming more and more a reality, as the required
technologies have reached an appropriate level of maturity. However, at this
stage, it is important to provide tools facilitating the use and deployment of
these technologies by end-users. In this paper, we describe EdHibou, an
automatically generated, ontology-based graphical user interface that
integrates in a semantic portal. The particularity of EdHibou is that it makes
use of OWL reasoning capabilities to provide intelligent features, such as
decision support, upon the underlying ontology. We present an application of
EdHibou to medical decision support based on a formalization of clinical
guidelines in OWL and show how it can be customized thanks to an ontology of
graphical components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0325</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0325</id><created>2008-11-03</created><authors><author><keyname>Goseling</keyname><forenames>Jasper</forenames></author><author><keyname>Weber</keyname><forenames>Jos. H.</forenames></author></authors><title>Energy Benefit of Network Coding for Multiple Unicast in Wireless
  Networks</title><categories>cs.IT math.IT</categories><journal-ref>Proceedings of the Twenty-ninth Symposium on Information Theory in
  the Benelux (ISBN: 978-90-9023135-8), Leuven, Belgium, pp. 85-91, May 29-30,
  2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the maximum possible energy benefit of network coding for
multiple unicast on wireless networks is at least 3. This improves the
previously known lower bound of 2.4 from [1].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0335</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0335</id><created>2008-11-03</created><authors><author><keyname>Saget</keyname><forenames>Sylvie</forenames></author><author><keyname>Legras</keyname><forenames>Francois</forenames></author><author><keyname>Coppin</keyname><forenames>Gilles</forenames></author></authors><title>Cooperative interface of a swarm of UAVs</title><categories>cs.AI cs.HC cs.MA</categories><comments>First Conference on Humans Operating Unmanned Systems (HUMOUS-08),
  Brest : France (2008)</comments><proxy>ccsd hal-00336200</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  After presenting the broad context of authority sharing, we outline how
introducing more natural interaction in the design of the ground operator
interface of UV systems should help in allowing a single operator to manage the
complexity of his/her task. Introducing new modalities is one one of the means
in the realization of our vision of next- generation GOI. A more fundamental
aspect resides in the interaction manager which should help balance the
workload of the operator between mission and interaction, notably by applying a
multi-strategy approach to generation and interpretation. We intend to apply
these principles to the context of the Smaart prototype, and in this
perspective, we illustrate how to characterize the workload associated with a
particular operational situation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0340</identifier>
 <datestamp>2008-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0340</id><created>2008-11-03</created><authors><author><keyname>Lelu</keyname><forenames>Alain</forenames><affiliation>LASELDI</affiliation></author><author><keyname>Cadot</keyname><forenames>Martine</forenames><affiliation>INIST</affiliation></author><author><keyname>Cuxac</keyname><forenames>Pascal</forenames><affiliation>INIST</affiliation></author></authors><title>Document stream clustering: experimenting an incremental algorithm and
  AR-based tools for highlighting dynamic trends</title><categories>cs.AI</categories><proxy>ccsd hal-00336175</proxy><journal-ref>International Workshop on Webometrics, Informetrics and
  Scientometrics &amp; Seventh COLLNET Meeting, France (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address here two major challenges presented by dynamic data mining: 1) the
stability challenge: we have implemented a rigorous incremental density-based
clustering algorithm, independent from any initial conditions and ordering of
the data-vectors stream, 2) the cognitive challenge: we have implemented a
stringent selection process of association rules between clusters at time t-1
and time t for directly generating the main conclusions about the dynamics of a
data-stream. We illustrate these points with an application to a two years and
2600 documents scientific information database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0359</identifier>
 <datestamp>2010-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0359</id><created>2008-11-03</created><updated>2010-06-11</updated><authors><author><keyname>de Bruijn</keyname><forenames>Jos</forenames></author><author><keyname>Eiter</keyname><forenames>Thomas</forenames></author><author><keyname>Polleres</keyname><forenames>Axel</forenames></author><author><keyname>Tompits</keyname><forenames>Hans</forenames></author></authors><title>Embedding Non-Ground Logic Programs into Autoepistemic Logic for
  Knowledge Base Combination</title><categories>cs.LO cs.AI</categories><comments>52 pages, submitted</comments><acm-class>I.2.4; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of the Semantic Web, several approaches to the combination of
ontologies, given in terms of theories of classical first-order logic and rule
bases, have been proposed. They either cast rules into classical logic or limit
the interaction between rules and ontologies. Autoepistemic logic (AEL) is an
attractive formalism which allows to overcome these limitations, by serving as
a uniform host language to embed ontologies and nonmonotonic logic programs
into it. For the latter, so far only the propositional setting has been
considered. In this paper, we present three embeddings of normal and three
embeddings of disjunctive non-ground logic programs under the stable model
semantics into first-order AEL. While the embeddings all correspond with
respect to objective ground atoms, differences arise when considering
non-atomic formulas and combinations with first-order theories. We compare the
embeddings with respect to stable expansions and autoepistemic consequences,
considering the embeddings by themselves, as well as combinations with
classical theories. Our results reveal differences and correspondences of the
embeddings and provide useful guidance in the choice of a particular embedding
for knowledge combination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0381</identifier>
 <datestamp>2010-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0381</id><created>2008-11-03</created><authors><author><keyname>Istrate</keyname><forenames>Gabriel</forenames></author></authors><title>On the dynamics of Social Balance on general networks (with an
  application to XOR-SAT)</title><categories>cs.DM math.CO math.PR physics.soc-ph</categories><journal-ref>Fundamenta Informaticae, 91 (2), pp. 341-356, 2009.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study nondeterministic and probabilistic versions of a discrete dynamical
system (due to T. Antal, P. L. Krapivsky, and S. Redner) inspired by Heider's
social balance theory. We investigate the convergence time of this dynamics on
several classes of graphs. Our contributions include:
  1. We point out the connection between the triad dynamics and a
generalization of annihilating walks to hypergraphs. In particular, this
connection allows us to completely characterize the recurrent states in graphs
where each edge belongs to at most two triangles.
  2. We also solve the case of hypergraphs that do not contain edges consisting
of one or two vertices.
  3. We show that on the so-called &quot;triadic cycle&quot; graph, the convergence time
is linear.
  4. We obtain a cubic upper bound on the convergence time on 2-regular triadic
simplexes G. This bound can be further improved to a quantity that depends on
the Cheeger constant of G. In particular this provides some rigorous
counterparts to previous experimental observations.
  We also point out an application to the analysis of the random walk algorithm
on certain instances of the 3-XOR-SAT problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0405</identifier>
 <datestamp>2008-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0405</id><created>2008-11-04</created><authors><author><keyname>Szabo</keyname><forenames>Gabor</forenames></author><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author></authors><title>Predicting the popularity of online content</title><categories>cs.CY cs.IR physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method for accurately predicting the long time popularity of
online content from early measurements of user access. Using two content
sharing portals, Youtube and Digg, we show that by modeling the accrual of
views and votes on content offered by these services we can predict the
long-term dynamics of individual submissions from initial data. In the case of
Digg, measuring access to given stories during the first two hours allows us to
forecast their popularity 30 days ahead with remarkable accuracy, while
downloads of Youtube videos need to be followed for 10 days to attain the same
performance. The differing time scales of the predictions are shown to be due
to differences in how content is consumed on the two portals: Digg stories
quickly become outdated, while Youtube videos are still found long after they
are initially submitted to the portal. We show that predictions are more
accurate for submissions for which attention decays quickly, whereas
predictions for evergreen content will be prone to larger errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0413</identifier>
 <datestamp>2008-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0413</id><created>2008-11-03</created><authors><author><keyname>Ma</keyname><forenames>Pengfei</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Zhao</keyname><forenames>Xiaochuan</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Peng</keyname><forenames>Mugen</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Wang</keyname><forenames>Wenbo</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author></authors><title>Robust Linear Processing for Downlink Multiuser MIMO System With
  Imperfectly Known Channel</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, Appeared in IEEE WCNC'08</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a roust downlink multiuser MIMO scheme that exploits the
channel mean and antenna correlations to alleviate the performance penalty due
to the mismatch between the true and estimated CSI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0417</identifier>
 <datestamp>2008-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0417</id><created>2008-11-03</created><authors><author><keyname>Zhao</keyname><forenames>Xiaochuan</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Peng</keyname><forenames>Tao</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Wang</keyname><forenames>Wenbo</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author></authors><title>Parametric Channel Estimation by Exploiting Hopping Pilots in Uplink
  OFDMA</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, Appeared in IEEE PIMRC'08</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a parametric channel estimation algorithm applicable to
uplink of OFDMA systems with pseudo-random subchannelization. It exploits the
hopping pilots to facilitate ESPRIT to estimate the delay subspace of the
multipath fading channel, and utilizes the global pilot tones to interpolate on
data subcarriers. Hence, it outperforms the traditional local channel
interpolators considerably.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0419</identifier>
 <datestamp>2008-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0419</id><created>2008-11-03</created><authors><author><keyname>Zhao</keyname><forenames>Xiaochuan</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Peng</keyname><forenames>Tao</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Yang</keyname><forenames>Ming</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Wang</keyname><forenames>Wenbo</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author></authors><title>Doppler Spread Estimation by Subspace Tracking for OFDM Systems</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, To appear in IEEE GLOBECOM'08</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel maximum Doppler spread estimation algorithm for
OFDM systems with the comb-type pilot pattern. By tracking the drifting delay
subspace of the multipath channel, the time correlation function is measured at
a high accuracy, which accordingly improves the estimation accuracy of the
maximum Doppler spread considerably.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0430</identifier>
 <datestamp>2015-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0430</id><created>2008-11-04</created><updated>2015-04-15</updated><authors><author><keyname>Zhao</keyname><forenames>Xiaochuan</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Peng</keyname><forenames>Tao</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Yang</keyname><forenames>Ming</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Wang</keyname><forenames>Wenbo</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author></authors><title>An Analysis of the Bias-Property of the Sample Auto-Correlation Matrices
  of Doubly Selective Fading Channels for OFDM Systems</title><categories>cs.IT math.IT</categories><comments>not sufficiently novel</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper derives the analytic expression of the sample auto-correlation
matrix from the least-squared channel estimation of doubly selective fading
channels for OFDM systems. According to the expression, the sample
auto-correlation matrix reveals the bias property which would cause the model
mismatch and therefore deteriorate the performance of channel estimation.
Numerical results demonstrate the bias property and corresponding analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0431</identifier>
 <datestamp>2008-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0431</id><created>2008-11-04</created><authors><author><keyname>Zhao</keyname><forenames>Xiaochuan</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Yang</keyname><forenames>Ming</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Peng</keyname><forenames>Tao</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Wang</keyname><forenames>Wenbo</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author></authors><title>On the Cramer-Rao Lower Bound for Frequency Correlation Matrices of
  Doubly Selective Fading Channels for OFDM Systems</title><categories>cs.IT math.IT</categories><comments>5 pages, 7 figures, Submitted to IEEE ICC'09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analytic expression of CRLB and the maximum likelihood estimator for the
sample frequency correlation matrices in doubly selective fading channels for
OFDM systems are reported in this paper. According to the analytical and
numerical results, the amount of samples affects the average mean square error
dominantly while the SNR and the Doppler spread do negligibly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0433</identifier>
 <datestamp>2008-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0433</id><created>2008-11-04</created><authors><author><keyname>Zhao</keyname><forenames>Xiaochuan</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Peng</keyname><forenames>Tao</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Yang</keyname><forenames>Ming</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Wang</keyname><forenames>Wenbo</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author></authors><title>On the Cramer-Rao Lower Bound for Spatial Correlation Matrices of Doubly
  Selective Fading Channels for MIMO OFDM Systems</title><categories>cs.IT math.IT</categories><comments>6 pages, 8 figures, Submitted to IEEE WCNC'09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analytic expression of CRLB and the maximum likelihood estimator for
spatial correlation matrices in time-varying multipath fading channels for MIMO
OFDM systems are reported in this paper. The analytical and numerical results
reveal that the amount of samples and the order of frequency selectivity have
dominant impact on the CRLB. Moreover, the number of pilot tones, SNR as well
as the normalized maximum Doppler spread together influence the effective order
of frequency selectivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0436</identifier>
 <datestamp>2008-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0436</id><created>2008-11-04</created><updated>2008-11-18</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Instruction sequences for the production of processes</title><categories>cs.PL cs.LO</categories><comments>23 pages; acknowledgement corrected, reference updated</comments><report-no>PRG0814</report-no><acm-class>D.1.4; F.1.1; F.1.2; F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single-pass instruction sequences under execution are considered to produce
behaviours to be controlled by some execution environment. Threads as
considered in thread algebra model such behaviours: upon each action performed
by a thread, a reply from its execution environment determines how the thread
proceeds. Threads in turn can be looked upon as producing processes as
considered in process algebra. We show that, by apposite choice of basic
instructions, all processes that can only be in a finite number of states can
be produced by single-pass instruction sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0452</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0452</id><created>2008-11-04</created><authors><author><keyname>Zhao</keyname><forenames>Xiaochuan</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Peng</keyname><forenames>Tao</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Yang</keyname><forenames>Ming</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author><author><keyname>Wang</keyname><forenames>Wenbo</forenames><affiliation>Beijing University of Posts and Telecommunications, Beijing, China</affiliation></author></authors><title>Doppler Spread Estimation by Tracking the Delay-Subspace for OFDM
  Systems in Doubly Selective Fading Channels</title><categories>cs.IT math.IT</categories><comments>4 pages, 2 figures, Appear in IEEE Signal Process. Letters</comments><doi>10.1109/LSP.2008.2010812</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel maximum Doppler spread estimation algorithm for OFDM systems with
comb-type pilot pattern is presented in this paper. By tracking the drifting
delay subspace of time-varying multipath channels, a Doppler dependent
parameter can be accurately measured and further expanded and transformed into
a non-linear high-order polynomial equation, from which the maximum Doppler
spread is readily solved by resorting to the Newton's method. Its performance
is demonstrated by simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0453</identifier>
 <datestamp>2008-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0453</id><created>2008-11-04</created><authors><author><keyname>Wagner</keyname><forenames>Cynthia</forenames></author><author><keyname>Schommer</keyname><forenames>Christoph</forenames></author></authors><title>CoZo+ - A Content Zoning Engine for textual documents</title><categories>cs.CL cs.IR</categories><comments>4 pages, 4 figures</comments><acm-class>H.3.3; H.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Content zoning can be understood as a segmentation of textual documents into
zones. This is inspired by [6] who initially proposed an approach for the
argumentative zoning of textual documents. With the prototypical CoZo+ engine,
we focus on content zoning towards an automatic processing of textual streams
while considering only the actors as the zones. We gain information that can be
used to realize an automatic recognition of content for pre-defined actors. We
understand CoZo+ as a necessary pre-step towards an automatic generation of
summaries and to make intellectual ownership of documents detectable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0463</identifier>
 <datestamp>2008-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0463</id><created>2008-11-04</created><updated>2008-11-10</updated><authors><author><keyname>Jaeger</keyname><forenames>Stefan</forenames></author></authors><title>Solving the P/NP Problem under Intrinsic Uncertainty</title><categories>cs.CC</categories><comments>typos corrected, figure added, statements clarified</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Heisenberg's uncertainty principle states that it is not possible to compute
both the position and momentum of an electron with absolute certainty. However,
this computational limitation, which is central to quantum mechanics, has no
counterpart in theoretical computer science. Here, I will show that we can
distinguish between the complexity classes P and NP when we consider intrinsic
uncertainty in our computations, and take uncertainty about whether a bit
belongs to the program code or machine input into account. Given intrinsic
uncertainty, every output is uncertain, and computations become meaningful only
in combination with a confidence level. In particular, it is impossible to
compute solutions with absolute certainty as this requires infinite run-time.
Considering intrinsic uncertainty, I will present a function that is in NP but
not in P, and thus prove that P is a proper subset of NP. I will also show that
all traditional hard decision problems have polynomial-time algorithms that
provide solutions with confidence under uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0475</identifier>
 <datestamp>2008-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0475</id><created>2008-11-04</created><updated>2008-11-08</updated><authors><author><keyname>Ishai</keyname><forenames>Yuval</forenames></author><author><keyname>Prabhakaran</keyname><forenames>Manoj</forenames></author><author><keyname>Sahai</keyname><forenames>Amit</forenames></author></authors><title>Secure Arithmetic Computation with No Honest Majority</title><categories>cs.CR cs.CC</categories><comments>minor editorial changes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of securely evaluating arithmetic circuits over
finite rings. This question is motivated by natural secure computation tasks.
Focusing mainly on the case of two-party protocols with security against
malicious parties, our main goals are to: (1) only make black-box calls to the
ring operations and standard cryptographic primitives, and (2) minimize the
number of such black-box calls as well as the communication overhead.
  We present several solutions which differ in their efficiency, generality,
and underlying intractability assumptions. These include:
  1. An unconditionally secure protocol in the OT-hybrid model which makes a
black-box use of an arbitrary ring $R$, but where the number of ring operations
grows linearly with (an upper bound on) $\log|R|$.
  2. Computationally secure protocols in the OT-hybrid model which make a
black-box use of an underlying ring, and in which the number of ring operations
does not grow with the ring size. These results extend a previous approach of
Naor and Pinkas for secure polynomial evaluation (SIAM J. Comput., 35(5),
2006).
  3. A protocol for the rings $\mathbb{Z}_m=\mathbb{Z}/m\mathbb{Z}$ which only
makes a black-box use of a homomorphic encryption scheme. When $m$ is prime,
the (amortized) number of calls to the encryption scheme for each gate of the
circuit is constant.
  All of our protocols are in fact UC-secure in the OT-hybrid model and can be
generalized to multiparty computation with an arbitrary number of malicious
parties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0537</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0537</id><created>2008-11-04</created><updated>2011-03-03</updated><authors><author><keyname>Alur</keyname><forenames>Rajeev</forenames><affiliation>UPenn</affiliation></author><author><keyname>Arenas</keyname><forenames>Marcelo</forenames><affiliation>PUC, Chile</affiliation></author><author><keyname>Barcelo</keyname><forenames>Pablo</forenames><affiliation>U Chile</affiliation></author><author><keyname>Etessami</keyname><forenames>Kousha</forenames><affiliation>U Edinburgh</affiliation></author><author><keyname>Immerman</keyname><forenames>Neil</forenames><affiliation>UMass</affiliation></author><author><keyname>Libkin</keyname><forenames>Leonid</forenames><affiliation>Edinbugh</affiliation></author></authors><title>First-Order and Temporal Logics for Nested Words</title><categories>cs.LO</categories><comments>revised and corrected version of Mar 03, 2011</comments><proxy>LMCS</proxy><acm-class>F.1.1, F.3.1, F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 4 (November
  25, 2008) lmcs:782</journal-ref><doi>10.2168/LMCS-4(4:11)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nested words are a structured model of execution paths in procedural
programs, reflecting their call and return nesting structure. Finite nested
words also capture the structure of parse trees and other tree-structured data,
such as XML. We provide new temporal logics for finite and infinite nested
words, which are natural extensions of LTL, and prove that these logics are
first-order expressively-complete. One of them is based on adding a &quot;within&quot;
modality, evaluating a formula on a subword, to a logic CaRet previously
studied in the context of verifying properties of recursive state machines
(RSMs). The other logic, NWTL, is based on the notion of a summary path that
uses both the linear and nesting structures. For NWTL we show that
satisfiability is EXPTIME-complete, and that model-checking can be done in time
polynomial in the size of the RSM model and exponential in the size of the NWTL
formula (and is also EXPTIME-complete). Finally, we prove that first-order
logic over nested words has the three-variable property, and we present a
temporal logic for nested words which is complete for the two-variable fragment
of first-order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0543</identifier>
 <datestamp>2008-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0543</id><created>2008-11-04</created><authors><author><keyname>Hucher</keyname><forenames>Charlotte</forenames></author><author><keyname>Othman</keyname><forenames>Ghaya Rekaya-Ben</forenames></author><author><keyname>Saadani</keyname><forenames>Ahmed</forenames></author></authors><title>Incomplete decode-and-forward protocol using distributed space-time
  block codes</title><categories>cs.IT math.IT</categories><comments>21 pages, 12 figures, submitted to Trans. Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we explore the introduction of distributed space-time codes in
decode-and-forward (DF) protocols. A first protocol named the Asymmetric DF is
presented. It is based on two phases of different lengths, defined so that
signals can be fully decoded at relays. This strategy brings full diversity but
the symbol rate is not optimal. To solve this problem a second protocol named
the Incomplete DF is defined. It is based on an incomplete decoding at the
relays reducing the length of the first phase. This last strategy brings both
full diversity and full symbol rate. The outage probability and the simulation
results show that the Incomplete DF has better performance than any existing DF
protocol and than the non-orthogonal amplify-and-forward (NAF) strategy using
the same space-time codes. Moreover the diversity-multiplexing gain tradeoff
(DMT) of this new DF protocol is proven to be the same as the one of the NAF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0573</identifier>
 <datestamp>2008-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0573</id><created>2008-11-04</created><authors><author><keyname>Lagoze</keyname><forenames>Carl</forenames></author><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author><author><keyname>Nelson</keyname><forenames>Michael</forenames></author><author><keyname>Warner</keyname><forenames>Simeon</forenames></author><author><keyname>Sanderson</keyname><forenames>Robert</forenames></author><author><keyname>Johnston</keyname><forenames>Pete</forenames></author></authors><title>A Web-Based Resource Model for eScience: Object Reuse &amp; Exchange</title><categories>cs.DL</categories><comments>2008 Microsoft eScience Workshop, Indianapolis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Work in the Open Archives Initiative - Object Reuse and Exchange (OAI-ORE)
focuses on an important aspect of infrastructure for eScience: the
specification of the data model and a suite of implementation standards to
identify and describe compound objects. These are objects that aggregate
multiple sources of content including text, images, data, visualization tools,
and the like. These aggregations are an essential product of eScience, and will
become increasingly common in the age of data-driven scholarship. The OAI-ORE
specifications conform to the core concepts of the Web architecture and the
semantic Web, ensuring that applications that use them will integrate well into
the general Web environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0579</identifier>
 <datestamp>2008-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0579</id><created>2008-11-04</created><authors><author><keyname>s&#xe9;rasset</keyname><forenames>Gilles</forenames><affiliation>IMAG, Clips - Imag, Lig</affiliation></author><author><keyname>Boitet</keyname><forenames>Christian</forenames><affiliation>IMAG, Clips - Imag, Lig</affiliation></author></authors><title>UNL-French deconversion as transfer &amp; generation from an interlingua
  with possible quality enhancement through offline human interaction</title><categories>cs.CL</categories><proxy>ccsd hal-00336645</proxy><journal-ref>MACHINE TRANSLATION SUMMIT VII, Singapour : Singapour (1999)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the architecture of the UNL-French deconverter, which &quot;generates&quot;
from the UNL interlingua by first&quot;localizing&quot; the UNL form for French, within
UNL, and then applying slightly adapted but classical transfer and generation
techniques, implemented in GETA's Ariane-G5 environment, supplemented by some
UNL-specific tools. Online interaction can be used during deconversion to
enhance output quality and is now used for development purposes. We show how
interaction could be delayed and embedded in the postedition phase, which would
then interact not directly with the output text, but indirectly with several
components of the deconverter. Interacting online or offline can improve the
quality not only of the utterance at hand, but also of the utterances processed
later, as various preferences may be automatically changed to let the
deconverter &quot;learn&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0582</identifier>
 <datestamp>2008-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0582</id><created>2008-11-04</created><authors><author><keyname>Pelcat</keyname><forenames>Maxime</forenames><affiliation>IETR</affiliation></author><author><keyname>Aridhi</keyname><forenames>Slaheddine</forenames><affiliation>IETR</affiliation></author><author><keyname>Nezan</keyname><forenames>Jean Fran&#xe7;ois</forenames><affiliation>IETR</affiliation></author></authors><title>Optimization of automatically generated multi-core code for the LTE
  RACH-PD algorithm</title><categories>cs.MM cs.DC</categories><proxy>ccsd hal-00336477</proxy><journal-ref>DASIP 2008, Bruxelles : Belgique (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Embedded real-time applications in communication systems require high
processing power. Manual scheduling devel-oped for single-processor
applications is not suited to multi-core architectures. The Algorithm
Architecture Matching (AAM) methodology optimizes static application
implementation on multi-core architectures. The Random Access Channel Preamble
Detection (RACH-PD) is an algorithm for non-synchronized access of Long Term
Evolu-tion (LTE) wireless networks. LTE aims to improve the spectral efficiency
of the next generation cellular system. This paper de-scribes a complete
methodology for implementing the RACH-PD. AAM prototyping is applied to the
RACH-PD which is modelled as a Synchronous DataFlow graph (SDF). An efficient
implemen-tation of the algorithm onto a multi-core DSP, the TI C6487, is then
explained. Benchmarks for the solution are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0602</identifier>
 <datestamp>2008-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0602</id><created>2008-11-04</created><authors><author><keyname>Lelu</keyname><forenames>Alain</forenames><affiliation>LASELDI</affiliation></author><author><keyname>Cuxac</keyname><forenames>Pascal</forenames><affiliation>INIST</affiliation></author><author><keyname>Johansson</keyname><forenames>Joel</forenames><affiliation>INIST</affiliation></author></authors><title>Classification dynamique d'un flux documentaire : une \'evaluation
  statique pr\'ealable de l'algorithme GERMEN</title><categories>cs.AI</categories><proxy>ccsd hal-00336419</proxy><journal-ref>JADT 2006 : 8es Journ\'ees internationales d'Analyse statistique
  des Donn\'ees Textuelles, France (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data-stream clustering is an ever-expanding subdomain of knowledge
extraction. Most of the past and present research effort aims at efficient
scaling up for the huge data repositories. Our approach focuses on qualitative
improvement, mainly for &quot;weak signals&quot; detection and precise tracking of
topical evolutions in the framework of information watch - though scalability
is intrinsically guaranteed in a possibly distributed implementation. Our
GERMEN algorithm exhaustively picks up the whole set of density peaks of the
data at time t, by identifying the local perturbations induced by the current
document vector, such as changing cluster borders, or new/vanishing clusters.
Optimality yields from the uniqueness 1) of the density landscape for any value
of our zoom parameter, 2) of the cluster allocation operated by our border
propagation rule. This results in a rigorous independence from the data
presentation ranking or any initialization parameter. We present here as a
first step the only assessment of a static view resulting from one year of the
CNRS/INIST Pascal database in the field of geotechnics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0603</identifier>
 <datestamp>2008-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0603</id><created>2008-11-04</created><authors><author><keyname>Lux-Pogodalla</keyname><forenames>Veronila</forenames><affiliation>INIST</affiliation></author><author><keyname>Juan</keyname><forenames>Eric San</forenames></author></authors><title>Query Refinement by Multi Word Term expansions and semantic synonymy</title><categories>cs.IR</categories><proxy>ccsd hal-00336469</proxy><journal-ref>InSciT2006, medira : Espagne (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We developed a system, TermWatch
(https://stid-bdd.iut.univ-metz.fr/TermWatch/index.pl), which combines a
linguistic extraction of terms, their structuring into a terminological network
with a clustering algorithm. In this paper we explore its ability in
integrating the most promising aspects of the studies on query refinement:
choice of meaningful text units to cluster (domain terms), choice of tight
semantic relations with which to cluster terms, structuring of terms in a
network enabling abetter perception of domain concepts. We have run this
experiment on the 367 645 English abstracts of PASCAL 2005-2006 bibliographic
database (http://www.inist.fr) and compared the structured terminological
resource automatically build by TermWarch to the English segment of TermScience
resource (http://termsciences.inist.fr/) containing 88 211 terms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0623</identifier>
 <datestamp>2008-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0623</id><created>2008-11-04</created><authors><author><keyname>Ratsaby</keyname><forenames>J.</forenames></author><author><keyname>Chaskalovic</keyname><forenames>J.</forenames></author></authors><title>Algorithmic complexity and randomness in elastic solids</title><categories>cs.CC cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A system comprised of an elastic solid and its response to an external random
force sequence is shown to behave based on the principles of the theory of
algorithmic complexity and randomness. The solid distorts the randomness of an
input force sequence in a way proportional to its algorithmic complexity. We
demonstrate this by numerical analysis of a one-dimensional vibrating elastic
solid (the system) on which we apply a maximally random input force. The level
of complexity of the system is controlled via external parameters. The output
response is the field of displacements observed at several positions on the
body. The algorithmic complexity and stochasticity of the resulting output
displacement sequence is measured and compared against the complexity of the
system. The results show that the higher the system complexity the more
random-deficient the output sequence. This agrees with the theory introduced in
[16] which states that physical systems such as this behave as algorithmic
selection-rules which act on random actions in their surroundings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0637</identifier>
 <datestamp>2009-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0637</id><created>2008-11-04</created><updated>2009-03-10</updated><authors><author><keyname>Ahmad</keyname><forenames>Sahand H. A.</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author><author><keyname>Javidi</keyname><forenames>Tara</forenames></author><author><keyname>Zhao</keyname><forenames>Qing</forenames></author><author><keyname>Krishnamachari</keyname><forenames>Bhaskar</forenames></author></authors><title>Optimality of Myopic Sensing in Multi-Channel Opportunistic Access</title><categories>cs.NI cs.IT math.IT</categories><comments>Revised version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider opportunistic communications over multiple channels where the
state (&quot;good&quot; or &quot;bad&quot;) of each channel evolves as independent and identically
distributed Markov processes. A user, with limited sensing and access
capability, chooses one channel to sense and subsequently access (based on the
sensed channel state) in each time slot. A reward is obtained when the user
senses and accesses a &quot;good&quot; channel. The objective is to design the optimal
channel selection policy that maximizes the expected reward accrued over time.
This problem can be generally cast as a Partially Observable Markov Decision
Process (POMDP) or a restless multi-armed bandit process, to which optimal
solutions are often intractable. We show in this paper that the myopic policy,
with a simple and robust structure, achieves optimality under certain
conditions. This result finds applications in opportunistic communications in
fading environment, cognitive radio networks for spectrum overlay, and
resource-constrained jamming and anti-jamming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0699</identifier>
 <datestamp>2008-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0699</id><created>2008-11-05</created><authors><author><keyname>Morizumi</keyname><forenames>Hiroki</forenames></author></authors><title>A Note on the Inversion Complexity of Boolean Functions in Boolean
  Formulas</title><categories>cs.CC cs.DM</categories><comments>5 pages, 1 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we consider the minimum number of NOT operators in a Boolean
formula representing a Boolean function. In circuit complexity theory, the
minimum number of NOT gates in a Boolean circuit computing a Boolean function
$f$ is called the inversion complexity of $f$. In 1958, Markov determined the
inversion complexity of every Boolean function and particularly proved that
$\lceil \log_2(n+1) \rceil$ NOT gates are sufficient to compute any Boolean
function on $n$ variables. As far as we know, no result is known for inversion
complexity in Boolean formulas, i.e., the minimum number of NOT operators in a
Boolean formula representing a Boolean function. The aim of this note is
showing that we can determine the inversion complexity of every Boolean
function in Boolean formulas by arguments based on the study of circuit
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0705</identifier>
 <datestamp>2008-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0705</id><created>2008-11-05</created><authors><author><keyname>Li</keyname><forenames>Lianlin</forenames></author><author><keyname>zhang</keyname><forenames>wenji</forenames></author><author><keyname>Li</keyname><forenames>Fang</forenames></author></authors><title>The Design of Sparse Antenna Array</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of antenna array synthesis is to achieve a desired radiation pattern
with the minimum number of antenna elements. In this paper the antenna
synthesis problem is studied from a totally new perspective. One of the key
principles of compressive sensing is that the signal to be sensed should be
sparse or compressible. This coincides with the requirement of minimum number
of element in the antenna array synthesis problem. In this paper the antenna
element of the array can be efficiently reduced via compressive sensing, which
shows a great improvement to the existing antenna synthesis method. Moreover,
the desired radiation pattern can be achieved in a very computation time which
is even shorter than the existing method. Numerical examples are presented to
show the high efficiency of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0709</identifier>
 <datestamp>2008-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0709</id><created>2008-11-05</created><authors><author><keyname>Broekens</keyname><forenames>Joost</forenames></author></authors><title>MMOGs as Social Experiments: the Case of Environmental Laws</title><categories>cs.CY</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we argue that Massively Multiplayer Online Games (MMOGs), also
known as Large Games are an interesting research tool for policy
experimentation. One of the major problems with lawmaking is that testing the
laws is a difficult enterprise. Here we show that the concept of an MMOG can be
used to experiment with environmental laws on a large scale, provided that the
MMOG is a real game, i.e., it is fun, addictive, presents challenges that last,
etc.. We present a detailed game concept as an initial step.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0717</identifier>
 <datestamp>2008-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0717</id><created>2008-11-05</created><authors><author><keyname>Juan</keyname><forenames>Eric San</forenames><affiliation>INIST</affiliation></author><author><keyname>Roche</keyname><forenames>Ivana</forenames><affiliation>INIST</affiliation></author></authors><title>Visualization of association graphs for assisting the interpretation of
  classifications</title><categories>stat.AP cs.DL cs.IR</categories><comments>International workshop on Webometrics, informetrics and
  scientometrics. Seventh collnet meeting, Nancy : France (2005)</comments><proxy>ccsd hal-00336807</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a query on the PASCAL database maintained by the INIST, we design user
interfaces to visualize and browse two types of graphs extracted from
abstracts: 1) the graph of all associations between authors (co-author graph),
2) the graph of strong associations between authors and terms automatically
extracted from abstracts and grouped using linguistic variations. We adapt for
this purpose the TermWatch system that comprises a term extractor, a relation
identifier which yields the terminological network and a clustering module. The
results are output on two interfaces: a graphic one mapping the clusters in a
2D space and a terminological hypertext network allowing the user to
interactively explore results and return to source texts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0719</identifier>
 <datestamp>2008-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0719</id><created>2008-11-05</created><authors><author><keyname>Polanco</keyname><forenames>Xavier</forenames><affiliation>INIST</affiliation></author><author><keyname>Roche</keyname><forenames>Ivana</forenames><affiliation>INIST</affiliation></author><author><keyname>Besagni</keyname><forenames>Dominique</forenames><affiliation>INIST</affiliation></author></authors><title>Web Usage Analysis: New Science Indicators and Co-usage</title><categories>cs.IR stat.AP</categories><proxy>ccsd hal-00336776</proxy><journal-ref>S\'eminaire VSST 2006, Lille : France (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new type of statistical analysis of the science and technical information
(STI) in the Web context is produced. We propose a set of indicators about Web
users, visualized bibliographic records, and e-commercial transactions. In
addition, we introduce two Web usage factors. Finally, we give an overview of
the co-usage analysis. For these tasks, we introduce a computer based system,
called Miri@d, which produces descriptive statistical information about the Web
users' searching behaviour, and what is effectively used from a free access
digital bibliographical database. The system is conceived as a server of
statistical data which are carried out beforehand, and as an interactive server
for online statistical work. The results will be made available to analysts,
who can use this descriptive statistical information as raw data for their
indicator design tasks, and as input for multivariate data analysis, clustering
analysis, and mapping. Managers also can exploit the results in order to
improve management and decision-making.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0726</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0726</id><created>2008-11-05</created><updated>2010-04-05</updated><authors><author><keyname>Shin</keyname><forenames>Won-Yong</forenames></author><author><keyname>Jeon</keyname><forenames>Sang-Woon</forenames></author><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author><author><keyname>Vu</keyname><forenames>Mai H.</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author><author><keyname>Lee</keyname><forenames>Yong H.</forenames></author><author><keyname>Tarokh</keyname><forenames>Vahid</forenames></author></authors><title>Improved Capacity Scaling in Wireless Networks With Infrastructure</title><categories>cs.IT math.IT</categories><comments>26 pages, 10 figures, 1 table, Under revision for IEEE Transactions
  on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyzes the impact and benefits of infrastructure support in
improving the throughput scaling in networks of $n$ randomly located wireless
nodes. The infrastructure uses multi-antenna base stations (BSs), in which the
number of BSs and the number of antennas at each BS can scale at arbitrary
rates relative to $n$. Under the model, capacity scaling laws are analyzed for
both dense and extended networks. Two BS-based routing schemes are first
introduced in this study: an infrastructure-supported single-hop (ISH) routing
protocol with multiple-access uplink and broadcast downlink and an
infrastructure-supported multi-hop (IMH) routing protocol. Then, their
achievable throughput scalings are analyzed. These schemes are compared against
two conventional schemes without BSs: the multi-hop (MH) transmission and
hierarchical cooperation (HC) schemes. It is shown that a linear throughput
scaling is achieved in dense networks, as in the case without help of BSs. In
contrast, the proposed BS-based routing schemes can, under realistic network
conditions, improve the throughput scaling significantly in extended networks.
The gain comes from the following advantages of these BS-based protocols.
First, more nodes can transmit simultaneously in the proposed scheme than in
the MH scheme if the number of BSs and the number of antennas are large enough.
Second, by improving the long-distance signal-to-noise ratio (SNR), the
received signal power can be larger than that of the HC, enabling a better
throughput scaling under extended networks. Furthermore, by deriving the
corresponding information-theoretic cut-set upper bounds, it is shown under
extended networks that a combination of four schemes IMH, ISH, MH, and HC is
order-optimal in all operating regimes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0731</identifier>
 <datestamp>2008-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0731</id><created>2008-11-05</created><updated>2008-11-25</updated><authors><author><keyname>Couillet</keyname><forenames>Romain</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Cognitive OFDM network sensing: a free probability approach</title><categories>cs.IT cs.AI math.IT math.PR</categories><comments>12 pages, 10 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a practical power detection scheme for OFDM terminals, based
on recent free probability tools, is proposed. The objective is for the
receiving terminal to determine the transmission power and the number of the
surrounding base stations in the network. However, thesystem dimensions of the
network model turn energy detection into an under-determined problem. The focus
of this paper is then twofold: (i) discuss the maximum amount of information
that an OFDM terminal can gather from the surrounding base stations in the
network, (ii) propose a practical solution for blind cell detection using the
free deconvolution tool. The efficiency of this solution is measured through
simulations, which show better performance than the classical power detection
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0741</identifier>
 <datestamp>2008-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0741</id><created>2008-11-05</created><authors><author><keyname>Mahboubi</keyname><forenames>Hadj</forenames><affiliation>ERIC</affiliation></author><author><keyname>Darmont</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>ERIC</affiliation></author></authors><title>Data Mining-based Fragmentation of XML Data Warehouses</title><categories>cs.DB</categories><proxy>ccsd hal-00336980</proxy><acm-class>H.2</acm-class><journal-ref>ACM 11th International Workshop on Data Warehousing and OLAP
  (CIKM/DOLAP 08), Napa Valley : \'Etats-Unis d'Am\'erique (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the multiplication of XML data sources, many XML data warehouse models
have been proposed to handle data heterogeneity and complexity in a way
relational data warehouses fail to achieve. However, XML-native database
systems currently suffer from limited performances, both in terms of manageable
data volume and response time. Fragmentation helps address both these issues.
Derived horizontal fragmentation is typically used in relational data
warehouses and can definitely be adapted to the XML context. However, the
number of fragments produced by classical algorithms is difficult to control.
In this paper, we propose the use of a k-means-based fragmentation approach
that allows to master the number of fragments through its $k$ parameter. We
experimentally compare its efficiency to classical derived horizontal
fragmentation algorithms adapted to XML data warehouses and show its
superiority.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0764</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0764</id><created>2008-11-05</created><updated>2009-09-08</updated><authors><author><keyname>Couillet</keyname><forenames>Romain</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>A Bayesian Framework for Collaborative Multi-Source Signal Detection</title><categories>cs.IT cs.AI math.IT math.PR</categories><comments>15 pages, 9 pictures, Submitted to IEEE Trans. on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a Bayesian framework to detect multiple signals
embedded in noisy observations from a sensor array. For various states of
knowledge on the communication channel and the noise at the receiving sensors,
a marginalization procedure based on recent tools of finite random matrix
theory, in conjunction with the maximum entropy principle, is used to compute
the hypothesis selection criterion. Quite remarkably, explicit expressions for
the Bayesian detector are derived which enable to decide on the presence of
signal sources in a noisy wireless environment. The proposed Bayesian detector
is shown to outperform the classical power detector when the noise power is
known and provides very good performance for limited knowledge on the noise
power. Simulations corroborate the theoretical results and quantify the gain
achieved using the proposed Bayesian framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0777</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0777</id><created>2008-11-05</created><updated>2009-01-10</updated><authors><author><keyname>Zia</keyname><forenames>Amin</forenames></author></authors><title>A random coding theorem for &quot;modulo-two adder&quot; source network</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author, due a crucial error in the proof
of the main Theorem (Sec. 3). In particular, in deriving the bound on the
probability of error (Eq. 10) the contribution of those pairs (x', y') that are
not equal to (x, y) has not been considered. By adding the contribution of
these pairs, one can verify that a region of rates similar to the Slepian-Wolf
region will emerge.
  The author would like to acknowledge a critical review of the paper by Mr.
Paul Cuff of Stanford University who first pointed out the error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0778</identifier>
 <datestamp>2008-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0778</id><created>2008-11-05</created><authors><author><keyname>Couillet</keyname><forenames>Romain</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>A maximum entropy approach to OFDM channel estimation</title><categories>cs.IT math.IT math.PR</categories><comments>15 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, a new Bayesian framework for OFDM channel estimation is
proposed. Using Jaynes' maximum entropy principle to derive prior information,
we successively tackle the situations when only the channel delay spread is a
priori known, then when it is not known. Exploitation of the time-frequency
dimensions are also considered in this framework, to derive the optimal channel
estimation associated to some performance measure under any state of knowledge.
Simulations corroborate the optimality claim and always prove as good or better
in performance than classical estimators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0811</identifier>
 <datestamp>2008-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0811</id><created>2008-11-05</created><authors><author><keyname>Blass</keyname><forenames>Andreas</forenames><affiliation>University of Michigan</affiliation></author><author><keyname>Dershowitz</keyname><forenames>Nachum</forenames><affiliation>Tel Aviv University</affiliation></author><author><keyname>Gurevich</keyname><forenames>Yuri</forenames><affiliation>Microsoft Research</affiliation></author></authors><title>When are two algorithms the same?</title><categories>cs.GL cs.DS cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  People usually regard algorithms as more abstract than the programs that
implement them. The natural way to formalize this idea is that algorithms are
equivalence classes of programs with respect to a suitable equivalence
relation. We argue that no such equivalence relation exists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0819</identifier>
 <datestamp>2008-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0819</id><created>2008-11-05</created><authors><author><keyname>Blass</keyname><forenames>Andreas</forenames><affiliation>University of Michigan</affiliation></author><author><keyname>Gurevich</keyname><forenames>Yuri</forenames><affiliation>Microsoft Research</affiliation></author></authors><title>Persistent Queries</title><categories>cs.PL cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a syntax and semantics for interactive abstract state machines to
deal with the following situation. A query is issued during a certain step, but
the step ends before any reply is received. Later, a reply arrives, and later
yet the algorithm makes use of this reply. By a persistent query, we mean a
query for which a late reply might be used. Syntactically, our proposal
involves issuing, along with a persistent query, a location where a late reply
is to be stored. Semantically, it involves only a minor modification of the
existing theory of interactive small-step abstract state machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0823</identifier>
 <datestamp>2008-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0823</id><created>2008-11-05</created><authors><author><keyname>Macready</keyname><forenames>William</forenames></author><author><keyname>Wolpert</keyname><forenames>David</forenames></author></authors><title>Distributed Constrained Optimization with Semicoordinate Transformations</title><categories>cs.NE cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work has shown how information theory extends conventional
full-rationality game theory to allow bounded rational agents. The associated
mathematical framework can be used to solve constrained optimization problems.
This is done by translating the problem into an iterated game, where each agent
controls a different variable of the problem, so that the joint probability
distribution across the agents' moves gives an expected value of the objective
function. The dynamics of the agents is designed to minimize a Lagrangian
function of that joint distribution. Here we illustrate how the updating of the
Lagrange parameters in the Lagrangian is a form of automated annealing, which
focuses the joint distribution more and more tightly about the joint moves that
optimize the objective function. We then investigate the use of
``semicoordinate'' variable transformations. These separate the joint state of
the agents from the variables of the optimization problem, with the two
connected by an onto mapping. We present experiments illustrating the ability
of such transformations to facilitate optimization. We focus on the special
kind of transformation in which the statistically independent states of the
agents induces a mixture distribution over the optimization variables. Computer
experiment illustrate this for $k$-sat constraint satisfaction problems and for
unconstrained minimization of $NK$ functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0851</identifier>
 <datestamp>2008-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0851</id><created>2008-11-06</created><authors><author><keyname>Beasley</keyname><forenames>John D.</forenames></author></authors><title>Solitaire: Recent Developments</title><categories>math.CO cs.DM</categories><comments>11 pages, 7 figures; The Games and Puzzles Journal, Issue 28,
  September 2003, http://gpj.connectfree.co.uk/gpjj.htm</comments><msc-class>00A08; 97A20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This special issue on Peg Solitaire has been put together by John Beasley as
guest editor, and reports work by John Harris, Alain Maye, Jean-Charles
Meyrignac, George Bell, and others. Topics include: short solutions on the 6 x
6 board and the 37-hole &quot;French&quot; board, solving generalized cross boards and
long-arm boards. Five new problems are given for readers to solve, with
solutions provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0881</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0881</id><created>2008-11-06</created><authors><author><keyname>Das</keyname><forenames>Arnab</forenames></author></authors><title>Non-classical Role of Potential Energy in Adiabatic Quantum Annealing</title><categories>quant-ph cond-mat.stat-mech cs.CC physics.comp-ph</categories><comments>10 pages, 2 figures (for the Proceedings of the International
  Workshop on Statis tical-Mechanical Informatics 2008, Sendai, Japan). Journal
  of Physics: Conference Series (to be publised)</comments><journal-ref>J. Phys.: Conf. Ser. vol. 143 012001 (2009)</journal-ref><doi>10.1088/1742-6596/143/1/012001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adiabatic quantum annealing is a paradigm of analog quantum computation,
where a given computational job is converted to the task of finding the global
minimum of some classical potential energy function and the search for the
global potential minimum is performed by employing external kinetic quantum
fluctuations and subsequent slow reduction (annealing) of them. In this method,
the entire potential energy landscape (PEL) may be accessed simultaneously
through a delocalized wave-function, in contrast to a classical search, where
the searcher has to visit different points in the landscape (i.e., individual
classical configurations) sequentially. Thus in such searches, the role of the
potential energy might be significantly different in the two cases. Here we
discuss this in the context of searching of a single isolated hole (potential
minimum) in a golf-course type gradient free PEL. We show, that the quantum
particle would be able to locate the hole faster if the hole is deeper, while
the classical particle of course would have no scope to exploit the depth of
the hole. We also discuss the effect of the underlying quantum phase transition
on the adiabatic dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0935</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0935</id><created>2008-11-06</created><updated>2011-01-14</updated><authors><author><keyname>Yetis</keyname><forenames>Cenk M.</forenames></author><author><keyname>Kayran</keyname><forenames>Ahmet H.</forenames></author></authors><title>A New Training Protocol for Channel State Estimation in Wireless Relay
  Networks</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author due to technical flaws in
  SISO section</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The accuracy of channel state information (CSI) is critical for improving the
capacity of wireless networks. In this paper, we introduce a training protocol
for wireless relay networks that uses channel estimation and feedforwarding
methods. The feedforwarding method is the distinctive feature of the proposed
protocol. As we show, each relay feedforwards the imperfect CSI to the
destination in a way that provides a higher network capacity and a faster
transfer of the CSI than the existing protocols. In addition, we show the
importance of the effective CSI accuracy on the wireless relay network capacity
by comparing networks with the perfect effective CSI, imperfect effective CSI,
and noisy imperfect effective CSI available at the destination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0942</identifier>
 <datestamp>2008-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0942</id><created>2008-11-06</created><authors><author><keyname>Ber</keyname><forenames>Florence Le</forenames><affiliation>INRIA Lorraine - Loria, Cevh</affiliation></author><author><keyname>Brassac</keyname><forenames>Christian</forenames><affiliation>LABPSYLOR, L2P</affiliation></author></authors><title>\'Etude longitudinale d'une proc\'edure de mod\'elisation de
  connaissances en mati\`ere de gestion du territoire agricole</title><categories>cs.AI</categories><proxy>ccsd hal-00337132</proxy><journal-ref>Revue d'Anthropologie des Connaissances 2, 2 (2008) 151-168</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper gives an introduction to this issue, and presents the framework
and the main steps of the Rosa project. Four teams of researchers, agronomists,
computer scientists, psychologists and linguists were involved during five
years within this project that aimed at the development of a knowledge based
system. The purpose of the Rosa system is the modelling and the comparison of
farm spatial organizations. It relies on a formalization of agronomical
knowledge and thus induces a joint knowledge building process involving both
the agronomists and the computer scientists. The paper describes the steps of
the modelling process as well as the filming procedures set up by the
psychologists and linguists in order to make explicit and to analyze the
underlying knowledge building process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0952</identifier>
 <datestamp>2008-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0952</id><created>2008-11-06</created><authors><author><keyname>Malinen</keyname><forenames>Mikko</forenames></author></authors><title>Raptor Codes and Cryptographic Issues</title><categories>cs.IT math.IT</categories><comments>2 pages. Submitted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper two cryptographic methods are introduced. In the first method
the presence of a certain size subgroup of persons can be checked for an action
to take place. For this we use fragments of Raptor codes delivered to the group
members. In the other method a selection of a subset of objects can be made
secret. Also, it can be proven afterwards, what the original selection was.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0959</identifier>
 <datestamp>2010-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0959</id><created>2008-11-06</created><updated>2009-08-12</updated><authors><author><keyname>Beyersdorff</keyname><forenames>Olaf</forenames></author><author><keyname>Meier</keyname><forenames>Arne</forenames></author><author><keyname>Thomas</keyname><forenames>Michael</forenames></author><author><keyname>Vollmer</keyname><forenames>Heribert</forenames></author></authors><title>The Complexity of Propositional Implication</title><categories>cs.CC cs.LO</categories><doi>10.1016/j.ipl.2009.06.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The question whether a set of formulae G implies a formula f is fundamental.
The present paper studies the complexity of the above implication problem for
propositional formulae that are built from a systematically restricted set of
Boolean connectives. We give a complete complexity classification for all sets
of Boolean functions in the meaning of Post's lattice and show that the
implication problem is efficentily solvable only if the connectives are
definable using the constants {false,true} and only one of {and,or,xor}. The
problem remains coNP-complete in all other cases. We also consider the
restriction of G to singletons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0964</identifier>
 <datestamp>2008-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0964</id><created>2008-11-06</created><authors><author><keyname>Blass</keyname><forenames>Andreas</forenames><affiliation>University of Michigan</affiliation></author><author><keyname>Gurevich</keyname><forenames>Yuri</forenames><affiliation>Microsoft Research</affiliation></author></authors><title>One useful logic that defines its own truth</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existential fixed point logic (EFPL) is a natural fit for some applications,
and the purpose of this talk is to attract attention to EFPL. The logic is also
interesting in its own right as it has attractive properties. One of those
properties is rather unusual: truth of formulas can be defined (given
appropriate syntactic apparatus) in the logic. We mentioned that property
elsewhere, and we use this opportunity to provide the proof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0971</identifier>
 <datestamp>2008-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0971</id><created>2008-11-06</created><authors><author><keyname>Bertaux</keyname><forenames>Aur&#xe9;lie</forenames><affiliation>CEVH, Lsiit</affiliation></author><author><keyname>Braud</keyname><forenames>AGN&#xe8;s</forenames><affiliation>LSIIT</affiliation></author><author><keyname>Ber</keyname><forenames>Florence Le</forenames><affiliation>CEVH, Inria Lorraine - Loria</affiliation></author></authors><title>Mining Complex Hydrobiological Data with Galois Lattices</title><categories>cs.AI q-bio.QM</categories><proxy>ccsd hal-00177936</proxy><journal-ref>International Workshop on Advances in Conceptual Knowledge
  Engineering (ACKE'07), Regensburg : Allemagne (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have used Galois lattices for mining hydrobiological data. These data are
about macrophytes, that are macroscopic plants living in water bodies. These
plants are characterized by several biological traits, that own several
modalities. Our aim is to cluster the plants according to their common traits
and modalities and to find out the relations between traits. Galois lattices
are efficient methods for such an aim, but apply on binary data. In this
article, we detail a few approaches we used to transform complex
hydrobiological data into binary data and compare the first results obtained
thanks to Galois lattices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0977</identifier>
 <datestamp>2008-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0977</id><created>2008-11-06</created><authors><author><keyname>Blass</keyname><forenames>Andreas</forenames><affiliation>University of Michigan</affiliation></author><author><keyname>Gurevich</keyname><forenames>Yuri</forenames><affiliation>Microsoft Research</affiliation></author></authors><title>Two Forms of One Useful Logic: Existential Fixed Point Logic and Liberal
  Datalog</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A natural liberalization of Datalog is used in the Distributed Knowledge
Authorization Language (DKAL). We show that the expressive power of this
liberal Datalog is that of existential fixed-point logic. The exposition is
self-contained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0980</identifier>
 <datestamp>2008-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0980</id><created>2008-11-06</created><authors><author><keyname>Rohlf</keyname><forenames>Thimo</forenames></author><author><keyname>Bornholdt</keyname><forenames>Stefan</forenames></author></authors><title>Self-organized criticality and adaptation in discrete dynamical networks</title><categories>nlin.AO cond-mat.dis-nn cs.NE</categories><comments>35 pages, 19 figures. Review article to appear in: &quot;Adaptive Networks
  - Theory, Models and Applications&quot;, eds. T. Gross and H. Sayama, Springer
  2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been proposed that adaptation in complex systems is optimized at the
critical boundary between ordered and disordered dynamical regimes. Here, we
review models of evolving dynamical networks that lead to self-organization of
network topology based on a local coupling between a dynamical order parameter
and rewiring of network connectivity, with convergence towards criticality in
the limit of large network size $N$. In particular, two adaptive schemes are
discussed and compared in the context of Boolean Networks and Threshold
Networks: 1) Active nodes loose links, frozen nodes aquire new links, 2) Nodes
with correlated activity connect, de-correlated nodes disconnect. These simple
local adaptive rules lead to co-evolution of network topology and -dynamics.
Adaptive networks are strikingly different from random networks: They evolve
inhomogeneous topologies and broad plateaus of homeostatic regulation,
dynamical activity exhibits $1/f$ noise and attractor periods obey a scale-free
distribution. The proposed co-evolutionary mechanism of topological
self-organization is robust against noise and does not depend on the details of
dynamical transition rules. Using finite-size scaling, it is shown that
networks converge to a self-organized critical state in the thermodynamic
limit. Finally, we discuss open questions and directions for future research,
and outline possible applications of these models to adaptive systems in
diverse areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0987</identifier>
 <datestamp>2008-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0987</id><created>2008-11-06</created><authors><author><keyname>Bj&#xf8;rner</keyname><forenames>Nikolaj</forenames></author><author><keyname>Blass</keyname><forenames>Andreas</forenames></author><author><keyname>Gurevich</keyname><forenames>Yuri</forenames></author><author><keyname>Musuvathi</keyname><forenames>Madan</forenames></author></authors><title>Modular difference logic is hard</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In connection with machine arithmetic, we are interested in systems of
constraints of the form x + k \leq y + k'. Over integers, the satisfiability
problem for such systems is polynomial time. The problem becomes NP complete if
we restrict attention to the residues for a fixed modulus N.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1000</identifier>
 <datestamp>2008-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1000</id><created>2008-11-06</created><authors><author><keyname>Ouertani</keyname><forenames>Rym</forenames></author><author><keyname>Ben-Othman</keyname><forenames>Ghaya Rekaya</forenames></author><author><keyname>Salah</keyname><forenames>Abdellatif</forenames></author></authors><title>Hard and Soft Spherical-Bound Stack decoder for MIMO systems</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Classical ML decoders of MIMO systems like the sphere decoder, the
Schnorr-Euchner algorithm, the Fano and the stack decoders suffer of high
complexity for high number of antennas and large constellation sizes. We
propose in this paper a novel sequential algorithm which combines the stack
algorithm search strategy and the sphere decoder search region. The proposed
decoder that we call the Spherical-Bound-Stack decoder (SB-Stack) can then be
used to resolve lattice and large size constellations decoding with a reduced
complexity compared to the classical ML decoders.
  The SB-Stack decoder will be further extended to support soft-output
detection over linear channels. It will be shown that the soft SB-Stack decoder
outperforms other MIMO soft decoders in term of performance and complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1061</identifier>
 <datestamp>2008-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1061</id><created>2008-11-06</created><updated>2008-11-27</updated><authors><author><keyname>Jolly</keyname><forenames>Raphael</forenames></author><author><keyname>Kredel</keyname><forenames>Heinz</forenames></author></authors><title>How to turn a scripting language into a domain specific language for
  computer algebra</title><categories>cs.SC</categories><acm-class>G.4; I.1; D.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have developed two computer algebra systems, meditor [Jolly:2007] and JAS
[Kredel:2006]. These CAS systems are available as Java libraries. For the
use-case of interactively entering and manipulating mathematical expressions,
there is a need of a scripting front-end for our libraries. Most other CAS
invent and implement their own scripting interface for this purpose. We,
however, do not want to reinvent the wheel and propose to use a contemporary
scripting language with access to Java code. In this paper we discuss the
requirements for a scripting language in computer algebra and check whether the
languages Python, Ruby, Groovy and Scala meet these requirements. We conclude
that, with minor problems, any of these languages is suitable for our purpose.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1067</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1067</id><created>2008-11-06</created><updated>2009-08-10</updated><authors><author><keyname>Jiang</keyname><forenames>Xiaoye</forenames></author><author><keyname>Lim</keyname><forenames>Lek-Heng</forenames></author><author><keyname>Yao</keyname><forenames>Yuan</forenames></author><author><keyname>Ye</keyname><forenames>Yinyu</forenames></author></authors><title>Statistical ranking and combinatorial Hodge theory</title><categories>stat.ML cs.DM</categories><comments>42 pages; minor changes throughout; numerical experiments added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a number of techniques for obtaining a global ranking from data
that may be incomplete and imbalanced -- characteristics almost universal to
modern datasets coming from e-commerce and internet applications. We are
primarily interested in score or rating-based cardinal data. From raw ranking
data, we construct pairwise rankings, represented as edge flows on an
appropriate graph. Our statistical ranking method uses the graph Helmholtzian,
the graph theoretic analogue of the Helmholtz operator or vector Laplacian, in
much the same way the graph Laplacian is an analogue of the Laplace operator or
scalar Laplacian. We study the graph Helmholtzian using combinatorial Hodge
theory: we show that every edge flow representing pairwise ranking can be
resolved into two orthogonal components, a gradient flow that represents the
L2-optimal global ranking and a divergence-free flow (cyclic) that measures the
validity of the global ranking obtained -- if this is large, then the data does
not have a meaningful global ranking. This divergence-free flow can be further
decomposed orthogonally into a curl flow (locally cyclic) and a harmonic flow
(locally acyclic but globally cyclic); these provides information on whether
inconsistency arises locally or globally. An obvious advantage over the NP-hard
Kemeny optimization is that discrete Hodge decomposition may be computed via a
linear least squares regression. We also investigated the L1-projection of edge
flows, showing that this is dual to correlation maximization over bounded
divergence-free flows, and the L1-approximate sparse cyclic ranking, showing
that this is dual to correlation maximization over bounded curl-free flows. We
discuss relations with Kemeny optimization, Borda count, and Kendall-Smith
consistency index from social choice theory and statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1075</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1075</id><created>2008-11-07</created><updated>2008-12-05</updated><authors><author><keyname>Buss</keyname><forenames>Samuel R.</forenames></author><author><keyname>Hoffmann</keyname><forenames>Jan</forenames></author><author><keyname>Johannsen</keyname><forenames>Jan</forenames></author></authors><title>Resolution Trees with Lemmas: Resolution Refinements that Characterize
  DLL Algorithms with Clause Learning</title><categories>cs.LO cs.CC</categories><acm-class>F.2.2; I.2.8</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 4 (December
  5, 2008) lmcs:860</journal-ref><doi>10.2168/LMCS-4(4:13)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Resolution refinements called w-resolution trees with lemmas (WRTL) and with
input lemmas (WRTI) are introduced. Dag-like resolution is equivalent to both
WRTL and WRTI when there is no regularity condition. For regular proofs, an
exponential separation between regular dag-like resolution and both regular
WRTL and regular WRTI is given.
  It is proved that DLL proof search algorithms that use clause learning based
on unit propagation can be polynomially simulated by regular WRTI. More
generally, non-greedy DLL algorithms with learning by unit propagation are
equivalent to regular WRTI. A general form of clause learning, called
DLL-Learn, is defined that is equivalent to regular WRTL.
  A variable extension method is used to give simulations of resolution by
regular WRTI, using a simplified form of proof trace extensions. DLL-Learn and
non-greedy DLL algorithms with learning by unit propagation can use variable
extensions to simulate general resolution without doing restarts.
  Finally, an exponential lower bound for WRTL where the lemmas are restricted
to short clauses is shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1081</identifier>
 <datestamp>2008-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1081</id><created>2008-11-06</created><authors><author><keyname>Andrecut</keyname><forenames>M.</forenames></author></authors><title>Parallel GPU Implementation of Iterative PCA Algorithms</title><categories>q-bio.QM cs.MS physics.comp-ph</categories><comments>45 pages, 1 figure, source code included</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Principal component analysis (PCA) is a key statistical technique for
multivariate data analysis. For large data sets the common approach to PCA
computation is based on the standard NIPALS-PCA algorithm, which unfortunately
suffers from loss of orthogonality, and therefore its applicability is usually
limited to the estimation of the first few components. Here we present an
algorithm based on Gram-Schmidt orthogonalization (called GS-PCA), which
eliminates this shortcoming of NIPALS-PCA. Also, we discuss the GPU (Graphics
Processing Unit) parallel implementation of both NIPALS-PCA and GS-PCA
algorithms. The numerical results show that the GPU parallel optimized
versions, based on CUBLAS (NVIDIA) are substantially faster (up to 12 times)
than the CPU optimized versions based on CBLAS (GNU Scientific Library).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1083</identifier>
 <datestamp>2008-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1083</id><created>2008-11-07</created><authors><author><keyname>Fletcher</keyname><forenames>George H. L.</forenames></author><author><keyname>Beck</keyname><forenames>Peter W.</forenames></author></authors><title>A role-free approach to indexing large RDF data sets in secondary memory
  for efficient SPARQL evaluation</title><categories>cs.DB cs.DS</categories><comments>12 pages, 5 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive RDF data sets are becoming commonplace. RDF data is typically
generated in social semantic domains (such as personal information management)
wherein a fixed schema is often not available a priori. We propose a simple
Three-way Triple Tree (TripleT) secondary-memory indexing technique to
facilitate efficient SPARQL query evaluation on such data sets. The novelty of
TripleT is that (1) the index is built over the atoms occurring in the data
set, rather than at a coarser granularity, such as whole triples occurring in
the data set; and (2) the atoms are indexed regardless of the roles (i.e.,
subjects, predicates, or objects) they play in the triples of the data set. We
show through extensive empirical evaluation that TripleT exhibits multiple
orders of magnitude improvement over the state of the art on RDF indexing, in
terms of both storage and query processing costs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1095</identifier>
 <datestamp>2009-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1095</id><created>2008-11-07</created><updated>2009-03-21</updated><authors><author><keyname>Slimane</keyname><forenames>Jamila Ben</forenames><affiliation>INRIA Lorraine - Loria, Mediatron</affiliation></author><author><keyname>Song</keyname><forenames>Ye-Qiong</forenames><affiliation>INRIA Lorraine - Loria, Loria</affiliation></author><author><keyname>Koub&#xe2;a</keyname><forenames>Anis</forenames><affiliation>IPP-Hurray! Research Group</affiliation></author><author><keyname>Frikha</keyname><forenames>Mounir</forenames><affiliation>MEDIATRON</affiliation></author></authors><title>Allocation of control and data channels for Large-Scale Wireless Sensor
  Networks</title><categories>cs.NI</categories><proxy>ccsd inria-00322584</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Both IEEE 802.15.4 and 802.15.4a standards allow for dynamic channel
allocation and use of multiple channels available at their physical layers but
its MAC protocols are designed only for single channel. Also, sensor's
transceivers such as CC2420 provide multiple channels and as shown in [1], [2]
and [3] channel switch latency of CC2420 transceiver is just about 200$\mu$s.
In order to enhance both energy efficiency and to shorten end to end delay, we
propose, in this report, a spectrum-efficient frequency allocation schemes that
are able to statically assign control channels and dynamically reuse data
channels for Personal Area Networks (PANs) inside a Large-Scale WSN based on
UWB technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1103</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1103</id><created>2008-11-07</created><updated>2008-12-05</updated><authors><author><keyname>Hague</keyname><forenames>Matthew</forenames></author><author><keyname>Ong</keyname><forenames>C. -H. Luke</forenames></author></authors><title>Symbolic Backwards-Reachability Analysis for Higher-Order Pushdown
  Systems</title><categories>cs.CC cs.GT</categories><acm-class>F.1.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 4 (December
  5, 2008) lmcs:831</journal-ref><doi>10.2168/LMCS-4(4:14)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Higher-order pushdown systems (PDSs) generalise pushdown systems through the
use of higher-order stacks, that is, a nested &quot;stack of stacks&quot; structure.
These systems may be used to model higher-order programs and are closely
related to the Caucal hierarchy of infinite graphs and safe higher-order
recursion schemes.
  We consider the backwards-reachability problem over higher-order Alternating
PDSs (APDSs), a generalisation of higher-order PDSs. This builds on and extends
previous work on pushdown systems and context-free higher-order processes in a
non-trivial manner. In particular, we show that the set of configurations from
which a regular set of higher-order APDS configurations is reachable is regular
and computable in n-EXPTIME. In fact, the problem is n-EXPTIME-complete.
  We show that this work has several applications in the verification of
higher-order PDSs, such as linear-time model-checking, alternation-free
mu-calculus model-checking and the computation of winning regions of
reachability games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1108</identifier>
 <datestamp>2009-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1108</id><created>2008-11-07</created><updated>2009-08-28</updated><authors><author><keyname>Ksairi</keyname><forenames>Nassar</forenames></author><author><keyname>Bianchi</keyname><forenames>Pascal</forenames></author><author><keyname>Ciblat</keyname><forenames>Philippe</forenames></author><author><keyname>Hachem</keyname><forenames>Walid</forenames></author></authors><title>Resource Allocation for Downlink Cellular OFDMA Systems: Part I -
  Optimal Allocation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this pair of papers (Part I and Part II in this issue), we investigate the
issue of power control and subcarrier assignment in a sectorized two-cell
downlink OFDMA system impaired by multicell interference. As recommended for
WiMAX, we assume that the first part of the available bandwidth is likely to be
reused by different base stations (and is thus subject to multicell
interference) and that the second part of the bandwidth is shared in an
orthogonal way between the different base stations (and is thus protected from
multicell interference).
  Although the problem of multicell resource allocation is nonconvex in this
scenario, we provide in Part I the general form of the global solution. In
particular, the optimal resource allocation turns out to be &quot;binary&quot; in the
sense that, except for at most one pivot-user in each cell, any user receives
data either in the reused bandwidth or in the protected bandwidth, but not in
both. The determination of the optimal resource allocation essentially reduces
to the determination of the latter pivot-position.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1112</identifier>
 <datestamp>2009-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1112</id><created>2008-11-07</created><updated>2009-08-28</updated><authors><author><keyname>Ksairi</keyname><forenames>Nassar</forenames></author><author><keyname>Bianchi</keyname><forenames>Pascal</forenames></author><author><keyname>ciblat</keyname><forenames>Phiippe</forenames></author><author><keyname>Hachem</keyname><forenames>Walid</forenames></author></authors><title>Resource Allocation for Downlink Cellular OFDMA Systems: Part II -
  Practical Algorithms and Optimal Reuse Factor</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a companion paper, we characterized the optimal resource allocation in
terms of power control and subcarrier assignment, for a downlink sectorized
OFDMA system. In our model, the network is assumed to be one dimensional for
the sake of analysis. We also assume that a certain part of the available
bandwidth is likely to be reused by different base stations while that the
other part of the bandwidth is shared in an orthogonal way between these base
stations. The optimal resource allocation characterized in Part I is obtained
by minimizing the total power spent by the network under the constraint that
all users rate requirements are satisfied. When optimal resource allocation is
used, any user receives data either in the reused bandwidth or in the protected
bandwidth, but not in both (except for at most one pivot-user in each cell). We
also proposed an algorithm that determines the optimal values of users resource
allocation parameters. The optimal allocation algorithm proposed in Part I
requires a large number of operations. In the present paper, we propose a
distributed practical resource allocation algorithm with low complexity. We
study the asymptotic behavior of both this simplified resource allocation
algorithm and the optimal resource allocation algorithm of Part I as the number
of users in each cell tends to infinity. Our analysis allows to prove that the
proposed simplified algorithm is asymptotically optimal. As a byproduct of our
analysis, we characterize the optimal value of the frequency reuse factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1151</identifier>
 <datestamp>2009-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1151</id><created>2008-11-07</created><authors><author><keyname>Delahaye</keyname><forenames>Beno&#xee;t</forenames><affiliation>IRISA</affiliation></author><author><keyname>Caillaud</keyname><forenames>Beno&#xee;t</forenames><affiliation>IRISA, Irisa, Irisa</affiliation></author></authors><title>A Model for Probabilistic Reasoning on Assume/Guarantee Contracts</title><categories>cs.PF</categories><proxy>ccsd inria-00337538</proxy><report-no>RR-6719</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a probabilistic adaptation of an Assume/Guarantee
contract formalism. For the sake of generality, we assume that the extended
state machines used in the contracts and implementations define sets of runs on
a given set of variables, that compose by intersection over the common
variables. In order to enable probabilistic reasoning, we consider that the
contracts dictate how certain input variables will behave, being either
non-deterministic, or probabilistic; the introduction of probabilistic
variables leading us to tune the notions of implementation, refinement and
composition. As shown in the report, this probabilistic adaptation of the
Assume/Guarantee contract theory preserves compositionality and therefore
allows modular reliability analysis, either with a top-down or a bottom-up
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1250</identifier>
 <datestamp>2008-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1250</id><created>2008-11-08</created><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author></authors><title>Adaptive Base Class Boost for Multi-class Classification</title><categories>cs.LG cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop the concept of ABC-Boost (Adaptive Base Class Boost) for
multi-class classification and present ABC-MART, a concrete implementation of
ABC-Boost. The original MART (Multiple Additive Regression Trees) algorithm has
been very successful in large-scale applications. For binary classification,
ABC-MART recovers MART. For multi-class classification, ABC-MART considerably
improves MART, as evaluated on several public data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1254</identifier>
 <datestamp>2008-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1254</id><created>2008-11-08</created><authors><author><keyname>Huber</keyname><forenames>Michael</forenames></author></authors><title>Coding Theory and Algebraic Combinatorics</title><categories>math.CO cs.IT math.IT</categories><comments>33 pages; handbook chapter, to appear in: &quot;Selected Topics in
  Information and Coding Theory&quot;, ed. by I. Woungang et al., World Scientific,
  Singapore, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This chapter introduces and elaborates on the fruitful interplay of coding
theory and algebraic combinatorics, with most of the focus on the interaction
of codes with combinatorial designs, finite geometries, simple groups, sphere
packings, kissing numbers, lattices, and association schemes. In particular,
special interest is devoted to the relationship between codes and combinatorial
designs. We describe and recapitulate important results in the development of
the state of the art. In addition, we give illustrative examples and
constructions, and highlight recent advances. Finally, we provide a collection
of significant open problems and challenges concerning future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1260</identifier>
 <datestamp>2008-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1260</id><created>2008-11-08</created><authors><author><keyname>Bisht</keyname><forenames>Raj Kishor</forenames></author><author><keyname>Dhami</keyname><forenames>H. S.</forenames></author></authors><title>The Application of Fuzzy Logic to Collocation Extraction</title><categories>cs.CL</categories><comments>13 pages,5 figures,5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collocations are important for many tasks of Natural language processing such
as information retrieval, machine translation, computational lexicography etc.
So far many statistical methods have been used for collocation extraction.
Almost all the methods form a classical crisp set of collocation. We propose a
fuzzy logic approach of collocation extraction to form a fuzzy set of
collocations in which each word combination has a certain grade of membership
for being collocation. Fuzzy logic provides an easy way to express natural
language into fuzzy logic rules. Two existing methods; Mutual information and
t-test have been utilized for the input of the fuzzy inference system. The
resulting membership function could be easily seen and demonstrated. To show
the utility of the fuzzy logic some word pairs have been examined as an
example. The working data has been based on a corpus of about one million words
contained in different novels constituting project Gutenberg available on
www.gutenberg.org. The proposed method has all the advantages of the two
methods, while overcoming their drawbacks. Hence it provides a better result
than the two methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1301</identifier>
 <datestamp>2008-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1301</id><created>2008-11-08</created><authors><author><keyname>Bhosle</keyname><forenames>Amit M.</forenames></author><author><keyname>Gonzalez</keyname><forenames>Teofilo F.</forenames></author></authors><title>Distributed Algorithms for Computing Alternate Paths Avoiding Failed
  Nodes and Links</title><categories>cs.DC cs.DS cs.NI</categories><comments>8 pages, 2 columns, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A recent study characterizing failures in computer networks shows that
transient single element (node/link) failures are the dominant failures in
large communication networks like the Internet. Thus, having the routing paths
globally recomputed on a failure does not pay off since the failed element
recovers fairly quickly, and the recomputed routing paths need to be discarded.
In this paper, we present the first distributed algorithm that computes the
alternate paths required by some &quot;proactive recovery schemes&quot; for handling
transient failures. Our algorithm computes paths that avoid a failed node, and
provides an alternate path to a particular destination from an upstream
neighbor of the failed node. With minor modifications, we can have the
algorithm compute alternate paths that avoid a failed link as well. To the best
of our knowledge all previous algorithms proposed for computing alternate paths
are centralized, and need complete information of the network graph as input to
the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1304</identifier>
 <datestamp>2008-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1304</id><created>2008-11-08</created><authors><author><keyname>Ha</keyname><forenames>Phuong Hoai</forenames></author><author><keyname>Tsigas</keyname><forenames>Philippas</forenames></author><author><keyname>Anshus</keyname><forenames>Otto J.</forenames></author></authors><title>NB-FEB: An Easy-to-Use and Scalable Universal Synchronization Primitive
  for Parallel Programming</title><categories>cs.DC cs.AR cs.DS</categories><report-no>CS:2008-69</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of universal synchronization primitives that
can support scalable thread synchronization for large-scale many-core
architectures. The universal synchronization primitives that have been deployed
widely in conventional architectures like CAS and LL/SC are expected to reach
their scalability limits in the evolution to many-core architectures with
thousands of cores. We introduce a non-blocking full/empty bit primitive, or
NB-FEB for short, as a promising synchronization primitive for parallel
programming on may-core architectures. We show that the NB-FEB primitive is
universal, scalable, feasible and convenient to use. NB-FEB, together with
registers, can solve the consensus problem for an arbitrary number of processes
(universality). NB-FEB is combinable, namely its memory requests to the same
memory location can be combined into only one memory request, which
consequently mitigates performance degradation due to synchronization &quot;hot
spots&quot; (scalability). Since NB-FEB is a variant of the original full/empty bit
that always returns a value instead of waiting for a conditional flag, it is as
feasible as the original full/empty bit, which has been implemented in many
computer systems (feasibility). The original full/empty bit is well-known as a
special-purpose primitive for fast producer-consumer synchronization and has
been used extensively in the specific domain of applications. In this paper, we
show that NB-FEB can be deployed easily as a general-purpose primitive. Using
NB-FEB, we construct a non-blocking software transactional memory system called
NBFEB-STM, which can be used to handle concurrent threads conveniently.
NBFEB-STM is space efficient: the space complexity of each object updated by
$N$ concurrent threads/transactions is $\Theta(N)$, the optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1305</identifier>
 <datestamp>2008-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1305</id><created>2008-11-08</created><authors><author><keyname>Williams</keyname><forenames>Ryan</forenames></author></authors><title>Applying Practice to Theory</title><categories>cs.CC cs.DS</categories><comments>16 pages, 1 figure; ACM SIGACT News, December 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How can complexity theory and algorithms benefit from practical advances in
computing? We give a short overview of some prior work using practical
computing to attack problems in computational complexity and algorithms,
informally describe how linear program solvers may be used to help prove new
lower bounds for satisfiability, and suggest a research program for developing
new understanding in circuit complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1317</identifier>
 <datestamp>2008-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1317</id><created>2008-11-09</created><authors><author><keyname>Ekrem</keyname><forenames>E.</forenames></author><author><keyname>Ulukus</keyname><forenames>S.</forenames></author></authors><title>Secrecy in Cooperative Relay Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Inf. Theory, October 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the effects of user cooperation on the secrecy of broadcast
channels by considering a cooperative relay broadcast channel. We show that
user cooperation can increase the achievable secrecy region. We propose an
achievable scheme that combines Marton's coding scheme for broadcast channels
and Cover and El Gamal's compress-and-forward scheme for relay channels. We
derive outer bounds for the rate-equivocation region using auxiliary random
variables for single-letterization. Finally, we consider a Gaussian channel and
show that both users can have positive secrecy rates, which is not possible for
scalar Gaussian broadcast channels without cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1319</identifier>
 <datestamp>2010-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1319</id><created>2008-11-09</created><updated>2010-05-26</updated><authors><author><keyname>Plangprasopchok</keyname><forenames>Anon</forenames></author><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author></authors><title>Modeling Social Annotation: a Bayesian Approach</title><categories>cs.AI</categories><comments>29 Pages, Accepted for publication at ACM Transactions on Knowledge
  Discovery from Data(TKDD) on March 2, 2010</comments><acm-class>H.2.8; I.5.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collaborative tagging systems, such as Delicious, CiteULike, and others,
allow users to annotate resources, e.g., Web pages or scientific papers, with
descriptive labels called tags. The social annotations contributed by thousands
of users, can potentially be used to infer categorical knowledge, classify
documents or recommend new relevant information. Traditional text inference
methods do not make best use of social annotation, since they do not take into
account variations in individual users' perspectives and vocabulary. In a
previous work, we introduced a simple probabilistic model that takes interests
of individual annotators into account in order to find hidden topics of
annotated resources. Unfortunately, that approach had one major shortcoming:
the number of topics and interests must be specified a priori. To address this
drawback, we extend the model to a fully Bayesian framework, which offers a way
to automatically estimate these numbers. In particular, the model allows the
number of interests and topics to change as suggested by the structure of the
data. We evaluate the proposed model in detail on the synthetic and real-world
data by comparing its performance to Latent Dirichlet Allocation on the topic
extraction task. For the latter evaluation, we apply the model to infer topics
of Web resources from social annotations obtained from Delicious in order to
discover new resources similar to a specified one. Our empirical results
demonstrate that the proposed model is a promising method for exploiting social
knowledge contained in user-generated annotations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1335</identifier>
 <datestamp>2009-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1335</id><created>2008-11-09</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author></authors><title>Algorithmic Techniques for Several Optimization Problems Regarding
  Distributed Systems with Tree Topologies</title><categories>cs.DS cs.DM cs.NI</categories><comments>The 16th International Conference on Applied and Industrial
  Mathematics, Oradea, Romania, 9-11 October, 2008. ROMAI Journal, vol. 4,
  2008. (ISSN: 841-5512). In Press</comments><acm-class>G.2.2; G.2.1</acm-class><journal-ref>ROMAI Journal, vol. 4, no. 1, pp. 1-25, 2008 (ISSN: 1841-5512) ;
  http://www.romai.ro</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the development of distributed systems progresses, more and more
challenges arise and the need for developing optimized systems and for
optimizing existing systems from multiple perspectives becomes more stringent.
In this paper I present novel algorithmic techniques for solving several
optimization problems regarding distributed systems with tree topologies. I
address topics like: reliability improvement, partitioning, coloring, content
delivery, optimal matchings, as well as some tree counting aspects. Some of the
presented techniques are only of theoretical interest, while others can be used
in practical settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1355</identifier>
 <datestamp>2009-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1355</id><created>2008-11-09</created><updated>2009-01-14</updated><authors><author><keyname>Podlubny</keyname><forenames>Igor</forenames></author><author><keyname>Chechkin</keyname><forenames>Aleksei V.</forenames></author><author><keyname>Skovranek</keyname><forenames>Tomas</forenames></author><author><keyname>Chen</keyname><forenames>YangQuan</forenames></author><author><keyname>Jara</keyname><forenames>Blas M. Vinagre</forenames></author></authors><title>Matrix approach to discrete fractional calculus II: partial fractional
  differential equations</title><categories>math.NA cs.NA math-ph math.CA math.MP physics.comp-ph</categories><comments>33 pages, 12 figures</comments><msc-class>26A33; 65M06; 91B82; 65Z05; 65D25</msc-class><journal-ref>Journal of Computational Physics, vol. 228, no. 8, 1 May 2009, pp.
  3137-3153</journal-ref><doi>10.1016/j.jcp.2009.01.014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new method that enables easy and convenient discretization of partial
differential equations with derivatives of arbitrary real order (so-called
fractional derivatives) and delays is presented and illustrated on numerical
solution of various types of fractional diffusion equation. The suggested
method is the development of Podlubny's matrix approach (Fractional Calculus
and Applied Analysis, vol. 3, no. 4, 2000, 359--386). Four examples of
numerical solution of fractional diffusion equation with various combinations
of time/space fractional derivatives (integer/integer, fractional/integer,
integer/fractional, and fractional/fractional) with respect to time and to the
spatial variable are provided in order to illustrate how simple and general is
the suggested approach. The fifth example illustrates that the method can be
equally simply used for fractional differential equations with delays. A set of
MATLAB routines for the implementation of the method as well as sample code
used to solve the examples have been developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1365</identifier>
 <datestamp>2008-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1365</id><created>2008-11-10</created><authors><author><keyname>Shimamoto</keyname><forenames>Don</forenames></author><author><keyname>Wootters</keyname><forenames>Mary</forenames></author></authors><title>Configuration spaces of convex and embedded polygons in the plane</title><categories>cs.CG</categories><comments>16 pages</comments><acm-class>I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the configuration spaces of linkages whose underlying
graph is a single cycle. Assume that the edge lengths are such that there are
no configurations in which all the edges lie along a line. The main results are
that, modulo translations and rotations, each component of the space of convex
configurations is homeomorphic to a closed Euclidean ball and each component of
the space of embedded configurations is homeomorphic to a Euclidean space. This
represents an elaboration on the topological information that follows from the
convexification theorem of Connelly, Demaine, and Rote.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1449</identifier>
 <datestamp>2008-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1449</id><created>2008-11-10</created><authors><author><keyname>Bruy&#xe8;re</keyname><forenames>V&#xe9;ronique</forenames></author><author><keyname>M&#xe9;lot</keyname><forenames>Hadrien</forenames></author></authors><title>Fibonacci Index and Stability Number of Graphs: a Polyhedral Study</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Fibonacci index of a graph is the number of its stable sets. This
parameter is widely studied and has applications in chemical graph theory. In
this paper, we establish tight upper bounds for the Fibonacci index in terms of
the stability number and the order of general graphs and connected graphs.
Tur\'an graphs frequently appear in extremal graph theory. We show that Tur\'an
graphs and a connected variant of them are also extremal for these particular
problems. We also make a polyhedral study by establishing all the optimal
linear inequalities for the stability number and the Fibonacci index, inside
the classes of general and connected graphs of order $n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1500</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1500</id><created>2008-11-10</created><updated>2009-02-10</updated><authors><author><keyname>Tenenbaum</keyname><forenames>Adam J.</forenames></author><author><keyname>Adve</keyname><forenames>Raviraj S.</forenames></author></authors><title>Linear Processing and Sum Throughput in the Multiuser MIMO Downlink</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider linear precoding and decoding in the downlink of a multiuser
multiple-input, multiple-output (MIMO) system, wherein each user may receive
more than one data stream. We propose several mean squared error (MSE) based
criteria for joint transmit-receive optimization and establish a series of
relationships linking these criteria to the signal-to-interference-plus-noise
ratios of individual data streams and the information theoretic channel
capacity under linear minimum MSE decoding. In particular, we show that
achieving the maximum sum throughput is equivalent to minimizing the product of
MSE matrix determinants (PDetMSE). Since the PDetMSE minimization problem does
not admit a computationally efficient solution, a simplified scalar version of
the problem is considered that minimizes the product of mean squared errors
(PMSE). An iterative algorithm is proposed to solve the PMSE problem, and is
shown to provide near-optimal performance with greatly reduced computational
complexity. Our simulations compare the achievable sum rates under linear
precoding strategies to the sum capacity for the broadcast channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1504</identifier>
 <datestamp>2008-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1504</id><created>2008-11-10</created><authors><author><keyname>Nuriyev</keyname><forenames>R.</forenames></author></authors><title>Parallel execution of portfolio optimization</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analysis of asset liability management (ALM) strategies especially for long
term horizon is a crucial issue for banks, funds and insurance companies.
  Modern economic models, investment strategies and optimization criteria make
ALM studies computationally very intensive task. It attracts attention to
multiprocessor system and especially to the cheapest one: multi core PCs and PC
clusters.
  In this article we are analyzing problem of parallel organization of
portfolio optimization, results of using clusters for optimization and the most
efficient cluster architecture for these kinds of tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1520</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1520</id><created>2008-11-10</created><authors><author><keyname>Hogg</keyname><forenames>Tad</forenames></author></authors><title>Modeling Microscopic Chemical Sensors in Capillaries</title><categories>cs.RO physics.bio-ph q-bio.TO</categories><comments>14 pages, 8 figures</comments><journal-ref>The Open Nanomedicine Journal 2:1-9 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nanotechnology-based microscopic robots could provide accurate in vivo
measurement of chemicals in the bloodstream for detailed biological research
and as an aid to medical treatment. Quantitative performance estimates of such
devices require models of how chemicals in the blood diffuse to the devices.
This paper models microscopic robots and red blood cells (erythrocytes) in
capillaries using realistic distorted cell shapes. The models evaluate two
sensing scenarios: robots moving with the cells past a chemical source on the
vessel wall, and robots attached to the wall for longer-term chemical
monitoring. Using axial symmetric geometry with realistic flow speeds and
diffusion coefficients, we compare detection performance with a simpler model
that does not include the cells. The average chemical absorption is
quantitatively similar in both models, indicating the simpler model is an
adequate design guide to sensor performance in capillaries. However,
determining the variation in forces and absorption as cells move requires the
full model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1570</identifier>
 <datestamp>2008-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1570</id><created>2008-11-10</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author><author><keyname>Klappenecker</keyname><forenames>Andreas</forenames></author></authors><title>Constructions of Subsystem Codes over Finite Fields</title><categories>quant-ph cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Subsystem codes protect quantum information by encoding it in a tensor factor
of a subspace of the physical state space. Subsystem codes generalize all major
quantum error protection schemes, and therefore are especially versatile. This
paper introduces numerous constructions of subsystem codes. It is shown how one
can derive subsystem codes from classical cyclic codes. Methods to trade the
dimensions of subsystem and co-subystem are introduced that maintain or improve
the minimum distance. As a consequence, many optimal subsystem codes are
obtained. Furthermore, it is shown how given subsystem codes can be extended,
shortened, or combined to yield new subsystem codes. These subsystem code
constructions are used to derive tables of upper and lower bounds on the
subsystem code parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1618</identifier>
 <datestamp>2008-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1618</id><created>2008-11-10</created><authors><author><keyname>Li</keyname><forenames>Chendong</forenames></author></authors><title>Airport Gate Assignment: New Model and Implementation</title><categories>cs.AI</categories><comments>5 pages, 2 figures, 1 table. Accepted by ICOR 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Airport gate assignment is of great importance in airport operations. In this
paper, we study the Airport Gate Assignment Problem (AGAP), propose a new model
and implement the model with Optimization Programming language (OPL). With the
objective to minimize the number of conflicts of any two adjacent aircrafts
assigned to the same gate, we build a mathematical model with logical
constraints and the binary constraints, which can provide an efficient
evaluation criterion for the Airlines to estimate the current gate assignment.
To illustrate the feasibility of the model we construct experiments with the
data obtained from Continental Airlines, Houston Gorge Bush Intercontinental
Airport IAH, which indicate that our model is both energetic and effective.
Moreover, we interpret experimental results, which further demonstrate that our
proposed model can provide a powerful tool for airline companies to estimate
the efficiency of their current work of gate assignment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1629</identifier>
 <datestamp>2008-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1629</id><created>2008-11-11</created><authors><author><keyname>Mohri</keyname><forenames>Mehryar</forenames></author><author><keyname>Rostamizadeh</keyname><forenames>Afshin</forenames></author></authors><title>Stability Bound for Stationary Phi-mixing and Beta-mixing Processes</title><categories>cs.LG</categories><comments>23 pages, 1 figure, submitted to JMLR</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most generalization bounds in learning theory are based on some measure of
the complexity of the hypothesis class used, independently of any algorithm. In
contrast, the notion of algorithmic stability can be used to derive tight
generalization bounds that are tailored to specific learning algorithms by
exploiting their particular properties. However, as in much of learning theory,
existing stability analyses and bounds apply only in the scenario where the
samples are independently and identically distributed. In many machine learning
applications, however, this assumption does not hold. The observations received
by the learning algorithm often have some inherent temporal dependence.
  This paper studies the scenario where the observations are drawn from a
stationary phi-mixing or beta-mixing sequence, a widely adopted assumption in
the study of non-i.i.d. processes that implies a dependence between
observations weakening over time. We prove novel and distinct stability-based
generalization bounds for stationary phi-mixing and beta-mixing sequences.
These bounds strictly generalize the bounds given in the i.i.d. case and apply
to all stable learning algorithms, thereby extending the use of
stability-bounds to non-i.i.d. scenarios.
  We also illustrate the application of our phi-mixing generalization bounds to
general classes of learning algorithms, including Support Vector Regression,
Kernel Ridge Regression, and Support Vector Machines, and many other kernel
regularization-based and relative entropy-based regularization algorithms.
These novel bounds can thus be viewed as the first theoretical basis for the
use of these algorithms in non-i.i.d. scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1664</identifier>
 <datestamp>2008-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1664</id><created>2008-11-11</created><authors><author><keyname>Faella</keyname><forenames>Marco</forenames></author></authors><title>Best-Effort Strategies for Losing States</title><categories>cs.GT</categories><comments>Technical report derived from the GAMES'07 talk &quot;Games you cannot
  win&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider games played on finite graphs, whose goal is to obtain a trace
belonging to a given set of winning traces. We focus on those states from which
Player 1 cannot force a win. We explore and compare several criteria for
establishing what is the preferable behavior of Player 1 from those states.
  Along the way, we prove several results of theoretical and practical
interest, such as a characterization of admissible strategies, which also
provides a simple algorithm for computing such strategies for various common
goals, and the equivalence between the existence of positional winning
strategies and the existence of positional subgame perfect strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1693</identifier>
 <datestamp>2008-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1693</id><created>2008-11-11</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author><author><keyname>Kamal</keyname><forenames>Ahmed E.</forenames></author></authors><title>Protection Schemes for Two Link Failures in Optical Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>2 figures, 5 pages, private comments are welcome</comments><journal-ref>Proc. of ICCTA, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we develop network protection schemes against two link failures
in optical networks. The motivation behind this work is the fact that the
majority of all available links in an optical network suffer from single and
double link failures. In the proposed network protection schemes, NPS2-I and
NPS2-II, we deploy network coding and reduced capacity on the working paths to
provide backup protection paths. In addition, we demonstrate the encoding and
decoding aspects of the proposed schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1711</identifier>
 <datestamp>2008-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1711</id><created>2008-11-11</created><authors><author><keyname>Wright</keyname><forenames>Sarah</forenames></author><author><keyname>Marwala</keyname><forenames>Tshilidzi</forenames></author></authors><title>Artificial Intelligence Techniques for Steam Generator Modelling</title><categories>cs.AI</categories><comments>23 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the use of different Artificial Intelligence methods
to predict the values of several continuous variables from a Steam Generator.
The objective was to determine how the different artificial intelligence
methods performed in making predictions on the given dataset. The artificial
intelligence methods evaluated were Neural Networks, Support Vector Machines,
and Adaptive Neuro-Fuzzy Inference Systems. The types of neural networks
investigated were Multi-Layer Perceptions, and Radial Basis Function. Bayesian
and committee techniques were applied to these neural networks. Each of the AI
methods considered was simulated in Matlab. The results of the simulations
showed that all the AI methods were capable of predicting the Steam Generator
data reasonably accurately. However, the Adaptive Neuro-Fuzzy Inference system
out performed the other methods in terms of accuracy and ease of
implementation, while still achieving a fast execution time as well as a
reasonable training time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1714</identifier>
 <datestamp>2012-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1714</id><created>2008-11-11</created><authors><author><keyname>Albrecht</keyname><forenames>Martin</forenames></author><author><keyname>Bard</keyname><forenames>Gregory</forenames></author><author><keyname>Hart</keyname><forenames>William</forenames></author></authors><title>Efficient Multiplication of Dense Matrices over GF(2)</title><categories>cs.MS</categories><acm-class>G.4</acm-class><doi>10.1145/1644001.1644010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an efficient implementation of a hierarchy of algorithms for
multiplication of dense matrices over the field with two elements (GF(2)). In
particular we present our implementation -- in the M4RI library -- of
Strassen-Winograd matrix multiplication and the &quot;Method of the Four Russians&quot;
multiplication (M4RM) and compare it against other available implementations.
Good performance is demonstrated on on AMD's Opteron and particulary good
performance on Intel's Core 2 Duo. The open-source M4RI library is available
stand-alone as well as part of the Sage mathematics software.
  In machine terms, addition in GF(2) is logical-XOR, and multiplication is
logical-AND, thus a machine word of 64-bits allows one to operate on 64
elements of GF(2) in parallel: at most one CPU cycle for 64 parallel additions
or multiplications. As such, element-wise operations over GF(2) are relatively
cheap. In fact, in this paper, we conclude that the actual bottlenecks are
memory reads and writes and issues of data locality. We present our empirical
findings in relation to minimizing these and give an analysis thereof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1770</identifier>
 <datestamp>2008-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1770</id><created>2008-11-11</created><authors><author><keyname>Korada</keyname><forenames>Satish Babu</forenames></author><author><keyname>Sasoglu</keyname><forenames>Eren</forenames></author></authors><title>A Class of Transformations that Polarize Symmetric Binary-Input
  Memoryless Channels</title><categories>cs.IT math.IT</categories><comments>7 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A generalization of Ar\i kan's polar code construction using transformations
of the form $G^{\otimes n}$ where $G$ is an $\ell \times \ell$ matrix is
considered. Necessary and sufficient conditions are given for these
transformations to ensure channel polarization. It is shown that a large class
of such transformations polarize symmetric binary-input memoryless channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1790</identifier>
 <datestamp>2008-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1790</id><created>2008-11-11</created><authors><author><keyname>Xu</keyname><forenames>Huan</forenames></author><author><keyname>Caramanis</keyname><forenames>Constantine</forenames></author><author><keyname>Mannor</keyname><forenames>Shie</forenames></author></authors><title>Robust Regression and Lasso</title><categories>cs.IT cs.LG math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lasso, or $\ell^1$ regularized least squares, has been explored extensively
for its remarkable sparsity properties. It is shown in this paper that the
solution to Lasso, in addition to its sparsity, has robustness properties: it
is the solution to a robust optimization problem. This has two important
consequences. First, robustness provides a connection of the regularizer to a
physical property, namely, protection from noise. This allows a principled
selection of the regularizer, and in particular, generalizations of Lasso that
also yield convex optimization problems are obtained by considering different
uncertainty sets.
  Secondly, robustness can itself be used as an avenue to exploring different
properties of the solution. In particular, it is shown that robustness of the
solution explains why the solution is sparse. The analysis as well as the
specific results obtained differ from standard sparsity results, providing
different geometric intuition. Furthermore, it is shown that the robust
optimization formulation is related to kernel density estimation, and based on
this approach, a proof that Lasso is consistent is given using robustness
directly. Finally, a theorem saying that sparsity and algorithmic stability
contradict each other, and hence Lasso is not stable, is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1825</identifier>
 <datestamp>2008-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1825</id><created>2008-11-12</created><authors><author><keyname>Lutz</keyname><forenames>Jack H.</forenames></author></authors><title>A Divergence Formula for Randomness and Dimension</title><categories>cs.CC cs.IT math.IT</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  If $S$ is an infinite sequence over a finite alphabet $\Sigma$ and $\beta$ is
a probability measure on $\Sigma$, then the {\it dimension} of $ S$ with
respect to $\beta$, written $\dim^\beta(S)$, is a constructive version of
Billingsley dimension that coincides with the (constructive Hausdorff)
dimension $\dim(S)$ when $\beta$ is the uniform probability measure. This paper
shows that $\dim^\beta(S)$ and its dual $\Dim^\beta(S)$, the {\it strong
dimension} of $S$ with respect to $\beta$, can be used in conjunction with
randomness to measure the similarity of two probability measures $\alpha$ and
$\beta$ on $\Sigma$. Specifically, we prove that the {\it divergence formula}
\[
  \dim^\beta(R) = \Dim^\beta(R) =\frac{\CH(\alpha)}{\CH(\alpha) + \D(\alpha ||
\beta)} \] holds whenever $\alpha$ and $\beta$ are computable, positive
probability measures on $\Sigma$ and $R \in \Sigma^\infty$ is random with
respect to $\alpha$. In this formula, $\CH(\alpha)$ is the Shannon entropy of
$\alpha$, and $\D(\alpha||\beta)$ is the Kullback-Leibler divergence between
$\alpha$ and $\beta$. We also show that the above formula holds for all
sequences $R$ that are $\alpha$-normal (in the sense of Borel) when
$\dim^\beta(R)$ and $\Dim^\beta(R)$ are replaced by the more effective
finite-state dimensions $\dimfs^\beta(R)$ and $\Dimfs^\beta(R)$. In the course
of proving this, we also prove finite-state compression characterizations of
$\dimfs^\beta(S)$ and $\Dimfs^\beta(S)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1859</identifier>
 <datestamp>2008-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1859</id><created>2008-11-12</created><authors><author><keyname>Arroyo</keyname><forenames>David</forenames></author><author><keyname>Alvarez</keyname><forenames>Gonzalo</forenames></author><author><keyname>Fernandez</keyname><forenames>Veronica</forenames></author></authors><title>A Basic Framework for the Cryptanalysis of Digital Chaos-Based
  Cryptography</title><categories>cs.CR</categories><comments>6 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chaotic cryptography is based on the properties of chaos as source of
entropy. Many different schemes have been proposed to take advantage of those
properties and to design new strategies to encrypt information. However, the
right and efficient use of chaos in the context of cryptography requires a
thorough knowledge about the dynamics of the selected chaotic system. Indeed,
if the final encryption system reveals enough information about the underlying
chaotic system it could be possible for a cryptanalyst to get the key, part of
the key or some information somehow equivalent to the key just analyzing those
dynamical properties leaked by the cryptosystem. This paper shows what those
dynamical properties are and how a cryptanalyst can use them to prove the
inadequacy of an encryption system for the secure exchange of information. This
study is performed through the introduction of a series of mathematical tools
which should be the basic framework of cryptanalysis in the context of digital
chaos-based cryptography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1868</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1868</id><created>2008-11-12</created><updated>2009-08-04</updated><authors><author><keyname>Cerri</keyname><forenames>Andrea</forenames></author><author><keyname>Frosini</keyname><forenames>Patrizio</forenames></author></authors><title>Necessary Conditions for Discontinuities of Multidimensional Size
  Functions</title><categories>cs.CG cs.CV math.AT</categories><comments>23 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some new results about multidimensional Topological Persistence are
presented, proving that the discontinuity points of a k-dimensional size
function are necessarily related to the pseudocritical or special values of the
associated measuring function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1875</identifier>
 <datestamp>2009-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1875</id><created>2008-11-12</created><updated>2009-06-12</updated><authors><author><keyname>Fernau</keyname><forenames>Henning</forenames></author><author><keyname>Gaspers</keyname><forenames>Serge</forenames></author><author><keyname>Raible</keyname><forenames>Daniel</forenames></author></authors><title>Exact Exponential Time Algorithms for Max Internal Spanning Tree</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the NP-hard problem of finding a spanning tree with a maximum
number of internal vertices. This problem is a generalization of the famous
  Hamiltonian Path problem. Our dynamic-programming algorithms for general and
degree-bounded graphs have running times of the form O*(c^n) (c &lt;= 3). The main
result, however, is a branching algorithm for graphs with maximum degree three.
It only needs polynomial space and has a running time of O*(1.8669^n) when
analyzed with respect to the number of vertices. We also show that its running
time is 2.1364^k n^O(1) when the goal is to find a spanning tree with at least
k internal vertices. Both running time bounds are obtained via a Measure &amp;
Conquer analysis, the latter one being a novel use of this kind of analyses for
parameterized algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1878</identifier>
 <datestamp>2008-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1878</id><created>2008-11-12</created><authors><author><keyname>Varzinczak</keyname><forenames>Ivan</forenames></author></authors><title>Action Theory Evolution</title><categories>cs.AI cs.LO</categories><comments>64 pages, 19 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Like any other logical theory, domain descriptions in reasoning about actions
may evolve, and thus need revision methods to adequately accommodate new
information about the behavior of actions. The present work is about changing
action domain descriptions in propositional dynamic logic. Its contribution is
threefold: first we revisit the semantics of action theory contraction that has
been done in previous work, giving more robust operators that express minimal
change based on a notion of distance between Kripke-models. Second we give
algorithms for syntactical action theory contraction and establish their
correctness w.r.t. our semantics. Finally we state postulates for action theory
contraction and assess the behavior of our operators w.r.t. them. Moreover, we
also address the revision counterpart of action theory change, showing that it
benefits from our semantics for contraction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1882</identifier>
 <datestamp>2008-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1882</id><created>2008-11-12</created><authors><author><keyname>Chatterjee</keyname><forenames>Soumyottam</forenames></author><author><keyname>Ghosh</keyname><forenames>Shamik</forenames></author></authors><title>Ferrers Dimension and Boxicity</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note explores the relation between the boxicity of undirected graphs and
the Ferrers dimension of digraphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1885</identifier>
 <datestamp>2009-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1885</id><created>2008-11-12</created><authors><author><keyname>Zivny</keyname><forenames>Stanislav</forenames></author><author><keyname>Cohen</keyname><forenames>David A.</forenames></author><author><keyname>Jeavons</keyname><forenames>Peter G.</forenames></author></authors><title>The Expressive Power of Binary Submodular Functions</title><categories>cs.DM cs.AI cs.CV</categories><comments>16 pages</comments><acm-class>F.2.2; G.2.1; I.2.4; I.4.0; I.5.1</acm-class><journal-ref>Discrete Applied Mathematics 157(15) (2009) 3347-3358</journal-ref><doi>10.1016/j.dam.2009.07.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has previously been an open problem whether all Boolean submodular
functions can be decomposed into a sum of binary submodular functions over a
possibly larger set of variables. This problem has been considered within
several different contexts in computer science, including computer vision,
artificial intelligence, and pseudo-Boolean optimisation. Using a connection
between the expressive power of valued constraints and certain algebraic
properties of functions, we answer this question negatively.
  Our results have several corollaries. First, we characterise precisely which
submodular functions of arity 4 can be expressed by binary submodular
functions. Next, we identify a novel class of submodular functions of arbitrary
arities which can be expressed by binary submodular functions, and therefore
minimised efficiently using a so-called expressibility reduction to the Min-Cut
problem. More importantly, our results imply limitations on this kind of
reduction and establish for the first time that it cannot be used in general to
minimise arbitrary submodular functions. Finally, we refute a conjecture of
Promislow and Young on the structure of the extreme rays of the cone of Boolean
submodular functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1914</identifier>
 <datestamp>2008-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1914</id><created>2008-11-12</created><authors><author><keyname>Chaudhuri</keyname><forenames>Kaustuv C.</forenames><affiliation>MRI</affiliation></author><author><keyname>Doligez</keyname><forenames>Damien</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Lamport</keyname><forenames>Leslie</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Merz</keyname><forenames>Stephan</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>A TLA+ Proof System</title><categories>cs.LO</categories><proxy>ccsd inria-00338299</proxy><journal-ref>Knowledge Exchange: Automated Provers and Proof Assistants
  (KEAPPA) (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an extension to the TLA+ specification language with constructs
for writing proofs and a proof environment, called the Proof Manager (PM), to
checks those proofs. The language and the PM support the incremental
development and checking of hierarchically structured proofs. The PM translates
a proof into a set of independent proof obligations and calls upon a collection
of back-end provers to verify them. Different provers can be used to verify
different obligations. The currently supported back-ends are the tableau prover
Zenon and Isabelle/TLA+, an axiomatisation of TLA+ in Isabelle/Pure. The proof
obligations for a complete TLA+ proof can also be used to certify the theorem
in Isabelle/TLA+.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1947</identifier>
 <datestamp>2008-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1947</id><created>2008-11-12</created><authors><author><keyname>Elkadiri</keyname><forenames>Soumaya</forenames><affiliation>LIESP</affiliation></author><author><keyname>Pernelle</keyname><forenames>Philippe</forenames><affiliation>LIESP</affiliation></author><author><keyname>Delattre</keyname><forenames>Miguel</forenames><affiliation>LIESP</affiliation></author><author><keyname>Bouras</keyname><forenames>Abdelaziz</forenames><affiliation>LIESP</affiliation></author></authors><title>Pilotage des processus collaboratifs dans les syst\`emes PLM. Quels
  indicateurs pour quelle \'evaluation des performances ?</title><categories>cs.SE</categories><proxy>ccsd hal-00338237</proxy><journal-ref>1er Congr\`es des innovations m\'ecaniques CIM'08, Sousse :
  Tunisie (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Les entreprises qui collaborent dans un processus de d\'eveloppement de
produit ont besoin de mettre en oeuvre une gestion efficace des activit\'es
collaborative. Malgr\'e la mise en place d'un PLM, les activit\'es
collaborative sont loin d'\^etre aussi efficace que l'on pourrait s'y attendre.
Cet article propose une analyse des probl\'ematiques de la collaboration avec
un syst\`eme PLM. A partir de ces analyses, nous proposons la mise en place
d'indicateurs et d'actions sur les processus visant \`a identifier puis
att\'enuer les freins dans le travail collaboratif.
-----
Companies that collaborate within the product development processes need to
implement an effective management of their collaborative activities. Despite
the implementation of a PLM system, the collaborative activities are not
efficient as it might be expected. This paper presents an analysis of the
problems related to the collaborative work using a PLM system, identified
through a survey. From this analysis, we propose an approach for improving
collaborative processes within a PLM system, based on monitoring indicators.
This approach leads to identify and therefore to mitigate the brakes of the
collaborative work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1950</identifier>
 <datestamp>2008-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1950</id><created>2008-11-12</created><authors><author><keyname>Elkadiri</keyname><forenames>Soumaya</forenames><affiliation>LIESP</affiliation></author><author><keyname>Pernelle</keyname><forenames>Philippe</forenames><affiliation>LIESP</affiliation></author><author><keyname>Delattre</keyname><forenames>Miguel</forenames><affiliation>LIESP</affiliation></author><author><keyname>Bouras</keyname><forenames>Abdelaziz</forenames><affiliation>LIESP</affiliation></author></authors><title>Collaborative process control: Observation of tracks generated by PLM
  system</title><categories>cs.SE</categories><proxy>ccsd hal-00338235</proxy><journal-ref>APMS 2008 - Innovations in Networks, Espoo : Finlande (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper aims at analyzing the problems related to collaborative work using
a PLM system. This research is mainly focused on the organisational aspects of
SMEs involved in networks composed of large companies, subcontractors and other
industrial partners. From this analysis, we propose the deployment of an
approach based on an observation process of tracks generated by PLM system. The
specific contributions are of two fold. First is to identify the brake points
of collaborative work. The second, thanks to the exploitation of generated
tracks, it allows reducing risks by reacting in real time to the incidents or
dysfunctions that may occur. The overall system architecture based on services
technology and supporting the proposed approach is described, as well as
associated prototype developed using an industrial PLM system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1959</identifier>
 <datestamp>2008-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1959</id><created>2008-11-12</created><authors><author><keyname>Robert</keyname><forenames>Charles A. B.</forenames><affiliation>LORIA</affiliation></author></authors><title>Characterization and collection of information from heterogeneous
  multimedia sources with users' parameters for decision support</title><categories>cs.MM</categories><proxy>ccsd hal-00338135</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  No single information source can be good enough to satisfy the divergent and
dynamic needs of users all the time. Integrating information from divergent
sources can be a solution to deficiencies in information content. We present
how Information from multimedia document can be collected based on associating
a generic database to a federated database. Information collected in this way
is brought into relevance by integrating the parameters of usage and user's
parameter for decision making. We identified seven different classifications of
multimedia document.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1974</identifier>
 <datestamp>2008-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1974</id><created>2008-11-12</created><authors><author><keyname>Averbukh</keyname><forenames>Vladimir L.</forenames></author></authors><title>Magic Fairy Tales as Source for Interface Metaphors</title><categories>cs.HC</categories><comments>4 pages</comments><acm-class>H.1.m</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The work is devoted to a problem of search of metaphors for interactive
systems and systems based on Virtual Reality (VR) environments. The analysis of
magic fairy tales as a source of metaphors for interface and virtual reality is
offered. Some results of design process based on magic metaphors are
considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1976</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1976</id><created>2008-11-12</created><updated>2008-11-21</updated><authors><author><keyname>Kupke</keyname><forenames>C.</forenames></author><author><keyname>Venema</keyname><forenames>Y.</forenames></author></authors><title>Coalgebraic Automata Theory: Basic Results</title><categories>cs.LO</categories><comments>43 pages</comments><acm-class>F.1.1; F.4.3; F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 4 (November
  21, 2008) lmcs:1203</journal-ref><doi>10.2168/LMCS-4(4:10)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We generalize some of the central results in automata theory to the
abstraction level of coalgebras and thus lay out the foundations of a universal
theory of automata operating on infinite objects.
  Let F be any set functor that preserves weak pullbacks. We show that the
class of recognizable languages of F-coalgebras is closed under taking unions,
intersections, and projections. We also prove that if a nondeterministic
F-automaton accepts some coalgebra it accepts a finite one of the size of the
automaton. Our main technical result concerns an explicit construction which
transforms a given alternating F-automaton into an equivalent nondeterministic
one, whose size is exponentially bound by the size of the original automaton.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2016</identifier>
 <datestamp>2008-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2016</id><created>2008-11-12</created><authors><author><keyname>Gidudu</keyname><forenames>A.</forenames></author><author><keyname>Abe</keyname><forenames>B.</forenames></author><author><keyname>Marwala</keyname><forenames>T.</forenames></author></authors><title>Land Cover Mapping Using Ensemble Feature Selection Methods</title><categories>cs.LG</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ensemble classification is an emerging approach to land cover mapping whereby
the final classification output is a result of a consensus of classifiers.
Intuitively, an ensemble system should consist of base classifiers which are
diverse i.e. classifiers whose decision boundaries err differently. In this
paper ensemble feature selection is used to impose diversity in ensembles. The
features of the constituent base classifiers for each ensemble were created
through an exhaustive search algorithm using different separability indices.
For each ensemble, the classification accuracy was derived as well as a
diversity measure purported to give a measure of the inensemble diversity. The
correlation between ensemble classification accuracy and diversity measure was
determined to establish the interplay between the two variables. From the
findings of this paper, diversity measures as currently formulated do not
provide an adequate means upon which to constitute ensembles for land cover
mapping.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2055</identifier>
 <datestamp>2008-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2055</id><created>2008-11-13</created><updated>2008-11-18</updated><authors><author><keyname>Szalay</keyname><forenames>Tamas</forenames></author><author><keyname>Springel</keyname><forenames>Volker</forenames></author><author><keyname>Lemson</keyname><forenames>Gerard</forenames></author></authors><title>GPU-Based Interactive Visualization of Billion Point Cosmological
  Simulations</title><categories>cs.GR astro-ph</categories><comments>2008 Microsoft eScience conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the recent advances in graphics hardware capabilities, a brute force
approach is incapable of interactively displaying terabytes of data. We have
implemented a system that uses hierarchical level-of-detailing for the results
of cosmological simulations, in order to display visually accurate results
without loading in the full dataset (containing over 10 billion points). The
guiding principle of the program is that the user should not be able to
distinguish what they are seeing from a full rendering of the original data.
Furthermore, by using a tree-based system for levels of detail, the size of the
underlying data is limited only by the capacity of the IO system containing it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2113</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2113</id><created>2008-11-13</created><updated>2008-11-17</updated><authors><author><keyname>Heunen</keyname><forenames>Chris</forenames></author></authors><title>Compactly accessible categories and quantum key distribution</title><categories>cs.LO cs.PL quant-ph</categories><comments>26 pages</comments><acm-class>F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 4 (November
  17, 2008) lmcs:1129</journal-ref><doi>10.2168/LMCS-4(4:9)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compact categories have lately seen renewed interest via applications to
quantum physics. Being essentially finite-dimensional, they cannot accomodate
(co)limit-based constructions. For example, they cannot capture protocols such
as quantum key distribution, that rely on the law of large numbers. To overcome
this limitation, we introduce the notion of a compactly accessible category,
relying on the extra structure of a factorisation system. This notion allows
for infinite dimension while retaining key properties of compact categories:
the main technical result is that the choice-of-duals functor on the compact
part extends canonically to the whole compactly accessible category. As an
example, we model a quantum key distribution protocol and prove its correctness
categorically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2117</identifier>
 <datestamp>2008-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2117</id><created>2008-11-13</created><authors><author><keyname>Molinaro</keyname><forenames>Cristian</forenames></author><author><keyname>Chomicki</keyname><forenames>Jan</forenames></author><author><keyname>Marcinkowski</keyname><forenames>Jerzy</forenames></author></authors><title>Disjunctive Databases for Representing Repairs</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of representing the set of repairs of a
possibly inconsistent database by means of a disjunctive database.
Specifically, the class of denial constraints is considered. We show that,
given a database and a set of denial constraints, there exists a (unique)
disjunctive database, called canonical, which represents the repairs of the
database w.r.t. the constraints and is contained in any other disjunctive
database with the same set of minimal models. We propose an algorithm for
computing the canonical disjunctive database. Finally, we study the size of the
canonical disjunctive database in the presence of functional dependencies for
both repairs and cardinality-based repairs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2180</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2180</id><created>2008-11-13</created><updated>2009-12-16</updated><authors><author><keyname>Chafai</keyname><forenames>Djalil</forenames><affiliation>LAMA</affiliation></author><author><keyname>Malrieu</keyname><forenames>Florent</forenames><affiliation>IRMAR</affiliation></author><author><keyname>Paroux</keyname><forenames>Katy</forenames><affiliation>LM-Besan&#xe7;on, INRIA - IRISA</affiliation></author></authors><title>On the long time behavior of the TCP window size process</title><categories>math.PR cs.NI</categories><comments>Corrections</comments><proxy>ccsd hal-00338640</proxy><msc-class>68M12, 60K30, 60K25, 90B18</msc-class><journal-ref>Stochastic Processes and their Applications 120, 8 (2010)
  1518-1534</journal-ref><doi>10.1016/j.spa.2010.03.019</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The TCP window size process appears in the modeling of the famous
Transmission Control Protocol used for data transmission over the Internet.
This continuous time Markov process takes its values in $[0,\infty)$, is
ergodic and irreversible. It belongs to the Additive Increase Multiplicative
Decrease class of processes. The sample paths are piecewise linear
deterministic and the whole randomness of the dynamics comes from the jump
mechanism. Several aspects of this process have already been investigated in
the literature. In the present paper, we mainly get quantitative estimates for
the convergence to equilibrium, in terms of the $W_1$ Wasserstein coupling
distance, for the process and also for its embedded chain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2198</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2198</id><created>2008-11-13</created><updated>2009-04-27</updated><authors><author><keyname>Rabinovich</keyname><forenames>Alexander</forenames></author></authors><title>The Church Problem for Countable Ordinals</title><categories>cs.LO</categories><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 2 (April 27,
  2009) lmcs:1204</journal-ref><doi>10.2168/LMCS-5(2:5)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental theorem of Buchi and Landweber shows that the Church synthesis
problem is computable. Buchi and Landweber reduced the Church Problem to
problems about &amp;#969;-games and used the determinacy of such games as one of
the main tools to show its computability. We consider a natural generalization
of the Church problem to countable ordinals and investigate games of arbitrary
countable length. We prove that determinacy and decidability parts of the
Bu}chi and Landweber theorem hold for all countable ordinals and that its full
extension holds for all ordinals &lt; \omega\^\omega.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2201</identifier>
 <datestamp>2008-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2201</id><created>2008-11-13</created><authors><author><keyname>Sinnokrot</keyname><forenames>Mohanned O.</forenames></author><author><keyname>Barry</keyname><forenames>John R.</forenames></author></authors><title>Fast Maximum-Likelihood Decoding of the Golden Code</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Wireless, November 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The golden code is a full-rate full-diversity space-time code for two
transmit antennas that has a maximal coding gain. Because each codeword conveys
four information symbols from an M-ary quadrature-amplitude modulation
alphabet, the complexity of an exhaustive search decoder is proportional to
M^2. In this paper we present a new fast algorithm for maximum-likelihood
decoding of the golden code that has a worst-case complexity of only O(2M^2.5).
We also present an efficient implementation of the fast decoder that exhibits a
low average complexity. Finally, in contrast to the overlaid Alamouti codes,
which lose their fast decodability property on time-varying channels, we show
that the golden code is fast decodable on both quasistatic and rapid
time-varying channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2250</identifier>
 <datestamp>2009-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2250</id><created>2008-11-13</created><updated>2009-06-08</updated><authors><author><keyname>Zhang</keyname><forenames>Xi</forenames></author><author><keyname>Chomicki</keyname><forenames>Jan</forenames></author></authors><title>Semantics and Evaluation of Top-k Queries in Probabilistic Databases</title><categories>cs.DB</categories><comments>60 pages, section 4.4 added, section 6 added, typos corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study here fundamental issues involved in top-k query evaluation in
probabilistic databases. We consider simple probabilistic databases in which
probabilities are associated with individual tuples, and general probabilistic
databases in which, additionally, exclusivity relationships between tuples can
be represented. In contrast to other recent research in this area, we do not
limit ourselves to injective scoring functions. We formulate three intuitive
postulates that the semantics of top-k queries in probabilistic databases
should satisfy, and introduce a new semantics, Global-Topk, that satisfies
those postulates to a large degree. We also show how to evaluate queries under
the Global-Topk semantics. For simple databases we design dynamic-programming
based algorithms, and for general databases we show polynomial-time reductions
to the simple cases. For example, we demonstrate that for a fixed k the time
complexity of top-k query evaluation is as low as linear, under the assumption
that probabilistic databases are simple and scoring functions are injective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2306</identifier>
 <datestamp>2008-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2306</id><created>2008-11-14</created><authors><author><keyname>Andreyev</keyname><forenames>Yuri V.</forenames><affiliation>Member, IEEE</affiliation></author><author><keyname>Dmitriev</keyname><forenames>Alexander S.</forenames><affiliation>Member, IEEE</affiliation></author><author><keyname>Kletsov</keyname><forenames>Andrey V.</forenames></author></authors><title>Multipath Amplification of Chaotic Radio Pulses and UWB Communications</title><categories>nlin.CD cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Effect of multipath amplification is found in ultrawideband wireless
communication systems with chaotic carrier, whereas information is transmitted
with chaotic radio pulses. This effect is observed in multipath environment
(residence, office, industrial or other indoor space). It exhibits itself
through an increase of signal power at the receiver input with respect to the
case of free space. Multipath amplification effect gives 5-15 dB energy gain
(depending on the environment), which allows to have 2-6 times longer distance
range for the same transmitter power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2356</identifier>
 <datestamp>2008-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2356</id><created>2008-11-14</created><authors><author><keyname>Kaufman</keyname><forenames>Tali</forenames></author><author><keyname>Lovett</keyname><forenames>Shachar</forenames></author></authors><title>The List-Decoding Size of Reed-Muller Codes</title><categories>cs.IT cs.DM math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we study the list-decoding size of Reed-Muller codes. Given a
received word and a distance parameter, we are interested in bounding the size
of the list of Reed-Muller codewords that are within that distance from the
received word. Previous bounds of Gopalan, Klivans and Zuckerman \cite{GKZ08}
on the list size of Reed-Muller codes apply only up to the minimum distance of
the code. In this work we provide asymptotic bounds for the list-decoding size
of Reed-Muller codes that apply for {\em all} distances. Additionally, we study
the weight distribution of Reed-Muller codes. Prior results of Kasami and
Tokura \cite{KT70} on the structure of Reed-Muller codewords up to twice the
minimum distance, imply bounds on the weight distribution of the code that
apply only until twice the minimum distance. We provide accumulative bounds for
the weight distribution of Reed-Muller codes that apply to {\em all} distances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2403</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2403</id><created>2008-11-14</created><updated>2009-05-22</updated><authors><author><keyname>Raymond</keyname><forenames>Jack</forenames></author><author><keyname>Saad</keyname><forenames>David</forenames></author></authors><title>Composite CDMA - A statistical mechanics analysis</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.IT math.IT</categories><comments>23 pages, 11 figures, Sigma Phi 2008 conference submission -
  submitted to J.Stat.Mech</comments><journal-ref>J. Stat. Mech. (2009) P05015</journal-ref><doi>10.1088/1742-5468/2009/05/P05015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Code Division Multiple Access (CDMA) in which the spreading code assignment
to users contains a random element has recently become a cornerstone of CDMA
research. The random element in the construction is particular attractive as it
provides robustness and flexibility in utilising multi-access channels, whilst
not making significant sacrifices in terms of transmission power. Random codes
are generated from some ensemble, here we consider the possibility of combining
two standard paradigms, sparsely and densely spread codes, in a single
composite code ensemble. The composite code analysis includes a replica
symmetric calculation of performance in the large system limit, and
investigation of finite systems through a composite belief propagation
algorithm. A variety of codes are examined with a focus on the high
multi-access interference regime. In both the large size limit and finite
systems we demonstrate scenarios in which the composite code has typical
performance exceeding sparse and dense codes at equivalent signal to noise
ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2457</identifier>
 <datestamp>2008-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2457</id><created>2008-11-15</created><authors><author><keyname>Goel</keyname><forenames>Ashish</forenames></author><author><keyname>Kapralov</keyname><forenames>Michael</forenames></author><author><keyname>Khanna</keyname><forenames>Sanjeev</forenames></author></authors><title>Perfect Matchings via Uniform Sampling in Regular Bipartite Graphs</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we further investigate the well-studied problem of finding a
perfect matching in a regular bipartite graph. The first non-trivial algorithm,
with running time $O(mn)$, dates back to K\&quot;{o}nig's work in 1916 (here $m=nd$
is the number of edges in the graph, $2n$ is the number of vertices, and $d$ is
the degree of each node). The currently most efficient algorithm takes time
$O(m)$, and is due to Cole, Ost, and Schirra. We improve this running time to
$O(\min\{m, \frac{n^{2.5}\ln n}{d}\})$; this minimum can never be larger than
$O(n^{1.75}\sqrt{\ln n})$. We obtain this improvement by proving a uniform
sampling theorem: if we sample each edge in a $d$-regular bipartite graph
independently with a probability $p = O(\frac{n\ln n}{d^2})$ then the resulting
graph has a perfect matching with high probability. The proof involves a
decomposition of the graph into pieces which are guaranteed to have many
perfect matchings but do not have any small cuts. We then establish a
correspondence between potential witnesses to non-existence of a matching
(after sampling) in any piece and cuts of comparable size in that same piece.
Karger's sampling theorem for preserving cuts in a graph can now be adapted to
prove our uniform sampling theorem for preserving perfect matchings. Using the
$O(m\sqrt{n})$ algorithm (due to Hopcroft and Karp) for finding maximum
matchings in bipartite graphs on the sampled graph then yields the stated
running time. We also provide an infinite family of instances to show that our
uniform sampling result is tight up to poly-logarithmic factors (in fact, up to
$\ln^2 n$).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2497</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2497</id><created>2008-11-15</created><updated>2010-02-01</updated><authors><author><keyname>Aziz</keyname><forenames>Haris</forenames></author><author><keyname>Paterson</keyname><forenames>Mike</forenames></author></authors><title>Computing voting power in easy weighted voting games</title><categories>cs.GT cs.CC cs.DS</categories><comments>12 pages, Presented at the International Symposium on Combinatorial
  Optimization 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Weighted voting games are ubiquitous mathematical models which are used in
economics, political science, neuroscience, threshold logic, reliability theory
and distributed systems. They model situations where agents with variable
voting weight vote in favour of or against a decision. A coalition of agents is
winning if and only if the sum of weights of the coalition exceeds or equals a
specified quota. The Banzhaf index is a measure of voting power of an agent in
a weighted voting game. It depends on the number of coalitions in which the
agent is the difference in the coalition winning or losing. It is well known
that computing Banzhaf indices in a weighted voting game is NP-hard. We give a
comprehensive classification of weighted voting games which can be solved in
polynomial time. Among other results, we provide a polynomial
($O(k{(\frac{n}{k})}^k)$) algorithm to compute the Banzhaf indices in weighted
voting games in which the number of weight values is bounded by $k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2518</identifier>
 <datestamp>2009-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2518</id><created>2008-11-15</created><updated>2009-07-12</updated><authors><author><keyname>Bickson</keyname><forenames>Danny</forenames></author></authors><title>Gaussian Belief Propagation: Theory and Aplication</title><categories>cs.IT math.IT</categories><comments>Ph.D. Thesis, Submitted to the Senate of the Hebrew University of
  Jerusalem, October 2008. 2nd Revision: July 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The canonical problem of solving a system of linear equations arises in
numerous contexts in information theory, communication theory, and related
fields. In this contribution, we develop a solution based upon Gaussian belief
propagation (GaBP) that does not involve direct matrix inversion. The iterative
nature of our approach allows for a distributed message-passing implementation
of the solution algorithm. In the first part of this thesis, we address the
properties of the GaBP solver. We characterize the rate of convergence, enhance
its message-passing efficiency by introducing a broadcast version, discuss its
relation to classical solution methods including numerical examples. We present
a new method for forcing the GaBP algorithm to converge to the correct solution
for arbitrary column dependent matrices.
  In the second part we give five applications to illustrate the applicability
of the GaBP algorithm to very large computer networks: Peer-to-Peer rating,
linear detection, distributed computation of support vector regression,
efficient computation of Kalman filter and distributed linear programming.
Using extensive simulations on up to 1,024 CPUs in parallel using IBM Bluegene
supercomputer we demonstrate the attractiveness and applicability of the GaBP
algorithm, using real network topologies with up to millions of nodes and
hundreds of millions of communication links. We further relate to several other
algorithms and explore their connection to the GaBP algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2519</identifier>
 <datestamp>2009-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2519</id><created>2008-11-15</created><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author></authors><title>Origins of Modern Data Analysis Linked to the Beginnings and Early
  Development of Computer Science and Information Engineering</title><categories>cs.CY cs.DL</categories><comments>26 pages</comments><journal-ref>Electronic Journal for History of Probability and Statisics, Vol.
  4, no. 2, Dec. 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The history of data analysis that is addressed here is underpinned by two
themes, -- those of tabular data analysis, and the analysis of collected
heterogeneous data. &quot;Exploratory data analysis&quot; is taken as the heuristic
approach that begins with data and information and seeks underlying explanation
for what is observed or measured. I also cover some of the evolving context of
research and applications, including scholarly publishing, technology transfer
and the economic relationship of the university to society.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2525</identifier>
 <datestamp>2008-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2525</id><created>2008-11-15</created><authors><author><keyname>Loyka</keyname><forenames>Sergey</forenames></author><author><keyname>Gagnon</keyname><forenames>Francois</forenames></author></authors><title>Amendment to &quot;Performance Analysis of the V-BLAST Algorithm: An
  Analytical Approach.&quot; [1]</title><categories>cs.IT math.IT</categories><comments>rejected by IEEE Trans. Wireless Communications, but useful anyway
  (some implicit assumptions of the original paper are removed and the results
  are extended)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An analytical technique for the outage and BER analysis of the nx2 V-BLAST
algorithm with the optimal ordering has been presented in [1], including
closed-form exact expressions for average BER and outage probabilities, and
simple high-SNR approximations. The analysis in [1] is based on the following
essential approximations: 1. The SNR was defined in terms of total
after-projection signal and noise powers, and the BER was analyzed based on
their ratio. This corresponds to a non-coherent (power-wise) equal-gain
combining of both the signal and the noise, and it is not optimum since it does
not provide the maximum output SNR. 2. The definition of the total
after-projection noise power at each step ignored the fact that the
after-projection noise vector had correlated components. 3. The after-combining
noises at different steps (and hence the errors) were implicitly assumed to be
independent of each other. Under non-coherent equal-gain combining, that is not
the case. It turns out that the results in [1] hold also true without these
approximations, subject to minor modifications only. The purpose of this note
is to show this and also to extend the average BER results in [1] to the case
of BPSK-modulated V-BLAST with more than two Rx antennas (eq. 18-20).
Additionally, we emphasize that the block error rate is dominated by the first
step BER at the high-SNR mode (eq. 14 and 21).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2535</identifier>
 <datestamp>2008-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2535</id><created>2008-11-15</created><authors><author><keyname>Hunt</keyname><forenames>Harry B.</forenames></author><author><keyname>Mullin</keyname><forenames>Lenore R.</forenames></author><author><keyname>Rosenkrantz</keyname><forenames>Daniel J.</forenames></author><author><keyname>Raynolds</keyname><forenames>James E.</forenames></author></authors><title>A Transformation--Based Approach for the Design of Parallel/Distributed
  Scientific Software: the FFT</title><categories>cs.SE cs.PL</categories><comments>45 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a methodology for designing efficient parallel and distributed
scientific software. This methodology utilizes sequences of mechanizable
algebra--based optimizing transformations. In this study, we apply our
methodology to the FFT, starting from a high--level algebraic algorithm
description. Abstract multiprocessor plans are developed and refined to specify
which computations are to be done by each processor. Templates are then created
that specify the locations of computations and data on the processors, as well
as data flow among processors. Templates are developed in both the MPI and
OpenMP programming styles.
  Preliminary experiments comparing code constructed using our methodology with
code from several standard scientific libraries show that our code is often
competitive and sometimes performs better. Interestingly, our code handled a
larger range of problem sizes on one target architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2546</identifier>
 <datestamp>2008-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2546</id><created>2008-11-15</created><authors><author><keyname>Bulatov</keyname><forenames>Andrei A.</forenames></author><author><keyname>Skvortsov</keyname><forenames>Evgeny S.</forenames></author></authors><title>Phase transition for Local Search on planted SAT</title><categories>cs.DS cs.LO</categories><comments>20 pages, 3 figures, submitted to a conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Local Search algorithm (or Hill Climbing, or Iterative Improvement) is
one of the simplest heuristics to solve the Satisfiability and
Max-Satisfiability problems. It is a part of many satisfiability and
max-satisfiability solvers, where it is used to find a good starting point for
a more sophisticated heuristics, and to improve a candidate solution. In this
paper we give an analysis of Local Search on random planted 3-CNF formulas. We
show that if there is k&lt;7/6 such that the clause-to-variable ratio is less than
k ln(n) (n is the number of variables in a CNF) then Local Search whp does not
find a satisfying assignment, and if there is k&gt;7/6 such that the
clause-to-variable ratio is greater than k ln(n)$ then the local search whp
finds a satisfying assignment. As a byproduct we also show that for any
constant r there is g such that Local Search applied to a random (not
necessarily planted) 3-CNF with clause-to-variable ratio r produces an
assignment that satisfies at least gn clauses less than the maximal number of
satisfiable clauses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2551</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2551</id><created>2008-11-15</created><authors><author><keyname>Gabora</keyname><forenames>Liane</forenames></author></authors><title>Modeling Cultural Dynamics</title><categories>cs.MA cs.AI q-bio.NC</categories><comments>8 pages</comments><journal-ref>Gabora, L. (2008). Modeling cultural dynamics. Proceedings of the
  Association for the Advancement of Artificial Intelligence (AAAI) Fall
  Symposium. Nov 7-9, Arlington VA, (pp. 18-25). Menlo Park, CA: AAAI Press</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  EVOC (for EVOlution of Culture) is a computer model of culture that enables
us to investigate how various factors such as barriers to cultural diffusion,
the presence and choice of leaders, or changes in the ratio of innovation to
imitation affect the diversity and effectiveness of ideas. It consists of
neural network based agents that invent ideas for actions, and imitate
neighbors' actions. The model is based on a theory of culture according to
which what evolves through culture is not memes or artifacts, but the internal
models of the world that give rise to them, and they evolve not through a
Darwinian process of competitive exclusion but a Lamarckian process involving
exchange of innovation protocols. EVOC shows an increase in mean fitness of
actions over time, and an increase and then decrease in the diversity of
actions. Diversity of actions is positively correlated with population size and
density, and with barriers between populations. Slowly eroding borders increase
fitness without sacrificing diversity by fostering specialization followed by
sharing of fit actions. Introducing a leader that broadcasts its actions
throughout the population increases the fitness of actions but reduces
diversity of actions. Increasing the number of leaders reduces this effect.
Efforts are underway to simulate the conditions under which an agent
immigrating from one culture to another contributes new ideas while still
fitting in.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2563</identifier>
 <datestamp>2008-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2563</id><created>2008-11-16</created><authors><author><keyname>Ranjan</keyname><forenames>Rajiv</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author></authors><title>Decentralized Overlay for Federation of Enterprise Clouds</title><categories>cs.DC cs.NI</categories><comments>This article appears in Handbook of Research on Scalable Computing
  Technologies, Kuan-Ching Li, Ching-Hsien Hsu, Laurence Tianruo Yang, Jack
  Dongarra, and Hans Zima, IGI Global, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This chapter describes Aneka-Federation, a decentralized and distributed
system that combines enterprise Clouds, overlay networking, and structured
peer-to-peer techniques to create scalable wide-area networking of compute
nodes for high-throughput computing. The Aneka-Federation integrates numerous
small scale Aneka Enterprise Cloud services and nodes that are distributed over
multiple control and enterprise domains as parts of a single coordinated
resource leasing abstraction. The system is designed with the aim of making
distributed enterprise Cloud resource integration and application programming
flexible, efficient, and scalable. The system is engineered such that it:
enables seamless integration of existing Aneka Enterprise Clouds as part of
single wide-area resource leasing federation; self-organizes the system
components based on a structured peer-to-peer routing methodology; and presents
end-users with a distributed application composition environment that can
support variety of programming and execution models. This chapter describes the
design and implementation of a novel, extensible and decentralized peer-to-peer
technique that helps to discover, connect and provision the services of Aneka
Enterprise Clouds among the users who can use different programming models to
compose their applications. Evaluations of the system with applications that
are programmed using the Task and Thread execution models on top of an overlay
of Aneka Enterprise Clouds have been described here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2572</identifier>
 <datestamp>2010-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2572</id><created>2008-11-17</created><updated>2009-12-01</updated><authors><author><keyname>Cardinal</keyname><forenames>Jean</forenames></author><author><keyname>Fiorini</keyname><forenames>Samuel</forenames></author><author><keyname>Joret</keyname><forenames>Gwena&#xeb;l</forenames></author><author><keyname>Jungers</keyname><forenames>Rapha&#xeb;l M.</forenames></author><author><keyname>Munro</keyname><forenames>J. Ian</forenames></author></authors><title>An Efficient Algorithm for Partial Order Production</title><categories>cs.DS</categories><comments>Referees' comments incorporated</comments><journal-ref>SIAM J. Comput. Volume 39, Issue 7, pp. 2927-2940 (2010)</journal-ref><doi>10.1137/090759860</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of partial order production: arrange the elements of
an unknown totally ordered set T into a target partially ordered set S, by
comparing a minimum number of pairs in T. Special cases include sorting by
comparisons, selection, multiple selection, and heap construction.
  We give an algorithm performing ITLB + o(ITLB) + O(n) comparisons in the
worst case. Here, n denotes the size of the ground sets, and ITLB denotes a
natural information-theoretic lower bound on the number of comparisons needed
to produce the target partial order.
  Our approach is to replace the target partial order by a weak order (that is,
a partial order with a layered structure) extending it, without increasing the
information theoretic lower bound too much. We then solve the problem by
applying an efficient multiple selection algorithm. The overall complexity of
our algorithm is polynomial. This answers a question of Yao (SIAM J. Comput.
18, 1989).
  We base our analysis on the entropy of the target partial order, a quantity
that can be efficiently computed and provides a good estimate of the
information-theoretic lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2578</identifier>
 <datestamp>2008-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2578</id><created>2008-11-16</created><authors><author><keyname>Kirwan</keyname><forenames>Edmund</forenames></author></authors><title>Encapsulation theory: the configuration efficiency limit</title><categories>cs.SE</categories><comments>7 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper shows how maximum possible configuration efficiency of an
indefinitely large software system is constrained by chosing a fixed upper
limit to the number of program units per subsystem. It is then shown how the
configuration efficiency of an indefinitely large software system depends on
the ratio of the total number of informaiton hiding violational software units
divided by the total number of program units.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2586</identifier>
 <datestamp>2008-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2586</id><created>2008-11-16</created><authors><author><keyname>Vyalyi</keyname><forenames>M. N.</forenames></author></authors><title>On models of a nondeterministic computation</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider a nondeterministic computation by deterministic
multi-head 2-way automata having a read-only access to an auxiliary memory. The
memory contains additional data (a guess) and computation is successful iff it
is successful for some memory content. Also we consider the case of restricted
guesses in which a guess should satisfy some constraint. We show that the
standard complexity classes such as L, NL, P, NP, PSPACE can be characterized
in terms of these models of nondeterministic computation. These
characterizations differ from the well-known ones by absence of alternation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2596</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2596</id><created>2008-11-16</created><updated>2009-12-05</updated><authors><author><keyname>Morsy</keyname><forenames>Mohamed H. S.</forenames></author><author><keyname>Sowailem</keyname><forenames>Mohamad Y. S.</forenames></author><author><keyname>Shalaby</keyname><forenames>Hossam M. H.</forenames></author></authors><title>An Enhanced Mathematical Model for Performance Evaluation of Optical
  Burst Switched Networks</title><categories>cs.NI cs.PF</categories><comments>This paper has been withdrawn by the authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the authors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2609</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2609</id><created>2008-11-16</created><updated>2011-07-22</updated><authors><author><keyname>Cheraghchi</keyname><forenames>Mahdi</forenames></author></authors><title>Noise-Resilient Group Testing: Limitations and Constructions</title><categories>cs.DM cs.IT math.CO math.IT</categories><comments>Full version. A preliminary summary of this work appears (under the
  same title) in proceedings of the 17th International Symposium on
  Fundamentals of Computation Theory (FCT 2009)</comments><doi>10.1007/978-3-642-03409-1_7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study combinatorial group testing schemes for learning $d$-sparse Boolean
vectors using highly unreliable disjunctive measurements. We consider an
adversarial noise model that only limits the number of false observations, and
show that any noise-resilient scheme in this model can only approximately
reconstruct the sparse vector. On the positive side, we take this barrier to
our advantage and show that approximate reconstruction (within a satisfactory
degree of approximation) allows us to break the information theoretic lower
bound of $\tilde{\Omega}(d^2 \log n)$ that is known for exact reconstruction of
$d$-sparse vectors of length $n$ via non-adaptive measurements, by a
multiplicative factor $\tilde{\Omega}(d)$.
  Specifically, we give simple randomized constructions of non-adaptive
measurement schemes, with $m=O(d \log n)$ measurements, that allow efficient
reconstruction of $d$-sparse vectors up to $O(d)$ false positives even in the
presence of $\delta m$ false positives and $O(m/d)$ false negatives within the
measurement outcomes, for any constant $\delta &lt; 1$. We show that, information
theoretically, none of these parameters can be substantially improved without
dramatically affecting the others. Furthermore, we obtain several explicit
constructions, in particular one matching the randomized trade-off but using $m
= O(d^{1+o(1)} \log n)$ measurements. We also obtain explicit constructions
that allow fast reconstruction in time $\poly(m)$, which would be sublinear in
$n$ for sufficiently sparse vectors. The main tool used in our construction is
the list-decoding view of randomness condensers and extractors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2612</identifier>
 <datestamp>2008-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2612</id><created>2008-11-16</created><authors><author><keyname>Gebremedhin</keyname><forenames>D H</forenames></author><author><keyname>Weatherford</keyname><forenames>C A</forenames></author><author><keyname>Zhang</keyname><forenames>X</forenames></author><author><keyname>Wynn</keyname><forenames>A</forenames><suffix>III</suffix></author><author><keyname>Tanaka</keyname><forenames>G</forenames></author></authors><title>Evaluation of the matrix exponential function using finite elements in
  time</title><categories>math-ph cs.NA math.MP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The evaluation of a matrix exponential function is a classic problem of
computational linear algebra. Many different methods have been employed for its
numerical evaluation [Moler C and van Loan C 1978 SIAM Review 20 4], none of
which produce a definitive algorithm which is broadly applicable and
sufficiently accurate, as well as being reasonably fast. Herein, we employ a
method which evaulates a matrix exponential as the solution to a first-order
initial value problem in a fictitious time variable. The new aspect of the
present implementation of this method is to use finite elements in the
fictitious time variable. [Weatherford C A, Red E, and Wynn A 2002 Journal of
Molecular Structure 592 47] Then using an expansion in a properly chosen time
basis, we are able to make accurate calculations of the exponential of any
given matrix as the solution to a set of simultaneous equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2637</identifier>
 <datestamp>2008-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2637</id><created>2008-11-17</created><authors><author><keyname>Li</keyname><forenames>Lianlin</forenames></author><author><keyname>Zhang</keyname><forenames>Wenji</forenames></author><author><keyname>Xiang</keyname><forenames>Yin</forenames></author><author><keyname>Li</keyname><forenames>Fang</forenames></author></authors><title>The Design of Compressive Sensing Filter</title><categories>cs.CE cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the design of universal compressive sensing filter based on
normal filters including the lowpass, highpass, bandpass, and bandstop filters
with different cutoff frequencies (or bandwidth) has been developed to enable
signal acquisition with sub-Nyquist sampling. Moreover, to control flexibly the
size and the coherence of the compressive sensing filter, as an example, the
microstrip filter based on defected ground structure (DGS) has been employed to
realize the compressive sensing filter. Of course, the compressive sensing
filter also can be constructed along the identical idea by many other
structures, for example, the man-made electromagnetic materials, the plasma
with different electron density, and so on. By the proposed architecture, the
n-dimensional signals of S-sparse in arbitrary orthogonal frame can be exactly
reconstructed with measurements on the order of Slog(n) with overwhelming
probability, which is consistent with the bonds estimated by theoretical
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2675</identifier>
 <datestamp>2008-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2675</id><created>2008-11-17</created><authors><author><keyname>Ghosh</keyname><forenames>Shamik</forenames></author><author><keyname>Podder</keyname><forenames>Maitry</forenames></author><author><keyname>Sen</keyname><forenames>Malay K.</forenames></author></authors><title>Characterizations of probe interval graphs</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we obtain several characterizations of the adjacency matrix of
a probe interval graph. In course of this study we describe an easy method of
obtaining interval representation of an interval bipartite graph from its
adjacency matrix. Finally, we note that if we add a loop at every probe vertex
of a probe interval graph, then the Ferrers dimension of the corresponding
symmetric bipartite graph is at most 3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2690</identifier>
 <datestamp>2014-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2690</id><created>2008-11-17</created><updated>2013-10-10</updated><authors><author><keyname>Lizier</keyname><forenames>Joseph T.</forenames></author><author><keyname>Prokopenko</keyname><forenames>Mikhail</forenames></author><author><keyname>Zomaya</keyname><forenames>Albert Y.</forenames></author></authors><title>A framework for the local information dynamics of distributed
  computation in complex systems</title><categories>nlin.CG cs.IT math.IT nlin.AO nlin.PS physics.data-an</categories><comments>44 pages, 8 figures</comments><report-no>ICT 08/320</report-no><msc-class>94A15</msc-class><journal-ref>in &quot;Guided Self-Organization: Inception&quot;, edited by M. Prokopenko,
  pp. 115-158, Springer, Berlin/Heidelberg, 2014</journal-ref><doi>10.1007/978-3-642-53734-9_5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The nature of distributed computation has often been described in terms of
the component operations of universal computation: information storage,
transfer and modification. We review the first complete framework that
quantifies each of these individual information dynamics on a local scale
within a system, and describes the manner in which they interact to create
non-trivial computation where &quot;the whole is greater than the sum of the parts&quot;.
We describe the application of the framework to cellular automata, a simple yet
powerful model of distributed computation. This is an important application,
because the framework is the first to provide quantitative evidence for several
important conjectures about distributed computation in cellular automata: that
blinkers embody information storage, particles are information transfer agents,
and particle collisions are information modification events. The framework is
also shown to contrast the computations conducted by several well-known
cellular automata, highlighting the importance of information coherence in
complex computation. The results reviewed here provide important quantitative
insights into the fundamental nature of distributed computation and the
dynamics of complex systems, as well as impetus for the framework to be applied
to the analysis and design of other systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2696</identifier>
 <datestamp>2010-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2696</id><created>2008-11-17</created><updated>2009-01-30</updated><authors><author><keyname>Ilten</keyname><forenames>Nathan</forenames></author><author><keyname>S&#xfc;&#xdf;</keyname><forenames>Hendrik</forenames></author></authors><title>AG Codes from Polyhedral Divisors</title><categories>math.AG cs.IT math.IT</categories><comments>30 pages, 9 figures; v2: replaced fansy cycles with fansy divisors</comments><msc-class>14G50, 94B27, 14L30, 14C20, 52B20</msc-class><journal-ref>Journal of Symbolic Computation 45 (2010) 734</journal-ref><doi>10.1016/j.jsc.2010.03.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A description of complete normal varieties with lower dimensional torus
action has been given by Altmann, Hausen, and Suess, generalizing the theory of
toric varieties. Considering the case where the acting torus T has codimension
one, we describe T-invariant Weil and Cartier divisors and provide formulae for
calculating global sections, intersection numbers, and Euler characteristics.
As an application, we use divisors on these so-called T-varieties to define new
evaluation codes called T-codes. We find estimates on their minimum distance
using intersection theory. This generalizes the theory of toric codes and
combines it with AG codes on curves. As the simplest application of our general
techniques we look at codes on ruled surfaces coming from decomposable vector
bundles. Already this construction gives codes that are better than the related
product code. Further examples show that we can improve these codes by
constructing more sophisticated T-varieties. These results suggest to look
further for good codes on T-varieties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2731</identifier>
 <datestamp>2009-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2731</id><created>2008-11-17</created><updated>2009-04-30</updated><authors><author><keyname>Sablik</keyname><forenames>Mathieu</forenames><affiliation>LATP</affiliation></author><author><keyname>Theyssier</keyname><forenames>Guillaume</forenames><affiliation>LAMA</affiliation></author></authors><title>Topological Dynamics of Cellular Automata: Dimension Matters</title><categories>cs.DM cs.CC</categories><comments>to appear in Theory of Computing Systems (2009)</comments><proxy>ccsd hal-00339354</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Topological dynamics of cellular automata (CA), inherited from classical
dynamical systems theory, has been essentially studied in dimension 1. This
paper focuses on higher dimensional CA and aims at showing that the situation
is different and more complex starting from dimension 2. The main results are
the existence of non sensitive CA without equicontinuous points, the
non-recursivity of sensitivity constants, the existence of CA having only
non-recursive equicontinuous points and the existence of CA having only
countably many equicontinuous points. They all show a difference between
dimension 1 and higher dimensions. Thanks to these new constructions, we also
extend undecidability results concerning topological classification previously
obtained in the 1D case. Finally, we show that the set of sensitive CA is only
Pi_2 in dimension 1, but becomes Sigma_3-hard for dimension 3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2827</identifier>
 <datestamp>2011-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2827</id><created>2008-11-17</created><updated>2011-11-02</updated><authors><author><keyname>Hayashi</keyname><forenames>Yukio</forenames></author></authors><title>Evolutionary Construction of Geographical Networks with Nearly Optimal
  Robustness and Efficient Routing Properties</title><categories>physics.data-an cs.CG cs.NI physics.soc-ph</categories><comments>14 pages, 10 figures, 1 table</comments><journal-ref>Physica A 388, pp.991-998, 2009</journal-ref><doi>10.1016/j.physa.2008.11.027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robust and efficient design of networks on a realistic geographical space is
one of the important issues for the realization of dependable communication
systems. In this paper, based on a percolation theory and a geometric graph
property, we investigate such a design from the following viewpoints: 1)
network evolution according to a spatially heterogeneous population, 2)
trimodal low degrees for the tolerant connectivity against both failures and
attacks, and 3) decentralized routing within short paths. Furthermore, we point
out the weakened tolerance by geographical constraints on local cycles, and
propose a practical strategy by adding a small fraction of shortcut links
between randomly chosen nodes in order to improve the robustness to a similar
level to that of the optimal bimodal networks with a larger degree
$O(\sqrt{N})$ for the network size $N$. These properties will be useful for
constructing future ad-hoc networks in wide-area communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2841</identifier>
 <datestamp>2009-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2841</id><created>2008-11-18</created><updated>2009-03-20</updated><authors><author><keyname>Ghosh</keyname><forenames>Arpita</forenames></author><author><keyname>Roughgarden</keyname><forenames>Tim</forenames></author><author><keyname>Sundararajan</keyname><forenames>Mukund</forenames></author></authors><title>Universally Utility-Maximizing Privacy Mechanisms</title><categories>cs.DB cs.GT</categories><comments>rewritten for clarity, typos corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mechanism for releasing information about a statistical database with
sensitive data must resolve a trade-off between utility and privacy. Privacy
can be rigorously quantified using the framework of {\em differential privacy},
which requires that a mechanism's output distribution is nearly the same
whether or not a given database row is included or excluded. The goal of this
paper is strong and general utility guarantees, subject to differential
privacy.
  We pursue mechanisms that guarantee near-optimal utility to every potential
user, independent of its side information (modeled as a prior distribution over
query results) and preferences (modeled via a loss function).
  Our main result is: for each fixed count query and differential privacy
level, there is a {\em geometric mechanism} $M^*$ -- a discrete variant of the
simple and well-studied Laplace mechanism -- that is {\em simultaneously
expected loss-minimizing} for every possible user, subject to the differential
privacy constraint. This is an extremely strong utility guarantee: {\em every}
potential user $u$, no matter what its side information and preferences,
derives as much utility from $M^*$ as from interacting with a differentially
private mechanism $M_u$ that is optimally tailored to $u$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2847</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2847</id><created>2008-11-18</created><updated>2009-05-25</updated><authors><author><keyname>Chu</keyname><forenames>Kevin T.</forenames></author></authors><title>Boosting the Accuracy of Finite Difference Schemes via Optimal Time Step
  Selection and Non-Iterative Defect Correction</title><categories>math.NA cs.NA</categories><comments>33 pages, 11 figures</comments><msc-class>65-02, 65M06, 65M12, 65M20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we present a simple technique for boosting the order of
accuracy of finite difference schemes for time dependent partial differential
equations by optimally selecting the time step used to advance the numerical
solution and adding defect correction terms in a non-iterative manner. The
power of the technique is its ability to extract as much accuracy as possible
from existing finite difference schemes with minimal additional effort. Through
straightforward numerical analysis arguments, we explain the origin of the
boost in accuracy and estimate the computational cost of the resulting
numerical method. We demonstrate the utility of optimal time step (OTS)
selection combined with non-iterative defect correction (NIDC) on several
different types of finite difference schemes for a wide array of classical
linear and semilinear PDEs in one and more space dimensions on both regular and
irregular domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2850</identifier>
 <datestamp>2008-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2850</id><created>2008-11-18</created><authors><author><keyname>Dey</keyname><forenames>Bikash Kumar</forenames></author><author><keyname>Jaggi</keyname><forenames>Sidharth</forenames></author><author><keyname>Langberg</keyname><forenames>Michael</forenames></author></authors><title>Codes against Online Adversaries</title><categories>cs.IT math.IT</categories><comments>10 pages + abstract + appendix/references. Submitted to STOC 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we consider the communication of information in the presence of
an online adversarial jammer. In the setting under study, a sender wishes to
communicate a message to a receiver by transmitting a codeword x=x_1,...,x_n
symbol-by-symbol over a communication channel. The adversarial jammer can view
the transmitted symbols x_i one at a time, and can change up to a p-fraction of
them. However, the decisions of the jammer must be made in an online or causal
manner. More generally, for a delay parameter 0&lt;d&lt;1, we study the scenario in
which the jammer's decision on the corruption of x_i must depend solely on x_j
for j &lt; i - dn. In this work, we initiate the study of codes for online
adversaries, and present a tight characterization of the amount of information
one can transmit in both the 0-delay and, more generally, the d-delay online
setting. We prove tight results for both additive and overwrite jammers when
the transmitted symbols are assumed to be over a sufficiently large field F.
Finally, we extend our results to a jam-or-listen online model, where the
online adversary can either jam a symbol or eavesdrop on it. We again provide a
tight characterization of the achievable rate for several variants of this
model. The rate-regions we prove for each model are informational-theoretic in
nature and hold for computationally unbounded adversaries. The rate regions are
characterized by &quot;simple&quot; piecewise linear functions of p and d. The codes we
construct to attain the optimal rate for each scenario are computationally
efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2853</identifier>
 <datestamp>2008-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2853</id><created>2008-11-18</created><authors><author><keyname>Bayati</keyname><forenames>Mohsen</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Saberi</keyname><forenames>Amin</forenames></author></authors><title>Generating Random Graphs with Large Girth</title><categories>cs.DS cs.IT math.IT</categories><comments>10 pages, Procedings of SODA 2009, New York January 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a simple and efficient algorithm for randomly generating simple
graphs without small cycles. These graphs can be used to design high
performance Low-Density Parity -Check (LDPC) codes. For any constant k,
alpha&lt;1/2k(k+3) and m=O(n^{1+alpha}), our algorithm generate s an
asymptotically uniform random graph with n vertices, m edges, and girth larger
tha n k in polynomial time. To the best of our knowledge this is the first
polynomial-algorith m for the problem.
  Our algorithm generates a graph by sequentially adding m edges to an empty
graph with n vertices. Recently, these types of sequential methods for counting
and random generation have been very successful.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2868</identifier>
 <datestamp>2008-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2868</id><created>2008-11-18</created><authors><author><keyname>Firouzi</keyname><forenames>Hamed</forenames></author><author><keyname>Farivar</keyname><forenames>Masoud</forenames></author><author><keyname>Babaie-Zadeh</keyname><forenames>Massoud</forenames></author><author><keyname>Jutten</keyname><forenames>Christian</forenames></author></authors><title>Approximate Sparse Decomposition Based on Smoothed L0-Norm</title><categories>cs.MM cs.IT math.IT</categories><comments>4 Pages, Submitted to ICASSP 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a method to address the problem of source
estimation for Sparse Component Analysis (SCA) in the presence of additive
noise. Our method is a generalization of a recently proposed method (SL0),
which has the advantage of directly minimizing the L0-norm instead of L1-norm,
while being very fast. SL0 is based on minimization of the smoothed L0-norm
subject to As=x. In order to better estimate the source vector for noisy
mixtures, we suggest then to remove the constraint As=x, by relaxing exact
equality to an approximation (we call our method Smoothed L0-norm Denoising or
SL0DN). The final result can then be obtained by minimization of a proper
linear combination of the smoothed L0-norm and a cost function for the
approximation. Experimental results emphasize on the significant enhancement of
the modified method in noisy cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2904</identifier>
 <datestamp>2008-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2904</id><created>2008-11-18</created><authors><author><keyname>Pagh</keyname><forenames>Rasmus</forenames></author><author><keyname>Rao</keyname><forenames>S. Srinivasa</forenames></author></authors><title>Secondary Indexing in One Dimension: Beyond B-trees and Bitmap Indexes</title><categories>cs.DB cs.DS</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let S be a finite, ordered alphabet, and let x = x_1 x_2 ... x_n be a string
over S. A &quot;secondary index&quot; for x answers alphabet range queries of the form:
Given a range [a_l,a_r] over S, return the set I_{[a_l;a_r]} = {i |x_i \in
[a_l; a_r]}. Secondary indexes are heavily used in relational databases and
scientific data analysis. It is well-known that the obvious solution, storing a
dictionary for the position set associated with each character, does not always
give optimal query time. In this paper we give the first theoretically optimal
data structure for the secondary indexing problem. In the I/O model, the amount
of data read when answering a query is within a constant factor of the minimum
space needed to represent I_{[a_l;a_r]}, assuming that the size of internal
memory is (|S| log n)^{delta} blocks, for some constant delta &gt; 0. The space
usage of the data structure is O(n log |S|) bits in the worst case, and we
further show how to bound the size of the data structure in terms of the 0-th
order entropy of x. We show how to support updates achieving various time-space
trade-offs.
  We also consider an approximate version of the basic secondary indexing
problem where a query reports a superset of I_{[a_l;a_r]} containing each
element not in I_{[a_l;a_r]} with probability at most epsilon, where epsilon &gt;
0 is the false positive probability. For this problem the amount of data that
needs to be read by the query algorithm is reduced to O(|I_{[a_l;a_r]}|
log(1/epsilon)) bits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2984</identifier>
 <datestamp>2008-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2984</id><created>2008-11-18</created><authors><author><keyname>Goldsztejn</keyname><forenames>Alexandre</forenames><affiliation>LINA</affiliation></author></authors><title>Sensitivity Analysis Using a Fixed Point Interval Iteration</title><categories>cs.NA</categories><proxy>ccsd hal-00339377</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Proving the existence of a solution to a system of real equations is a
central issue in numerical analysis. In many situations, the system of
equations depend on parameters which are not exactly known. It is then natural
to aim proving the existence of a solution for all values of these parameters
in some given domains. This is the aim of the parametrization of existence
tests. A new parametric existence test based on the Hansen-Sengupta operator is
presented and compared to a similar one based on the Krawczyk operator. It is
used as a basis of a fixed point iteration dedicated to rigorous sensibility
analysis of parametric systems of equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3055</identifier>
 <datestamp>2008-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3055</id><created>2008-11-19</created><authors><author><keyname>Li</keyname><forenames>Liang</forenames></author><author><keyname>Liu</keyname><forenames>Tian</forenames></author><author><keyname>Xu</keyname><forenames>Ke</forenames></author></authors><title>Exact phase transition of backtrack-free search with implications on the
  power of greedy algorithms</title><categories>cs.AI cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Backtracking is a basic strategy to solve constraint satisfaction problems
(CSPs). A satisfiable CSP instance is backtrack-free if a solution can be found
without encountering any dead-end during a backtracking search, implying that
the instance is easy to solve. We prove an exact phase transition of
backtrack-free search in some random CSPs, namely in Model RB and in Model RD.
This is the first time an exact phase transition of backtrack-free search can
be identified on some random CSPs. Our technical results also have interesting
implications on the power of greedy algorithms, on the width of random
hypergraphs and on the exact satisfiability threshold of random CSPs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3062</identifier>
 <datestamp>2008-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3062</id><created>2008-11-19</created><authors><author><keyname>Wei</keyname><forenames>Zhewei</forenames></author><author><keyname>Yi</keyname><forenames>Ke</forenames></author><author><keyname>Zhang</keyname><forenames>Qin</forenames></author></authors><title>Dynamic External Hashing: The Limit of Buffering</title><categories>cs.DS</categories><comments>10 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hash tables are one of the most fundamental data structures in computer
science, in both theory and practice. They are especially useful in external
memory, where their query performance approaches the ideal cost of just one
disk access. Knuth gave an elegant analysis showing that with some simple
collision resolution strategies such as linear probing or chaining, the
expected average number of disk I/Os of a lookup is merely $1+1/2^{\Omega(b)}$,
where each I/O can read a disk block containing $b$ items. Inserting a new item
into the hash table also costs $1+1/2^{\Omega(b)}$ I/Os, which is again almost
the best one can do if the hash table is entirely stored on disk. However, this
assumption is unrealistic since any algorithm operating on an external hash
table must have some internal memory (at least $\Omega(1)$ blocks) to work
with. The availability of a small internal memory buffer can dramatically
reduce the amortized insertion cost to $o(1)$ I/Os for many external memory
data structures. In this paper we study the inherent query-insertion tradeoff
of external hash tables in the presence of a memory buffer. In particular, we
show that for any constant $c&gt;1$, if the query cost is targeted at
$1+O(1/b^{c})$ I/Os, then it is not possible to support insertions in less than
$1-O(1/b^{\frac{c-1}{4}})$ I/Os amortized, which means that the memory buffer
is essentially useless. While if the query cost is relaxed to $1+O(1/b^{c})$
I/Os for any constant $c&lt;1$, there is a simple dynamic hash table with $o(1)$
insertion cost. These results also answer the open question recently posed by
Jensen and Pagh.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3116</identifier>
 <datestamp>2010-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3116</id><created>2008-11-19</created><authors><author><keyname>Istrate</keyname><forenames>Gabriel</forenames></author></authors><title>Geometric properties of satisfying assignments of random
  $\epsilon$-1-in-k SAT</title><categories>cs.CC cs.DM</categories><acm-class>F.2.2; G.2</acm-class><journal-ref>International Journal of Computer Mathematics, 86(12), pp.
  2029-2039, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the geometric structure of the set of solutions of random
$\epsilon$-1-in-k SAT problem. For $l\geq 1$, two satisfying assignments $A$
and $B$ are $l$-connected if there exists a sequence of satisfying assignments
connecting them by changing at most $l$ bits at a time.
  We first prove that w.h.p. two assignments of a random $\epsilon$-1-in-$k$
SAT instance are $O(\log n)$-connected, conditional on being satisfying
assignments. Also, there exists $\epsilon_{0}\in (0,\frac{1}{k-2})$ such that
w.h.p. no two satisfying assignments at distance at least $\epsilon_{0}\cdot n$
form a &quot;hole&quot; in the set of assignments. We believe that this is true for all
$\epsilon &gt;0$, and thus satisfying assignments of a random 1-in-$k$ SAT
instance form a single cluster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3137</identifier>
 <datestamp>2008-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3137</id><created>2008-11-19</created><authors><author><keyname>Winget</keyname><forenames>Megan A.</forenames></author><author><keyname>Murray</keyname><forenames>Caitlin</forenames></author></authors><title>Collecting and Preserving Videogames and Their Related Materials: A
  Review of Current Practice, Game-Related Archives and Research Projects</title><categories>cs.DL</categories><comments>9 pages, 0 figures, ASIS&amp;T Conference Paper</comments><acm-class>H.3.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reviews the major methods and theories regarding the preservation
of new media artifacts such as videogames, and argues for the importance of
collecting and coming to a better understanding of videogame artifacts of
creation, which will help build a more detailed understanding of the essential
qualities of these culturally significant artifacts. We will also review the
major videogame collections in the United States, Europe and Japan to give an
idea of the current state of videogame archives, and argue for a fuller, more
comprehensive coverage of these materials in institutional repositories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3140</identifier>
 <datestamp>2008-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3140</id><created>2008-11-19</created><authors><author><keyname>Hansen</keyname><forenames>Michael</forenames></author><author><keyname>Laros</keyname><forenames>Jeroen F. J.</forenames></author></authors><title>Desynched channels on IRCnet</title><categories>cs.NI cs.CR</categories><comments>13 pages, 3 figures, 2 algorithms</comments><acm-class>C.2.2; C.2.4; C.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe what a desynchronised channel on IRC is. We give
procedures on how to create such a channel and how to remove desynchronisation.
We explain which types of desynchronisation there are, what properties
desynchronised channels have, and which properties can be exploited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3161</identifier>
 <datestamp>2008-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3161</id><created>2008-11-19</created><authors><author><keyname>Saxena</keyname><forenames>Nitin</forenames></author><author><keyname>Seshadhri</keyname><forenames>C.</forenames></author></authors><title>An Almost Optimal Rank Bound for Depth-3 Identities</title><categories>cs.CC</categories><comments>25 pages, preliminary version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the rank of a depth-3 circuit (over any field) that is simple,
minimal and zero is at most k^3\log d. The previous best rank bound known was
2^{O(k^2)}(\log d)^{k-2} by Dvir and Shpilka (STOC 2005). This almost resolves
the rank question first posed by Dvir and Shpilka (as we also provide a simple
and minimal identity of rank \Omega(k\log d)).
  Our rank bound significantly improves (dependence on k exponentially reduced)
the best known deterministic black-box identity tests for depth-3 circuits by
Karnin and Shpilka (CCC 2008). Our techniques also shed light on the
factorization pattern of nonzero depth-3 circuits, most strikingly: the rank of
linear factors of a simple, minimal and nonzero depth-3 circuit (over any
field) is at most k^3\log d.
  The novel feature of this work is a new notion of maps between sets of linear
forms, called &quot;ideal matchings&quot;, used to study depth-3 circuits. We prove
interesting structural results about depth-3 identities using these techniques.
We believe that these can lead to the goal of a deterministic polynomial time
identity test for these circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3165</identifier>
 <datestamp>2009-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3165</id><created>2008-11-19</created><updated>2009-02-08</updated><authors><author><keyname>Ivanyos</keyname><forenames>G&#xe1;bor</forenames></author><author><keyname>Karpinski</keyname><forenames>Marek</forenames></author><author><keyname>R&#xf3;nyai</keyname><forenames>Lajos</forenames></author><author><keyname>Saxena</keyname><forenames>Nitin</forenames></author></authors><title>Trading GRH for algebra: algorithms for factoring polynomials and
  related structures</title><categories>cs.CC cs.SC</categories><comments>35 pages, preliminary version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we develop techniques that eliminate the need of the
Generalized Riemann Hypothesis (GRH) from various (almost all) known results
about deterministic polynomial factoring over finite fields. Our main result
shows that given a polynomial f(x) of degree n over a finite field k, we can
find in deterministic poly(n^{\log n},\log |k|) time &quot;either&quot; a nontrivial
factor of f(x) &quot;or&quot; a nontrivial automorphism of k[x]/(f(x)) of order n. This
main tool leads to various new GRH-free results, most striking of which are:
  (1) Given a noncommutative algebra over a finite field, we can find a zero
divisor in deterministic subexponential time.
  (2) Given a positive integer r such that either 8|r or r has at least two
distinct odd prime factors. There is a deterministic polynomial time algorithm
to find a nontrivial factor of the r-th cyclotomic polynomial over a finite
field.
  In this paper, following the seminal work of Lenstra (1991) on constructing
isomorphisms between finite fields, we further generalize classical Galois
theory constructs like cyclotomic extensions, Kummer extensions, Teichmuller
subgroups, to the case of commutative semisimple algebras with automorphisms.
These generalized constructs help eliminate the dependence on GRH.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3176</identifier>
 <datestamp>2008-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3176</id><created>2008-11-19</created><authors><author><keyname>Hoch</keyname><forenames>Ezra N.</forenames></author><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author></authors><title>Self-stabilizing Numerical Iterative Computation</title><categories>cs.DC</categories><journal-ref>In the 10th International Symposium on Stabilization, Safety, and
  Security of Distributed Systems (SSS '08), Detriot, Nov. 2008</journal-ref><doi>10.1007/978-3-540-89335-6_9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many challenging tasks in sensor networks, including sensor calibration,
ranking of nodes, monitoring, event region detection, collaborative filtering,
collaborative signal processing, {\em etc.}, can be formulated as a problem of
solving a linear system of equations. Several recent works propose different
distributed algorithms for solving these problems, usually by using linear
iterative numerical methods.
  In this work, we extend the settings of the above approaches, by adding
another dimension to the problem. Specifically, we are interested in {\em
self-stabilizing} algorithms, that continuously run and converge to a solution
from any initial state. This aspect of the problem is highly important due to
the dynamic nature of the network and the frequent changes in the measured
environment.
  In this paper, we link together algorithms from two different domains. On the
one hand, we use the rich linear algebra literature of linear iterative methods
for solving systems of linear equations, which are naturally distributed with
rapid convergence properties. On the other hand, we are interested in
self-stabilizing algorithms, where the input to the computation is constantly
changing, and we would like the algorithms to converge from any initial state.
We propose a simple novel method called \syncAlg as a self-stabilizing variant
of the linear iterative methods. We prove that under mild conditions the
self-stabilizing algorithm converges to a desired result. We further extend
these results to handle the asynchronous case.
  As a case study, we discuss the sensor calibration problem and provide
simulation results to support the applicability of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3208</identifier>
 <datestamp>2013-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3208</id><created>2008-11-19</created><updated>2009-11-24</updated><authors><author><keyname>Roetteler</keyname><forenames>Martin</forenames></author></authors><title>Quantum algorithms for highly non-linear Boolean functions</title><categories>quant-ph cs.CC</categories><comments>15 pages, 1 figure, to appear in Proceedings of the 21st Annual
  ACM-SIAM Symposium on Discrete Algorithms (SODA'10). This updated version of
  the paper contains a new exponential separation between classical and quantum
  query complexity</comments><journal-ref>Proceedings of the 21st Annual ACM-SIAM Symposium on Discrete
  Algorithms (SODA'10), pp. 448-457, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Attempts to separate the power of classical and quantum models of computation
have a long history. The ultimate goal is to find exponential separations for
computational problems. However, such separations do not come a dime a dozen:
while there were some early successes in the form of hidden subgroup problems
for abelian groups--which generalize Shor's factoring algorithm perhaps most
faithfully--only for a handful of non-abelian groups efficient quantum
algorithms were found. Recently, problems have gotten increased attention that
seek to identify hidden sub-structures of other combinatorial and algebraic
objects besides groups. In this paper we provide new examples for exponential
separations by considering hidden shift problems that are defined for several
classes of highly non-linear Boolean functions. These so-called bent functions
arise in cryptography, where their property of having perfectly flat Fourier
spectra on the Boolean hypercube gives them resilience against certain types of
attack. We present new quantum algorithms that solve the hidden shift problems
for several well-known classes of bent functions in polynomial time and with a
constant number of queries, while the classical query complexity is shown to be
exponential. Our approach uses a technique that exploits the duality between
bent functions and their Fourier transforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3231</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3231</id><created>2008-11-19</created><updated>2008-11-28</updated><authors><author><keyname>Danvy</keyname><forenames>Olivier</forenames></author><author><keyname>Millikin</keyname><forenames>Kevin</forenames></author></authors><title>A Rational Deconstruction of Landin's SECD Machine with the J Operator</title><categories>cs.PL cs.LO</categories><acm-class>D.1.1, D.3.3, F.1.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 4 (November
  29, 2008) lmcs:1112</journal-ref><doi>10.2168/LMCS-4(4:12)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Landin's SECD machine was the first abstract machine for applicative
expressions, i.e., functional programs. Landin's J operator was the first
control operator for functional languages, and was specified by an extension of
the SECD machine. We present a family of evaluation functions corresponding to
this extension of the SECD machine, using a series of elementary
transformations (transformation into continu-ation-passing style (CPS) and
defunctionalization, chiefly) and their left inverses (transformation into
direct style and refunctionalization). To this end, we modernize the SECD
machine into a bisimilar one that operates in lockstep with the original one
but that (1) does not use a data stack and (2) uses the caller-save rather than
the callee-save convention for environments. We also identify that the dump
component of the SECD machine is managed in a callee-save way. The caller-save
counterpart of the modernized SECD machine precisely corresponds to Thielecke's
double-barrelled continuations and to Felleisen's encoding of J in terms of
call/cc. We then variously characterize the J operator in terms of CPS and in
terms of delimited-control operators in the CPS hierarchy. As a byproduct, we
also present several reduction semantics for applicative expressions with the J
operator, based on Curien's original calculus of explicit substitutions. These
reduction semantics mechanically correspond to the modernized versions of the
SECD machine and to the best of our knowledge, they provide the first syntactic
theories of applicative expressions with the J operator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3233</identifier>
 <datestamp>2009-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3233</id><created>2008-11-19</created><authors><author><keyname>Currie</keyname><forenames>James</forenames></author><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author></authors><title>Cubefree words with many squares</title><categories>math.CO cs.FL</categories><comments>6 pages</comments><msc-class>68R15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct infinite cubefree binary words containing exponentially many
distinct squares of length n. We also show that for every positive integer n,
there is a cubefree binary square of length 2n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3244</identifier>
 <datestamp>2008-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3244</id><created>2008-11-19</created><authors><author><keyname>Karpinski</keyname><forenames>Marek</forenames></author><author><keyname>Schudy</keyname><forenames>Warren</forenames></author></authors><title>Linear Time Approximation Schemes for the Gale-Berlekamp Game and
  Related Minimization Problems</title><categories>cs.DS cs.DM</categories><comments>18 pages LaTeX, 2 figures</comments><acm-class>F.2.2; G.2.1; G.2.2; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design a linear time approximation scheme for the Gale-Berlekamp Switching
Game and generalize it to a wider class of dense fragile minimization problems
including the Nearest Codeword Problem (NCP) and Unique Games Problem. Further
applications include, among other things, finding a constrained form of matrix
rigidity and maximum likelihood decoding of an error correcting code. As
another application of our method we give the first linear time approximation
schemes for correlation clustering with a fixed number of clusters and its
hierarchical generalization. Our results depend on a new technique for dealing
with small objective function values of optimization problems and could be of
independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3247</identifier>
 <datestamp>2008-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3247</id><created>2008-11-19</created><authors><author><keyname>Codenotti</keyname><forenames>Bruno</forenames></author><author><keyname>De Rossi</keyname><forenames>Stefano</forenames></author><author><keyname>Pagan</keyname><forenames>Marino</forenames></author></authors><title>An experimental analysis of Lemke-Howson algorithm</title><categories>cs.DS cs.NA</categories><comments>15 pages, 18 figures. The source code of our implementation can be
  found at http://allievi.sssup.it/game/index.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an experimental investigation of the performance of the
Lemke-Howson algorithm, which is the most widely used algorithm for the
computation of a Nash equilibrium for bimatrix games. Lemke-Howson algorithm is
based upon a simple pivoting strategy, which corresponds to following a path
whose endpoint is a Nash equilibrium. We analyze both the basic Lemke-Howson
algorithm and a heuristic modification of it, which we designed to cope with
the effects of a 'bad' initial choice of the pivot. Our experimental findings
show that, on uniformly random games, the heuristics achieves a linear running
time, while the basic Lemke-Howson algorithm runs in time roughly proportional
to a polynomial of degree seven. To conduct the experiments, we have developed
our own implementation of Lemke-Howson algorithm, which turns out to be
significantly faster than state-of-the-art software. This allowed us to run the
algorithm on a much larger set of data, and on instances of much larger size,
compared with previous work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3272</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3272</id><created>2008-11-20</created><updated>2009-09-25</updated><authors><author><keyname>Sydney</keyname><forenames>Ali</forenames></author><author><keyname>Scoglio</keyname><forenames>Caterina</forenames></author><author><keyname>Youssef</keyname><forenames>Mina</forenames></author><author><keyname>Schumm</keyname><forenames>Phillip</forenames></author></authors><title>Characterizing the Robustness of Complex Networks</title><categories>cs.NI cs.PF physics.data-an</categories><comments>This paper serves as a replacement to its predecessor</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With increasingly ambitious initiatives such as GENI and FIND that seek to
design the future Internet, it becomes imperative to define the characteristics
of robust topologies, and build future networks optimized for robustness. This
paper investigates the characteristics of network topologies that maintain a
high level of throughput in spite of multiple attacks. To this end, we select
network topologies belonging to the main network models and some real world
networks. We consider three types of attacks: removal of random nodes, high
degree nodes, and high betweenness nodes. We use elasticity as our robustness
measure and, through our analysis, illustrate that different topologies can
have different degrees of robustness. In particular, elasticity can fall as low
as 0.8% of the upper bound based on the attack employed. This result
substantiates the need for optimized network topology design. Furthermore, we
implement a tradeoff function that combines elasticity under the three attack
strategies and considers the cost of the network. Our extensive simulations
show that, for a given network density, regular and semi-regular topologies can
have higher degrees of robustness than heterogeneous topologies, and that link
redundancy is a sufficient but not necessary condition for robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3284</identifier>
 <datestamp>2008-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3284</id><created>2008-11-20</created><updated>2008-12-10</updated><authors><author><keyname>Avin</keyname><forenames>Chen</forenames><affiliation>Department of Communication Systems Engineering, Ben Gurion University, Israel</affiliation></author><author><keyname>Emek</keyname><forenames>Yuval</forenames><affiliation>Department of Computer Science and Applied Mathematics, Weizmann Institute of Science, Israel</affiliation></author><author><keyname>Kantor</keyname><forenames>Erez</forenames><affiliation>Department of Computer Science and Applied Mathematics, Weizmann Institute of Science, Israel</affiliation></author><author><keyname>Lotker</keyname><forenames>Zvi</forenames><affiliation>Department of Communication Systems Engineering, Ben Gurion University, Israel</affiliation></author><author><keyname>Peleg</keyname><forenames>David</forenames><affiliation>Department of Computer Science and Applied Mathematics, Weizmann Institute of Science, Israel</affiliation></author><author><keyname>Roditty</keyname><forenames>Liam</forenames><affiliation>Department of Computer Science, Bar Ilan University, Israel</affiliation></author></authors><title>SINR Diagrams: Towards Algorithmically Usable SINR Models of Wireless
  Networks</title><categories>cs.NI cs.DC</categories><comments>34 pages, 17 Figures</comments><acm-class>C.2.1; F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rules governing the availability and quality of connections in a wireless
network are described by physical models such as the signal-to-interference &amp;
noise ratio (SINR) model. For a collection of simultaneously transmitting
stations in the plane, it is possible to identify a reception zone for each
station, consisting of the points where its transmission is received correctly.
The resulting SINR diagram partitions the plane into a reception zone per
station and the remaining plane where no station can be heard.
  SINR diagrams appear to be fundamental to understanding the behavior of
wireless networks, and may play a key role in the development of suitable
algorithms for such networks, analogous perhaps to the role played by Voronoi
diagrams in the study of proximity queries and related issues in computational
geometry. So far, however, the properties of SINR diagrams have not been
studied systematically, and most algorithmic studies in wireless networking
rely on simplified graph-based models such as the unit disk graph (UDG) model,
which conveniently abstract away interference-related complications, and make
it easier to handle algorithmic issues, but consequently fail to capture
accurately some important aspects of wireless networks.
  The current paper focuses on obtaining some basic understanding of SINR
diagrams, their properties and their usability in algorithmic applications.
Specifically, based on some algebraic properties of the polynomials defining
the reception zones we show that assuming uniform power transmissions, the
reception zones are convex and relatively well-rounded. These results are then
used to develop an efficient approximation algorithm for a fundamental point
location problem in wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3301</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3301</id><created>2008-11-20</created><updated>2009-06-10</updated><authors><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author></authors><title>Faster Retrieval with a Two-Pass Dynamic-Time-Warping Lower Bound</title><categories>cs.DB cs.CV</categories><comments>Accepted in Pattern Recognition on November 20th, 2008</comments><journal-ref>Daniel Lemire, Faster Retrieval with a Two-Pass
  Dynamic-Time-Warping Lower Bound, Pattern Recognition 42(9): 2169-2180 (2009)</journal-ref><doi>10.1016/j.patcog.2008.11.030</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Dynamic Time Warping (DTW) is a popular similarity measure between time
series. The DTW fails to satisfy the triangle inequality and its computation
requires quadratic time. Hence, to find closest neighbors quickly, we use
bounding techniques. We can avoid most DTW computations with an inexpensive
lower bound (LB Keogh). We compare LB Keogh with a tighter lower bound (LB
Improved). We find that LB Improved-based search is faster. As an example, our
approach is 2-3 times faster over random-walk and shape time series.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3328</identifier>
 <datestamp>2008-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3328</id><created>2008-11-20</created><authors><author><keyname>Bogevolnov</keyname><forenames>Justislav</forenames></author></authors><title>chi2TeX Semi-automatic translation from chiwriter to LaTeX</title><categories>cs.SE cs.CV</categories><comments>8 pages, 8 figures in Russian</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semi-automatic translation of math-filled book from obsolete ChiWriter format
to LaTeX. Is it possible? Idea of criterion whether to use automatic or hand
mode for translation. Illustrations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3373</identifier>
 <datestamp>2008-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3373</id><created>2008-11-20</created><authors><author><keyname>Grabisch</keyname><forenames>Michel</forenames><affiliation>CERMSEM, Ces</affiliation></author></authors><title>Belief functions on lattices</title><categories>cs.DM</categories><proxy>ccsd hal-00340378</proxy><journal-ref>International Journal of Intelligent Systems (2009) 1-20</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the notion of belief function to the case where the underlying
structure is no more the Boolean lattice of subsets of some universal set, but
any lattice, which we will endow with a minimal set of properties according to
our needs. We show that all classical constructions and definitions (e.g., mass
allocation, commonality function, plausibility functions, necessity measures
with nested focal elements, possibility distributions, Dempster rule of
combination, decomposition w.r.t. simple support functions, etc.) remain valid
in this general setting. Moreover, our proof of decomposition of belief
functions into simple support functions is much simpler and general than the
original one by Shafer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3387</identifier>
 <datestamp>2009-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3387</id><created>2008-11-20</created><updated>2009-05-25</updated><authors><author><keyname>W&#xe4;hlisch</keyname><forenames>Matthias</forenames></author><author><keyname>Schmidt</keyname><forenames>Thomas C.</forenames></author><author><keyname>Wittenburg</keyname><forenames>Georg</forenames></author></authors><title>Broadcasting in Prefix Space: P2P Data Dissemination with Predictable
  Performance</title><categories>cs.NI cs.PF</categories><comments>final version for ICIW'09</comments><acm-class>C.2.1; C.2.2; C.2.4; C.4</acm-class><journal-ref>Matthias W\&quot;ahlisch, Thomas C. Schmidt, and Georg Wittenburg,
  &quot;Broadcasting in Prefix Space: P2P Data Dissemination with Predictable
  Performance,&quot; in Proc. of the Fourth ICIW: IEEE ComSoc Press, 2009, pp. 74-83</journal-ref><doi>10.1109/ICIW.2009.19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A broadcast mode may augment peer-to-peer overlay networks with an efficient,
scalable data replication function, but may also give rise to a virtual link
layer in VPN-type solutions. We introduce a simple broadcasting mechanism that
operates in the prefix space of distributed hash tables without signaling. This
paper concentrates on the performance analysis of the prefix flooding scheme.
Starting from simple models of recursive $k$-ary trees, we analytically derive
distributions of hop counts and the replication load. Extensive simulation
results are presented further on, based on an implementation within the OverSim
framework. Comparisons are drawn to Scribe, taken as a general reference model
for group communication according to the shared, rendezvous-point-centered
distribution paradigm. The prefix flooding scheme thereby confirmed its widely
predictable performance and consistently outperformed Scribe in all metrics.
Reverse path selection in overlays is identified as a major cause of
performance degradation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3400</identifier>
 <datestamp>2008-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3400</id><created>2008-11-20</created><authors><author><keyname>Duval</keyname><forenames>Dominique</forenames><affiliation>LMC - IMAG, LJK, NMST</affiliation></author><author><keyname>Echahed</keyname><forenames>Rachid</forenames><affiliation>LIG, Leibniz - IMAG, IMAG</affiliation></author><author><keyname>Prost</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LIG</affiliation></author></authors><title>A Cloning Pushout Approach to Term-Graph Transformation</title><categories>cs.LO</categories><proxy>ccsd hal-00340202</proxy><acm-class>F.4.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of cyclic termgraph rewriting. We propose a new
framework where rewrite rules are tuples of the form $(L,R,\tau,\sigma)$ such
that $L$ and $R$ are termgraphs representing the left-hand and the right-hand
sides of the rule, $\tau$ is a mapping from the nodes of $L$ to those of $R$
and $\sigma$ is a partial function from nodes of $R$ to nodes of $L$. $\tau$
describes how incident edges of the nodes in $L$ are connected in $R$. $\tau$
is not required to be a graph morphism as in classical algebraic approaches of
graph transformation. The role of $\sigma$ is to indicate the parts of $L$ to
be cloned (copied). Furthermore, we introduce a new notion of \emph{cloning
pushout} and define rewrite steps as cloning pushouts in a given category.
Among the features of the proposed rewrite systems, we quote the ability to
perform local and global redirection of pointers, addition and deletion of
nodes as well as cloning and collapsing substructures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3448</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3448</id><created>2008-11-20</created><updated>2011-05-17</updated><authors><author><keyname>Gilreath</keyname><forenames>William F.</forenames></author></authors><title>Binar Sort: A Linear Generalized Sorting Algorithm</title><categories>cs.DS</categories><comments>PDF from Word, 25-pages, 2-figures, 4-diagrams, version 2.0</comments><acm-class>B.2.4; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sorting is a common and ubiquitous activity for computers. It is not
surprising that there exist a plethora of sorting algorithms. For all the
sorting algorithms, it is an accepted performance limit that sorting algorithms
are linearithmic or O(N lg N). The linearithmic lower bound in performance
stems from the fact that the sorting algorithms use the ordering property of
the data. The sorting algorithm uses comparison by the ordering property to
arrange the data elements from an initial permutation into a sorted
permutation.
  Linear O(N) sorting algorithms exist, but use a priori knowledge of the data
to use a specific property of the data and thus have greater performance. In
contrast, the linearithmic sorting algorithms are generalized by using a
universal property of data-comparison, but have a linearithmic performance
lower bound. The trade-off in sorting algorithms is generality for performance
by the chosen property used to sort the data elements.
  A general-purpose, linear sorting algorithm in the context of the trade-off
of performance for generality at first consideration seems implausible. But,
there is an implicit assumption that only the ordering property is universal.
But, as will be discussed and examined, it is not the only universal property
for data elements. The binar sort is a general-purpose sorting algorithm that
uses this other universal property to sort linearly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3449</identifier>
 <datestamp>2008-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3449</id><created>2008-11-20</created><authors><author><keyname>Gilreath</keyname><forenames>William F.</forenames></author></authors><title>Binar Shuffle Algorithm: Shuffling Bit by Bit</title><categories>cs.DS</categories><comments>27-pages, watermarked</comments><acm-class>B.2.4; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frequently, randomly organized data is needed to avoid an anomalous operation
of other algorithms and computational processes. An analogy is that a deck of
cards is ordered within the pack, but before a game of poker or solitaire the
deck is shuffled to create a random permutation. Shuffling is used to assure
that an aggregate of data elements for a sequence S is randomly arranged, but
avoids an ordered or partially ordered permutation.
  Shuffling is the process of arranging data elements into a random
permutation. The sequence S as an aggregation of N data elements, there are N!
possible permutations. For the large number of possible permutations, two of
the possible permutations are for a sorted or ordered placement of data
elements--both an ascending and descending sorted permutation. Shuffling must
avoid inadvertently creating either an ascending or descending permutation.
  Shuffling is frequently coupled to another algorithmic function --
pseudo-random number generation. The efficiency and quality of the shuffle is
directly dependent upon the random number generation algorithm utilized. A more
effective and efficient method of shuffling is to use parameterization to
configure the shuffle, and to shuffle into sub-arrays by utilizing the encoding
of the data elements. The binar shuffle algorithm uses the encoding of the data
elements and parameterization to avoid any direct coupling to a random number
generation algorithm, but still remain a linear O(N) shuffle algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3475</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3475</id><created>2008-11-21</created><updated>2010-04-26</updated><authors><author><keyname>Wang</keyname><forenames>Da</forenames></author><author><keyname>Silva</keyname><forenames>Danilo</forenames></author><author><keyname>Kschischang</keyname><forenames>Frank R.</forenames></author></authors><title>Robust Network Coding in the Presence of Untrusted Nodes</title><categories>cs.IT cs.NI math.IT</categories><comments>7 pages, 4 figures, to be published at the IEEE Transactions on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While network coding can be an efficient means of information dissemination
in networks, it is highly susceptible to &quot;pollution attacks,&quot; as the injection
of even a single erroneous packet has the potential to corrupt each and every
packet received by a given destination. Even when suitable error-control coding
is applied, an adversary can, in many interesting practical situations,
overwhelm the error-correcting capability of the code. To limit the power of
potential adversaries, a broadcast transformation is introduced, in which nodes
are limited to just a single (broadcast) transmission per generation. Under
this broadcast transformation, the multicast capacity of a network is changed
(in general reduced) from the number of edge-disjoint paths between source and
sink to the number of internally-disjoint paths. Exploiting this fact, we
propose a family of networks whose capacity is largely unaffected by a
broadcast transformation. This results in a significant achievable transmission
rate for such networks, even in the presence of adversaries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3476</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3476</id><created>2008-11-21</created><updated>2010-01-16</updated><authors><author><keyname>Cousseau</keyname><forenames>Florent</forenames></author><author><keyname>Mimura</keyname><forenames>Kazushi</forenames></author><author><keyname>Okada</keyname><forenames>Masato</forenames></author></authors><title>Error correcting code using tree-like multilayer perceptron</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.IT math.IT</categories><comments>23 pages, 3 figures, Content has been extended and revised</comments><journal-ref>Phys. Rev. E, 81, 021104 (2010)</journal-ref><doi>10.1103/PhysRevE.81.021104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An error correcting code using a tree-like multilayer perceptron is proposed.
An original message $\mbi{s}^0$ is encoded into a codeword $\boldmath{y}_0$
using a tree-like committee machine (committee tree) or a tree-like parity
machine (parity tree). Based on these architectures, several schemes featuring
monotonic or non-monotonic units are introduced. The codeword $\mbi{y}_0$ is
then transmitted via a Binary Asymmetric Channel (BAC) where it is corrupted by
noise. The analytical performance of these schemes is investigated using the
replica method of statistical mechanics. Under some specific conditions, some
of the proposed schemes are shown to saturate the Shannon bound at the infinite
codeword length limit. The influence of the monotonicity of the units on the
performance is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3479</identifier>
 <datestamp>2008-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3479</id><created>2008-11-21</created><authors><author><keyname>Ghosh</keyname><forenames>Shamik</forenames></author></authors><title>Counting number of factorizations of a natural number</title><categories>cs.DM math.NT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we describe a new method of counting the number of unordered
factorizations of a natural number by means of a generating function and a
recurrence relation arising from it, which improves an earlier result in this
direction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3490</identifier>
 <datestamp>2011-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3490</id><created>2008-11-21</created><updated>2011-03-17</updated><authors><author><keyname>Bille</keyname><forenames>Philip</forenames></author></authors><title>Faster Approximate String Matching for Short Patterns</title><categories>cs.DS</categories><comments>To appear in Theory of Computing Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the classical approximate string matching problem, that is, given
strings $P$ and $Q$ and an error threshold $k$, find all ending positions of
substrings of $Q$ whose edit distance to $P$ is at most $k$. Let $P$ and $Q$
have lengths $m$ and $n$, respectively. On a standard unit-cost word RAM with
word size $w \geq \log n$ we present an algorithm using time $$ O(nk \cdot
\min(\frac{\log^2 m}{\log n},\frac{\log^2 m\log w}{w}) + n) $$ When $P$ is
short, namely, $m = 2^{o(\sqrt{\log n})}$ or $m = 2^{o(\sqrt{w/\log w})}$ this
improves the previously best known time bounds for the problem. The result is
achieved using a novel implementation of the Landau-Vishkin algorithm based on
tabulation and word-level parallelism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3492</identifier>
 <datestamp>2008-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3492</id><created>2008-11-21</created><authors><author><keyname>Groenewegen</keyname><forenames>L. P. J.</forenames></author><author><keyname>de Vink</keyname><forenames>E. P.</forenames></author></authors><title>Dynamic System Adaptation by Constraint Orchestration</title><categories>cs.SE</categories><comments>19 pages</comments><report-no>CSR 08/29</report-no><acm-class>D.2.11; F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For Paradigm models, evolution is just-in-time specified coordination
conducted by a special reusable component McPal. Evolution can be treated
consistently and on-the-fly through Paradigm's constraint orchestration, also
for originally unforeseen evolution. UML-like diagrams visually supplement such
migration, as is illustrated for the case of a critical section solution
evolving into a pipeline architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3521</identifier>
 <datestamp>2008-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3521</id><created>2008-11-21</created><authors><author><keyname>Brillout</keyname><forenames>Angelo</forenames></author><author><keyname>Kroening</keyname><forenames>Daniel</forenames></author><author><keyname>Wahl</keyname><forenames>Thomas</forenames></author></authors><title>Craig Interpolation for Quantifier-Free Presburger Arithmetic</title><categories>cs.LO cs.SC</categories><comments>15 pages, 1 algorithm, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Craig interpolation has become a versatile algorithmic tool for improving
software verification. Interpolants can, for instance, accelerate the
convergence of fixpoint computations for infinite-state systems. They also help
improve the refinement of iteratively computed lazy abstractions. Efficient
interpolation procedures have been presented only for a few theories. In this
paper, we introduce a complete interpolation method for the full range of
quantifier-free Presburger arithmetic formulas. We propose a novel convex
variable projection for integer inequalities and a technique to combine them
with equalities. The derivation of the interpolant has complexity low-degree
polynomial in the size of the refutation proof and is typically fast in
practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3536</identifier>
 <datestamp>2008-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3536</id><created>2008-11-21</created><authors><author><keyname>Pashkevich</keyname><forenames>Anatoly</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Analyse de la rigidit\'e des machines outils 3 axes d'architecture
  parall\`ele hyperstatique</title><categories>cs.RO</categories><proxy>ccsd hal-00340626</proxy><journal-ref>5eme Assises Machines et Usinage \`a grande vitesse, Nantes :
  France (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents a new stiffness modelling method for overconstrained
parallel manipulators, which is applied to 3-d.o.f. translational mechanisms.
It is based on a multidimensional lumped-parameter model that replaces the link
flexibility by localized 6-d.o.f. virtual springs. In contrast to other works,
the method includes a FEA-based link stiffness evaluation and employs a new
solution strategy of the kinetostatic equations, which allows computing the
stiffness matrix for the overconstrained architectures and for the singular
manipulator postures. The advantages of the developed technique are confirmed
by application examples, which deal with comparative stiffness analysis of two
translational parallel manipulators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3585</identifier>
 <datestamp>2008-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3585</id><created>2008-11-21</created><authors><author><keyname>Mhatre</keyname><forenames>Vivek P.</forenames></author><author><keyname>Rosenberg</keyname><forenames>Catherine P.</forenames></author><author><keyname>Mazumdar</keyname><forenames>Ravi R.</forenames></author></authors><title>The Capacity of Ad hoc Networks under Random Packet Losses</title><categories>cs.IT cs.NI math.IT</categories><comments>12 pages, earlier version in ISIT 2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of determining asymptotic bounds on the capacity of a
random ad hoc network. Previous approaches assumed a link layer model in which
if a transmitter-receiver pair can communicate with each other, i.e., the
Signal to Interference and Noise Ratio (SINR) is above a certain threshold,
then every transmitted packet is received error-free by the receiver thereby.
Using this model, the per node capacity of the network was shown to be
$\Theta(\frac{1}{\sqrt{n\log{n}}})$. In reality, for any finite link SINR,
there is a non-zero probability of erroneous reception of the packet. We show
that in a large network, as the packet travels an asymptotically large number
of hops from source to destination, the cumulative impact of packet losses over
intermediate links results in a per-node throughput of only $O(\frac{1}{n})$.
We then propose a new scheduling scheme to counter this effect. The proposed
scheme provides tight guarantees on end-to-end packet loss probability, and
improves the per-node throughput to $\Omega(\frac{1}{\sqrt{n}
({\log{n}})^{\frac{\alpha{{+2}}}{2(\alpha-2)}}})$ where $\alpha&gt;2$ is the path
loss exponent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3602</identifier>
 <datestamp>2008-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3602</id><created>2008-11-21</created><authors><author><keyname>Gagie</keyname><forenames>Travis</forenames></author><author><keyname>Karpinski</keyname><forenames>Marek</forenames></author><author><keyname>Nekrich</keyname><forenames>Yakov</forenames></author></authors><title>Low-Memory Adaptive Prefix Coding</title><categories>cs.DS</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the adaptive prefix coding problem in cases where the
size of the input alphabet is large. We present an online prefix coding
algorithm that uses $O(\sigma^{1 / \lambda + \epsilon}) $ bits of space for any
constants $\eps&gt;0$, $\lambda&gt;1$, and encodes the string of symbols in $O(\log
\log \sigma)$ time per symbol \emph{in the worst case}, where $\sigma$ is the
size of the alphabet. The upper bound on the encoding length is $\lambda n H
(s) +(\lambda \ln 2 + 2 + \epsilon) n + O (\sigma^{1 / \lambda} \log^2 \sigma)$
bits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3617</identifier>
 <datestamp>2015-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3617</id><created>2008-11-21</created><updated>2011-05-12</updated><authors><author><keyname>Misra</keyname><forenames>Vinith</forenames></author><author><keyname>Goyal</keyname><forenames>Vivek K</forenames></author><author><keyname>Varshney</keyname><forenames>Lav R.</forenames></author></authors><title>Distributed Scalar Quantization for Computing: High-Resolution Analysis
  and Extensions</title><categories>cs.IT math.IT</categories><comments>36 pages, 10 figures</comments><journal-ref>IEEE Trans. on Information Theory, vol. 57, no. 8, pp. 5298-5325,
  August 2011</journal-ref><doi>10.1109/TIT.2011.2158882</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communication of quantized information is frequently followed by a
computation. We consider situations of \emph{distributed functional scalar
quantization}: distributed scalar quantization of (possibly correlated) sources
followed by centralized computation of a function. Under smoothness conditions
on the sources and function, companding scalar quantizer designs are developed
to minimize mean-squared error (MSE) of the computed function as the quantizer
resolution is allowed to grow. Striking improvements over quantizers designed
without consideration of the function are possible and are larger in the
entropy-constrained setting than in the fixed-rate setting. As extensions to
the basic analysis, we characterize a large class of functions for which
regular quantization suffices, consider certain functions for which asymptotic
optimality is achieved without arbitrarily fine quantization, and allow limited
collaboration between source encoders. In the entropy-constrained setting, a
single bit per sample communicated between encoders can have an
arbitrarily-large effect on functional distortion. In contrast, such
communication has very little effect in the fixed-rate setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3620</identifier>
 <datestamp>2008-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3620</id><created>2008-11-21</created><authors><author><keyname>Treinen</keyname><forenames>Ralf</forenames><affiliation>PPS</affiliation></author><author><keyname>Zacchiroli</keyname><forenames>Stefano</forenames><affiliation>PPS</affiliation></author></authors><title>Solving package dependencies: from EDOS to Mancoosi</title><categories>cs.SE</categories><proxy>ccsd hal-00340581</proxy><journal-ref>DebConf8, Argentine (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mancoosi (Managing the Complexity of the Open Source Infrastructure) is an
ongoing research project funded by the European Union for addressing some of
the challenges related to the &quot;upgrade problem&quot; of interdependent software
components of which Debian packages are prototypical examples. Mancoosi is the
natural continuation of the EDOS project which has already contributed tools
for distribution-wide quality assurance in Debian and other GNU/Linux
distributions. The consortium behind the project consists of several European
public and private research institutions as well as some commercial GNU/Linux
distributions from Europe and South America. Debian is represented by a small
group of Debian Developers who are working in the ranks of the involved
universities to drive and integrate back achievements into Debian. This paper
presents relevant results from EDOS in dependency management and gives an
overview of the Mancoosi project and its objectives, with a particular focus on
the prospective benefits for Debian.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3621</identifier>
 <datestamp>2008-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3621</id><created>2008-11-21</created><authors><author><keyname>Treinen</keyname><forenames>Ralf</forenames><affiliation>PPS</affiliation></author><author><keyname>Zacchiroli</keyname><forenames>Stefano</forenames><affiliation>PPS</affiliation></author></authors><title>Description of the CUDF Format</title><categories>cs.SE</categories><proxy>ccsd hal-00340678</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document contains several related specifications, together they describe
the document formats related to the solver competition which will be organized
by Mancoosi. In particular, this document describes: - DUDF (Distribution
Upgradeability Description Format), the document format to be used to submit
upgrade problem instances from user machines to a (distribution-specific)
database of upgrade problems; - CUDF (Common Upgradeability Description
Format), the document format used to encode upgrade problems, abstracting over
distribution-specific details. Solvers taking part in the competition will be
fed with input in CUDF format.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3648</identifier>
 <datestamp>2009-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3648</id><created>2008-11-21</created><updated>2009-04-08</updated><authors><author><keyname>Kane</keyname><forenames>Daniel M.</forenames></author><author><keyname>Nelson</keyname><forenames>Jelani</forenames></author><author><keyname>Woodruff</keyname><forenames>David P.</forenames></author></authors><title>Revisiting Norm Estimation in Data Streams</title><categories>cs.DS cs.CC</categories><comments>added content; modified L_0 algorithm -- ParityLogEstimator in
  version 1 contained an error, and the new algorithm uses slightly more space</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of estimating the pth moment F_p (p nonnegative and real) in data
streams is as follows. There is a vector x which starts at 0, and many updates
of the form x_i &lt;-- x_i + v come sequentially in a stream. The algorithm also
receives an error parameter 0 &lt; eps &lt; 1. The goal is then to output an
approximation with relative error at most eps to F_p = ||x||_p^p.
  Previously, it was known that polylogarithmic space (in the vector length n)
was achievable if and only if p &lt;= 2. We make several new contributions in this
regime, including:
  (*) An optimal space algorithm for 0 &lt; p &lt; 2, which, unlike previous
algorithms which had optimal dependence on 1/eps but sub-optimal dependence on
n, does not rely on a generic pseudorandom generator.
  (*) A near-optimal space algorithm for p = 0 with optimal update and query
time.
  (*) A near-optimal space algorithm for the &quot;distinct elements&quot; problem (p = 0
and all updates have v = 1) with optimal update and query time.
  (*) Improved L_2 --&gt; L_2 dimensionality reduction in a stream.
  (*) New 1-pass lower bounds to show optimality and near-optimality of our
algorithms, as well as of some previous algorithms (the &quot;AMS sketch&quot; for p = 2,
and the L_1-difference algorithm of Feigenbaum et al.).
  As corollaries of our work, we also obtain a few separations in the
complexity of moment estimation problems: F_0 in 1 pass vs. 2 passes, p = 0 vs.
p &gt; 0, and F_0 with strictly positive updates vs. arbitrary updates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3691</identifier>
 <datestamp>2008-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3691</id><created>2008-11-22</created><authors><author><keyname>Gomez</keyname><forenames>Leticia</forenames></author><author><keyname>Kuijpers</keyname><forenames>Bart</forenames></author><author><keyname>Vaisman</keyname><forenames>Alejandro</forenames></author></authors><title>Temporal Support of Regular Expressions in Sequential Pattern Mining</title><categories>cs.DB</categories><comments>15 pages, 2 figures</comments><acm-class>H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classic algorithms for sequential pattern discovery, return all frequent
sequences present in a database, but, in general, only a few ones are
interesting for the user. Languages based on regular expressions (RE) have been
proposed to restrict frequent sequences to the ones that satisfy user-specified
constraints. Although the support of a sequence is computed as the number of
data-sequences satisfying a pattern with respect to the total number of
data-sequences in the database, once regular expressions come into play, new
approaches to the concept of support are needed. For example, users may be
interested in computing the support of the RE as a whole, in addition to the
one of a particular pattern. Also, when the items are frequently updated, the
traditional way of counting support in sequential pattern mining may lead to
incorrect (or, at least incomplete), conclusions. The problem gets more
involved if we are interested in categorical sequential patterns. In light of
the above, in this paper we propose to revise the classic notion of support in
sequential pattern mining, introducing the concept of temporal support of
regular expressions, intuitively defined as the number of sequences satisfying
a target pattern, out of the total number of sequences that could have possibly
matched such pattern, where the pattern is defined as a RE over complex items
(i.e., not only item identifiers, but also attributes and functions).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3704</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3704</id><created>2008-11-22</created><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>LIP, Elm</affiliation></author></authors><title>Highly Undecidable Problems about Recognizability by Tiling Systems</title><categories>cs.CC cs.LO math.LO</categories><comments>to appear in a Special Issue of the journal Fundamenta Informaticae
  on Machines, Computations and Universality</comments><proxy>ccsd ensl-00340791</proxy><journal-ref>Fundamenta Informaticae 2, 91 (2009) 305-323</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Altenbernd, Thomas and W\&quot;ohrle have considered acceptance of languages of
infinite two-dimensional words (infinite pictures) by finite tiling systems,
with usual acceptance conditions, such as the B\&quot;uchi and Muller ones [1]. It
was proved in [9] that it is undecidable whether a B\&quot;uchi-recognizable
language of infinite pictures is E-recognizable (respectively, A-recognizable).
We show here that these two decision problems are actually $\Pi_2^1$-complete,
hence located at the second level of the analytical hierarchy, and &quot;highly
undecidable&quot;. We give the exact degree of numerous other undecidable problems
for B\&quot;uchi-recognizable languages of infinite pictures. In particular, the
non-emptiness and the infiniteness problems are $\Sigma^1_1$-complete, and the
universality problem, the inclusion problem, the equivalence problem, the
determinizability problem, the complementability problem, are all
$\Pi^1_2$-complete. It is also $\Pi^1_2$-complete to determine whether a given
B\&quot;uchi recognizable language of infinite pictures can be accepted row by row
using an automaton model over ordinal words of length $\omega^2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3712</identifier>
 <datestamp>2008-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3712</id><created>2008-11-22</created><authors><author><keyname>Wu</keyname><forenames>Kui</forenames></author><author><keyname>Jiang</keyname><forenames>Yuming</forenames></author><author><keyname>Hu</keyname><forenames>Guoqiang</forenames></author></authors><title>Performance Modeling and Evaluation for Information-Driven Networks</title><categories>cs.PF cs.NI</categories><comments>14 pages</comments><acm-class>C.4; H.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information-driven networks include a large category of networking systems,
where network nodes are aware of information delivered and thus can not only
forward data packets but may also perform information processing. In many
situations, the quality of service (QoS) in information-driven networks is
provisioned with the redundancy in information. Traditional performance models
generally adopt evaluation measures suitable for packet-oriented service
guarantee, such as packet delay, throughput, and packet loss rate. These
performance measures, however, do not align well with the actual need of
information-driven networks. New performance measures and models for
information-driven networks, despite their importance, have been mainly blank,
largely because information processing is clearly application dependent and
cannot be easily captured within a generic framework. To fill the vacancy, we
present a new performance evaluation framework particularly tailored for
information-driven networks, based on the recent development of stochastic
network calculus. We analyze the QoS with respect to information delivery and
study the scheduling problem with the new performance metrics. Our analytical
framework can be used to calculate the network capacity in information delivery
and in the meantime to help transmission scheduling for a large body of systems
where QoS is stochastically guaranteed with the redundancy in information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3723</identifier>
 <datestamp>2008-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3723</id><created>2008-11-22</created><authors><author><keyname>Xiao</keyname><forenames>Mingyu</forenames></author><author><keyname>Cai</keyname><forenames>Leizhen</forenames></author><author><keyname>Yao</keyname><forenames>Andrew C.</forenames></author></authors><title>Tight Approximation Ratio of a General Greedy Splitting Algorithm for
  the Minimum k-Way Cut Problem</title><categories>cs.DS cs.DM</categories><comments>12 pages</comments><acm-class>G.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For an edge-weighted connected undirected graph, the minimum $k$-way cut
problem is to find a subset of edges of minimum total weight whose removal
separates the graph into $k$ connected components. The problem is NP-hard when
$k$ is part of the input and W[1]-hard when $k$ is taken as a parameter.
  A simple algorithm for approximating a minimum $k$-way cut is to iteratively
increase the number of components of the graph by $h-1$, where $2 \le h \le k$,
until the graph has $k$ components. The approximation ratio of this algorithm
is known for $h \le 3$ but is open for $h \ge 4$.
  In this paper, we consider a general algorithm that iteratively increases the
number of components of the graph by $h_i-1$, where $h_1 \le h_2 \le ... \le
h_q$ and $\sum_{i=1}^q (h_i-1) = k-1$. We prove that the approximation ratio of
this general algorithm is $2 - (\sum_{i=1}^q {h_i \choose 2})/{k \choose 2}$,
which is tight. Our result implies that the approximation ratio of the simple
algorithm is $2-h/k + O(h^2/k^2)$ in general and $2-h/k$ if $k-1$ is a multiple
of $h-1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3760</identifier>
 <datestamp>2008-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3760</id><created>2008-11-23</created><authors><author><keyname>Devismes</keyname><forenames>St&#xe9;phane</forenames><affiliation>LIP6</affiliation></author><author><keyname>Masuzawa</keyname><forenames>Toshimitsu</forenames><affiliation>LIP6</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6</affiliation></author></authors><title>Communication Efficiency in Self-stabilizing Silent Protocols</title><categories>cs.DS cs.CC cs.DC cs.NI</categories><proxy>ccsd inria-00340805</proxy><report-no>RR-6731</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-stabilization is a general paradigm to provide forward recovery
capabilities to distributed systems and networks. Intuitively, a protocol is
self-stabilizing if it is able to recover without external intervention from
any catastrophic transient failure. In this paper, our focus is to lower the
communication complexity of self-stabilizing protocols \emph{below} the need of
checking every neighbor forever. In more details, the contribution of the paper
is threefold: (i) We provide new complexity measures for communication
efficiency of self-stabilizing protocols, especially in the stabilized phase or
when there are no faults, (ii) On the negative side, we show that for
non-trivial problems such as coloring, maximal matching, and maximal
independent set, it is impossible to get (deterministic or probabilistic)
self-stabilizing solutions where every participant communicates with less than
every neighbor in the stabilized phase, and (iii) On the positive side, we
present protocols for coloring, maximal matching, and maximal independent set
such that a fraction of the participants communicates with exactly one neighbor
in the stabilized phase.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3777</identifier>
 <datestamp>2008-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3777</id><created>2008-11-23</created><authors><author><keyname>Nelson</keyname><forenames>Kenric P.</forenames></author><author><keyname>Umarov</keyname><forenames>Sabir</forenames></author></authors><title>The Relationship between Tsallis Statistics, the Fourier Transform, and
  Nonlinear Coupling</title><categories>cs.IT math.IT math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tsallis statistics (or q-statistics) in nonextensive statistical mechanics is
a one-parameter description of correlated states. In this paper we use a
translated entropic index: $1 - q \to q$ . The essence of this translation is
to improve the mathematical symmetry of the q-algebra and make q directly
proportional to the nonlinear coupling. A conjugate transformation is defined
$\hat q \equiv \frac{{- 2q}}{{2 + q}}$ which provides a dual mapping between
the heavy-tail q-Gaussian distributions, whose translated q parameter is
between $ - 2 &lt; q &lt; 0$, and the compact-support q-Gaussians, between $0 &lt; q &lt;
\infty $ . This conjugate transformation is used to extend the definition of
the q-Fourier transform to the domain of compact support. A conjugate q-Fourier
transform is proposed which transforms a q-Gaussian into a conjugate $\hat q$
-Gaussian, which has the same exponential decay as the Fourier transform of a
power-law function. The nonlinear statistical coupling is defined such that the
conjugate pair of q-Gaussians have equal strength but either couple
(compact-support) or decouple (heavy-tail) the statistical states. Many of the
nonextensive entropy applications can be shown to have physical parameters
proportional to the nonlinear statistical coupling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3779</identifier>
 <datestamp>2008-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3779</id><created>2008-11-23</created><authors><author><keyname>Andersen</keyname><forenames>Reid</forenames></author><author><keyname>Peres</keyname><forenames>Yuval</forenames></author></authors><title>Finding Sparse Cuts Locally Using Evolving Sets</title><categories>cs.DS</categories><comments>20 pages, no figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A {\em local graph partitioning algorithm} finds a set of vertices with small
conductance (i.e. a sparse cut) by adaptively exploring part of a large graph
$G$, starting from a specified vertex. For the algorithm to be local, its
complexity must be bounded in terms of the size of the set that it outputs,
with at most a weak dependence on the number $n$ of vertices in $G$. Previous
local partitioning algorithms find sparse cuts using random walks and
personalized PageRank. In this paper, we introduce a randomized local
partitioning algorithm that finds a sparse cut by simulating the {\em
volume-biased evolving set process}, which is a Markov chain on sets of
vertices. We prove that for any set of vertices $A$ that has conductance at
most $\phi$, for at least half of the starting vertices in $A$ our algorithm
will output (with probability at least half), a set of conductance
$O(\phi^{1/2} \log^{1/2} n)$. We prove that for a given run of the algorithm,
the expected ratio between its computational complexity and the volume of the
set that it outputs is $O(\phi^{-1/2} polylog(n))$. In comparison, the best
previous local partitioning algorithm, due to Andersen, Chung, and Lang, has
the same approximation guarantee, but a larger ratio of $O(\phi^{-1}
polylog(n))$ between the complexity and output volume. Using our local
partitioning algorithm as a subroutine, we construct a fast algorithm for
finding balanced cuts. Given a fixed value of $\phi$, the resulting algorithm
has complexity $O((m+n\phi^{-1/2}) polylog(n))$ and returns a cut with
conductance $O(\phi^{1/2} \log^{1/2} n)$ and volume at least $v_{\phi}/2$,
where $v_{\phi}$ is the largest volume of any set with conductance at most
$\phi$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3782</identifier>
 <datestamp>2009-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3782</id><created>2008-11-23</created><updated>2009-09-02</updated><authors><author><keyname>Ziegler</keyname><forenames>Martin</forenames></author></authors><title>Real Computation with Least Discrete Advice: A Complexity Theory of
  Nonuniform Computability</title><categories>cs.CC math.LO</categories><comments>added Sections 5.1 and 5.2</comments><acm-class>F.1.1; F.2.1; F.4.1; H.1.1; G.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is folklore particularly in numerical and computer sciences that, instead
of solving some general problem f:A-&gt;B, additional structural information about
the input x in A (that is any kind of promise that x belongs to a certain
subset A' of A) should be taken advantage of. Some examples from real number
computation show that such discrete advice can even make the difference between
computability and uncomputability. We turn this into a both topological and
combinatorial complexity theory of information, investigating for several
practical problems how much advice is necessary and sufficient to render them
computable.
  Specifically, finding a nontrivial solution to a homogeneous linear equation
A*x=0 for a given singular real NxN-matrix A is possible when knowing
rank(A)=0,1,...,N-1; and we show this to be best possible. Similarly,
diagonalizing (i.e. finding a BASIS of eigenvectors of) a given real symmetric
NxN-matrix is possible when knowing the number of distinct eigenvalues: an
integer between 1 and N (the latter corresponding to the nondegenerate case).
And again we show that N-fold (i.e. roughly log N bits of) additional
information is indeed necessary in order to render this problem (continuous
and) computable; whereas for finding SOME SINGLE eigenvector of A, providing
the truncated binary logarithm of the least-dimensional eigenspace of A--i.e.
Theta(log N)-fold advice--is sufficient and optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3816</identifier>
 <datestamp>2009-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3816</id><created>2008-11-24</created><updated>2009-02-05</updated><authors><author><keyname>Alagoz</keyname><forenames>B. Baykant</forenames></author></authors><title>Adaptive Fault Masking With Incoherence Scoring</title><categories>cs.OH</categories><journal-ref>OncuBilim Algorithm And systems Lab, Vol.8,No:1,(2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An adaptive voting algorithm for digital media was introduced in this study.
Availability was improved by incoherence scoring in voting mechanism of
Multi-Modular Redundancy. Regulation parameters give the algorithm flexibility
of adjusting priorities in decision process. Proposed adaptive voting algorithm
was shown to be more aware of fault status of redundant modules
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3828</identifier>
 <datestamp>2008-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3828</id><created>2008-11-24</created><authors><author><keyname>Soldo</keyname><forenames>Fabio</forenames></author><author><keyname>Markopoulou</keyname><forenames>Athina</forenames></author><author><keyname>Argyraki</keyname><forenames>Katerina</forenames></author></authors><title>Optimal Filtering of Malicious IP Sources</title><categories>cs.NI</categories><comments>submitted to Infocom 09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How can we protect the network infrastructure from malicious traffic, such as
scanning, malicious code propagation, and distributed denial-of-service (DDoS)
attacks? One mechanism for blocking malicious traffic is filtering: access
control lists (ACLs) can selectively block traffic based on fields of the IP
header. Filters (ACLs) are already available in the routers today but are a
scarce resource because they are stored in the expensive ternary content
addressable memory (TCAM).
  In this paper, we develop, for the first time, a framework for studying
filter selection as a resource allocation problem. Within this framework, we
study five practical cases of source address/prefix filtering, which correspond
to different attack scenarios and operator's policies. We show that filter
selection optimization leads to novel variations of the multidimensional
knapsack problem and we design optimal, yet computationally efficient,
algorithms to solve them. We also evaluate our approach using data from
Dshield.org and demonstrate that it brings significant benefits in practice.
Our set of algorithms is a building block that can be immediately used by
operators and manufacturers to block malicious traffic in a cost-efficient way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3859</identifier>
 <datestamp>2008-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3859</id><created>2008-11-24</created><authors><author><keyname>V.</keyname><forenames>Raghavendra Rao B.</forenames></author><author><keyname>Sarma</keyname><forenames>Jayalal M. N.</forenames></author></authors><title>On the Complexity of Matroid Isomorphism Problem</title><categories>cs.CC</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We study the complexity of testing if two given matroids are isomorphic. The
problem is easily seen to be in $\Sigma_2^p$. In the case of linear matroids,
which are represented over polynomially growing fields, we note that the
problem is unlikely to be $\Sigma_2^p$-complete and is $\co\NP$-hard. We show
that when the rank of the matroid is bounded by a constant, linear matroid
isomorphism, and matroid isomorphism are both polynomial time many-one
equivalent to graph isomorphism. We give a polynomial time Turing reduction
from graphic matroid isomorphism problem to the graph isomorphism problem.
Using this, we are able to show that graphic matroid isomorphism testing for
planar graphs can be done in deterministic polynomial time. We then give a
polynomial time many-one reduction from bounded rank matroid isomorphism
problem to graphic matroid isomorphism, thus showing that all the above
problems are polynomial time equivalent. Further, for linear and graphic
matroids, we prove that the automorphism problem is polynomial time equivalent
to the corresponding isomorphism problems. In addition, we give a polynomial
time membership test algorithm for the automorphism group of a graphic matroid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3887</identifier>
 <datestamp>2009-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3887</id><created>2008-11-24</created><updated>2009-03-05</updated><authors><author><keyname>Lozano</keyname><forenames>Angel</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author></authors><title>Transmit Diversity v. Spatial Multiplexing in Modern MIMO Systems</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Wireless Communications (revised Feb. 2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A contemporary perspective on the tradeoff between transmit antenna diversity
and spatial multiplexing is provided. It is argued that, in the context of most
modern wireless systems and for the operating points of interest, transmission
techniques that utilize all available spatial degrees of freedom for
multiplexing outperform techniques that explicitly sacrifice spatial
multiplexing for diversity. In the context of such systems, therefore, there
essentially is no decision to be made between transmit antenna diversity and
spatial multiplexing in MIMO communication. Reaching this conclusion, however,
requires that the channel and some key system features be adequately modeled
and that suitable performance metrics be adopted; failure to do so may bring
about starkly different conclusions. As a specific example, this contrast is
illustrated using the 3GPP Long-Term Evolution system design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3958</identifier>
 <datestamp>2008-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3958</id><created>2008-11-24</created><authors><author><keyname>Musatov</keyname><forenames>Daniil</forenames></author></authors><title>Extractors and an efficient variant of Muchnik's theorem</title><categories>cs.CC</categories><comments>37 pages, in Russian</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Muchnik's theorem about simple conditional descriprion states that for all
words $a$ and $b$ there exists a short program $p$ transforming $a$ to $b$ that
has the least possible length and is simple conditional on $b$. This paper
presents a new proof of this theorem, based on extractors. Employing the
extractor technique, two new versions of Muchnik's theorem for space- and
time-bounded Kolmogorov complexity are proven.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3959</identifier>
 <datestamp>2008-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3959</id><created>2008-11-24</created><authors><author><keyname>Herman</keyname><forenames>Grzegorz</forenames></author><author><keyname>Soltys</keyname><forenames>Michael</forenames></author></authors><title>A polytime proof of correctness of the Rabin-Miller algorithm from
  Fermat's little theorem</title><categories>cs.CC cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although a deterministic polytime algorithm for primality testing is now
known, the Rabin-Miller randomized test of primality continues being the most
efficient and widely used algorithm.
  We prove the correctness of the Rabin-Miller algorithm in the theory V1 for
polynomial time reasoning, from Fermat's little theorem. This is interesting
because the Rabin-Miller algorithm is a polytime randomized algorithm, which
runs in the class RP (i.e., the class of polytime Monte-Carlo algorithms), with
a sampling space exponential in the length of the binary encoding of the input
number. (The class RP contains polytime P.) However, we show how to express the
correctness in the language of V1, and we also show that we can prove the
formula expressing correctness with polytime reasoning from Fermat's Little
theorem, which is generally expected to be independent of V1.
  Our proof is also conceptually very basic in the sense that we use the
extended Euclid's algorithm, for computing greatest common divisors, as the
main workhorse of the proof. For example, we make do without proving the
Chinese Reminder theorem, which is used in the standard proofs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3975</identifier>
 <datestamp>2008-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3975</id><created>2008-11-24</created><authors><author><keyname>Bertrand</keyname><forenames>Nathalie</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Genest</keyname><forenames>Blaise</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Gimbert</keyname><forenames>Hugo</forenames><affiliation>LaBRI</affiliation></author></authors><title>Determinacy and Decidability of Reachability Games with Partial
  Observation on Both Sides</title><categories>cs.GT</categories><proxy>ccsd hal-00341288</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove two determinacy and decidability results about two-players
stochastic reachability games with partial observation on both sides and
finitely many states, signals and actions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3978</identifier>
 <datestamp>2013-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3978</id><created>2008-11-24</created><updated>2013-11-19</updated><authors><author><keyname>Gimbert</keyname><forenames>Hugo</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Horn</keyname><forenames>Florian</forenames><affiliation>LIAFA</affiliation></author></authors><title>Optimal Strategies in Perfect-Information Stochastic Games with Tail
  Winning Conditions</title><categories>cs.GT</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that optimal strategies exist in every perfect-information
stochastic game with finitely many states and actions and a tail winning
condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4007</identifier>
 <datestamp>2008-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4007</id><created>2008-11-24</created><authors><author><keyname>Jampani</keyname><forenames>Krishnam Raju</forenames></author><author><keyname>Lubiw</keyname><forenames>Anna</forenames></author></authors><title>The Simultaneous Membership Problem for Chordal, Comparability and
  Permutation graphs</title><categories>cs.DM cs.DS</categories><comments>15 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce the 'simultaneous membership problem', defined for
any graph class C characterized in terms of representations, e.g. any class of
intersection graphs. Two graphs G_1 and G_2, sharing some vertices X (and the
corresponding induced edges), are said to be 'simultaneous members' of graph
class C, if there exist representations R_1 and R_2 of G_1 and G_2 that are
&quot;consistent&quot; on X. Equivalently (for the classes C that we consider) there
exist edges E' between G_1-X and G_2-X such that G_1 \cup G_2 \cup E' belongs
to class C.
  Simultaneous membership problems have application in any situation where it
is desirable to consistently represent two related graphs, for example:
interval graphs capturing overlaps of DNA fragments of two similar organisms;
or graphs connected in time, where one is an updated version of the other.
Simultaneous membership problems are related to simultaneous planar embeddings,
graph sandwich problems and probe graph recognition problems.
  In this paper we give efficient algorithms for the simultaneous membership
problem on chordal, comparability and permutation graphs. These results imply
that graph sandwich problems for the above classes are tractable for an
interesting special case: when the set of optional edges form a complete
bipartite graph. Our results complement the recent polynomial time recognition
algorithms for probe chordal, comparability, and permutation graphs, where the
set of optional edges form a clique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4030</identifier>
 <datestamp>2008-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4030</id><created>2008-11-25</created><authors><author><keyname>Xie</keyname><forenames>Bike</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author><author><keyname>Wesel</keyname><forenames>Richard D.</forenames></author></authors><title>Analytical Framework for Optimizing Weighted Average Download Time in
  Peer-to-Peer Networks</title><categories>cs.NI</categories><comments>12 pages, 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an analytical framework for peer-to-peer (P2P) networks
and introduces schemes for building P2P networks to approach the minimum
weighted average download time (WADT). In the considered P2P framework, the
server, which has the information of all the download bandwidths and upload
bandwidths of the peers, minimizes the weighted average download time by
determining the optimal transmission rate from the server to the peers and from
the peers to the other peers. This paper first defines the static P2P network,
the hierarchical P2P network and the strictly hierarchical P2P network. Any
static P2P network can be decomposed into an equivalent network of sub-peers
that is strictly hierarchical. This paper shows that convex optimization can
minimize the WADT for P2P networks by equivalently minimizing the WADT for
strictly hierarchical networks of sub-peers. This paper then gives an upper
bound for minimizing WADT by constructing a hierarchical P2P network, and lower
bound by weakening the constraints of the convex problem. Both the upper bound
and the lower bound are very tight. This paper also provides several suboptimal
solutions for minimizing the WADT for strictly hierarchical networks, in which
peer selection algorithms and chunk selection algorithm can be locally
designed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4033</identifier>
 <datestamp>2008-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4033</id><created>2008-11-25</created><authors><author><keyname>Van</keyname><forenames>Vo Tam</forenames></author><author><keyname>Matsui</keyname><forenames>Hajime</forenames></author><author><keyname>Mita</keyname><forenames>Seiichi</forenames></author></authors><title>Computation of Grobner basis for systematic encoding of generalized
  quasi-cyclic codes</title><categories>cs.IT cs.DM math.AC math.IT</categories><comments>1 column, 36 pages, 7 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generalized quasi-cyclic (GQC) codes form a wide and useful class of linear
codes that includes thoroughly quasi-cyclic codes, finite geometry (FG) low
density parity check (LDPC) codes, and Hermitian codes. Although it is known
that the systematic encoding of GQC codes is equivalent to the division
algorithm in the theory of Grobner basis of modules, there has been no
algorithm that computes Grobner basis for all types of GQC codes. In this
paper, we propose two algorithms to compute Grobner basis for GQC codes from
their parity check matrices: echelon canonical form algorithm and transpose
algorithm. Both algorithms require sufficiently small number of finite-field
operations with the order of the third power of code-length. Each algorithm has
its own characteristic; the first algorithm is composed of elementary methods,
and the second algorithm is based on a novel formula and is faster than the
first one for high-rate codes. Moreover, we show that a serial-in serial-out
encoder architecture for FG LDPC codes is composed of linear feedback shift
registers with the size of the linear order of code-length; to encode a binary
codeword of length n, it takes less than 2n adder and 2n memory elements.
Keywords: automorphism group, Buchberger's algorithm, division algorithm,
circulant matrix, finite geometry low density parity check (LDPC) codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4040</identifier>
 <datestamp>2008-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4040</id><created>2008-11-25</created><authors><author><keyname>Sydney</keyname><forenames>Ali</forenames></author><author><keyname>Scoglio</keyname><forenames>Caterina</forenames></author><author><keyname>Schumm</keyname><forenames>Phillip</forenames></author><author><keyname>Kooij</keyname><forenames>Robert</forenames></author></authors><title>ELASTICITY: Topological Characterization of Robustness in Complex
  Networks</title><categories>cs.NI physics.data-an</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Just as a herd of animals relies on its robust social structure to survive in
the wild, similarly robustness is a crucial characteristic for the survival of
a complex network under attack. The capacity to measure robustness in complex
networks defines the resolve of a network to maintain functionality in the
advent of classical component failures and at the onset of cryptic malicious
attacks. To date, robustness metrics are deficient and unfortunately the
following dilemmas exist: accurate models necessitate complex analysis while
conversely, simple models lack applicability to our definition of robustness.
In this paper, we define robustness and present a novel metric, elasticity- a
bridge between accuracy and complexity-a link in the chain of network
robustness. Additionally, we explore the performance of elasticity on Internet
topologies and online social networks, and articulate results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4061</identifier>
 <datestamp>2008-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4061</id><created>2008-11-25</created><updated>2008-11-25</updated><authors><author><keyname>Pipin</keyname><forenames>Valery V.</forenames></author></authors><title>Benchmarking the solar dynamo with Maxima</title><categories>cs.SE cs.SC</categories><comments>8 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Jouve et al(A&amp;A, 2008) published the paper that presents the
numerical benchmark for the solar dynamo models. Here, I would like to show a
way how to get it with help of computer algebra system Maxima. This way was
used in our paper (Pipin &amp; Seehafer, A&amp;A 2008, in print) to test some new ideas
in the large-scale stellar dynamos. In the present paper I complement the
dynamo benchmark with the standard test that address the problem of the
free-decay modes in the sphere which is submerged in vacuum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4089</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4089</id><created>2008-11-25</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>Interval greedoids and families of local maximum stable sets of graphs</title><categories>math.CO cs.DM</categories><comments>13 pages, 11 figures</comments><msc-class>05C69, 05B35 (Primary); 51D10, 90C27 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A maximum stable set in a graph G is a stable set of maximum cardinality. S
is a local maximum stable set of G, if S is a maximum stable set of the
subgraph induced by its closed neighborhood.
  Nemhauser and Trotter Jr. proved in 1975 that any local maximum stable set is
a subset of a maximum stable set of G. In 2002 we showed that the family of all
local maximum stable sets of a forest forms a greedoid on its vertex set. The
cases where G is bipartite, triangle-free, well-covered, while the family of
all local maximum stable sets is a greedoid, were analyzed in 2004, 2007, and
2008, respectively.
  In this paper we demonstrate that if the family of all local maximum stable
sets of the graph satisfies the accessibility property, then it is an interval
greedoid. We also characterize those graphs whose families of local maximum
stable sets are either antimatroids or matroids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4121</identifier>
 <datestamp>2008-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4121</id><created>2008-11-25</created><authors><author><keyname>K</keyname><forenames>Sankar</forenames></author><author><keyname>AV</keyname><forenames>Sarad</forenames></author></authors><title>String Art: Circle Drawing Using Straight Lines</title><categories>cs.GR cs.OH</categories><comments>12 pages, code included</comments><acm-class>I.3.3</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  An algorithm to generate the locus of a circle using the intersection points
of straight lines is proposed. The pixels on the circle are plotted independent
of one another and the operations involved in finding the locus of the circle
from the intersection of straight lines are parallelizable. Integer only
arithmetic and algorithmic optimizations are used for speedup. The proposed
algorithm makes use of an envelope to form a parabolic arc which is consequent
transformed into a circle. The use of parabolic arcs for the transformation
results in higher pixel errors as the radius of the circle to be drawn
increases. At its current state, the algorithm presented may be suitable only
for generating circles for string art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4138</identifier>
 <datestamp>2008-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4138</id><created>2008-11-25</created><authors><author><keyname>Mazurczyk</keyname><forenames>Wojciech</forenames></author><author><keyname>Lubacz</keyname><forenames>Jozef</forenames></author></authors><title>LACK - a VoIP Steganographic Method</title><categories>cs.CR cs.MM</categories><comments>13 pages, 11 figures, final version of this paper will be published
  in Springer's Telecommunication Systems Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents a new steganographic method called LACK (Lost Audio
PaCKets Steganography) which is intended mainly for VoIP. The method is
presented in a broader context of network steganography and of VoIP
steganography in particular. The analytical results presented in the paper
concern the influence of LACK's hidden data insertion procedure on the method's
impact on quality of voice transmission and its resistance to steganalysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4139</identifier>
 <datestamp>2008-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4139</id><created>2008-11-25</created><authors><author><keyname>Guruswami</keyname><forenames>Venkatesan</forenames></author></authors><title>Artin automorphisms, Cyclotomic function fields, and Folded
  list-decodable codes</title><categories>math.NT cs.IT math.IT</categories><comments>26 pages</comments><msc-class>11R60 (primary) 11G30, 94B27, 14Q05 (secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algebraic codes that achieve list decoding capacity were recently constructed
by a careful ``folding'' of the Reed-Solomon code. The ``low-degree'' nature of
this folding operation was crucial to the list decoding algorithm. We show how
such folding schemes conducive to list decoding arise out of the
Artin-Frobenius automorphism at primes in Galois extensions. Using this
approach, we construct new folded algebraic-geometric codes for list decoding
based on cyclotomic function fields with a cyclic Galois group. Such function
fields are obtained by adjoining torsion points of the Carlitz action of an
irreducible $M \in \F_q[T]$. The Reed-Solomon case corresponds to the simplest
such extension (corresponding to the case $M=T$). In the general case, we need
to descend to the fixed field of a suitable Galois subgroup in order to ensure
the existence of many degree one places that can be used for encoding.
  Our methods shed new light on algebraic codes and their list decoding, and
lead to new codes achieving list decoding capacity. Quantitatively, these codes
provide list decoding (and list recovery/soft decoding) guarantees similar to
folded Reed-Solomon codes but with an alphabet size that is only
polylogarithmic in the block length. In comparison, for folded RS codes, the
alphabet size is a large polynomial in the block length. This has applications
to fully explicit (with no brute-force search) binary concatenated codes for
list decoding up to the Zyablov radius.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4162</identifier>
 <datestamp>2011-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4162</id><created>2008-11-25</created><updated>2011-10-23</updated><authors><author><keyname>Xie</keyname><forenames>Bike</forenames></author><author><keyname>Courtade</keyname><forenames>Thomas</forenames></author><author><keyname>Wesel</keyname><forenames>Richard D.</forenames></author></authors><title>Optimal Encoding Schemes for Several Classes of Discrete Degraded
  Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>50 pages, 18 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a memoryless degraded broadcast channel (DBC) in which the channel
output is a single-letter function of the channel input and the channel noise.
As examples, for the Gaussian broadcast channel (BC) this single-letter
function is regular Euclidian addition and for the binary-symmetric BC this
single-letter function is Galois-Field-two addition. This paper identifies
several classes of discrete memoryless DBCs for which a relatively simple
encoding scheme, which we call natural encoding, achieves capacity. Natural
Encoding (NE) combines symbols from independent codebooks (one for each
receiver) using the same single-letter function that adds distortion to the
channel. The alphabet size of each NE codebook is bounded by that of the
channel input.
  Inspired by Witsenhausen and Wyner, this paper defines the conditional
entropy bound function $F^*$, studies its properties, and applies them to show
that NE achieves the boundary of the capacity region for the multi-receiver
broadcast Z channel. Then, this paper defines the input-symmetric DBC,
introduces permutation encoding for the input-symmetric DBC, and proves its
optimality. Because it is a special case of permutation encoding, NE is
capacity achieving for the two-receiver group-operation DBC. Combining the
broadcast Z channel and group-operation DBC results yields a proof that NE is
also optimal for the discrete multiplication DBC. Along the way, the paper also
provides explicit parametric expressions for the two-receiver binary-symmetric
DBC and broadcast Z channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4163</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4163</id><created>2008-11-25</created><updated>2010-03-30</updated><authors><author><keyname>Gadouleau</keyname><forenames>Maximilien</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>Packing and Covering Properties of Subspace Codes for Error Control in
  Random Linear Network Coding</title><categories>cs.IT math.IT</categories><comments>12 pages, to appear in IEEE Transactions on Information Theory, May
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Codes in the projective space and codes in the Grassmannian over a finite
field - referred to as subspace codes and constant-dimension codes (CDCs),
respectively - have been proposed for error control in random linear network
coding. For subspace codes and CDCs, a subspace metric was introduced to
correct both errors and erasures, and an injection metric was proposed to
correct adversarial errors. In this paper, we investigate the packing and
covering properties of subspace codes with both metrics. We first determine
some fundamental geometric properties of the projective space with both
metrics. Using these properties, we then derive bounds on the cardinalities of
packing and covering subspace codes, and determine the asymptotic rates of
optimal packing and optimal covering subspace codes with both metrics. Our
results not only provide guiding principles for the code design for error
control in random linear network coding, but also illustrate the difference
between the two metrics from a geometric perspective. In particular, our
results show that optimal packing CDCs are optimal packing subspace codes up to
a scalar for both metrics if and only if their dimension is half of their
length (up to rounding). In this case, CDCs suffer from only limited rate loss
as opposed to subspace codes with the same minimum distance. We also show that
optimal covering CDCs can be used to construct asymptotically optimal covering
subspace codes with the injection metric only.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4170</identifier>
 <datestamp>2010-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4170</id><created>2008-11-25</created><updated>2008-11-25</updated><authors><author><keyname>Barrat</keyname><forenames>Alain</forenames></author><author><keyname>Cattuto</keyname><forenames>Ciro</forenames></author><author><keyname>Colizza</keyname><forenames>Vittoria</forenames></author><author><keyname>Pinton</keyname><forenames>Jean-Francois</forenames></author><author><keyname>Broeck</keyname><forenames>Wouter Van den</forenames></author><author><keyname>Vespignani</keyname><forenames>Alessandro</forenames></author></authors><title>High resolution dynamical mapping of social interactions with active
  RFID</title><categories>cs.CY cs.HC physics.soc-ph</categories><journal-ref>PLoS ONE 5(7): e11596 (2010)</journal-ref><doi>10.1371/journal.pone.0011596</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present an experimental framework to gather data on
face-to-face social interactions between individuals, with a high spatial and
temporal resolution. We use active Radio Frequency Identification (RFID)
devices that assess contacts with one another by exchanging low-power radio
packets. When individuals wear the beacons as a badge, a persistent radio
contact between the RFID devices can be used as a proxy for a social
interaction between individuals. We present the results of a pilot study
recently performed during a conference, and a subsequent preliminary data
analysis, that provides an assessment of our method and highlights its
versatility and applicability in many areas concerned with human dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4186</identifier>
 <datestamp>2008-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4186</id><created>2008-11-25</created><authors><author><keyname>Bradic</keyname><forenames>Aleksandar</forenames></author></authors><title>Search Result Clustering via Randomized Partitioning of Query-Induced
  Subgraphs</title><categories>cs.IR cs.DS</categories><comments>16th Telecommunications Forum TELFOR 2008</comments><acm-class>H.3.3; I.1.2; E.1; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an approach to search result clustering, using
partitioning of underlying link graph. We define the notion of &quot;query-induced
subgraph&quot; and formulate the problem of search result clustering as a problem of
efficient partitioning of given subgraph into topic-related clusters. Also, we
propose a novel algorithm for approximative partitioning of such graph, which
results in cluster quality comparable to the one obtained by deterministic
algorithms, while operating in more efficient computation time, suitable for
practical implementations. Finally, we present a practical clustering search
engine developed as a part of this research and use it to get results about
real-world performance of proposed concepts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4191</identifier>
 <datestamp>2009-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4191</id><created>2008-11-25</created><updated>2009-09-17</updated><authors><author><keyname>Wu</keyname><forenames>Peng</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author></authors><title>Performance of Hybrid-ARQ in Block-Fading Channels: A Fixed Outage
  Probability Analysis</title><categories>cs.IT math.IT</categories><comments>28 pages, 11 figures, accepted at IEEE Trans. Communications</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper studies the performance of hybrid-ARQ (automatic repeat request)
in Rayleigh block fading channels. The long-term average transmitted rate is
analyzed in a fast-fading scenario where the transmitter only has knowledge of
channel statistics, and, consistent with contemporary wireless systems, rate
adaptation is performed such that a target outage probability (after a maximum
number of H-ARQ rounds) is maintained. H-ARQ allows for early termination once
decoding is possible, and thus is a coarse, and implicit, mechanism for rate
adaptation to the instantaneous channel quality. Although the rate with H-ARQ
is not as large as the ergodic capacity, which is achievable with rate
adaptation to the instantaneous channel conditions, even a few rounds of H-ARQ
make the gap to ergodic capacity reasonably small for operating points of
interest. Furthermore, the rate with H-ARQ provides a significant advantage
compared to systems that do not use H-ARQ and only adapt rate based on the
channel statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4200</identifier>
 <datestamp>2008-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4200</id><created>2008-11-25</created><authors><author><keyname>Aggarwal</keyname><forenames>Vaneet</forenames></author><author><keyname>Krishna</keyname><forenames>Gajanana</forenames></author><author><keyname>Bhashyam</keyname><forenames>Srikrishna</forenames></author><author><keyname>Sabharwal</keyname><forenames>Ashutosh</forenames></author></authors><title>Two Models for Noisy Feedback in MIMO Channels</title><categories>cs.IT math.IT</categories><comments>In Proceedings of Asilomar Conference on Signals, Systems, and
  Computers, Oct. 2008, Pacific Grove, CA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two distinct models of feedback, suited for FDD (Frequency Division Duplex)
and TDD (Frequency Division Duplex) systems respectively, have been widely
studied in the literature. In this paper, we compare these two models of
feedback in terms of the diversity multiplexing tradeoff for varying amount of
channel state information at the terminals. We find that, when all
imperfections are accounted for, the maximum achievable diversity order in FDD
systems matches the diversity order in TDD systems. TDD systems achieve better
diversity order at higher multiplexing gains. In FDD systems, the maximum
diversity order can be achieved with just a single bit of feedback. Additional
bits of feedback (perfect or imperfect) do not affect the diversity order if
the receiver does not know the channel state information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4227</identifier>
 <datestamp>2010-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4227</id><created>2008-11-26</created><updated>2010-03-02</updated><authors><author><keyname>Hsieh</keyname><forenames>Min-Hsiu</forenames></author><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author></authors><title>Entanglement-assisted communication of classical and quantum information</title><categories>quant-ph cs.IT math.IT</categories><comments>23 pages, 5 figures, 1 table, simplification of capacity region--it
  now has the simple interpretation as the unit resource capacity region
  translated along the classically-enhanced father trade-off curve</comments><journal-ref>IEEE Transactions on Information Theory, vol. 56, no. 9, pp.
  4682-4704, September 2010</journal-ref><doi>10.1109/TIT.2010.2053903</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of transmitting classical and quantum information
reliably over an entanglement-assisted quantum channel. Our main result is a
capacity theorem that gives a three-dimensional achievable rate region. Points
in the region are rate triples, consisting of the classical communication rate,
the quantum communication rate, and the entanglement consumption rate of a
particular coding scheme. The crucial protocol in achieving the boundary points
of the capacity region is a protocol that we name the classically-enhanced
father protocol. The classically-enhanced father protocol is more general than
other protocols in the family tree of quantum Shannon theoretic protocols, in
the sense that several previously known quantum protocols are now child
protocols of it. The classically-enhanced father protocol also shows an
improvement over a time-sharing strategy for the case of a qubit dephasing
channel--this result justifies the need for simultaneous coding of classical
and quantum information over an entanglement-assisted quantum channel. Our
capacity theorem is of a multi-letter nature (requiring a limit over many uses
of the channel), but it reduces to a single-letter characterization for at
least three channels: the completely depolarizing channel, the quantum erasure
channel, and the qubit dephasing channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4257</identifier>
 <datestamp>2008-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4257</id><created>2008-11-26</created><authors><author><keyname>Hernandez-Castro</keyname><forenames>Julio C.</forenames></author><author><keyname>Tapiador</keyname><forenames>Juan M. E.</forenames></author><author><keyname>Peris-Lopez</keyname><forenames>Pedro</forenames></author><author><keyname>Quisquater</keyname><forenames>Jean-Jacques</forenames></author></authors><title>Cryptanalysis of the SASI Ultralightweight RFID Authentication Protocol
  with Modular Rotations</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we present the first passive attack over the SASI lightweight
authentication protocol with modular rotations. This can be used to fully
recover the secret $ID$ of the RFID tag, which is the value the protocol is
designed to conceal. The attack is described initially for recovering $\lfloor
log_2(96) \rfloor=6$ bits of the secret value $ID$, a result that by itself
allows to mount traceability attacks on any given tag. However, the proposed
scheme can be extended to obtain any amount of bits of the secret $ID$,
provided a sufficiently large number of successful consecutive sessions are
eavesdropped. We also present results on the attack's efficiency, and some
ideas to secure this version of the SASI protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4324</identifier>
 <datestamp>2008-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4324</id><created>2008-11-26</created><authors><author><keyname>Genev&#xe8;s</keyname><forenames>Pierre</forenames></author><author><keyname>Laya&#xef;da</keyname><forenames>Nabil</forenames></author><author><keyname>Quint</keyname><forenames>Vincent</forenames></author></authors><title>Ensuring Query Compatibility with Evolving XML Schemas</title><categories>cs.PL cs.SE</categories><report-no>RR-6711</report-no><acm-class>D.3.0; D.3.1; D.3.4; E.1; F.3.1; F.3.2; F.4.1; F.4.3; H.2.3; I.2.4;
  I.7.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During the life cycle of an XML application, both schemas and queries may
change from one version to another. Schema evolutions may affect query results
and potentially the validity of produced data. Nowadays, a challenge is to
assess and accommodate the impact of theses changes in rapidly evolving XML
applications.
  This article proposes a logical framework and tool for verifying
forward/backward compatibility issues involving schemas and queries. First, it
allows analyzing relations between schemas. Second, it allows XML designers to
identify queries that must be reformulated in order to produce the expected
results across successive schema versions. Third, it allows examining more
precisely the impact of schema changes over queries, therefore facilitating
their reformulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4339</identifier>
 <datestamp>2008-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4339</id><created>2008-11-26</created><authors><author><keyname>Studer</keyname><forenames>Christoph</forenames></author><author><keyname>Seethaler</keyname><forenames>Dominik</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>Finite Lattice-Size Effects in MIMO Detection</title><categories>cs.IT math.IT</categories><comments>presented at the 42th Asilomar Conf. Signals, Systems, and Computers,
  Pacific Grove, CA, 2008</comments><journal-ref>Proc. 42th Asilomar Conf. Signals, Systems, and Computers, Pacific
  Grove, CA, Oct. 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many powerful data detection algorithms employed in multiple-input
multiple-output (MIMO) communication systems, such as sphere decoding (SD) and
lattice-reduction (LR)-aided detection, were initially designed for infinite
lattices. Detection in MIMO systems is, however, based on finite lattices. In
this paper, we systematically study the consequences of finite lattice-size for
the performance and complexity of MIMO detection algorithms formulated for
infinite lattices. Specifically, we find, considering performance and
complexity, that LR does not seem to offer advantages when used in conjunction
with SD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4346</identifier>
 <datestamp>2008-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4346</id><created>2008-11-26</created><authors><author><keyname>Yi</keyname><forenames>Ke</forenames></author></authors><title>Dynamic Indexability: The Query-Update Tradeoff for One-Dimensional
  Range Queries</title><categories>cs.DS cs.DB</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The B-tree is a fundamental secondary index structure that is widely used for
answering one-dimensional range reporting queries. Given a set of $N$ keys, a
range query can be answered in $O(\log_B \nm + \frac{K}{B})$ I/Os, where $B$ is
the disk block size, $K$ the output size, and $M$ the size of the main memory
buffer. When keys are inserted or deleted, the B-tree is updated in $O(\log_B
N)$ I/Os, if we require the resulting changes to be committed to disk right
away. Otherwise, the memory buffer can be used to buffer the recent updates,
and changes can be written to disk in batches, which significantly lowers the
amortized update cost. A systematic way of batching up updates is to use the
logarithmic method, combined with fractional cascading, resulting in a dynamic
B-tree that supports insertions in $O(\frac{1}{B}\log\nm)$ I/Os and queries in
$O(\log\nm + \frac{K}{B})$ I/Os. Such bounds have also been matched by several
known dynamic B-tree variants in the database literature.
  In this paper, we prove that for any dynamic one-dimensional range query
index structure with query cost $O(q+\frac{K}{B})$ and amortized insertion cost
$O(u/B)$, the tradeoff $q\cdot \log(u/q) = \Omega(\log B)$ must hold if
$q=O(\log B)$. For most reasonable values of the parameters, we have $\nm =
B^{O(1)}$, in which case our query-insertion tradeoff implies that the bounds
mentioned above are already optimal. Our lower bounds hold in a dynamic version
of the {\em indexability model}, which is of independent interests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4349</identifier>
 <datestamp>2008-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4349</id><created>2008-11-26</created><authors><author><keyname>Mutiara</keyname><forenames>A. B.</forenames></author><author><keyname>Agustina</keyname><forenames>S.</forenames></author></authors><title>Anti Plagiarism Application with Algorithm Karp-Rabin at Thesis in
  Gunadarma University</title><categories>cs.IT cs.DL math.IT</categories><comments>9 pages, 22 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Plagiarism that is plagiarizing or composition retrieval, opinion, etcetera
from other people and makes it is likely composition and opinion him-self.
Plagiarism can be considered to be crime because stealing others copyrights.
Like action a student copying some part of writings without valid permission
from the original writer. In education world, plagiarism perpetrator can get
the devil to pay from school/university. Plagiarism perpetrator conceived of
plagiator. This thing is possible unable to be paid attention by the side of
campus because of limitation from some interconnected factors for example
student amounts Gunadarma University reaching thousands and incommensurate to
tester amounts or lecturer the side of campus in charge directs problem thesis.
In this paper, an application have been developed in order to check and look
for 5 type percentage similarity from a thesis with other one at certain part
or chapters. Percentage got that is 0%, under 15%, between 15-50%, up to 50%
and 100%. So it should be expected that the results could be used by thesis
advisor and also thesis examiner from the Student at Gunadarma University.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4354</identifier>
 <datestamp>2008-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4354</id><created>2008-11-26</created><authors><author><keyname>Studer</keyname><forenames>Christoph</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>Soft-Input Soft-Output Sphere Decoding</title><categories>cs.IT math.IT</categories><comments>presented at IEEE Int. Symposium on Information Theory (ISIT),
  Toronto, ON, Canada</comments><journal-ref>IEEE Int. Symposium on Information Theory (ISIT), Toronto, ON,
  Canada, pp. 2007-2011, July 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Soft-input soft-output (SISO) detection algorithms form the basis for
iterative decoding. The associated computational complexity often poses
significant challenges for practical receiver implementations, in particular in
the context of multiple-input multiple-output wireless systems. In this paper,
we present a low-complexity SISO sphere decoder which is based on the single
tree search paradigm, proposed originally for soft-output detection in Studer
et al., IEEE J-SAC, 2008. The algorithm incorporates clipping of the extrinsic
log-likelihood ratios in the tree search, which not only results in significant
complexity savings, but also allows to cover a large performance/complexity
trade-off region by adjusting a single parameter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4364</identifier>
 <datestamp>2008-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4364</id><created>2008-11-26</created><authors><author><keyname>Jureta</keyname><forenames>Ivan</forenames></author><author><keyname>Mylopoulos</keyname><forenames>John</forenames></author><author><keyname>Faulkner</keyname><forenames>Stephane</forenames></author></authors><title>Revisiting the Core Ontology and Problem in Requirements Engineering</title><categories>cs.SE</categories><comments>Appears in the proceedings of the 16th IEEE International
  Requirements Engineering Conference, 2008 (RE'08). Best paper award</comments><acm-class>D.2.1</acm-class><doi>10.1109/RE.2008.13</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In their seminal paper in the ACM Transactions on Software Engineering and
Methodology, Zave and Jackson established a core ontology for Requirements
Engineering (RE) and used it to formulate the &quot;requirements problem&quot;, thereby
defining what it means to successfully complete RE. Given that stakeholders of
the system-to-be communicate the information needed to perform RE, we show that
Zave and Jackson's ontology is incomplete. It does not cover all types of basic
concerns that the stakeholders communicate. These include beliefs, desires,
intentions, and attitudes. In response, we propose a core ontology that covers
these concerns and is grounded in sound conceptual foundations resting on a
foundational ontology. The new core ontology for RE leads to a new formulation
of the requirements problem that extends Zave and Jackson's formulation. We
thereby establish new standards for what minimum information should be
represented in RE languages and new criteria for determining whether RE has
been successfully completed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4367</identifier>
 <datestamp>2010-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4367</id><created>2008-11-26</created><updated>2010-05-26</updated><authors><author><keyname>Felty</keyname><forenames>Amy</forenames></author><author><keyname>Momigliano</keyname><forenames>Alberto</forenames></author></authors><title>Hybrid: A Definitional Two-Level Approach to Reasoning with Higher-Order
  Abstract Syntax</title><categories>cs.LO</categories><comments>58 pages, with 12 figures. To appear in the Journal of Automated
  Reasoning, accepted April 2010. For associated code, see
  http://hybrid.dsi.unimi.it/jar/index.html</comments><report-no>University of Ottawa Technical Report, number TR-2008-03</report-no><acm-class>F.4.1; I.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Combining higher-order abstract syntax and (co)induction in a logical
framework is well known to be problematic. Previous work described the
implementation of a tool called Hybrid, within Isabelle HOL, which aims to
address many of these difficulties. It allows object logics to be represented
using higher-order abstract syntax, and reasoned about using tactical theorem
proving and principles of (co)induction. In this paper we describe how to use
it in a multi-level reasoning fashion, similar in spirit to other meta-logics
such as Twelf. By explicitly referencing provability in a middle layer called a
specification logic, we solve the problem of reasoning by (co)induction in the
presence of non-stratifiable hypothetical judgments, which allow very elegant
and succinct specifications of object logic inference rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4376</identifier>
 <datestamp>2008-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4376</id><created>2008-11-26</created><authors><author><keyname>Sourabh</keyname><forenames>Suman Kumar</forenames></author><author><keyname>Chakraborty</keyname><forenames>Soubhik</forenames></author></authors><title>How robust is quicksort average complexity?</title><categories>cs.DS cs.CC</categories><comments>15 pages;12figures;2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper questions the robustness of average case time complexity of the
fast and popular quicksort algorithm. Among the six standard probability
distributions examined in the paper, only continuous uniform, exponential and
standard normal are supporting it whereas the others are supporting the worst
case complexity measure. To the question -why are we getting the worst case
complexity measure each time the average case measure is discredited?-- one
logical answer is average case complexity under the universal distribution
equals worst case complexity. This answer, which is hard to challenge, however
gives no idea as to which of the standard probability distributions come under
the umbrella of universality. The morale is that average case complexity
measures, in cases where they are different from those in worst case, should be
deemed as robust provided only they get the support from at least the standard
probability distributions, both discrete and continuous. Regretfully, this is
not the case with quicksort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4391</identifier>
 <datestamp>2009-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4391</id><created>2008-11-26</created><updated>2009-02-17</updated><authors><author><keyname>Mardani</keyname><forenames>Morteza</forenames></author><author><keyname>Harsini</keyname><forenames>Jalil S.</forenames></author><author><keyname>Lahouti</keyname><forenames>Farshad</forenames></author></authors><title>Cross-Layer Link Adaptation Design for Relay Channels with Cooperative
  ARQ Protocol</title><categories>cs.IT math.IT</categories><comments>6 pages, 3 figures, Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The cooperative automatic repeat request (C-ARQ) is a link layer relaying
protocol which exploits the spatial diversity and allows the relay node to
retransmit the source data packet to the destination, when the latter is unable
to decode the source data correctly. This paper presents a cross-layer link
adaptation design for C-ARQ based relay channels in which both source and relay
nodes employ adaptive modulation coding and power adaptation at the physical
layer. For this scenario, we first derive closed-form expressions for the
system spectral efficiency and average power consumption. We then present a low
complexity iterative algorithm to find the optimized adaptation solution by
maximizing the spectral efficiency subject to a packet loss rate (PLR) and an
average power consumption constraint. The results indicate that the proposed
adaptation scheme enhances the spectral efficiency noticeably when compared to
other adaptive schemes, while guaranteeing the required PLR performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4395</identifier>
 <datestamp>2008-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4395</id><created>2008-11-26</created><authors><author><keyname>Gopalan</keyname><forenames>Parikshit</forenames></author><author><keyname>Guruswami</keyname><forenames>Venkatesan</forenames></author><author><keyname>Raghavendra</keyname><forenames>Prasad</forenames></author></authors><title>List Decoding Tensor Products and Interleaved Codes</title><categories>cs.IT math.IT</categories><comments>32 pages</comments><acm-class>E.4; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design the first efficient algorithms and prove new combinatorial bounds
for list decoding tensor products of codes and interleaved codes. We show that
for {\em every} code, the ratio of its list decoding radius to its minimum
distance stays unchanged under the tensor product operation (rather than
squaring, as one might expect). This gives the first efficient list decoders
and new combinatorial bounds for some natural codes including multivariate
polynomials where the degree in each variable is bounded. We show that for {\em
every} code, its list decoding radius remains unchanged under $m$-wise
interleaving for an integer $m$. This generalizes a recent result of Dinur et
al \cite{DGKS}, who proved such a result for interleaved Hadamard codes
(equivalently, linear transformations). Using the notion of generalized Hamming
weights, we give better list size bounds for {\em both} tensoring and
interleaving of binary linear codes. By analyzing the weight distribution of
these codes, we reduce the task of bounding the list size to bounding the
number of close-by low-rank codewords. For decoding linear transformations,
using rank-reduction together with other ideas, we obtain list size bounds that
are tight over small fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4397</identifier>
 <datestamp>2008-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4397</id><created>2008-11-26</created><authors><author><keyname>Mardani</keyname><forenames>Morteza</forenames></author><author><keyname>Harsini</keyname><forenames>Jalil S.</forenames></author><author><keyname>Lahouti</keyname><forenames>Farshad</forenames></author><author><keyname>Eliasi</keyname><forenames>Behrouz</forenames></author></authors><title>Joint Adaptive Modulation-Coding and Cooperative ARQ for Wireless Relay
  Networks</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, To appear in the Proceedings of the 2008 IEEE
  International Symposium on Wireless Communication Systems (ISWCS), Rykevick,
  Island, Oct 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a cross-layer approach to jointly design adaptive
modulation and coding (AMC) at the physical layer and cooperative truncated
automatic repeat request (ARQ) protocol at the data link layer. We first derive
an exact closed form expression for the spectral efficiency of the proposed
joint AMC-cooperative ARQ scheme. Aiming at maximizing this system performance
measure, we then optimize an AMC scheme which directly satisfies a prescribed
packet loss rate constraint at the data-link layer. The results indicate that
utilizing cooperative ARQ as a retransmission strategy, noticeably enhances the
spectral efficiency compared with the system that employs AMC alone at the
physical layer. Moreover, the proposed adaptive rate cooperative ARQ scheme
outperforms the fixed rate counterpart when the transmission modes at the
source and relay are chosen based on the channel statistics. This in turn
quantifies the possible gain achieved by joint design of AMC and ARQ in
wireless relay networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4403</identifier>
 <datestamp>2008-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4403</id><created>2008-11-26</created><authors><author><keyname>Mardani</keyname><forenames>Morteza</forenames></author><author><keyname>Harsini</keyname><forenames>Jalil S.</forenames></author><author><keyname>Lahouti</keyname><forenames>Farshad</forenames></author><author><keyname>Eliasi</keyname><forenames>Behrouz</forenames></author></authors><title>Joint Adaptive Modulation Coding and Cooperative ARQ over Relay
  Channels-Applications to Land Mobile Satellite Communications</title><categories>cs.IT math.IT</categories><comments>24 pages, 7 figures, 1 table, Submitted to the International Journal
  on Wireless Communications and Mobile Computing, Wiley &amp; Sons, Submitted July
  2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a cooperative relay network, a relay node (R) facilitates data
transmission to the destination node (D), when the latter is unable to decode
the source node (S) data correctly. This paper considers such a system model
and presents a cross-layer approach to jointly design adaptive modulation and
coding (AMC) at the physical layer and cooperative truncated automatic repeat
request (ARQ) protocol at the data link layer. We first derive a closed form
expression for the spectral efficiency of the joint cooperative ARQ-AMC scheme.
Aiming at maximizing this performance measure, we then optimize two AMC schemes
for S-D and R-D links, which directly satisfy a prescribed packet loss rate
constraint. As an interesting application, we also consider the problem of
joint link adaptation and blockage mitigation in land mobile satellite
communications (LMSC). We also present a new relay-assisted transmission
protocol for LMSC, which delivers the source data to the destination via the
relaying link, when the S-D channel is in outage. Numerical results indicate
that the proposed schemes noticeably enhances the spectral efficiency compared
to a system, which uses a conventional ARQ-AMC scheme at the S-D link, or a
system which employs an optimized fixed rate cooperative-ARQ protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4413</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4413</id><created>2008-11-26</created><updated>2012-07-06</updated><authors><author><keyname>Hsu</keyname><forenames>Daniel</forenames></author><author><keyname>Kakade</keyname><forenames>Sham M.</forenames></author><author><keyname>Zhang</keyname><forenames>Tong</forenames></author></authors><title>A Spectral Algorithm for Learning Hidden Markov Models</title><categories>cs.LG cs.AI</categories><comments>Published in JCSS Special Issue &quot;Learning Theory 2009&quot;</comments><journal-ref>Journal of Computer and System Sciences, 78(5):1460-1480, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hidden Markov Models (HMMs) are one of the most fundamental and widely used
statistical tools for modeling discrete time series. In general, learning HMMs
from data is computationally hard (under cryptographic assumptions), and
practitioners typically resort to search heuristics which suffer from the usual
local optima issues. We prove that under a natural separation condition (bounds
on the smallest singular value of the HMM parameters), there is an efficient
and provably correct algorithm for learning HMMs. The sample complexity of the
algorithm does not explicitly depend on the number of distinct (discrete)
observations---it implicitly depends on this quantity through spectral
properties of the underlying HMM. This makes the algorithm particularly
applicable to settings with a large number of observations, such as those in
natural language processing where the space of observation is sometimes the
words in a language. The algorithm is also simple, employing only a singular
value decomposition and matrix multiplications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4458</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4458</id><created>2008-11-26</created><updated>2009-10-20</updated><authors><author><keyname>Schulte</keyname><forenames>Oliver</forenames></author><author><keyname>Khosravi</keyname><forenames>Hassan</forenames></author><author><keyname>Moser</keyname><forenames>Flavia</forenames></author><author><keyname>Ester</keyname><forenames>Martin</forenames></author></authors><title>Learning Class-Level Bayes Nets for Relational Data</title><categories>cs.LG cs.AI</categories><comments>14 pages (2 column)</comments><report-no>TR 2008-17, School of Computing Science, Simon Fraser University</report-no><acm-class>I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many databases store data in relational format, with different types of
entities and information about links between the entities. The field of
statistical-relational learning (SRL) has developed a number of new statistical
models for such data. In this paper we focus on learning class-level or
first-order dependencies, which model the general database statistics over
attributes of linked objects and links (e.g., the percentage of A grades given
in computer science classes). Class-level statistical relationships are
important in themselves, and they support applications like policy making,
strategic planning, and query optimization. Most current SRL methods find
class-level dependencies, but their main task is to support instance-level
predictions about the attributes or links of specific entities. We focus only
on class-level prediction, and describe algorithms for learning class-level
models that are orders of magnitude faster for this task. Our algorithms learn
Bayes nets with relational structure, leveraging the efficiency of single-table
nonrelational Bayes net learners. An evaluation of our methods on three data
sets shows that they are computationally feasible for realistic table sizes,
and that the learned structures represent the statistical information in the
databases well. After learning compiles the database statistics into a Bayes
net, querying these statistics via Bayes net inference is faster than with SQL
queries, and does not depend on the size of the database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4483</identifier>
 <datestamp>2008-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4483</id><created>2008-11-28</created><authors><author><keyname>Guelvouit</keyname><forenames>Ga&#xeb;tan Le</forenames></author><author><keyname>Pateux</keyname><forenames>St&#xe9;phane</forenames></author></authors><title>Wide spread spectrum watermarking with side information and interference
  cancellation</title><categories>cs.MM cs.IT math.IT</categories><comments>12 pages, 8 figures</comments><journal-ref>Proc. IS&amp;T/SPIE Electronic Imaging, vol. 5020, Santa Clara, CA,
  Jan. 2003</journal-ref><doi>10.1117/12.476839</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, a popular method used for additive watermarking is wide spread
spectrum. It consists in adding a spread signal into the host document. This
signal is obtained by the sum of a set of carrier vectors, which are modulated
by the bits to be embedded. To extract these embedded bits, weighted
correlations between the watermarked document and the carriers are computed.
Unfortunately, even without any attack, the obtained set of bits can be
corrupted due to the interference with the host signal (host interference) and
also due to the interference with the others carriers (inter-symbols
interference (ISI) due to the non-orthogonality of the carriers). Some recent
watermarking algorithms deal with host interference using side informed
methods, but inter-symbols interference problem is still open. In this paper,
we deal with interference cancellation methods, and we propose to consider ISI
as side information and to integrate it into the host signal. This leads to a
great improvement of extraction performance in term of signal-to-noise ratio
and/or watermark robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4489</identifier>
 <datestamp>2013-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4489</id><created>2008-11-27</created><updated>2009-03-10</updated><authors><author><keyname>Jiang</keyname><forenames>Bin</forenames></author><author><keyname>Liu</keyname><forenames>Xintao</forenames></author></authors><title>Automatic Generation of the Axial Lines of Urban Environments to Capture
  What We Perceive</title><categories>cs.CG cs.CV</categories><comments>13 pages, 9 figures submitted to International Journal of
  Geographical Information Science. With version 2, the concept of bucket has
  been explained and illustrated in more detail. With version 3, better
  formating and finetune</comments><journal-ref>International Journal of Geographical Information Science, 24(4),
  2010, 545-558</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based on the concepts of isovists and medial axes, we developed a set of
algorithms that can automatically generate axial lines for representing
individual linearly stretched parts of open space of an urban environment. Open
space is the space between buildings, where people can freely move around. The
generation of the axial lines has been a key aspect of space syntax research,
conventionally relying on hand-drawn axial lines of an urban environment, often
called axial map, for urban morphological analysis. Although various attempts
have been made towards an automatic solution, few of them can produce the axial
map that consists of the least number of longest visibility lines, and none of
them really works for different urban environments. Our algorithms provide a
better solution than existing ones. Throughout this paper, we have also argued
and demonstrated that the axial lines constitute a true skeleton, superior to
medial axes, in capturing what we perceive about the urban environment.
  Keywords: Visibility, space syntax, topological analysis, medial axes, axial
lines, isovists
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4497</identifier>
 <datestamp>2009-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4497</id><created>2008-11-27</created><updated>2009-03-08</updated><authors><author><keyname>Dawar</keyname><forenames>Anuj</forenames></author></authors><title>Homomorphism Preservation on Quasi-Wide Classes</title><categories>cs.LO</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A class of structures is said to have the homomorphism-preservation property
just in case every first-order formula that is preserved by homomorphisms on
this class is equivalent to an existential-positive formula. It is known by a
result of Rossman that the class of finite structures has this property and by
previous work of Atserias et al. that various of its subclasses do. We extend
the latter results by introducing the notion of a quasi-wide class and showing
that any quasi-wide class that is closed under taking substructures and
disjoint unions has the homomorphism-preservation property. We show, in
particular, that classes of structures of bounded expansion and that locally
exclude minors are quasi-wide. We also construct an example of a class of
finite structures which is closed under substructures and disjoint unions but
does not admit the homomorphism-preservation property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4565</identifier>
 <datestamp>2008-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4565</id><created>2008-11-27</created><authors><author><keyname>Jin</keyname><forenames>Shi</forenames></author><author><keyname>McKay</keyname><forenames>Matthew R.</forenames></author><author><keyname>Zhong</keyname><forenames>Caijun</forenames></author><author><keyname>Wong</keyname><forenames>Kai-Kit</forenames></author></authors><title>Ergodic Capacity Analysis of Amplify-and-Forward MIMO Dual-Hop Systems</title><categories>cs.IT math.IT</categories><comments>40 pages, 9 figures, Submitted to to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an analytical characterization of the ergodic capacity of
amplify-and-forward (AF) MIMO dual-hop relay channels, assuming that the
channel state information is available at the destination terminal only. In
contrast to prior results, our expressions apply for arbitrary numbers of
antennas and arbitrary relay configurations. We derive an expression for the
exact ergodic capacity, simplified closed-form expressions for the high SNR
regime, and tight closed-form upper and lower bounds. These results are made
possible to employing recent tools from finite-dimensional random matrix theory
to derive new closed-form expressions for various statistical properties of the
equivalent AF MIMO dual-hop relay channel, such as the distribution of an
unordered eigenvalue and certain random determinant properties. Based on the
analytical capacity expressions, we investigate the impact of the system and
channel characteristics, such as the antenna configuration and the relay power
gain. We also demonstrate a number of interesting relationships between the
dual-hop AF MIMO relay channel and conventional point-to-point MIMO channels in
various asymptotic regimes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4603</identifier>
 <datestamp>2009-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4603</id><created>2008-11-27</created><updated>2009-07-17</updated><authors><author><keyname>Franceschet</keyname><forenames>Massimo</forenames></author></authors><title>Frozen Footprints</title><categories>cs.DL cs.IR</categories><comments>Added section about bibliometric distributions; improved section
  about bibliometric maps; added references; changed title; latex format</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bibliometrics has the ambitious goal of measuring science. To this end, it
exploits the way science is disseminated trough scientific publications and the
resulting citation network of scientific papers. We survey the main historical
contributions to the field, the most interesting bibliometric indicators, and
the most popular bibliometric data sources. Moreover, we discuss distributions
commonly used to model bibliometric phenomena and give an overview of methods
to build bibliometric maps of science.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4630</identifier>
 <datestamp>2008-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4630</id><created>2008-11-27</created><authors><author><keyname>Shirani-Mehr</keyname><forenames>Hooman</forenames></author><author><keyname>Liu</keyname><forenames>Daniel N.</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>Channel State Prediction, Feedback and Scheduling for a Multiuser
  MIMO-OFDM Downlink</title><categories>cs.IT math.IT</categories><comments>In Proceedings of 42th Asilomar Conference on Signals, Systems, and
  Computers, Oct. 2008, Pacific Grove, CA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the downlink of a MIMO-OFDM wireless systems where the
base-station (BS) has M antennas and serves K single-antenna user terminals
(UT) with K larger than or equal to M. Users estimate their channel vectors
from common downlink pilot symbols and feed back a prediction, which is used by
the BS to compute the linear beamforming matrix for the next time slot and to
select the users to be served according to the proportional fair scheduling
(PFS) algorithm. We consider a realistic physical channel model used as a
benchmark in standardization and some alternatives for the channel estimation
and prediction scheme. We show that a parametric method based on ESPRIT is able
to accurately predict the channel even for relatively high user mobility.
However, there exists a class of channels characterized by large Doppler spread
(high mobility) and clustered angular spread for which prediction is
intrinsically difficult and all considered methods fail. We propose a modified
PFS that take into account the &quot;predictability&quot; state of the UTs, and
significantly outperform the classical PFS in the presence of prediction
errors. The main conclusion of this work is that multiuser MIMO downlink yields
very good performance even in the presence of high mobility users, provided
that the nonpredictable users are handled appropriately
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4672</identifier>
 <datestamp>2008-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4672</id><created>2008-11-28</created><authors><author><keyname>Soroush</keyname><forenames>Emad</forenames></author><author><keyname>Wu</keyname><forenames>Kui</forenames></author><author><keyname>Pei</keyname><forenames>Jian</forenames></author></authors><title>Fast and Quality-Guaranteed Data Streaming in Resource-Constrained
  Sensor Networks</title><categories>cs.DS cs.MM</categories><comments>Published in ACM MobiHoc 2008</comments><acm-class>C.3; G.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many emerging applications, data streams are monitored in a network
environment. Due to limited communication bandwidth and other resource
constraints, a critical and practical demand is to online compress data streams
continuously with quality guarantee. Although many data compression and digital
signal processing methods have been developed to reduce data volume, their
super-linear time and more-than-constant space complexity prevents them from
being applied directly on data streams, particularly over resource-constrained
sensor networks. In this paper, we tackle the problem of online quality
guaranteed compression of data streams using fast linear approximation (i.e.,
using line segments to approximate a time series). Technically, we address two
versions of the problem which explore quality guarantees in different forms. We
develop online algorithms with linear time complexity and constant cost in
space. Our algorithms are optimal in the sense they generate the minimum number
of segments that approximate a time series with the required quality guarantee.
To meet the resource constraints in sensor networks, we also develop a fast
algorithm which creates connecting segments with very simple computation. The
low cost nature of our methods leads to a unique edge on the applications of
massive and fast streaming environment, low bandwidth networks, and heavily
constrained nodes in computational power. We implement and evaluate our methods
in the application of an acoustic wireless sensor network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4681</identifier>
 <datestamp>2008-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4681</id><created>2008-11-28</created><authors><author><keyname>Guelvouit</keyname><forenames>Ga&#xeb;tan Le</forenames></author><author><keyname>Furon</keyname><forenames>Teddy</forenames></author><author><keyname>Cayre</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>The Good, the Bad, and the Ugly: three different approaches to break
  their watermarking system</title><categories>cs.GR cs.MM</categories><comments>8 pages, 8 figures</comments><journal-ref>Proc. IS&amp;T/SPIE Electronic Imaging, vol. 6505, San Jose, CA, Jan.
  2007</journal-ref><doi>10.1117/12.703968</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Good is Blondie, a wandering gunman with a strong personal sense of
honor. The Bad is Angel Eyes, a sadistic hitman who always hits his mark. The
Ugly is Tuco, a Mexican bandit who's always only looking out for himself.
Against the backdrop of the BOWS contest, they search for a watermark in gold
buried in three images. Each knows only a portion of the gold's exact location,
so for the moment they're dependent on each other. However, none are
particularly inclined to share...
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4697</identifier>
 <datestamp>2008-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4697</id><created>2008-11-28</created><authors><author><keyname>Braci</keyname><forenames>Sofiane</forenames></author><author><keyname>Delpha</keyname><forenames>Claude</forenames></author><author><keyname>Boyer</keyname><forenames>R&#xe9;my</forenames></author><author><keyname>Guelvouit</keyname><forenames>Ga&#xeb;tan Le</forenames></author></authors><title>Informed stego-systems in active warden context: statistical
  undetectability and capacity</title><categories>cs.IT cs.MM math.IT</categories><comments>6 pages, 8 figures</comments><journal-ref>Proc. IEEE Conf. on Multimedia Signal Processing, Cairns,
  Australia, Oct. 2008</journal-ref><doi>10.1109/MMSP.2008.4665167</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several authors have studied stego-systems based on Costa scheme, but just a
few ones gave both theoretical and experimental justifications of these schemes
performance in an active warden context. We provide in this paper a
steganographic and comparative study of three informed stego-systems in active
warden context: scalar Costa scheme, trellis-coded quantization and spread
transform scalar Costa scheme. By leading on analytical formulations and on
experimental evaluations, we show the advantages and limits of each scheme in
term of statistical undetectability and capacity in the case of active warden.
Such as the undetectability is given by the distance between the stego-signal
and the cover distance. It is measured by the Kullback-Leibler distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4699</identifier>
 <datestamp>2010-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4699</id><created>2008-11-28</created><updated>2009-03-03</updated><authors><author><keyname>Sparavigna</keyname><forenames>A.</forenames></author><author><keyname>Marazzato</keyname><forenames>R.</forenames></author></authors><title>Mapping Images with the Coherence Length Diagrams</title><categories>cs.CV</categories><journal-ref>International Journal of Software Engineering and Computing, pp.
  53-57, 2009, Vol. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statistical pattern recognition methods based on the Coherence Length Diagram
(CLD) have been proposed for medical image analyses, such as quantitative
characterisation of human skin textures, and for polarized light microscopy of
liquid crystal textures. Further investigations are made on image maps
originated from such diagram and some examples related to irregularity of
microstructures are shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4700</identifier>
 <datestamp>2008-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4700</id><created>2008-11-28</created><authors><author><keyname>Guelvouit</keyname><forenames>Ga&#xeb;tan Le</forenames></author></authors><title>Trellis-coded quantization for public-key steganography</title><categories>cs.MM cs.IT math.IT</categories><comments>4 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with public-key steganography in the presence of a passive
warden. The aim is to hide secret messages within cover-documents without
making the warden suspicious, and without any preliminar secret key sharing.
Whereas a practical attempt has been already done to provide a solution to this
problem, it suffers of poor flexibility (since embedding and decoding steps
highly depend on cover-signals statistics) and of little capacity compared to
recent data hiding techniques. Using the same framework, this paper explores
the use of trellis-coded quantization techniques (TCQ and turbo TCQ) to design
a more efficient public-key scheme. Experiments on audio signals show great
improvements considering Cachin's security criterion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4702</identifier>
 <datestamp>2008-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4702</id><created>2008-11-28</created><authors><author><keyname>Pateux</keyname><forenames>St&#xe9;phane</forenames></author><author><keyname>Guelvouit</keyname><forenames>Ga&#xeb;tan Le</forenames></author><author><keyname>Guillemot</keyname><forenames>Christine</forenames></author></authors><title>Information-theoretic resolution of perceptual WSS watermarking of non
  i.i.d. Gaussian signals</title><categories>cs.IT cs.MM math.IT</categories><comments>4 pages, 3 figures</comments><journal-ref>Proc. European Signal Processing Conf., Toulouse, France, Sep.
  2002</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theoretical foundations of data hiding have been revealed by formulating
the problem as message communication over a noisy channel. We revisit the
problem in light of a more general characterization of the watermark channel
and of weighted distortion measures. Considering spread spectrum based
information hiding, we release the usual assumption of an i.i.d. cover signal.
The game-theoretic resolution of the problem reveals a generalized
characterization of optimum attacks. The paper then derives closed-form
expressions for the different parameters exhibiting a practical embedding and
extraction technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4706</identifier>
 <datestamp>2009-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4706</id><created>2008-11-28</created><updated>2009-04-27</updated><authors><author><keyname>Hurley</keyname><forenames>Niall P.</forenames></author><author><keyname>Rickard</keyname><forenames>Scott T.</forenames></author></authors><title>Comparing Measures of Sparsity</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory (November 2008),
  17 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparsity of representations of signals has been shown to be a key concept of
fundamental importance in fields such as blind source separation, compression,
sampling and signal analysis. The aim of this paper is to compare several
commonlyused sparsity measures based on intuitive attributes. Intuitively, a
sparse representation is one in which a small number of coefficients contain a
large proportion of the energy. In this paper six properties are discussed:
(Robin Hood, Scaling, Rising Tide, Cloning, Bill Gates and Babies), each of
which a sparsity measure should have. The main contributions of this paper are
the proofs and the associated summary table which classify commonly-used
sparsity measures based on whether or not they satisfy these six propositions
and the corresponding proofs. Only one of these measures satisfies all six: The
Gini Index. measures based on whether or not they satisfy these six
propositions and the corresponding proofs. Only one of these measures satisfies
all six: The Gini Index.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4713</identifier>
 <datestamp>2014-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4713</id><created>2008-11-28</created><updated>2014-07-08</updated><authors><author><keyname>Courcelle</keyname><forenames>Bruno</forenames><affiliation>LaBRI, IUF</affiliation></author><author><keyname>Gavoille</keyname><forenames>Cyril</forenames><affiliation>LaBRI, INRIA Futurs</affiliation></author><author><keyname>Kant&#xe9;</keyname><forenames>Mamadou Moustapha</forenames><affiliation>LaBRI</affiliation></author></authors><title>Compact Labelings For Efficient First-Order Model-Checking</title><categories>cs.DS cs.LO</categories><proxy>ccsd hal-00342668</proxy><msc-class>68R05, 68R10, 05C78, 05C85</msc-class><acm-class>F.0; G.2.2</acm-class><journal-ref>Journal of Combinatorial Optimisation 21(1):19-46(2011)</journal-ref><doi>10.1007/s10878-009-9260-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider graph properties that can be checked from labels, i.e., bit
sequences, of logarithmic length attached to vertices. We prove that there
exists such a labeling for checking a first-order formula with free set
variables in the graphs of every class that is \emph{nicely locally
cwd-decomposable}. This notion generalizes that of a \emph{nicely locally
tree-decomposable} class. The graphs of such classes can be covered by graphs
of bounded \emph{clique-width} with limited overlaps. We also consider such
labelings for \emph{bounded} first-order formulas on graph classes of
\emph{bounded expansion}. Some of these results are extended to counting
queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4717</identifier>
 <datestamp>2008-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4717</id><created>2008-11-28</created><authors><author><keyname>Teodorescu</keyname><forenames>Roxana</forenames><affiliation>UPT, LAB</affiliation></author><author><keyname>Racoceanu</keyname><forenames>Daniel</forenames><affiliation>LAB, IPAAL</affiliation></author><author><keyname>Leow</keyname><forenames>Wee-Kheng</forenames><affiliation>IPAAL, NUS</affiliation></author><author><keyname>Cretu</keyname><forenames>Vladimir</forenames><affiliation>UPT</affiliation></author></authors><title>Prospective Study for Semantic Inter-Media Fusion in Content-Based
  Medical Image Retrieval</title><categories>cs.IR cs.CL</categories><comments>11 pages</comments><proxy>ccsd hal-00342276</proxy><report-no>Onco-media Teodorescu 2008</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One important challenge in modern Content-Based Medical Image Retrieval
(CBMIR) approaches is represented by the semantic gap, related to the
complexity of the medical knowledge. Among the methods that are able to close
this gap in CBMIR, the use of medical thesauri/ontologies has interesting
perspectives due to the possibility of accessing on-line updated relevant
webservices and to extract real-time medical semantic structured information.
The CBMIR approach proposed in this paper uses the Unified Medical Language
System's (UMLS) Metathesaurus to perform a semantic indexing and fusion of
medical media. This fusion operates before the query processing (retrieval) and
works at an UMLS-compliant conceptual indexing level. Our purpose is to study
various techniques related to semantic data alignment, preprocessing, fusion,
clustering and retrieval, by evaluating the various techniques and highlighting
future research directions. The alignment and the preprocessing are based on
partial text/image retrieval feedback and on the data structure. We analyze
various probabilistic, fuzzy and evidence-based approaches for the fusion
process and different similarity functions for the retrieval process. All the
proposed methods are evaluated on the Cross Language Evaluation Forum's (CLEF)
medical image retrieval benchmark, by focusing also on a more homogeneous
component medical image database: the Pathology Education Instructional
Resource (PEIR).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4718</identifier>
 <datestamp>2008-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4718</id><created>2008-11-28</created><authors><author><keyname>Bracken</keyname><forenames>Carl</forenames></author><author><keyname>Zha</keyname><forenames>Zhengbang</forenames></author></authors><title>On the Fourier Spectra of the Infinite Families of Quadratic APN
  Functions</title><categories>cs.IT cs.CR cs.DM math.IT</categories><comments>12 pages, submitted to Adavances in the Mathematics of communication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that a quadratic function defined on a finite field of odd
degree is almost bent (AB) if and only if it is almost perfect nonlinear (APN).
For the even degree case there is no apparent relationship between the values
in the Fourier spectrum of a function and the APN property. In this article we
compute the Fourier spectrum of the new quadranomial family of APN functions.
With this result, all known infinite families of APN functions now have their
Fourier spectra and hence their nonlinearities computed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4720</identifier>
 <datestamp>2008-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4720</id><created>2008-11-28</created><authors><author><keyname>Bouhoula</keyname><forenames>Adel</forenames></author><author><keyname>Jacquemard</keyname><forenames>Florent</forenames></author></authors><title>Automated Induction for Complex Data Structures</title><categories>cs.LO cs.SC</categories><comments>This is the long version of a paper which appeared in IJCAR 2008. 38
  pages</comments><acm-class>F.4.1; F.4.2; F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a procedure for automated implicit inductive theorem proving for
equational specifications made of rewrite rules with conditions and
constraints. The constraints are interpreted over constructor terms
(representing data values), and may express syntactic equality, disequality,
ordering and also membership in a fixed tree language. Constrained equational
axioms between constructor terms are supported and can be used in order to
specify complex data structures like sets, sorted lists, trees, powerlists...
  Our procedure is based on tree grammars with constraints, a formalism which
can describe exactly the initial model of the given specification (when it is
sufficiently complete and terminating). They are used in the inductive proofs
first as an induction scheme for the generation of subgoals at induction steps,
second for checking validity and redundancy criteria by reduction to an
emptiness problem, and third for defining and solving membership constraints.
  We show that the procedure is sound and refutationally complete. It
generalizes former test set induction techniques and yields natural proofs for
several non-trivial examples presented in the paper, these examples are
difficult to specify and carry on automatically with related induction
procedures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4733</identifier>
 <datestamp>2008-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4733</id><created>2008-11-28</created><authors><author><keyname>Kanaan</keyname><forenames>Daniel</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Kinematic Analysis of a Serial - Parallel Machine Tool: the VERNE
  machine</title><categories>cs.RO</categories><proxy>ccsd hal-00342928</proxy><journal-ref>Mechanism and Machine Theory 44, 2 (2009) 487-498</journal-ref><doi>10.1016/j.mechmachtheory.2008.03.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper derives the inverse and the forward kinematic equations of a serial
- parallel 5-axis machine tool: the VERNE machine. This machine is composed of
a three-degree-of-freedom (DOF) parallel module and a two-DOF serial tilting
table. The parallel module consists of a moving platform that is connected to a
fixed base by three non-identical legs. These legs are connected in a way that
the combined effects of the three legs lead to an over-constrained mechanism
with complex motion. This motion is defined as a simultaneous combination of
rotation and translation. In this paper we propose symbolical methods that able
to calculate all kinematic solutions and identify the acceptable one by adding
analytical constraint on the disposition of legs of the parallel module.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4773</identifier>
 <datestamp>2009-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4773</id><created>2008-11-28</created><updated>2009-04-05</updated><authors><author><keyname>Permuter</keyname><forenames>Haim</forenames></author><author><keyname>Steinberg</keyname><forenames>Yossi</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Two-way source coding with a helper</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the two-way rate-distortion problem in which a helper sends a common
limited-rate message to both users based on side information at its disposal.
We characterize the region of achievable rates and distortions where a Markov
form (Helper)-(User 1)-(User 2) holds. The main insight of the result is that
in order to achieve the optimal rate, the helper may use a binning scheme, as
in Wyner-Ziv, where the side information at the decoder is the &quot;further&quot; user,
namely, User 2. We derive these regions explicitly for the Gaussian sources
with square error distortion, analyze a trade-off between the rate from the
helper and the rate from the source, and examine a special case where the
helper has the freedom to send different messages, at different rates, to the
encoder and the decoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0038</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0038</id><created>2008-11-28</created><updated>2010-11-14</updated><authors><author><keyname>Xie</keyname><forenames>Liang-Liang</forenames></author></authors><title>Omnidirectional Relay in Wireless Networks</title><categories>cs.IT math.IT</categories><comments>Revised</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For wireless networks with multiple sources, an omnidirectional relay scheme
is developed, where each node can simultaneously relay different messages in
different directions. This is accomplished by the decode-and-forward relay
strategy, with each relay binning the multiple messages to be transmitted, in
the same spirit of network coding. Specially for the all-source all-cast
problem, where each node is an independent source to be transmitted to all the
other nodes, this scheme completely eliminates interference in the whole
network, and the signal transmitted by any node can be used by any other node.
For networks with some kind of symmetry, assuming no beamforming is to be
performed, this omnidirectional relay scheme is capable of achieving the
maximum achievable rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0067</identifier>
 <datestamp>2008-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0067</id><created>2008-11-29</created><authors><author><keyname>Mourrain</keyname><forenames>Bernard</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Tr&#xe9;buchet</keyname><forenames>Philippe</forenames><affiliation>LIP6</affiliation></author></authors><title>Stable normal forms for polynomial system solving</title><categories>cs.SC</categories><proxy>ccsd inria-00343103</proxy><journal-ref>Theoretical Computer Science 409, 2 (2008) 229-240</journal-ref><doi>10.1016/j.tcs.2008.09.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes and analyzes a method for computing border bases of a
zero-dimensional ideal $I$. The criterion used in the computation involves
specific commutation polynomials and leads to an algorithm and an
implementation extending the one provided in [MT'05]. This general border basis
algorithm weakens the monomial ordering requirement for \grob bases
computations. It is up to date the most general setting for representing
quotient algebras, embedding into a single formalism Gr\&quot;obner bases, Macaulay
bases and new representation that do not fit into the previous categories. With
this formalism we show how the syzygies of the border basis are generated by
commutation relations. We also show that our construction of normal form is
stable under small perturbations of the ideal, if the number of solutions
remains constant. This new feature for a symbolic algorithm has a huge impact
on the practical efficiency as it is illustrated by the experiments on
classical benchmark polynomial systems, at the end of the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0070</identifier>
 <datestamp>2009-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0070</id><created>2008-11-29</created><authors><author><keyname>Firmansyah</keyname><forenames>I.</forenames></author><author><keyname>Akbar</keyname><forenames>Z.</forenames></author><author><keyname>Hermanto</keyname><forenames>B.</forenames></author><author><keyname>Handoko</keyname><forenames>L. T.</forenames></author></authors><title>An Integrated Software-based Solution for Modular and Self-independent
  Networked Robot</title><categories>cs.RO</categories><comments>9 pages, Proceeding of the 10th International Conference on Control,
  Automation, Robotics and Vision</comments><report-no>FISIKALIPI-08078</report-no><doi>10.1109/ICARCV.2008.4795695</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An integrated software-based solution for a modular and self-independent
networked robot is introduced. The wirelessly operatable robot has been
developed mainly for autonomous monitoring works with full control over web.
The integrated software solution covers three components : a) the digital
signal processing unit for data retrieval and monitoring system; b) the
externally executable codes for control system; and c) the web programming for
interfacing the end-users with the robot. It is argued that this integrated
software-based approach is crucial to realize a flexible, modular and low
development cost mobile monitoring apparatus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0088</identifier>
 <datestamp>2009-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0088</id><created>2008-11-29</created><authors><author><keyname>Janovitz-Freireich</keyname><forenames>Itnuit</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Szanto</keyname><forenames>Agnes</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Mourrain</keyname><forenames>Bernard</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Ronyai</keyname><forenames>Lajos</forenames></author></authors><title>Moment matrices, trace matrices and the radical of ideals</title><categories>cs.SC</categories><proxy>ccsd inria-00343126</proxy><journal-ref>nternational Conference on Symbolic and Algebraic Computation
  (2008) 125-132</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $f_1,...,f_s \in \mathbb{K}[x_1,...,x_m]$ be a system of polynomials
generating a zero-dimensional ideal $\I$, where $\mathbb{K}$ is an arbitrary
algebraically closed field. Assume that the factor algebra
$\A=\mathbb{K}[x_1,...,x_m]/\I$ is Gorenstein and that we have a bound
$\delta&gt;0$ such that a basis for $\A$ can be computed from multiples of
$f_1,...,f_s$ of degrees at most $\delta$. We propose a method using Sylvester
or Macaulay type resultant matrices of $f_1,...,f_s$ and $J$, where $J$ is a
polynomial of degree $\delta$ generalizing the Jacobian, to compute moment
matrices, and in particular matrices of traces for $\A$. These matrices of
traces in turn allow us to compute a system of multiplication matrices
$\{M_{x_i}|i=1,...,m\}$ of the radical $\sqrt{\I}$, following the approach in
the previous work by Janovitz-Freireich, R\'{o}nyai and Sz\'ant\'o.
Additionally, we give bounds for $\delta$ for the case when $\I$ has finitely
many projective roots in $\mathbb{P}^m_\CC$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0146</identifier>
 <datestamp>2013-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0146</id><created>2008-11-30</created><updated>2012-02-24</updated><authors><author><keyname>Pestov</keyname><forenames>Vladimir</forenames></author></authors><title>Lower Bounds on Performance of Metric Tree Indexing Schemes for Exact
  Similarity Search in High Dimensions</title><categories>cs.DS</categories><comments>21 pages, revised submission to Algorithmica, an improved and
  extended journal version of the conference paper arXiv:0812.0146v3 [cs.DS],
  with lower bounds strengthened, and the proof of the main Theorem 4
  simplified</comments><msc-class>68P10</msc-class><acm-class>H.3.3</acm-class><journal-ref>Algorithmica 66 (2013), 310-328</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Within a mathematically rigorous model, we analyse the curse of
dimensionality for deterministic exact similarity search in the context of
popular indexing schemes: metric trees. The datasets $X$ are sampled randomly
from a domain $\Omega$, equipped with a distance, $\rho$, and an underlying
probability distribution, $\mu$. While performing an asymptotic analysis, we
send the intrinsic dimension $d$ of $\Omega$ to infinity, and assume that the
size of a dataset, $n$, grows superpolynomially yet subexponentially in $d$.
Exact similarity search refers to finding the nearest neighbour in the dataset
$X$ to a query point $\omega\in\Omega$, where the query points are subject to
the same probability distribution $\mu$ as datapoints. Let $\mathscr F$ denote
a class of all 1-Lipschitz functions on $\Omega$ that can be used as decision
functions in constructing a hierarchical metric tree indexing scheme. Suppose
the VC dimension of the class of all sets $\{\omega\colon f(\omega)\geq a\}$,
$a\in\R$ is $o(n^{1/4}/\log^2n)$. (In view of a 1995 result of Goldberg and
Jerrum, even a stronger complexity assumption $d^{O(1)}$ is reasonable.) We
deduce the $\Omega(n^{1/4})$ lower bound on the expected average case
performance of hierarchical metric-tree based indexing schemes for exact
similarity search in $(\Omega,X)$. In paricular, this bound is superpolynomial
in $d$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0192</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0192</id><created>2008-11-30</created><updated>2009-12-05</updated><authors><author><keyname>Morsy</keyname><forenames>Mohamed H. S.</forenames></author><author><keyname>Sowailem</keyname><forenames>Mohammad Y. S.</forenames></author><author><keyname>Shalaby</keyname><forenames>Hossam M. H.</forenames></author></authors><title>A Simple Performance Analysis of a Core Node in an Optical Burst
  Switched Network</title><categories>cs.NI cs.PF</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0193</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0193</id><created>2008-11-30</created><updated>2009-12-05</updated><authors><author><keyname>Sowailem</keyname><forenames>Mohamed Y. S.</forenames></author><author><keyname>Morsy</keyname><forenames>Mohamed H. S.</forenames></author><author><keyname>Shalaby</keyname><forenames>Hossam M. H.</forenames></author></authors><title>Contention Resolution in Optical Burst Switched Networks using Spectral-
  Amplitude-Coding Optical Code Division Multiple Access</title><categories>cs.NI</categories><comments>This paper has been withdrawn by the authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the authors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0197</identifier>
 <datestamp>2008-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0197</id><created>2008-11-30</created><authors><author><keyname>Carlsson</keyname><forenames>Gunnar</forenames></author><author><keyname>de Silva</keyname><forenames>Vin</forenames></author></authors><title>Zigzag Persistence</title><categories>cs.CG</categories><comments>32 pages, 7 figures</comments><acm-class>I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new methodology for studying persistence of topological
features across a family of spaces or point-cloud data sets, called zigzag
persistence. Building on classical results about quiver representations, zigzag
persistence generalises the highly successful theory of persistent homology and
addresses several situations which are not covered by that theory. In this
paper we develop theoretical and algorithmic foundations with a view towards
applications in topological statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0198</identifier>
 <datestamp>2008-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0198</id><created>2008-11-30</created><authors><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Saberi</keyname><forenames>Amin</forenames></author></authors><title>Convergence to Equilibrium in Local Interaction Games and Ising Models</title><categories>cs.GT</categories><comments>17 pages, 2 eps figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coordination games describe social or economic interactions in which the
adoption of a common strategy has a higher payoff. They are classically used to
model the spread of conventions, behaviors, and technologies in societies. Here
we consider a two-strategies coordination game played asynchronously between
the nodes of a network. Agents behave according to a noisy best-response
dynamics.
  It is known that noise removes the degeneracy among equilibria: In the long
run, the ``risk-dominant'' behavior spreads throughout the network. Here we
consider the problem of computing the typical time scale for the spread of this
behavior. In particular, we study its dependence on the network structure and
derive a dichotomy between highly-connected, non-local graphs that show slow
convergence, and poorly connected, low dimensional graphs that show fast
convergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0209</identifier>
 <datestamp>2008-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0209</id><created>2008-11-30</created><authors><author><keyname>Yi</keyname><forenames>Ke</forenames></author><author><keyname>Zhang</keyname><forenames>Qin</forenames></author></authors><title>Optimal Tracking of Distributed Heavy Hitters and Quantiles</title><categories>cs.DS</categories><comments>10 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the the problem of tracking heavy hitters and quantiles in the
distributed streaming model. The heavy hitters and quantiles are two important
statistics for characterizing a data distribution. Let $A$ be a multiset of
elements, drawn from the universe $U=\{1,...,u\}$. For a given $0 \le \phi \le
1$, the $\phi$-heavy hitters are those elements of $A$ whose frequency in $A$
is at least $\phi |A|$; the $\phi$-quantile of $A$ is an element $x$ of $U$
such that at most $\phi|A|$ elements of $A$ are smaller than $A$ and at most
$(1-\phi)|A|$ elements of $A$ are greater than $x$. Suppose the elements of $A$
are received at $k$ remote {\em sites} over time, and each of the sites has a
two-way communication channel to a designated {\em coordinator}, whose goal is
to track the set of $\phi$-heavy hitters and the $\phi$-quantile of $A$
approximately at all times with minimum communication. We give tracking
algorithms with worst-case communication cost $O(k/\eps \cdot \log n)$ for both
problems, where $n$ is the total number of items in $A$, and $\eps$ is the
approximation error. This substantially improves upon the previous known
algorithms. We also give matching lower bounds on the communication costs for
both problems, showing that our algorithms are optimal. We also consider a more
general version of the problem where we simultaneously track the
$\phi$-quantiles for all $0 \le \phi \le 1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0262</identifier>
 <datestamp>2008-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0262</id><created>2008-12-01</created><authors><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author></authors><title>An evaluation of Bradfordizing effects</title><categories>cs.DL</categories><comments>8 pages, 9th COLLNET Meeting</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The purpose of this paper is to apply and evaluate the bibliometric method
Bradfordizing for information retrieval (IR) experiments. Bradfordizing is used
for generating core document sets for subject-specific questions and to reorder
result sets from distributed searches. The method will be applied and tested in
a controlled scenario of scientific literature databases from social and
political sciences, economics, psychology and medical science (SOLIS, SoLit,
USB Koeln Opac, CSA Sociological Abstracts, World Affairs Online, Psyndex and
Medline) and 164 standardized topics. An evaluation of the method and its
effects is carried out in two laboratory-based information retrieval
experiments (CLEF and KoMoHe) using a controlled document corpus and human
relevance assessments. The results show that Bradfordizing is a very robust
method for re-ranking the main document types (journal articles and monographs)
in today's digital libraries (DL). The IR tests show that relevance
distributions after re-ranking improve at a significant level if articles in
the core are compared with articles in the succeeding zones. The items in the
core are significantly more often assessed as relevant, than items in zone 2
(z2) or zone 3 (z3). The improvements between the zones are statistically
significant based on the Wilcoxon signed-rank test and the paired T-Test.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0283</identifier>
 <datestamp>2008-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0283</id><created>2008-12-01</created><authors><author><keyname>Homan</keyname><forenames>Christopher M.</forenames></author><author><keyname>Kosub</keyname><forenames>Sven</forenames></author></authors><title>Dichotomy Results for Fixed Point Counting in Boolean Dynamical Systems</title><categories>cs.CC cond-mat.dis-nn cs.DM nlin.AO nlin.CG</categories><comments>16 pages, extended abstract presented at 10th Italian Conference on
  Theoretical Computer Science (ICTCS'2007)</comments><report-no>revised version of TR No. TUM-I0706, Institut fuer Informatik, TU
  Muenchen</report-no><acm-class>F.2.2; F.1.1; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present dichotomy theorems regarding the computational complexity of
counting fixed points in boolean (discrete) dynamical systems, i.e., finite
discrete dynamical systems over the domain {0,1}. For a class F of boolean
functions and a class G of graphs, an (F,G)-system is a boolean dynamical
system with local transitions functions lying in F and graphs in G. We show
that, if local transition functions are given by lookup tables, then the
following complexity classification holds: Let F be a class of boolean
functions closed under superposition and let G be a graph class closed under
taking minors. If F contains all min-functions, all max-functions, or all
self-dual and monotone functions, and G contains all planar graphs, then it is
#P-complete to compute the number of fixed points in an (F,G)-system; otherwise
it is computable in polynomial time. We also prove a dichotomy theorem for the
case that local transition functions are given by formulas (over logical
bases). This theorem has a significantly more complicated structure than the
theorem for lookup tables. A corresponding theorem for boolean circuits
coincides with the theorem for formulas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0319</identifier>
 <datestamp>2008-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0319</id><created>2008-12-01</created><authors><author><keyname>Ekrem</keyname><forenames>Ersen</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Secrecy Capacity of a Class of Broadcast Channels with an Eavesdropper</title><categories>cs.IT math.IT</categories><comments>Submitted to EURASIP Journal on Wireless Communications and
  Networking (Special Issue on Wireless Physical Layer Security)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the security of communication between a single transmitter and
multiple receivers in a broadcast channel in the presence of an eavesdropper.
We consider several special classes of channels. As the first model, we
consider the degraded multi-receiver wiretap channel where the legitimate
receivers exhibit a degradedness order while the eavesdropper is more noisy
with respect to all legitimate receivers. We establish the secrecy capacity
region of this channel model. Secondly, we consider the parallel multi-receiver
wiretap channel with a less noisiness order in each sub-channel, where this
order is not necessarily the same for all sub-channels. We establish the common
message secrecy capacity and sum secrecy capacity of this channel. Thirdly, we
study a special class of degraded parallel multi-receiver wiretap channels and
provide a stronger result. In particular, we study the case with two
sub-channels two users and one eavesdropper, where there is a degradedness
order in each sub-channel such that in the first (resp. second) sub-channel the
second (resp. first) receiver is degraded with respect to the first (resp.
second) receiver, while the eavesdropper is degraded with respect to both
legitimate receivers in both sub-channels. We determine the secrecy capacity
region of this channel. Finally, we focus on a variant of this previous channel
model where the transmitter can use only one of the sub-channels at any time.
We characterize the secrecy capacity region of this channel as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0320</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0320</id><created>2008-12-01</created><authors><author><keyname>Joret</keyname><forenames>Gwena&#xeb;l</forenames></author></authors><title>Stackelberg Network Pricing is Hard to Approximate</title><categories>cs.DS cs.GT</categories><journal-ref>Networks, vol. 57, no. 2, pp. 117--120, 2011</journal-ref><doi>10.1002/net.20391</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Stackelberg Network Pricing problem, one has to assign tariffs to a
certain subset of the arcs of a given transportation network. The aim is to
maximize the amount paid by the user of the network, knowing that the user will
take a shortest st-path once the tariffs are fixed. Roch, Savard, and Marcotte
(Networks, Vol. 46(1), 57-67, 2005) proved that this problem is NP-hard, and
gave an O(log m)-approximation algorithm, where m denote the number of arcs to
be priced. In this note, we show that the problem is also APX-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0329</identifier>
 <datestamp>2008-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0329</id><created>2008-12-01</created><authors><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Bolcskei</keyname><forenames>Helmut</forenames></author></authors><title>Block-Sparsity: Coherence and Efficient Recovery</title><categories>cs.IT math.IT</categories><comments>Submitted to ICASSP 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider compressed sensing of block-sparse signals, i.e., sparse signals
that have nonzero coefficients occuring in clusters. Based on an uncertainty
relation for block-sparse signals, we define a block-coherence measure and we
show that a block-version of the orthogonal matching pursuit algorithm recovers
block k-sparse signals in no more than k steps if the block-coherence is
sufficiently small. The same condition on block-sparsity is shown to guarantee
successful recovery through a mixed l2/l1 optimization approach. The
significance of the results lies in the fact that making explicit use of
block-sparsity can yield better reconstruction properties than treating the
signal as being sparse in the conventional sense thereby ignoring the
additional structure in the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0340</identifier>
 <datestamp>2013-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0340</id><created>2008-12-01</created><updated>2009-10-01</updated><authors><author><keyname>Morgan</keyname><forenames>Simon P.</forenames></author><author><keyname>Yin</keyname><forenames>Wotao</forenames></author><author><keyname>Vixie</keyname><forenames>Kevin R.</forenames></author></authors><title>A Matlab Implementation of a Flat Norm Motivated Polygonal Edge Matching
  Method using a Decomposition of Boundary into Four 1-Dimensional Currents</title><categories>cs.CV cs.CG</categories><comments>Contains Matlab code and 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe and provide code and examples for a polygonal edge matching
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0372</identifier>
 <datestamp>2012-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0372</id><created>2008-12-01</created><authors><author><keyname>Gravin</keyname><forenames>Nikolay</forenames></author></authors><title>Non-degenerate colorings in the Brook's Theorem</title><categories>math.CO cs.DM</categories><comments>18 pages, 10 figures</comments><report-no>MR2641023</report-no><journal-ref>Diskretnaya Matematika, 2009 N4 pp. 105-128</journal-ref><doi>10.1515/DMA.2009.036</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $c\geq 2$ and $p\geq c$ be two integers. We will call a proper coloring
of the graph $G$ a \textit{$(c,p)$-nondegenerate}, if for any vertex of $G$
with degree at least $p$ there are at least $c$ vertices of different colors
adjacent to it. In our work we prove the following result, which generalizes
Brook's Theorem. Let $D\geq 3$ and $G$ be a graph without cliques on $D+1$
vertices and the degree of any vertex in this graph is not greater than $D$.
Then for every integer $c\geq 2$ there is a proper $(c,p)$-nondegenerate vertex
$D$-coloring of $G$, where $p=(c^3+8c^2+19c+6)(c+1).$ During the primary proof,
some interesting corollaries are derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0382</identifier>
 <datestamp>2008-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0382</id><created>2008-12-01</created><authors><author><keyname>Vattani</keyname><forenames>Andrea</forenames></author></authors><title>k-means requires exponentially many iterations even in the plane</title><categories>cs.CG cs.DS cs.LG</categories><comments>Submitted to SoCG 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The k-means algorithm is a well-known method for partitioning n points that
lie in the d-dimensional space into k clusters. Its main features are
simplicity and speed in practice. Theoretically, however, the best known upper
bound on its running time (i.e. O(n^{kd})) can be exponential in the number of
points. Recently, Arthur and Vassilvitskii [3] showed a super-polynomial
worst-case analysis, improving the best known lower bound from \Omega(n) to
2^{\Omega(\sqrt{n})} with a construction in d=\Omega(\sqrt{n}) dimensions. In
[3] they also conjectured the existence of superpolynomial lower bounds for any
d &gt;= 2.
  Our contribution is twofold: we prove this conjecture and we improve the
lower bound, by presenting a simple construction in the plane that leads to the
exponential lower bound 2^{\Omega(n)}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0387</identifier>
 <datestamp>2009-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0387</id><created>2008-12-01</created><updated>2009-12-13</updated><authors><author><keyname>Buchin</keyname><forenames>Kevin</forenames></author></authors><title>Delaunay Triangulations in Linear Time? (Part I)</title><categories>cs.CG cs.DS</categories><comments>8 pages, no figures; added footnote about newer algorithm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new and simple randomized algorithm for constructing the
Delaunay triangulation using nearest neighbor graphs for point location. Under
suitable assumptions, it runs in linear expected time for points in the plane
with polynomially bounded spread, i.e., if the ratio between the largest and
smallest pointwise distance is polynomially bounded. This also holds for point
sets with bounded spread in higher dimensions as long as the expected
complexity of the Delaunay triangulation of a sample of the points is linear in
the sample size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0389</identifier>
 <datestamp>2009-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0389</id><created>2008-12-01</created><updated>2009-11-09</updated><authors><author><keyname>Jegelka</keyname><forenames>Stefanie</forenames></author><author><keyname>Sra</keyname><forenames>Suvrit</forenames></author><author><keyname>Banerjee</keyname><forenames>Arindam</forenames></author></authors><title>Approximation Algorithms for Bregman Co-clustering and Tensor Clustering</title><categories>cs.DS cs.LG</categories><comments>18 pages; improved metric case</comments><journal-ref>short version in ALT 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the past few years powerful generalizations to the Euclidean k-means
problem have been made, such as Bregman clustering [7], co-clustering (i.e.,
simultaneous clustering of rows and columns of an input matrix) [9,18], and
tensor clustering [8,34]. Like k-means, these more general problems also suffer
from the NP-hardness of the associated optimization. Researchers have developed
approximation algorithms of varying degrees of sophistication for k-means,
k-medians, and more recently also for Bregman clustering [2]. However, there
seem to be no approximation algorithms for Bregman co- and tensor clustering.
In this paper we derive the first (to our knowledge) guaranteed methods for
these increasingly important clustering settings. Going beyond Bregman
divergences, we also prove an approximation factor for tensor clustering with
arbitrary separable metrics. Through extensive experiments we evaluate the
characteristics of our method, and show that it also has practical impact.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0438</identifier>
 <datestamp>2008-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0438</id><created>2008-12-02</created><authors><author><keyname>Thampi</keyname><forenames>Sabu M.</forenames></author></authors><title>An Introduction to Knowledge Management</title><categories>cs.DB cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowledge has been lately recognized as one of the most important assets of
organizations. Managing knowledge has grown to be imperative for the success of
a company. This paper presents an overview of Knowledge Management and various
aspects of secure knowledge management. A case study of knowledge management
activities at Tata Steel is also discussed
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0486</identifier>
 <datestamp>2008-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0486</id><created>2008-12-02</created><authors><author><keyname>Gurvich</keyname><forenames>Vladimir</forenames></author><author><keyname>Miltersen</keyname><forenames>Peter Bro</forenames></author></authors><title>On the computational complexity of solving stochastic mean-payoff games</title><categories>cs.GT</categories><comments>s</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider some well-known families of two-player, zero-sum, perfect
information games that can be viewed as special cases of Shapley's stochastic
games. We show that the following tasks are polynomial time equivalent:
  - Solving simple stochastic games.
  - Solving stochastic mean-payoff games with rewards and probabilities given
in unary. - Solving stochastic mean-payoff games with rewards and probabilities
given in binary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0492</identifier>
 <datestamp>2008-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0492</id><created>2008-12-02</created><authors><author><keyname>Miltersen</keyname><forenames>Peter Bro</forenames></author></authors><title>Trembling hand perfection is NP-hard</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is NP-hard to decide if a given pure-strategy Nash equilibrium of a given
three-player game in strategic form with integer payoffs is trembling hand
perfect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0515</identifier>
 <datestamp>2008-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0515</id><created>2008-12-02</created><updated>2008-12-02</updated><authors><author><keyname>Li</keyname><forenames>Cuilian</forenames><affiliation>Nanjing University of Posts &amp; Telecommunications</affiliation><affiliation>Zhejiang Wanli University</affiliation></author><author><keyname>Yang</keyname><forenames>Zhen</forenames><affiliation>Nanjing University of Posts &amp; Telecommunications</affiliation></author><author><keyname>Tian</keyname><forenames>Feng</forenames><affiliation>Nanjing University of Posts &amp; Telecommunications</affiliation></author></authors><title>A Relaying Incentive Scheme in Multihop Cellular Networks Based on
  Coalitional Game with Externalities</title><categories>cs.GT</categories><comments>21 pages,9 figures, 11 tables. Submitted to Wireless Personal
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperative multihop communication can greatly increase network throughput,
yet packet forwarding for other nodes involves opportunity and energy cost for
relays. Thus one of the pre-requisite problems in the successful implementation
of multihop transmission is how to foster cooperation among selfish nodes.
Existing researches mainly adopt monetary stimulating. In this manuscript, we
propose instead a simple and self-enforcing forwarding incentive scheme free of
indirect monetary remunerating for asymmetric (uplink multihop, downlink
single-hop) cellar network based on coalitional game theory, which comprises
double compensation, namely, Inter- BEA, global stimulating policy allotting
resources among relaying coalitions according to group size, and Intra-BEA,
local compensating and allocating rule within coalitions. Firstly, given the
global allotting policy, we introduce a fair allocation estimating approach
which includes remunerating for relaying cost using Myerson value for partition
function game, to enlighten the design of local allocating rules. Secondly,
given the inter- and intra-BEA relay fostering approach, we check stability of
coalition structures in terms of internal and external stability as well as
inductive core. Theoretic analysis and numerical simulation show that our
measure can provide communication opportunities for outer ring nodes and
enlarge system coverage, while at the same time provide enough motivation with
respect to resource allocation and energy saving for nodes in inner and middle
ring to relay for own profits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0564</identifier>
 <datestamp>2008-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0564</id><created>2008-12-02</created><authors><author><keyname>Cheney</keyname><forenames>James</forenames></author><author><keyname>Acar</keyname><forenames>Umut</forenames></author><author><keyname>Ahmed</keyname><forenames>Amal</forenames></author></authors><title>Provenance Traces</title><categories>cs.PL cs.DB</categories><comments>Technical report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Provenance is information about the origin, derivation, ownership, or history
of an object. It has recently been studied extensively in scientific databases
and other settings due to its importance in helping scientists judge data
validity, quality and integrity. However, most models of provenance have been
stated as ad hoc definitions motivated by informal concepts such as &quot;comes
from&quot;, &quot;influences&quot;, &quot;produces&quot;, or &quot;depends on&quot;. These models lack clear
formalizations describing in what sense the definitions capture these intuitive
concepts. This makes it difficult to compare approaches, evaluate their
effectiveness, or argue about their validity.
  We introduce provenance traces, a general form of provenance for the nested
relational calculus (NRC), a core database query language. Provenance traces
can be thought of as concrete data structures representing the operational
semantics derivation of a computation; they are related to the traces that have
been used in self-adjusting computation, but differ in important respects. We
define a tracing operational semantics for NRC queries that produces both an
ordinary result and a trace of the execution. We show that three pre-existing
forms of provenance for the NRC can be extracted from provenance traces.
Moreover, traces satisfy two semantic guarantees: consistency, meaning that the
traces describe what actually happened during execution, and fidelity, meaning
that the traces &quot;explain&quot; how the expression would behave if the input were
changed. These guarantees are much stronger than those contemplated for
previous approaches to provenance; thus, provenance traces provide a general
semantic foundation for comparing and unifying models of provenance in
databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0581</identifier>
 <datestamp>2009-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0581</id><created>2008-12-02</created><updated>2009-05-12</updated><authors><author><keyname>Blond</keyname><forenames>Stevens Le</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Legout</keyname><forenames>Arnaud</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Dabbous</keyname><forenames>Walid</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>Pushing BitTorrent Locality to the Limit</title><categories>cs.NI</categories><proxy>ccsd inria-00343822</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Peer-to-peer (P2P) locality has recently raised a lot of interest in the
community. Indeed, whereas P2P content distribution enables financial savings
for the content providers, it dramatically increases the traffic on inter-ISP
links. To solve this issue, the idea to keep a fraction of the P2P traffic
local to each ISP was introduced a few years ago. Since then, P2P solutions
exploiting locality have been introduced. However, several fundamental issues
on locality still need to be explored. In particular, how far can we push
locality, and what is, at the scale of the Internet, the reduction of traffic
that can be achieved with locality? In this paper, we perform extensive
experiments on a controlled environment with up to 10 000 BitTorrent clients to
evaluate the impact of high locality on inter-ISP links traffic and peers
download completion time. We introduce two simple mechanisms that make high
locality possible in challenging scenarios and we show that we save up to
several orders of magnitude inter-ISP traffic compared to traditional locality
without adversely impacting peers download completion time. In addition, we
crawled 214 443 torrents representing 6 113 224 unique peers spread among 9 605
ASes. We show that whereas the torrents we crawled generated 11.6 petabytes of
inter-ISP traffic, our locality policy implemented for all torrents would have
reduced the global inter-ISP traffic by 40%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0598</identifier>
 <datestamp>2008-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0598</id><created>2008-12-02</created><updated>2008-12-05</updated><authors><author><keyname>Poplawski</keyname><forenames>Laura J.</forenames></author><author><keyname>Rajaraman</keyname><forenames>Rajmohan</forenames></author><author><keyname>Sundaram</keyname><forenames>Ravi</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>Preference Games and Personalized Equilibria, with Applications to
  Fractional BGP</title><categories>cs.GT cs.DS</categories><comments>25 pages, 3 figures, v2: minor editorial changes</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of computing equilibria in two classes of network
games based on flows - fractional BGP (Border Gateway Protocol) games and
fractional BBC (Bounded Budget Connection) games. BGP is the glue that holds
the Internet together and hence its stability, i.e. the equilibria of
fractional BGP games (Haxell, Wilfong), is a matter of practical importance.
BBC games (Laoutaris et al) follow in the tradition of the large body of work
on network formation games and capture a variety of applications ranging from
social networks and overlay networks to peer-to-peer networks.
  The central result of this paper is that there are no fully polynomial-time
approximation schemes (unless PPAD is in FP) for computing equilibria in both
fractional BGP games and fractional BBC games. We obtain this result by proving
the hardness for a new and surprisingly simple game, the fractional preference
game, which is reducible to both fractional BGP and BBC games.
  We define a new flow-based notion of equilibrium for matrix games --
personalized equilibria -- generalizing both fractional BBC and fractional BGP
games. We prove not just the existence, but the existence of rational
personalized equilibria for all matrix games, which implies the existence of
rational equilibria for fractional BGP and BBC games. In particular, this
provides an alternative proof and strengthening of the main result in [Haxell,
Wilfong]. For k-player matrix games, where k = 2, we provide a combinatorial
characterization leading to a polynomial-time algorithm for computing all
personalized equilibria. For k &gt;= 5, we prove that personalized equilibria are
PPAD-hard to approximate in fully polynomial time. We believe that the concept
of personalized equilibria has potential for real-world significance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0601</identifier>
 <datestamp>2009-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0601</id><created>2008-12-02</created><updated>2009-06-22</updated><authors><author><keyname>Lin</keyname><forenames>Shaowei</forenames></author><author><keyname>Sturmfels</keyname><forenames>Bernd</forenames></author></authors><title>Polynomial relations among principal minors of a 4x4-matrix</title><categories>math.AG cs.SC math.AC</categories><comments>16 pages, v2: Remark 14</comments><msc-class>14M12, 15A72, 15A29, 15A15, 13P10, 14L30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The image of the principal minor map for n x n-matrices is shown to be
closed. In the 19th century, Nansen and Muir studied the implicitization
problem of finding all relations among principal minors when n=4. We complete
their partial results by constructing explicit polynomials of degree 12 that
scheme-theoretically define this affine variety and also its projective closure
in $\PP^{15}$. The latter is the main component in the singular locus of the 2
x 2 x 2 x 2-hyperdeterminant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0607</identifier>
 <datestamp>2010-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0607</id><created>2008-12-02</created><updated>2010-05-13</updated><authors><author><keyname>Dickerson</keyname><forenames>Matthew</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Wortman</keyname><forenames>Kevin A.</forenames></author></authors><title>Dilation, smoothed distance, and minimization diagrams of convex
  functions</title><categories>cs.CG</categories><comments>10 pages, 6 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study Voronoi diagrams for distance functions that add together two convex
functions, each taking as its argument the difference between Cartesian
coordinates of two planar points. When the functions do not grow too quickly,
then the Voronoi diagram has linear complexity and can be constructed in
near-linear randomized expected time. Additionally, the level sets of the
distances from the sites form a family of pseudocircles in the plane, all cells
in the Voronoi diagram are connected, and the set of bisectors separating any
one cell in the diagram from each of the others forms an arrangement of
pseudolines in the plane. We apply these results to the smoothed distance or
biotope transform metric, a geometric analogue of the Jaccard distance whose
Voronoi diagrams can be used to determine the dilation of a star network with a
given hub. For sufficiently closely spaced points in the plane, the Voronoi
diagram of smoothed distance has linear complexity and can be computed
efficiently. We also experiment with a variant of Lloyd's algorithm, adapted to
smoothed distance, to find uniformly spaced point samples with exponentially
decreasing density around a given point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0617</identifier>
 <datestamp>2008-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0617</id><created>2008-12-02</created><authors><author><keyname>Liu</keyname><forenames>Nan</forenames><affiliation>Shitz</affiliation></author><author><keyname>Maric</keyname><forenames>Ivana</forenames><affiliation>Shitz</affiliation></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>The Capacity Region of the Cognitive Z-interference Channel with One
  Noiseless Component</title><categories>cs.IT math.IT</categories><comments>The conference version has been submitted to ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the discrete memoryless Z-interference channel (ZIC) where the
transmitter of the pair that suffers from interference is cognitive. We first
provide upper and lower bounds on the capacity of this channel. We then show
that, when the channel of the transmitter-receiver pair that does not face
interference is noiseless, the two bounds coincide and therefore yield the
capacity region. The obtained results imply that, unlike in the Gaussian
cognitive ZIC, in the considered channel superposition encoding at the
non-cognitive transmitter as well as Gel'fand-Pinsker encoding at the cognitive
transmitter are needed in order to minimize the impact of interference. As a
byproduct of the obtained capacity region, we obtain the capacity result for a
generalized Gel'fand-Pinsker problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0621</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0621</id><created>2008-12-02</created><updated>2011-06-27</updated><authors><author><keyname>Jose</keyname><forenames>Jubin</forenames></author><author><keyname>Ashikhmin</keyname><forenames>Alexei</forenames></author><author><keyname>Whiting</keyname><forenames>Phil</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Channel Estimation and Linear Precoding in Multiuser Multiple-Antenna
  TDD Systems</title><categories>cs.IT math.IT</categories><journal-ref>IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 60, NO. 5, JUNE
  2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional approaches in the analysis of downlink systems decouple the
precoding and the channel estimation problems. However, in cellular systems
with mobile users, these two problems are in fact tightly coupled. In this
paper, this coupling is explicitly studied by accounting for channel training
overhead and estimation error while determining the overall system throughput.
The paper studies the problem of utilizing imperfect channel estimates for
efficient linear precoding and user selection. It presents precoding methods
that take into account the degree of channel estimation error.
Information-theoretic lower and upper bounds are derived to evaluate the
performance of these precoding methods. In typical scenarios, these bounds are
close.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0629</identifier>
 <datestamp>2009-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0629</id><created>2008-12-02</created><updated>2009-06-18</updated><authors><author><keyname>Li</keyname><forenames>Cuilian</forenames><affiliation>Nanjing University of Posts &amp; Telecommunications</affiliation><affiliation>Zhejiang Wanli University</affiliation></author><author><keyname>Yang</keyname><forenames>Zhen</forenames><affiliation>Nanjing University of Posts &amp; Telecommunications</affiliation></author><author><keyname>Li</keyname><forenames>Jun</forenames><affiliation>Zhejiang Wanli University</affiliation></author><author><keyname>Tian</keyname><forenames>Feng</forenames><affiliation>Nanjing University of Posts &amp; Telecommunications</affiliation></author></authors><title>Dynamic spectrum sharing game by lease</title><categories>cs.GT</categories><comments>15 pages, 4 figures, 1 table. Revision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose and analyze a dynamic implementation of the property-rights model
of cognitive radio. A primary link has the possibility to lease the owned
spectrum to a MAC network of secondary nodes, in exchange for cooperation in
the form of distributed space-time coding (DSTC). The cooperation and
competition between the primary and secondary network are cast in the framework
of sequential game. On one hand, the primary link attempts to maximize its
quality of service in terms of signal-to-interference-plus-noise ratio (SINR);
on the other hand, nodes in the secondary network compete for transmission
within the leased time-slot following a power control mechanism. We consider
both a baseline model with complete information and a more practical version
with incomplete information, using the backward induction approach for the
former and providing approximate algorithm for the latter. Analysis and
numerical results show that our models and algorithms provide a promising
framework for fair and effective spectrum sharing, both between primary and
secondary networks and among secondary nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0635</identifier>
 <datestamp>2008-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0635</id><created>2008-12-02</created><authors><author><keyname>Li</keyname><forenames>Cuilian</forenames><affiliation>Nanjing University of Posts &amp; Telecommunications</affiliation><affiliation>Zhejiang Wanli University</affiliation></author><author><keyname>Yang</keyname><forenames>Zhen</forenames><affiliation>Nanjing University of Posts &amp; Telecommunications</affiliation></author></authors><title>Analysis of Group Multiuser Detection Based on Coalitional Game</title><categories>cs.GT</categories><comments>4 pages, 5 figures. Accepted by ICWMMN2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The issue of group-blind multiuser detection in MAC channel among wireless
nodes in the environment of multiple networks coexisting and sharing spectrum
is addressed under the Framework of coalitional game. We investigate the
performance and stability of multiple access channel (MAC) with linear
decorrelating multiuser detection under varying SNR, channel gains and
coalitional structures, in which both single BS and multiple BSs cases were
considered. The main results and conclusion are as follows: (1) the grand
coalition is payoff maximizing under loose SNR; (2) it is in conformity with
group and coalitional rationality forming coalition among nodes that have
comparative channel gains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0659</identifier>
 <datestamp>2008-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0659</id><created>2008-12-03</created><authors><author><keyname>Baral</keyname><forenames>Chitta</forenames></author><author><keyname>Gelfond</keyname><forenames>Michael</forenames></author><author><keyname>Rushton</keyname><forenames>Nelson</forenames></author></authors><title>Probabilistic reasoning with answer sets</title><categories>cs.AI cs.LO</categories><comments>77 pages. To appear in Theory and Practice of Logic Programming
  (TPLP)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a declarative language, P-log, that combines logical and
probabilistic arguments in its reasoning. Answer Set Prolog is used as the
logical foundation, while causal Bayes nets serve as a probabilistic
foundation. We give several non-trivial examples and illustrate the use of
P-log for knowledge representation and updating of knowledge. We argue that our
approach to updates is more appealing than existing approaches. We give
sufficiency conditions for the coherency of P-log programs and show that Bayes
nets can be easily mapped to coherent P-log programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0686</identifier>
 <datestamp>2008-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0686</id><created>2008-12-03</created><authors><author><keyname>Tapiador</keyname><forenames>Juan M. E.</forenames></author><author><keyname>Alcaide</keyname><forenames>Almudena</forenames></author><author><keyname>Hernandez-Castro</keyname><forenames>Julio C.</forenames></author><author><keyname>Ribagorda</keyname><forenames>Arturo</forenames></author></authors><title>Cryptanalysis of the RSA-CEGD protocol</title><categories>cs.CR</categories><comments>8 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Nenadi\'c et al. (2004) proposed the RSA-CEGD protocol for
certified delivery of e-goods. This is a relatively complex scheme based on
verifiable and recoverable encrypted signatures (VRES) to guarantee properties
such as strong fairness and non-repudiation, among others. In this paper, we
demonstrate how this protocol cannot achieve fairness by presenting a severe
attack and also pointing out some other weaknesses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0698</identifier>
 <datestamp>2008-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0698</id><created>2008-12-03</created><authors><author><keyname>Cattuto</keyname><forenames>Ciro</forenames></author><author><keyname>Baldassarri</keyname><forenames>Andrea</forenames></author><author><keyname>Servedio</keyname><forenames>Vito D. P.</forenames></author><author><keyname>Loreto</keyname><forenames>Vittorio</forenames></author></authors><title>Emergent Community Structure in Social Tagging Systems</title><categories>cs.IR cs.CY cs.HC</categories><comments>14 pages, 8 figures</comments><journal-ref>Advances in Complex Systems 11, 597 (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A distributed classification paradigm known as collaborative tagging has been
widely adopted in new Web applications designed to manage and share online
resources. Users of these applications organize resources (Web pages, digital
photographs, academic papers) by associating with them freely chosen text
labels, or tags. Here we leverage the social aspects of collaborative tagging
and introduce a notion of resource distance based on the collective tagging
activity of users. We collect data from a popular system and perform
experiments showing that our definition of distance can be used to build a
weighted network of resources with a detectable community structure. We show
that this community structure clearly exposes the semantic relations among
resources. The communities of resources that we observe are a genuinely
emergent feature, resulting from the uncoordinated activity of a large number
of users, and their detection paves the way for mapping emergent semantics in
social tagging systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0706</identifier>
 <datestamp>2008-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0706</id><created>2008-12-03</created><authors><author><keyname>Chakraborty</keyname><forenames>Soubhik</forenames></author><author><keyname>Ranganayakulu</keyname><forenames>Rayalla</forenames></author><author><keyname>Chauhan</keyname><forenames>Shivee</forenames></author><author><keyname>Solanki</keyname><forenames>Sandeep Singh</forenames></author><author><keyname>Mahto</keyname><forenames>Kartik</forenames></author></authors><title>Which notes are Vadi-Samvadi in Raga Rageshree?</title><categories>cs.SD</categories><comments>20 pages;04 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notes which play the most important and second most important roles in
expressing a raga are called Vadi and Samvadi swars respectively in (North)
Indian Classical music. Like Bageshree, Bhairavi, Shankara, Hamir and Kalingra,
Rageshree is another controversial raga so far as the choice of Vadi-Samvadi
selection is concerned where there are two different opinions. In the present
work, a two minute vocal recording of raga Rageshree is subjected to a careful
statistical analysis. Our analysis is broken into three phases: first half,
middle half and last half. Under a multinomial model set up holding appreciably
in the first two phases, only one opinion is found acceptable. In the last
phase the distribution seems to be quasi multinomial, characterized by an
unstable nature of relative occurrence of pitch of all the notes and although
the note whose relative occurrence of pitch suddenly shoots is the Vadi swar
selected from our analysis of the first two phases, we take it as an outlier
demanding a separate treatment like any other in statistics. Selection of
Vadi-Samvadi notes in a quasi-multinomial set up is still an open research
problem. An interesting musical cocktail is proposed, however, embedding
several ideas like melodic property of notes, note combinations and pitch
movements between notes, using some weighted combination of psychological and
statistical stability of notes along with watching carefully the sudden shoot
of one or more notes whenever there is enough evidence that multinomial model
has broken down.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0736</identifier>
 <datestamp>2008-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0736</id><created>2008-12-03</created><authors><author><keyname>Bui</keyname><forenames>Alain</forenames></author><author><keyname>Flauzac</keyname><forenames>Olivier</forenames></author><author><keyname>Rabat</keyname><forenames>Cyril</forenames></author></authors><title>Fully distributed and fault tolerant task management based on diffusions</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The task management is a critical component for the computational grids. The
aim is to assign tasks on nodes according to a global scheduling policy and a
view of local resources of nodes. A peer-to-peer approach for the task
management involves a better scalability for the grid and a higher fault
tolerance. But some mechanisms have to be proposed to avoid the computation of
replicated tasks that can reduce the efficiency and increase the load of nodes.
In the same way, these mechanisms have to limit the number of exchanged
messages to avoid the overload of the network.
  In a previous paper, we have proposed two methods for the task management
called active and passive. These methods are based on a random walk: they are
fully distributed and fault tolerant. Each node owns a local tasks states set
updated thanks to a random walk and each node is in charge of the local
assignment. Here, we propose three methods to improve the efficiency of the
active method. These new methods are based on a circulating word. The nodes
local tasks states sets are updated thanks to periodical diffusions along trees
built from the circulating word. Particularly, we show that these methods
increase the efficiency of the active method: they produce less replicated
tasks. These three methods are also fully distributed and fault tolerant. On
the other way, the circulating word can be exploited for other applications
like the resources management or the nodes synchronization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0743</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0743</id><created>2008-12-03</created><updated>2009-10-10</updated><authors><author><keyname>Li</keyname><forenames>Qiang</forenames></author><author><keyname>He</keyname><forenames>Yan</forenames></author><author><keyname>Jiang</keyname><forenames>Jing-ping</forenames></author></authors><title>A Novel Clustering Algorithm Based on Quantum Games</title><categories>cs.LG cs.AI cs.CV cs.GT cs.MA cs.NE quant-ph</categories><comments>19 pages, 5 figures, 5 tables</comments><journal-ref>2009 J. Phys. A: Math. Theor. 42 445303</journal-ref><doi>10.1088/1751-8113/42/44/445303</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Enormous successes have been made by quantum algorithms during the last
decade. In this paper, we combine the quantum game with the problem of data
clustering, and then develop a quantum-game-based clustering algorithm, in
which data points in a dataset are considered as players who can make decisions
and implement quantum strategies in quantum games. After each round of a
quantum game, each player's expected payoff is calculated. Later, he uses a
link-removing-and-rewiring (LRR) function to change his neighbors and adjust
the strength of links connecting to them in order to maximize his payoff.
Further, algorithms are discussed and analyzed in two cases of strategies, two
payoff matrixes and two LRR functions. Consequently, the simulation results
have demonstrated that data points in datasets are clustered reasonably and
efficiently, and the clustering algorithms have fast rates of convergence.
Moreover, the comparison with other algorithms also provides an indication of
the effectiveness of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0754</identifier>
 <datestamp>2009-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0754</id><created>2008-12-03</created><updated>2009-03-04</updated><authors><author><keyname>Zhang</keyname><forenames>Jinshan</forenames></author></authors><title>Strong Spatial Mixing and Approximating Partition Functions of Two-State
  Spin Systems without Hard Constrains</title><categories>cs.DM cs.GR</categories><comments>9 pages</comments><acm-class>F.2.0</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We prove Gibbs distribution of two-state spin systems(also known as binary
Markov random fields) without hard constrains on a tree exhibits strong spatial
mixing(also known as strong correlation decay), under the assumption that, for
arbitrary `external field', the absolute value of `inverse temperature' is
small, or the `external field' is uniformly large or small. The first condition
on `inverse temperature' is tight if the distribution is restricted to
ferromagnetic or antiferromagnetic Ising models.
  Thanks to Weitz's self-avoiding tree, we extends the result for sparse on
average graphs, which generalizes part of the recent work of Mossel and
Sly\cite{MS08}, who proved the strong spatial mixing property for ferromagnetic
Ising model. Our proof yields a different approach, carefully exploiting the
monotonicity of local recursion. To our best knowledge, the second condition of
`external field' for strong spatial mixing in this paper is first considered
and stated in term of `maximum average degree' and `interaction energy'. As an
application, we present an FPTAS for partition functions of two-state spin
models without hard constrains under the above assumptions in a general family
of graphs including interesting bounded degree graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0759</identifier>
 <datestamp>2008-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0759</id><created>2008-12-03</created><authors><author><keyname>Balasubramanian</keyname><forenames>R.</forenames></author><author><keyname>Bhatnagar</keyname><forenames>Gaurav</forenames></author></authors><title>A new Contrast Based Image Fusion using Wavelet Packets</title><categories>cs.IT cs.MM math.IT</categories><comments>5 Pages, 10 Figures, 1 Table</comments><journal-ref>Proc. of IEEE Conference on Applications of Intelligent Systems
  (AIS 2008), March 13-15, 2008, Sonepat, India, pp. 141-145.
  (ISBN:978-81-906531-0-7)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image Fusion, a technique which combines complimentary information from
different images of the same scene so that the fused image is more suitable for
segmentation, feature extraction, object recognition and Human Visual System.
In this paper, a simple yet efficient algorithm is presented based on contrast
using wavelet packet decomposition. First, all the source images are decomposed
into low and high frequency sub-bands and then fusion of high frequency
sub-bands is done by the means of Directive Contrast. Now, inverse wavelet
packet transform is performed to reconstruct the fused image. The performance
of the algorithm is carried out by the comparison made between proposed and
existing algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0790</identifier>
 <datestamp>2008-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0790</id><created>2008-12-03</created><authors><author><keyname>Pontelli</keyname><forenames>Enrico</forenames></author><author><keyname>Son</keyname><forenames>Tran Cao</forenames></author><author><keyname>Elkhatib</keyname><forenames>Omar</forenames></author></authors><title>Justifications for Logic Programs under Answer Set Semantics</title><categories>cs.AI cs.PL</categories><comments>59 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper introduces the notion of off-line justification for Answer Set
Programming (ASP). Justifications provide a graph-based explanation of the
truth value of an atom w.r.t. a given answer set. The paper extends also this
notion to provide justification of atoms during the computation of an answer
set (on-line justification), and presents an integration of on-line
justifications within the computation model of Smodels. Off-line and on-line
justifications provide useful tools to enhance understanding of ASP, and they
offer a basic data structure to support methodologies and tools for debugging
answer set programs. A preliminary implementation has been developed in
ASP-PROLOG.
  (To appear in Theory and Practice of Logic Programming (TPLP))
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0852</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0852</id><created>2008-12-03</created><updated>2009-03-10</updated><authors><author><keyname>Qiu</keyname><forenames>Daowen</forenames></author><author><keyname>Yu</keyname><forenames>Sheng</forenames></author></authors><title>Hierarchy and equivalence of multi-letter quantum finite automata</title><categories>cs.CC</categories><comments>22 pages, 8 figures. The is a further revised version, and it has
  been accepted for publication in Theoretical Computer Science</comments><acm-class>F.1.1; F.1.2; F.4.3</acm-class><journal-ref>Theoretical Computer Science, 410 (30-32) (2009) 3006-3017.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-letter {\it quantum finite automata} (QFAs) were a new one-way QFA
model proposed recently by Belovs, Rosmanis, and Smotrovs (LNCS, Vol. 4588,
Springer, Berlin, 2007, pp. 60-71), and they showed that multi-letter QFAs can
accept with no error some regular languages ($(a+b)^{*}b$) that are
unacceptable by the one-way QFAs. In this paper, we continue to study
multi-letter QFAs. We mainly focus on two issues: (1) we show that
$(k+1)$-letter QFAs are computationally more powerful than $k$-letter QFAs,
that is, $(k+1)$-letter QFAs can accept some regular languages that are
unacceptable by any $k$-letter QFA. A comparison with the one-way QFAs is made
by some examples; (2) we prove that a $k_{1}$-letter QFA ${\cal A}_1$ and
another $k_{2}$-letter QFA ${\cal A}_2$ are equivalent if and only if they are
$(n_{1}+n_{2})^{4}+k-1$-equivalent, and the time complexity of determining the
equivalence of two multi-letter QFAs using this method is
$O(n^{12}+k^{2}n^{4}+kn^{8})$, where $n_{1}$ and $n_{2}$ are the numbers of
states of ${\cal A}_{1}$ and ${\cal A}_{2}$, respectively, and
$k=\max(k_{1},k_{2})$. Some other issues are addressed for further
consideration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0872</identifier>
 <datestamp>2008-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0872</id><created>2008-12-04</created><authors><author><keyname>Theran</keyname><forenames>Louis</forenames></author></authors><title>Rigid Components of Random Graphs</title><categories>math.CO cs.CG</categories><msc-class>05C80; 68R10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The planar rigidity problem asks, given a set of m pairwise distances among a
set P of n unknown points, whether it is possible to reconstruct P, up to a
finite set of possibilities (modulo rigid motions of the plane). The celebrated
Maxwell-Laman Theorem from Rigidity Theory says that, generically, the rigidity
problem has a combinatorial answer: the underlying combinatorial structure must
contain a spanning minimally-rigid graph (Laman graph). In the case where the
system is not rigid, its inclusion-wise maximal rigid substructures (rigid
components) are also combinatorially characterized via the Maxwell-Laman
theorem, and may be found efficiently.
  Physicists have used planar combinatorial rigidity has been used to study the
phase transition between liquid and solid in network glasses. The approach has
been to generate a graph via a stochastic process and then experimentally
analyze its rigidity properties. Of particular interest is the size of the
largest rigid components.
  In this paper, we study the emergence of rigid components in an Erdos-Renyi
random graph G(n,p), using the parameterization p=c/n for a fixed constant c&gt;0.
Our first result is that for all c&gt;0, almost surely all rigid components have
size 2, 3 or Omega(n). We also show that for c&gt;4, almost surely the largest
rigid components have size at least n/10.
  While the G(n,p) model is simpler than those appearing in the physics
literature, these results are the first of this type where the distribution is
over all graphs on n vertices and the expected number of edges is O(n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0874</identifier>
 <datestamp>2008-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0874</id><created>2008-12-04</created><authors><author><keyname>Feng</keyname><forenames>Guihuan</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Viard-Gaudin</keyname><forenames>Christian</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Stroke Fragmentation based on Geometry Features and HMM</title><categories>cs.HC cs.CV</categories><proxy>ccsd hal-00344151</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stroke fragmentation is one of the key steps in pen-based interaction. In
this letter, we present a unified HMM-based stroke fragmentation technique that
can do segment point location and primitive type determination simultaneously.
The geometry features included are used to evaluate local features, and the HMM
model is utilized to measure the global drawing context. Experiments prove that
the model can efficiently represent smooth curves as well as strokes made up of
arbitrary lines and circular arcs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0882</identifier>
 <datestamp>2008-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0882</id><created>2008-12-04</created><authors><author><keyname>Thomas</keyname><forenames>Philippe</forenames><affiliation>CRAN</affiliation></author><author><keyname>Thomas</keyname><forenames>Andr&#xe9;</forenames><affiliation>CRAN</affiliation></author></authors><title>Elagage d'un perceptron multicouches : utilisation de l'analyse de la
  variance de la sensibilit\'e des param\`etres</title><categories>cs.NE</categories><comments>6 pages</comments><proxy>ccsd hal-00320832</proxy><journal-ref>Conf\'erence Internationale Francophone d'Automatique CIFA'08,
  Bucarest : Roumanie (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stucture determination of a neural network for the modelisation of a
system remain the core of the problem. Within this framework, we propose a
pruning algorithm of the network based on the use of the analysis of the
sensitivity of the variance of all the parameters of the network. This
algorithm will be tested on two examples of simulation and its performances
will be compared with three other algorithms of pruning of the literature
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0885</identifier>
 <datestamp>2013-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0885</id><created>2008-12-04</created><updated>2013-02-09</updated><authors><author><keyname>Horvat</keyname><forenames>Marko</forenames></author></authors><title>Elementary epistemological features of machine intelligence</title><categories>cs.AI</categories><comments>The paper needs to be redesigned</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Theoretical analysis of machine intelligence (MI) is useful for defining a
common platform in both theoretical and applied artificial intelligence (AI).
The goal of this paper is to set canonical definitions that can assist
pragmatic research in both strong and weak AI. Described epistemological
features of machine intelligence include relationship between intelligent
behavior, intelligent and unintelligent machine characteristics, observable and
unobservable entities and classification of intelligence. The paper also
establishes algebraic definitions of efficiency and accuracy of MI tests as
their quality measure. The last part of the paper addresses the learning
process with respect to the traditional epistemology and the epistemology of MI
described here. The proposed views on MI positively correlate to the Hegelian
monistic epistemology and contribute towards amalgamating idealistic
deliberations with the AI theory, particularly in a local frame of reference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0893</identifier>
 <datestamp>2010-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0893</id><created>2008-12-04</created><updated>2009-05-13</updated><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Strash</keyname><forenames>Darren</forenames></author></authors><title>Linear-Time Algorithms for Geometric Graphs with Sublinearly Many Edge
  Crossings</title><categories>cs.CG cs.DM cs.DS cs.GR</categories><comments>Expanded version of a paper appearing at the 20th ACM-SIAM Symposium
  on Discrete Algorithms (SODA09)</comments><acm-class>F.2.2; G.2.2; G.3</acm-class><journal-ref>SIAM J. Computing 39(8): 3814-3829, 2010</journal-ref><doi>10.1137/090759112</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide linear-time algorithms for geometric graphs with sublinearly many
crossings. That is, we provide algorithms running in O(n) time on connected
geometric graphs having n vertices and k crossings, where k is smaller than n
by an iterated logarithmic factor. Specific problems we study include Voronoi
diagrams and single-source shortest paths. Our algorithms all run in linear
time in the standard comparison-based computational model; hence, we make no
assumptions about the distribution or bit complexities of edge weights, nor do
we utilize unusual bit-level operations on memory words. Instead, our
algorithms are based on a planarization method that &quot;zeroes in&quot; on edge
crossings, together with methods for extending planar separator decompositions
to geometric graphs with sublinearly many crossings. Incidentally, our
planarization algorithm also solves an open computational geometry problem of
Chazelle for triangulating a self-intersecting polygonal chain having n
segments and k crossings in linear time, for the case when k is sublinear in n
by an iterated logarithmic factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0904</identifier>
 <datestamp>2008-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0904</id><created>2008-12-04</created><authors><author><keyname>Lee</keyname><forenames>Jun Kyoung</forenames></author><author><keyname>Yang</keyname><forenames>Janghoon</forenames></author><author><keyname>Kim</keyname><forenames>Dong Ku</forenames></author></authors><title>An Approximation of the Outage Probability for Multi-hop AF Fixed Gain
  Relay</title><categories>cs.PF</categories><comments>3 pages, 3 figures, Submitted to IEEE Communication Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we present a closed-form approximation of the outage
probability for the multi-hop amplify-and-forward (AF) relaying systems with
fixed gain in Rayleigh fading channel. The approximation is derived from the
outage event for each hop. The simulation results show the tightness of the
proposed approximation in low and high signal-to-noise ratio (SNR) region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0933</identifier>
 <datestamp>2008-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0933</id><created>2008-12-04</created><authors><author><keyname>Kalai</keyname><forenames>Adam Tauman</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>Decision trees are PAC-learnable from most product distributions: a
  smoothed analysis</title><categories>cs.LG cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of PAC-learning decision trees, i.e., learning a
decision tree over the n-dimensional hypercube from independent random labeled
examples. Despite significant effort, no polynomial-time algorithm is known for
learning polynomial-sized decision trees (even trees of any super-constant
size), even when examples are assumed to be drawn from the uniform distribution
on {0,1}^n. We give an algorithm that learns arbitrary polynomial-sized
decision trees for {\em most product distributions}. In particular, consider a
random product distribution where the bias of each bit is chosen independently
and uniformly from, say, [.49,.51]. Then with high probability over the
parameters of the product distribution and the random examples drawn from it,
the algorithm will learn any tree. More generally, in the spirit of smoothed
analysis, we consider an arbitrary product distribution whose parameters are
specified only up to a [-c,c] accuracy (perturbation), for an arbitrarily small
positive constant c.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0956</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0956</id><created>2008-12-04</created><updated>2010-09-03</updated><authors><author><keyname>Hartig</keyname><forenames>Florian</forenames></author><author><keyname>Horn</keyname><forenames>Martin</forenames></author><author><keyname>Drechsler</keyname><forenames>Martin</forenames></author></authors><title>EcoTRADE - a multi player network game of a tradable permit market for
  biodiversity credits</title><categories>cs.GT</categories><comments>3 pages, 1 figure</comments><journal-ref>Environmental Modelling &amp; Software, 2010, 25, 1479-1480</journal-ref><doi>10.1016/j.envsoft.2009.01.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  EcoTRADE is a multi player network game of a virtual biodiversity credit
market. Each player controls the land use of a certain amount of parcels on a
virtual landscape. The biodiversity credits of a particular parcel depend on
neighboring parcels, which may be owned by other players. The game can be used
to study the strategies of players in experiments or classroom games and also
as a communication tool for stakeholders participating in credit markets that
include spatially interdependent credits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0972</identifier>
 <datestamp>2008-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0972</id><created>2008-12-04</created><updated>2008-12-16</updated><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author><author><keyname>Kamal</keyname><forenames>Ahmed E.</forenames></author></authors><title>Network Protection Codes: Providing Self-healing in Autonomic Networks
  Using Network Coding</title><categories>cs.NI cs.IT math.IT</categories><comments>12 pages, 2 figures, and 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Agile recovery from link failures in autonomic communication networks is
essential to increase robustness, accessibility, and reliability of data
transmission. However, this must be done with the least amount of protection
resources, while using simple management plane functionality. Recently, network
coding has been proposed as a solution to provide agile and cost efficient
network self-healing against link failures, in a manner that does not require
data rerouting, packet retransmission, or failure localization, hence leading
to simple control and management planes. To achieve this, separate paths have
to be provisioned to carry encoded packets, hence requiring either the addition
of extra links, or reserving some of the resources for this purpose.
  In this paper we introduce autonomic self-healing strategies for autonomic
networks in order to protect against link failures. The strategies are based on
network coding and reduced capacity, which is a technique that we call network
protection codes (NPC). In these strategies, an autonomic network is able to
provide self-healing from various network failures affecting network operation.
The techniques improve service and enhance reliability of autonomic
communication.
  Network protection codes are extended to provide self-healing from multiple
link failures in autonomic networks. We provide implementation aspects of the
proposed strategies. We present bounds and network protection code
constructions. Finally, we study the construction of such codes over the binary
field. The paper also develops an Integer Linear Program formulation to
evaluate the cost of provisioning connections using the proposed strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1012</identifier>
 <datestamp>2010-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1012</id><created>2008-12-04</created><updated>2010-01-28</updated><authors><author><keyname>Guha</keyname><forenames>Sudipto</forenames></author><author><keyname>Munagala</keyname><forenames>Kamesh</forenames></author></authors><title>Adaptive Uncertainty Resolution in Bayesian Combinatorial Optimization
  Problems</title><categories>cs.DS</categories><comments>Journal version of the paper &quot;Model-driven Optimization using
  Adaptive Probes&quot; that appeared in the ACM-SIAM Symposium on Discrete
  Algorithms (SODA), 2007</comments><acm-class>F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In several applications such as databases, planning, and sensor networks,
parameters such as selectivity, load, or sensed values are known only with some
associated uncertainty. The performance of such a system (as captured by some
objective function over the parameters) is significantly improved if some of
these parameters can be probed or observed. In a resource constrained
situation, deciding which parameters to observe in order to optimize system
performance itself becomes an interesting and important optimization problem.
This general problem is the focus of this paper.
  One of the most important considerations in this framework is whether
adaptivity is required for the observations. Adaptive observations introduce
blocking or sequential operations in the system whereas non-adaptive
observations can be performed in parallel. One of the important questions in
this regard is to characterize the benefit of adaptivity for probes and
observation.
  We present general techniques for designing constant factor approximations to
the optimal observation schemes for several widely used scheduling and metric
objective functions. We show a unifying technique that relates this
optimization problem to the outlier version of the corresponding deterministic
optimization. By making this connection, our technique shows constant factor
upper bounds for the benefit of adaptivity of the observation schemes. We show
that while probing yields significant improvement in the objective function,
being adaptive about the probing is not beneficial beyond constant factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1014</identifier>
 <datestamp>2008-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1014</id><created>2008-12-04</created><authors><author><keyname>Abi-Haidar</keyname><forenames>Alaa</forenames></author><author><keyname>Rocha</keyname><forenames>Luis M.</forenames></author></authors><title>Adaptive Spam Detection Inspired by a Cross-Regulation Model of Immune
  Dynamics: A Study of Concept Drift</title><categories>cs.AI cs.IR nlin.AO</categories><journal-ref>Artificial Immune Systems: 7th International Conference, (ICARIS
  2008). Bentley, Peter; Lee, Doheon; Jung, Sungwon (Eds.) Lecture Notes in
  Computer Science. Springer-Verlag, 5132: 36-47</journal-ref><doi>10.1007/978-3-540-85072-4_4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel solution to spam detection inspired by a model of
the adaptive immune system known as the crossregulation model. We report on the
testing of a preliminary algorithm on six e-mail corpora. We also compare our
results statically and dynamically with those obtained by the Naive Bayes
classifier and another binary classification method we developed previously for
biomedical text-mining applications. We show that the cross-regulation model is
competitive against those and thus promising as a bio-inspired algorithm for
spam detection in particular, and binary classification in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1029</identifier>
 <datestamp>2008-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1029</id><created>2008-12-04</created><authors><author><keyname>Abi-Haidar</keyname><forenames>Alaa</forenames></author><author><keyname>Kaur</keyname><forenames>Jasleen</forenames></author><author><keyname>Maguitman</keyname><forenames>Ana G.</forenames></author><author><keyname>Radivojac</keyname><forenames>Predrag</forenames></author><author><keyname>Retchsteiner</keyname><forenames>Andreas</forenames></author><author><keyname>Verspoor</keyname><forenames>Karin</forenames></author><author><keyname>Wang</keyname><forenames>Zhiping</forenames></author><author><keyname>Rocha</keyname><forenames>Luis M.</forenames></author></authors><title>Uncovering protein interaction in abstracts and text using a novel
  linear model and word proximity networks</title><categories>cs.IR cs.LG</categories><journal-ref>Genome Biology 2008, 9(Suppl 2):S11</journal-ref><doi>10.1186/gb-2008-9-s2-s11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We participated in three of the protein-protein interaction subtasks of the
Second BioCreative Challenge: classification of abstracts relevant for
protein-protein interaction (IAS), discovery of protein pairs (IPS) and text
passages characterizing protein interaction (ISS) in full text documents. We
approached the abstract classification task with a novel, lightweight linear
model inspired by spam-detection techniques, as well as an uncertainty-based
integration scheme. We also used a Support Vector Machine and the Singular
Value Decomposition on the same features for comparison purposes. Our approach
to the full text subtasks (protein pair and passage identification) includes a
feature expansion method based on word-proximity networks. Our approach to the
abstract classification task (IAS) was among the top submissions for this task
in terms of the measures of performance used in the challenge evaluation
(accuracy, F-score and AUC). We also report on a web-tool we produced using our
approach: the Protein Interaction Abstract Relevance Evaluator (PIARE). Our
approach to the full text tasks resulted in one of the highest recall rates as
well as mean reciprocal rank of correct passages. Our approach to abstract
classification shows that a simple linear model, using relatively few features,
is capable of generalizing and uncovering the conceptual nature of
protein-protein interaction from the bibliome. Since the novel approach is
based on a very lightweight linear model, it can be easily ported and applied
to similar problems. In full text problems, the expansion of word features with
word-proximity networks is shown to be useful, though the need for some
improvements is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1045</identifier>
 <datestamp>2008-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1045</id><created>2008-12-04</created><authors><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author><author><keyname>Romero</keyname><forenames>Daniel M.</forenames></author><author><keyname>Wu</keyname><forenames>Fang</forenames></author></authors><title>Social networks that matter: Twitter under the microscope</title><categories>cs.CY physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scholars, advertisers and political activists see massive online social
networks as a representation of social interactions that can be used to study
the propagation of ideas, social bond dynamics and viral marketing, among
others. But the linked structures of social networks do not reveal actual
interactions among people. Scarcity of attention and the daily rythms of life
and work makes people default to interacting with those few that matter and
that reciprocate their attention. A study of social interactions within Twitter
reveals that the driver of usage is a sparse and hidden network of connections
underlying the declared set of friends and followers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1061</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1061</id><created>2008-12-04</created><updated>2010-10-24</updated><authors><author><keyname>Qiu</keyname><forenames>Daowen</forenames></author><author><keyname>Zou</keyname><forenames>Xiangfu</forenames></author><author><keyname>Li</keyname><forenames>Lvzhou</forenames></author><author><keyname>Mateus</keyname><forenames>Paulo</forenames></author></authors><title>Decidability of the Equivalence of Multi-Letter Quantum Finite Automata</title><categories>cs.FL cs.CC</categories><comments>18 pages; this is a further revised version</comments><acm-class>F.1.1; F.1.2; F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-letter {\it quantum finite automata} (QFAs) were a quantum variant of
classical {\it one-way multi-head finite automata} (J. Hromkovi\v{c}, Acta
Informatica 19 (1983) 377-384), and it has been shown that this new one-way
QFAs (multi-letter QFAs) can accept with no error some regular languages
$(a+b)^{*}b$ that are unacceptable by the previous one-way QFAs. In this paper,
we study the decidability of the equivalence of multi-letter QFAs, and the main
technical contributions are as follows: (1) We show that any two automata, a
$k_{1}$-letter QFA ${\cal A}_1$ and a $k_{2}$-letter QFA ${\cal A}_2$, over the
same input alphabet $\Sigma$ are equivalent if and only if they are
$(n^2m^{k-1}-m^{k-1}+k)$-equivalent, where $m=|\Sigma|$ is the cardinality of
$\Sigma$, $k=\max(k_{1},k_{2})$, and $n=n_{1}+n_{2}$, with $n_{1}$ and $n_{2}$
being the numbers of states of ${\cal A}_{1}$ and ${\cal A}_{2}$, respectively.
When $k=1$, we obtain the decidability of equivalence of measure-once QFAs in
the literature. It is worth mentioning that our technical method is essentially
different from that for the decidability of the case of single input alphabet
(i.e., $m=1$). (2) However, if we determine the equivalence of multi-letter
QFAs by checking all strings of length not more than $ n^2m^{k-1}-m^{k-1}+k$,
then the worst time complexity is exponential, i.e.,
$O(n^6m^{n^2m^{k-1}-m^{k-1}+2k-1})$. Therefore, we design a polynomial-time
$O(m^{2k-1}n^{8}+km^kn^{6})$ algorithm for determining the equivalence of any
two multi-letter QFAs. Here, the time complexity is concerning the number of
states in the multi-letter QFAs, and $k$ is thought of as a constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1091</identifier>
 <datestamp>2008-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1091</id><created>2008-12-05</created><authors><author><keyname>Soundararajan</keyname><forenames>Rajiv</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Communicating the Difference of Correlated Gaussian Sources Over a MAC</title><categories>cs.IT math.IT</categories><comments>8 pages, 2 figures, submitted to DCC 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of transmitting the difference of two
jointly Gaussian sources over a two-user additive Gaussian noise multiple
access channel (MAC). The goal is to recover this difference within an average
mean squared error distortion criterion. Each transmitter has access to only
one of the two Gaussian sources and is limited by an average power constraint.
In this work, a lattice coding scheme that achieves a distortion within a
constant of a distortion lower bound is presented if the signal to noise ratio
(SNR) is greater than a threshold. Further, uncoded transmission is shown to be
worse in performance to lattice coding methods. An alternative lattice coding
scheme is presented that can potentially improve on the performance of uncoded
transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1093</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1093</id><created>2008-12-05</created><updated>2009-02-13</updated><authors><author><keyname>Datta</keyname><forenames>Ajoy K.</forenames><affiliation>UNLV</affiliation></author><author><keyname>Devismes</keyname><forenames>St&#xe9;phane</forenames><affiliation>VERIMAG - IMAG</affiliation></author><author><keyname>Horn</keyname><forenames>Florian</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Larmore</keyname><forenames>Lawrence L.</forenames><affiliation>UNLV</affiliation></author></authors><title>Self-stabilizing K-out-of-L exclusion on tree network</title><categories>cs.NI</categories><comments>15 pages</comments><proxy>ccsd hal-00344193</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the problem of K-out-of-L exclusion, a
generalization of the mutual exclusion problem, in which there are $\ell$ units
of a shared resource, and any process can request up to $\mathtt k$ units
($1\leq\mathtt k\leq\ell$). We propose the first deterministic self-stabilizing
distributed K-out-of-L exclusion protocol in message-passing systems for
asynchronous oriented tree networks which assumes bounded local memory for each
process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1094</identifier>
 <datestamp>2008-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1094</id><created>2008-12-05</created><authors><author><keyname>Thomas</keyname><forenames>Philippe</forenames><affiliation>CRAN</affiliation></author><author><keyname>Thomas</keyname><forenames>Andr&#xe9;</forenames><affiliation>CRAN</affiliation></author></authors><title>S\'election de la structure d'un perceptron multicouches pour la
  r\'eduction dun mod\`ele de simulation d'une scierie</title><categories>cs.NE</categories><comments>7 pages</comments><proxy>ccsd hal-00320824</proxy><journal-ref>Conf\'erence Internationale Francophone d'Automatique CIFA'08,
  Bucarest : Roumanie (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Simulation is often used to evaluate the relevance of a Directing Program of
Production (PDP) or to evaluate its impact on detailed sc\'enarii of
scheduling. Within this framework, we propose to reduce the complexity of a
model of simulation by exploiting a multilayer perceptron. A main phase of the
modeling of one system using a multilayer perceptron remains the determination
of the structure of the network. We propose to compare and use various pruning
algorithms in order to determine the optimal structure of the network used to
reduce the complexity of the model of simulation of our case of application: a
sawmill.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1119</identifier>
 <datestamp>2008-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1119</id><created>2008-12-05</created><authors><author><keyname>Zhang</keyname><forenames>Jinshan</forenames></author></authors><title>An analysis of a random algorithm for estimating all the matchings</title><categories>cs.GR cs.AI</categories><comments>10 pages</comments><acm-class>F.2.0</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Counting the number of all the matchings on a bipartite graph has been
transformed into calculating the permanent of a matrix obtained from the
extended bipartite graph by Yan Huo, and Rasmussen presents a simple approach
(RM) to approximate the permanent, which just yields a critical ratio
O($n\omega(n)$) for almost all the 0-1 matrices, provided it's a simple
promising practical way to compute this #P-complete problem. In this paper, the
performance of this method will be shown when it's applied to compute all the
matchings based on that transformation. The critical ratio will be proved to be
very large with a certain probability, owning an increasing factor larger than
any polynomial of $n$ even in the sense for almost all the 0-1 matrices. Hence,
RM fails to work well when counting all the matchings via computing the
permanent of the matrix. In other words, we must carefully utilize the known
methods of estimating the permanent to count all the matchings through that
transformation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1123</identifier>
 <datestamp>2009-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1123</id><created>2008-12-05</created><updated>2009-11-21</updated><authors><author><keyname>Zhang</keyname><forenames>Jinshan</forenames></author></authors><title>Improved Approximation for the Number of Hamiltonian Cycles in Dense
  Digraphs</title><categories>cs.DS cs.DM</categories><comments>20 pages</comments><acm-class>F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an improved algorithm for counting the number of Hamiltonian
cycles in a directed graph. The basic idea of the method is sequential
acceptance/rejection, which is successfully used in approximating the number of
perfect matchings in dense bipartite graphs. As a consequence, a new bound on
the number of Hamiltonian cycles in a directed graph is proved, by using the
ratio of the number of 1-factors. Based on this bound, we prove that our
algorithm runs in expected time of $O(n^{8.5})$ for dense problems. This
improves the Markov chain method, the most powerful existing method, a factor
of at least $n^{4.5}(\log n)^{4}$ in running time. This class of dense problems
is shown to be nontrivial in counting, in the sense that it is $#$P-Complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1126</identifier>
 <datestamp>2009-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1126</id><created>2008-12-05</created><updated>2009-03-10</updated><authors><author><keyname>Kalles</keyname><forenames>Dimitris</forenames></author><author><keyname>Kaporis</keyname><forenames>Alexis</forenames></author></authors><title>Emerge-Sort: Converging to Ordered Sequences by Simple Local Operators</title><categories>cs.AI cs.DS</categories><comments>Contains 16 pages, 17 figures, 1 table. Text updated as of March 10,
  2009. Submitted to a journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we examine sorting on the assumption that we do not know in
advance which way to sort a sequence of numbers and we set at work simple local
comparison and swap operators whose repeating application ends up in sorted
sequences. These are the basic elements of Emerge-Sort, our approach to
self-organizing sorting, which we then validate experimentally across a range
of samples. Observing an O(n2) run-time behaviour, we note that the n/logn
delay coefficient that differentiates Emerge-Sort from the classical comparison
based algorithms is an instantiation of the price of anarchy we pay for not
imposing a sorting order and for letting that order emerge through the local
interactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1155</identifier>
 <datestamp>2009-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1155</id><created>2008-12-05</created><updated>2009-02-16</updated><authors><author><keyname>Mei</keyname><forenames>Shan</forenames></author><author><keyname>Sloot</keyname><forenames>P. M. A</forenames></author><author><keyname>Quax</keyname><forenames>Rick</forenames></author><author><keyname>Zhu</keyname><forenames>Yifan</forenames></author><author><keyname>Wang</keyname><forenames>Weiping</forenames></author></authors><title>Complex Agent Networks explaining the HIV epidemic among homosexual men
  in Amsterdam</title><categories>cs.MA q-bio.PE</categories><comments>21 pages, 4 figures, Mathematics and Computers in Simulation, added
  references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Simulating the evolution of the Human Immunodeficiency Virus (HIV) epidemic
requires a detailed description of the population network, especially for small
populations in which individuals can be represented in detail and accuracy. In
this paper, we introduce the concept of a Complex Agent Network(CAN) to model
the HIV epidemics by combining agent-based modelling and complex networks, in
which agents represent individuals that have sexual interactions. The
applicability of CANs is demonstrated by constructing and executing a detailed
HIV epidemic model for men who have sex with men (MSM) in Amsterdam, including
a distinction between steady and casual relationships. We focus on MSM contacts
because they play an important role in HIV epidemics and have been tracked in
Amsterdam for a long time. Our experiments show good correspondence between the
historical data of the Amsterdam cohort and the simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1194</identifier>
 <datestamp>2008-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1194</id><created>2008-12-05</created><authors><author><keyname>Istrate</keyname><forenames>Gabriel</forenames></author><author><keyname>Marathe</keyname><forenames>Madhav V.</forenames></author><author><keyname>Ravi</keyname><forenames>S. S.</forenames></author></authors><title>Adversarial Scheduling in Evolutionary Game Dynamics</title><categories>cs.DM cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a system in which players at nodes of an underlying graph G
repeatedly play Prisoner's Dilemma against their neighbors. The players adapt
their strategies based on the past behavior of their opponents by applying the
so-called win-stay lose-shift strategy. This dynamics has been studied in
(Kittock 94), (Dyer et al. 2002), (Mossel and Roch, 2006).
  With random scheduling, starting from any initial configuration with high
probability the system reaches the unique fixed point in which all players
cooperate. This paper investigates the validity of this result under various
classes of adversarial schedulers. Our results can be sumarized as follows:
  1. An adversarial scheduler that can select both participants to the game can
preclude the system from reaching the unique fixed point on most graph
topologies. 2. A nonadaptive scheduler that is only allowed to choose one of
the participants is no more powerful than a random scheduler. With this
restriction even an adaptive scheduler is not significantly more powerful than
the random scheduler, provided it is &quot;reasonably fair&quot;.
  The results exemplify the adversarial scheduling approach we propose as a
foundational basis for the generative approach to social science (Epstein
2007).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1200</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1200</id><created>2008-12-05</created><updated>2010-01-09</updated><authors><author><keyname>Basu</keyname><forenames>Saugata</forenames></author><author><keyname>Zell</keyname><forenames>Thierry</forenames></author></authors><title>Polynomial hierarchy, Betti numbers and a real analogue of Toda's
  theorem</title><categories>cs.CC math.AT math.CO math.LO</categories><comments>Final version to appear in Found. Comput. Math</comments><journal-ref>Found. Comput. Math, 10:429-454, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Toda proved in 1989 that the (discrete) polynomial time hierarchy,
$\mathbf{PH}$, is contained in the class $\mathbf{P}^{#\mathbf{P}}$, namely the
class of languages that can be decided by a Turing machine in polynomial time
given access to an oracle with the power to compute a function in the counting
complexity class $#\mathbf{P}$. This result which illustrates the power of
counting is considered to be a seminal result in computational complexity
theory. An analogous result in the complexity theory over the reals (in the
sense of Blum-Shub-Smale real machines) has been missing so far. In this paper
we formulate and prove a real analogue of Toda's theorem. Unlike Toda's proof
in the discrete case, which relied on sophisticated combinatorial arguments,
our proof is topological in nature. As a consequence of our techniques we are
also able to relate the computational hardness of two extremely well-studied
problems in algorithmic semi-algebraic geometry -- namely the problem of
deciding sentences in the first order theory of the reals with a constant
number of quantifier alternations, and that of computing Betti numbers of
semi-algebraic sets. We obtain a polynomial time reduction of the compact
version of the first problem to the second. This latter result might be of
independent interest to researchers in algorithmic semi-algebraic geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1203</identifier>
 <datestamp>2009-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1203</id><created>2008-12-05</created><updated>2008-12-07</updated><authors><author><keyname>Abouei</keyname><forenames>Jamshid</forenames></author><author><keyname>Bagheri</keyname><forenames>Hossein</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>An Efficient Adaptive Distributed Space-Time Coding Scheme for
  Cooperative Relaying</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Wireless Communications (24 pages)</comments><journal-ref>IEEE Transactions on Wireless Communications, vol. 8, no. 10, pp.
  4957-4962, Oct. 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A non-regenerative dual-hop wireless system based on a distributed space-time
coding strategy is considered. It is assumed that each relay retransmits an
appropriately scaled space-time coded version of its received signal. The main
goal of this paper is to investigate a power allocation strategy in relay
stations, which is based on minimizing the outage probability. In the high
signal-to-noise ratio regime for the relay-destination link, it is shown that a
threshold-based power allocation scheme (i.e., the relay remains silent if its
channel gain with the source is less than a prespecified threshold) is optimum.
Monte-Carlo simulations show that the derived on-off power allocation scheme
performs close to optimum for finite signal-to-noise ratio values. Numerical
results demonstrate a dramatic improvement in system performance as compared to
the case that the relay stations forward their received signals with full
power. In addition, a hybrid amplify-and-forward/detect-and-forward scheme is
proposed for the case that the quality of the source-relay link is good.
Finally, the robustness of the proposed scheme in the presence of channel
estimation errors is numerically evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1218</identifier>
 <datestamp>2008-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1218</id><created>2008-12-05</created><authors><author><keyname>David</keyname><forenames>Amos</forenames><affiliation>LORIA</affiliation></author></authors><title>The Impact of New Technologies in Public Financial Management and
  Performance: Agenda for Public Financial Management Reformance in the Context
  of Global Best Practices</title><categories>cs.OH</categories><proxy>ccsd inria-00344850</proxy><journal-ref>6th Nigeria Development Forum Retreat (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information and Communication Technologies (ICT) has practically penetrated
into all spheres of life. Therefore a closer look at the impact of ICT in
public financial management and performance is highly justified. Public finance
is defined as a field of economics concerned with paying for collective or
governmental activities, and with the administration and design of those
activities. Activities will be viewed as services or more precisely as public
services. We believe that there is need to consider performance from the
perspective of effective performance and the perceived performance. In fact the
real or effective performance might not correspond to the perceived
performance. A service can be considered from the perspective of the
decision-maker, who in our case could be a government or a collectivity. ICT
can be employed in the three phases that concern the decision-maker: design,
implementation and evaluation. The beneficiaries of a service can employ ICT in
any of the three phases - awareness, exploitation and assessment - for
guarantying a high level of efficiency. Each phase in the environment of a
service will be presented as well as illustrations of how ICT can be employed
in order to improve the end-result of each one of them. We believe that a high
efficiency of each phase will produce a high global efficiency. It should be
noted however that the effectiveness of any system is highly dependent on the
human engagement in the system. Therefore, the impact of ICT in public
financial management will be felt only if the decision-makers and the end-users
of the services engage themselves in the success of the system. Instead of
giving a catalog of services, the focus has been on the model (or methodology)
to adopt in designing services for which ICT could enhance the implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1244</identifier>
 <datestamp>2008-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1244</id><created>2008-12-05</created><authors><author><keyname>Fu</keyname><forenames>Fangwen</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Decomposition Principles and Online Learning in Cross-Layer Optimization
  for Delay-Sensitive Applications</title><categories>cs.MM cs.LG</categories><comments>30 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a general cross-layer optimization framework in
which we explicitly consider both the heterogeneous and dynamically changing
characteristics of delay-sensitive applications and the underlying time-varying
network conditions. We consider both the independently decodable data units
(DUs, e.g. packets) and the interdependent DUs whose dependencies are captured
by a directed acyclic graph (DAG). We first formulate the cross-layer design as
a non-linear constrained optimization problem by assuming complete knowledge of
the application characteristics and the underlying network conditions. The
constrained cross-layer optimization is decomposed into several cross-layer
optimization subproblems for each DU and two master problems. The proposed
decomposition method determines the necessary message exchanges between layers
for achieving the optimal cross-layer solution. However, the attributes (e.g.
distortion impact, delay deadline etc) of future DUs as well as the network
conditions are often unknown in the considered real-time applications. The
impact of current cross-layer actions on the future DUs can be characterized by
a state-value function in the Markov decision process (MDP) framework. Based on
the dynamic programming solution to the MDP, we develop a low-complexity
cross-layer optimization algorithm using online learning for each DU
transmission. This online algorithm can be implemented in real-time in order to
cope with unknown source characteristics, network dynamics and resource
constraints. Our numerical results demonstrate the efficiency of the proposed
online algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1291</identifier>
 <datestamp>2008-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1291</id><created>2008-12-06</created><authors><author><keyname>To</keyname><forenames>Anthony Widjaja</forenames></author></authors><title>Unary finite automata vs. arithmetic progressions</title><categories>cs.CC cs.LO</categories><comments>Journal paper submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We point out a subtle error in the proof of Chrobak's theorem that every
unary NFA can be represented as a union of arithmetic progressions that is at
most quadratically large. We propose a correction for this and show how
Martinez's polynomial time algorithm, which realizes Chrobak's theorem, can be
made correct accordingly. We also show that Martinez's algorithm cannot be
improved to have logarithmic space, unless L = NL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1321</identifier>
 <datestamp>2008-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1321</id><created>2008-12-06</created><authors><author><keyname>Andrews</keyname><forenames>Matthew</forenames></author><author><keyname>Slivkins</keyname><forenames>Aleksandrs</forenames></author></authors><title>Oscillations with TCP-like Flow Control in Networks of Queues</title><categories>cs.NI cs.DS</categories><comments>Preliminary version has appeared in IEEE INFOCOM 2006. The current
  version is dated November 2005, with a minor revision in December 2008</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a set of flows passing through a set of servers. The injection
rate into each flow is governed by a flow control that increases the injection
rate when all the servers on the flow's path are empty and decreases the
injection rate when some server is congested. We show that if each server's
congestion is governed by the arriving traffic at the server then the system
can *oscillate*. This is in contrast to previous work on flow control where
congestion was modeled as a function of the flow injection rates and the system
was shown to converge to a steady state that maximizes an overall network
utility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1340</identifier>
 <datestamp>2009-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1340</id><created>2008-12-07</created><updated>2009-02-03</updated><authors><author><keyname>Alagoz</keyname><forenames>B. Baykant</forenames></author></authors><title>Obtaining Depth Maps From Color Images By Region Based Stereo Matching
  Algorithms</title><categories>cs.CV</categories><comments>New figures were added</comments><journal-ref>OncuBilim Algorithm And Systems Labs. Vol.08, Art.No:04,(2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the paper, region based stereo matching algorithms are developed for
extraction depth information from two color stereo image pair. A filter
eliminating unreliable disparity estimation was used for increasing reliability
of the disparity map. Obtained results by algorithms were represented and
compared.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1357</identifier>
 <datestamp>2008-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1357</id><created>2008-12-07</created><authors><author><keyname>Li</keyname><forenames>Qiang</forenames></author><author><keyname>He</keyname><forenames>Yan</forenames></author><author><keyname>Jiang</keyname><forenames>Jing-ping</forenames></author></authors><title>A Novel Clustering Algorithm Based on Quantum Random Walk</title><categories>cs.LG</categories><comments>14 pages, 6 figures, 3 tables</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The enormous successes have been made by quantum algorithms during the last
decade. In this paper, we combine the quantum random walk (QRW) with the
problem of data clustering, and develop two clustering algorithms based on the
one dimensional QRW. Then, the probability distributions on the positions
induced by QRW in these algorithms are investigated, which also indicates the
possibility of obtaining better results. Consequently, the experimental results
have demonstrated that data points in datasets are clustered reasonably and
efficiently, and the clustering algorithms are of fast rates of convergence.
Moreover, the comparison with other algorithms also provides an indication of
the effectiveness of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1364</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1364</id><created>2008-12-07</created><authors><author><keyname>Godlin</keyname><forenames>Benny</forenames></author><author><keyname>Katz</keyname><forenames>Emilia</forenames></author><author><keyname>Makowsky</keyname><forenames>Johann A.</forenames></author></authors><title>Graph Polynomials: From Recursive Definitions To Subset Expansion
  Formulas</title><categories>cs.LO cs.DM</categories><comments>25 pages, 2 figures</comments><journal-ref>Journal of Logic and Computation, Volume 22(2), (2012) Pages
  237-265</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many graph polynomials, such as the Tutte polynomial, the interlace
polynomial and the matching polynomial, have both a recursive definition and a
defining subset expansion formula. In this paper we present a general,
logic-based framework which gives a precise meaning to recursive definitions of
graph polynomials. We then prove that in this framework every recursive
definition of a graph polynomial can be converted into a subset expansion
formula.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1379</identifier>
 <datestamp>2008-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1379</id><created>2008-12-07</created><updated>2008-12-26</updated><authors><author><keyname>Barenboim</keyname><forenames>Leonid</forenames></author><author><keyname>Elkin</keyname><forenames>Michael</forenames></author></authors><title>Distributed (Delta + 1)-coloring in linear (in Delta) time</title><categories>cs.DC cs.NI</categories><comments>12 pages, 2 figures. Contents added: pages 11-12</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The distributed (Delta + 1)-coloring problem is one of most fundamental and
well-studied problems of Distributed Algorithms. Starting with the work of Cole
and Vishkin in 86, there was a long line of gradually improving algorithms
published. The current state-of-the-art running time is O(Delta log Delta +
log^* n), due to Kuhn and Wattenhofer, PODC'06. Linial (FOCS'87) has proved a
lower bound of 1/2 \log^* n for the problem, and Szegedy and Vishwanathan
(STOC'93) provided a heuristic argument that shows that algorithms from a wide
family of locally iterative algorithms are unlikely to achieve running time
smaller than \Theta(Delta log Delta).
  We present a deterministic (Delta + 1)-coloring distributed algorithm with
running time O(Delta) + 1/2 log^* n. We also present a tradeoff between the
running time and the number of colors, and devise an O(Delta * t)-coloring
algorithm with running time O(Delta / t + \log^* n), for any parameter t, 1 &lt; t
&lt; Delta^{1-epsilon}, for an arbitrarily small constant epsilon, 0 &lt; epsilon &lt;
1.
  On the way to this result we study a generalization of the notion of graph
coloring, which is called defective coloring. In an m-defective p-coloring the
vertices are colored with p colors so that each vertex has up to m neighbors
with the same color. We show that an m-defective p-coloring with reasonably
small m and p can be computed very efficiently. We also develop a technique to
employ multiple defect colorings of various subgraphs of the original graph G
for computing a (Delta+1)-coloring of G. We believe that these techniques are
of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1385</identifier>
 <datestamp>2016-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1385</id><created>2008-12-07</created><updated>2016-03-03</updated><authors><author><keyname>Aslam</keyname><forenames>Javaid</forenames></author></authors><title>A Characterization of Polynomial Time Enumeration (Collapse of the
  Polynomial Hierarchy: $\mathbf{NP = P}$)</title><categories>cs.CC cs.DS math.GR</categories><comments>Revisions: Revised the definition of the relation R and 2 proofs
  Total Pages 55, including 12 page appendix</comments><acm-class>F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We resolve the $\mathbf{NP =P?}$ question by providing an existential proof
to the following conjecture on the characterization of polynomial time
enumeration:
  A sufficient condition for the existence of a P-time algorithm for any
enumeration problem is the existence of a polynomially bounded partition
hierarchy of the exponentially decreasing solution spaces, where each disjoint
subset in each partition is P-time enumerable for each $n \ge 1$, n being the
problem size.
  The existential proof is a P-time counting algorithm for perfect matchings,
obtained by extending the basic enumeration technique for permutation groups to
the set of perfect matchings in a bipartite graph. The sequential time
complexity of this $\mathbf{\#P}$-complete problem is shown to be $O(n^{45}\log
n)$.
  And thus we prove a result even more surprising than $\mathbf{NP = P}$, that
is, $\mathbf{\#P}=\mathbf{FP}$, where $\mathbf{FP}$ is the class of functions,
$f: \{0, 1\}^* \rightarrow \mathbb{N} $, computable in polynomial time on a
deterministic model of computation such as a deterministic Turing machine or a
RAM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1390</identifier>
 <datestamp>2008-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1390</id><created>2008-12-07</created><authors><author><keyname>Chazal</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Sophia Antipolis, INRIA Sophia Antipolis / INRIA Futurs</affiliation></author><author><keyname>Cohen-Steiner</keyname><forenames>David</forenames><affiliation>INRIA Sophia Antipolis, INRIA Sophia Antipolis / INRIA Futurs</affiliation></author><author><keyname>Lieutier</keyname><forenames>Andr&#xe9;</forenames><affiliation>LJK</affiliation></author><author><keyname>Thibert</keyname><forenames>Boris</forenames><affiliation>LJK, LMC - IMAG</affiliation></author></authors><title>Stability of Curvature Measures</title><categories>cs.CG math.DG</categories><proxy>ccsd inria-00344903</proxy><report-no>RR-6756</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of curvature estimation from sampled compact sets. The
main contribution is a stability result: we show that the gaussian, mean or
anisotropic curvature measures of the offset of a compact set K with positive
$\mu$-reach can be estimated by the same curvature measures of the offset of a
compact set K' close to K in the Hausdorff sense. We show how these curvature
measures can be computed for finite unions of balls. The curvature measures of
the offset of a compact set with positive $\mu$-reach can thus be approximated
by the curvature measures of the offset of a point-cloud sample. These results
can also be interpreted as a framework for an effective and robust notion of
curvature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1394</identifier>
 <datestamp>2008-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1394</id><created>2008-12-07</created><authors><author><keyname>Sidhom</keyname><forenames>Sahbi</forenames><affiliation>LORIA, Sii</affiliation></author></authors><title>Conceptual approach through an annotation process for the representation
  and the information contents enhancement in economic intelligence (EI)</title><categories>cs.IR</categories><proxy>ccsd inria-00344867</proxy><journal-ref>Journal of Global Management Research (2008) 15 pages</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the era of the information society, the impact of the information systems
on the economy of material and immaterial is certainly perceptible. With
regards to the information resources of an organization, the annotation
involved to enrich informational content, to track the intellectual activities
on a document and to set the added value on information for the benefit of
solving a decision-making problem in the context of economic intelligence. Our
contribution is distinguished by the representation of an annotation process
and its inherent concepts to lead the decisionmaker to an anticipated decision:
the provision of relevant and annotated information. Such information in the
system is made easy by taking into account the diversity of resources and those
that are well annotated so formally and informally by the EI actors. A capital
research framework consist of integrating in the decision-making process the
annotator activity, the software agent (or the reasoning mechanisms) and the
information resources enhancement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1405</identifier>
 <datestamp>2008-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1405</id><created>2008-12-07</created><authors><author><keyname>Geirhofer</keyname><forenames>Stefan</forenames></author><author><keyname>Tong</keyname><forenames>Lang</forenames></author><author><keyname>Sadler</keyname><forenames>Brian M.</forenames></author></authors><title>Cognitive Coexistence between Infrastructure and Ad-hoc Systems</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapid proliferation of wireless systems makes interference management
more and more important. This paper presents a novel cognitive coexistence
framework, which enables an infrastructure system to reduce interference to
ad-hoc or peer-to-peer communication links in close proximity. Motivated by the
superior resources of the infrastructure system, we study how its centralized
resource allocation can accommodate the ad-hoc links based on sensing and
predicting their interference patterns.
  Based on an ON/OFF continuous-time Markov chain model, the optimal allocation
of power and transmission time is formulated as a convex optimization problem
and closed-form solutions are derived. The optimal scheduling is extended to
the case where the infrastructure channel is random and rate constraints need
only be met in the long-term average. Finally, the multi-terminal case is
addressed and the problem of optimal sub-channel allocation discussed.
Numerical performance analysis illustrates that utilizing the superior
flexibility of the infrastructure links can effectively mitigate interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1462</identifier>
 <datestamp>2008-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1462</id><created>2008-12-08</created><authors><author><keyname>Ferraris</keyname><forenames>Paolo</forenames></author></authors><title>Logic programs with propositional connectives and aggregates</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Answer set programming (ASP) is a logic programming paradigm that can be used
to solve complex combinatorial search problems. Aggregates are an ASP construct
that plays an important role in many applications. Defining a satisfactory
semantics of aggregates turned out to be a difficult problem, and in this paper
we propose a new approach, based on an analogy between aggregates and
propositional connectives. First, we extend the definition of an answer
set/stable model to cover arbitrary propositional theories; then we define
aggregates on top of them both as primitive constructs and as abbreviations for
formulas. Our definition of an aggregate combines expressiveness and
simplicity, and it inherits many theorems about programs with nested
expressions, such as theorems about strong equivalence and splitting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1553</identifier>
 <datestamp>2008-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1553</id><created>2008-12-08</created><authors><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author><author><keyname>Qiao</keyname><forenames>Deli</forenames></author><author><keyname>Velipasalar</keyname><forenames>Senem</forenames></author></authors><title>Analysis of Energy Efficiency in Fading Channels under QoS Constraints</title><categories>cs.IT math.IT</categories><comments>conference version appeared at Globecom 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy efficiency in fading channels in the presence of Quality of Service
(QoS) constraints is studied. Effective capacity, which provides the maximum
arrival rate that a wireless channel can sustain while satisfying statistical
QoS constraints, is considered. Spectral efficiency--bit energy tradeoff is
analyzed in the low-power and wideband regimes by employing the effective
capacity formulation, rather than the Shannon capacity. Through this analysis,
energy requirements under QoS constraints are identified. The analysis is
conducted under two assumptions: perfect channel side information (CSI)
available only at the receiver and perfect CSI available at both the receiver
and transmitter. In particular, it is shown in the low-power regime that the
minimum bit energy required under QoS constraints is the same as that attained
when there are no such limitations. However, this performance is achieved as
the transmitted power vanishes. Through the wideband slope analysis, the
increased energy requirements at low but nonzero power levels in the presence
of QoS constraints are determined. A similar analysis is also conducted in the
wideband regime, and minimum bit energy and wideband slope expressions are
obtained. In this regime, the required bit energy levels are found to be
strictly greater than those achieved when Shannon capacity is considered.
Overall, a characterization of the energy-bandwidth-delay tradeoff is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1554</identifier>
 <datestamp>2008-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1554</id><created>2008-12-08</created><authors><author><keyname>Eckford</keyname><forenames>Andrew W.</forenames></author></authors><title>Molecular communication: Physically realistic models and achievable
  information rates</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory. 28 pages, 8
  figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Molecular communication is a biologically-inspired method of communication
with attractive properties for microscale and nanoscale devices. In molecular
communication, messages are transmitted by releasing a pattern of molecules at
a transmitter, which propagate through a fluid medium towards a receiver. In
this paper, molecular communication is formulated as a mathematical
communication problem in an information-theoretic context. Physically realistic
models are obtained, with sufficient abstraction to allow manipulation by
communication and information theorists. Although mutual information in these
channels is intractable, we give sequences of upper and lower bounds on the
mutual information which trade off complexity and performance, and present
results to illustrate the feasibility of these bounds in estimating the true
mutual information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1557</identifier>
 <datestamp>2008-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1557</id><created>2008-12-08</created><authors><author><keyname>Zhang</keyname><forenames>Junwei</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>To Cooperate, or Not to Cooperate in Imperfectly-Known Fading Channels</title><categories>cs.IT math.IT</categories><comments>appeared at IEEE SPAWC 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, communication over imperfectly-known fading channels with
different degrees of cooperation is studied. The three-node relay channel is
considered. It is assumed that communication starts with the network training
phase in which the receivers estimate the fading coefficients of their
respective channels. In the data transmission phase, amplify-and-forward and
decode-and-forward relaying schemes are employed. For different cooperation
protocols, achievable rate expressions are obtained. These achievable rate
expressions are then used to find the optimal resource allocation strategies.
In particular, the fraction of total time or bandwidth that needs to be
allocated to the relay for best performance is identified. Under a total power
constraint, optimal allocation of power between the source and relay is
investigated. Finally, bit energy requirements in the low-power regime are
studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1558</identifier>
 <datestamp>2008-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1558</id><created>2008-12-08</created><authors><author><keyname>Akin</keyname><forenames>Sami</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>Pilot-Symbol-Assisted Communications with Noncausal and Causal Wiener
  Filters</title><categories>cs.IT math.IT</categories><comments>appeared at IEEE SPAWC 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, pilot-assisted transmission over time-selective flat fading
channels is studied. It is assumed that noncausal and causal Wiener filters are
employed at the receiver to perform channel estimation with the aid of training
symbols sent periodically by the transmitter. For both filters, the variances
of estimate errors are obtained from the Doppler power spectrum of the channel.
Subsequently, achievable rate expressions are provided. The training period,
and data and training power allocations are jointly optimized by maximizing the
achievable rate expressions. Numerical results are obtained by modeling the
fading as a Gauss-Markov process. The achievable rates of causal and noncausal
filtering approaches are compared. For the particular ranges of parameters
considered in the paper, the performance loss incurred by using a causal filter
as opposed to a noncausal filter is shown to be small. The impact of aliasing
that occurs in the undersampled version of the channel Doppler spectrum due to
fast fading is analyzed. Finally, energy-per-bit requirements are investigated
in the presence of noncausal and causal Wiener filters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1560</identifier>
 <datestamp>2008-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1560</id><created>2008-12-08</created><authors><author><keyname>Akin</keyname><forenames>Sami</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>Achievable Rates and Training Optimization for Fading Relay Channels
  with Memory</title><categories>cs.IT math.IT</categories><comments>appeared at CISS 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, transmission over time-selective, flat fading relay channels
is studied. It is assumed that channel fading coefficients are not known a
priori. Transmission takes place in two phases: network training phase and data
transmission phase. In the training phase, pilot symbols are sent and the
receivers employ single-pilot MMSE estimation or noncausal Wiener filter to
learn the channel. Amplify-and-Forward (AF) and Decode-and-Forward (DF)
techniques are considered in the data transmission phase and achievable rate
expressions are obtained. The training period, and data and training power
allocations are jointly optimized by using the achievable rate expressions.
Numerical results are obtained considering Gauss-Markov and lowpass fading
models. Achievable rates are computed and energy-per-bit requirements are
investigated. The optimal power distributions among pilot and data symbols are
provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1587</identifier>
 <datestamp>2008-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1587</id><created>2008-12-08</created><authors><author><keyname>Mihaescu</keyname><forenames>Radu</forenames></author><author><keyname>Hill</keyname><forenames>Cameron</forenames></author><author><keyname>Rao</keyname><forenames>Satish</forenames></author></authors><title>Fast phylogeny reconstruction through learning of ancestral sequences</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given natural limitations on the length DNA sequences, designing phylogenetic
reconstruction methods which are reliable under limited information is a
crucial endeavor. There have been two approaches to this problem:
reconstructing partial but reliable information about the tree (\cite{Mo07,
DMR08,DHJ06,GMS08}), and reaching &quot;deeper&quot; in the tree through reconstruction
of ancestral sequences. In the latter category, \cite{DMR06} settled an
important conjecture of M.Steel, showing that, under the CFN model of
evolution, all trees on $n$ leaves with edge lengths bounded by the Ising model
phase transition can be recovered with high probability from genomes of length
$O(\log n)$ with a polynomial time algorithm. Their methods had a running time
of $O(n^{10})$.
  Here we enhance our methods from \cite{DHJ06} with the learning of ancestral
sequences and provide an algorithm for reconstructing a sub-forest of the tree
which is reliable given available data, without requiring a-priori known bounds
on the edge lengths of the tree. Our methods are based on an intuitive minimum
spanning tree approach and run in $O(n^3)$ time. For the case of full
reconstruction of trees with edges under the phase transition, we maintain the
same sequence length requirements as \cite{DMR06}, despite the considerably
faster running time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1595</identifier>
 <datestamp>2008-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1595</id><created>2008-12-08</created><authors><author><keyname>Das</keyname><forenames>Aparna</forenames></author><author><keyname>Mathieu</keyname><forenames>Claire</forenames></author></authors><title>A quasi-polynomial time approximation scheme for Euclidean capacitated
  vehicle routing</title><categories>cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the capacitated vehicle routing problem, introduced by Dantzig and Ramser
in 1959, we are given the locations of n customers and a depot, along with a
vehicle of capacity k, and wish to find a minimum length collection of tours,
each starting from the depot and visiting at most k customers, whose union
covers all the customers. We give a quasi-polynomial time approximation scheme
for the setting where the customers and the depot are on the plane, and
distances are given by the Euclidean metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1597</identifier>
 <datestamp>2008-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1597</id><created>2008-12-08</created><authors><author><keyname>Mohajer</keyname><forenames>Soheil</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas N.</forenames></author><author><keyname>Fragouli</keyname><forenames>Christina</forenames></author><author><keyname>Tse</keyname><forenames>David N. C.</forenames></author></authors><title>Transmission Techniques for Relay-Interference Networks</title><categories>cs.IT math.IT</categories><comments>8 pages, 8 figures, presented at 46. Allerton Conf. On Comm.,
  Control, and Computing 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the relay-interference wireless network, in which
relay (helper) nodes are to facilitate competing information flows over a
wireless network. We examine this in the context of a deterministic wireless
interaction model, which eliminates the channel noise and focuses on the signal
interactions. Using this model, we show that almost all the known schemes such
as interference suppression, interference alignment and interference separation
are necessary for relay-interference networks. In addition, we discover a new
interference management technique, which we call interference neutralization,
which allows for over-the-air interference removal, without the transmitters
having complete access the interfering signals. We show that interference
separation, suppression, and neutralization arise in a fundamental manner,
since we show complete characterizations for special configurations of the
relay-interference network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1599</identifier>
 <datestamp>2008-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1599</id><created>2008-12-09</created><authors><author><keyname>Ellowitz</keyname><forenames>Jake</forenames></author></authors><title>Multi-Agent Reinforcement Learning and Genetic Policy Sharing</title><categories>cs.MA cs.AI</categories><comments>7 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The effects of policy sharing between agents in a multi-agent dynamical
system has not been studied extensively. I simulate a system of agents
optimizing the same task using reinforcement learning, to study the effects of
different population densities and policy sharing. I demonstrate that sharing
policies decreases the time to reach asymptotic behavior, and results in
improved asymptotic behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1601</identifier>
 <datestamp>2009-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1601</id><created>2008-12-08</created><updated>2009-05-03</updated><authors><author><keyname>Kintali</keyname><forenames>Shiva</forenames></author></authors><title>Scarf is Ppad-Complete</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scarf's lemma is one of the fundamental results in combinatorics, originally
introduced to study the core of an N-person game. Over the last four decades,
the usefulness of Scarf's lemma has been demonstrated in several important
combinatorial problems seeking &quot;stable&quot; solutions. However, the complexity of
the computational version of Scarf's lemma (SCARF) remained open. In this
paper, we prove that SCARF is complete for the complexity class PPAD. This
proves that SCARF is as hard as the computational versions of Brouwer's fixed
point theorem and Sperner's lemma. Hence, there is no polynomial-time algorithm
for SCARF unless PPAD \subseteq P. We also show that fractional stable paths
problem and finding strong fractional kernels in digraphs are PPAD-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1628</identifier>
 <datestamp>2008-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1628</id><created>2008-12-09</created><authors><author><keyname>Farivar</keyname><forenames>Masoud</forenames></author><author><keyname>Mehrdad</keyname><forenames>Behzad</forenames></author><author><keyname>Ashtiani</keyname><forenames>Farid</forenames></author></authors><title>Two Dimensional Connectivity for Vehicular Ad-Hoc Networks</title><categories>cs.NI cs.DS</categories><comments>9 Pages, 10 figures,Submitted to INFOCOM 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we focus on two-dimensional connectivity in sparse vehicular
ad hoc networks (VANETs). In this respect, we find thresholds for the arrival
rates of vehicles at entrances of a block of streets such that the connectivity
is guaranteed for any desired probability. To this end, we exploit a mobility
model recently proposed for sparse VANETs, based on BCMP open queuing networks
and solve the related traffic equations to find the traffic characteristics of
each street and use the results to compute the exact probability of
connectivity along these streets. Then, we use the results from percolation
theory and the proposed fast algorithms for evaluation of bond percolation
problem in a random graph corresponding to the block of the streets. We then
find sufficiently accurate two dimensional connectivity-related parameters,
such as the average number of intersections connected to each other and the
size of the largest set of inter-connected intersections. We have also proposed
lower bounds for the case of heterogeneous network with two transmission
ranges. In the last part of the paper, we apply our method to several numerical
examples and confirm our results by simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1629</identifier>
 <datestamp>2009-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1629</id><created>2008-12-09</created><updated>2009-03-18</updated><authors><author><keyname>Caranti</keyname><forenames>A.</forenames></author><author><keyname>Volta</keyname><forenames>F. Dalla</forenames></author><author><keyname>Sala</keyname><forenames>M.</forenames></author></authors><title>An application of the O'Nan-Scott theorem to the group generated by the
  round functions of an AES-like cipher</title><categories>math.GR cs.IT math.IT</categories><comments>10 pages: several improvements in exposition and content, including
  ruling out the symmetric group 9 pages; several changes in layout and
  exposition</comments><msc-class>20B25; 20B15; 68R99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a previous paper, we had proved that the permutation group generated by
the round functions of an AES-like cipher is primitive. Here we apply the O'Nan
Scott classification of primitive groups to prove that this group is the
alternating group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1633</identifier>
 <datestamp>2009-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1633</id><created>2008-12-09</created><authors><author><keyname>Bussi</keyname><forenames>Giovanni</forenames></author></authors><title>A simple asynchronous replica-exchange implementation</title><categories>physics.comp-ph cs.DC</categories><comments>Preprint of Proceeding for CSFI 2008</comments><journal-ref>G. Bussi, Nuovo Cimento Soc. Ital. Fis., C 32, 61 (2009)</journal-ref><doi>10.1393/ncc/i2009-10369-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the possibility of implementing asynchronous replica-exchange (or
parallel tempering) molecular dynamics. In our scheme, the exchange attempts
are driven by asynchronous messages sent by one of the computing nodes, so that
different replicas are allowed to perform a different number of time-steps
between subsequent attempts. The implementation is simple and based on the
message-passing interface (MPI). We illustrate the advantages of our scheme
with respect to the standard synchronous algorithm and we benchmark it for a
model Lennard-Jones liquid on an IBM-LS21 blade center cluster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1647</identifier>
 <datestamp>2008-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1647</id><created>2008-12-09</created><authors><author><keyname>Vanderhaeghe</keyname><forenames>David</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LJK Laboratoire Jean Kuntzmann, LJK</affiliation></author><author><keyname>Ostromoukhov</keyname><forenames>Victor</forenames><affiliation>DIRO</affiliation></author></authors><title>Polyomino-Based Digital Halftoning</title><categories>cs.GR</categories><comments>http://artis.imag.fr/Publications/2008/VO08/</comments><proxy>ccsd inria-00345283</proxy><journal-ref>IADIS International Conference on Computer Graphics and
  Visualization 2008 (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we present a new method for generating a threshold structure.
This kind of structure can be advantageously used in various halftoning
algorithms such as clustered-dot or dispersed-dot dithering, error diffusion
with threshold modulation, etc. The proposed method is based on rectifiable
polyominoes -- a non-periodic hierarchical structure, which tiles the Euclidean
plane with no gaps. Each polyomino contains a fixed number of discrete
threshold values. Thanks to its inherent non-periodic nature combined with
off-line optimization of threshold values, our polyomino-based threshold
structure shows blue-noise spectral properties. The halftone images produced
with this threshold structure have high visual quality. Although the proposed
method is general, and can be applied on any polyomino tiling, we consider one
particular case: tiling with G-hexominoes. We compare our polyomino-based
threshold structure with the best known state-of-the-art methods for generation
threshold matrices, and conclude considerable improvement achieved with our
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1713</identifier>
 <datestamp>2008-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1713</id><created>2008-12-09</created><authors><author><keyname>Gunduz</keyname><forenames>Deniz</forenames></author><author><keyname>Brown</keyname><forenames>D. Richard</forenames><suffix>III</suffix></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Secret Communication with Feedback</title><categories>cs.IT math.IT</categories><comments>Presented at the IEEE Int'l Symposium on Information Theory and its
  Applications (ISITA), Auckland, New Zealand, December 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secure communication with feedback is studied. An achievability scheme in
which the backward channel is used to generate a shared secret key is proposed.
The scenario of binary symmetric forward and backward channels is considered,
and a combination of the proposed scheme and Maurer's coding scheme is shown to
achieve improved secrecy rates. The scenario of a Gaussian channel with perfect
output feedback is also analyzed and the Schalkwijk-Kailath coding scheme is
shown to achieve the secrecy capacity for this channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1729</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1729</id><created>2008-12-09</created><updated>2008-12-23</updated><authors><author><keyname>Murlak</keyname><forenames>Filip</forenames></author></authors><title>The Wadge Hierarchy of Deterministic Tree Languages</title><categories>cs.LO</categories><comments>44 pages, 8 figures; extended abstract presented at ICALP 2006,
  Venice, Italy; full version appears in LMCS special issue</comments><acm-class>F.4.3; F.4.1; F.1.1; F.1.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 4 (December
  23, 2008) lmcs:994</journal-ref><doi>10.2168/LMCS-4(4:15)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a complete description of the Wadge hierarchy for
deterministically recognisable sets of infinite trees. In particular we give an
elementary procedure to decide if one deterministic tree language is
continuously reducible to another. This extends Wagner's results on the
hierarchy of omega-regular languages of words to the case of trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1778</identifier>
 <datestamp>2008-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1778</id><created>2008-12-09</created><authors><author><keyname>Qiao</keyname><forenames>Deli</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author><author><keyname>Velipasalar</keyname><forenames>Senem</forenames></author></authors><title>The Impact of QoS Constraints on the Energy Efficiency of Fixed-Rate
  Wireless Transmissions</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transmission over wireless fading channels under quality of service (QoS)
constraints is studied when only the receiver has channel side information.
Being unaware of the channel conditions, transmitter is assumed to send the
information at a fixed rate. Under these assumptions, a two-state (ON-OFF)
transmission model is adopted, where information is transmitted reliably at a
fixed rate in the ON state while no reliable transmission occurs in the OFF
state. QoS limitations are imposed as constraints on buffer violation
probabilities, and effective capacity formulation is used to identify the
maximum throughput that a wireless channel can sustain while satisfying
statistical QoS constraints. Energy efficiency is investigated by obtaining the
bit energy required at zero spectral efficiency and the wideband slope in both
wideband and low-power regimes assuming that the receiver has perfect channel
side information (CSI). In both wideband and low-power regimes, the increased
energy requirements due to the presence of QoS constraints are quantified.
Comparisons with variable-rate/fixed-power and variable-rate/variable-power
cases are given. Energy efficiency is further analyzed in the presence of
channel uncertainties. The optimal fraction of power allocated to training is
identified under QoS constraints. It is proven that the minimum bit energy in
the low-power regime is attained at a certain nonzero power level below which
bit energy increases without bound with vanishing power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1780</identifier>
 <datestamp>2008-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1780</id><created>2008-12-09</created><authors><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>On the Energy Efficiency of Orthogonal Signaling</title><categories>cs.IT math.IT</categories><comments>appeared at ISIT 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, transmission over the additive white Gaussian noise (AWGN)
channel, and coherent and noncoherent fading channels using M-ary orthogonal
frequency-shift keying (FSK) or on-off frequency-shift keying (OOFSK) is
considered. The receiver is assumed to perform hard-decision detection. In this
setting, energy required to reliably send one bit of information is
investigated. It is shown that for fixed M and duty cycle, bit energy
requirements grow without bound as the signal-to-noise ratio (SNR) vanishes.
The minimum bit energy values are numerically obtained for different values of
M and the duty cycle. The impact of fading on the energy efficiency is
identified. Requirements to approach the minimum bit energy of -1.59 dB are
determined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1811</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1811</id><created>2008-12-09</created><updated>2009-03-11</updated><authors><author><keyname>Delvenne</keyname><forenames>J. -C.</forenames></author><author><keyname>Yaliraki</keyname><forenames>S. N.</forenames></author><author><keyname>Barahona</keyname><forenames>M.</forenames></author></authors><title>Stability of graph communities across time scales</title><categories>physics.soc-ph cs.IR physics.data-an</categories><comments>submitted; updated bibliography from v3</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The complexity of biological, social and engineering networks makes it
desirable to find natural partitions into communities that can act as
simplified descriptions and provide insight into the structure and function of
the overall system. Although community detection methods abound, there is a
lack of consensus on how to quantify and rank the quality of partitions. We
show here that the quality of a partition can be measured in terms of its
stability, defined in terms of the clustered autocovariance of a Markov process
taking place on the graph. Because the stability has an intrinsic dependence on
time scales of the graph, it allows us to compare and rank partitions at each
time and also to establish the time spans over which partitions are optimal.
Hence the Markov time acts effectively as an intrinsic resolution parameter
that establishes a hierarchy of increasingly coarser clusterings. Within our
framework we can then provide a unifying view of several standard partitioning
measures: modularity and normalized cut size can be interpreted as one-step
time measures, whereas Fiedler's spectral clustering emerges at long times. We
apply our method to characterize the relevance and persistence of partitions
over time for constructive and real networks, including hierarchical graphs and
social networks. We also obtain reduced descriptions for atomic level protein
structures over different time scales.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1843</identifier>
 <datestamp>2008-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1843</id><created>2008-12-10</created><authors><author><keyname>Kumar</keyname><forenames>N. Arvind</forenames></author></authors><title>Identification of parameters underlying emotions and a classification of
  emotions</title><categories>cs.AI</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The standard classification of emotions involves categorizing the expression
of emotions. In this paper, parameters underlying some emotions are identified
and a new classification based on these parameters is suggested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1857</identifier>
 <datestamp>2008-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1857</id><created>2008-12-10</created><updated>2008-12-18</updated><authors><author><keyname>Tandon</keyname><forenames>Ravi</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Dependence Balance Based Outer Bounds for Gaussian Networks with
  Cooperation and Feedback</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We obtain new outer bounds on the capacity regions of the two-user multiple
access channel with generalized feedback (MAC-GF) and the two-user interference
channel with generalized feedback (IC-GF). These outer bounds are based on the
idea of dependence balance which was proposed by Hekstra and Willems [1]. To
illustrate the usefulness of our outer bounds, we investigate three different
channel models. We first consider a Gaussian MAC with noisy feedback (MAC-NF),
where transmitter $k$, $k=1,2$, receives a feedback $Y_{F_{k}}$, which is the
channel output $Y$ corrupted with additive white Gaussian noise $Z_{k}$. As the
feedback noise variances become large, one would expect the feedback to become
useless, which is not reflected by the cut-set bound. We demonstrate that our
outer bound improves upon the cut-set bound for all non-zero values of the
feedback noise variances. Moreover, in the limit as $\sigma_{Z_{k}}^{2}\to
\infty$, $k=1,2$, our outer bound collapses to the capacity region of the
Gaussian MAC without feedback. Secondly, we investigate a Gaussian MAC with
user-cooperation (MAC-UC), where each transmitter receives an additive white
Gaussian noise corrupted version of the channel input of the other transmitter
[2]. For this channel model, the cut-set bound is sensitive to the cooperation
noises, but not sensitive enough. For all non-zero values of cooperation noise
variances, our outer bound strictly improves upon the cut-set outer bound.
Thirdly, we investigate a Gaussian IC with user-cooperation (IC-UC). For this
channel model, the cut-set bound is again sensitive to cooperation noise
variances but not sensitive enough. We demonstrate that our outer bound
strictly improves upon the cut-set bound for all non-zero values of cooperation
noise variances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1869</identifier>
 <datestamp>2008-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1869</id><created>2008-12-10</created><authors><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Mairal</keyname><forenames>Julien</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Ponce</keyname><forenames>Jean</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Convex Sparse Matrix Factorizations</title><categories>cs.LG</categories><proxy>ccsd hal-00345747</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a convex formulation of dictionary learning for sparse signal
decomposition. Convexity is obtained by replacing the usual explicit upper
bound on the dictionary size by a convex rank-reducing term similar to the
trace norm. In particular, our formulation introduces an explicit trade-off
between size and sparsity of the decomposition of rectangular matrices. Using a
large set of synthetic examples, we compare the estimation abilities of the
convex and non-convex approaches, showing that while the convex formulation has
a single local minimum, this may lead in some cases to performance which is
inferior to the local minima of the non-convex formulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1908</identifier>
 <datestamp>2008-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1908</id><created>2008-12-10</created><authors><author><keyname>Kooij</keyname><forenames>Robert</forenames></author><author><keyname>Schumm</keyname><forenames>Phillip</forenames></author><author><keyname>Scoglio</keyname><forenames>Caterina</forenames></author></authors><title>A new metric for robustness with respect to virus spread</title><categories>cs.DM</categories><comments>12 pages, 4 figures</comments><acm-class>D.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The robustness of a network is depending on the type of attack we are
considering. In this paper we focus on the spread of viruses on networks. It is
common practice to use the epidemic threshold as a measure for robustness.
Because the epidemic threshold is inversely proportional to the largest
eigenvalue of the adjacency matrix, it seems easy to compare the robustness of
two networks. We will show in this paper that the comparison of the robustness
with respect to virus spread for two networks actually depends on the value of
the effective spreading rate tau. For this reason we propose a new metric, the
viral conductance, which takes into account the complete range of values tau
can obtain. In this paper we determine the viral conductance of regular graphs,
complete bi-partite graphs and a number of realistic networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1915</identifier>
 <datestamp>2008-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1915</id><created>2008-12-10</created><authors><author><keyname>Gelade</keyname><forenames>Wouter</forenames></author><author><keyname>Marquardt</keyname><forenames>Marcel</forenames></author><author><keyname>Schwentick</keyname><forenames>Thomas</forenames></author></authors><title>Dynamic Complexity of Formal Languages</title><categories>cs.CC cs.DS cs.LO</categories><comments>Contains the material presenten at STACS 2009, extendes with proofs
  and examples which were omitted due lack of space</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper investigates the power of the dynamic complexity classes DynFO,
DynQF and DynPROP over string languages. The latter two classes contain
problems that can be maintained using quantifier-free first-order updates, with
and without auxiliary functions, respectively. It is shown that the languages
maintainable in DynPROP exactly are the regular languages, even when allowing
arbitrary precomputation. This enables lower bounds for DynPROP and separates
DynPROP from DynQF and DynFO. Further, it is shown that any context-free
language can be maintained in DynFO and a number of specific context-free
languages, for example all Dyck-languages, are maintainable in DynQF.
Furthermore, the dynamic complexity of regular tree languages is investigated
and some results concerning arbitrary structures are obtained: there exist
first-order definable properties which are not maintainable in DynPROP. On the
other hand any existential first-order property can be maintained in DynQF when
allowing precomputation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1951</identifier>
 <datestamp>2008-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1951</id><created>2008-12-10</created><authors><author><keyname>Finkel</keyname><forenames>Alain</forenames><affiliation>LSV</affiliation></author><author><keyname>Leroux</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>LaBRI</affiliation></author></authors><title>The convex hull of a regular set of integer vectors is polyhedral and
  effectively computable</title><categories>cs.CG cs.DS cs.LO</categories><proxy>ccsd hal-00345982</proxy><journal-ref>Information Processing Letters 96, 1 (2005) 30 - 35</journal-ref><doi>10.1016/j.ipl.2005.04.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Number Decision Diagrams (NDD) provide a natural finite symbolic
representation for regular set of integer vectors encoded as strings of digit
vectors (least or most significant digit first). The convex hull of the set of
vectors represented by a NDD is proved to be an effectively computable convex
polyhedron.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1967</identifier>
 <datestamp>2008-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1967</id><created>2008-12-10</created><authors><author><keyname>Bouchy</keyname><forenames>Florent</forenames><affiliation>LSV</affiliation></author><author><keyname>Finkel</keyname><forenames>Alain</forenames><affiliation>LSV</affiliation></author><author><keyname>Leroux</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>LaBRI</affiliation></author></authors><title>Decomposition of Decidable First-Order Logics over Integers and Reals</title><categories>cs.LO</categories><proxy>ccsd hal-00345998</proxy><journal-ref>Temporal Representation and Reasoning, 2008. TIME '08. 15th
  International Symposium on, Montreal, QC : Canada (2008)</journal-ref><doi>10.1109/TIME.2008.22</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We tackle the issue of representing infinite sets of real- valued vectors.
This paper introduces an operator for combining integer and real sets. Using
this operator, we decompose three well-known logics extending Presburger with
reals. Our decomposition splits a logic into two parts : one integer, and one
decimal (i.e. on the interval [0,1]). We also give a basis for an
implementation of our representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1986</identifier>
 <datestamp>2008-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1986</id><created>2008-12-10</created><authors><author><keyname>Feron</keyname><forenames>Eric</forenames></author><author><keyname>Alegre</keyname><forenames>Fernando</forenames></author></authors><title>Control software analysis, part II: Closed-loop analysis</title><categories>cs.SE cs.PL</categories><comments>16 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analysis and proper documentation of the properties of closed-loop
control software presents many distinct aspects from the analysis of the same
software running open-loop. Issues of physical system representations arise,
and it is desired that such representations remain independent from the
representations of the control program. For that purpose, a concurrent program
representation of the plant and the control processes is proposed, although the
closed-loop system is sufficiently serialized to enable a sequential analysis.
While dealing with closed-loop system properties, it is also shown by means of
examples how special treatment of nonlinearities extends from the analysis of
control specifications to code analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2011</identifier>
 <datestamp>2008-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2011</id><created>2008-12-10</created><authors><author><keyname>Leroux</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Sutre</keyname><forenames>Gregoire</forenames><affiliation>LaBRI</affiliation></author></authors><title>Accelerated Data-Flow Analysis</title><categories>cs.DS</categories><proxy>ccsd hal-00346005</proxy><journal-ref>Static Analysis, Kongens Lyngby : Danemark (2007)</journal-ref><doi>10.1007/978-3-540-74061-2_12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acceleration in symbolic verification consists in computing the exact effect
of some control-flow loops in order to speed up the iterative fix-point
computation of reachable states. Even if no termination guarantee is provided
in theory, successful results were obtained in practice by different tools
implementing this framework. In this paper, the acceleration framework is
extended to data-flow analysis. Compared to a classical
widening/narrowing-based abstract interpretation, the loss of precision is
controlled here by the choice of the abstract domain and does not depend on the
way the abstract value is computed. Our approach is geared towards precision,
but we don't loose efficiency on the way. Indeed, we provide a cubic-time
acceleration-based algorithm for solving interval constraints with full
multiplication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2014</identifier>
 <datestamp>2008-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2014</id><created>2008-12-10</created><authors><author><keyname>Leroux</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>LaBRI</affiliation></author></authors><title>Convex Hull of Arithmetic Automata</title><categories>cs.DS</categories><proxy>ccsd hal-00346001</proxy><journal-ref>Static Analysis, Valencia : Espagne (2008)</journal-ref><doi>10.1007/978-3-540-69166-2_4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Arithmetic automata recognize infinite words of digits denoting
decompositions of real and integer vectors. These automata are known expressive
and efficient enough to represent the whole set of solutions of complex linear
constraints combining both integral and real variables. In this paper, the
closed convex hull of arithmetic automata is proved rational polyhedral.
Moreover an algorithm computing the linear constraints defining these convex
set is provided. Such an algorithm is useful for effectively extracting
geometrical properties of the whole set of solutions of complex constraints
symbolically represented by arithmetic automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2049</identifier>
 <datestamp>2008-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2049</id><created>2008-12-10</created><authors><author><keyname>Li</keyname><forenames>Jian</forenames></author><author><keyname>Deshpande</keyname><forenames>Amol</forenames></author></authors><title>Consensus Answers for Queries over Probabilistic Databases</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of finding a &quot;best&quot; deterministic query answer to a
query over a probabilistic database. For this purpose, we propose the notion of
a consensus world (or a consensus answer) which is a deterministic world
(answer) that minimizes the expected distance to the possible worlds (answers).
This problem can be seen as a generalization of the well-studied inconsistent
information aggregation problems (e.g. rank aggregation) to probabilistic
databases. We consider this problem for various types of queries including SPJ
queries, \Topk queries, group-by aggregate queries, and clustering. For
different distance metrics, we obtain polynomial time optimal or approximation
algorithms for computing the consensus answers (or prove NP-hardness). Most of
our results are for a general probabilistic database model, called {\em and/xor
tree model}, which significantly generalizes previous probabilistic database
models like x-tuples and block-independent disjoint models, and is of
independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2094</identifier>
 <datestamp>2008-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2094</id><created>2008-12-11</created><authors><author><keyname>Ates</keyname><forenames>Mika&#xeb;l</forenames><affiliation>DIOM</affiliation></author><author><keyname>Gravier</keyname><forenames>Christophe</forenames><affiliation>DIOM</affiliation></author><author><keyname>Lardon</keyname><forenames>J&#xe9;r&#xe9;my</forenames><affiliation>DIOM</affiliation></author><author><keyname>Fayolle</keyname><forenames>Jacques</forenames><affiliation>DIOM</affiliation></author><author><keyname>Sauviac</keyname><forenames>B.</forenames><affiliation>DIOM</affiliation></author></authors><title>Interoperability between Heterogeneous Federation Architectures:
  Illustration with SAML and WS-Federation</title><categories>cs.CR</categories><proxy>ccsd ujm-00345878</proxy><journal-ref>Third International IEEE Conference on Signal-Image Technologies
  and Internet-Based System (SITIS 07), Shangai : Chine (2007)</journal-ref><doi>10.1109/SITIS.2007.148</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital identity management intra and inter information systems, and, service
oriented architectures, are the roots of identity federation. This kind of
security architectures aims at enabling information system interoperability.
Existing architectures, however, do not consider interoperability of
heterogeneous federation architectures, which rely on different federation
protocols.In this paper, we try to initiate an in-depth reflection on this
issue, through the comparison of two main federation architecture
specifications: SAML and WS-Federation. We firstly propose an overall outline
of identity federation. We furthermore address the issue of interoperability
for federation architectures using a different federation protocol. Afterwards,
we compare SAML and WS-Federation. Eventually, we define the ways of
convergence, and therefore, of interoperability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2115</identifier>
 <datestamp>2008-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2115</id><created>2008-12-11</created><authors><author><keyname>Caimi</keyname><forenames>Gabrio</forenames></author><author><keyname>Flier</keyname><forenames>Holger</forenames></author><author><keyname>Fuchsberger</keyname><forenames>Martin</forenames></author><author><keyname>Nunkesser</keyname><forenames>Marc</forenames></author></authors><title>Performance of a greedy algorithm for edge covering by cliques in
  interval graphs</title><categories>cs.DM cs.DS</categories><comments>8 pages, 3 pictures, technical report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a greedy algorithm to detect conflict cliques in interval
graphs and circular-arc graphs is analyzed. In a graph, a stable set requires
that at most one vertex is chosen for each edge. It is equivalent to requiring
that at most one vertex for each maximal clique is chosen. We show that this
algorithm finds all maximal cliques for interval graphs, i.e. it can compute
the convex hull of the stable set polytope. In case of circular-arc graphs, the
algorithm is not able to detect all maximal cliques, yet remaining correct.
This problem occurs in the context of railway scheduling. A train requests the
allocation of a railway infrastructure resource for a specific time interval.
As one is looking for conflict-free train schedules, the used resource
allocation intervals in a schedule must not overlap. The conflict-free choices
of used intervals for each resource correspond to stable sets in the interval
graph associated to the allocation time intervals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2137</identifier>
 <datestamp>2008-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2137</id><created>2008-12-11</created><authors><author><keyname>Berman</keyname><forenames>Piotr</forenames></author><author><keyname>Karpinski</keyname><forenames>Marek</forenames></author><author><keyname>Zelikovsky</keyname><forenames>Alex</forenames></author></authors><title>A Factor 3/2 Approximation for Generalized Steiner Tree Problem with
  Distances One and Two</title><categories>cs.CC cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design a 3/2 approximation algorithm for the Generalized Steiner Tree
problem (GST) in metrics with distances 1 and 2. This is the first polynomial
time approximation algorithm for a wide class of non-geometric metric GST
instances with approximation factor below 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2164</identifier>
 <datestamp>2008-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2164</id><created>2008-12-11</created><authors><author><keyname>Pop</keyname><forenames>Florin</forenames></author></authors><title>Optimization of Decentralized Scheduling for Physic Applications in Grid
  Environments</title><categories>cs.DC physics.comp-ph</categories><journal-ref>D. Iordache, P. Sterian (eds.), Proceedings of the 4th edition of
  the Colloquium Mathematics in Engineering and Numerical Physics, pp. 150-153,
  October 6-8, Ed. Printech, 2007, ISBN: 978-973-718-761-1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a scheduling framework that is configured for, and used
in physic systems. Our work addresses the problem of scheduling various
computationally intensive and data intensive applications that are required for
extracting information from satellite images. The proposed solution allows
mapping of image processing applications onto available resources. The
scheduling is done at the level of groups of concurrent applications. It
demonstrates a very good behavior for scheduling and executing groups of
applications, while also achieving a near-optimal utilization of the resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2195</identifier>
 <datestamp>2009-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2195</id><created>2008-12-11</created><updated>2009-06-26</updated><authors><author><keyname>Chirkova</keyname><forenames>Rada</forenames></author><author><keyname>Genesereth</keyname><forenames>Michael</forenames></author></authors><title>Equivalence of SQL Queries in Presence of Embedded Dependencies</title><categories>cs.DB</categories><comments>Correction of the previous version as described in the last sentence
  of the Abstract</comments><report-no>NCSU CSC TR-2008-27</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding equivalent minimal-size reformulations of
SQL queries in presence of embedded dependencies [1]. Our focus is on
select-project-join (SPJ) queries with equality comparisons, also known as safe
conjunctive (CQ) queries, possibly with grouping and aggregation. For SPJ
queries, the semantics of the SQL standard treat query answers as multisets
(a.k.a. bags), whereas the stored relations may be treated either as sets,
which is called bag-set semantics for query evaluation, or as bags, which is
called bag semantics. (Under set semantics, both query answers and stored
relations are treated as sets.)
  In the context of the above Query-Reformulation Problem, we develop a
comprehensive framework for equivalence of CQ queries under bag and bag-set
semantics in presence of embedded dependencies, and make a number of conceptual
and technical contributions. Specifically, we develop equivalence tests for CQ
queries in presence of arbitrary sets of embedded dependencies under bag and
bag-set semantics, under the condition that chase [9] under set semantics
(set-chase) on the inputs terminates. We also present equivalence tests for
aggregate CQ queries in presence of embedded dependencies. We use our
equivalence tests to develop sound and complete (whenever set-chase on the
inputs terminates) algorithms for solving instances of the Query-Reformulation
Problem with CQ queries under each of bag and bag-set semantics, as well as for
instances of the problem with aggregate queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2202</identifier>
 <datestamp>2008-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2202</id><created>2008-12-11</created><authors><author><keyname>Needell</keyname><forenames>D.</forenames></author><author><keyname>Tropp</keyname><forenames>J. A.</forenames></author><author><keyname>Vershynin</keyname><forenames>R.</forenames></author></authors><title>Greedy Signal Recovery Review</title><categories>math.NA cs.IT math.IT</categories><msc-class>41A46, 68Q25, 68W20, 90C27</msc-class><journal-ref>Proc. Asilomar Conference on Signals, Systems, and Computers,
  Pacific Grove, CA Oct. 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The two major approaches to sparse recovery are L1-minimization and greedy
methods. Recently, Needell and Vershynin developed Regularized Orthogonal
Matching Pursuit (ROMP) that has bridged the gap between these two approaches.
ROMP is the first stable greedy algorithm providing uniform guarantees.
  Even more recently, Needell and Tropp developed the stable greedy algorithm
Compressive Sampling Matching Pursuit (CoSaMP). CoSaMP provides uniform
guarantees and improves upon the stability bounds and RIC requirements of ROMP.
CoSaMP offers rigorous bounds on computational cost and storage. In many cases,
the running time is just O(NlogN), where N is the ambient dimension of the
signal. This review summarizes these major advances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2257</identifier>
 <datestamp>2008-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2257</id><created>2008-12-12</created><authors><author><keyname>Itoh</keyname><forenames>Jin-ichi</forenames></author><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author><author><keyname>V&#xee;lcu</keyname><forenames>Costin</forenames></author></authors><title>Unfolding Convex Polyhedra via Quasigeodesic Star Unfoldings</title><categories>cs.CG</categories><comments>18 pages, 10 figures</comments><report-no>Smith 091</report-no><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the notion of a star unfolding to be based on a simple
quasigeodesic loop Q rather than on a point. This gives a new general method to
unfold the surface of any convex polyhedron P to a simple, planar polygon:
shortest paths from all vertices of P to Q are cut, and all but one segment of
Q is cut.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2275</identifier>
 <datestamp>2009-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2275</id><created>2008-12-11</created><updated>2009-06-08</updated><authors><author><keyname>Aggarwal</keyname><forenames>Vaneet</forenames></author><author><keyname>Sankar</keyname><forenames>Lalitha</forenames></author><author><keyname>Calderbank</keyname><forenames>A. Robert</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Secrecy capacity of a class of orthogonal relay eavesdropper channels</title><categories>cs.IT math.IT</categories><comments>Submitted to Eurasip Journal on Wireless Communications and
  Networking special issue on Wireless physical layer security, Dec. 2008,
  Revised Jun. 2009</comments><journal-ref>Eurasip Journal on Wireless Communications and Networking, Special
  Issue on Wireless Physical Layer Security, vol. 2009, Jun. 2009.</journal-ref><doi>10.1155/2009/494696</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The secrecy capacity of relay channels with orthogonal components is studied
in the presence of an additional passive eavesdropper node. The relay and
destination receive signals from the source on two orthogonal channels such
that the destination also receives transmissions from the relay on its channel.
The eavesdropper can overhear either one or both of the orthogonal channels.
Inner and outer bounds on the secrecy capacity are developed for both the
discrete memoryless and the Gaussian channel models. For the discrete
memoryless case, the secrecy capacity is shown to be achieved by a partial
decode-and-forward (PDF) scheme when the eavesdropper can overhear only one of
the two orthogonal channels. Two new outer bounds are presented for the
Gaussian model using recent capacity results for a Gaussian multi-antenna
point-to-point channel with a multi-antenna eavesdropper. The outer bounds are
shown to be tight for two sub-classes of channels. The first sub-class is one
in which the source and relay are clustered and the and the eavesdropper
receives signals only on the channel from the source and the relay to the
destination, for which the PDF strategy is optimal. The second is a sub-class
in which the source does not transmit to the relay, for which a
noise-forwarding strategy is optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2277</identifier>
 <datestamp>2008-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2277</id><created>2008-12-11</created><authors><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author></authors><title>An Efficient PTAS for Two-Strategy Anonymous Games</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel polynomial time approximation scheme for two-strategy
anonymous games, in which the players' utility functions, although potentially
different, do not differentiate among the identities of the other players. Our
algorithm computes an $eps$-approximate Nash equilibrium of an $n$-player
2-strategy anonymous game in time $poly(n) (1/eps)^{O(1/eps^2)}$, which
significantly improves upon the running time $n^{O(1/eps^2)}$ required by the
algorithm of Daskalakis &amp; Papadimitriou, 2007. The improved running time is
based on a new structural understanding of approximate Nash equilibria: We show
that, for any $eps$, there exists an $eps$-approximate Nash equilibrium in
which either only $O(1/eps^3)$ players randomize, or all players who randomize
use the same mixed strategy. To show this result we employ tools from the
literature on Stein's Method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2288</identifier>
 <datestamp>2008-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2288</id><created>2008-12-11</created><authors><author><keyname>Monowar</keyname><forenames>Muhammad Mostafa</forenames></author><author><keyname>Rahman</keyname><forenames>Md. Obaidur</forenames></author><author><keyname>Pathan</keyname><forenames>Al-Sakib Khan</forenames></author><author><keyname>Hong</keyname><forenames>Choong Seon</forenames></author></authors><title>Congestion Control Protocol for Wireless Sensor Networks Handling
  Prioritized Heterogeneous Traffic</title><categories>cs.NI</categories><comments>8 Pages</comments><journal-ref>Proceedings of SMPE'08 in conjunction with MobiQuitous 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Heterogeneous applications could be assimilated within the same wireless
sensor network with the aid of modern motes that have multiple sensor boards on
a single radio board. Different types of data generated from such types of
motes might have different transmission characteristics in terms of priority,
transmission rate, required bandwidth, tolerable packet loss, delay demands
etc. Considering a sensor network consisting of such multi-purpose nodes, in
this paper we propose Prioritized Heterogeneous Traffic-oriented Congestion
Control Protocol (PHTCCP) which ensures efficient rate control for prioritized
heterogeneous traffic. Our protocol uses intra-queue and inter-queue priorities
for ensuring feasible transmission rates of heterogeneous data. It also
guarantees efficient link utilization by using dynamic transmission rate
adjustment. Detailed analysis and simulation results are presented along with
the description of our protocol to demonstrate its effectiveness in handling
prioritized heterogeneous traffic in wireless sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2291</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2291</id><created>2008-12-11</created><updated>2013-06-03</updated><authors><author><keyname>Babaioff</keyname><forenames>Moshe</forenames></author><author><keyname>Sharma</keyname><forenames>Yogeshwer</forenames></author><author><keyname>Slivkins</keyname><forenames>Aleksandrs</forenames></author></authors><title>Characterizing Truthful Multi-Armed Bandit Mechanisms</title><categories>cs.DS cs.GT cs.LG</categories><comments>This is the full version of a conference paper published in ACM EC
  2009. This revision is re-focused to emphasize the results that do not rely
  on the &quot;IIA assumption&quot; (see the paper for the definition)</comments><acm-class>F.2.2; K.4.4; F.1.2; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a multi-round auction setting motivated by pay-per-click auctions
for Internet advertising. In each round the auctioneer selects an advertiser
and shows her ad, which is then either clicked or not. An advertiser derives
value from clicks; the value of a click is her private information. Initially,
neither the auctioneer nor the advertisers have any information about the
likelihood of clicks on the advertisements. The auctioneer's goal is to design
a (dominant strategies) truthful mechanism that (approximately) maximizes the
social welfare.
  If the advertisers bid their true private values, our problem is equivalent
to the &quot;multi-armed bandit problem&quot;, and thus can be viewed as a strategic
version of the latter. In particular, for both problems the quality of an
algorithm can be characterized by &quot;regret&quot;, the difference in social welfare
between the algorithm and the benchmark which always selects the same &quot;best&quot;
advertisement. We investigate how the design of multi-armed bandit algorithms
is affected by the restriction that the resulting mechanism must be truthful.
We find that truthful mechanisms have certain strong structural properties --
essentially, they must separate exploration from exploitation -- and they incur
much higher regret than the optimal multi-armed bandit algorithms. Moreover, we
provide a truthful mechanism which (essentially) matches our lower bound on
regret.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2298</identifier>
 <datestamp>2010-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2298</id><created>2008-12-12</created><authors><author><keyname>Gall</keyname><forenames>Francois Le</forenames></author></authors><title>Efficient Isomorphism Testing for a Class of Group Extensions</title><categories>cs.DS cs.CC math.GR quant-ph</categories><comments>17 pages, accepted to the STACS 2009 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The group isomorphism problem asks whether two given groups are isomorphic or
not. Whereas the case where both groups are abelian is well understood and can
be solved efficiently, very little is known about the complexity of isomorphism
testing for nonabelian groups. In this paper we study this problem for a class
of groups corresponding to one of the simplest ways of constructing nonabelian
groups from abelian groups: the groups that are extensions of an abelian group
A by a cyclic group of order m. We present an efficient algorithm solving the
group isomorphism problem for all the groups of this class such that the order
of A is coprime with m. More precisely, our algorithm runs in time almost
linear in the orders of the input groups and works in the general setting where
the groups are given as black-boxes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2301</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2301</id><created>2008-12-12</created><updated>2010-10-18</updated><authors><author><keyname>Byun</keyname><forenames>Ilmu</forenames></author><author><keyname>Kim</keyname><forenames>Kwang Soon</forenames></author></authors><title>Cooperative Hybrid ARQ Protocols: Unified Frameworks for Protocol
  Analysis</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author for submission to another
  journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperative hybrid-ARQ (HARQ) protocols, which can exploit the spatial and
temporal diversities, have been widely studied. The efficiency of cooperative
HARQ protocols is higher than that of cooperative protocols, because
retransmissions are only performed when necessary. We classify cooperative HARQ
protocols as three decode-and-forward based HARQ (DF-HARQ) protocols and two
amplified-and-forward based (AF-HARQ) protocols. To compare these protocols and
obtain the optimum parameters, two unified frameworks are developed for
protocol analysis. Using the frameworks, we can evaluate and compare the
maximum throughput and outage probabilities according to the SNR, the relay
location, and the delay constraint for the protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2309</identifier>
 <datestamp>2008-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2309</id><created>2008-12-12</created><authors><author><keyname>Abenius</keyname><forenames>Tobias</forenames></author></authors><title>Classification of Cell Images Using MPEG-7-influenced Descriptors and
  Support Vector Machines in Cell Morphology</title><categories>stat.AP cs.CV stat.ML</categories><comments>For associated files and erratum, see
  http://Tobbe.nu/pub/2008/cell.morph.mpeg7.svm/</comments><report-no>ISSN 1651-6389</report-no><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Counting and classifying blood cells is an important diagnostic tool in
medicine. Support Vector Machines are increasingly popular and efficient and
could replace artificial neural network systems. Here a method to classify
blood cells is proposed using SVM. A set of statistics on images are
implemented in C++. The MPEG-7 descriptors Scalable Color Descriptor, Color
Structure Descriptor, Color Layout Descriptor and Homogeneous Texture
Descriptor are extended in size and combined with textural features
corresponding to textural properties perceived visually by humans. From a set
of images of human blood cells these statistics are collected. A SVM is
implemented and trained to classify the cell images. The cell images come from
a CellaVision DM-96 machine which classify cells from images from microscopy.
The output images and classification of the CellaVision machine is taken as
ground truth, a truth that is 90-95% correct. The problem is divided in two --
the primary and the simplified. The primary problem is to classify the same
classes as the CellaVision machine. The simplified problem is to differ between
the five most common types of white blood cells. An encouraging result is
achieved in both cases -- error rates of 10.8% and 3.1% -- considering that the
SVM is misled by the errors in ground truth. Conclusion is that further
investigation of performance is worthwhile.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2313</identifier>
 <datestamp>2008-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2313</id><created>2008-12-12</created><authors><author><keyname>Mozer</keyname><forenames>Pierre</forenames><affiliation>TIMC, URObotics</affiliation></author><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author><author><keyname>Stoianovici</keyname><forenames>Dan</forenames><affiliation>URObotics</affiliation></author></authors><title>Urologic robots and future directions</title><categories>cs.RO</categories><proxy>ccsd hal-00346648</proxy><journal-ref>Current Opinion in Urology 19, 1 (2009) 114-9</journal-ref><doi>10.1097/MOU.0b013e32831cc1ba</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  PURPOSE OF REVIEW: Robot-assisted laparoscopic surgery in urology has gained
immense popularity with the daVinci system, but a lot of research teams are
working on new robots. The purpose of this study is to review current urologic
robots and present future development directions. RECENT FINDINGS: Future
systems are expected to advance in two directions: improvements of remote
manipulation robots and developments of image-guided robots. SUMMARY: The final
goal of robots is to allow safer and more homogeneous outcomes with less
variability of surgeon performance, as well as new tools to perform tasks on
the basis of medical transcutaneous imaging, in a less invasive way, at lower
costs. It is expected that improvements for a remote system could be augmented
in reality, with haptic feedback, size reduction, and development of new tools
for natural orifice translumenal endoscopic surgery. The paradigm of
image-guided robots is close to clinical availability and the most advanced
robots are presented with end-user technical assessments. It is also notable
that the potential of robots lies much further ahead than the accomplishments
of the daVinci system. The integration of imaging with robotics holds a
substantial promise, because this can accomplish tasks otherwise impossible.
Image-guided robots have the potential to offer a paradigm shift.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2324</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2324</id><created>2008-12-12</created><authors><author><keyname>Scutari</keyname><forenames>Gesualdo</forenames></author><author><keyname>Palomar</keyname><forenames>Daniel P.</forenames></author><author><keyname>Barbarossa</keyname><forenames>Sergio</forenames></author></authors><title>The MIMO Iterative Waterfilling Algorithm</title><categories>cs.IT cs.GT math.IT</categories><comments>IEEE Transactions on Signal Processing (accepted)</comments><doi>10.1109/TSP.2009.2013894</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the non-cooperative maximization of mutual information
in the vector Gaussian interference channel in a fully distributed fashion via
game theory. This problem has been widely studied in a number of works during
the past decade for frequency-selective channels, and recently for the more
general MIMO case, for which the state-of-the art results are valid only for
nonsingular square channel matrices. Surprisingly, these results do not hold
true when the channel matrices are rectangular and/or rank deficient matrices.
The goal of this paper is to provide a complete characterization of the MIMO
game for arbitrary channel matrices, in terms of conditions guaranteeing both
the uniqueness of the Nash equilibrium and the convergence of asynchronous
distributed iterative waterfilling algorithms. Our analysis hinges on new
technical intermediate results, such as a new expression for the MIMO
waterfilling projection valid (also) for singular matrices, a mean-value
theorem for complex matrix-valued functions, and a general contraction theorem
for the multiuser MIMO watefilling mapping valid for arbitrary channel
matrices. The quite surprising result is that uniqueness/convergence conditions
in the case of tall (possibly singular) channel matrices are more restrictive
than those required in the case of (full rank) fat channel matrices. We also
propose a modified game and algorithm with milder conditions for the uniqueness
of the equilibrium and convergence, and virtually the same performance (in
terms of Nash equilibria) of the original game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2379</identifier>
 <datestamp>2010-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2379</id><created>2008-12-12</created><updated>2010-03-31</updated><authors><author><keyname>Gadouleau</keyname><forenames>Maximilien</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>On the Decoder Error Probability of Rank Metric Codes and
  Constant-Dimension Codes</title><categories>cs.IT math.IT</categories><comments>19 pages, 2 figures, submitted to IEEE Transactions on Information
  Theory. Revised in May 2010.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rank metric codes and constant-dimension codes (CDCs) have been considered
for error control in random network coding. Since decoder errors are more
detrimental to system performance than decoder failures, in this paper we
investigate the decoder error probability (DEP) of bounded distance decoders
(BDDs) for rank metric codes and CDCs. For rank metric codes, we consider a
channel motivated by network coding, where errors with the same row space are
equiprobable. Over such channels, we establish upper bounds on the DEPs of
BDDs, determine the exact DEP of BDDs for maximum rank distance (MRD) codes,
and show that MRD codes have the greatest DEPs up to a scalar. To evaluate the
DEPs of BDDs for CDCs, we first establish some fundamental geometric properties
of the projective space. Using these geometric properties, we then consider
BDDs in both subspace and injection metrics and derive analytical expressions
of their DEPs for CDCs, over a symmetric operator channel, as functions of
their distance distributions. Finally, we focus on CDCs obtained by lifting
rank metric codes and establish two important results: First, we derive
asymptotically tight upper bounds on the DEPs of BDDs in both metrics; Second,
we show that the DEPs for KK codes are the greatest up to a scalar among all
CDCs obtained by lifting rank metric codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2386</identifier>
 <datestamp>2010-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2386</id><created>2008-12-12</created><updated>2009-07-21</updated><authors><author><keyname>Alon</keyname><forenames>Noga</forenames></author><author><keyname>Ben-Shimon</keyname><forenames>Sonny</forenames></author><author><keyname>Krivelevich</keyname><forenames>Michael</forenames></author></authors><title>A note on regular Ramsey graphs</title><categories>math.CO cs.DM</categories><comments>5 pages</comments><journal-ref>Journal of Graph Theory, 64 (3):244--249, 2010</journal-ref><doi>10.1002/jgt.20453</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that there is an absolute constant $C&gt;0$ so that for every natural
$n$ there exists a triangle-free \emph{regular} graph with no independent set
of size at least $C\sqrt{n\log n}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2388</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2388</id><created>2008-12-12</created><updated>2009-10-21</updated><authors><author><keyname>Yukalov</keyname><forenames>V. I.</forenames></author><author><keyname>Sornette</keyname><forenames>D.</forenames></author></authors><title>Physics of risk and uncertainty in quantum decision making</title><categories>physics.soc-ph cs.AI quant-ph</categories><comments>Latex file, 30 pages. Published variant</comments><journal-ref>Eur. Phys. J. B 71 (2009) 533-548</journal-ref><doi>10.1140/epjb/e2009-00245-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Quantum Decision Theory, developed recently by the authors, is applied to
clarify the role of risk and uncertainty in decision making and in particular
in relation to the phenomenon of dynamic inconsistency. By formulating this
notion in precise mathematical terms, we distinguish three types of
inconsistency: time inconsistency, planning paradox, and inconsistency
occurring in some discounting effects. While time inconsistency is well
accounted for in classical decision theory, the planning paradox is in
contradiction with classical utility theory. It finds a natural explanation in
the frame of the Quantum Decision Theory. Different types of discounting
effects are analyzed and shown to enjoy a straightforward explanation within
the suggested theory. We also introduce a general methodology based on
self-similar approximation theory for deriving the evolution equations for the
probabilities of future prospects. This provides a novel classification of
possible discount factors, which include the previously known cases
(exponential or hyperbolic discounting), but also predicts a novel class of
discount factors that decay to a strictly positive constant for very large
future time horizons. This class may be useful to deal with very long-term
discounting situations associated with intergenerational public policy choices,
encompassing issues such as global warming and nuclear waste disposal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2390</identifier>
 <datestamp>2008-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2390</id><created>2008-12-12</created><authors><author><keyname>Santocanale</keyname><forenames>Luigi</forenames><affiliation>LIF</affiliation></author><author><keyname>Venema</keyname><forenames>Yde</forenames><affiliation>ILLC</affiliation></author></authors><title>Completeness for Flat Modal Fixpoint Logics</title><categories>cs.LO math.LO</categories><proxy>ccsd hal-00346782</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper exhibits a general and uniform method to prove completeness for
certain modal fixpoint logics. Given a set \Gamma of modal formulas of the form
\gamma(x, p1, . . ., pn), where x occurs only positively in \gamma, the
language L\sharp (\Gamma) is obtained by adding to the language of polymodal
logic a connective \sharp\_\gamma for each \gamma \epsilon. The term
\sharp\_\gamma (\varphi1, . . ., \varphin) is meant to be interpreted as the
least fixed point of the functional interpretation of the term \gamma(x,
\varphi 1, . . ., \varphi n). We consider the following problem: given \Gamma,
construct an axiom system which is sound and complete with respect to the
concrete interpretation of the language L\sharp (\Gamma) on Kripke frames. We
prove two results that solve this problem. First, let K\sharp (\Gamma) be the
logic obtained from the basic polymodal K by adding a Kozen-Park style fixpoint
axiom and a least fixpoint rule, for each fixpoint connective \sharp\_\gamma.
Provided that each indexing formula \gamma satisfies the syntactic criterion of
being untied in x, we prove this axiom system to be complete. Second,
addressing the general case, we prove the soundness and completeness of an
extension K+ (\Gamma) of K\_\sharp (\Gamma). This extension is obtained via an
effective procedure that, given an indexing formula \gamma as input, returns a
finite set of axioms and derivation rules for \sharp\_\gamma, of size bounded
by the length of \gamma. Thus the axiom system K+ (\Gamma) is finite whenever
\Gamma is finite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2405</identifier>
 <datestamp>2008-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2405</id><created>2008-12-12</created><authors><author><keyname>Valiollahzadeh</keyname><forenames>SeyyedMajid</forenames></author><author><keyname>Nazari</keyname><forenames>Mohammad</forenames></author><author><keyname>Babaie-Zadeh</keyname><forenames>Massoud</forenames></author><author><keyname>Jutten</keyname><forenames>Christian</forenames></author></authors><title>A New Trend in Optimization on Multi Overcomplete Dictionary toward
  Inpainting</title><categories>cs.MM cs.AI</categories><comments>4 pages</comments><report-no>ICASSP 2009</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, great attention was intended toward overcomplete dictionaries and
the sparse representations they can provide. In a wide variety of signal
processing problems, sparsity serves a crucial property leading to high
performance. Inpainting, the process of reconstructing lost or deteriorated
parts of images or videos, is an interesting application which can be handled
by suitably decomposition of an image through combination of overcomplete
dictionaries. This paper addresses a novel technique of such a decomposition
and investigate that through inpainting of images. Simulations are presented to
demonstrate the validation of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2409</identifier>
 <datestamp>2008-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2409</id><created>2008-12-12</created><authors><author><keyname>Hossain</keyname><forenames>Ashraf</forenames></author><author><keyname>Chakrabarti</keyname><forenames>S.</forenames></author><author><keyname>Biswas</keyname><forenames>P. K.</forenames></author></authors><title>Sensing Models and Its Impact on Network Coverage in Wireless Sensor
  Network</title><categories>cs.IT math.IT</categories><comments>5 pages, 5 figures, IEEE Region 10 Colloquium and the Third ICIIS,
  Kharagpur, INDIA December 8-10, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network coverage of wireless sensor network (WSN) means how well an area of
interest is being monitored by the deployed network. It depends mainly on
sensing model of nodes. In this paper, we present three types of sensing models
viz. Boolean sensing model, shadow-fading sensing model and Elfes sensing
model. We investigate the impact of sensing models on network coverage. We also
investigate network coverage based on Poisson node distribution. A comparative
study between regular and random node placement has also been presented in this
paper. This study will be useful for coverage analysis of WSN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2411</identifier>
 <datestamp>2008-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2411</id><created>2008-12-12</created><authors><author><keyname>Nazari</keyname><forenames>Mohammad</forenames></author><author><keyname>Sayadiyan</keyname><forenames>Abolghasem</forenames></author><author><keyname>Valiollahzadeh</keyname><forenames>SeyedMajid</forenames></author></authors><title>Probabilistic SVM/GMM Classifier for Speaker-Independent Vowel
  Recognition in Continues Speech</title><categories>cs.MM cs.AI</categories><comments>4 pages</comments><report-no>ICASSP 2009</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we discuss the issues in automatic recognition of vowels in
Persian language. The present work focuses on new statistical method of
recognition of vowels as a basic unit of syllables. First we describe a vowel
detection system then briefly discuss how the detected vowels can feed to
recognition unit. According to pattern recognition, Support Vector Machines
(SVM) as a discriminative classifier and Gaussian mixture model (GMM) as a
generative model classifier are two most popular techniques. Current
state-ofthe- art systems try to combine them together for achieving more power
of classification and improving the performance of the recognition systems. The
main idea of the study is to combine probabilistic SVM and traditional GMM
pattern classification with some characteristic of speech like band-pass energy
to achieve better classification rate. This idea has been analytically
formulated and tested on a FarsDat based vowel recognition system. The results
show inconceivable increases in recognition accuracy. The tests have been
carried out by various proposed vowel recognition algorithms and the results
have been compared.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2423</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2423</id><created>2008-12-12</created><updated>2008-12-24</updated><authors><author><keyname>Bollig</keyname><forenames>Benedikt</forenames></author></authors><title>On the Expressive Power of 2-Stack Visibly Pushdown Automata</title><categories>cs.LO</categories><acm-class>F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 4 (December
  24, 2008) lmcs:1101</journal-ref><doi>10.2168/LMCS-4(4:16)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visibly pushdown automata are input-driven pushdown automata that recognize
some non-regular context-free languages while preserving the nice closure and
decidability properties of finite automata. Visibly pushdown automata with
multiple stacks have been considered recently by La Torre, Madhusudan, and
Parlato, who exploit the concept of visibility further to obtain a rich
automata class that can even express properties beyond the class of
context-free languages. At the same time, their automata are closed under
boolean operations, have a decidable emptiness and inclusion problem, and enjoy
a logical characterization in terms of a monadic second-order logic over words
with an additional nesting structure. These results require a restricted
version of visibly pushdown automata with multiple stacks whose behavior can be
split up into a fixed number of phases. In this paper, we consider 2-stack
visibly pushdown automata (i.e., visibly pushdown automata with two stacks) in
their unrestricted form. We show that they are expressively equivalent to the
existential fragment of monadic second-order logic. Furthermore, it turns out
that monadic second-order quantifier alternation forms an infinite hierarchy
wrt words with multiple nestings. Combining these results, we conclude that
2-stack visibly pushdown automata are not closed under complementation.
Finally, we discuss the expressive power of B\&quot;{u}chi 2-stack visibly pushdown
automata running on infinite (nested) words. Extending the logic by an infinity
quantifier, we can likewise establish equivalence to existential monadic
second-order logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2454</identifier>
 <datestamp>2008-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2454</id><created>2008-12-12</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>On the statistical physics of directed polymers in a random medium and
  their relation to tree codes</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using well-known results from statistical physics, concerning the almost-sure
behavior of the free energy of directed polymers in a random medium, we prove
that random tree codes achieve the distortion-rate function almost surely under
a certain symmetry condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2458</identifier>
 <datestamp>2008-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2458</id><created>2008-12-12</created><authors><author><keyname>Das</keyname><forenames>Smarajit</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Square Complex Orthogonal Designs with no Zero Entry for any $2^m$
  Antennas</title><categories>cs.IT math.IT</categories><comments>11 pages, 7 figures, 1 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Space-time block codes from square complex orthogonal designs (SCOD) have
been extensively studied and most of the existing SCODs contain large number of
zeros. The zeros in the designs result in high peak-to-average power ratio and
also impose a severe constraint on hardware implementation of the code while
turning off some of the transmitting antennas whenever a zero is transmitted.
Recently, SCODs with no zero entry have been constructed for $2^a$ transmit
antennas whenever $a+1$ is a power of 2. Though there exists codes for 4 and 16
transmit antennas with no zero entry, there is no general method of
construction which gives codes for any number of transmit antennas. In this
paper, we construct SCODs for any power of 2 number of transmit antennas having
all its entries non-zero. Simulation results show that the codes constructed in
this paper outperform the existing codes for the same number of antennas under
peak power constraint while performing the same under average power constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2466</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2466</id><created>2008-12-12</created><updated>2009-11-17</updated><authors><author><keyname>Au</keyname><forenames>Yu-Hin</forenames></author><author><keyname>Robertson</keyname><forenames>Aaron</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>Van der Waerden's Theorem and Avoidability in Words</title><categories>math.CO cs.FL</categories><comments>Co-author added; new results</comments><msc-class>68R15, 20M35, 68Q45, 11B25, 10A50</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pirillo and Varricchio, and independently, Halbeisen and Hungerbuhler
considered the following problem, open since 1994: Does there exist an infinite
word w over a finite subset of Z such that w contains no two consecutive blocks
of the same length and sum? We consider some variations on this problem in the
light of van der Waerden's theorem on arithmetic progressions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2518</identifier>
 <datestamp>2008-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2518</id><created>2008-12-12</created><authors><author><keyname>Zhang</keyname><forenames>Zhifang</forenames></author><author><keyname>Liu</keyname><forenames>Mulan</forenames></author><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author><author><keyname>Ling</keyname><forenames>San</forenames></author><author><keyname>Wang</keyname><forenames>Huaxiong</forenames></author></authors><title>Strongly Multiplicative and 3-Multiplicative Linear Secret Sharing
  Schemes</title><categories>cs.CR</categories><comments>18 pages</comments><journal-ref>Advances in Cryptology - Asiacrypt 2008, vol. 5350 of Lecture
  Notes in Computer Science, pp. 19-36, Springer-Verlag, 2008</journal-ref><doi>10.1007/978-3-540-89255-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Strongly multiplicative linear secret sharing schemes (LSSS) have been a
powerful tool for constructing secure multiparty computation protocols.
However, it remains open whether or not there exist efficient constructions of
strongly multiplicative LSSS from general LSSS. In this paper, we propose the
new concept of a 3-multiplicative LSSS, and establish its relationship with
strongly multiplicative LSSS. More precisely, we show that any 3-multiplicative
LSSS is a strongly multiplicative LSSS, but the converse is not true; and that
any strongly multiplicative LSSS can be efficiently converted into a
3-multiplicative LSSS. Furthermore, we apply 3-multiplicative LSSS to the
computation of unbounded fan-in multiplication, which reduces its round
complexity to four (from five of the previous protocol based on strongly
multiplicative LSSS). We also give two constructions of 3-multiplicative LSSS
from Reed-Muller codes and algebraic geometric codes. We believe that the
construction and verification of 3-multiplicative LSSS are easier than those of
strongly multiplicative LSSS. This presents a step forward in settling the open
problem of efficient constructions of strongly multiplicative LSSS from general
LSSS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2529</identifier>
 <datestamp>2008-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2529</id><created>2008-12-13</created><authors><author><keyname>Laplace</keyname><forenames>Sophie</forenames><affiliation>LIUPPA</affiliation></author><author><keyname>Dalmau</keyname><forenames>Marc</forenames><affiliation>LIUPPA</affiliation></author><author><keyname>Roose</keyname><forenames>Philippe</forenames><affiliation>LIUPPA</affiliation></author></authors><title>Kalinahia: Considering Quality of Service to Design and Execute
  Distributed Multimedia Applications</title><categories>cs.MM</categories><proxy>ccsd hal-00346911</proxy><journal-ref>IEEE/IFIP Int'l Conference on Network Management and Management
  Symposium, Salvador de Bahia : Br\'esil (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the current challenges of Information Systems is to ensure
semi-structured data transmission, such as multimedia data, in a distributed
and pervasive environment. Information Sytems must then guarantee users a
quality of service ensuring data accessibility whatever the hardware and
network conditions may be. They must also guarantee information coherence and
particularly intelligibility that imposes a personalization of the service.
Within this framework, we propose a design method based on original models of
multimedia applications and quality of service. We also define a supervision
platform Kalinahia using a user centered heuristic allowing us to define at any
moment which configuration of software components constitutes the best answers
to users' wishes in terms of service.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2535</identifier>
 <datestamp>2008-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2535</id><created>2008-12-13</created><authors><author><keyname>Deepthi</keyname><forenames>Dasika Ratna</forenames></author><author><keyname>Eswaran</keyname><forenames>K.</forenames></author></authors><title>Pattern Recognition and Memory Mapping using Mirroring Neural Networks</title><categories>cs.AI cs.NE</categories><journal-ref>Paper No 336, IEEE, ICETiC 2009, International Conference on
  Emerging Trends in Computing</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a new kind of learning implementation to recognize
the patterns using the concept of Mirroring Neural Network (MNN) which can
extract information from distinct sensory input patterns and perform pattern
recognition tasks. It is also capable of being used as an advanced associative
memory wherein image data is associated with voice inputs in an unsupervised
manner. Since the architecture is hierarchical and modular it has the potential
of being used to devise learning engines of ever increasing complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2543</identifier>
 <datestamp>2008-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2543</id><created>2008-12-13</created><authors><author><keyname>Fricker</keyname><forenames>Christine</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Guillemin</keyname><forenames>Fabrice</forenames><affiliation>FT R&amp;D</affiliation></author><author><keyname>Robert</keyname><forenames>Philippe</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Perturbation analysis of an M/M/1 queue in a diffusion random
  environment</title><categories>cs.NI</categories><proxy>ccsd inria-00347006</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study in this paper an $M/M/1$ queue whose server rate depends upon the
state of an independent Ornstein-Uhlenbeck diffusion process $(X(t))$ so that
its value at time $t$ is $\mu \phi(X(t))$, where $\phi(x)$ is some bounded
function and $\mu&gt;0$. We first establish the differential system for the
conditional probability density functions of the couple $(L(t),X(t))$ in the
stationary regime, where $L(t)$ is the number of customers in the system at
time $t$. By assuming that $\phi(x)$ is defined by $\phi(x) = 1-\varepsilon
((x\wedge a/\varepsilon)\vee(-b/\varepsilon))$ for some positive real numbers
$a$, $b$ and $\varepsilon$, we show that the above differential system has a
unique solution under some condition on $a$ and $b$. We then show that this
solution is close, in some appropriate sense, to the solution to the
differential system obtained when $\phi$ is replaced with
$\Phi(x)=1-\varepsilon x$ for sufficiently small $\varepsilon$. We finally
perform a perturbation analysis of this latter solution for small
$\varepsilon$. This allows us to check at the first order the validity of the
so-called reduced service rate approximation, stating that everything happens
as if the server rate were constant and equal to $\mu(1-\eps\E(X(t)))$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2544</identifier>
 <datestamp>2008-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2544</id><created>2008-12-13</created><authors><author><keyname>Chabchoub</keyname><forenames>Yousra</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Fricker</keyname><forenames>Christine</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Guillemin</keyname><forenames>Fabrice</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Robert</keyname><forenames>Philippe</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Inference of Flow Statistics via Packet Sampling in the Internet</title><categories>cs.NI</categories><proxy>ccsd inria-00347008</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show in this note that by deterministic packet sampling, the tail of the
distribution of the original flow size can be obtained by rescaling that of the
sampled flow size. To recover information on the flow size distribution lost
through packet sampling, we propose some heuristics based on measurements from
different backbone IP networks. These heuristic arguments allow us to recover
the complete flow size distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2546</identifier>
 <datestamp>2009-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2546</id><created>2008-12-13</created><updated>2009-06-20</updated><authors><author><keyname>Fricker</keyname><forenames>Christine</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Guillemin</keyname><forenames>Fabrice</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Robert</keyname><forenames>Philippe</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>An identification problem in an urn and ball model with heavy tailed
  distributions</title><categories>cs.NI</categories><proxy>ccsd inria-00347012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider in this paper an urn and ball problem with replacement, where
balls are with different colors and are drawn uniformly from a unique urn. The
numbers of balls with a given color are i.i.d. random variables with a heavy
tailed probability distribution, for instance a Pareto or a Weibull
distribution. We draw a small fraction $p\ll 1$ of the total number of balls.
The basic problem addressed in this paper is to know to which extent we can
infer the total number of colors and the distribution of the number of balls
with a given color. By means of Le Cam's inequality and Chen-Stein method,
bounds for the total variation norm between the distribution of the number of
balls drawn with a given color and the Poisson distribution with the same mean
are obtained. We then show that the distribution of the number of balls drawn
with a given color has the same tail as that of the original number of balls.
We finally establish explicit bounds between the two distributions when each
ball is drawn with fixed probability $p$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2559</identifier>
 <datestamp>2008-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2559</id><created>2008-12-13</created><authors><author><keyname>Tanatmis</keyname><forenames>Akin</forenames></author><author><keyname>Ruzika</keyname><forenames>Stefan</forenames></author><author><keyname>Hamacher</keyname><forenames>Horst W.</forenames></author><author><keyname>Punekar</keyname><forenames>Mayur</forenames></author><author><keyname>Kienle</keyname><forenames>Frank</forenames></author><author><keyname>Wehn</keyname><forenames>Norbert</forenames></author></authors><title>A Separation Algorithm for Improved LP-Decoding of Linear Block Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximum Likelihood (ML) decoding is the optimal decoding algorithm for
arbitrary linear block codes and can be written as an Integer Programming (IP)
problem. Feldman et al. relaxed this IP problem and presented Linear
Programming (LP) based decoding algorithm for linear block codes. In this
paper, we propose a new IP formulation of the ML decoding problem and solve the
IP with generic methods. The formulation uses indicator variables to detect
violated parity checks. We derive Gomory cuts from our formulation and use them
in a separation algorithm to find ML codewords. We further propose an efficient
method of finding cuts induced by redundant parity checks (RPC). Under certain
circumstances we can guarantee that these RPC cuts are valid and cut off the
fractional optimal solutions of LP decoding. We demonstrate on two LDPC codes
and one BCH code that our separation algorithm performs significantly better
than LP decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2563</identifier>
 <datestamp>2009-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2563</id><created>2008-12-15</created><authors><author><keyname>Laurent</keyname><forenames>Monique</forenames><affiliation>CWI</affiliation></author><author><keyname>Mourrain</keyname><forenames>Bernard</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>A Sparse Flat Extension Theorem for Moment Matrices</title><categories>cs.SC math.AC</categories><proxy>ccsd inria-00347022</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we prove a generalization of the flat extension theorem of Curto
and Fialkow for truncated moment matrices. It applies to moment matrices
indexed by an arbitrary set of monomials and its border, assuming that this set
is connected to 1. When formulated in a basis-free setting, this gives an
equivalent result for truncated Hankel operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2567</identifier>
 <datestamp>2014-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2567</id><created>2008-12-13</created><authors><author><keyname>Li</keyname><forenames>Jian</forenames></author></authors><title>An $O({\log n\over \log\log n})$ Upper Bound on the Price of Stability
  for Undirected Shapley Network Design Games</title><categories>cs.GT</categories><journal-ref>Information Processing Letters archive Volume 109 Issue 15, July,
  2009 Pages 876-878</journal-ref><doi>10.1016/j.ipl.2009.04.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the Shapley network design game on undirected
networks. In this game, we have an edge weighted undirected network $G(V,E)$
and $n$ selfish players where player $i$ wants to choose a path from source
vertex $s_i$ to destination vertex $t_i$. The cost of each edge is equally
split among players who pass it. The price of stability is defined as the ratio
of the cost of the best Nash equilibrium to that of the optimal solution. We
present an $O(\log n/\log\log n)$ upper bound on price of stability for the
single sink case, i.e, $t_i=t$ for all $i$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2574</identifier>
 <datestamp>2008-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2574</id><created>2008-12-13</created><authors><author><keyname>Valiollahzadeh</keyname><forenames>Seyyed Majid</forenames></author><author><keyname>Sayadiyan</keyname><forenames>Abolghasem</forenames></author><author><keyname>Nazari</keyname><forenames>Mohammad</forenames></author></authors><title>Feature Selection By KDDA For SVM-Based MultiView Face Recognition</title><categories>cs.CV cs.LG</categories><comments>6 pages</comments><report-no>IEEE SETIT 2007</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Applications such as face recognition that deal with high-dimensional data
need a mapping technique that introduces representation of low-dimensional
features with enhanced discriminatory power and a proper classifier, able to
classify those complex features. Most of traditional Linear Discriminant
Analysis suffer from the disadvantage that their optimality criteria are not
directly related to the classification ability of the obtained feature
representation. Moreover, their classification accuracy is affected by the
&quot;small sample size&quot; problem which is often encountered in FR tasks. In this
short paper, we combine nonlinear kernel based mapping of data called KDDA with
Support Vector machine classifier to deal with both of the shortcomings in an
efficient and cost effective manner. The proposed here method is compared, in
terms of classification accuracy, to other commonly used FR methods on UMIST
face database. Results indicate that the performance of the proposed method is
overall superior to those of traditional FR approaches, such as the Eigenfaces,
Fisherfaces, and D-LDA methods and traditional linear classifiers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2575</identifier>
 <datestamp>2008-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2575</id><created>2008-12-13</created><authors><author><keyname>Valiollahzadeh</keyname><forenames>Seyyed Majid</forenames></author><author><keyname>Sayadiyan</keyname><forenames>Abolghasem</forenames></author><author><keyname>Nazari</keyname><forenames>Mohammad</forenames></author></authors><title>Face Detection Using Adaboosted SVM-Based Component Classifier</title><categories>cs.CV cs.LG</categories><comments>7 pages</comments><report-no>ICEIS Portugal 2007</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Adaboost has been widely used to improve the accuracy of any given
learning algorithm. In this paper we focus on designing an algorithm to employ
combination of Adaboost with Support Vector Machine as weak component
classifiers to be used in Face Detection Task. To obtain a set of effective
SVM-weaklearner Classifier, this algorithm adaptively adjusts the kernel
parameter in SVM instead of using a fixed one. Proposed combination outperforms
in generalization in comparison with SVM on imbalanced classification problem.
The proposed here method is compared, in terms of classification accuracy, to
other commonly used Adaboost methods, such as Decision Trees and Neural
Networks, on CMU+MIT face database. Results indicate that the performance of
the proposed method is overall superior to previous Adaboost approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2599</identifier>
 <datestamp>2008-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2599</id><created>2008-12-14</created><authors><author><keyname>Keshavan</keyname><forenames>Raghunandan H.</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Oh</keyname><forenames>Sewoong</forenames></author></authors><title>Learning Low Rank Matrices from O(n) Entries</title><categories>cs.DS</categories><comments>8 pages, 11 figures, Forty-sixth Allerton Conference on
  Communication, Control and Computing, invited paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How many random entries of an n by m, rank r matrix are necessary to
reconstruct the matrix within an accuracy d? We address this question in the
case of a random matrix with bounded rank, whereby the observed entries are
chosen uniformly at random. We prove that, for any d&gt;0, C(r,d)n observations
are sufficient. Finally we discuss the question of reconstructing the matrix
efficiently, and demonstrate through extensive simulations that this task can
be accomplished in nPoly(log n) operations, for small rank.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2602</identifier>
 <datestamp>2008-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2602</id><created>2008-12-14</created><authors><author><keyname>Gurevich</keyname><forenames>Shamgar</forenames><affiliation>University of California Berkeley</affiliation></author><author><keyname>Hadani</keyname><forenames>Ronny</forenames><affiliation>University of Chicago</affiliation></author></authors><title>The statistical restricted isometry property and the Wigner semicircle
  distribution of incoherent dictionaries</title><categories>cs.IT cs.DM math.IT math.PR</categories><comments>Submitted for The 2009 IEEE International Symposium on Information
  Theory; Key words: Compressive sensing, Stastical version of Candes-Tao RIP,
  Incoherent Dictionaries, Semicircle distribution</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we present a statistical version of the Candes-Tao restricted
isometry property (SRIP for short) which holds in general for any incoherent
dictionary which is a disjoint union of orthonormal bases. In addition, we show
that, under appropriate normalization, the eigenvalues of the associated Gram
matrix fluctuate around 1 according to the Wigner semicircle distribution. The
result is then applied to various dictionaries that arise naturally in the
setting of finite harmonic analysis, giving, in particular, a better
understanding on a remark of Applebaum-Howard-Searle-Calderbank concerning RIP
for the Heisenberg dictionary of chirp like functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2636</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2636</id><created>2008-12-14</created><updated>2010-09-24</updated><authors><author><keyname>Bringmann</keyname><forenames>Karl</forenames></author><author><keyname>Friedrich</keyname><forenames>Tobias</forenames></author></authors><title>Approximating the least hypervolume contributor: NP-hard in general, but
  fast in practice</title><categories>cs.DS cs.CC</categories><comments>22 pages, to appear in Theoretical Computer Science</comments><doi>10.1016/j.tcs.2010.09.026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The hypervolume indicator is an increasingly popular set measure to compare
the quality of two Pareto sets. The basic ingredient of most hypervolume
indicator based optimization algorithms is the calculation of the hypervolume
contribution of single solutions regarding a Pareto set. We show that exact
calculation of the hypervolume contribution is #P-hard while its approximation
is NP-hard. The same holds for the calculation of the minimal contribution. We
also prove that it is NP-hard to decide whether a solution has the least
hypervolume contribution. Even deciding whether the contribution of a solution
is at most $(1+\eps)$ times the minimal contribution is NP-hard. This implies
that it is neither possible to efficiently find the least contributing solution
(unless $P = NP$) nor to approximate it (unless $NP = BPP$).
  Nevertheless, in the second part of the paper we present a fast approximation
algorithm for this problem. We prove that for arbitrarily given $\eps,\delta&gt;0$
it calculates a solution with contribution at most $(1+\eps)$ times the minimal
contribution with probability at least $(1-\delta)$. Though it cannot run in
polynomial time for all instances, it performs extremely fast on various
benchmark datasets. The algorithm solves very large problem instances which are
intractable for exact algorithms (e.g., 10000 solutions in 100 dimensions)
within a few seconds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2702</identifier>
 <datestamp>2008-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2702</id><created>2008-12-14</created><authors><author><keyname>Pavicic</keyname><forenames>Mladen</forenames></author><author><keyname>Megill</keyname><forenames>Norman D.</forenames></author></authors><title>Standard Logics Are Valuation-Nonmonotonic</title><categories>cs.LO cs.AI quant-ph</categories><comments>35 pages, 3 figures</comments><journal-ref>Journal of Logic and Computation, 18 (6) 959-982 (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has recently been discovered that both quantum and classical propositional
logics can be modelled by classes of non-orthomodular and thus non-distributive
lattices that properly contain standard orthomodular and Boolean classes,
respectively. In this paper we prove that these logics are complete even for
those classes of the former lattices from which the standard orthomodular
lattices and Boolean algebras are excluded. We also show that neither quantum
nor classical computers can be founded on the latter models. It follows that
logics are &quot;valuation-nonmonotonic&quot; in the sense that their possible models
(corresponding to their possible hardware implementations) and the valuations
for them drastically change when we add new conditions to their defining
conditions. These valuations can even be completely separated by putting them
into disjoint lattice classes by a technique presented in the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2709</identifier>
 <datestamp>2009-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2709</id><created>2008-12-14</created><updated>2009-11-20</updated><authors><author><keyname>Gallager</keyname><forenames>Robert G.</forenames></author><author><keyname>Nakiboglu</keyname><forenames>Baris</forenames></author></authors><title>Variations on a theme by Schalkwijk and Kailath</title><categories>cs.IT math.IT</categories><comments>18 Pages, 4 figures (added reference)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Schalkwijk and Kailath (1966) developed a class of block codes for Gaussian
channels with ideal feedback for which the probability of decoding error
decreases as a second-order exponent in block length for rates below capacity.
This well-known but surprising result is explained and simply derived here in
terms of a result by Elias (1956) concerning the minimum mean-square distortion
achievable in transmitting a single Gaussian random variable over multiple uses
of the same Gaussian channel. A simple modification of the Schalkwijk-Kailath
scheme is then shown to have an error probability that decreases with an
exponential order which is linearly increasing with block length. In the
infinite bandwidth limit, this scheme produces zero error probability using
bounded expected energy at all rates below capacity. A lower bound on error
probability for the finite bandwidth case is then derived in which the error
probability decreases with an exponential order which is linearly increasing in
block length at the same rate as the upper bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2719</identifier>
 <datestamp>2009-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2719</id><created>2008-12-14</created><updated>2009-09-11</updated><authors><author><keyname>Wong</keyname><forenames>Tan F.</forenames></author><author><keyname>Bloch</keyname><forenames>Matthieu</forenames></author><author><keyname>Shea</keyname><forenames>John M.</forenames></author></authors><title>Secret Sharing over Fast-Fading MIMO Wiretap Channels</title><categories>cs.IT math.IT</categories><comments>Revision submitted to EURASIP Journal on Wireless Communications and
  Networking, Special Issue on Wireless Physical Layer Security, Sept. 2009.
  v.3: Fixes to proofs. Matthieu Bloch added as co-author for contributions to
  proofs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secret sharing over the fast-fading MIMO wiretap channel is considered. A
source and a destination try to share secret information over a fast-fading
MIMO channel in the presence of a wiretapper who also makes channel
observations that are different from but correlated to those made by the
destination. An interactive authenticated unrestricted public channel is also
available for use by the source and destination in the secret sharing process.
This falls under the &quot;channel-type model with wiretapper&quot; considered by
Ahlswede and Csiszar. A minor extension of their result (to continuous channel
alphabets) is employed to evaluate the key capacity of the fast-fading MIMO
wiretap channel. The effects of spatial dimensionality provided by the use of
multiple antennas at the source, destination, and wiretapper are then
investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2726</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2726</id><created>2008-12-15</created><authors><author><keyname>Murayama</keyname><forenames>Tatsuto</forenames></author><author><keyname>Davis</keyname><forenames>Peter</forenames></author></authors><title>Universal Behavior in Large-scale Aggregation of Independent Noisy
  Observations</title><categories>cs.IT math.IT</categories><comments>10 pages, 3 figures</comments><doi>10.1209/0295-5075/87/48003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aggregation of noisy observations involves a difficult tradeoff between
observation quality, which can be increased by increasing the number of
observations, and aggregation quality which decreases if the number of
observations is too large. We clarify this behavior for a protypical system in
which arbitrarily large numbers of observations exceeding the system capacity
can be aggregated using lossy data compression. We show the existence of a
scaling relation between the collective error and the system capacity, and show
that large scale lossy aggregation can outperform lossless aggregation above a
critical level of observation noise. Further, we show that universal results
for scaling and critical value of noise which are independent of system
capacity can be obtained by considering asymptotic behavior when the system
capacity increases toward infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2734</identifier>
 <datestamp>2008-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2734</id><created>2008-12-15</created><updated>2008-12-30</updated><authors><author><keyname>Cameron</keyname><forenames>Kathie</forenames></author><author><keyname>Ho&#xe0;ng</keyname><forenames>Chinh</forenames></author><author><keyname>L&#xe9;v&#xea;que</keyname><forenames>Benjamin</forenames></author></authors><title>Asteroids in rooted and directed path graphs</title><categories>cs.DM</categories><proxy>ccsd hal-00347163</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An asteroidal triple is a stable set of three vertices such that each pair is
connected by a path avoiding the neighborhood of the third vertex. Asteroidal
triples play a central role in a classical characterization of interval graphs
by Lekkerkerker and Boland. Their result says that a chordal graph is an
interval graph if and only if it contains no asteroidal triple. In this paper,
we prove an analogous theorem for directed path graphs which are the
intersection graphs of directed paths in a directed tree. For this purpose, we
introduce the notion of a strong path. Two non-adjacent vertices are linked by
a strong path if either they have a common neighbor or they are the endpoints
of two vertex-disjoint chordless paths satisfying certain conditions. A strong
asteroidal triple is an asteroidal triple such that each pair is linked by a
strong path. We prove that a chordal graph is a directed path graph if and only
if it contains no strong asteroidal triple. We also introduce a related notion
of asteroidal quadruple, and conjecture a characterization of rooted path
graphs which are the intersection graphs of directed paths in a rooted tree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2769</identifier>
 <datestamp>2009-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2769</id><created>2008-12-15</created><updated>2009-05-04</updated><authors><author><keyname>Gordon</keyname><forenames>Dan</forenames><affiliation>Univ. of Haifa</affiliation></author><author><keyname>Gordon</keyname><forenames>Rachel</forenames><affiliation>Technion-Israel Inst. of Technology</affiliation></author></authors><title>Geometric scaling: a simple preconditioner for certain linear systems
  with discontinuous coefficients</title><categories>cs.MS cs.NA</categories><comments>22 pages, 13 tables, 14 figures, 22 references. Submitted for
  publication</comments><acm-class>G.1.3; G.1.8; G.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear systems with large differences between coefficients (&quot;discontinuous
coefficients&quot;) arise in many cases in which partial differential
equations(PDEs) model physical phenomena involving heterogeneous media. The
standard approach to solving such problems is to use domain decomposition
techniques, with domain boundaries conforming to the boundaries between the
different media. This approach can be difficult to implement when the geometry
of the domain boundaries is complicated or the grid is unstructured. This work
examines the simple preconditioning technique of scaling the equations by
dividing each equation by the Lp-norm of its coefficients. This preconditioning
is called geometric scaling (GS). It has long been known that diagonal scaling
can be useful in improving convergence, but there is no study on the general
usefulness of this approach for discontinuous coefficients. GS was tested on
several nonsymmetric linear systems with discontinuous coefficients derived
from convection-diffusion elliptic PDEs with small to moderate convection
terms. It is shown that GS improved the convergence properties of restarted
GMRES and Bi-CGSTAB, with and without the ILUT preconditioner. GS was also
shown to improve the distribution of the eigenvalues by reducing their
concentration around the origin very significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2775</identifier>
 <datestamp>2009-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2775</id><created>2008-12-15</created><updated>2009-12-02</updated><authors><author><keyname>Fischer</keyname><forenames>Johannes</forenames></author></authors><title>Optimal Succinctness for Range Minimum Queries</title><categories>cs.DS</categories><comments>12 pages; to appear in Proc. LATIN'10</comments><acm-class>E.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a static array A of n ordered objects, a range minimum query asks for the
position of the minimum between two specified array indices. We show how to
preprocess A into a scheme of size 2n+o(n) bits that allows to answer range
minimum queries on A in constant time. This space is asymptotically optimal in
the important setting where access to A is not permitted after the
preprocessing step. Our scheme can be computed in linear time, using only n +
o(n) additional bits at construction time. In interesting by-product is that we
also improve on LCA-computation in BPS- or DFUDS-encoded trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2785</identifier>
 <datestamp>2008-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2785</id><created>2008-12-15</created><authors><author><keyname>Lubinsky</keyname><forenames>Baruch</forenames></author><author><keyname>Genc</keyname><forenames>Bekir</forenames></author><author><keyname>Marwala</keyname><forenames>Tshilidzi</forenames></author></authors><title>Prediction of Platinum Prices Using Dynamically Weighted Mixture of
  Experts</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural networks are powerful tools for classification and regression in
static environments. This paper describes a technique for creating an ensemble
of neural networks that adapts dynamically to changing conditions. The model
separates the input space into four regions and each network is given a weight
in each region based on its performance on samples from that region. The
ensemble adapts dynamically by constantly adjusting these weights based on the
current performance of the networks. The data set used is a collection of
financial indicators with the goal of predicting the future platinum price. An
ensemble with no weightings does not improve on the naive estimate of no weekly
change; our weighting algorithm gives an average percentage error of 63% for
twenty weeks of prediction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2851</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2851</id><created>2008-12-15</created><updated>2010-02-11</updated><authors><author><keyname>Elmasry</keyname><forenames>Amr</forenames></author></authors><title>The Violation Heap: A Relaxed Fibonacci-Like Heap</title><categories>cs.DS</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a priority queue that achieves the same amortized bounds as Fibonacci
heaps. Namely, find-min requires O(1) worst-case time, insert, meld and
decrease-key require O(1) amortized time, and delete-min requires $O(\log n)$
amortized time. Our structure is simple and promises an efficient practical
behavior when compared to other known Fibonacci-like heaps. The main idea
behind our construction is to propagate rank updates instead of performing
cascaded cuts following a decrease-key operation, allowing for a relaxed
structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2868</identifier>
 <datestamp>2009-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2868</id><created>2008-12-15</created><updated>2009-01-28</updated><authors><author><keyname>Gawrychowski</keyname><forenames>Pawel</forenames></author><author><keyname>Gagie</keyname><forenames>Travis</forenames></author></authors><title>Minimax Trees in Linear Time</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A minimax tree is similar to a Huffman tree except that, instead of
minimizing the weighted average of the leaves' depths, it minimizes the maximum
of any leaf's weight plus its depth. Golumbic (1976) introduced minimax trees
and gave a Huffman-like, $\Oh{n \log n}$-time algorithm for building them.
Drmota and Szpankowski (2002) gave another $\Oh{n \log n}$-time algorithm,
which checks the Kraft Inequality in each step of a binary search. In this
paper we show how Drmota and Szpankowski's algorithm can be made to run in
linear time on a word RAM with (\Omega (\log n))-bit words. We also discuss how
our solution applies to problems in data compression, group testing and circuit
design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2870</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2870</id><created>2008-12-15</created><updated>2011-01-24</updated><authors><author><keyname>Knauer</keyname><forenames>Kolja</forenames></author><author><keyname>Micek</keyname><forenames>Piotr</forenames></author><author><keyname>Ueckerdt</keyname><forenames>Torsten</forenames></author></authors><title>How to eat 4/9 of a pizza</title><categories>cs.DM math.CO</categories><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given two players alternately picking pieces of a pizza sliced by radial
cuts, in such a way that after the first piece is taken every subsequent chosen
piece is adjacent to some previously taken piece, we provide a strategy for the
starting player to get 4/9 of the pizza. This is best possible and settles a
conjecture of Peter Winkler.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2874</identifier>
 <datestamp>2008-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2874</id><created>2008-12-15</created><authors><author><keyname>Branson</keyname><forenames>Andrew</forenames></author><author><keyname>Hauer</keyname><forenames>Tamas</forenames></author><author><keyname>McClatchey</keyname><forenames>Richard</forenames></author><author><keyname>Rogulin</keyname><forenames>Dmitry</forenames></author><author><keyname>Shamdasani</keyname><forenames>Jetendr</forenames></author></authors><title>A Data Model for Integrating Heterogeneous Medical Data in the
  Health-e-Child Project</title><categories>cs.DB</categories><comments>10 pages, 4 figures, 1 table. Proceedings the 6th HealthGrid Int.
  Conference (HG08)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been much research activity in recent times about providing the
data infrastructures needed for the provision of personalised healthcare. In
particular the requirement of integrating multiple, potentially distributed,
heterogeneous data sources in the medical domain for the use of clinicians has
set challenging goals for the healthgrid community. The approach advocated in
this paper surrounds the provision of an Integrated Data Model plus links
to/from ontologies to homogenize biomedical (from genomic, through cellular,
disease, patient and population-related) data in the context of the EC
Framework 6 Health-e-Child project. Clinical requirements are identified, the
design approach in constructing the model is detailed and the integrated model
described in the context of examples taken from that project. Pointers are
given to future work relating the model to medical ontologies and challenges to
the use of fully integrated models and ontologies are identified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2879</identifier>
 <datestamp>2008-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2879</id><created>2008-12-15</created><authors><author><keyname>Munir</keyname><forenames>Kamran</forenames></author><author><keyname>Odeh</keyname><forenames>Mohammed</forenames></author><author><keyname>McClatchey</keyname><forenames>Richard</forenames></author></authors><title>Ontology Assisted Query Reformulation Using Semantic and Assertion
  Capabilities of OWL-DL Ontologies</title><categories>cs.DB</categories><comments>15 pages, 4 figures. Proceedings of the 12th International Database
  Engineering &amp; Applications Symposium (Ideas2008)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  End users of recent biomedical information systems are often unaware of the
storage structure and access mechanisms of the underlying data sources and can
require simplified mechanisms for writing domain specific complex queries. This
research aims to assist users and their applications in formulating queries
without requiring complete knowledge of the information structure of underlying
data sources. To achieve this, query reformulation techniques and algorithms
have been developed that can interpret ontology-based search criteria and
associated domain knowledge in order to reformulate a relational query. These
query reformulation algorithms exploit the semantic relationships and assertion
capabilities of OWL-DL based domain ontologies for query reformulation. In this
paper, this approach is applied to the integrated database schema of the EU
funded Health-e-Child (HeC) project with the aim of providing ontology assisted
query reformulation techniques to simplify the global access that is needed to
millions of medical records across the UK and Europe.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2891</identifier>
 <datestamp>2008-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2891</id><created>2008-12-15</created><authors><author><keyname>Chalasani</keyname><forenames>Sandeep</forenames></author></authors><title>On the Value of a Social Network</title><categories>cs.NI</categories><comments>12 pages; 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate the value of a social network with respect to
the probability mechanism underlying its structure. Specifically, we compute
the value for small world and scale free networks. We provide evidence in
support of the value to be given by Zipfs law.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2892</identifier>
 <datestamp>2008-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2892</id><created>2008-12-15</created><authors><author><keyname>Zayyani</keyname><forenames>Hadi.</forenames></author><author><keyname>Valiollahzadeh</keyname><forenames>Seyyedmajid</forenames></author><author><keyname>Babaie-Zadeh</keyname><forenames>Massoud.</forenames></author></authors><title>Sparse Component Analysis (SCA) in Random-valued and Salt and Pepper
  Noise Removal</title><categories>cs.CV</categories><comments>6 pages</comments><report-no>ICEE 2008</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new method for impulse noise removal from images.
It uses the sparsity of images in the Discrete Cosine Transform (DCT) domain.
The zeros in this domain give us the exact mathematical equation to reconstruct
the pixels that are corrupted by random-value impulse noises. The proposed
method can also detect and correct the corrupted pixels. Moreover, in a simpler
case that salt and pepper noise is the brightest and darkest pixels in the
image, we propose a simpler version of our method. In addition to the proposed
method, we suggest a combination of the traditional median filter method with
our method to yield better results when the percentage of the corrupted samples
is high.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2926</identifier>
 <datestamp>2008-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2926</id><created>2008-12-15</created><authors><author><keyname>Stefanescu</keyname><forenames>Gheorghe</forenames></author><author><keyname>Chira</keyname><forenames>Camelia</forenames></author></authors><title>New parallel programming language design: a bridge between brain models
  and multi-core/many-core computers?</title><categories>cs.PL cs.AI</categories><comments>To appear in: &quot;From Natural Language to Soft Computing: New Paradigms
  in Artificial Intelligence,&quot;, L.A. Zadeh et.al (Eds.), Editing House of
  Romanian Academy, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recurrent theme of this paper is that sequences of long temporal patterns
as opposed to sequences of simple statements are to be fed into computation
devices, being them (new proposed) models for brain activity or
multi-core/many-core computers. In such models, parts of these long temporal
patterns are already committed while other are predicted. This combination of
matching patterns and making predictions appears as a key element in producing
intelligent processing in brain models and getting efficient speculative
execution on multi-core/many-core computers. A bridge between these far-apart
models of computation could be provided by appropriate design of massively
parallel, interactive programming languages. Agapia is a recently proposed
language of this kind, where user controlled long high-level temporal
structures occur at the interaction interfaces of processes. In this paper
Agapia is used to link HTMs brain models with TRIPS multi-core/many-core
architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2967</identifier>
 <datestamp>2008-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2967</id><created>2008-12-15</created><authors><author><keyname>Loffler</keyname><forenames>Maarten</forenames></author><author><keyname>Phillips</keyname><forenames>Jeff M.</forenames></author></authors><title>Shape Fitting on Point Sets with Probability Distributions</title><categories>cs.CG</categories><comments>19 pages, 24 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A typical computational geometry problem begins: Consider a set P of n points
in R^d. However, many applications today work with input that is not precisely
known, for example when the data is sensed and has some known error model. What
if we do not know the set P exactly, but rather we have a probability
distribution mu_p governing the location of each point p in P?
  Consider a set of (non-fixed) points P, and let mu_P be the probability
distribution of this set. We study several measures (e.g. the radius of the
smallest enclosing ball, or the area of the smallest enclosing box) with
respect to mu_P. The solutions to these problems do not, as in the traditional
case, consist of a single answer, but rather a distribution of answers. We
describe several data structures that approximate distributions of answers for
shape fitting problems.
  We provide simple and efficient randomized algorithms for computing all of
these data structures, which are easy to implement and practical. We provide
some experimental results to assert this. We also provide more involved
deterministic algorithms for some of these data structures that run in time
polynomial in n and 1/eps, where eps is the approximation factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2969</identifier>
 <datestamp>2015-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2969</id><created>2008-12-16</created><updated>2008-12-21</updated><authors><author><keyname>Piastra</keyname><forenames>Marco</forenames></author></authors><title>A Growing Self-Organizing Network for Reconstructing Curves and Surfaces</title><categories>cs.NE cs.AI</categories><journal-ref>Neural Networks, 2009. IJCNN 2009. International Joint Conference
  on , vol., no., pp.2533,2540, 14-19 June 2009</journal-ref><doi>10.1109/IJCNN.2009.5178709</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-organizing networks such as Neural Gas, Growing Neural Gas and many
others have been adopted in actual applications for both dimensionality
reduction and manifold learning. Typically, in these applications, the
structure of the adapted network yields a good estimate of the topology of the
unknown subspace from where the input data points are sampled. The approach
presented here takes a different perspective, namely by assuming that the input
space is a manifold of known dimension. In return, the new type of growing
self-organizing network presented gains the ability to adapt itself in way that
may guarantee the effective and stable recovery of the exact topological
structure of the input manifold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2971</identifier>
 <datestamp>2009-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2971</id><created>2008-12-16</created><updated>2009-04-20</updated><authors><author><keyname>Wagh</keyname><forenames>Meghanad D.</forenames></author><author><keyname>Chen</keyname><forenames>Ning</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>Cyclotomic FFT of Length 2047 Based on a Novel 11-point Cyclic
  Convolution</title><categories>cs.IT math.IT</categories><comments>11 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this manuscript, we propose a novel 11-point cyclic convolution algorithm
based on alternate Fourier transform. With the proposed bilinear form, we
construct a length-2047 cyclotomic FFT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2988</identifier>
 <datestamp>2008-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2988</id><created>2008-12-16</created><authors><author><keyname>Bouix</keyname><forenames>Emmanuel</forenames><affiliation>LIUPPA</affiliation></author><author><keyname>Roose</keyname><forenames>Philippe</forenames><affiliation>LIUPPA</affiliation></author><author><keyname>Dalmau</keyname><forenames>Marc</forenames><affiliation>LIUPPA</affiliation></author></authors><title>The Korrontea Data Modeling</title><categories>cs.MM</categories><proxy>ccsd hal-00346824</proxy><journal-ref>Ambisys, Quebec City : Canada (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Needs of multimedia systems evolved due to the evolution of their
architecture which is now distributed into heterogeneous contexts. A critical
issue lies in the fact that they handle, process, and transmit multimedia data.
This data integrates several properties which should be considered since it
holds a considerable part of its semantics, for instance the lips
synchronization in a video. In this paper, we focus on the definition of a
model as a basic abstraction for describing and modeling media in multimedia
systems by taking into account their properties. This model will be used in
software architecture in order to handle data in efficient way. The provided
model is an interesting solution for the integration of media into
applications; we propose to consider and to handle them in a uniform way. This
model is proposed with synchronization policies to ensure synchronous transport
of media. Therefore, we use it in a component model that we develop for the
design and deployment of distributed multimedia systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2989</identifier>
 <datestamp>2008-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2989</id><created>2008-12-16</created><authors><author><keyname>Louberry</keyname><forenames>Christine</forenames><affiliation>LIUPPA</affiliation></author><author><keyname>Roose</keyname><forenames>Philippe</forenames><affiliation>LIUPPA</affiliation></author><author><keyname>Dalmau</keyname><forenames>Marc</forenames><affiliation>LIUPPA</affiliation></author></authors><title>Heterogeneous component interactions: Sensors integration into
  multimedia applications</title><categories>cs.MM</categories><proxy>ccsd hal-00346841</proxy><journal-ref>Journal of Networks, Issue N6, Academy Publisher 3, 4 (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Resource-constrained embedded and mobile devices are becoming increasingly
common. Since few years, some mobile and ubiquitous devices such as wireless
sensor, able to be aware of their physical environment, appeared. Such devices
enable proposing applications which adapt to user's need according the context
evolution. It implies the collaboration of sensors and software components
which differ on their nature and their communication mechanisms. This paper
proposes a unified component model in order to easily design applications based
on software components and sensors without taking care of their nature. Then it
presents a state of the art of communication problems linked to heterogeneous
components and proposes an interaction mechanism which ensures information
exchanges between wireless sensors and software components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2990</identifier>
 <datestamp>2008-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2990</id><created>2008-12-16</created><authors><author><keyname>Mazoit</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LaBRI</affiliation></author></authors><title>Tree-width of hypergraphs and surface duality</title><categories>cs.DM</categories><proxy>ccsd hal-00347270</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Graph Minor III, Robertson and Seymour conjecture that the tree-width of a
planar graph and that of its dual differ by at most one. We prove that given a
hypergraph H on a surface of Euler genus k, the tree-width of H^* is at most
the maximum of tw(H) + 1 + k and the maximum size of a hyperedge of H^*.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2991</identifier>
 <datestamp>2008-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2991</id><created>2008-12-16</created><authors><author><keyname>Bouffier</keyname><forenames>Amanda</forenames><affiliation>LIPN</affiliation></author><author><keyname>Poibeau</keyname><forenames>Thierry</forenames><affiliation>LIPN</affiliation></author><author><keyname>Duclos</keyname><forenames>Catherine</forenames><affiliation>LIM&amp;Bio</affiliation></author></authors><title>Analyse et structuration automatique des guides de bonnes pratiques
  cliniques : essai d'\'evaluation</title><categories>cs.AI</categories><proxy>ccsd hal-00347010</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Health Practice Guideliens are supposed to unify practices and propose
recommendations to physicians. This paper describes GemFrame, a system capable
of semi-automatically filling an XML template from free texts in the clinical
domain. The XML template includes semantic information not explicitly encoded
in the text (pairs of conditions and ac-tions/recommendations). Therefore,
there is a need to compute the exact scope of condi-tions over text sequences
expressing the re-quired actions. We present a system developped for this task.
We show that it yields good performance when applied to the analysis of French
practice guidelines. We conclude with a precise evaluation of the tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3066</identifier>
 <datestamp>2008-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3066</id><created>2008-12-16</created><authors><author><keyname>Eldar</keyname><forenames>Y. C.</forenames></author><author><keyname>Michaeli</keyname><forenames>T.</forenames></author></authors><title>Beyond Bandlimited Sampling: Nonlinearities, Smoothness and Sparsity</title><categories>cs.IT math.IT</categories><comments>35 pages, 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sampling theory has benefited from a surge of research in recent years, due
in part to the intense research in wavelet theory and the connections made
between the two fields. In this survey we present several extensions of the
Shannon theorem, that have been developed primarily in the past two decades,
which treat a wide class of input signals as well as nonideal sampling and
nonlinear distortions. This framework is based on viewing sampling in a broader
sense of projection onto appropriate subspaces, and then choosing the subspaces
to yield interesting new possibilities. For example, our results can be used to
uniformly sample non-bandlimited signals, and to perfectly compensate for
nonlinear effects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3068</identifier>
 <datestamp>2008-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3068</id><created>2008-12-16</created><authors><author><keyname>van Glabbeek</keyname><forenames>Rob</forenames></author><author><keyname>Luttik</keyname><forenames>Bas</forenames></author><author><keyname>Trcka</keyname><forenames>Nikola</forenames></author></authors><title>Branching Bisimilarity with Explicit Divergence</title><categories>cs.LO</categories><report-no>CS-R 08-25</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the relational characterisation of branching bisimilarity with
explicit divergence. We prove that it is an equivalence and that it coincides
with the original definition of branching bisimilarity with explicit divergence
in terms of coloured traces. We also establish a correspondence with several
variants of an action-based modal logic with until- and divergence modalities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3070</identifier>
 <datestamp>2008-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3070</id><created>2008-12-16</created><authors><author><keyname>Borge</keyname><forenames>J.</forenames></author><author><keyname>Arenas</keyname><forenames>A.</forenames></author></authors><title>A Computational Model to Disentangle Semantic Information Embedded in
  Word Association Norms</title><categories>cs.CL cs.AI physics.data-an physics.soc-ph</categories><comments>9 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two well-known databases of semantic relationships between pairs of words
used in psycholinguistics, feature-based and association-based, are studied as
complex networks. We propose an algorithm to disentangle feature based
relationships from free association semantic networks. The algorithm uses the
rich topology of the free association semantic network to produce a new set of
relationships between words similar to those observed in feature production
norms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3120</identifier>
 <datestamp>2016-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3120</id><created>2008-12-16</created><authors><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr.</suffix></author><author><keyname>Kountouris</keyname><forenames>Marios</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Mode Switching for MIMO Broadcast Channel Based on Delay and Channel
  Quantization</title><categories>cs.IT math.IT</categories><comments>29 pages, submitted to EURASIP Special Issue on Multiuser MIMO
  Transmission with Limited Feedback, Cooperation, and Coordination</comments><doi>10.1155/2009/802548</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Imperfect channel state information degrades the performance of
multiple-input multiple-output (MIMO) communications; its effect on single-user
(SU) and multi-user (MU) MIMO transmissions are quite different. In particular,
MU-MIMO suffers from residual inter-user interference due to imperfect channel
state information while SU-MIMO only suffers from a power loss. This paper
compares the throughput loss of both SU and MU MIMO on the downlink due to
delay and channel quantization. Accurate closed-form approximations are derived
for the achievable rates for both SU and MU MIMO. It is shown that SU-MIMO is
relatively robust to delayed and quantized channel information, while MU MIMO
with zero-forcing precoding loses spatial multiplexing gain with a fixed delay
or fixed codebook size. Based on derived achievable rates, a mode switching
algorithm is proposed that switches between SU and MU MIMO modes to improve the
spectral efficiency, based on the average signal-to-noise ratio (SNR), the
normalized Doppler frequency, and the channel quantization codebook size. The
operating regions for SU and MU modes with different delays and codebook sizes
are determined, which can be used to select the preferred mode. It is shown
that the MU mode is active only when the normalized Doppler frequency is very
small and the codebook size is large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3124</identifier>
 <datestamp>2008-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3124</id><created>2008-12-16</created><authors><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Kountouris</keyname><forenames>Marios</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Achievable Throughput of Multi-mode Multiuser MIMO with Imperfect CSI
  Constraints</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to 2009 IEEE International Symposium on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the multiple-input multiple-output (MIMO) broadcast channel with
imperfect channel state information (CSI), neither the capacity nor the optimal
transmission technique have been fully discovered. In this paper, we derive
achievable ergodic rates for a MIMO fading broadcast channel when CSI is
delayed and quantized. It is shown that we should not support too many users
with spatial division multiplexing due to the residual inter-user interference
caused by imperfect CSI. Based on the derived achievable rates, we propose a
multi-mode transmission strategy to maximize the throughput, which adaptively
adjusts the number of active users based on the channel statistics information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3137</identifier>
 <datestamp>2009-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3137</id><created>2008-12-16</created><authors><author><keyname>Holtz</keyname><forenames>Olga</forenames></author></authors><title>Compressive sensing: a paradigm shift in signal processing</title><categories>math.HO cs.DS cs.NA math.NA math.OC</categories><comments>A short survey of compressive sensing</comments><msc-class>90C05, 90C25, 65F50, 94A08, 94A20, 68P30, 65Y20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey a new paradigm in signal processing known as &quot;compressive sensing&quot;.
Contrary to old practices of data acquisition and reconstruction based on the
Shannon-Nyquist sampling principle, the new theory shows that it is possible to
reconstruct images or signals of scientific interest accurately and even
exactly from a number of samples which is far smaller than the desired
resolution of the image/signal, e.g., the number of pixels in the image. This
new technique draws from results in several fields of mathematics, including
algebra, optimization, probability theory, and harmonic analysis. We will
discuss some of the key mathematical ideas behind compressive sensing, as well
as its implications to other fields: numerical analysis, information theory,
theoretical computer science, and engineering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3145</identifier>
 <datestamp>2008-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3145</id><created>2008-12-16</created><updated>2008-12-16</updated><authors><author><keyname>Boczko</keyname><forenames>Erik</forenames></author><author><keyname>DiLullo</keyname><forenames>Andrew</forenames></author><author><keyname>Young</keyname><forenames>Todd</forenames></author></authors><title>Binary Classification Based on Potentials</title><categories>cs.LG</categories><comments>5 pages, 2 figures. Presented at the Ohio Collaborative Conference on
  Bioinformatics (OCCBIO) June 2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a simple and computationally trivial method for binary
classification based on the evaluation of potential functions. We demonstrate
that despite the conceptual and computational simplicity of the method its
performance can match or exceed that of standard Support Vector Machine
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3147</identifier>
 <datestamp>2008-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3147</id><created>2008-12-16</created><authors><author><keyname>Boczko</keyname><forenames>Erik M.</forenames></author><author><keyname>Young</keyname><forenames>Todd</forenames></author><author><keyname>Zie</keyname><forenames>Minhui</forenames></author><author><keyname>Wu</keyname><forenames>Di</forenames></author></authors><title>Comparison of Binary Classification Based on Signed Distance Functions
  with Support Vector Machines</title><categories>cs.LG cs.CG</categories><comments>5 pages, 4 figures. Presented at the Ohio Collaborative Conference on
  Bioinformatics (OCCBIO), June 2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the performance of a simple signed distance function (SDF)
based method by direct comparison with standard SVM packages, as well as
K-nearest neighbor and RBFN methods. We present experimental results comparing
the SDF approach with other classifiers on both synthetic geometric problems
and five benchmark clinical microarray data sets. On both geometric problems
and microarray data sets, the non-optimized SDF based classifiers perform just
as well or slightly better than well-developed, standard SVM methods. These
results demonstrate the potential accuracy of SDF-based methods on some types
of problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3186</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3186</id><created>2008-12-16</created><updated>2009-02-11</updated><authors><author><keyname>Grant</keyname><forenames>E.</forenames></author><author><keyname>Shallit</keyname><forenames>J.</forenames></author><author><keyname>Stoll</keyname><forenames>T.</forenames></author></authors><title>Bounds for the discrete correlation of infinite sequences on k symbols
  and generalized Rudin-Shapiro sequences</title><categories>math.CO cs.FL math.NT</categories><comments>Improved Introduction and new Section 6 (Lovasz local lemma)</comments><msc-class>68R15; 11K38; 11A63; 05D99; 11K31</msc-class><doi>10.4064/aa140-4-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the known autocorrelation properties of the Rudin-Shapiro
sequence, we study the discrete correlation among infinite sequences over a
finite alphabet, where we just take into account whether two symbols are
identical. We show by combinatorial means that sequences cannot be &quot;too&quot;
different, and by an explicit construction generalizing the Rudin-Shapiro
sequence, we show that we can achieve the maximum possible difference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3214</identifier>
 <datestamp>2008-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3214</id><created>2008-12-17</created><updated>2008-12-30</updated><authors><author><keyname>Dutta</keyname><forenames>Malay</forenames><affiliation>Tezpur University India</affiliation></author></authors><title>Two conjectures such that the proof of any one of them will lead to the
  proof that P = NP</title><categories>cs.CC</categories><comments>Some minor corrections</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we define a construct called a time-graph. A complete
time-graph of order n is the cartesian product of a complete graph with n
vertices and a linear graph with n vertices. A time-graph of order n is given
by a subset of the set of edges E(n) of such a graph. The notion of a
hamiltonian time-graph is defined in a natural way and we define the
Hamiltonian time-graph problem (HAMTG) as : Given a time-graph is it
hamiltonian ? We show that the Hamiltonian path problem (HAMP) can be
transformed to HAMTG in polynomial time. We then define certain vector spaces
of functions from E(n) and E(n)xE(n) to B = {0,1}, the field of two elements
and derive certain properties of these spaces. We give two conjectures about
these spaces and prove that if any one of these conjectures is true, we get a
polynomial time algorithm for the Hamiltonian path problem. Since the
Hamiltonian path problem is NP-complete we obtain the proof of P = NP provided
any one of the two conjectures is true.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3226</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3226</id><created>2008-12-17</created><authors><author><keyname>Sclaverano</keyname><forenames>Stefano</forenames><affiliation>TIMC</affiliation></author><author><keyname>Chevreau</keyname><forenames>Gr&#xe9;goire</forenames><affiliation>TIMC</affiliation></author><author><keyname>Vadcard</keyname><forenames>Lucile</forenames><affiliation>LSE</affiliation></author><author><keyname>Mozer</keyname><forenames>Pierre</forenames><affiliation>TIMC</affiliation></author><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author></authors><title>BiopSym: a simulator for enhanced learning of ultrasound-guided prostate
  biopsy</title><categories>cs.RO</categories><proxy>ccsd hal-00347915</proxy><journal-ref>Medecine Meets Virtual Reality, Los Angeles : \'Etats-Unis
  d'Am\'erique (2009)</journal-ref><doi>10.3233/978-1-58603-964-6-301</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a simulator of ultrasound-guided prostate biopsies for
cancer diagnosis. When performing biopsy series, the clinician has to move the
ultrasound probe and to mentally integrate the real-time bi-dimensional images
into a three-dimensional (3D) representation of the anatomical environment.
Such a 3D representation is necessary to sample regularly the prostate in order
to maximize the probability of detecting a cancer if any. To make the training
of young physicians easier and faster we developed a simulator that combines
images computed from three-dimensional ultrasound recorded data to haptic
feedback. The paper presents the first version of this simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3232</identifier>
 <datestamp>2008-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3232</id><created>2008-12-17</created><updated>2008-12-18</updated><authors><author><keyname>Louie</keyname><forenames>Raymond H. Y.</forenames></author><author><keyname>McKay</keyname><forenames>Matthew R.</forenames></author><author><keyname>Collings</keyname><forenames>Iain B.</forenames></author></authors><title>Maximum Sum-Rate of MIMO Multiuser Scheduling with Linear Receivers</title><categories>cs.IT math.IT</categories><comments>25 pages, 8 figures, corrected typos, Subject to minor revision in
  IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze scheduling algorithms for multiuser communication systems with
users having multiple antennas and linear receivers. When there is no feedback
of channel information, we consider a common round robin scheduling algorithm,
and derive new exact and high signal-to-noise ratio (SNR) maximum sum-rate
results for the maximum ratio combining (MRC) and minimum mean squared error
(MMSE) receivers. We also present new analysis of MRC, zero forcing (ZF) and
MMSE receivers in the low SNR regime. When there are limited feedback
capabilities in the system, we consider a common practical scheduling scheme
based on signal-to-interference-and-noise ratio (SINR) feedback at the
transmitter. We derive new accurate approximations for the maximum sum-rate,
for the cases of MRC, ZF and MMSE receivers. We also derive maximum sum-rate
scaling laws, which reveal that the maximum sum-rate of all three linear
receivers converge to the same value for a large number of users, but at
different rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3249</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3249</id><created>2008-12-17</created><authors><author><keyname>DiCarlo</keyname><forenames>Antonio</forenames></author><author><keyname>Milicchio</keyname><forenames>Franco</forenames></author><author><keyname>Paoluzzi</keyname><forenames>Alberto</forenames></author><author><keyname>Shapiro</keyname><forenames>Vadim</forenames></author></authors><title>Chain-Based Representations for Solid and Physical Modeling</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we show that the (co)chain complex associated with a
decomposition of the computational domain, commonly called a mesh in
computational science and engineering, can be represented by a block-bidiagonal
matrix that we call the Hasse matrix. Moreover, we show that
topology-preserving mesh refinements, produced by the action of (the simplest)
Euler operators, can be reduced to multilinear transformations of the Hasse
matrix representing the complex. Our main result is a new representation of the
(co)chain complex underlying field computations, a representation that provides
new insights into the transformations induced by local mesh refinements. Our
approach is based on first principles and is general in that it applies to most
representational domains that can be characterized as cell complexes, without
any restrictions on their type, dimension, codimension, orientability,
manifoldness, connectedness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3259</identifier>
 <datestamp>2009-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3259</id><created>2008-12-17</created><authors><author><keyname>Leao</keyname><forenames>Rodrigo S. C.</forenames></author><author><keyname>Barbosa</keyname><forenames>Valmir C.</forenames></author></authors><title>Approximate conditional distributions of distances between nodes in a
  two-dimensional sensor network</title><categories>cs.NI</categories><journal-ref>Lecture Notes in Computer Science 5513 (2009), 324-338</journal-ref><doi>10.1007/978-3-642-02205-0_23</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When we represent a network of sensors in Euclidean space by a graph, there
are two distances between any two nodes that we may consider. One of them is
the Euclidean distance. The other is the distance between the two nodes in the
graph, defined to be the number of edges on a shortest path between them. In
this paper, we consider a network of sensors placed uniformly at random in a
two-dimensional region and study two conditional distributions related to these
distances. The first is the probability distribution of distances in the graph,
conditioned on Euclidean distances; the other is the probability density
function associated with Euclidean distances, conditioned on distances in the
graph. We study these distributions both analytically (when feasible) and by
means of simulations. To the best of our knowledge, our results constitute the
first of their kind and open up the possibility of discovering improved
solutions to certain sensor-network problems, as for example sensor
localization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3285</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3285</id><created>2008-12-17</created><authors><author><keyname>Maor</keyname><forenames>Alina</forenames></author><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>On Successive Refinement for the Kaspi/Heegard-Berger Problem</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Inform. Theory, December 2008</comments><report-no>Technical Report, CCIT Pub. no. 711, EE Pub. no. 1668, December 2008</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a source that produces independent copies of a triplet of jointly
distributed random variables, $\{X_{i},Y_{i},Z_{i}\}_{i=1}^{\infty}$. The
process $\{X_{i}\}$ is observed at the encoder, and is supposed to be
reproduced at two decoders, where $\{Y_{i}\}$ and $\{Z_{i}\}$ are observed, in
either a causal or non-causal manner. The communication between the encoder and
the decoders is carried in two successive stages. In the first stage, the
transmission is available to both decoders and the source is reconstructed
according to the received bit-stream and the individual side information (SI).
In the second stage, additional information is sent to both decoders and the
source reconstructions are refined according to the transmissions at both
stages and the available SI. It is desired to find the necessary and sufficient
conditions on the communication rates between the encoder and decoders, so that
the distortions incurred (at each stage) will not exceed given thresholds. For
the case of non-degraded causal SI at the decoders, an exact single-letter
characterization of the achievable region is derived for the case of pure
source-coding. Then, for the case of communication carried over independent
DMS's with random states known causally/non-causally at the encoder and with
causal SI about the source at the decoders, a single-letter characterization of
all achievable distortion in both stages is provided and it is shown that the
separation theorem holds. Finally, for non-causal degraded SI, inner and outer
bounds to the achievable rate-distortion region are derived. These bounds are
shown to be tight for certain cases of reconstruction requirements at the
decoders, thereby shading some light on the problem of successive refinement
with non-degraded SI at the decoders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3306</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3306</id><created>2008-12-17</created><authors><author><keyname>Gagie</keyname><forenames>Travis</forenames></author><author><keyname>Nekrich</keyname><forenames>Yakov</forenames></author></authors><title>Worst-Case Optimal Adaptive Prefix Coding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A common complaint about adaptive prefix coding is that it is much slower
than static prefix coding. Karpinski and Nekrich recently took an important
step towards resolving this: they gave an adaptive Shannon coding algorithm
that encodes each character in (O (1)) amortized time and decodes it in (O
(\log H)) amortized time, where $H$ is the empirical entropy of the input
string $s$. For comparison, Gagie's adaptive Shannon coder and both Knuth's and
Vitter's adaptive Huffman coders all use (\Theta (H)) amortized time for each
character. In this paper we give an adaptive Shannon coder that both encodes
and decodes each character in (O (1)) worst-case time. As with both previous
adaptive Shannon coders, we store $s$ in at most ((H + 1) |s| + o (|s|)) bits.
We also show that this encoding length is worst-case optimal up to the lower
order term.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3404</identifier>
 <datestamp>2009-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3404</id><created>2008-12-17</created><updated>2009-11-08</updated><authors><author><keyname>Leveque</keyname><forenames>Olivier</forenames></author><author><keyname>Vignat</keyname><forenames>Christophe</forenames></author><author><keyname>Yuksel</keyname><forenames>Melda</forenames></author></authors><title>Diversity-Multiplexing Tradeoff for the MIMO Static Half-Duplex Relay</title><categories>cs.IT math.IT</categories><comments>19 pages, 2 figures, submitted to the IEEE Transactions on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we investigate the diversity-multiplexing tradeoff (DMT) of the
multiple-antenna (MIMO) static half-duplex relay channel. A general expression
is derived for the DMT upper bound, which can be achieved by a
compress-and-forward protocol at the relay, under certain assumptions. The DMT
expression is given as the solution of a minimization problem in general, and
an explicit expression is found when the relay channel is symmetric in terms of
number of antennas, i.e. the source and the destination have n antennas each,
and the relay has m antennas. It is observed that the static half-duplex DMT
matches the full-duplex DMT when the relay has a single antenna, and is
strictly below the full-duplex DMT when the relay has multiple antennas.
Besides, the derivation of the upper bound involves a new asymptotic study of
spherical integrals (that is, integrals with respect to the Haar measure on the
unitary group U(n)), which is a topic of mathematical interest in itself.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3429</identifier>
 <datestamp>2012-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3429</id><created>2008-12-17</created><updated>2012-03-14</updated><authors><author><keyname>Gavinsky</keyname><forenames>Dmitry</forenames></author></authors><title>Quantum Predictive Learning and Communication Complexity with Single
  Input</title><categories>quant-ph cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a new model of quantum learning that we call Predictive Quantum
(PQ). This is a quantum analogue of PAC, where during the testing phase the
student is only required to answer a polynomial number of testing queries.
  We demonstrate a relational concept class that is efficiently learnable in
PQ, while in any &quot;reasonable&quot; classical model exponential amount of training
data would be required. This is the first unconditional separation between
quantum and classical learning.
  We show that our separation is the best possible in several ways; in
particular, there is no analogous result for a functional class, as well as for
several weaker versions of quantum learning. In order to demonstrate tightness
of our separation we consider a special case of one-way communication that we
call single-input mode, where Bob receives no input. Somewhat surprisingly,
this setting becomes nontrivial when relational communication tasks are
considered. In particular, any problem with two-sided input can be transformed
into a single-input relational problem of equal classical one-way cost. We show
that the situation is different in the quantum case, where the same
transformation can make the communication complexity exponentially larger. This
happens if and only if the original problem has exponential gap between quantum
and classical one-way communication costs. We believe that these auxiliary
results might be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3447</identifier>
 <datestamp>2011-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3447</id><created>2008-12-17</created><updated>2011-04-05</updated><authors><author><keyname>Ng</keyname><forenames>Chris T. K.</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames></author></authors><title>Completion Time Minimization and Robust Power Control in Wireless Packet
  Networks</title><categories>cs.IT math.IT</categories><comments>16 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A wireless packet network is considered in which each user transmits a stream
of packets to its destination. The transmit power of each user interferes with
the transmission of all other users. A convex cost function of the completion
times of the user packets is minimized by optimally allocating the users'
transmission power subject to their respective power constraints. At all ranges
of SINR, completion time minimization can be formulated as a convex
optimization problem and hence can be efficiently solved. In particular,
although the feasible rate region of the wireless network is non-convex, its
corresponding completion time region is shown to be convex. When channel
knowledge is imperfect, robust power control is considered based on the channel
fading distribution subject to outage probability constraints. The problem is
shown to be convex when the fading distribution is log-concave in exponentiated
channel power gains; e.g., when each user is under independent Rayleigh,
Nakagami, or log-normal fading. Applying the optimization frameworks in a
wireless cellular network, the average completion time is significantly reduced
as compared to full power transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3465</identifier>
 <datestamp>2010-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3465</id><created>2008-12-18</created><updated>2010-02-24</updated><authors><author><keyname>Rusmevichientong</keyname><forenames>Paat</forenames></author><author><keyname>Tsitsiklis</keyname><forenames>John N.</forenames></author></authors><title>Linearly Parameterized Bandits</title><categories>cs.LG</categories><comments>40 pages; updated results and references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider bandit problems involving a large (possibly infinite) collection
of arms, in which the expected reward of each arm is a linear function of an
$r$-dimensional random vector $\mathbf{Z} \in \mathbb{R}^r$, where $r \geq 2$.
The objective is to minimize the cumulative regret and Bayes risk. When the set
of arms corresponds to the unit sphere, we prove that the regret and Bayes risk
is of order $\Theta(r \sqrt{T})$, by establishing a lower bound for an
arbitrary policy, and showing that a matching upper bound is obtained through a
policy that alternates between exploration and exploitation phases. The
phase-based policy is also shown to be effective if the set of arms satisfies a
strong convexity condition. For the case of a general set of arms, we describe
a near-optimal policy whose regret and Bayes risk admit upper bounds of the
form $O(r \sqrt{T} \log^{3/2} T)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3478</identifier>
 <datestamp>2008-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3478</id><created>2008-12-18</created><authors><author><keyname>Wong</keyname><forenames>Wilson</forenames></author><author><keyname>Liu</keyname><forenames>Wei</forenames></author><author><keyname>Liaw</keyname><forenames>Saujoe</forenames></author><author><keyname>Balliu</keyname><forenames>Nicoletta</forenames></author><author><keyname>Wu</keyname><forenames>Hongwei</forenames></author><author><keyname>Tade</keyname><forenames>Moses</forenames></author></authors><title>Automatic Construction of Lightweight Domain Ontologies for Chemical
  Engineering Risk Management</title><categories>cs.AI</categories><comments>In the Proceedings of the 11th Conference on Process Integration,
  Modelling and Optimisation for Energy Saving and Pollution Reduction (PRES),
  Prague, Czech Rep., August, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The need for domain ontologies in mission critical applications such as risk
management and hazard identification is becoming more and more pressing. Most
research on ontology learning conducted in the academia remains unrealistic for
real-world applications. One of the main problems is the dependence on
non-incremental, rare knowledge and textual resources, and manually-crafted
patterns and rules. This paper reports work in progress aiming to address such
undesirable dependencies during ontology construction. Initial experiments
using a working prototype of the system revealed promising potentials in
automatically constructing high-quality domain ontologies using real-world
texts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3550</identifier>
 <datestamp>2008-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3550</id><created>2008-12-18</created><authors><author><keyname>Geneves</keyname><forenames>Pierre</forenames></author><author><keyname>Layaida</keyname><forenames>Nabil</forenames></author></authors><title>XML Static Analyzer User Manual</title><categories>cs.PL cs.DB cs.LO cs.SE</categories><report-no>RR-6726</report-no><acm-class>D.3.0; D.3.1; D.3.4; E.1; F.3.1; F.3.2; F.4.1; F.4.3; H.2.3; I.2.4;
  I.7.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document describes how to use the XML static analyzer in practice. It
provides informal documentation for using the XML reasoning solver
implementation. The solver allows automated verification of properties that are
expressed as logical formulas over trees. A logical formula may for instance
express structural constraints or navigation properties (like e.g. path
existence and node selection) in finite trees. Logical formulas can be
expressed using the syntax of XPath expressions, DTD, XML Schemas, and Relax NG
definitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3563</identifier>
 <datestamp>2009-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3563</id><created>2008-12-18</created><updated>2009-01-26</updated><authors><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>LORIA</affiliation></author></authors><title>Questions &amp; Answers for TEI Newcomers</title><categories>cs.DL</categories><proxy>ccsd hal-00348372</proxy><journal-ref>Jahrbuch f\&quot;ur Computerphilologie 10 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides an introduction to the Text Encoding Initia-tive (TEI),
focused at bringing in newcomers who have to deal with a digital document
project and are looking at the capacity that the TEI environment may have to
fulfil his needs. To this end, we avoid a strictly technical presentation of
the TEI and concentrate on the actual issues that such projects face, with
parallel made on the situation within two institutions. While a quick
walkthrough the TEI technical framework is provided, the papers ends up by
showing the essential role of the community in the actual technical
contributions that are being brought to the TEI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3593</identifier>
 <datestamp>2008-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3593</id><created>2008-12-18</created><authors><author><keyname>Caracciolo</keyname><forenames>Sergio</forenames></author><author><keyname>Masbaum</keyname><forenames>Gregor</forenames></author><author><keyname>Sokal</keyname><forenames>Alan D.</forenames></author><author><keyname>Sportiello</keyname><forenames>Andrea</forenames></author></authors><title>A randomized polynomial-time algorithm for the Spanning Hypertree
  Problem on 3-uniform hypergraphs</title><categories>cs.CC math.CO</categories><comments>6 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the problem of determining whether there exists a spanning hypertree
in a given k-uniform hypergraph. This problem is trivially in P for k=2, and is
NP-complete for k&gt;= 4, whereas for k=3, there exists a polynomial-time
algorithm based on Lovasz' theory of polymatroid matching. Here we give a
completely different, randomized polynomial-time algorithm in the case k=3. The
main ingredients are a Pfaffian formula by Vaintrob and one of the authors
(G.M.) for a polynomial that enumerates spanning hypertrees with some signs,
and a lemma on the number of roots of polynomials over a finite field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3632</identifier>
 <datestamp>2011-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3632</id><created>2008-12-18</created><updated>2009-12-13</updated><authors><author><keyname>Sarnowski</keyname><forenames>Wojciech</forenames></author><author><keyname>Szajowski</keyname><forenames>Krzysztof</forenames></author></authors><title>Optimal detection of homogeneous segment of observations in stochastic
  sequence</title><categories>math.PR cs.IT math.IT math.ST stat.TH</categories><comments>13 pages</comments><report-no>Institute of Mathematics, Polish Academy of Science 696</report-no><msc-class>60G40 60K99, 90D60</msc-class><journal-ref>Stochastics An International Journal of Probability and Stochastic
  Processes, Vol. 83, Issue 4-6, 2011, pp. 569-581</journal-ref><doi>10.1080/17442508.2010.540015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Markov process is registered. At random moment $\theta$ the distribution of
observed sequence changes. Using probability maximizing approach the optimal
stopping rule for detecting the change is identified. Some explicit solution is
obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3642</identifier>
 <datestamp>2008-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3642</id><created>2008-12-18</created><authors><author><keyname>Gunduz</keyname><forenames>Deniz</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>MIMO Two-way Relay Channel: Diversity-Multiplexing Tradeoff Analysis</title><categories>cs.IT math.IT</categories><comments>Presented at the Asilomar Conference on Signals, Systems and
  Computers, Pacific Grove, CA, Oct. 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A multi-hop two-way relay channel is considered in which all the terminals
are equipped with multiple antennas. Assuming independent quasi-static Rayleigh
fading channels and channel state information available at the receivers, we
characterize the optimal diversity-multiplexing gain tradeoff (DMT) curve for a
full-duplex relay terminal. It is shown that the optimal DMT can be achieved by
a compress-and-forward type relaying strategy in which the relay quantizes its
received signal and transmits the corresponding channel codeword. It is
noteworthy that, with this transmission protocol, the two transmissions in
opposite directions can achieve their respective single user optimal DMT
performances simultaneously, despite the interference they cause to each other.
Motivated by the optimality of this scheme in the case of the two-way relay
channel, a novel dynamic compress-and-forward (DCF) protocol is proposed for
the one-way multi-hop MIMO relay channel for a half-duplex relay terminal, and
this scheme is shown to achieve the optimal DMT performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3648</identifier>
 <datestamp>2008-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3648</id><created>2008-12-18</created><authors><author><keyname>Bahrami</keyname><forenames>Mehdi</forenames></author></authors><title>A New Method for Knowledge Representation in Expert System's (XMLKR)</title><categories>cs.DC cs.AI</categories><comments>IEEE Procceding 2008</comments><journal-ref>Emerging Trends in Engineering and Technology, 2008. ICETET '08.
  First International Conference, IEEE</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowledge representation it is an essential section of a Expert Systems,
Because in this section we have a framework to establish an expert system then
we can modeling and use by this to design an expert system. Many method it is
exist for knowledge representation but each method have problems, in this paper
we introduce a new method of object oriented by XML language as XMLKR to
knowledge representation, and we want to discuss advantage and disadvantage of
this method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3702</identifier>
 <datestamp>2008-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3702</id><created>2008-12-18</created><authors><author><keyname>Mahoney</keyname><forenames>Michael W.</forenames></author><author><keyname>Lim</keyname><forenames>Lek-Heng</forenames></author><author><keyname>Carlsson</keyname><forenames>Gunnar E.</forenames></author></authors><title>Algorithmic and Statistical Challenges in Modern Large-Scale Data
  Analysis are the Focus of MMDS 2008</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 2008 Workshop on Algorithms for Modern Massive Data Sets (MMDS 2008),
sponsored by the NSF, DARPA, LinkedIn, and Yahoo!, was held at Stanford
University, June 25--28. The goals of MMDS 2008 were (1) to explore novel
techniques for modeling and analyzing massive, high-dimensional, and
nonlinearly-structured scientific and internet data sets; and (2) to bring
together computer scientists, statisticians, mathematicians, and data analysis
practitioners to promote cross-fertilization of ideas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3709</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3709</id><created>2008-12-19</created><updated>2012-05-22</updated><authors><author><keyname>Ng</keyname><forenames>Chris T. K.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Tian</keyname><forenames>Chao</forenames><affiliation>Shitz</affiliation></author><author><keyname>Goldsmith</keyname><forenames>Andrea J.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Minimum Expected Distortion in Gaussian Source Coding with Fading Side
  Information</title><categories>cs.IT math.IT</categories><comments>24 pages, 10 figures</comments><journal-ref>IEEE Trans. Inf. Theory, vol. 58, no. 9, pp. 5725-5739, Sep. 2012</journal-ref><doi>10.1109/TIT.2012.2204476</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An encoder, subject to a rate constraint, wishes to describe a Gaussian
source under squared error distortion. The decoder, besides receiving the
encoder's description, also observes side information consisting of
uncompressed source symbol subject to slow fading and noise. The decoder knows
the fading realization but the encoder knows only its distribution. The
rate-distortion function that simultaneously satisfies the distortion
constraints for all fading states was derived by Heegard and Berger. A layered
encoding strategy is considered in which each codeword layer targets a given
fading state. When the side-information channel has two discrete fading states,
the expected distortion is minimized by optimally allocating the encoding rate
between the two codeword layers. For multiple fading states, the minimum
expected distortion is formulated as the solution of a convex optimization
problem with linearly many variables and constraints. Through a limiting
process on the primal and dual solutions, it is shown that single-layer rate
allocation is optimal when the fading probability density function is
continuous and quasiconcave (e.g., Rayleigh, Rician, Nakagami, and log-normal).
In particular, under Rayleigh fading, the optimal single codeword layer targets
the least favorable state as if the side information was absent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3715</identifier>
 <datestamp>2008-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3715</id><created>2008-12-19</created><authors><author><keyname>Bissay</keyname><forenames>Aur&#xe9;lie</forenames><affiliation>LIESP</affiliation></author><author><keyname>Pernelle</keyname><forenames>Philippe</forenames><affiliation>LIESP</affiliation></author><author><keyname>Lefebvre</keyname><forenames>Arnaud</forenames><affiliation>LIESP</affiliation></author><author><keyname>Bouras</keyname><forenames>Abdelaziz</forenames><affiliation>LIESP</affiliation></author></authors><title>Business processes integration and performance indicators in a PLM</title><categories>cs.DB</categories><proxy>ccsd hal-00345046</proxy><journal-ref>APMS'08, Espoo : Finlande (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an economic environment more and more competitive, the effective
management of information and knowledge is a strategic issue for industrial
enterprises. In the global marketplace, companies must use reactive strategies
and reduce their products development cycle. In this context, the PLM (Product
Lifecycle Management) is considered as a key component of the information
system. The aim of this paper is to present an approach to integrate Business
Processes in a PLM system. This approach is implemented in automotive sector
with second-tier subcontractor
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3716</identifier>
 <datestamp>2008-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3716</id><created>2008-12-19</created><authors><author><keyname>Rodriguez</keyname><forenames>Ismael Bouassida</forenames><affiliation>LAAS</affiliation></author><author><keyname>DRIRA</keyname><forenames>Khalil</forenames><affiliation>LAAS</affiliation></author><author><keyname>Chassot</keyname><forenames>Christophe</forenames><affiliation>LAAS</affiliation></author><author><keyname>Jmaiel</keyname><forenames>Mohamed</forenames><affiliation>ReDCAD</affiliation></author></authors><title>Context-aware adaptation for group communication support applications
  with dynamic architecture</title><categories>cs.SE</categories><proxy>ccsd hal-00345074</proxy><journal-ref>System and Information Sciences Notes 2, 1 (2007) 88</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a refinement-based adaptation approach for the
architecture of distributed group communication support applications. Unlike
most of previous works, our approach reaches implementable, context-aware and
dynamically adaptable architectures. To model the context, we manage
simultaneously four parameters that influence Qos provided by the application.
These parameters are: the available bandwidth, the exchanged data communication
priority, the energy level and the available memory for processing. These
parameters make it possible to refine the choice between the various
architectural configurations when passing from a given abstraction level to the
lower level which implements it. Our approach allows the importance degree
associated with each parameter to be adapted dynamically. To implement
adaptation, we switch between the various configurations of the same level, and
we modify the state of the entities of a given configuration when necessary. We
adopt the direct and mediated Producer- Consumer architectural styles and
graphs for architecture modelling. In order to validate our approach we
elaborate a simulation model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3719</identifier>
 <datestamp>2008-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3719</id><created>2008-12-19</created><authors><author><keyname>Louberry</keyname><forenames>Christine</forenames><affiliation>LIUPPA</affiliation></author><author><keyname>Dalmau</keyname><forenames>Marc</forenames><affiliation>LIUPPA</affiliation></author><author><keyname>Roose</keyname><forenames>Philippe</forenames><affiliation>LIUPPA</affiliation></author></authors><title>Architecture Logicielles pour des Applications h\'et\'erog\`enes,
  distribu\'ees et reconfigurables</title><categories>cs.SE</categories><proxy>ccsd hal-00346770</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent apparition of mobile wireless sensor aware to their physical
environment and able to process information must allow proposing applications
able to take into account their physical context and to react according to the
changes of the environment. It suppose to design applications integrating both
software and hardware components able to communicate. Applications must use
context information from components to measure the quality of the proposed
services in order to adapt them in real time. This work is interested in the
integration of sensors in distributed applications. It present a service
oriented software architecture allowing to manage and to reconfigure
applications in heterogeneous environment where entities of different nature
collaborate: software components and wireless sensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3742</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3742</id><created>2008-12-19</created><authors><author><keyname>Raghavan</keyname><forenames>Vasanthan</forenames></author><author><keyname>Veeravalli</keyname><forenames>Venugopal V.</forenames></author></authors><title>Quickest Change Detection of a Markov Process Across a Sensor Array</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>40 pages, 5 figures, Submitted to IEEE Trans. Inform. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent attention in quickest change detection in the multi-sensor setting has
been on the case where the densities of the observations change at the same
instant at all the sensors due to the disruption. In this work, a more general
scenario is considered where the change propagates across the sensors, and its
propagation can be modeled as a Markov process. A centralized, Bayesian version
of this problem, with a fusion center that has perfect information about the
observations and a priori knowledge of the statistics of the change process, is
considered. The problem of minimizing the average detection delay subject to
false alarm constraints is formulated as a partially observable Markov decision
process (POMDP). Insights into the structure of the optimal stopping rule are
presented. In the limiting case of rare disruptions, we show that the structure
of the optimal test reduces to thresholding the a posteriori probability of the
hypothesis that no change has happened. We establish the asymptotic optimality
(in the vanishing false alarm probability regime) of this threshold test under
a certain condition on the Kullback-Leibler (K-L) divergence between the post-
and the pre-change densities. In the special case of near-instantaneous change
propagation across the sensors, this condition reduces to the mild condition
that the K-L divergence be positive. Numerical studies show that this low
complexity threshold test results in a substantial improvement in performance
over naive tests such as a single-sensor test or a test that wrongly assumes
that the change propagates instantaneously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3788</identifier>
 <datestamp>2009-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3788</id><created>2008-12-19</created><updated>2009-01-26</updated><authors><author><keyname>Schmidt</keyname><forenames>Michael</forenames></author><author><keyname>Meier</keyname><forenames>Michael</forenames></author><author><keyname>Lausen</keyname><forenames>Georg</forenames></author></authors><title>Foundations of SPARQL Query Optimization</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The SPARQL query language is a recent W3C standard for processing RDF data, a
format that has been developed to encode information in a machine-readable way.
We investigate the foundations of SPARQL query optimization and (a) provide
novel complexity results for the SPARQL evaluation problem, showing that the
main source of complexity is operator OPTIONAL alone; (b) propose a
comprehensive set of algebraic query rewriting rules; (c) present a framework
for constraint-based SPARQL optimization based upon the well-known chase
procedure for Conjunctive Query minimization. In this line, we develop two
novel termination conditions for the chase. They subsume the strongest
conditions known so far and do not increase the complexity of the recognition
problem, thus making a larger class of both Conjunctive and SPARQL queries
amenable to constraint-based optimization. Our results are of immediate
practical interest and might empower any SPARQL query optimizer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3836</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3836</id><created>2008-12-19</created><updated>2008-12-25</updated><authors><author><keyname>Schr&#xf6;der</keyname><forenames>Lutz</forenames></author></authors><title>Bootstrapping Inductive and Coinductive Types in HasCASL</title><categories>cs.LO cs.SE</categories><acm-class>D.2.1; E.1; F.3.1; F.3.2; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 4 (December
  25, 2008) lmcs:1166</journal-ref><doi>10.2168/LMCS-4(4:17)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the treatment of initial datatypes and final process types in the
wide-spectrum language HasCASL. In particular, we present specifications that
illustrate how datatypes and process types arise as bootstrapped concepts using
HasCASL's type class mechanism, and we describe constructions of types of
finite and infinite trees that establish the conservativity of datatype and
process type declarations adhering to certain reasonable formats. The latter
amounts to modifying known constructions from HOL to avoid unique choice; in
categorical terminology, this means that we establish that quasitoposes with an
internal natural numbers object support initial algebras and final coalgebras
for a range of polynomial functors, thereby partially generalising
corresponding results from topos theory. Moreover, we present similar
constructions in categories of internal complete partial orders in
quasitoposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3871</identifier>
 <datestamp>2008-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3871</id><created>2008-12-19</created><authors><author><keyname>Alves</keyname><forenames>Nuno</forenames></author></authors><title>Decting Errors in Reversible Circuits With Invariant Relationships</title><categories>cs.AR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reversible logic is experience renewed interest as we are approach the limits
of CMOS technologies. While physical implementations of reversible gates have
yet to materialize, it is safe to assume that they will rely on faulty
individual components. In this work we present a present a method to provide
fault tolerance to a reversible circuit based on invariant relationships.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3873</identifier>
 <datestamp>2008-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3873</id><created>2008-12-19</created><authors><author><keyname>Choo</keyname><forenames>Li-Chia</forenames></author><author><keyname>Wong</keyname><forenames>Kai-Kit</forenames></author></authors><title>The K-Receiver Broadcast Channel with Confidential Messages</title><categories>cs.IT math.IT</categories><comments>19 pages, 1 figure, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The secrecy capacity region for the K-receiver degraded broadcast channel
(BC) is given for confidential messages sent to the receivers and to be kept
secret from an external wiretapper. Superposition coding and Wyner's random
code partitioning are used to show the achievable rate tuples. Error
probability analysis and equivocation calculation are also provided. In the
converse proof, a new definition for the auxiliary random variables is used,
which is different from either the case of the 2-receiver BC without common
message or the K-receiver BC with common message, both with an external
wiretapper; or the K-receiver BC without a wiretapper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3890</identifier>
 <datestamp>2008-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3890</id><created>2008-12-19</created><authors><author><keyname>Beres</keyname><forenames>Elzbieta</forenames></author><author><keyname>Adve</keyname><forenames>Raviraj</forenames></author></authors><title>Optimal Relay-Subset Selection and Time-Allocation in Decode-and-Forward
  Cooperative Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Wirless Comm., Dec. 19th 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the optimal relay-subset selection and transmission-time for a
decode-and-forward, half-duplex cooperative network of arbitrary size. The
resource allocation is obtained by maximizing over the rates obtained for each
possible subset of active relays, and the unique time allocation for each set
can be obtained by solving a linear system of equations. We also present a
simple recursive algorithm for the optimization problem which reduces the
computational load of finding the required matrix inverses, and reduces the
number of required iterations. Our results, in terms of outage rate, confirm
the benefit of adding potential relays to a small network and the diminishing
marginal returns for a larger network. We also show that optimizing over the
channel resources ensures that more relays are active over a larger SNR range,
and that linear network constellations significantly outperform grid
constellations. Through simulations, the optimization is shown to be robust to
node numbering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3893</identifier>
 <datestamp>2009-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3893</id><created>2008-12-19</created><updated>2009-10-02</updated><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Strash</keyname><forenames>Darren</forenames></author></authors><title>Succinct Greedy Geometric Routing in the Euclidean Plane</title><categories>cs.CG</categories><comments>19 pages, 5 figures. To appear at 20th International Symposium on
  Algorithms and Computation (ISAAC 2009)</comments><acm-class>F.2.2; C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In greedy geometric routing, messages are passed in a network embedded in a
metric space according to the greedy strategy of always forwarding messages to
nodes that are closer to the destination. We show that greedy geometric routing
schemes exist for the Euclidean metric in R^2, for 3-connected planar graphs,
with coordinates that can be represented succinctly, that is, with O(log n)
bits, where n is the number of vertices in the graph. Moreover, our embedding
strategy introduces a coordinate system for R^2 that supports distance
comparisons using our succinct coordinates. Thus, our scheme can be used to
significantly reduce bandwidth, space, and header size over other recently
discovered greedy geometric routing implementations for R^2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3933</identifier>
 <datestamp>2009-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3933</id><created>2008-12-19</created><updated>2009-05-04</updated><authors><author><keyname>Hasan</keyname><forenames>Masud</forenames></author><author><keyname>Rahman</keyname><forenames>Atif</forenames></author><author><keyname>Rahman</keyname><forenames>M. Sohel</forenames></author><author><keyname>Sharmin</keyname><forenames>Mahfuza</forenames></author><author><keyname>Yeasmin</keyname><forenames>Rukhsana</forenames></author></authors><title>Pancake Flipping with Two Spatulas</title><categories>cs.DS cs.OH</categories><comments>10 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study several variations of the \emph{pancake flipping
problem}, which is also well known as the problem of \emph{sorting by prefix
reversals}. We consider the variations in the sorting process by adding with
prefix reversals other similar operations such as prefix transpositions and
prefix transreversals. These type of sorting problems have applications in
interconnection networks and computational biology. We first study the problem
of sorting unsigned permutations by prefix reversals and prefix transpositions
and present a 3-approximation algorithm for this problem. Then we give a
2-approximation algorithm for sorting by prefix reversals and prefix
transreversals. We also provide a 3-approximation algorithm for sorting by
prefix reversals and prefix transpositions where the operations are always
applied at the unsorted suffix of the permutation. We further analyze the
problem in more practical way and show quantitatively how approximation ratios
of our algorithms improve with the increase of number of prefix reversals
applied by optimal algorithms. Finally, we present experimental results to
support our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3946</identifier>
 <datestamp>2008-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3946</id><created>2008-12-20</created><authors><author><keyname>Blin</keyname><forenames>Guillaume</forenames><affiliation>IGM</affiliation></author><author><keyname>Hamel</keyname><forenames>Sylvie</forenames><affiliation>DIRO</affiliation></author><author><keyname>Vialette</keyname><forenames>St&#xe9;phane</forenames><affiliation>IGM</affiliation></author></authors><title>Comparing RNA structures using a full set of biologically relevant edit
  operations is intractable</title><categories>cs.DS q-bio.QM</categories><comments>7 pages</comments><proxy>ccsd hal-00347464</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Arc-annotated sequences are useful for representing structural information of
RNAs and have been extensively used for comparing RNA structures in both terms
of sequence and structural similarities. Among the many paradigms referring to
arc-annotated sequences and RNA structures comparison (see
\cite{IGMA_BliDenDul08} for more details), the most important one is the
general edit distance. The problem of computing an edit distance between two
non-crossing arc-annotated sequences was introduced in \cite{Evans99}. The
introduced model uses edit operations that involve either single letters or
pairs of letters (never considered separately) and is solvable in
polynomial-time \cite{ZhangShasha:1989}. To account for other possible RNA
structural evolutionary events, new edit operations, allowing to consider
either silmutaneously or separately letters of a pair were introduced in
\cite{jiangli}; unfortunately at the cost of computational tractability. It has
been proved that comparing two RNA secondary structures using a full set of
biologically relevant edit operations is {\sf\bf NP}-complete. Nevertheless, in
\cite{DBLP:conf/spire/GuignonCH05}, the authors have used a strong
combinatorial restriction in order to compare two RNA stem-loops with a full
set of biologically relevant edit operations; which have allowed them to design
a polynomial-time and space algorithm for comparing general secondary RNA
structures. In this paper we will prove theoretically that comparing two RNA
structures using a full set of biologically relevant edit operations cannot be
done without strong combinatorial restrictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4009</identifier>
 <datestamp>2015-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4009</id><created>2008-12-21</created><updated>2015-12-04</updated><authors><author><keyname>Herman</keyname><forenames>Joshua</forenames></author><author><keyname>Pedersen</keyname><forenames>Keith David</forenames></author></authors><title>Graph Field Automata</title><categories>cs.CC</categories><comments>totally wrong doesn't make any sense would like to widthdraw</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The Graph Automata have been the paradigm in the expression of utilizing
Graphs as a language. Matrix Graph grammars \cite{Pedro} are an algebratization
of graph rewriting systems. Here we present the dual of this formalizm which
some extensions which we term Graph Field Automata The advantage to this
approach is a framework for expressing machines that can use Matrix Graph
Grammars.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4012</identifier>
 <datestamp>2008-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4012</id><created>2008-12-20</created><authors><author><keyname>Alhakim</keyname><forenames>Abbas</forenames></author><author><keyname>Akinwande</keyname><forenames>Mufutau</forenames></author></authors><title>De Bruijn Graph Homomorphisms and Recursive De Bruijn Sequences</title><categories>math.CO cs.IT math.IT</categories><comments>15 pages, 1 figure, 2 tables, submitted</comments><msc-class>68R05, 68R10, 68R15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a method to find new De Bruijn cycles based on ones of
lesser order. This is done by mapping a De Bruijn cycle to several vertex
disjoint cycles in a De Bruijn digraph of higher order and connecting these
cycles into one full cycle. We characterize homomorphisms between De Bruijn
digraphs of different orders that allow this construction. These maps
generalize the well-known D-morphism of Lempel between De Bruijn digraphs of
consecutive orders. Also, an efficient recursive algorithm that yields an
exponential number of nonbinary De Bruijn cycles is implemented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4044</identifier>
 <datestamp>2009-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4044</id><created>2008-12-21</created><updated>2009-02-06</updated><authors><author><keyname>Beygelzimer</keyname><forenames>Alina</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author></authors><title>The Offset Tree for Learning with Partial Labels</title><categories>cs.LG cs.AI</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We present an algorithm, called the Offset Tree, for learning to make
decisions in situations where the payoff of only one choice is observed, rather
than all choices. The algorithm reduces this setting to binary classification,
allowing one to reuse of any existing, fully supervised binary classification
algorithm in this partial information setting. We show that the Offset Tree is
an optimal reduction to binary classification. In particular, it has regret at
most $(k-1)$ times the regret of the binary classifier it uses (where $k$ is
the number of choices), and no reduction to binary classification can do
better. This reduction is also computationally optimal, both at training and
test time, requiring just $O(\log_2 k)$ work to train on an example or make a
prediction.
  Experiments with the Offset Tree show that it generally performs better than
several alternative approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4073</identifier>
 <datestamp>2009-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4073</id><created>2008-12-22</created><updated>2008-12-29</updated><authors><author><keyname>Noack</keyname><forenames>Andreas</forenames></author><author><keyname>Rotta</keyname><forenames>Randolf</forenames></author></authors><title>Multi-level algorithms for modularity clustering</title><categories>cs.DS cond-mat.stat-mech cs.DM physics.soc-ph</categories><comments>12 pages, 10 figures, see
  http://www.informatik.tu-cottbus.de/~rrotta/ for downloading the graph
  clustering software</comments><acm-class>G.2.2; G.2.3; I.5.3</acm-class><journal-ref>Proceedings of the 8th International Symposium on Experimental
  Algorithms (SEA 2009). Lecture Notes in Computer Science 5526, Springer
  (2009) 257-268</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modularity is one of the most widely used quality measures for graph
clusterings. Maximizing modularity is NP-hard, and the runtime of exact
algorithms is prohibitive for large graphs. A simple and effective class of
heuristics coarsens the graph by iteratively merging clusters (starting from
singletons), and optionally refines the resulting clustering by iteratively
moving individual vertices between clusters. Several heuristics of this type
have been proposed in the literature, but little is known about their relative
performance.
  This paper experimentally compares existing and new coarsening- and
refinement-based heuristics with respect to their effectiveness (achieved
modularity) and efficiency (runtime). Concerning coarsening, it turns out that
the most widely used criterion for merging clusters (modularity increase) is
outperformed by other simple criteria, and that a recent algorithm by Schuetz
and Caflisch is no improvement over simple greedy coarsening for these
criteria. Concerning refinement, a new multi-level algorithm is shown to
produce significantly better clusterings than conventional single-level
algorithms. A comparison with published benchmark results and algorithm
implementations shows that combinations of coarsening and multi-level
refinement are competitive with the best algorithms in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4170</identifier>
 <datestamp>2008-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4170</id><created>2008-12-22</created><authors><author><keyname>Gallardo</keyname><forenames>Jose E.</forenames></author><author><keyname>Cotta</keyname><forenames>Carlos</forenames></author><author><keyname>Fernandez</keyname><forenames>Antonio J.</forenames></author></authors><title>Finding Still Lifes with Memetic/Exact Hybrid Algorithms</title><categories>cs.NE cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The maximum density still life problem (MDSLP) is a hard constraint
optimization problem based on Conway's game of life. It is a prime example of
weighted constrained optimization problem that has been recently tackled in the
constraint-programming community. Bucket elimination (BE) is a complete
technique commonly used to solve this kind of constraint satisfaction problem.
When the memory required to apply BE is too high, a heuristic method based on
it (denominated mini-buckets) can be used to calculate bounds for the optimal
solution. Nevertheless, the curse of dimensionality makes these techniques
unpractical for large size problems. In response to this situation, we present
a memetic algorithm for the MDSLP in which BE is used as a mechanism for
recombining solutions, providing the best possible child from the parental set.
Subsequently, a multi-level model in which this exact/metaheuristic hybrid is
further hybridized with branch-and-bound techniques and mini-buckets is
studied. Extensive experimental results analyze the performance of these models
and multi-parent recombination. The resulting algorithm consistently finds
optimal patterns for up to date solved instances in less time than current
approaches. Moreover, it is shown that this proposal provides new best known
solutions for very large instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4171</identifier>
 <datestamp>2009-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4171</id><created>2008-12-22</created><updated>2009-06-03</updated><authors><author><keyname>Bulatov</keyname><forenames>Andrei</forenames></author><author><keyname>Dyer</keyname><forenames>Martin</forenames></author><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author><author><keyname>Jalsenius</keyname><forenames>Markus</forenames></author><author><keyname>Richerby</keyname><forenames>David</forenames></author></authors><title>The Complexity of Weighted Boolean #CSP with Mixed Signs</title><categories>cs.CC cs.DM</categories><comments>24 pages</comments><acm-class>F.2.2; F.4.1; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a complexity dichotomy for the problem of computing the partition
function of a weighted Boolean constraint satisfaction problem. Such a problem
is parameterized by a set of rational-valued functions, which generalize
constraints. Each function assigns a weight to every assignment to a set of
Boolean variables. Our dichotomy extends previous work in which the weight
functions were restricted to being non-negative. We represent a weight function
as a product of the form (-1)^s g, where the polynomial s determines the sign
of the weight and the non-negative function g determines its magnitude. We show
that the problem of computing the partition function (the sum of the weights of
all possible variable assignments) is in polynomial time if either every weight
function can be defined by a &quot;pure affine&quot; magnitude with a quadratic sign
polynomial or every function can be defined by a magnitude of &quot;product type&quot;
with a linear sign polynomial. In all other cases, computing the partition
function is FP^#P-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4181</identifier>
 <datestamp>2008-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4181</id><created>2008-12-22</created><authors><author><keyname>Benameur</keyname><forenames>Azzedine</forenames></author><author><keyname>Kadir</keyname><forenames>Faisal Abdul</forenames></author><author><keyname>Fenet</keyname><forenames>Serge</forenames></author></authors><title>XML Rewriting Attacks: Existing Solutions and their Limitations</title><categories>cs.CR cs.SE</categories><journal-ref>IADIS Applied Computing 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web Services are web-based applications made available for web users or
remote Web-based programs. In order to promote interoperability, they publish
their interfaces in the so-called WSDL file and allow remote call over the
network. Although Web Services can be used in different ways, the industry
standard is the Service Oriented Architecture Web Services that doesn't rely on
the implementation details. In this architecture, communication is performed
through XML-based messages called SOAP messages. However, those messages are
prone to attacks that can lead to code injection, unauthorized accesses,
identity theft, etc. This type of attacks, called XML Rewriting Attacks, are
all based on unauthorized, yet possible, modifications of SOAP messages. We
present in this paper an explanation of this kind of attack, review the
existing solutions, and show their limitations. We also propose some ideas to
secure SOAP messages, as well as implementation ideas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4206</identifier>
 <datestamp>2008-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4206</id><created>2008-12-22</created><authors><author><keyname>Mavronicolas</keyname><forenames>Marios</forenames></author><author><keyname>Monien</keyname><forenames>Burkhard</forenames></author><author><keyname>Papadopoulou</keyname><forenames>Vicky</forenames></author></authors><title>How Many Attackers Can Selfish Defenders Catch?</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a distributed system with {\it attacks} and {\it defenses,} both {\it
attackers} and {\it defenders} are self-interested entities. We assume a {\it
reward-sharing} scheme among {\it interdependent} defenders; each defender
wishes to (locally) maximize her own total {\it fair share} to the attackers
extinguished due to her involvement (and possibly due to those of others). What
is the {\em maximum} amount of protection achievable by a number of such
defenders against a number of attackers while the system is in a {\it Nash
equilibrium}? As a measure of system protection, we adopt the {\it
Defense-Ratio} \cite{MPPS05a}, which provides the expected (inverse) proportion
of attackers caught by the defenders. In a {\it Defense-Optimal} Nash
equilibrium, the Defense-Ratio is optimized.
  We discover that the possibility of optimizing the Defense-Ratio (in a Nash
equilibrium) depends in a subtle way on how the number of defenders compares to
two natural graph-theoretic thresholds we identify. In this vein, we obtain,
through a combinatorial analysis of Nash equilibria, a collection of trade-off
results:
  - When the number of defenders is either sufficiently small or sufficiently
large, there are cases where the Defense-Ratio can be optimized. The
optimization problem is computationally tractable for a large number of
defenders; the problem becomes ${\cal NP}$-complete for a small number of
defenders and the intractability is inherited from a previously unconsidered
combinatorial problem in {\em Fractional Graph Theory}.
  - Perhaps paradoxically, there is a middle range of values for the number of
defenders where optimizing the Defense-Ratio is never possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4235</identifier>
 <datestamp>2013-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4235</id><created>2008-12-22</created><updated>2010-01-11</updated><authors><author><keyname>Dinuzzo</keyname><forenames>Francesco</forenames></author><author><keyname>Pillonetto</keyname><forenames>Gianluigi</forenames></author><author><keyname>De Nicolao</keyname><forenames>Giuseppe</forenames></author></authors><title>Client-server multi-task learning from distributed datasets</title><categories>cs.LG cs.AI</categories><doi>10.1109/TNN.2010.2095882</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A client-server architecture to simultaneously solve multiple learning tasks
from distributed datasets is described. In such architecture, each client is
associated with an individual learning task and the associated dataset of
examples. The goal of the architecture is to perform information fusion from
multiple datasets while preserving privacy of individual data. The role of the
server is to collect data in real-time from the clients and codify the
information in a common database. The information coded in this database can be
used by all the clients to solve their individual learning task, so that each
client can exploit the informative content of all the datasets without actually
having access to private data of others. The proposed algorithmic framework,
based on regularization theory and kernel methods, uses a suitable class of
mixed effect kernels. The new method is illustrated through a simulated music
recommendation system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4279</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4279</id><created>2008-12-22</created><updated>2010-04-22</updated><authors><author><keyname>Stein</keyname><forenames>Noah D.</forenames></author><author><keyname>Parrilo</keyname><forenames>Pablo A.</forenames></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames></author></authors><title>Correlated Equilibria in Continuous Games: Characterization and
  Computation</title><categories>cs.GT</categories><comments>Games and Economic Behavior, In Press, Accepted Manuscript, Available
  online 16 April 2010</comments><report-no>LIDS Technical Report 2805</report-no><journal-ref>Games and Economic Behavior, Vol. 71, No. 2, March 2011, Pages
  436-455</journal-ref><doi>10.1016/j.geb.2010.04.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present several new characterizations of correlated equilibria in games
with continuous utility functions. These have the advantage of being more
computationally and analytically tractable than the standard definition in
terms of departure functions. We use these characterizations to construct
effective algorithms for approximating a single correlated equilibrium or the
entire set of correlated equilibria of a game with polynomial utility
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4293</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4293</id><created>2008-12-22</created><updated>2010-05-11</updated><authors><author><keyname>Boutsidis</keyname><forenames>Christos</forenames></author><author><keyname>Mahoney</keyname><forenames>Michael W.</forenames></author><author><keyname>Drineas</keyname><forenames>Petros</forenames></author></authors><title>An Improved Approximation Algorithm for the Column Subset Selection
  Problem</title><categories>cs.DS</categories><comments>17 pages; corrected a bug in the spectral norm bound of the previous
  version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of selecting the best subset of exactly $k$ columns
from an $m \times n$ matrix $A$. We present and analyze a novel two-stage
algorithm that runs in $O(\min\{mn^2,m^2n\})$ time and returns as output an $m
\times k$ matrix $C$ consisting of exactly $k$ columns of $A$. In the first
(randomized) stage, the algorithm randomly selects $\Theta(k \log k)$ columns
according to a judiciously-chosen probability distribution that depends on
information in the top-$k$ right singular subspace of $A$. In the second
(deterministic) stage, the algorithm applies a deterministic column-selection
procedure to select and return exactly $k$ columns from the set of columns
selected in the first stage. Let $C$ be the $m \times k$ matrix containing
those $k$ columns, let $P_C$ denote the projection matrix onto the span of
those columns, and let $A_k$ denote the best rank-$k$ approximation to the
matrix $A$. Then, we prove that, with probability at least 0.8, $$ \FNorm{A -
P_CA} \leq \Theta(k \log^{1/2} k) \FNorm{A-A_k}. $$ This Frobenius norm bound
is only a factor of $\sqrt{k \log k}$ worse than the best previously existing
existential result and is roughly $O(\sqrt{k!})$ better than the best previous
algorithmic result for the Frobenius norm version of this Column Subset
Selection Problem (CSSP). We also prove that, with probability at least 0.8, $$
\TNorm{A - P_CA} \leq \Theta(k \log^{1/2} k)\TNorm{A-A_k} +
\Theta(k^{3/4}\log^{1/4}k)\FNorm{A-A_k}. $$ This spectral norm bound is not
directly comparable to the best previously existing bounds for the spectral
norm version of this CSSP. Our bound depends on $\FNorm{A-A_k}$, whereas
previous results depend on $\sqrt{n-k}\TNorm{A-A_k}$; if these two quantities
are comparable, then our bound is asymptotically worse by a $(k \log k)^{1/4}$
factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4296</identifier>
 <datestamp>2008-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4296</id><created>2008-12-22</created><authors><author><keyname>Anastasiadis</keyname><forenames>A. D.</forenames></author><author><keyname>de Albuquerque</keyname><forenames>Marcelo P.</forenames></author><author><keyname>de Albuquerque</keyname><forenames>Marcio P.</forenames></author><author><keyname>Mussi</keyname><forenames>Diogo B.</forenames></author></authors><title>Tsallis $q$-exponential describes the distribution of scientific
  citations - A new characterization of the impact</title><categories>cs.DL physics.data-an</categories><comments>13 pages including 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we have studied the research activity for countries of Europe,
Latin America and Africa for all sciences between 1945 and November 2008. All
the data are captured from the Web of Science database during this period. The
analysis of the experimental data shows that, within a nonextensive
thermostatistical formalism, the Tsallis \emph{q}-exponential distribution
$N(c)$ satisfactorily describes Institute of Scientific Information citations.
The data which are examined in the present survey can be fitted successfully as
a first approach by applying a {\it single} curve (namely, $N(c) \propto
1/[1+(q-1) c/T]^{\frac{1}{q-1}}$ with $q\simeq 4/3$ for {\it all} the available
citations $c$, $T$ being an &quot;effective temperature&quot;. The present analysis
ultimately suggests that the phenomenon might essentially be {\it one and the
same} along the {\it entire} range of the citation number. Finally, this
manuscript provides a new ranking index, via the &quot;effective temperature&quot; $T$,
for the impact level of the research activity in these countries, taking into
account the number of the publications and their citations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4322</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4322</id><created>2008-12-22</created><authors><author><keyname>Cibulka</keyname><forenames>Josef</forenames></author><author><keyname>Kyn&#x10d;l</keyname><forenames>Jan</forenames></author><author><keyname>M&#xe9;sz&#xe1;ros</keyname><forenames>Viola</forenames></author><author><keyname>Stola&#x159;</keyname><forenames>Rudolf</forenames></author><author><keyname>Valtr</keyname><forenames>Pavel</forenames></author></authors><title>Solution of Peter Winkler's Pizza Problem</title><categories>cs.DM</categories><comments>29 pages, 14 figures</comments><acm-class>G.2.1</acm-class><journal-ref>In: Fete of Combinatorics and Computer Science, Bolyai Society
  Mathematical Studies, vol. 20, pp. 63-93, Springer, 2010</journal-ref><doi>10.1007/978-3-642-13580-4_4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bob cuts a pizza into slices of not necessarily equal size and shares it with
Alice by alternately taking turns. One slice is taken in each turn. The first
turn is Alice's. She may choose any of the slices. In all other turns only
those slices can be chosen that have a neighbor slice already eaten. We prove a
conjecture of Peter Winkler by showing that Alice has a strategy for obtaining
4/9 of the pizza. This is best possible, that is, there is a cutting and a
strategy for Bob to get 5/9 of the pizza. We also give a characterization of
Alice's best possible gain depending on the number of slices. For a given
cutting of the pizza, we describe a linear time algorithm that computes Alice's
strategy gaining at least 4/9 of the pizza and another algorithm that computes
the optimal strategy for both players in any possible position of the game in
quadratic time. We distinguish two types of turns, shifts and jumps. We prove
that Alice can gain 4/9, 7/16 and 1/3 of the pizza if she is allowed to make at
most two jumps, at most one jump and no jump, respectively, and the three
constants are the best possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4329</identifier>
 <datestamp>2008-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4329</id><created>2008-12-22</created><authors><author><keyname>Zhu</keyname><forenames>Guohun</forenames></author></authors><title>Some sufficient conditions on Hamiltonian digraph</title><categories>cs.DM</categories><comments>7 pages, the main result did during 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Z-mapping graph is a balanced bipartite graph $G$ of a digraph $D$ by split
each vertex of $D$ into a pair of vertices of $G$. Based on the property of the
$G$, it is proved that if $D$ is strong connected and $G$ is Hamiltonian, then
$D$ is Hamiltonian. It is also proved if $D$ is Hamiltonian, then $G$ contains
at least a perfect matching. Thus some existence sufficient conditions for
Hamiltonian digraph and Hamiltonian graph are proved to be equivalent, and two
sufficient conditions of disjoint Hamiltonian digraph are given in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4332</identifier>
 <datestamp>2009-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4332</id><created>2008-12-22</created><authors><author><keyname>Rafols</keyname><forenames>Ismael</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Content-based and Algorithmic Classifications of Journals: Perspectives
  on the Dynamics of Scientific Communication and Indexer Effects</title><categories>physics.data-an cs.DL cs.IR physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aggregated journal-journal citation matrix -based on the Journal Citation
Reports (JCR) of the Science Citation Index- can be decomposed by indexers
and/or algorithmically. In this study, we test the results of two recently
available algorithms for the decomposition of large matrices against two
content-based classifications of journals: the ISI Subject Categories and the
field/subfield classification of Glaenzel &amp; Schubert (2003). The content-based
schemes allow for the attribution of more than a single category to a journal,
whereas the algorithms maximize the ratio of within-category citations over
between-category citations in the aggregated category-category citation matrix.
By adding categories, indexers generate between-category citations, which may
enrich the database, for example, in the case of inter-disciplinary
developments. The consequent indexer effects are significant in sparse areas of
the matrix more than in denser ones. Algorithmic decompositions, on the other
hand, are more heavily skewed towards a relatively small number of categories,
while this is deliberately counter-acted upon in the case of content-based
classifications. Because of the indexer effects, science policy studies and the
sociology of science should be careful when using content-based
classifications, which are made for bibliographic disclosure, and not for the
purpose of analyzing latent structures in scientific communications. Despite
the large differences among them, the four classification schemes enable us to
generate surprisingly similar maps of science at the global level. Erroneous
classifications are cancelled as noise at the aggregate level, but may disturb
the evaluation locally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4334</identifier>
 <datestamp>2008-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4334</id><created>2008-12-22</created><authors><author><keyname>Chua</keyname><forenames>Wee Seng</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Guan</keyname><forenames>Yong Liang</forenames></author><author><keyname>Chin</keyname><forenames>Francois</forenames></author></authors><title>Multi-User SISO Precoding based on Generalized Multi-Unitary
  Decomposition for Single-carrier Transmission in Frequency Selective Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose to exploit the richly scattered multi-path nature
of a frequency selective channel to provide additional degrees of freedom for
desigining effective precoding schemes for multi-user communications. We design
the precoding matrix for multi-user communications based on the Generalized
Multi-Unitary Decomposition (GMUD), where the channel matrix H is transformed
into P_i*R_r*Q_i^H. An advantage of GMUD is that multiple pairs of unitary
matrices P_i and Q_i can be obtained with one single R_r. Since the column of
Q_i can be used as the transmission beam of a particular user, multiple
solutions of Q_i provide a large selection of transmission beams, which can be
exploited to achieve high degrees of orthogonality between the multipaths, as
well as between the interfering users. Hence the proposed precoding technique
based on GMUD achieves better performance than precoding based on singular
value decomposition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4346</identifier>
 <datestamp>2013-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4346</id><created>2008-12-23</created><authors><author><keyname>Kaminski</keyname><forenames>Marcin</forenames></author><author><keyname>Medvedev</keyname><forenames>Paul</forenames></author><author><keyname>Milanic</keyname><forenames>Martin</forenames></author></authors><title>The Plane-Width of Graphs</title><categories>cs.DM</categories><journal-ref>Journal of Graph Theory 68 (2011) 229-245</journal-ref><doi>10.1002/jgt.20554</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Map vertices of a graph to (not necessarily distinct) points of the plane so
that two adjacent vertices are mapped at least a unit distance apart. The
plane-width of a graph is the minimum diameter of the image of the vertex set
over all such mappings. We establish a relation between the plane-width of a
graph and its chromatic number, and connect it to other well-known areas,
including the circular chromatic number and the problem of packing unit discs
in the plane. We also investigate how plane-width behaves under various
operations, such as homomorphism, disjoint union, complement, and the Cartesian
product.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4360</identifier>
 <datestamp>2009-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4360</id><created>2008-12-23</created><updated>2009-04-15</updated><authors><author><keyname>Schmidhuber</keyname><forenames>Juergen</forenames></author></authors><title>Driven by Compression Progress: A Simple Principle Explains Essential
  Aspects of Subjective Beauty, Novelty, Surprise, Interestingness, Attention,
  Curiosity, Creativity, Art, Science, Music, Jokes</title><categories>cs.AI cs.NE</categories><comments>35 pages, 3 figures, based on KES 2008 keynote and ALT 2007 / DS 2007
  joint invited lecture</comments><journal-ref>Short version: J. Schmidhuber. Simple Algorithmic Theory of
  Subjective Beauty, Novelty, Surprise, Interestingness, Attention, Curiosity,
  Creativity, Art, Science, Music, Jokes. Journal of SICE 48(1), 21-32, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I argue that data becomes temporarily interesting by itself to some
self-improving, but computationally limited, subjective observer once he learns
to predict or compress the data in a better way, thus making it subjectively
simpler and more beautiful. Curiosity is the desire to create or discover more
non-random, non-arbitrary, regular data that is novel and surprising not in the
traditional sense of Boltzmann and Shannon but in the sense that it allows for
compression progress because its regularity was not yet known. This drive
maximizes interestingness, the first derivative of subjective beauty or
compressibility, that is, the steepness of the learning curve. It motivates
exploring infants, pure mathematicians, composers, artists, dancers, comedians,
yourself, and (since 1990) artificial systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4367</identifier>
 <datestamp>2008-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4367</id><created>2008-12-23</created><authors><author><keyname>Kovachev</keyname><forenames>Dimiter Stoichkov</forenames></author></authors><title>On Some Classes of Functions and Hypercubes</title><categories>cs.DM cs.CC</categories><comments>8 pages, 3 tables</comments><acm-class>G.2.0</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, some classes of discrete functions of $k$-valued logic are
considered, that depend on sets of their variables in a particular way.
Obtained results allow to &quot;construct&quot; these functions and to present them in
their tabular, analytical or matrix form, that is, as hypercubes, and in
particular Latin hypercubes. Results connected with identifying of variables of
some classes of functions are obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4442</identifier>
 <datestamp>2008-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4442</id><created>2008-12-23</created><authors><author><keyname>Chuzhoy</keyname><forenames>Julia</forenames></author><author><keyname>Khanna</keyname><forenames>Sanjeev</forenames></author></authors><title>An $O(k^{3} log n)$-Approximation Algorithm for Vertex-Connectivity
  Survivable Network Design</title><categories>cs.DS</categories><comments>8 pages</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Survivable Network Design problem (SNDP), we are given an undirected
graph $G(V,E)$ with costs on edges, along with a connectivity requirement
$r(u,v)$ for each pair $u,v$ of vertices. The goal is to find a minimum-cost
subset $E^*$ of edges, that satisfies the given set of pairwise connectivity
requirements. In the edge-connectivity version we need to ensure that there are
$r(u,v)$ edge-disjoint paths for every pair $u, v$ of vertices, while in the
vertex-connectivity version the paths are required to be vertex-disjoint. The
edge-connectivity version of SNDP is known to have a 2-approximation. However,
no non-trivial approximation algorithm has been known so far for the vertex
version of SNDP, except for special cases of the problem. We present an
extremely simple algorithm to achieve an $O(k^3 \log n)$-approximation for this
problem, where $k$ denotes the maximum connectivity requirement, and $n$
denotes the number of vertices. We also give a simple proof of the recently
discovered $O(k^2 \log n)$-approximation result for the single-source version
of vertex-connectivity SNDP. We note that in both cases, our analysis in fact
yields slightly better guarantees in that the $\log n$ term in the
approximation guarantee can be replaced with a $\log \tau$ term where $\tau$
denotes the number of distinct vertices that participate in one or more pairs
with a positive connectivity requirement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4446</identifier>
 <datestamp>2008-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4446</id><created>2008-12-23</created><authors><author><keyname>Turney</keyname><forenames>Peter D.</forenames><affiliation>National Research Council of Canada</affiliation></author></authors><title>The Latent Relation Mapping Engine: Algorithm and Experiments</title><categories>cs.CL cs.AI cs.LG</categories><comments>related work available at http://purl.org/peter.turney/</comments><report-no>NRC-50738</report-no><acm-class>H.3.1, I.2.6, I.2.7</acm-class><journal-ref>Journal of Artificial Intelligence Research, (2008), 33, 615-655</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many AI researchers and cognitive scientists have argued that analogy is the
core of cognition. The most influential work on computational modeling of
analogy-making is Structure Mapping Theory (SMT) and its implementation in the
Structure Mapping Engine (SME). A limitation of SME is the requirement for
complex hand-coded representations. We introduce the Latent Relation Mapping
Engine (LRME), which combines ideas from SME and Latent Relational Analysis
(LRA) in order to remove the requirement for hand-coded representations. LRME
builds analogical mappings between lists of words, using a large corpus of raw
text to automatically discover the semantic relations among the words. We
evaluate LRME on a set of twenty analogical mapping problems, ten based on
scientific analogies and ten based on common metaphors. LRME achieves
human-level performance on the twenty problems. We compare LRME with a variety
of alternative approaches and find that they are not able to reach the same
level of performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4460</identifier>
 <datestamp>2008-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4460</id><created>2008-12-23</created><authors><author><keyname>Diaz-Aviles</keyname><forenames>Ernesto</forenames></author><author><keyname>Schmidt-Thieme</keyname><forenames>Lars</forenames></author><author><keyname>Ziegler</keyname><forenames>Cai-Nicolas</forenames></author></authors><title>Emergence of Spontaneous Order Through Neighborhood Formation in
  Peer-to-Peer Recommender Systems</title><categories>cs.AI cs.IR cs.MA</categories><comments>WWW '05 International Workshop on Innovations in Web Infrastructure
  (IWI '05) May 10, 2005, Chiba, Japan</comments><acm-class>C.2.4; H.3.3</acm-class><journal-ref>WWW '05 International Workshop on Innovations in Web
  Infrastructure (IWI '05) May 10, 2005, Chiba, Japan</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The advent of the Semantic Web necessitates paradigm shifts away from
centralized client/server architectures towards decentralization and
peer-to-peer computation, making the existence of central authorities
superfluous and even impossible. At the same time, recommender systems are
gaining considerable impact in e-commerce, providing people with
recommendations that are personalized and tailored to their very needs. These
recommender systems have traditionally been deployed with stark centralized
scenarios in mind, operating in closed communities detached from their host
network's outer perimeter. We aim at marrying these two worlds, i.e.,
decentralized peer-to-peer computing and recommender systems, in one
agent-based framework. Our architecture features an epidemic-style protocol
maintaining neighborhoods of like-minded peers in a robust, selforganizing
fashion. In order to demonstrate our architecture's ability to retain
scalability, robustness and to allow for convergence towards high-quality
recommendations, we conduct offline experiments on top of the popular MovieLens
dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4461</identifier>
 <datestamp>2008-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4461</id><created>2008-12-23</created><authors><author><keyname>Stewart</keyname><forenames>Avare</forenames></author><author><keyname>Diaz-Aviles</keyname><forenames>Ernesto</forenames></author><author><keyname>Nejdl</keyname><forenames>Wolfgang</forenames></author></authors><title>Mining User Profiles to Support Structure and Explanation in Open Social
  Networking</title><categories>cs.IR</categories><comments>International Workshop on Interacting with Multimedia Content in the
  Social Semantic Web (IMC-SSW 2008). Collocated with the 3rd International
  Conference on Semantic and Digital Media Technologies (SAMT 2008), Koblenz,
  Germany, Dec. 03 2008</comments><acm-class>H.3.3; H.3.5</acm-class><journal-ref>In Proceedings of the International Workshop on Interacting with
  Multimedia Content in the Social Semantic Web (IMC-SSW'08), pages 21-30.
  Koblenz, Germany, Dec. 3, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The proliferation of media sharing and social networking websites has brought
with it vast collections of site-specific user generated content. The result is
a Social Networking Divide in which the concepts and structure common across
different sites are hidden. The knowledge and structures from one social site
are not adequately exploited to provide new information and resources to the
same or different users in comparable social sites. For music bloggers, this
latent structure, forces bloggers to select sub-optimal blogrolls. However, by
integrating the social activities of music bloggers and listeners, we are able
to overcome this limitation: improving the quality of the blogroll
neighborhoods, in terms of similarity, by 85 percent when using tracks and by
120 percent when integrating tags from another site.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4470</identifier>
 <datestamp>2009-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4470</id><created>2008-12-23</created><authors><author><keyname>Currie</keyname><forenames>James</forenames></author><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author></authors><title>There are k-uniform cubefree binary morphisms for all k &gt;= 0</title><categories>math.CO cs.FL</categories><comments>5 pages</comments><msc-class>68R15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A word is cubefree if it contains no non-empty subword of the form xxx. A
morphism h : Sigma^* -&gt; Sigma^* is k-uniform if h(a) has length k for all a in
Sigma. A morphism is cubefree if it maps cubefree words to cubefree words. We
show that for all k &gt;= 0 there exists a k-uniform cubefree binary morphism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4471</identifier>
 <datestamp>2009-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4471</id><created>2008-12-23</created><updated>2009-09-25</updated><authors><author><keyname>Liu</keyname><forenames>Chun-Hung</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffery G.</forenames></author></authors><title>Diversity-Multiplexing Tradeoff of Network Coding with Bidirectional
  Random Relaying</title><categories>cs.IT math.IT</categories><comments>7 pages, 4 figures, to appear in the Proceedings of Allerton
  Conference on Communication, Control and Computing, September 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a diversity-multiplexing tradeoff (DMT) over a
bidirectional random relay set in a wireless network where the distribution of
all nodes is a stationary Poisson point process. This is a nontrivial extension
of the DMT because it requires consideration of the cooperation (or lack
thereof) of relay nodes, the traffic pattern and the time allocation between
the forward and reverse traffic directions. We then use this tradeoff to
compare the DMTs of traditional time-division multihop (TDMH) and network
coding (NC). Our main results are the derivations of the DMT for both TDMH and
NC. This shows, surprisingly, that if relay nodes collaborate NC does not
always have a better DMT than TDMH since it is difficult to simultaneously
achieve bidirectional transmit diversity for both source nodes. In fact, for
certain traffic patterns NC can have a worse DMT due to suboptimal time
allocation between the forward and reverse transmission directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4485</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4485</id><created>2008-12-24</created><authors><author><keyname>Mohaisen</keyname><forenames>Abedelaziz</forenames></author></authors><title>A computationally-efficient construction for the matrix-based key
  distribution in sensor network</title><categories>cs.CR</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a variant for the symmetric matrix-based key
distribution in sensor network introduced by Du et al. Our slight modification
shows that the usage of specific structures for the public matrix instead of
fully random matrix with elements in $\mathbb{Z}_q$ can reduce the computation
overhead for generating the public key information and the key itself. An
intensive analysis followed by modified scheme demonstrates the value of our
contribution in relation with the current work and show the equivalence of the
security
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4487</identifier>
 <datestamp>2011-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4487</id><created>2008-12-24</created><updated>2011-05-13</updated><authors><author><keyname>Wang</keyname><forenames>Zilong</forenames></author><author><keyname>Gong</keyname><forenames>Guang</forenames></author></authors><title>New Sequences Design from Weil Representation with Low Two-Dimensional
  Correlation in Both Time and Phase Shifts</title><categories>cs.IT cs.DM math.IT math.RT</categories><comments>23 pages, accepted by IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a given prime $p$, a new construction of families of the complex valued
sequences of period $p$ with efficient implementation is given by applying both
multiplicative characters and additive characters of finite field
$\mathbb{F}_p$. Such a signal set consists of $p^2(p-2)$ time-shift distinct
sequences, the magnitude of the two-dimensional autocorrelation function (i.e.,
the ambiguity function) in both time and phase of each sequence is upper
bounded by $2\sqrt{p}$ at any shift not equal to $(0, 0)$, and the magnitude of
the ambiguity function of any pair of phase-shift distinct sequences is upper
bounded by $4\sqrt{p}$. Furthermore, the magnitude of their Fourier transform
spectrum is less than or equal to 2. A proof is given through finding a simple
elementary construction for the sequences constructed from the Weil
representation by Gurevich, Hadani and Sochen. An open problem for directly
establishing these assertions without involving the Weil representation is
addressed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4514</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4514</id><created>2008-12-24</created><authors><author><keyname>Li</keyname><forenames>Zhuo</forenames></author><author><keyname>Xing</keyname><forenames>Li-Juan</forenames></author><author><keyname>Wang</keyname><forenames>Xin-Mei</forenames></author></authors><title>Quantum generalized Reed-Solomon codes: Unified framework for quantum
  MDS codes</title><categories>quant-ph cs.IT math.IT</categories><comments>9 pages, no figures</comments><journal-ref>Phys. Rev. A, 2008, 77, 012308</journal-ref><doi>10.1103/PhysRevA.77.012308</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct a new family of quantum MDS codes from classical generalized
Reed-Solomon codes and derive the necessary and sufficient condition under
which these quantum codes exist. We also give code bounds and show how to
construct them analytically. We find that existing quantum MDS codes can be
unified under these codes in the sense that when a quantum MDS code exists,
then a quantum code of this type with the same parameters also exists. Thus as
far as is known at present, they are the most important family of quantum MDS
codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4523</identifier>
 <datestamp>2008-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4523</id><created>2008-12-24</created><authors><author><keyname>Bagdasaryan</keyname><forenames>Armen</forenames></author></authors><title>System Theoretic Viewpoint on Modeling of Complex Systems: Design,
  Synthesis, Simulation, and Control</title><categories>cs.CE</categories><comments>10 pages; Contribution to the Proceedings of the 7th WSEAS
  International Conference on Computational Intelligence, Man-Machine Systems,
  and Cybernetics, Cairo, Egypt, December 29-31, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the basic features of complex dynamic and control systems,
including systems having hierarchical structure. Special attention is paid to
the problems of design and synthesis of complex systems and control models, and
to the development of simulation techniques and systems. A model of complex
system is proposed and briefly analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4542</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4542</id><created>2008-12-24</created><updated>2009-09-15</updated><authors><author><keyname>Panaretos</keyname><forenames>John</forenames></author><author><keyname>Malesios</keyname><forenames>Chrisovaladis</forenames></author></authors><title>Assessing scientific research performance and impact with single indices</title><categories>cs.IR physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a comprehensive and critical review of the h-index and its most
important modifications proposed in the literature, as well as of other similar
indicators measuring research output and impact. Extensions of some of these
indices are presented and illustrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4547</identifier>
 <datestamp>2009-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4547</id><created>2008-12-24</created><updated>2009-03-13</updated><authors><author><keyname>Boutsidis</keyname><forenames>Christos</forenames></author><author><keyname>Drineas</keyname><forenames>Petros</forenames></author></authors><title>Random Projections for the Nonnegative Least-Squares Problem</title><categories>cs.DS</categories><comments>to appear in Linear Algebra and its Applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constrained least-squares regression problems, such as the Nonnegative Least
Squares (NNLS) problem, where the variables are restricted to take only
nonnegative values, often arise in applications. Motivated by the recent
development of the fast Johnson-Lindestrauss transform, we present a fast
random projection type approximation algorithm for the NNLS problem. Our
algorithm employs a randomized Hadamard transform to construct a much smaller
NNLS problem and solves this smaller problem using a standard NNLS solver. We
prove that our approach finds a nonnegative solution vector that, with high
probability, is close to the optimum nonnegative solution in a relative error
approximation sense. We experimentally evaluate our approach on a large
collection of term-document data and verify that it does offer considerable
speedups without a significant loss in accuracy. Our analysis is based on a
novel random projection type result that might be of independent interest. In
particular, given a tall and thin matrix $\Phi \in \mathbb{R}^{n \times d}$ ($n
\gg d$) and a vector $y \in \mathbb{R}^d$, we prove that the Euclidean length
of $\Phi y$ can be estimated very accurately by the Euclidean length of
$\tilde{\Phi}y$, where $\tilde{\Phi}$ consists of a small subset of
(appropriately rescaled) rows of $\Phi$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4580</identifier>
 <datestamp>2009-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4580</id><created>2008-12-24</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Feature Markov Decision Processes</title><categories>cs.AI cs.IT cs.LG math.IT</categories><comments>7 pages</comments><journal-ref>Proc. 2nd Conf. on Artificial General Intelligence (AGI 2009)
  pages 61-66</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  General purpose intelligent learning agents cycle through (complex,non-MDP)
sequences of observations, actions, and rewards. On the other hand,
reinforcement learning is well-developed for small finite state Markov Decision
Processes (MDPs). So far it is an art performed by human designers to extract
the right state representation out of the bare observations, i.e. to reduce the
agent setup to the MDP framework. Before we can think of mechanizing this
search for suitable MDPs, we need a formal objective criterion. The main
contribution of this article is to develop such a criterion. I also integrate
the various parts into one learning algorithm. Extensions to more realistic
dynamic Bayesian networks are developed in a companion article.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4581</identifier>
 <datestamp>2009-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4581</id><created>2008-12-24</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Feature Dynamic Bayesian Networks</title><categories>cs.AI cs.IT cs.LG math.IT</categories><comments>7 pages</comments><journal-ref>Proc. 2nd Conf. on Artificial General Intelligence (AGI 2009)
  pages 67-73</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feature Markov Decision Processes (PhiMDPs) are well-suited for learning
agents in general environments. Nevertheless, unstructured (Phi)MDPs are
limited to relatively simple environments. Structured MDPs like Dynamic
Bayesian Networks (DBNs) are used for large-scale real-world problems. In this
article I extend PhiMDP to PhiDBN. The primary contribution is to derive a cost
criterion that allows to automatically extract the most relevant features from
the environment, leading to the &quot;best&quot; DBN representation. I discuss all
building blocks required for a complete general learning algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4614</identifier>
 <datestamp>2009-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4614</id><created>2008-12-25</created><updated>2009-05-28</updated><authors><author><keyname>Zizzi</keyname><forenames>Paola</forenames></author></authors><title>I, Quantum Robot: Quantum Mind control on a Quantum Computer</title><categories>quant-ph cs.AI cs.LO cs.RO</categories><comments>13 pages; revised version for publication, references added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The logic which describes quantum robots is not orthodox quantum logic, but a
deductive calculus which reproduces the quantum tasks (computational processes,
and actions) taking into account quantum superposition and quantum
entanglement. A way toward the realization of intelligent quantum robots is to
adopt a quantum metalanguage to control quantum robots. A physical
implementation of a quantum metalanguage might be the use of coherent states in
brain signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4627</identifier>
 <datestamp>2009-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4627</id><created>2008-12-25</created><updated>2009-06-24</updated><authors><author><keyname>Baron</keyname><forenames>Dror</forenames><affiliation>Technion - Israel Institute of Technology</affiliation></author><author><keyname>Sarvotham</keyname><forenames>Shriram</forenames><affiliation>Halliburton</affiliation></author><author><keyname>Baraniuk</keyname><forenames>Richard G.</forenames><affiliation>Rice University</affiliation></author></authors><title>Bayesian Compressive Sensing via Belief Propagation</title><categories>cs.IT math.IT</categories><comments>25 pages with 8 figures; to appear in IEEE Transactions on Signal
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressive sensing (CS) is an emerging field based on the revelation that a
small collection of linear projections of a sparse signal contains enough
information for stable, sub-Nyquist signal acquisition. When a statistical
characterization of the signal is available, Bayesian inference can complement
conventional CS methods based on linear programming or greedy algorithms. We
perform approximate Bayesian inference using belief propagation (BP) decoding,
which represents the CS encoding matrix as a graphical model. Fast computation
is obtained by reducing the size of the graphical model with sparse encoding
matrices. To decode a length-N signal containing K large coefficients, our
CS-BP decoding algorithm uses O(Klog(N)) measurements and O(Nlog^2(N))
computation. Finally, although we focus on a two-state mixture Gaussian model,
CS-BP is easily adapted to other signal models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4642</identifier>
 <datestamp>2009-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4642</id><created>2008-12-26</created><updated>2009-01-08</updated><authors><author><keyname>Tajima</keyname><forenames>M.</forenames></author><author><keyname>Okino</keyname><forenames>K.</forenames></author><author><keyname>Miyagoshi</keyname><forenames>T.</forenames></author></authors><title>Error-Trellis State Complexity of LDPC Convolutional Codes Based on
  Circulant Matrices</title><categories>cs.IT math.IT</categories><comments>5 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let H(D) be the parity-check matrix of an LDPC convolutional code
corresponding to the parity-check matrix H of a QC code obtained using the
method of Tanner et al. We see that the entries in H(D) are all monomials and
several rows (columns) have monomial factors. Let us cyclically shift the rows
of H. Then the parity-check matrix H'(D) corresponding to the modified matrix
H' defines another convolutional code. However, its free distance is
lower-bounded by the minimum distance of the original QC code. Also, each row
(column) of H'(D) has a factor different from the one in H(D). We show that the
state-space complexity of the error-trellis associated with H'(D) can be
significantly reduced by controlling the row shifts applied to H with the
error-correction capability being preserved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4646</identifier>
 <datestamp>2008-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4646</id><created>2008-12-26</created><authors><author><keyname>Liu</keyname><forenames>Lian-dong</forenames></author><author><keyname>Xu</keyname><forenames>Ke</forenames></author></authors><title>Time series of Internet AS-level topology graphs: four patterns and one
  model</title><categories>cs.NI</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Researchers have proposed a variety of Internet topology models. However
almost all of them focus on generating one graph based on one single static
source graph. On the other hand, Internet topology is evolving over time
continuously with the addition and deletion of nodes and edges. If a model is
based on all the topologies in the past, instead of one of them, it will be
more accurate and closer to the real world topology. In this paper, we study
the Internet As-level topology time-series from two different sources and find
that both of them obey four same dynamic graph patterns. Then we propose a mode
that can infer the topology in the future based on all the topologies in the
past. Through theoretical and experimental analysis, we prove the topology that
our model generates can match both the static and dynamic graph patterns. In
addition, the parameters in the model are meaningful. Finally, we theoretically
and experimentally prove that these parameters are directly related to some
important graph characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4706</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4706</id><created>2008-12-26</created><updated>2011-08-17</updated><authors><author><keyname>Bus&#xe9;</keyname><forenames>Laurent</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Ch&#xe8;ze</keyname><forenames>Guillaume</forenames><affiliation>IMT</affiliation></author></authors><title>On the total order of reducibility of a pencil of algebraic plane curves</title><categories>math.AC cs.SC math.AG</categories><proxy>ccsd</proxy><journal-ref>Journal of Algebra 341, 1 (2011) 256-278</journal-ref><doi>10.1016/j.jalgebra.2011.06.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the problem of bounding the number of reducible curves in a
pencil of algebraic plane curves is addressed. Unlike most of the previous
related works, each reducible curve of the pencil is here counted with its
appropriate multiplicity. It is proved that this number of reducible curves,
counted with multiplicity, is bounded by d^2-1 where d is the degree of the
pencil. Then, a sharper bound is given by taking into account the Newton's
polygon of the pencil.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4710</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4710</id><created>2008-12-26</created><authors><author><keyname>Rakotondrainibe</keyname><forenames>Lahatra</forenames><affiliation>IETR</affiliation></author><author><keyname>Zaharia</keyname><forenames>Gheorghe</forenames><affiliation>IETR</affiliation></author><author><keyname>Zein</keyname><forenames>Gha&#xef;s El</forenames><affiliation>IETR</affiliation></author><author><keyname>Lostanlen</keyname><forenames>Yves</forenames><affiliation>IETR</affiliation></author></authors><title>Indoor Channel Measurements and Communications System Design at 60 GHz</title><categories>cs.NI</categories><comments>2 pages</comments><proxy>ccsd hal-00348803</proxy><journal-ref>XXIX URSI General Assembly, Chicago : \'Etats-Unis (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a brief overview of several studies concerning the indoor
wireless communications at 60 GHz performed by the IETR. The characterization
and the modeling of the radio propagation channel are based on several
measurement campaigns realized with the channel sounder developed at IETR. Some
typical residential environments were also simulated by ray tracing and
Gaussian Beam Tracking. The obtained results show a good agreement with the
similar experimental results. Currently, the IETR is developing a high data
rate wireless communication system operating at 60 GHz. The single-carrier
architecture of this system is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4727</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4727</id><created>2008-12-27</created><updated>2009-09-30</updated><authors><author><keyname>Tiu</keyname><forenames>Alwen</forenames></author><author><keyname>Momigliano</keyname><forenames>Alberto</forenames></author></authors><title>Induction and Co-induction in Sequent Calculus</title><categories>cs.LO</categories><comments>This is an extended and revised version of an extended abstract which
  appeared in the proceedings of TYPES 2003</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Proof search has been used to specify a wide range of computation systems. In
order to build a framework for reasoning about such specifications, we make use
of a sequent calculus involving induction and co-induction. These proof
principles are based on a proof theoretic (rather than set-theoretic) notion of
definition. Definitions are akin to (stratified) logic programs, where the left
and right rules for defined atoms allow one to view theories as &quot;closed&quot; or
defining fixed points. The use of definitions makes it possible to reason
intensionally about syntax, in particular enforcing free equality via
unification. We add in a consistent way rules for pre and post fixed points,
thus allowing the user to reason inductively and co-inductively about
properties of computational system making full use of higher-order abstract
syntax. Consistency is guaranteed via cut-elimination, where we give the first,
to our knowledge, cut-elimination procedure in the presence of general
inductive and co-inductive definitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4744</identifier>
 <datestamp>2008-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4744</id><created>2008-12-27</created><authors><author><keyname>Gore</keyname><forenames>Ashutosh Deepak</forenames></author></authors><title>On Wireless Link Scheduling and Flow Control</title><categories>cs.NI</categories><comments>Author's Ph.D. Thesis, 213 pages, 64 figures</comments><report-no>EE-PHD-08-007</report-no><acm-class>C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis focuses on link scheduling in wireless mesh networks by taking
into account physical layer characteristics. The assumption made throughout is
that a packet is received successfully only if the Signal to Interference and
Noise Ratio (SINR) at the receiver exceeds the communication threshold. The
thesis also discusses the complementary problem of flow control. (1) We
consider various problems on centralized link scheduling in Spatial Time
Division Multiple Access (STDMA) wireless mesh networks. We motivate the use of
spatial reuse as performance metric and provide an explicit characterization of
spatial reuse. We propose link scheduling algorithms based on certain graph
models (communication graph, SINR graph) of the network. Our algorithms achieve
higher spatial reuse than that of existing algorithms, with only a slight
increase in computational complexity. (2) We investigate random access
algorithms in wireless networks. We assume that the receiver is capable of
power-based capture and propose a splitting algorithm that varies transmission
powers of users on the basis of quaternary channel feedback. We model the
algorithm dynamics by a Discrete Time Markov Chain and consequently show that
its maximum stable throughput is 0.5518. Our algorithm achieves higher maximum
stable throughput and significantly lower delay than the First Come First Serve
(FCFS) splitting algorithm with uniform transmission power. (3) We consider the
problem of flow control in packet networks from an information-theoretic
perspective. We derive the maximum entropy of a flow which conforms to traffic
constraints imposed by a generalized token bucket regulator (GTBR), by taking
into account the covert information present in randomness of packet lengths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4792</identifier>
 <datestamp>2008-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4792</id><created>2008-12-28</created><authors><author><keyname>Gujar</keyname><forenames>Sujit</forenames></author><author><keyname>Narahari</keyname><forenames>Yadati</forenames></author></authors><title>On Optimal Linear Redistribution of VCG Payments in Assignment of
  Heterogeneous Objects</title><categories>cs.GT</categories><comments>12 pages</comments><acm-class>J.4; I.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are p heterogeneous objects to be assigned to n competing agents (n &gt;
p) each with unit demand. It is required to design a Groves mechanism for this
assignment problem satisfying weak budget balance, individual rationality, and
minimizing the budget imbalance. This calls for designing an appropriate rebate
function. Our main result is an impossibility theorem which rules out linear
rebate functions with non-zero efficiency in heterogeneous object assignment.
Motivated by this theorem, we explore two approaches to get around this
impossibility. In the first approach, we show that linear rebate functions with
non-zero are possible when the valuations for the objects are correlated. In
the second approach, we show that rebate functions with non-zero efficiency are
possible if linearity is relaxed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4798</identifier>
 <datestamp>2009-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4798</id><created>2008-12-28</created><updated>2009-01-05</updated><authors><author><keyname>Trahtman</keyname><forenames>A. N.</forenames></author></authors><title>The Road Coloring for Mapping on k States(withdrawn)</title><categories>cs.DM</categories><comments>withdrawn, the result was known</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\Gamma$ be directed strongly connected finite graph of uniform outdegree
(constant outdegree of any vertex) and let some coloring of edges of $\Gamma$
turn the graph into deterministic complete automaton. Let the word $s$ be a
word in the alphabet of colors (considered also as letters) on the edges of
$\Gamma$ and let $\Gamma s$ be a mapping of vertices $\Gamma$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4803</identifier>
 <datestamp>2008-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4803</id><created>2008-12-28</created><authors><author><keyname>Philosof</keyname><forenames>Tal</forenames></author><author><keyname>Zamir</keyname><forenames>Ram</forenames></author><author><keyname>Erez</keyname><forenames>Uri</forenames></author></authors><title>Technical Report: Achievable Rates for the MAC with Correlated
  Channel-State Information</title><categories>cs.IT math.IT</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we provide an achievable rate region for the discrete
memoryless multiple access channel with correlated state information known
non-causally at the encoders using a random binning technique. This result is a
generalization of the random binning technique used by Gel'fand and Pinsker for
the problem with non-causal channel state information at the encoder in point
to point communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4814</identifier>
 <datestamp>2008-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4814</id><created>2008-12-28</created><authors><author><keyname>Villadsen</keyname><forenames>J&#xf8;rgen</forenames></author></authors><title>Nominalistic Logic (Extended Abstract)</title><categories>cs.LO</categories><comments>3 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nominalistic Logic (NL) is a new presentation of Paul Gilmore's Intensional
Type Theory (ITT) as a sequent calculus together with a succinct nominalization
axiom (N) that permits names of predicates as individuals in certain cases. The
logic has a flexible comprehension axiom, but no extensionality axiom and no
infinity axiom, although axiom N is the key to the derivation of Peano's
postulates for the natural numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4826</identifier>
 <datestamp>2008-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4826</id><created>2008-12-28</created><authors><author><keyname>Gao</keyname><forenames>Long</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Yin</keyname><forenames>Changchuan</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Delay-Throughput Tradeoff for Supportive Two-Tier Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>5 pages, 1 figure, submitted to ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a static wireless network that has two tiers with different
priorities: a primary tier vs. a secondary tier. The primary tier consists of
randomly distributed legacy nodes of density $n$, which have an absolute
priority to access the spectrum. The secondary tier consists of randomly
distributed cognitive nodes of density $m=n^\beta$ with $\beta\geq 2$, which
can only access the spectrum opportunistically to limit the interference to the
primary tier. By allowing the secondary tier to route the packets for the
primary tier, we show that the primary tier can achieve a throughput scaling of
$\lambda_p(n)=\Theta(1/\log n)$ per node and a delay-throughput tradeoff of
$D_p(n)=\Theta(\sqrt{n^\beta\log n}\lambda_p(n))$ for $\lambda_p(n)=O(1/\log
n)$, while the secondary tier still achieves the same optimal delay-throughput
tradeoff as a stand-alone network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4835</identifier>
 <datestamp>2011-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4835</id><created>2008-12-28</created><authors><author><keyname>Boyer</keyname><forenames>Michel</forenames></author><author><keyname>Gelles</keyname><forenames>Ran</forenames></author><author><keyname>Kenigsberg</keyname><forenames>Dan</forenames></author><author><keyname>Mor</keyname><forenames>Tal</forenames></author></authors><title>Semi-Quantum Key Distribution</title><categories>quant-ph cs.CR</categories><comments>13 pages, 2 figures</comments><doi>10.1103/PhysRevA.79.032341</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secure key distribution among two remote parties is impossible when both are
classical, unless some unproven (and arguably unrealistic)
computation-complexity assumptions are made, such as the difficulty of
factorizing large numbers. On the other hand, a secure key distribution is
possible when both parties are quantum. What is possible when only one party
(Alice) is quantum, yet the other (Bob) has only classical capabilities?
Recently, a semi-quantum key distribution protocol was presented (Boyer,
Kenigsberg and Mor, Physical Review Letters, 2007), in which one of the parties
(Bob) is classical, and yet, the protocol is proven to be completely robust
against an eavesdropping attempt.
  Here we extend that result much further. We present two protocols with this
constraint, and prove their robustness against attacks: we prove that any
attempt of an adversary to obtain information (and even a tiny amount of
information) necessarily induces some errors that the legitimate parties could
notice. One protocol presented here is identical to the one referred to above,
however, its robustness is proven here in a much more general scenario. The
other protocol is very different as it is based on randomization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4848</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4848</id><created>2008-12-28</created><updated>2009-03-23</updated><authors><author><keyname>Bauland</keyname><forenames>Michael</forenames></author><author><keyname>Schneider</keyname><forenames>Thomas</forenames></author><author><keyname>Schnoor</keyname><forenames>Henning</forenames></author><author><keyname>Schnoor</keyname><forenames>Ilka</forenames></author><author><keyname>Vollmer</keyname><forenames>Heribert</forenames></author></authors><title>The Complexity of Generalized Satisfiability for Linear Temporal Logic</title><categories>cs.LO</categories><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 1 (January
  26, 2009) lmcs:1158</journal-ref><doi>10.2168/LMCS-5(1:1)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a seminal paper from 1985, Sistla and Clarke showed that satisfiability
for Linear Temporal Logic (LTL) is either NP-complete or PSPACE-complete,
depending on the set of temporal operators used. If, in contrast, the set of
propositional operators is restricted, the complexity may decrease. This paper
undertakes a systematic study of satisfiability for LTL formulae over
restricted sets of propositional and temporal operators. Since every
propositional operator corresponds to a Boolean function, there exist
infinitely many propositional operators. In order to systematically cover all
possible sets of them, we use Post's lattice. With its help, we determine the
computational complexity of LTL satisfiability for all combinations of temporal
operators and all but two classes of propositional functions. Each of these
infinitely many problems is shown to be either PSPACE-complete, NP-complete, or
in P.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4852</identifier>
 <datestamp>2015-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4852</id><created>2008-12-28</created><updated>2015-03-02</updated><authors><author><keyname>Hewitt</keyname><forenames>Carl</forenames></author></authors><title>Formalizing common sense for scalable inconsistency-robust information
  integration using Direct Logic(TM) reasoning and the Actor Model</title><categories>cs.LO cs.PL cs.SE</categories><comments>Corrected: all types are strict</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Because contemporary large software systems are pervasively inconsistent, it
is not safe to reason about them using classical logic. The goal of Direct
Logic is to be a minimal fix to classical mathematical logic that meets the
requirements of large-scale Internet applications (including sense making for
natural language) by addressing the following issues: inconsistency robustness,
contrapositive inference bug, and direct argumentation.
  Direct Logic makes the following contributions over previous work:
  * Direct Inference (no contrapositive bug for inference)
  * Direct Argumentation (inference directly expressed)
  * Inconsistency-robust deduction without artifices such as indices (labels)
on propositions or restrictions on reiteration
  * Intuitive inferences hold including the following:
  * Boolean Equivalences
  * Reasoning by splitting for disjunctive cases
  * Soundness
  * Inconsistency-robust Proof by Contradiction
  Since the global state model of computation (first formalized by Turing) is
inadequate to the needs of modern large-scale Internet applications the Actor
Model was developed to meet this need. Using, the Actor Model, this paper
proves that Logic Programming is not computationally universal in that there
are computations that cannot be implemented using logical inference.
Consequently the Logic Programming paradigm is strictly less general than the
Procedural Embedding of Knowledge paradigm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4889</identifier>
 <datestamp>2008-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4889</id><created>2008-12-29</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames><affiliation>Shitz</affiliation></author><author><keyname>Guo</keyname><forenames>Dongning</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Statistical Physics of Signal Estimation in Gaussian Noise: Theory and
  Examples of Phase Transitions</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of signal estimation (denoising) from a statistical
mechanical perspective, using a relationship between the minimum mean square
error (MMSE), of estimating a signal, and the mutual information between this
signal and its noisy version. The paper consists of essentially two parts. In
the first, we derive several statistical-mechanical relationships between a few
important quantities in this problem area, such as the MMSE, the differential
entropy, the Fisher information, the free energy, and a generalized notion of
temperature. We also draw analogies and differences between certain relations
pertaining to the estimation problem and the parallel relations in
thermodynamics and statistical physics. In the second part of the paper, we
provide several application examples, where we demonstrate how certain analysis
tools that are customary in statistical physics, prove useful in the analysis
of the MMSE. In most of these examples, the corresponding
statistical-mechanical systems turn out to consist of strong interactions that
cause phase transitions, which in turn are reflected as irregularities and
discontinuities (similar to threshold effects) in the behavior of the MMSE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4893</identifier>
 <datestamp>2012-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4893</id><created>2008-12-29</created><authors><author><keyname>Flor&#xe9;en</keyname><forenames>Patrik</forenames></author><author><keyname>Kaski</keyname><forenames>Petteri</forenames></author><author><keyname>Polishchuk</keyname><forenames>Valentin</forenames></author><author><keyname>Suomela</keyname><forenames>Jukka</forenames></author></authors><title>Almost stable matchings in constant time</title><categories>cs.DS cs.DC</categories><comments>20 pages</comments><journal-ref>Algorithmica 58 (2010) 102-118</journal-ref><doi>10.1007/s00453-009-9353-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the ratio of matched individuals to blocking pairs grows
linearly with the number of propose--accept rounds executed by the
Gale--Shapley algorithm for the stable marriage problem. Consequently, the
participants can arrive at an almost stable matching even without full
information about the problem instance; for each participant, knowing only its
local neighbourhood is enough. In distributed-systems parlance, this means that
if each person has only a constant number of acceptable partners, an almost
stable matching emerges after a constant number of synchronous communication
rounds. This holds even if ties are present in the preference lists.
  We apply our results to give a distributed $(2+\epsilon)$-approximation
algorithm for maximum-weight matching in bicoloured graphs and a centralised
randomised constant-time approximation scheme for estimating the size of a
stable matching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4905</identifier>
 <datestamp>2009-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4905</id><created>2008-12-29</created><updated>2009-08-21</updated><authors><author><keyname>Leskovec</keyname><forenames>Jure</forenames></author><author><keyname>Chakrabarti</keyname><forenames>Deepayan</forenames></author><author><keyname>Kleinberg</keyname><forenames>Jon</forenames></author><author><keyname>Faloutsos</keyname><forenames>Christos</forenames></author><author><keyname>Ghahramani</keyname><forenames>Zoubin</forenames></author></authors><title>Kronecker Graphs: An Approach to Modeling Networks</title><categories>stat.ML cs.DS physics.data-an physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How can we model networks with a mathematically tractable model that allows
for rigorous analysis of network properties? Networks exhibit a long list of
surprising properties: heavy tails for the degree distribution; small
diameters; and densification and shrinking diameters over time. Most present
network models either fail to match several of the above properties, are
complicated to analyze mathematically, or both. In this paper we propose a
generative model for networks that is both mathematically tractable and can
generate networks that have the above mentioned properties. Our main idea is to
use the Kronecker product to generate graphs that we refer to as &quot;Kronecker
graphs&quot;.
  First, we prove that Kronecker graphs naturally obey common network
properties. We also provide empirical evidence showing that Kronecker graphs
can effectively model the structure of real networks.
  We then present KronFit, a fast and scalable algorithm for fitting the
Kronecker graph generation model to large real networks. A naive approach to
fitting would take super- exponential time. In contrast, KronFit takes linear
time, by exploiting the structure of Kronecker matrix multiplication and by
using statistical simulation techniques.
  Experiments on large real and synthetic networks show that KronFit finds
accurate parameters that indeed very well mimic the properties of target
networks. Once fitted, the model parameters can be used to gain insights about
the network structure, and the resulting synthetic graphs can be used for null-
models, anonymization, extrapolations, and graph summarization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4919</identifier>
 <datestamp>2008-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4919</id><created>2008-12-29</created><authors><author><keyname>Marx</keyname><forenames>D&#xe1;niel</forenames></author><author><keyname>Schlotter</keyname><forenames>Ildik&#xf3;</forenames></author></authors><title>Obtaining a Planar Graph by Vertex Deletion</title><categories>cs.DS</categories><comments>16 pages, 4 figures. A preliminary version of this paper appeared in
  the proceedings of WG 2007 (33rd International Workshop on Graph-Theoretic
  Concepts in Computer Science). The paper has been submitted to Algorithmica</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the k-Apex problem the task is to find at most k vertices whose deletion
makes the given graph planar. The graphs for which there exists a solution form
a minor closed class of graphs, hence by the deep results of Robertson and
Seymour, there is an O(n^3) time algorithm for every fixed value of k. However,
the proof is extremely complicated and the constants hidden by the big-O
notation are huge. Here we give a much simpler algorithm for this problem with
quadratic running time, by iteratively reducing the input graph and then
applying techniques for graphs of bounded treewidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4937</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4937</id><created>2008-12-29</created><updated>2010-04-12</updated><authors><author><keyname>Trifonov</keyname><forenames>Peter</forenames></author></authors><title>Efficient Interpolation in the Guruswami-Sudan Algorithm</title><categories>cs.IT cs.DM math.AC math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel algorithm is proposed for the interpolation step of the
Guruswami-Sudan list decoding algorithm. The proposed method is based on the
binary exponentiation algorithm, and can be considered as an extension of the
Lee-O'Sullivan algorithm. The algorithm is shown to achieve both asymptotical
and practical performance gain compared to the case of iterative interpolation
algorithm. Further complexity reduction is achieved by integrating the proposed
method with re-encoding. The key contribution of the paper, which enables the
complexity reduction, is a novel randomized ideal multiplication algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4952</identifier>
 <datestamp>2009-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4952</id><created>2008-12-29</created><updated>2009-05-20</updated><authors><author><keyname>Beygelzimer</keyname><forenames>Alina</forenames></author><author><keyname>Dasgupta</keyname><forenames>Sanjoy</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author></authors><title>Importance Weighted Active Learning</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a practical and statistically consistent scheme for actively
learning binary classifiers under general loss functions. Our algorithm uses
importance weighting to correct sampling bias, and by controlling the variance,
we are able to give rigorous label complexity bounds for the learning process.
Experiments on passively labeled data show that this approach reduces the label
complexity required to achieve good predictive performance on many learning
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4973</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4973</id><created>2008-12-29</created><authors><author><keyname>Dickson</keyname><forenames>Neil G.</forenames></author></authors><title>A Simple, Linear-Time Algorithm for x86 Jump Encoding</title><categories>cs.PL</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of space-optimal jump encoding in the x86 instruction set, also
known as branch displacement optimization, is described, and a linear-time
algorithm is given that uses no complicated data structures, no recursion, and
no randomization. The only assumption is that there are no array declarations
whose size depends on the negative of the size of a section of code (Hyde
2006), which is reasonable for real code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4974</identifier>
 <datestamp>2008-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4974</id><created>2008-12-29</created><authors><author><keyname>Knoll</keyname><forenames>Cecilia</forenames></author><author><keyname>Fulton</keyname><forenames>Charles</forenames></author></authors><title>Using a computer algebra system to simplify expressions for
  Titchmarsh-Weyl m-functions associated with the Hydrogen Atom on the half
  line</title><categories>math.SP cs.SC math.CO</categories><comments>10 pages</comments><msc-class>34B20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we give simplified formulas for certain polynomials which arise
in some new Titchmarsh-Weyl m-functions for the radial part of the separated
Hydrogen atom on the half line and two independent programs for generating them
using the symbolic manipulator Mathematica.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4983</identifier>
 <datestamp>2008-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4983</id><created>2008-12-29</created><authors><author><keyname>Saxena</keyname><forenames>Nitesh</forenames></author><author><keyname>Uddin</keyname><forenames>Md. Borhan</forenames></author></authors><title>Bootstrapping Key Pre-Distribution: Secure, Scalable and User-Friendly
  Initialization of Sensor Nodes</title><categories>cs.CR</categories><comments>10 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To establish secure (point-to-point and/or broadcast) communication channels
among the nodes of a wireless sensor network is a fundamental task. To this
end, a plethora of (socalled) key pre-distribution schemes have been proposed
in the past. All these schemes, however, rely on shared secret(s), which are
assumed to be somehow pre-loaded onto the sensor nodes. In this paper, we
propose a novel method for secure initialization of sensor nodes based on a
visual out-of-band channel. Using the proposed method, the administrator of a
sensor network can distribute keys onto the sensor nodes, necessary to
bootstrap key pre-distribution. Our secure initialization method requires only
a little extra cost, is efficient and scalable with respect to the number of
sensor nodes. Moreover, based on a usability study that we conducted, the
method turns out to be quite user-friendly and easy to use by naive human
users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4985</identifier>
 <datestamp>2008-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4985</id><created>2008-12-29</created><authors><author><keyname>Chung</keyname><forenames>G.</forenames></author><author><keyname>Sridharan</keyname><forenames>S.</forenames></author><author><keyname>Vishwanath</keyname><forenames>S.</forenames></author><author><keyname>Hwang</keyname><forenames>C. S.</forenames></author></authors><title>On the Capacity of Partially Cognitive Radios</title><categories>cs.IT math.IT</categories><comments>7 pages,2 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper considers the problem of cognitive radios with partial-message
information. Here, an interference channel setting is considered where one
transmitter (the &quot;cognitive&quot; one) knows the message of the other (&quot;legitimate&quot;
user) partially. An outer bound on the capacity region of this channel is found
for the &quot;weak&quot; interference case (where the interference from the cognitive
transmitter to the legitimate receiver is weak). This outer bound is shown for
both the discrete-memoryless and the Gaussian channel cases. An achievable
region is subsequently determined for a mixed interference Gaussian cognitive
radio channel, where the interference from the legitimate transmitter to the
cognitive receiver is &quot;strong&quot;. It is shown that, for a class of mixed Gaussian
cognitive radio channels, portions of the outer bound are achievable thus
resulting in a characterization of a part of this channel's capacity region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4986</identifier>
 <datestamp>2008-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4986</id><created>2008-12-29</created><authors><author><keyname>Schmidt</keyname><forenames>Albrecht</forenames></author></authors><title>An Array Algebra</title><categories>cs.DB</categories><comments>Five pages, no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a proposal of an algebra which aims at distributed array processing.
The focus lies on re-arranging and distributing array data, which may be
multi-dimensional. The context of the work is scientific processing; thus, the
core science operations are assumed to be taken care of in external libraries
or languages. A main design driver is the desire to carry over some of the
strategies of the relational algebra into the array domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.5026</identifier>
 <datestamp>2008-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.5026</id><created>2008-12-30</created><authors><author><keyname>Gurevich</keyname><forenames>Shamgar</forenames><affiliation>UC Berkeley</affiliation></author><author><keyname>Hadani</keyname><forenames>Ronny</forenames><affiliation>University of Chicago</affiliation></author><author><keyname>Sochen</keyname><forenames>Nir</forenames><affiliation>Tel Aviv University</affiliation></author></authors><title>Group representation design of digital signals and sequences</title><categories>cs.IT cs.DM math.IT math.RT</categories><comments>Appeared in the proceedings of the international conference on
  Sequences and Their Applications (SETA) 2008. Key words: Weil representation,
  commutative subgroups, eigenfunctions, good correlations, low supremum,
  Fourier invariance, explicit algorithm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this survey a novel system, called the oscillator system, consisting of
order of p^3 functions (signals) on the finite field F_{p}, is described and
studied. The new functions are proved to satisfy good auto-correlation,
cross-correlation and low peak-to-average power ratio properties. Moreover, the
oscillator system is closed under the operation of discrete Fourier transform.
Applications of the oscillator system for discrete radar and digital
communication theory are explained. Finally, an explicit algorithm to construct
the oscillator system is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.5030</identifier>
 <datestamp>2010-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.5030</id><created>2008-12-30</created><updated>2010-01-03</updated><authors><author><keyname>Kane</keyname><forenames>Daniel</forenames></author><author><keyname>Price</keyname><forenames>Gregory N.</forenames></author><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author></authors><title>A Pseudopolynomial Algorithm for Alexandrov's Theorem</title><categories>cs.CG</categories><comments>25 pages; new Delaunay triangulation algorithm, minor other changes;
  an abbreviated v2 was at WADS 2009</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Alexandrov's Theorem states that every metric with the global topology and
local geometry required of a convex polyhedron is in fact the intrinsic metric
of a unique convex polyhedron. Recent work by Bobenko and Izmestiev describes a
differential equation whose solution leads to the polyhedron corresponding to a
given metric. We describe an algorithm based on this differential equation to
compute the polyhedron to arbitrary precision given the metric, and prove a
pseudopolynomial bound on its running time. Along the way, we develop
pseudopolynomial algorithms for computing shortest paths and weighted Delaunay
triangulations on a polyhedral surface, even when the surface edges are not
shortest paths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.5032</identifier>
 <datestamp>2008-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.5032</id><created>2008-12-30</created><authors><author><keyname>Li</keyname><forenames>Qiang</forenames></author><author><keyname>He</keyname><forenames>Yan</forenames></author><author><keyname>Jiang</keyname><forenames>Jing-ping</forenames></author></authors><title>A New Clustering Algorithm Based Upon Flocking On Complex Network</title><categories>cs.LG cs.AI cs.CV physics.soc-ph</categories><comments>18 pages, 4 figures, 3 tables</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We have proposed a model based upon flocking on a complex network, and then
developed two clustering algorithms on the basis of it. In the algorithms,
firstly a \textit{k}-nearest neighbor (knn) graph as a weighted and directed
graph is produced among all data points in a dataset each of which is regarded
as an agent who can move in space, and then a time-varying complex network is
created by adding long-range links for each data point. Furthermore, each data
point is not only acted by its \textit{k} nearest neighbors but also \textit{r}
long-range neighbors through fields established in space by them together, so
it will take a step along the direction of the vector sum of all fields. It is
more important that these long-range links provides some hidden information for
each data point when it moves and at the same time accelerate its speed
converging to a center. As they move in space according to the proposed model,
data points that belong to the same class are located at a same position
gradually, whereas those that belong to different classes are away from one
another. Consequently, the experimental results have demonstrated that data
points in datasets are clustered reasonably and efficiently, and the rates of
convergence of clustering algorithms are fast enough. Moreover, the comparison
with other algorithms also provides an indication of the effectiveness of the
proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.5039</identifier>
 <datestamp>2013-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.5039</id><created>2008-12-30</created><updated>2009-10-14</updated><authors><author><keyname>Bukh</keyname><forenames>Boris</forenames></author><author><keyname>Matou&#x161;ek</keyname><forenames>Ji&#x159;&#xed;</forenames></author><author><keyname>Nivasch</keyname><forenames>Gabriel</forenames></author></authors><title>Lower bounds for weak epsilon-nets and stair-convexity</title><categories>math.CO cs.CG</categories><comments>To appear in Israel J. Math. 21 pages, 4 figures</comments><msc-class>52A30, 52C99, 68U05</msc-class><journal-ref>Israel Journal of Mathematics, 182:199-228, 2011</journal-ref><doi>10.1007/s11856-011-0029-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A set N is called a &quot;weak epsilon-net&quot; (with respect to convex sets) for a
finite set X in R^d if N intersects every convex set that contains at least
epsilon*|X| points of X. For every fixed d&gt;=2 and every r&gt;=1 we construct sets
X in R^d for which every weak (1/r)-net has at least Omega(r log^{d-1} r)
points; this is the first superlinear lower bound for weak epsilon-nets in a
fixed dimension.
  The construction is a &quot;stretched grid&quot;, i.e., the Cartesian product of d
suitable fast-growing finite sequences, and convexity in this grid can be
analyzed using &quot;stair-convexity&quot;, a new variant of the usual notion of
convexity.
  We also consider weak epsilon-nets for the diagonal of our stretched grid in
R^d, d&gt;=3, which is an &quot;intrinsically 1-dimensional&quot; point set. In this case we
exhibit slightly superlinear lower bounds (involving the inverse Ackermann
function), showing that upper bounds by Alon, Kaplan, Nivasch, Sharir, and
Smorodinsky (2008) are not far from the truth in the worst case.
  Using the stretched grid we also improve the known upper bound for the
so-called &quot;second selection lemma&quot; in the plane by a logarithmic factor: We
obtain a set T of t triangles with vertices in an n-point set in the plane such
that no point is contained in more than O(t^2 / (n^3 log (n^3/t))) triangles of
T.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.5064</identifier>
 <datestamp>2010-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.5064</id><created>2008-12-30</created><updated>2010-03-19</updated><authors><author><keyname>Li</keyname><forenames>Qiang</forenames></author><author><keyname>Chen</keyname><forenames>Zhuo</forenames></author><author><keyname>He</keyname><forenames>Yan</forenames></author><author><keyname>Jiang</keyname><forenames>Jing-ping</forenames></author></authors><title>A Novel Clustering Algorithm Based Upon Games on Evolving Network</title><categories>cs.LG cs.CV cs.GT nlin.AO</categories><comments>17 pages, 5 figures, 3 tables</comments><journal-ref>Expert Systems with Applications, 2010</journal-ref><doi>10.1016/j.eswa.2010.02.050</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper introduces a model based upon games on an evolving network, and
develops three clustering algorithms according to it. In the clustering
algorithms, data points for clustering are regarded as players who can make
decisions in games. On the network describing relationships among data points,
an edge-removing-and-rewiring (ERR) function is employed to explore in a
neighborhood of a data point, which removes edges connecting to neighbors with
small payoffs, and creates new edges to neighbors with larger payoffs. As such,
the connections among data points vary over time. During the evolution of
network, some strategies are spread in the network. As a consequence, clusters
are formed automatically, in which data points with the same evolutionarily
stable strategy are collected as a cluster, so the number of evolutionarily
stable strategies indicates the number of clusters. Moreover, the experimental
results have demonstrated that data points in datasets are clustered reasonably
and efficiently, and the comparison with other algorithms also provides an
indication of the effectiveness of the proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.5101</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.5101</id><created>2008-12-30</created><authors><author><keyname>Paluch</keyname><forenames>Katarzyna</forenames></author><author><keyname>Mucha</keyname><forenames>Marcin</forenames></author><author><keyname>Madry</keyname><forenames>Aleksander</forenames></author></authors><title>A 7/9 - Approximation Algorithm for the Maximum Traveling Salesman
  Problem</title><categories>cs.GT cs.DM cs.DS</categories><comments>6 figures</comments><doi>10.1007/978-3-642-03685-9_23</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a 7/9 - Approximation Algorithm for the Maximum Traveling Salesman
Problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.5104</identifier>
 <datestamp>2009-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.5104</id><created>2008-12-30</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author></authors><title>On Quantum and Classical Error Control Codes: Constructions and
  Applications</title><categories>cs.IT math.IT quant-ph</categories><comments>Parts of PhD dissertation, Texas A&amp;M University</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is conjectured that quantum computers are able to solve certain problems
more quickly than any deterministic or probabilistic computer. A quantum
computer exploits the rules of quantum mechanics to speed up computations.
However, it is a formidable task to build a quantum computer, since the quantum
mechanical systems storing the information unavoidably interact with their
environment. Therefore, one has to mitigate the resulting noise and decoherence
effects to avoid computational errors.
  In this work, I study various aspects of quantum error control codes -- the
key component of fault-tolerant quantum information processing. I present the
fundamental theory and necessary background of quantum codes and construct many
families of quantum block and convolutional codes over finite fields, in
addition to families of subsystem codes over symmetric and asymmetric channels.
  Particularly, many families of quantum BCH, RS, duadic, and convolutional
codes are constructed over finite fields. Families of subsystem codes and a
class of optimal MDS subsystem codes are derived over asymmetric and symmetric
quantum channels. In addition, propagation rules and tables of upper bounds on
subsystem code parameters are established. Classes of quantum and classical
LDPC codes based on finite geometries and Latin squares are constructed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0015</identifier>
 <datestamp>2010-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0015</id><created>2008-12-30</created><updated>2009-03-29</updated><authors><author><keyname>Harremoes</keyname><forenames>Peter</forenames></author></authors><title>Maximum Entropy on Compact Groups</title><categories>cs.IT math.IT math.PR</categories><journal-ref>Entropy 2009, 11(2), 222-237</journal-ref><doi>10.3390/e11020222</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  On a compact group the Haar probability measure plays the role of uniform
distribution. The entropy and rate distortion theory for this uniform
distribution is studied. New results and simplified proofs on convergence of
convolutions on compact groups are presented and they can be formulated as
entropy increases to its maximum. Information theoretic techniques and Markov
chains play a crucial role. The convergence results are also formulated via
rate distortion functions. The rate of convergence is shown to be exponential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0029</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0029</id><created>2008-12-31</created><authors><author><keyname>Rehr</keyname><forenames>J. J.</forenames></author><author><keyname>Gardner</keyname><forenames>J. P.</forenames></author><author><keyname>Prange</keyname><forenames>M.</forenames></author><author><keyname>Svec</keyname><forenames>L.</forenames></author><author><keyname>Vila</keyname><forenames>F.</forenames></author></authors><title>Scientific Computing in the Cloud</title><categories>cond-mat.mtrl-sci cs.DC physics.comp-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the feasibility of high performance scientific computation
using cloud computers as an alternative to traditional computational tools. The
availability of these large, virtualized pools of compute resources raises the
possibility of a new compute paradigm for scientific research with many
advantages. For research groups, cloud computing provides convenient access to
reliable, high performance clusters and storage, without the need to purchase
and maintain sophisticated hardware. For developers, virtualization allows
scientific codes to be optimized and pre-installed on machine images,
facilitating control over the computational environment. Preliminary tests are
presented for serial and parallelized versions of the widely used x-ray
spectroscopy and electronic structure code FEFF on the Amazon Elastic Compute
Cloud, including CPU and network performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0042</identifier>
 <datestamp>2009-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0042</id><created>2008-12-30</created><authors><author><keyname>Li</keyname><forenames>Zhuo</forenames></author><author><keyname>Xing</keyname><forenames>Li-Juan</forenames></author><author><keyname>Wang</keyname><forenames>Xin-Mei</forenames></author></authors><title>A family of asymptotically good quantum codes based on code
  concatenation</title><categories>quant-ph cs.IT math.IT</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explicitly construct an infinite family of asymptotically good
concatenated quantum stabilizer codes where the outer code uses CSS-type
quantum Reed-Solomon code and the inner code uses a set of special quantum
codes. In the field of quantum error-correcting codes, this is the first time
that a family of asymptotically good quantum codes is derived from bad codes.
Its occurrence supplies a gap in quantum coding theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0043</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0043</id><created>2008-12-30</created><authors><author><keyname>van Glabbeek</keyname><forenames>Rob</forenames></author><author><keyname>Goltz</keyname><forenames>Ursula</forenames></author><author><keyname>Schicke</keyname><forenames>Jens-Wolfhard</forenames></author></authors><title>Symmetric and Asymmetric Asynchronous Interaction</title><categories>cs.LO cs.DC</categories><comments>27 pages. An extended abstract of this paper was presented at the
  first Interaction and Concurrency Experience (ICE'08) on Synchronous and
  Asynchronous Interactions in Concurrent Distributed Systems, and will appear
  in Electronic Notes in Theoretical Computer Science, Elsevier</comments><report-no>Technical Report 2008-03, Technical University of Braunschweig</report-no><acm-class>F.1.2; B.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate classes of systems based on different interaction patterns
with the aim of achieving distributability. As our system model we use Petri
nets. In Petri nets, an inherent concept of simultaneity is built in, since
when a transition has more than one preplace, it can be crucial that tokens are
removed instantaneously. When modelling a system which is intended to be
implemented in a distributed way by a Petri net, this built-in concept of
synchronous interaction may be problematic. To investigate this we consider
asynchronous implementations of nets, in which removing tokens from places can
no longer be considered as instantaneous. We model this by inserting silent
(unobservable) transitions between transitions and some of their preplaces. We
investigate three such implementations, differing in the selection of preplaces
of a transition from which the removal of a token is considered time consuming,
and the possibility of collecting the tokens in a given order.
  We investigate the effect of these different transformations of instantaneous
interaction into asynchronous interaction patterns by comparing the behaviours
of nets before and after insertion of the silent transitions. We exhibit for
which classes of Petri nets we obtain equivalent behaviour with respect to
failures equivalence.
  It turns out that the resulting hierarchy of Petri net classes can be
described by semi-structural properties. For two of the classes we obtain
precise characterisations; for the remaining class we obtain lower and upper
bounds.
  We briefly comment on possible applications of our results to Message
Sequence Charts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0044</identifier>
 <datestamp>2010-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0044</id><created>2008-12-30</created><updated>2009-08-03</updated><authors><author><keyname>Madiman</keyname><forenames>Mokshay</forenames></author><author><keyname>Tetali</keyname><forenames>Prasad</forenames></author></authors><title>Information Inequalities for Joint Distributions, with Interpretations
  and Applications</title><categories>cs.IT math.CO math.IT math.PR</categories><comments>15 pages, 1 figure. Originally submitted to the IEEE Transactions on
  Information Theory in May 2007, the current version incorporates reviewer
  comments including elimination of an error</comments><journal-ref>IEEE Transactions on Information Theory, Vol. 56(6), pp.
  2699-2713, June 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Upper and lower bounds are obtained for the joint entropy of a collection of
random variables in terms of an arbitrary collection of subset joint entropies.
These inequalities generalize Shannon's chain rule for entropy as well as
inequalities of Han, Fujishige and Shearer. A duality between the upper and
lower bounds for joint entropy is developed. All of these results are shown to
be special cases of general, new results for submodular functions-- thus, the
inequalities presented constitute a richly structured class of Shannon-type
inequalities. The new inequalities are applied to obtain new results in
combinatorics, such as bounds on the number of independent sets in an arbitrary
graph and the number of zero-error source-channel codes, as well as new
determinantal inequalities in matrix theory. A new inequality for relative
entropies is also developed, along with interpretations in terms of hypothesis
testing. Finally, revealing connections of the results to literature in
economics, computer science, and physics are explored.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0048</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0048</id><created>2008-12-30</created><authors><author><keyname>van Glabbeek</keyname><forenames>Rob</forenames></author><author><keyname>Goltz</keyname><forenames>Ursula</forenames></author><author><keyname>Schicke</keyname><forenames>Jens-Wolfhard</forenames></author></authors><title>On Synchronous and Asynchronous Interaction in Distributed Systems</title><categories>cs.LO cs.DC</categories><comments>26 pages. An extended abstract of this paper appeared in Proceedings
  33rd International Symposium on Mathematical Foundations of Computer Science
  (MFCS 2008), Torun, Poland, August 2008 (E. Ochmanski &amp; J. Tyszkiewicz,
  eds.), LNCS 5162, Springer, 2008, pp. 16-35</comments><report-no>Technical Report 2008-04, Technical University of Braunschweig</report-no><acm-class>F.1.2; B.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When considering distributed systems, it is a central issue how to deal with
interactions between components. In this paper, we investigate the paradigms of
synchronous and asynchronous interaction in the context of distributed systems.
We investigate to what extent or under which conditions synchronous interaction
is a valid concept for specification and implementation of such systems. We
choose Petri nets as our system model and consider different notions of
distribution by associating locations to elements of nets. First, we
investigate the concept of simultaneity which is inherent in the semantics of
Petri nets when transitions have multiple input places. We assume that tokens
may only be taken instantaneously by transitions on the same location. We
exhibit a hierarchy of `asynchronous' Petri net classes by different
assumptions on possible distributions. Alternatively, we assume that the
synchronisations specified in a Petri net are crucial system properties. Hence
transitions and their preplaces may no longer placed on separate locations. We
then answer the question which systems may be implemented in a distributed way
without restricting concurrency, assuming that locations are inherently
sequential. It turns out that in both settings we find semi-structural
properties of Petri nets describing exactly the problematic situations for
interactions in distributed systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0055</identifier>
 <datestamp>2012-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0055</id><created>2008-12-30</created><updated>2011-08-09</updated><authors><author><keyname>Madiman</keyname><forenames>Mokshay</forenames></author><author><keyname>Marcus</keyname><forenames>Adam</forenames></author><author><keyname>Tetali</keyname><forenames>Prasad</forenames></author></authors><title>Entropy and set cardinality inequalities for partition-determined
  functions</title><categories>cs.IT math.CO math.IT math.NT math.PR</categories><comments>26 pages. v2: Revised version incorporating referee feedback plus
  inclusion of some additional corollaries and discussion. v3: Final version
  with minor corrections. To appear in Random Structures and Algorithms</comments><journal-ref>Random Structures and Algorithms, Vol. 40, pp. 399-424, 2012</journal-ref><doi>10.1002/rsa.20385</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new notion of partition-determined functions is introduced, and several
basic inequalities are developed for the entropy of such functions of
independent random variables, as well as for cardinalities of compound sets
obtained using these functions. Here a compound set means a set obtained by
varying each argument of a function of several variables over a set associated
with that argument, where all the sets are subsets of an appropriate algebraic
structure so that the function is well defined. On the one hand, the entropy
inequalities developed for partition-determined functions imply entropic
analogues of general inequalities of Pl\&quot;unnecke-Ruzsa type. On the other hand,
the cardinality inequalities developed for compound sets imply several
inequalities for sumsets, including for instance a generalization of
inequalities proved by Gyarmati, Matolcsi and Ruzsa (2010). We also provide
partial progress towards a conjecture of Ruzsa (2007) for sumsets in nonabelian
groups. All proofs are elementary and rely on properly developing certain
information-theoretic inequalities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0062</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0062</id><created>2008-12-31</created><authors><author><keyname>Madiman</keyname><forenames>Mokshay</forenames></author></authors><title>Cores of Cooperative Games in Information Theory</title><categories>cs.IT cs.GT math.IT</categories><comments>12 pages, published at
  http://www.hindawi.com/GetArticle.aspx?doi=10.1155/2008/318704 in EURASIP
  Journal on Wireless Communications and Networking, Special Issue on &quot;Theory
  and Applications in Multiuser/Multiterminal Communications&quot;, April 2008</comments><journal-ref>EURASIP Journal on Wireless Communications and Networking, Volume
  2008, Article ID 318704</journal-ref><doi>10.1155/2008/318704</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cores of cooperative games are ubiquitous in information theory, and arise
most frequently in the characterization of fundamental limits in various
scenarios involving multiple users. Examples include classical settings in
network information theory such as Slepian-Wolf source coding and multiple
access channels, classical settings in statistics such as robust hypothesis
testing, and new settings at the intersection of networking and statistics such
as distributed estimation problems for sensor networks. Cooperative game theory
allows one to understand aspects of all of these problems from a fresh and
unifying perspective that treats users as players in a game, sometimes leading
to new insights. At the heart of these analyses are fundamental dualities that
have been long studied in the context of cooperative games; for information
theoretic purposes, these are dualities between information inequalities on the
one hand and properties of rate, capacity or other resource allocation regions
on the other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0065</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0065</id><created>2008-12-31</created><authors><author><keyname>Avanaki</keyname><forenames>Alireza</forenames></author></authors><title>Exact Histogram Specification Optimized for Structural Similarity</title><categories>cs.CV cs.MM</categories><doi>10.1007/s10043-009-0119-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An exact histogram specification (EHS) method modifies its input image to
have a specified histogram. Applications of EHS include image (contrast)
enhancement (e.g., by histogram equalization) and histogram watermarking.
Performing EHS on an image, however, reduces its visual quality. Starting from
the output of a generic EHS method, we maximize the structural similarity index
(SSIM) between the original image (before EHS) and the result of EHS
iteratively. Essential in this process is the computationally simple and
accurate formula we derive for SSIM gradient. As it is based on gradient
ascent, the proposed EHS always converges. Experimental results confirm that
while obtaining the histogram exactly as specified, the proposed method
invariably outperforms the existing methods in terms of visual quality of the
result. The computational complexity of the proposed method is shown to be of
the same order as that of the existing methods.
  Index terms: histogram modification, histogram equalization, optimization for
perceptual visual quality, structural similarity gradient ascent, histogram
watermarking, contrast enhancement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0118</identifier>
 <datestamp>2009-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0118</id><created>2008-12-31</created><updated>2009-08-06</updated><authors><author><keyname>Jose</keyname><forenames>Jubin</forenames></author><author><keyname>Ying</keyname><forenames>Lei</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>On the Stability Region of Amplify-and-Forward Cooperative Relay
  Networks</title><categories>cs.IT math.IT</categories><comments>accepted for presentation at ITW 2009, Taormina, Sicily</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers an amplify-and-forward relay network with fading states.
Amplify-and-forward scheme (along with its variations) is the core mechanism
for enabling cooperative communication in wireless networks, and hence
understanding the network stability region under amplify-and-forward scheme is
very important. However, in a relay network employing amplify-and-forward, the
interaction between nodes is described in terms of real-valued ``packets''
(signals) instead of discrete packets (bits). This restrains the relay nodes
from re-encoding the packets at desired rates. Hence, the stability analysis
for relay networks employing amplify-and-forward scheme is by no means a
straightforward extension of that in packet-based networks. In this paper, the
stability region of a four-node relay network is characterized, and a simple
throughput optimal algorithm with joint scheduling and rate allocation is
proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0121</identifier>
 <datestamp>2011-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0121</id><created>2008-12-31</created><updated>2011-07-25</updated><authors><author><keyname>Khojabaghyan</keyname><forenames>Artur</forenames></author><author><keyname>Mkrtchyan</keyname><forenames>Vahan V.</forenames></author></authors><title>On upper bounds for parameters related to construction of special
  maximum matchings</title><categories>cs.DM math.CO</categories><comments>11 pages, no figures</comments><journal-ref>Discrete Mathematics 312/2 (2012), pp. 213--220</journal-ref><doi>10.1016/j.disc.2011.08.026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a graph $G$ let $L(G)$ and $l(G)$ denote the size of the largest and
smallest maximum matching of a graph obtained from $G$ by removing a maximum
matching of $G$. We show that $L(G)\leq 2l(G),$ and $L(G)\leq (3/2)l(G)$
provided that $G$ contains a perfect matching. We also characterize the class
of graphs for which $L(G)=2l(G)$. Our characterization implies the existence of
a polynomial algorithm for testing the property $L(G)=2l(G)$. Finally we show
that it is $NP$-complete to test whether a graph $G$ containing a perfect
matching satisfies $L(G)=(3/2)l(G)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0131</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0131</id><created>2008-12-31</created><authors><author><keyname>Foster</keyname><forenames>Ian</forenames></author><author><keyname>Zhao</keyname><forenames>Yong</forenames></author><author><keyname>Raicu</keyname><forenames>Ioan</forenames></author><author><keyname>Lu</keyname><forenames>Shiyong</forenames></author></authors><title>Cloud Computing and Grid Computing 360-Degree Compared</title><categories>cs.DC</categories><comments>IEEE Grid Computing Environments (GCE08) 2008</comments><acm-class>C.2.4; A.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud Computing has become another buzzword after Web 2.0. However, there are
dozens of different definitions for Cloud Computing and there seems to be no
consensus on what a Cloud is. On the other hand, Cloud Computing is not a
completely new concept; it has intricate connection to the relatively new but
thirteen-year established Grid Computing paradigm, and other relevant
technologies such as utility computing, cluster computing, and distributed
systems in general. This paper strives to compare and contrast Cloud Computing
with Grid Computing from various angles and give insights into the essential
characteristics of both.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0134</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0134</id><created>2008-12-31</created><authors><author><keyname>Zhang</keyname><forenames>Zhao</forenames></author><author><keyname>Espinosa</keyname><forenames>Allan</forenames></author><author><keyname>Iskra</keyname><forenames>Kamil</forenames></author><author><keyname>Raicu</keyname><forenames>Ioan</forenames></author><author><keyname>Foster</keyname><forenames>Ian</forenames></author><author><keyname>Wilde</keyname><forenames>Michael</forenames></author></authors><title>Design and Evaluation of a Collective IO Model for Loosely Coupled
  Petascale Programming</title><categories>cs.DC</categories><comments>IEEE Many-Task Computing on Grids and Supercomputers (MTAGS08) 2008</comments><acm-class>C.2.4; D.4.2; D.4.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Loosely coupled programming is a powerful paradigm for rapidly creating
higher-level applications from scientific programs on petascale systems,
typically using scripting languages. This paradigm is a form of many-task
computing (MTC) which focuses on the passing of data between programs as
ordinary files rather than messages. While it has the significant benefits of
decoupling producer and consumer and allowing existing application programs to
be executed in parallel with no recoding, its typical implementation using
shared file systems places a high performance burden on the overall system and
on the user who will analyze and consume the downstream data. Previous efforts
have achieved great speedups with loosely coupled programs, but have done so
with careful manual tuning of all shared file system access. In this work, we
evaluate a prototype collective IO model for file-based MTC. The model enables
efficient and easy distribution of input data files to computing nodes and
gathering of output results from them. It eliminates the need for such manual
tuning and makes the programming of large-scale clusters using a loosely
coupled model easier. Our approach, inspired by in-memory approaches to
collective operations for parallel programming, builds on fast local file
systems to provide high-speed local file caches for parallel scripts, uses a
broadcast approach to handle distribution of common input data, and uses
efficient scatter/gather and caching techniques for input and output. We
describe the design of the prototype model, its implementation on the Blue
Gene/P supercomputer, and present preliminary measurements of its performance
on synthetic benchmarks and on a large-scale molecular dynamics application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0148</identifier>
 <datestamp>2009-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0148</id><created>2008-12-31</created><authors><author><keyname>Zerola</keyname><forenames>Michal</forenames></author><author><keyname>Lauret</keyname><forenames>Jerome</forenames></author><author><keyname>Bartak</keyname><forenames>Roman</forenames></author><author><keyname>Sumbera</keyname><forenames>Michal</forenames></author></authors><title>Using constraint programming to resolve the multi-source/multi-site data
  movement paradigm on the Grid</title><categories>cs.PF</categories><comments>10 pages; ACAT 2008 workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to achieve both fast and coordinated data transfer to collaborative
sites as well as to create a distribution of data over multiple sites,
efficient data movement is one of the most essential aspects in distributed
environment. With such capabilities at hand, truly distributed task scheduling
with minimal latencies would be reachable by internationally distributed
collaborations (such as ones in HENP) seeking for scavenging or maximizing on
geographically spread computational resources. But it is often not all clear
(a) how to move data when available from multiple sources or (b) how to move
data to multiple compute resources to achieve an optimal usage of available
resources. We present a method of creating a Constraint Programming (CP) model
consisting of sites, links and their attributes such as bandwidth for grid
network data transfer also considering user tasks as part of the objective
function for an optimal solution. We will explore and explain trade-off between
schedule generation time and divergence from the optimal solution and show how
to improve and render viable the solution's finding time by using search tree
time limit, approximations, restrictions such as symmetry breaking or grouping
similar tasks together, or generating sequence of optimal schedules by
splitting the input problem. Results of data transfer simulation for each case
will also include a well known Peer-2-Peer model, and time taken to generate a
schedule as well as time needed for a schedule execution will be compared to a
CP optimal solution. We will additionally present a possible implementation
aimed to bring a distributed datasets (multiple sources) to a given site in a
minimal time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0163</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0163</id><created>2009-01-01</created><authors><author><keyname>Agarwal</keyname><forenames>Manish</forenames></author><author><keyname>Guo</keyname><forenames>Dongning</forenames></author><author><keyname>Honig</keyname><forenames>Michael</forenames></author></authors><title>Limited-Rate Channel State Feedback for Multicarrier Block Fading
  Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity of a fading channel can be substantially increased by feeding
back channel state information from the receiver to the transmitter. With
limited-rate feedback what state information to feed back and how to encode it
are important open questions. This paper studies power loading in a
multicarrier system using no more than one bit of feedback per sub-channel. The
sub-channels can be correlated and full channel state information is assumed at
the receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0168</identifier>
 <datestamp>2009-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0168</id><created>2009-01-01</created><updated>2009-02-09</updated><authors><author><keyname>Harshan</keyname><forenames>J.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Coding for Two-User SISO and MIMO Multiple Access Channels</title><categories>cs.IT math.IT</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constellation Constrained (CC) capacity regions of a two-user SISO Gaussian
Multiple Access Channel (GMAC) with finite complex input alphabets and
continuous output are computed in this paper. When both the users employ the
same code alphabet, it is well known that an appropriate rotation between the
alphabets provides unique decodability to the receiver. For such a set-up, a
metric is proposed to compute the angle(s) of rotation between the alphabets
such that the CC capacity region is maximally enlarged. Subsequently, code
pairs based on Trellis Coded Modulation (TCM) are designed for the two-user
GMAC with $M$-PSK and $M$-PAM alphabet pairs for arbitrary values of $M$ and it
is proved that, for certain angles of rotation, Ungerboeck labelling on the
trellis of each user maximizes the guaranteed squared Euclidean distance of the
\textit{sum trellis}. Hence, such a labelling scheme can be used systematically
to construct trellis code pairs for a two-user GMAC to achieve sum rates close
to the sum capacity of the channel. More importantly, it is shown for the first
time that ML decoding complexity at the destination is significantly reduced
when $M$-PAM alphabet pairs are employed with \textit{almost} no loss in the
sum capacity. \indent A two-user Multiple Input Multiple Output (MIMO) fading
MAC with $N_{t}$ antennas at both the users and a single antenna at the
destination has also been considered with the assumption that the destination
has the perfect knowledge of channel state information and the two users have
the perfect knowledge of only the phase components of their channels. For such
a set-up, two distinct classes of Space Time Block Code (STBC) pairs derived
from the well known class of real orthogonal designs are proposed such that the
STBC pairs are information lossless and have low ML decoding complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0170</identifier>
 <datestamp>2009-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0170</id><created>2009-01-01</created><authors><author><keyname>Kretz</keyname><forenames>Tobias</forenames></author></authors><title>Pedestrian Traffic: on the Quickest Path</title><categories>physics.soc-ph cs.MA physics.comp-ph</categories><report-no>P03012</report-no><journal-ref>J. Stat. Mech. (2009)</journal-ref><doi>10.1088/1742-5468/2009/03/P03012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When a large group of pedestrians moves around a corner, most pedestrians do
not follow the shortest path, which is to stay as close as possible to the
inner wall, but try to minimize the travel time. For this they accept to move
on a longer path with some distance to the corner, to avoid large densities and
by this succeed in maintaining a comparatively high speed. In many models of
pedestrian dynamics the basic rule of motion is often either &quot;move as far as
possible toward the destination&quot; or - reformulated - &quot;of all coordinates
accessible in this time step move to the one with the smallest distance to the
destination&quot;. Atop of this rule modifications are placed to make the motion
more realistic. These modifications usually focus on local behavior and neglect
long-ranged effects. Compared to real pedestrians this leads to agents in a
simulation valuing the shortest path a lot better than the quickest. So, in a
situation as the movement of a large crowd around a corner, one needs an
additional element in a model of pedestrian dynamics that makes the agents
deviate from the rule of the shortest path. In this work it is shown, how this
can be achieved by using a flood fill dynamic potential field method, where
during the filling process the value of a field cell is not increased by 1, but
by a larger value, if it is occupied by an agent. This idea may be an obvious
one, however, the tricky part - and therefore in a strict sense the
contribution of this work - is a) to minimize unrealistic artifacts, as naive
flood fill metrics deviate considerably from the Euclidean metric and in this
respect yield large errors, b) do this with limited computational effort, and
c) keep agents' movement at very low densities unaltered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0179</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0179</id><created>2009-01-01</created><authors><author><keyname>Misra</keyname><forenames>Janardan</forenames></author><author><keyname>Roy</keyname><forenames>Suman</forenames></author></authors><title>Techniques for Distributed Reachability Analysis with Partial Order and
  Symmetry based Reductions</title><categories>cs.DC cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we propose techniques for efficient reachability analysis of the
state space (e.g., detection of bad states) using a combination of partial
order and symmetry based reductions in a distributed setting. The proposed
techniques are focused towards explicit state space enumeration based
model-checkers like SPIN. We consider variants for both depth-first as well as
breadth-first based generation of the reduced state graphs on-the-fly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0205</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0205</id><created>2009-01-01</created><authors><author><keyname>Chakrabarty</keyname><forenames>Deeparnab</forenames></author><author><keyname>Chuzhoy</keyname><forenames>Julia</forenames></author><author><keyname>Khanna</keyname><forenames>Sanjeev</forenames></author></authors><title>On Allocating Goods to Maximize Fairness</title><categories>cs.DS</categories><comments>35 pages</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set of $m$ agents and a set of $n$ items, where agent $A$ has utility
$u_{A,i}$ for item $i$, our goal is to allocate items to agents to maximize
fairness. Specifically, the utility of an agent is the sum of its utilities for
items it receives, and we seek to maximize the minimum utility of any agent.
While this problem has received much attention recently, its approximability
has not been well-understood thus far: the best known approximation algorithm
achieves an $\tilde{O}(\sqrt{m})$-approximation, and in contrast, the best
known hardness of approximation stands at 2.
  Our main result is an approximation algorithm that achieves an
$\tilde{O}(n^{\eps})$ approximation for any $\eps=\Omega(\log\log n/\log n)$ in
time $n^{O(1/\eps)}$. In particular, we obtain poly-logarithmic approximation
in quasi-polynomial time, and for any constant $\eps &gt; 0$, we obtain
$O(n^{\eps})$ approximation in polynomial time. An interesting aspect of our
algorithm is that we use as a building block a linear program whose integrality
gap is $\Omega(\sqrt m)$. We bypass this obstacle by iteratively using the
solutions produced by the LP to construct new instances with significantly
smaller integrality gaps, eventually obtaining the desired approximation.
  We also investigate the special case of the problem, where every item has a
non-zero utility for at most two agents. We show that even in this restricted
setting the problem is hard to approximate upto any factor better tha 2, and
show a factor $(2+\eps)$-approximation algorithm running in time
$poly(n,1/\eps)$ for any $\eps&gt;0$. This special case can be cast as a graph
edge orientation problem, and our algorithm can be viewed as a generalization
of Eulerian orientations to weighted graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0213</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0213</id><created>2009-01-01</created><authors><author><keyname>Ling</keyname><forenames>Maurice HT</forenames></author><author><keyname>Lefevre</keyname><forenames>Christophe</forenames></author><author><keyname>Nicholas</keyname><forenames>Kevin R.</forenames></author></authors><title>Filtering Microarray Correlations by Statistical Literature Analysis
  Yields Potential Hypotheses for Lactation Research</title><categories>cs.DL cs.DB</categories><journal-ref>Ling, MHT, Lefevre, C, Nicholas, KR. 2008. Filtering Microarray
  Correlations by Statistical Literature Analysis Yields Potential Hypotheses
  for Lactation Research. The Python Papers 3(3): 4</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Our results demonstrated that a previously reported protein name
co-occurrence method (5-mention PubGene) which was not based on a hypothesis
testing framework, it is generally statistically more significant than the 99th
percentile of Poisson distribution-based method of calculating co-occurrence.
It agrees with previous methods using natural language processing to extract
protein-protein interaction from text as more than 96% of the interactions
found by natural language processing methods to overlap with the results from
5-mention PubGene method. However, less than 2% of the gene co-expressions
analyzed by microarray were found from direct co-occurrence or interaction
information extraction from the literature. At the same time, combining
microarray and literature analyses, we derive a novel set of 7 potential
functional protein-protein interactions that had not been previously described
in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0220</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0220</id><created>2009-01-02</created><authors><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author><author><keyname>Nair</keyname><forenames>Chandra</forenames></author></authors><title>Comments on &quot;Broadcast Channels with Arbitrarily Correlated Sources&quot;</title><categories>cs.IT math.IT</categories><comments>3 pages, 1 figure, submitted for presentation at the 2009 IEEE
  International Symposium on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Marton-Gelfand-Pinsker inner bound on the capacity region of broadcast
channels was extended by Han-Costa to include arbitrarily correlated sources
where the capacity region is replaced by an admissible source region. The main
arguments of Han-Costa are correct but unfortunately the authors overlooked an
inequality in their derivation. The corrected region is presented and the
absence of the omitted inequality is shown to sometimes admit sources that are
not admissible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0222</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0222</id><created>2009-01-02</created><authors><author><keyname>Ma</keyname><forenames>Liang</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Bennis</keyname><forenames>Fouad</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Zhang</keyname><forenames>Wei</forenames><affiliation>DIE</affiliation></author></authors><title>Dynamic Muscle Fatigue Evaluation in Virtual Working Environment</title><categories>cs.RO</categories><proxy>ccsd hal-00349573</proxy><journal-ref>International Journal of Industrial Ergonomics 39, 1 (2009)
  211-220</journal-ref><doi>10.1016/j.ergon.2008.04.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Musculoskeletal disorder (MSD) is one of the major health problems in
mechanical work especially in manual handling jobs. Muscle fatigue is believed
to be the main reason for MSD. Posture analysis techniques have been used to
expose MSD risks of the work, but most of the conventional methods are only
suitable for static posture analysis. Meanwhile the subjective influences from
the inspectors can result differences in the risk assessment. Another
disadvantage is that the evaluation has to be taken place in the workshop, so
it is impossible to avoid some design defects before data collection in the
field environment and it is time consuming. In order to enhance the efficiency
of ergonomic MSD risk evaluation and avoid subjective influences, we develop a
new muscle fatigue model and a new fatigue index to evaluate the human muscle
fatigue during manual handling jobs in this paper. Our new fatigue model is
closely related to the muscle load during working procedure so that it can be
used to evaluate the dynamic working process. This muscle fatigue model is
mathematically validated and it is to be further experimental validated and
integrated into a virtual working environment to evaluate the muscle fatigue
and predict the MSD risks quickly and objectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0252</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0252</id><created>2009-01-02</created><authors><author><keyname>Leshem</keyname><forenames>Amir</forenames></author><author><keyname>Goldberger</keyname><forenames>Jacob</forenames></author></authors><title>MIMO decoding based on stochastic reconstruction from multiple
  projections</title><categories>cs.IT cs.LG math.IT</categories><comments>To appear in Proc. of ICASSP 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Least squares (LS) fitting is one of the most fundamental techniques in
science and engineering. It is used to estimate parameters from multiple noisy
observations. In many problems the parameters are known a-priori to be bounded
integer valued, or they come from a finite set of values on an arbitrary finite
lattice. In this case finding the closest vector becomes NP-Hard problem. In
this paper we propose a novel algorithm, the Tomographic Least Squares Decoder
(TLSD), that not only solves the ILS problem, better than other sub-optimal
techniques, but also is capable of providing the a-posteriori probability
distribution for each element in the solution vector. The algorithm is based on
reconstruction of the vector from multiple two-dimensional projections. The
projections are carefully chosen to provide low computational complexity.
Unlike other iterative techniques, such as the belief propagation, the proposed
algorithm has ensured convergence. We also provide simulated experiments
comparing the algorithm to other sub-optimal algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0269</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0269</id><created>2009-01-02</created><authors><author><keyname>Lucani</keyname><forenames>Daniel E.</forenames></author><author><keyname>Stojanovic</keyname><forenames>Milica</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author></authors><title>Random Linear Network Coding For Time Division Duplexing: Energy
  Analysis</title><categories>cs.IT math.IT</categories><comments>5 pages, 6 figures, Accepted to ICC 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the energy performance of random linear network coding for time
division duplexing channels. We assume a packet erasure channel with nodes that
cannot transmit and receive information simultaneously. The sender transmits
coded data packets back-to-back before stopping to wait for the receiver to
acknowledge the number of degrees of freedom, if any, that are required to
decode correctly the information. Our analysis shows that, in terms of mean
energy consumed, there is an optimal number of coded data packets to send
before stopping to listen. This number depends on the energy needed to transmit
each coded packet and the acknowledgment (ACK), probabilities of packet and ACK
erasure, and the number of degrees of freedom that the receiver requires to
decode the data. We show that its energy performance is superior to that of a
full-duplex system. We also study the performance of our scheme when the number
of coded packets is chosen to minimize the mean time to complete transmission
as in [1]. Energy performance under this optimization criterion is found to be
close to optimal, thus providing a good trade-off between energy and time
required to complete transmissions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0275</identifier>
 <datestamp>2015-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0275</id><created>2009-01-02</created><updated>2009-04-16</updated><authors><author><keyname>Harrison</keyname><forenames>Willie K</forenames></author><author><keyname>McLaughlin</keyname><forenames>Steven W.</forenames></author></authors><title>Physical-Layer Security: Combining Error Control Coding and Cryptography</title><categories>cs.IT cs.CR math.IT</categories><comments>12 pages, 5 figures. Submitted and accepted to the International
  Conference on Communications (ICC) 2009. v2: equivalent to the version that
  will be published in the conference proceedings. Has some altered notation
  from version 1 as well as slight changes in the wording to make the paper
  more readable and easier to understand</comments><acm-class>H.1.1; K.6.5</acm-class><doi>10.1109/ICC.2009.5199337</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider tandem error control coding and cryptography in the
setting of the {\em wiretap channel} due to Wyner. In a typical communications
system a cryptographic application is run at a layer above the physical layer
and assumes the channel is error free. However, in any real application the
channels for friendly users and passive eavesdroppers are not error free and
Wyner's wiretap model addresses this scenario. Using this model, we show the
security of a common cryptographic primitive, i.e. a keystream generator based
on linear feedback shift registers (LFSR), can be strengthened by exploiting
properties of the physical layer. A passive eavesdropper can be made to
experience greater difficulty in cracking an LFSR-based cryptographic system
insomuch that the computational complexity of discovering the secret key
increases by orders of magnitude, or is altogether infeasible. This result is
shown for two fast correlation attacks originally presented by Meier and
Staffelbach, in the context of channel errors due to the wiretap channel model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0290</identifier>
 <datestamp>2009-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0290</id><created>2009-01-02</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Tapus</keyname><forenames>Nicolae</forenames></author></authors><title>Offline Algorithmic Techniques for Several Content Delivery Problems in
  Some Restricted Types of Distributed Systems</title><categories>cs.DS cs.NI</categories><comments>Proceedings of the International Workshop on High Performance Grid
  Middleware (HiPerGrid), pp. 65-72, Bucharest, Romania, 21-22 November, 2008.
  (ISSN: 2065-0701)</comments><acm-class>G.2.2; G.2.1</acm-class><journal-ref>Proceedings of the International Workshop on High Performance Grid
  Middleware (HiPerGrid), pp. 65-72, Bucharest, Romania, 2008. (ISSN:
  2065-0701)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider several content delivery problems (broadcast and
multicast, in particular) in some restricted types of distributed systems (e.g.
optical Grids and wireless sensor networks with tree-like topologies). For each
problem we provide efficient algorithmic techniques for computing optimal
content delivery strategies. The techniques we present are offline, which means
that they can be used only when full information is available and the problem
parameters do not fluctuate too much.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0291</identifier>
 <datestamp>2009-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0291</id><created>2009-01-02</created><authors><author><keyname>Carpen-Amarie</keyname><forenames>Alexandra</forenames></author><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Cristea</keyname><forenames>Valentin</forenames></author></authors><title>An Algorithm for File Transfer Scheduling in Grid Environments</title><categories>cs.NI cs.DC cs.DS</categories><comments>Proceedings of the International Workshop on High Performance Grid
  Middleware (HiPerGrid), pp. 33-40, Bucharest, Romania, 21-22 November, 2008.
  (ISSN: 2065-0701)</comments><acm-class>C.2.3; C.2.4</acm-class><journal-ref>Proceedings of the International Workshop on High Performance Grid
  Middleware (HiPerGrid), pp. 33-40, Bucharest, Romania, 2008. (ISSN:
  2065-0701)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the data transfer scheduling problem for Grid
environments, presenting a centralized scheduler developed with dynamic and
adaptive features. The algorithm offers a reservation system for user transfer
requests that allocates them transfer times and bandwidth, according to the
network topology and the constraints the user specified for the requests. This
paper presents the projects related to the data transfer field, the design of
the framework for which the scheduler was built, the main features of the
scheduler, the steps for transfer requests rescheduling and two tests that
illustrate the system's behavior for different types of transfer requests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0296</identifier>
 <datestamp>2009-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0296</id><created>2009-01-02</created><authors><author><keyname>Kong</keyname><forenames>Joseph S.</forenames></author><author><keyname>Sarshar</keyname><forenames>Nima</forenames></author><author><keyname>Roychowdhury</keyname><forenames>Vwani P.</forenames></author></authors><title>Experience versus Talent Shapes the Structure of the Web</title><categories>cs.CY cs.IR physics.soc-ph</categories><journal-ref>Proceedings of the National Academy of Sciences (PNAS), Vol. 105,
  Pages 13724-13729, 2008</journal-ref><doi>10.1073/pnas.0805921105</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use sequential large-scale crawl data to empirically investigate and
validate the dynamics that underlie the evolution of the structure of the web.
We find that the overall structure of the web is defined by an intricate
interplay between experience or entitlement of the pages (as measured by the
number of inbound hyperlinks a page already has), inherent talent or fitness of
the pages (as measured by the likelihood that someone visiting the page would
give a hyperlink to it), and the continual high rates of birth and death of
pages on the web. We find that the web is conservative in judging talent and
the overall fitness distribution is exponential, showing low variability. The
small variance in talent, however, is enough to lead to experience
distributions with high variance: The preferential attachment mechanism
amplifies these small biases and leads to heavy-tailed power-law (PL) inbound
degree distributions over all pages, as well as over pages that are of the same
age. The balancing act between experience and talent on the web allows newly
introduced pages with novel and interesting content to grow quickly and surpass
older pages. In this regard, it is much like what we observe in high-mobility
and meritocratic societies: People with entitlement continue to have access to
the best resources, but there is just enough screening for fitness that allows
for talented winners to emerge and join the ranks of the leaders. Finally, we
show that the fitness estimates have potential practical applications in
ranking query results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0317</identifier>
 <datestamp>2009-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0317</id><created>2009-01-03</created><authors><author><keyname>Misra</keyname><forenames>Janardan</forenames></author></authors><title>Design of a P System based Artificial Graph Chemistry</title><categories>cs.NE cs.AI</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificial Chemistries (ACs) are symbolic chemical metaphors for the
exploration of Artificial Life, with specific focus on the origin of life. In
this work we define a P system based artificial graph chemistry to understand
the principles leading to the evolution of life-like structures in an AC set up
and to develop a unified framework to characterize and classify symbolic
artificial chemistries by devising appropriate formalism to capture semantic
and organizational information. An extension of P system is considered by
associating probabilities with the rules providing the topological framework
for the evolution of a labeled undirected graph based molecular reaction
semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0318</identifier>
 <datestamp>2009-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0318</id><created>2009-01-03</created><authors><author><keyname>Misra</keyname><forenames>Janrdan</forenames></author></authors><title>Thoughts on an Unified Framework for Artificial Chemistries</title><categories>cs.AI cs.IT math.IT nlin.AO</categories><comments>17 papges</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificial Chemistries (ACs) are symbolic chemical metaphors for the
exploration of Artificial Life, with specific focus on the problem of
biogenesis or the origin of life. This paper presents authors thoughts towards
defining a unified framework to characterize and classify symbolic artificial
chemistries by devising appropriate formalism to capture semantic and
organizational information. We identify three basic high level abstractions in
initial proposal for this framework viz., information, computation, and
communication. We present an analysis of two important notions of information,
namely, Shannon's Entropy and Algorithmic Information, and discuss inductive
and deductive approaches for defining the framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0339</identifier>
 <datestamp>2009-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0339</id><created>2009-01-03</created><updated>2009-05-03</updated><authors><author><keyname>Riazanov</keyname><forenames>Alexandre</forenames></author></authors><title>Resolution-based Query Answering for Semantic Access to Relational
  Databases: A Research Note</title><categories>cs.LO cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of semantic querying of relational databases (RDB)
modulo knowledge bases using very expressive knowledge representation
formalisms, such as full first-order logic or its various fragments. We propose
to use a first-order logic (FOL) reasoner for computing schematic answers to
deductive queries, with the subsequent instantiation of these schematic answers
using a conventional relational DBMS. In this research note, we outline the
main idea of this technique -- using abstractions of databases and constrained
clauses for deriving schematic answers. The proposed method can be directly
used with regular RDB, including legacy databases. Moreover, we propose it as a
potential basis for an efficient Web-scale semantic search technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0349</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0349</id><created>2009-01-03</created><authors><author><keyname>Wang</keyname><forenames>Xingang</forenames></author><author><keyname>Guan</keyname><forenames>Shuguang</forenames></author><author><keyname>Lai</keyname><forenames>Choy Heng</forenames></author></authors><title>Protecting infrastructure networks from cost-based attacks</title><categories>cs.NI</categories><comments>5 pages, 4 figures</comments><doi>10.1088/1367-2630/11/3/033006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been known that heterogeneous networks are vulnerable to the
intentional removal of a small fraction of highly connected or loaded nodes,
which implies that, to protect a network effectively, a few important nodes
should be allocated with more defense resources than the others. However, if
too many resources are allocated to the few important nodes, the numerous
less-important nodes will be less protected, which, when attacked all together,
still capable of causing a devastating damage. A natural question therefore is
how to efficiently distribute the limited defense resources among the network
nodes such that the network damage is minimized whatever attack strategy the
attacker may take. In this paper, taking into account the factor of attack
cost, we will revisit the problem of network security and search for efficient
network defense against the cost-based attacks. The study shows that, for a
general complex network, there will exist an optimal distribution of the
defense resources, with which the network is well protected from cost-based
attacks. Furthermore, it is found that the configuration of the optimal defense
is dependent on the network parameters. Specifically, network that has a larger
size, sparser connection and more heterogeneous structure will be more
benefited from the defense optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0355</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0355</id><created>2009-01-04</created><authors><author><keyname>Roca</keyname><forenames>Carlos P.</forenames></author><author><keyname>Cuesta</keyname><forenames>Jose A.</forenames></author><author><keyname>Sanchez</keyname><forenames>Angel</forenames></author></authors><title>Promotion of cooperation on networks? The myopic best response case</title><categories>q-bio.PE cs.GT physics.soc-ph</categories><doi>10.1140/epjb/e2009-00189-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the issue of the effects of considering a network of contacts on
the emergence of cooperation on social dilemmas under myopic best response
dynamics. We begin by summarizing the main features observed under less
intellectually demanding dynamics, pointing out their most relevant general
characteristics. Subsequently we focus on the new framework of best response.
By means of an extensive numerical simulation program we show that, contrary to
the rest of dynamics considered so far, best response is largely unaffected by
the underlying network, which implies that, in most cases, no promotion of
cooperation is found with this dynamics. We do find, however, nontrivial
results differing from the well-mixed population in the case of coordination
games on lattices, which we explain in terms of the formation of spatial
clusters and the conditions for their advancement, subsequently discussing
their relevance to other networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0358</identifier>
 <datestamp>2009-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0358</id><created>2009-01-04</created><authors><author><keyname>Marteau</keyname><forenames>Pierre-Fran&#xe7;ois</forenames><affiliation>VALORIA</affiliation></author><author><keyname>M&#xe9;nier</keyname><forenames>Gilbas</forenames><affiliation>VALORIA</affiliation></author><author><keyname>Popovici</keyname><forenames>Eugen</forenames><affiliation>VALORIA</affiliation></author></authors><title>Weighted Naive Bayes Model for Semi-Structured Document Categorization</title><categories>cs.IR</categories><proxy>ccsd hal-00349731</proxy><acm-class>H.3.3</acm-class><journal-ref>1st International Conference on Multidisciplinary Information
  Sciences and Technologies InSciT2006, Merida : Espagne (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is the supervised classification of semi-structured
data. A formal model based on bayesian classification is developed while
addressing the integration of the document structure into classification tasks.
We define what we call the structural context of occurrence for unstructured
data, and we derive a recursive formulation in which parameters are used to
weight the contribution of structural element relatively to the others. A
simplified version of this formal model is implemented to carry out textual
documents classification experiments. First results show, for a adhoc weighting
strategy, that the structural context of word occurrences has a significant
impact on classification results comparing to the performance of a simple
multinomial naive Bayes classifier. The proposed implementation competes on the
Reuters-21578 data with the SVM classifier associated or not with the splitting
of structural components. These results encourage exploring the learning of
acceptable weighting strategies for this model, in particular boosting
strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0373</identifier>
 <datestamp>2009-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0373</id><created>2009-01-04</created><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>ELM, Lip</affiliation></author></authors><title>Highly Undecidable Problems For Infinite Computations</title><categories>cs.LO cs.CC math.LO</categories><comments>to appear in RAIRO-Theoretical Informatics and Applications</comments><proxy>ccsd hal-00349761</proxy><journal-ref>RAIRO - Theoretical Informatics and Applications 43, 2 (2009)
  339-364</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that many classical decision problems about 1-counter
omega-languages, context free omega-languages, or infinitary rational
relations, are $\Pi_2^1$-complete, hence located at the second level of the
analytical hierarchy, and &quot;highly undecidable&quot;. In particular, the universality
problem, the inclusion problem, the equivalence problem, the determinizability
problem, the complementability problem, and the unambiguity problem are all
$\Pi_2^1$-complete for context-free omega-languages or for infinitary rational
relations. Topological and arithmetical properties of 1-counter
omega-languages, context free omega-languages, or infinitary rational
relations, are also highly undecidable. These very surprising results provide
the first examples of highly undecidable problems about the behaviour of very
simple finite machines like 1-counter automata or 2-tape automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0401</identifier>
 <datestamp>2009-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0401</id><created>2009-01-04</created><authors><author><keyname>Giffin</keyname><forenames>Adom</forenames></author></authors><title>From Physics to Economics: An Econometric Example Using Maximum Relative
  Entropy</title><categories>q-fin.ST cs.IT math.IT physics.data-an physics.pop-ph stat.CO stat.ME</categories><comments>This paper has been accepted in Physica A. 19 Pages, 3 Figures</comments><journal-ref>Physica A 388 (2009), pp. 1610-1620</journal-ref><doi>10.1016/j.physa.2008.12.066</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Econophysics, is based on the premise that some ideas and methods from
physics can be applied to economic situations. We intend to show in this paper
how a physics concept such as entropy can be applied to an economic problem. In
so doing, we demonstrate how information in the form of observable data and
moment constraints are introduced into the method of Maximum relative Entropy
(MrE). A general example of updating with data and moments is shown. Two
specific econometric examples are solved in detail which can then be used as
templates for real world problems. A numerical example is compared to a large
deviation solution which illustrates some of the advantages of the MrE method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0492</identifier>
 <datestamp>2009-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0492</id><created>2009-01-05</created><authors><author><keyname>Yin</keyname><forenames>Changchuan</forenames></author><author><keyname>Gao</keyname><forenames>Long</forenames></author><author><keyname>Liu</keyname><forenames>Tie</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Transmission Capacities for Overlaid Wireless Ad Hoc Networks with
  Outage Constraints</title><categories>cs.IT math.IT</categories><comments>6 pages, 5 figures, accepted by IEEE ICC 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the transmission capacities of two coexisting wireless networks (a
primary network vs. a secondary network) that operate in the same geographic
region and share the same spectrum. We define transmission capacity as the
product among the density of transmissions, the transmission rate, and the
successful transmission probability (1 minus the outage probability). The
primary (PR) network has a higher priority to access the spectrum without
particular considerations for the secondary (SR) network, where the SR network
limits its interference to the PR network by carefully controlling the density
of its transmitters. Assuming that the nodes are distributed according to
Poisson point processes and the two networks use different transmission ranges,
we quantify the transmission capacities for both of these two networks and
discuss their tradeoff based on asymptotic analyses. Our results show that if
the PR network permits a small increase of its outage probability, the sum
transmission capacity of the two networks (i.e., the overall spectrum
efficiency per unit area) will be boosted significantly over that of a single
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0498</identifier>
 <datestamp>2010-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0498</id><created>2009-01-05</created><authors><author><keyname>Goncalves</keyname><forenames>Bruno</forenames></author><author><keyname>Ramasco</keyname><forenames>Jose J.</forenames></author></authors><title>Towards the characterization of individual users through Web analytics</title><categories>cs.HC cs.CY physics.soc-ph</categories><comments>8 pages, 4 figures. To appear in Proceeding of Complex'09</comments><journal-ref>Complex Sciences, 2247-2254 (2009)</journal-ref><doi>10.1007/978-3-642-02469-6_102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We perform an analysis of the way individual users navigate in the Web. We
focus primarily in the temporal patterns of they return to a given page. The
return probability as a function of time as well as the distribution of time
intervals between consecutive visits are measured and found to be independent
of the level of activity of single users. The results indicate a rich variety
of individual behaviors and seem to preclude the possibility of defining a
characteristic frequency for each user in his/her visits to a single site.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0501</identifier>
 <datestamp>2009-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0501</id><created>2009-01-05</created><updated>2009-01-06</updated><authors><author><keyname>K&#xfc;hnrich</keyname><forenames>Morten</forenames></author><author><keyname>Schwoon</keyname><forenames>Stefan</forenames></author><author><keyname>Srba</keyname><forenames>Ji&#x159;&#xed;</forenames></author><author><keyname>Kiefer</keyname><forenames>Stefan</forenames></author></authors><title>Interprocedural Dataflow Analysis over Weight Domains with Infinite
  Descending Chains</title><categories>cs.DS</categories><comments>technical report for a FOSSACS'09 publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study generalized fixed-point equations over idempotent semirings and
provide an efficient algorithm for the detection whether a sequence of Kleene's
iterations stabilizes after a finite number of steps. Previously known
approaches considered only bounded semirings where there are no infinite
descending chains. The main novelty of our work is that we deal with semirings
without the boundedness restriction. Our study is motivated by several
applications from interprocedural dataflow analysis. We demonstrate how the
reachability problem for weighted pushdown automata can be reduced to solving
equations in the framework mentioned above and we describe a few applications
to demonstrate its usability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0521</identifier>
 <datestamp>2009-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0521</id><created>2009-01-05</created><authors><author><keyname>Koch</keyname><forenames>Tobias</forenames></author><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author></authors><title>On Multipath Fading Channels at High SNR</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work studies the capacity of multipath fading channels. A noncoherent
channel model is considered, where neither the transmitter nor the receiver is
cognizant of the realization of the path gains, but both are cognizant of their
statistics. It is shown that if the delay spread is large in the sense that the
variances of the path gains decay exponentially or slower, then capacity is
bounded in the signal-to-noise ratio (SNR). For such channels, capacity does
not tend to infinity as the SNR tends to infinity. In contrast, if the
variances of the path gains decay faster than exponentially, then capacity is
unbounded in the SNR. It is further demonstrated that if the number of paths is
finite, then at high SNR capacity grows double-logarithmically with the SNR,
and the capacity pre-loglog, defined as the limiting ratio of capacity to
log(log(SNR)) as SNR tends to infinity, is 1 irrespective of the number of
paths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0529</identifier>
 <datestamp>2009-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0529</id><created>2009-01-05</created><authors><author><keyname>Gujar</keyname><forenames>Sujit</forenames></author><author><keyname>Madhavan</keyname><forenames>C E Veni</forenames></author></authors><title>Measures for classification and detection in steganalysis</title><categories>cs.OH cs.CR</categories><comments>15 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Still and multi-media images are subject to transformations for compression,
steganographic embedding and digital watermarking. In a major program of
activities we are engaged in the modeling, design and analysis of digital
content. Statistical and pattern classification techniques should be combined
with understanding of run length, transform coding techniques, and also
encryption techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0536</identifier>
 <datestamp>2009-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0536</id><created>2009-01-05</created><updated>2009-01-26</updated><authors><author><keyname>Korada</keyname><forenames>Satish Babu</forenames></author><author><keyname>Sasoglu</keyname><forenames>Eren</forenames></author><author><keyname>Urbanke</keyname><forenames>Rudiger</forenames></author></authors><title>Polar Codes: Characterization of Exponent, Bounds, and Constructions</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, minor updates</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polar codes were recently introduced by Ar\i kan. They achieve the capacity
of arbitrary symmetric binary-input discrete memoryless channels under a low
complexity successive cancellation decoding strategy. The original polar code
construction is closely related to the recursive construction of Reed-Muller
codes and is based on the $2 \times 2$ matrix $\bigl[ 1 &amp;0 1&amp; 1 \bigr]$. It was
shown by Ar\i kan and Telatar that this construction achieves an error exponent
of $\frac12$, i.e., that for sufficiently large blocklengths the error
probability decays exponentially in the square root of the length. It was
already mentioned by Ar\i kan that in principle larger matrices can be used to
construct polar codes. A fundamental question then is to see whether there
exist matrices with exponent exceeding $\frac12$. We first show that any $\ell
\times \ell$ matrix none of whose column permutations is upper triangular
polarizes symmetric channels. We then characterize the exponent of a given
square matrix and derive upper and lower bounds on achievable exponents. Using
these bounds we show that there are no matrices of size less than 15 with
exponents exceeding $\frac12$. Further, we give a general construction based on
BCH codes which for large $n$ achieves exponents arbitrarily close to 1 and
which exceeds $\frac12$ for size 16.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0541</identifier>
 <datestamp>2009-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0541</id><created>2009-01-05</created><authors><author><keyname>Ying</keyname><forenames>Leslie</forenames></author><author><keyname>Zou</keyname><forenames>Yi Ming</forenames></author></authors><title>Linear Transformations and Restricted Isometry Property</title><categories>cs.IT math.IT</categories><msc-class>94A20; 94A08</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Restricted Isometry Property (RIP) introduced by Cand\'es and Tao is a
fundamental property in compressed sensing theory. It says that if a sampling
matrix satisfies the RIP of certain order proportional to the sparsity of the
signal, then the original signal can be reconstructed even if the sampling
matrix provides a sample vector which is much smaller in size than the original
signal. This short note addresses the problem of how a linear transformation
will affect the RIP. This problem arises from the consideration of extending
the sensing matrix and the use of compressed sensing in different bases. As an
application, the result is applied to the redundant dictionary setting in
compressed sensing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0573</identifier>
 <datestamp>2009-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0573</id><created>2009-01-05</created><authors><author><keyname>Rodriguez</keyname><forenames>Virgilio</forenames></author><author><keyname>Mathar</keyname><forenames>Rudolf</forenames></author><author><keyname>Schmeink</keyname><forenames>Anke</forenames></author></authors><title>Asymptotic stability and capacity results for a broad family of power
  adjustment rules: Expanded discussion</title><categories>cs.IT math.FA math.IT</categories><comments>9 pages; 3 figures</comments><msc-class>94A05; 91A80</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In any wireless communication environment in which a transmitter creates
interference to the others, a system of non-linear equations arises. Its form
(for 2 terminals) is p1=g1(p2;a1) and p2=g2(p1;a2), with p1, p2 power levels;
a1, a2 quality-of-service (QoS) targets; and g1, g2 functions akin to
&quot;interference functions&quot; in Yates (JSAC, 13(7):1341-1348, 1995). Two
fundamental questions are: (1) does the system have a solution?; and if so, (2)
what is it?. (Yates, 1995) shows that IF the system has a solution, AND the
&quot;interference functions&quot; satisfy some simple properties, a &quot;greedy&quot; power
adjustment process will always converge to a solution. We show that, if the
power-adjustment functions have similar properties to those of (Yates, 1995),
and satisfy a condition of the simple form gi(1,1,...,1)&lt;1, then the system has
a unique solution that can be found iteratively. As examples, feasibility
conditions for macro-diversity and multiple-connection receptions are given.
Informally speaking, we complement (Yates, 1995) by adding the feasibility
condition it lacked. Our analysis is based on norm concepts, and the Banach's
contraction-mapping principle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0585</identifier>
 <datestamp>2009-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0585</id><created>2009-01-05</created><authors><author><keyname>Malmgren</keyname><forenames>R. Dean</forenames></author><author><keyname>Stouffer</keyname><forenames>Daniel B.</forenames></author><author><keyname>Motter</keyname><forenames>Adilson E.</forenames></author><author><keyname>Amaral</keyname><forenames>Luis A. N.</forenames></author></authors><title>A Poissonian explanation for heavy-tails in e-mail communication</title><categories>physics.soc-ph cs.CY physics.data-an</categories><comments>9 pages, 5 figures</comments><journal-ref>PNAS 105(47): 18153-18158 (2008)</journal-ref><doi>10.1073/pnas.0800332105</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Patterns of deliberate human activity and behavior are of utmost importance
in areas as diverse as disease spread, resource allocation, and emergency
response. Because of its widespread availability and use, e-mail correspondence
provides an attractive proxy for studying human activity. Recently, it was
reported that the probability density for the inter-event time $\tau$ between
consecutively sent e-mails decays asymptotically as $\tau^{-\alpha}$, with
$\alpha \approx 1$. The slower than exponential decay of the inter-event time
distribution suggests that deliberate human activity is inherently
non-Poissonian. Here, we demonstrate that the approximate power-law scaling of
the inter-event time distribution is a consequence of circadian and weekly
cycles of human activity. We propose a cascading non-homogeneous Poisson
process which explicitly integrates these periodic patterns in activity with an
individual's tendency to continue participating in an activity. Using standard
statistical techniques, we show that our model is consistent with the empirical
data. Our findings may also provide insight into the origins of heavy-tailed
distributions in other complex systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0595</identifier>
 <datestamp>2009-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0595</id><created>2009-01-06</created><updated>2009-04-28</updated><authors><author><keyname>Nair</keyname><forenames>Chandra</forenames></author></authors><title>Capacity regions of two new classes of 2-receiver broadcast channels</title><categories>cs.IT math.IT</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by a simple broadcast channel, we generalize the notions of a less
noisy receiver and a more capable receiver to an essentially less noisy
receiver and an essentially more capable receiver respectively. We establish
the capacity regions of these classes by borrowing on existing techniques to
obtain the characterization of the capacity region for certain new and
interesting classes of broadcast channels. We also establish the relationships
between the new classes and the existing classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0597</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0597</id><created>2009-01-06</created><updated>2010-09-13</updated><authors><author><keyname>Rastegar</keyname><forenames>Reza</forenames></author></authors><title>On the Optimal Convergence Probability of Univariate Estimation of
  Distribution Algorithms</title><categories>cs.NE cs.AI</categories><comments>evolutionary computation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we obtain bounds on the probability of convergence to the
optimal solution for the compact Genetic Algorithm (cGA) and the Population
Based Incremental Learning (PBIL). We also give a sufficient condition for
convergence of these algorithms to the optimal solution and compute a range of
possible values of the parameters of these algorithms for which they converge
to the optimal solution with a confidence level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0598</identifier>
 <datestamp>2009-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0598</id><created>2009-01-06</created><authors><author><keyname>Rastegar</keyname><forenames>Reza</forenames></author><author><keyname>Hariri</keyname><forenames>Arash</forenames></author></authors><title>A Step Forward in Studying the Compact Genetic Algorithm</title><categories>cs.NE cs.AI</categories><comments>13 Pages</comments><journal-ref>Evolutionary Computation (2006),Vol 14, No 3, 277-290</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The compact Genetic Algorithm (cGA) is an Estimation of Distribution
Algorithm that generates offspring population according to the estimated
probabilistic model of the parent population instead of using traditional
recombination and mutation operators. The cGA only needs a small amount of
memory; therefore, it may be quite useful in memory-constrained applications.
This paper introduces a theoretical framework for studying the cGA from the
convergence point of view in which, we model the cGA by a Markov process and
approximate its behavior using an Ordinary Differential Equation (ODE). Then,
we prove that the corresponding ODE converges to local optima and stays there.
Consequently, we conclude that the cGA will converge to the local optima of the
function to be optimized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0608</identifier>
 <datestamp>2010-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0608</id><created>2009-01-06</created><updated>2010-01-29</updated><authors><author><keyname>Han</keyname><forenames>Te Sun</forenames></author></authors><title>Multicasting correlated multi-source to multi-sink over a network</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of network coding with multicast of a single source to multisink
has first been studied by Ahlswede, Cai, Li and Yeung in 2000, in which they
have established the celebrated max-flow mini-cut theorem on non-physical
information flow over a network of independent channels. On the other hand, in
1980, Han has studied the case with correlated multisource and a single sink
from the viewpoint of polymatroidal functions in which a necessary and
sufficient condition has been demonstrated for reliable transmission over the
network. This paper presents an attempt to unify both cases, which leads to
establish a necessary and sufficient condition for reliable transmission over a
network multicasting correlated multisource to multisink. Here, the problem of
separation of source coding and channel coding is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0633</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0633</id><created>2009-01-06</created><updated>2012-01-18</updated><authors><author><keyname>Kappen</keyname><forenames>B.</forenames></author><author><keyname>Gomez</keyname><forenames>V.</forenames></author><author><keyname>Opper</keyname><forenames>M.</forenames></author></authors><title>Optimal control as a graphical model inference problem</title><categories>math.OC cs.SY</categories><comments>26 pages, 12 Figures; Machine Learning Journal (2012)</comments><acm-class>F.1.2; G.3; I.2.8</acm-class><doi>10.1007/s10994-012-5278-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We reformulate a class of non-linear stochastic optimal control problems
introduced by Todorov (2007) as a Kullback-Leibler (KL) minimization problem.
As a result, the optimal control computation reduces to an inference
computation and approximate inference methods can be applied to efficiently
compute approximate optimal controls. We show how this KL control theory
contains the path integral control method as a special case. We provide an
example of a block stacking task and a multi-agent cooperative game where we
demonstrate how approximate inference can be successfully applied to instances
that are too complex for exact computation. We discuss the relation of the KL
control approach to other inference approaches to control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0643</identifier>
 <datestamp>2009-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0643</id><created>2009-01-06</created><authors><author><keyname>Altug</keyname><forenames>Yucel</forenames></author><author><keyname>Kozat</keyname><forenames>S. Serdar</forenames></author><author><keyname>Mihcak</keyname><forenames>M. Kivanc</forenames></author></authors><title>An Information Theoretic Analysis of Single Transceiver Passive RFID
  Networks</title><categories>cs.IT math.IT</categories><comments>15 pages, 2 figures, submitted to IEEE Trans. Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study single transceiver passive RFID networks by modeling
the underlying physical system as a special cascade of a certain broadcast
channel (BCC) and a multiple access channel (MAC), using a &quot;nested codebook&quot;
structure in between. The particular application differentiates this
communication setup from an ordinary cascade of a BCC and a MAC, and requires
certain structures such as &quot;nested codebooks&quot;, impurity channels or additional
power constraints. We investigate this problem both for discrete alphabets,
where we characterize the achievable rate region, as well as for continuous
alphabets with additive Gaussian noise, where we provide the capacity region.
Hence, we establish the maximal achievable error free communication rates for
this particular problem which constitutes the fundamental limit that is
achievable by any TDMA based RFID protocol and the achievable rate region for
any RFID protocol for the case of continuous alphabets under additive Gaussian
noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0702</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0702</id><created>2009-01-06</created><updated>2009-04-03</updated><authors><author><keyname>Yaakobi</keyname><forenames>Eitan</forenames></author><author><keyname>Vardy</keyname><forenames>Alexander</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author><author><keyname>Wolf</keyname><forenames>Jack K.</forenames></author></authors><title>Multidimensional Flash Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Flash memory is a non-volatile computer memory comprised of blocks of cells,
wherein each cell can take on q different levels corresponding to the number of
electrons it contains. Increasing the cell level is easy; however, reducing a
cell level forces all the other cells in the same block to be erased. This
erasing operation is undesirable and therefore has to be used as infrequently
as possible. We consider the problem of designing codes for this purpose, where
k bits are stored using a block of n cells with q levels each. The goal is to
maximize the number of bit writes before an erase operation is required. We
present an efficient construction of codes that can store an arbitrary number
of bits. Our construction can be viewed as an extension to multiple dimensions
of the earlier work of Jiang and Bruck, where single-dimensional codes that can
store only 2 bits were proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0733</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0733</id><created>2009-01-06</created><updated>2011-05-06</updated><authors><author><keyname>Martin</keyname><forenames>&#xc9;ric A.</forenames></author></authors><title>Contextual hypotheses and semantics of logic programs</title><categories>cs.LO cs.AI</categories><comments>To appear in Theory and Practice of Logic Programming (TPLP) 46
  pages, 3 figures</comments><msc-class>03B70 (Primary) 68T27 (Secondary)</msc-class><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Logic programming has developed as a rich field, built over a logical
substratum whose main constituent is a nonclassical form of negation, sometimes
coexisting with classical negation. The field has seen the advent of a number
of alternative semantics, with Kripke-Kleene semantics, the well-founded
semantics, the stable model semantics, and the answer-set semantics standing
out as the most successful. We show that all aforementioned semantics are
particular cases of a generic semantics, in a framework where classical
negation is the unique form of negation and where the literals in the bodies of
the rules can be `marked' to indicate that they can be the targets of
hypotheses. A particular semantics then amounts to choosing a particular
marking scheme and choosing a particular set of hypotheses. When a literal
belongs to the chosen set of hypotheses, all marked occurrences of that literal
in the body of a rule are assumed to be true, whereas the occurrences of that
literal that have not been marked in the body of the rule are to be derived in
order to contribute to the firing of the rule. Hence the notion of hypothetical
reasoning that is presented in this framework is not based on making global
assumptions, but more subtly on making local, contextual assumptions, taking
effect as indicated by the chosen marking scheme on the basis of the chosen set
of hypotheses. Our approach offers a unified view on the various semantics
proposed in logic programming, classical in that only classical negation is
used, and links the semantics of logic programs to mechanisms that endow
rule-based systems with the power to harness hypothetical reasoning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0734</identifier>
 <datestamp>2009-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0734</id><created>2009-01-06</created><authors><author><keyname>Babadi</keyname><forenames>Behtash</forenames></author><author><keyname>Kalouptsidis</keyname><forenames>Nicholas</forenames></author><author><keyname>Tarokh</keyname><forenames>Vahid</forenames></author></authors><title>SPARLS: A Low Complexity Recursive $\mathcal{L}_1$-Regularized Least
  Squares Algorithm</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a Recursive $\mathcal{L}_1$-Regularized Least Squares (SPARLS)
algorithm for the estimation of a sparse tap-weight vector in the adaptive
filtering setting. The SPARLS algorithm exploits noisy observations of the
tap-weight vector output stream and produces its estimate using an
Expectation-Maximization type algorithm. Simulation studies in the context of
channel estimation, employing multi-path wireless channels, show that the
SPARLS algorithm has significant improvement over the conventional widely-used
Recursive Least Squares (RLS) algorithm, in terms of both mean squared error
(MSE) and computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0749</identifier>
 <datestamp>2009-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0749</id><created>2009-01-06</created><updated>2009-03-07</updated><authors><author><keyname>Dai</keyname><forenames>Wei</forenames></author><author><keyname>Pham</keyname><forenames>Hoa Vinh</forenames></author><author><keyname>Milenkovic</keyname><forenames>Olgica</forenames></author></authors><title>Quantized Compressive Sensing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the average distortion introduced by scalar, vector, and entropy
coded quantization of compressive sensing (CS) measurements. The asymptotic
behavior of the underlying quantization schemes is either quantified exactly or
characterized via bounds. We adapt two benchmark CS reconstruction algorithms
to accommodate quantization errors, and empirically demonstrate that these
methods significantly reduce the reconstruction distortion when compared to
standard CS techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0753</identifier>
 <datestamp>2009-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0753</id><created>2009-01-06</created><authors><author><keyname>Jeon</keyname><forenames>Sung-eok</forenames></author><author><keyname>Ji</keyname><forenames>Chuanyi</forenames></author></authors><title>Distributed Preemption Decisions: Probabilistic Graphical Model,
  Algorithm and Near-Optimality</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperative decision making is a vision of future network management and
control. Distributed connection preemption is an important example where nodes
can make intelligent decisions on allocating resources and controlling traffic
flows for multi-class service networks. A challenge is that nodal decisions are
spatially dependent as traffic flows trespass multiple nodes in a network.
Hence the performance-complexity trade-off becomes important, i.e., how
accurate decisions are versus how much information is exchanged among nodes.
Connection preemption is known to be NP-complete. Centralized preemption is
optimal but computationally intractable. Decentralized preemption is
computationally efficient but may result in a poor performance. This work
investigates distributed preemption where nodes decide whether and which flows
to preempt using only local information exchange with neighbors. We develop,
based on the probabilistic graphical models, a near-optimal distributed
algorithm. The algorithm is used by each node to make collectively near-optimal
preemption decisions. We study trade-offs between near-optimal performance and
complexity that corresponds to the amount of information-exchange of the
distributed algorithm. The algorithm is validated by both analysis and
simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0760</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0760</id><created>2009-01-07</created><updated>2009-12-09</updated><authors><author><keyname>Davenport</keyname><forenames>Mark A.</forenames></author><author><keyname>Hegde</keyname><forenames>Chinmay</forenames></author><author><keyname>Duarte</keyname><forenames>Marco F.</forenames></author><author><keyname>Baraniuk</keyname><forenames>Richard G.</forenames></author></authors><title>A Theoretical Analysis of Joint Manifolds</title><categories>cs.LG cs.CV</categories><comments>24 pages, 4 figures. Corrected typo on grant number in
  acknowledgements, page 1</comments><report-no>TREE0901, Department of Electrical and Computer Engineering, Rice
  University</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The emergence of low-cost sensor architectures for diverse modalities has
made it possible to deploy sensor arrays that capture a single event from a
large number of vantage points and using multiple modalities. In many
scenarios, these sensors acquire very high-dimensional data such as audio
signals, images, and video. To cope with such high-dimensional data, we
typically rely on low-dimensional models. Manifold models provide a
particularly powerful model that captures the structure of high-dimensional
data when it is governed by a low-dimensional set of parameters. However, these
models do not typically take into account dependencies among multiple sensors.
We thus propose a new joint manifold framework for data ensembles that exploits
such dependencies. We show that simple algorithms can exploit the joint
manifold structure to improve their performance on standard signal processing
applications. Additionally, recent results concerning dimensionality reduction
for manifolds enable us to formulate a network-scalable data compression scheme
that uses random projections of the sensed data. This scheme efficiently fuses
the data from all sensors through the addition of such projections, regardless
of the data modalities and dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0763</identifier>
 <datestamp>2010-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0763</id><created>2009-01-07</created><updated>2010-08-31</updated><authors><author><keyname>Ren</keyname><forenames>Shaolei</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Distributed Power Allocation in Multi-User Multi-Channel Relay Networks</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the authors as they feel it inappropriate to
publish this paper for the time being.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0786</identifier>
 <datestamp>2009-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0786</id><created>2009-01-07</created><updated>2009-05-25</updated><authors><author><keyname>G&#xf3;mez</keyname><forenames>V.</forenames></author><author><keyname>Kappen</keyname><forenames>H. J.</forenames></author><author><keyname>Chertkov</keyname><forenames>M.</forenames></author></authors><title>Approximate inference on planar graphs using Loop Calculus and Belief
  Propagation</title><categories>cs.AI</categories><comments>23 pages, 10 figures. Submitted to Journal of Machine Learning
  Research. Proceedings version accepted for UAI 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce novel results for approximate inference on planar graphical
models using the loop calculus framework. The loop calculus (Chertkov and
Chernyak, 2006) allows to express the exact partition function of a graphical
model as a finite sum of terms that can be evaluated once the belief
propagation (BP) solution is known. In general, full summation over all
correction terms is intractable. We develop an algorithm for the approach
presented in (Certkov et al., 2008) which represents an efficient truncation
scheme on planar graphs and a new representation of the series in terms of
Pfaffians of matrices. We analyze the performance of the algorithm for the
partition function approximation for models with binary variables and pairwise
interactions on grids and other planar graphs. We study in detail both the loop
series and the equivalent Pfaffian series and show that the first term of the
Pfaffian series for the general, intractable planar model, can provide very
accurate approximations. The algorithm outperforms previous truncation schemes
of the loop series and is competitive with other state-of-the-art methods for
approximate inference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0824</identifier>
 <datestamp>2009-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0824</id><created>2009-01-07</created><updated>2009-07-21</updated><authors><author><keyname>Sta&#x144;czak</keyname><forenames>S&#x142;awomir</forenames></author><author><keyname>Kaliszan</keyname><forenames>Micha&#x142;</forenames></author><author><keyname>Bambos</keyname><forenames>Nicholas</forenames></author><author><keyname>Wiczanowski</keyname><forenames>Marcin</forenames></author></authors><title>A Characterization of Max-Min SIR-Balanced Power Allocation with
  Applications</title><categories>cs.IT math.IT</categories><comments>21 pages (onecolumn), 2 figures; changed (extended) content</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a power-controlled wireless network with an established network
topology in which the communication links (transmitter-receiver pairs) are
corrupted by the co-channel interference and background noise. We have fairly
general power constraints since the vector of transmit powers is confined to
belong to an arbitrary convex polytope. The interference is completely
determined by a so-called gain matrix. Assuming irreducibility of this gain
matrix, we provide an elegant characterization of the max-min SIR-balanced
power allocation under such general power constraints. This characterization
gives rise to two types of algorithms for computing the max-min SIR-balanced
power allocation. One of the algorithms is a utility-based power control
algorithm to maximize a weighted sum of the utilities of the link SIRs. Our
results show how to choose the weight vector and utility function so that the
utility-based solution is equal to the solution of the max-min SIR-balancing
problem. The algorithm is not amenable to distributed implementation as the
weights are global variables. In order to mitigate the problem of computing the
weight vector in distributed wireless networks, we point out a saddle point
characterization of the Perron root of some extended gain matrices and discuss
how this characterization can be used in the design of algorithms in which each
link iteratively updates its weight vector in parallel to the power control
recursion. Finally, the paper provides a basis for the development of
distributed power control and beamforming algorithms to find a global solution
of the max-min SIR-balancing problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0825</identifier>
 <datestamp>2009-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0825</id><created>2009-01-07</created><authors><author><keyname>Ma</keyname><forenames>Liang</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Bennis</keyname><forenames>Fouad</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Zhang</keyname><forenames>Wei</forenames><affiliation>DIE</affiliation></author><author><keyname>Guillaume</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>EADS</affiliation></author></authors><title>A new muscle fatigue and recovery model and its ergonomics application
  in human simulation</title><categories>cs.RO</categories><comments>IDMME - Virtual Concept, Beijing : Chine (2008)</comments><proxy>ccsd hal-00350663</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although automatic techniques have been employed in manufacturing industries
to increase productivity and efficiency, there are still lots of manual
handling jobs, especially for assembly and maintenance jobs. In these jobs,
musculoskeletal disorders (MSDs) are one of the major health problems due to
overload and cumulative physical fatigue. With combination of conventional
posture analysis techniques, digital human modelling and simulation (DHM)
techniques have been developed and commercialized to evaluate the potential
physical exposures. However, those ergonomics analysis tools are mainly based
on posture analysis techniques, and until now there is still no fatigue index
available in the commercial software to evaluate the physical fatigue easily
and quickly. In this paper, a new muscle fatigue and recovery model is proposed
and extended to evaluate joint fatigue level in manual handling jobs. A special
application case is described and analyzed by digital human simulation
technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0834</identifier>
 <datestamp>2010-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0834</id><created>2009-01-07</created><updated>2010-07-28</updated><authors><author><keyname>Wang</keyname><forenames>Ligong</forenames></author><author><keyname>Colbeck</keyname><forenames>Roger</forenames></author><author><keyname>Renner</keyname><forenames>Renato</forenames></author></authors><title>Simple Channel Coding Bounds</title><categories>cs.IT math.IT</categories><comments>Presented at ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New channel coding converse and achievability bounds are derived for a single
use of an arbitrary channel. Both bounds are expressed using a quantity called
the &quot;smooth 0-divergence&quot;, which is a generalization of Renyi's divergence of
order 0. The bounds are also studied in the limit of large block-lengths. In
particular, they combine to give a general capacity formula which is equivalent
to the one derived by Verdu and Han.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0858</identifier>
 <datestamp>2010-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0858</id><created>2009-01-07</created><updated>2010-09-16</updated><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Tankus</keyname><forenames>David</forenames></author></authors><title>Weighted Well-Covered Graphs without Cycles of Length 4, 5, 6 and 7</title><categories>cs.DM cs.CC</categories><comments>10 pages</comments><acm-class>G.2.2; F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph is well-covered if every maximal independent set has the same
cardinality. The recognition problem of well-covered graphs is known to be
co-NP-complete. Let w be a weight function defined on the vertices of G. Then G
is w-well-covered if all maximal independent sets of G are of the same weight.
The set of weight functions w for which a graph is w-well-covered is a vector
space. We prove that finding the vector space of weight functions under which
an input graph is w-well-covered can be done in polynomial time, if the input
graph does not contain cycles of length 4, 5, 6 and 7.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0869</identifier>
 <datestamp>2011-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0869</id><created>2009-01-07</created><updated>2011-11-28</updated><authors><author><keyname>Durand</keyname><forenames>Ir&#xe8;ne</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Middeldorp</keyname><forenames>Aart</forenames></author></authors><title>On the Complexity of Deciding Call-by-Need</title><categories>cs.LO cs.PL</categories><proxy>ccsd hal-00344320</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent paper we introduced a new framework for the study of call by need
computations to normal form and root-stable form in term rewriting. Using
elementary tree automata techniques and ground tree transducers we obtained
simple decidability proofs for classes of rewrite systems that are much larger
than earlier classes defined using the complicated sequentiality concept. In
this paper we show that we can do without ground tree transducers in order to
arrive at decidability proofs that are phrased in direct tree automata
constructions. This allows us to derive better complexity bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0886</identifier>
 <datestamp>2009-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0886</id><created>2009-01-07</created><authors><author><keyname>Brun</keyname><forenames>R.</forenames><affiliation>CERN</affiliation></author><author><keyname>Canal</keyname><forenames>P.</forenames><affiliation>Fermilab</affiliation></author><author><keyname>Frank</keyname><forenames>M.</forenames><affiliation>CERN</affiliation></author><author><keyname>Kreshuk</keyname><forenames>A.</forenames><affiliation>CERN</affiliation></author><author><keyname>Linev</keyname><forenames>S.</forenames><affiliation>Darmstadt, GSI</affiliation></author><author><keyname>Russo</keyname><forenames>P.</forenames><affiliation>Fermilab</affiliation></author><author><keyname>Rademakers</keyname><forenames>F.</forenames><affiliation>CERN</affiliation></author></authors><title>Developments in ROOT I/O and trees</title><categories>cs.OH</categories><journal-ref>J.Phys.Conf.Ser.119:042006,2008</journal-ref><doi>10.1088/1742-6596/119/4/042006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the last several months the main focus of development in the ROOT I/O
package has been code consolidation and performance improvements. Access to
remote files is affected both by bandwidth and latency. We introduced a
pre-fetch mechanism to minimize the number of transactions between client and
server and hence reducing the effect of latency. We will review the
implementation and how well it works in different conditions (gain of an order
of magnitude for remote file access). We will also review new utilities,
including a faster implementation of TTree cloning (gain of an order of
magnitude), a generic mechanism for object references, and a new entry list
mechanism tuned both for small and large number of selections. In addition to
reducing the coupling with the core module and becoming its owns library
(libRIO) (as part of the general restructuration of the ROOT libraries), the
I/O package has been enhanced in the area of XML and SQL support, thread
safety, schema evolution, TTreeFormula, and many other areas. We will also
discuss various ways, ROOT will be able to benefit from multi-core architecture
to improve I/O performances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0911</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0911</id><created>2009-01-07</created><updated>2011-01-31</updated><authors><author><keyname>Berzati</keyname><forenames>Alexandre</forenames><affiliation>LETI, PRISM</affiliation></author><author><keyname>Canovas</keyname><forenames>C&#xe9;cile</forenames><affiliation>LETI</affiliation></author><author><keyname>Dumas</keyname><forenames>Jean-Guillaume</forenames><affiliation>LJK</affiliation></author><author><keyname>Goubin</keyname><forenames>Louis</forenames><affiliation>PRISM</affiliation></author></authors><title>Fault Attacks on RSA Public Keys: Left-To-Right Implementations are also
  Vulnerable</title><categories>cs.CR</categories><proxy>ccsd</proxy><journal-ref>RSA Conference 2009, Cryptographers' Track, San Francisco : United
  States (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  After attacking the RSA by injecting fault and corresponding countermeasures,
works appear now about the need for protecting RSA public elements against
fault attacks. We provide here an extension of a recent attack based on the
public modulus corruption. The difficulty to decompose the &quot;Left-To-Right&quot;
exponentiation into partial multiplications is overcome by modifying the public
modulus to a number with known factorization. This fault model is justified
here by a complete study of faulty prime numbers with a fixed size. The good
success rate of this attack combined with its practicability raises the
question of using faults for changing algebraic properties of finite field
based cryptosystems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0930</identifier>
 <datestamp>2009-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0930</id><created>2009-01-07</created><updated>2009-03-23</updated><authors><author><keyname>M&#xf6;rig</keyname><forenames>Marc</forenames></author><author><keyname>Rautenbach</keyname><forenames>Dieter</forenames></author><author><keyname>Smid</keyname><forenames>Michiel</forenames></author><author><keyname>Tusch</keyname><forenames>Jan</forenames></author></authors><title>An \Omega(n log n) lower bound for computing the sum of even-ranked
  elements</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a sequence A of 2n real numbers, the Even-Rank-Sum problem asks for the
sum of the n values that are at the even positions in the sorted order of the
elements in A. We prove that, in the algebraic computation-tree model, this
problem has time complexity \Theta(n log n). This solves an open problem posed
by Michael Shamos at the Canadian Conference on Computational Geometry in 2008.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0948</identifier>
 <datestamp>2009-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0948</id><created>2009-01-08</created><authors><author><keyname>Nazari</keyname><forenames>Ali</forenames></author><author><keyname>Anastasopoulos</keyname><forenames>Achilleas</forenames></author><author><keyname>Pradhan</keyname><forenames>S. Sandeep</forenames></author></authors><title>A New Universal Random-Coding Bound for Average Probability Error
  Exponent for Multiple-Access Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, a new upper bound for average error probability of a two-user
discrete memoryless (DM) multiple-access channel (MAC) is derived. This bound
can be universally obtained for all discrete memoryless MACs with given input
and output alphabets. This is the first bound of this type that explicitly uses
the method of expurgation. It is shown that the exponent of this bound is
greater than or equal to those of previously known bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1043</identifier>
 <datestamp>2009-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1043</id><created>2009-01-08</created><authors><author><keyname>Alves</keyname><forenames>Marcelo Muniz S.</forenames></author><author><keyname>Panek</keyname><forenames>Luciano</forenames></author></authors><title>The Symmetries of the $\pi$-metric</title><categories>cs.IT cs.DM math.CO math.IT math.MG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let V be an n-dimensional vector space over a finite field F_q. We consider
on V the $\pi$-metric recently introduced by K. Feng, L. Xu and F. J.
Hickernell. In this short note we give a complete description of the group of
symmetries of V under the $\pi$-metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1062</identifier>
 <datestamp>2009-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1062</id><created>2009-01-08</created><updated>2009-09-07</updated><authors><author><keyname>Bringer</keyname><forenames>Julien</forenames></author><author><keyname>Chabanne</keyname><forenames>Herve</forenames></author><author><keyname>Kindarji</keyname><forenames>Bruno</forenames></author></authors><title>Identification with Encrypted Biometric Data</title><categories>cs.CR</categories><comments>An extended abstract -- entitled &quot;Error-Tolerant Searchable
  Encryption&quot; -- of this work has been accepted to and will be presented at the
  Communication and Information Systems Security Symposium, International
  Conference on Communications (ICC) 2009, June 14-18, Germany. This paper is
  the full version. Submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Biometrics make human identification possible with a sample of a biometric
trait and an associated database. Classical identification techniques lead to
privacy concerns. This paper introduces a new method to identify someone using
his biometrics in an encrypted way. Our construction combines Bloom Filters
with Storage and Locality-Sensitive Hashing. We apply this error-tolerant
scheme, in a Hamming space, to achieve biometric identification in an efficient
way. This is the first non-trivial identification scheme dealing with fuzziness
and encrypted data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1084</identifier>
 <datestamp>2010-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1084</id><created>2009-01-08</created><updated>2009-07-01</updated><authors><author><keyname>van Handel</keyname><forenames>Ramon</forenames></author></authors><title>When do nonlinear filters achieve maximal accuracy?</title><categories>math.PR cs.IT math.IT</categories><comments>18 pages</comments><msc-class>93E11, 60G10, 62M20, 93B07, 94A12</msc-class><journal-ref>SIAM J. Control Optim. 48, 3151-3168 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The nonlinear filter for an ergodic signal observed in white noise is said to
achieve maximal accuracy if the stationary filtering error vanishes as the
signal to noise ratio diverges. We give a general characterization of the
maximal accuracy property in terms of various systems theoretic notions. When
the signal state space is a finite set explicit necessary and sufficient
conditions are obtained, while the linear Gaussian case reduces to a classic
result of Kwakernaak and Sivan (1972).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1095</identifier>
 <datestamp>2009-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1095</id><created>2009-01-08</created><authors><author><keyname>De Cristofaro</keyname><forenames>Emiliano</forenames></author><author><keyname>Bohli</keyname><forenames>Jens-Matthias</forenames></author><author><keyname>Westhoff</keyname><forenames>Dirk</forenames></author></authors><title>FAIR: Fuzzy-based Aggregation providing In-network Resilience for
  real-time Wireless Sensor Networks</title><categories>cs.CR</categories><comments>This paper is an extended version of the paper appeared in the 2nd
  Conference on Wireless Network Security (WiSec'09)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work introduces FAIR, a novel framework for Fuzzy-based Aggregation
providing In-network Resilience for Wireless Sensor Networks. FAIR addresses
the possibility of malicious aggregator nodes manipulating data. It provides
data-integrity based on a trust level of the WSN response and it tolerates link
or node failures. Compared to available solutions, it offers a general
aggregation model and makes the trust level visible to the querier. We classify
the proposed approach as complementary to protocols ensuring resilience against
sensor leaf nodes providing faulty data. Thanks to our flexible resilient
framework and due to the use of Fuzzy Inference Schemes, we achieve promising
results within a short design cycle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1123</identifier>
 <datestamp>2009-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1123</id><created>2009-01-08</created><authors><author><keyname>Hariri</keyname><forenames>Arash</forenames></author><author><keyname>Navi</keyname><forenames>K.</forenames></author><author><keyname>Rastegar</keyname><forenames>Reza</forenames></author></authors><title>A High Dynamic Range 3-Moduli-Set with Efficient Reverse Converter</title><categories>cs.AR cs.DC</categories><journal-ref>Computers &amp; Mathematics with Applications (2008), Vol 55, No 4,
  660-668</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  -Residue Number System (RNS) is a valuable tool for fast and parallel
arithmetic. It has a wide application in digital signal processing, fault
tolerant systems, etc. In this work, we introduce the 3-moduli set {2^n,
2^{2n}-1, 2^{2n}+1} and propose its residue to binary converter using the
Chinese Remainder Theorem. We present its simple hardware implementation that
mainly includes one Carry Save Adder (CSA) and a Modular Adder (MA). We compare
the performance and area utilization of our reverse converter to the reverse
converters of the moduli sets {2^n-1, 2^n, 2^n+1, 2^{2n}+1} and {2^n-1, 2^n,
2^n+1, 2^n-2^{(n+1)/2}+1, 2^n+2^{(n+1)/2}+1} that have the same dynamic range
and we demonstrate that our architecture is better in terms of performance and
area utilization. Also, we show that our reverse converter is faster than the
reverse converter of {2^n-1, 2^n, 2^n+1} for dynamic ranges like 8-bit, 16-bit,
32-bit and 64-bit however it requires more area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1140</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1140</id><created>2009-01-08</created><updated>2009-03-18</updated><authors><author><keyname>Elbassioni</keyname><forenames>Khaled</forenames></author><author><keyname>Raman</keyname><forenames>Rajiv</forenames></author><author><keyname>Ray</keyname><forenames>Saurabh</forenames></author><author><keyname>Sitters</keyname><forenames>Rene</forenames></author></authors><title>On Profit-Maximizing Pricing for the Highway and Tollbooth Problems</title><categories>cs.DS cs.GT</categories><doi>10.1007/978-3-642-04645-2_25</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the \emph{tollbooth problem}, we are given a tree $\bT=(V,E)$ with $n$
edges, and a set of $m$ customers, each of whom is interested in purchasing a
path on the tree. Each customer has a fixed budget, and the objective is to
price the edges of $\bT$ such that the total revenue made by selling the paths
to the customers that can afford them is maximized. An important special case
of this problem, known as the \emph{highway problem}, is when $\bT$ is
restricted to be a line.
  For the tollbooth problem, we present a randomized $O(\log n)$-approximation,
improving on the current best $O(\log m)$-approximation. We also study a
special case of the tollbooth problem, when all the paths that customers are
interested in purchasing go towards a fixed root of $\bT$. In this case, we
present an algorithm that returns a $(1-\epsilon)$-approximation, for any
$\epsilon &gt; 0$, and runs in quasi-polynomial time. On the other hand, we rule
out the existence of an FPTAS by showing that even for the line case, the
problem is strongly NP-hard. Finally, we show that in the \emph{coupon model},
when we allow some items to be priced below zero to improve the overall profit,
the problem becomes even APX-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1144</identifier>
 <datestamp>2009-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1144</id><created>2009-01-08</created><updated>2009-10-25</updated><authors><author><keyname>Berrones</keyname><forenames>Arturo</forenames></author></authors><title>Bayesian Inference Based on Stationary Fokker-Planck Sampling</title><categories>cond-mat.dis-nn cs.NE physics.data-an</categories><comments>Accepted in Neural Computation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel formalism for Bayesian learning in the context of complex inference
models is proposed. The method is based on the use of the Stationary
Fokker--Planck (SFP) approach to sample from the posterior density. Stationary
Fokker--Planck sampling generalizes the Gibbs sampler algorithm for arbitrary
and unknown conditional densities. By the SFP procedure approximate analytical
expressions for the conditionals and marginals of the posterior can be
constructed. At each stage of SFP, the approximate conditionals are used to
define a Gibbs sampling process, which is convergent to the full joint
posterior. By the analytical marginals efficient learning methods in the
context of Artificial Neural Networks are outlined. Off--line and incremental
Bayesian inference and Maximum Likelihood Estimation from the posterior is
performed in classification and regression examples. A comparison of SFP with
other Monte Carlo strategies in the general problem of sampling from arbitrary
densities is also presented. It is shown that SFP is able to jump large
low--probabilty regions without the need of a careful tuning of any step size
parameter. In fact, the SFP method requires only a small set of meaningful
parameters which can be selected following clear, problem--independent
guidelines. The computation cost of SFP, measured in terms of loss function
evaluations, grows linearly with the given model's dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1152</identifier>
 <datestamp>2009-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1152</id><created>2009-01-08</created><authors><author><keyname>Eliashberg</keyname><forenames>Victor</forenames></author></authors><title>A nonclassical symbolic theory of working memory, mental computations,
  and mental set</title><categories>cs.AI cs.NE</categories><comments>29 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper tackles four basic questions associated with human brain as a
learning system. How can the brain learn to (1) mentally simulate different
external memory aids, (2) perform, in principle, any mental computations using
imaginary memory aids, (3) recall the real sensory and motor events and
synthesize a combinatorial number of imaginary events, (4) dynamically change
its mental set to match a combinatorial number of contexts? We propose a
uniform answer to (1)-(4) based on the general postulate that the human
neocortex processes symbolic information in a &quot;nonclassical&quot; way. Instead of
manipulating symbols in a read/write memory, as the classical symbolic systems
do, it manipulates the states of dynamical memory representing different
temporary attributes of immovable symbolic structures stored in a long-term
memory. The approach is formalized as the concept of E-machine. Intuitively, an
E-machine is a system that deals mainly with characteristic functions
representing subsets of memory pointers rather than the pointers themselves.
This nonclassical symbolic paradigm is Turing universal, and, unlike the
classical one, is efficiently implementable in homogeneous neural networks with
temporal modulation topologically resembling that of the neocortex.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1155</identifier>
 <datestamp>2012-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1155</id><created>2009-01-08</created><updated>2012-09-12</updated><authors><author><keyname>Benjamini</keyname><forenames>Itai</forenames></author><author><keyname>Makarychev</keyname><forenames>Yury</forenames></author></authors><title>Balanced allocation: Memory performance tradeoffs</title><categories>cs.DS cs.DM math.PR</categories><comments>Published in at http://dx.doi.org/10.1214/11-AAP804 the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AAP-AAP804</report-no><journal-ref>Annals of Applied Probability 2012, Vol. 22, No. 4, 1642-1649</journal-ref><doi>10.1214/11-AAP804</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose we sequentially put $n$ balls into $n$ bins. If we put each ball into
a random bin then the heaviest bin will contain ${\sim}\log n/\log\log n$ balls
with high probability. However, Azar, Broder, Karlin and Upfal [SIAM J. Comput.
29 (1999) 180--200] showed that if each time we choose two bins at random and
put the ball in the least loaded bin among the two, then the heaviest bin will
contain only ${\sim}\log\log n$ balls with high probability. How much memory do
we need to implement this scheme? We need roughly $\log\log\log n$ bits per
bin, and $n\log\log\log n$ bits in total. Let us assume now that we have
limited amount of memory. For each ball, we are given two random bins and we
have to put the ball into one of them. Our goal is to minimize the load of the
heaviest bin. We prove that if we have $n^{1-\delta}$ bits then the heaviest
bin will contain at least $\Omega(\delta\log n/\log\log n)$ balls with high
probability. The bound is tight in the communication complexity model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1162</identifier>
 <datestamp>2009-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1162</id><created>2009-01-08</created><authors><author><keyname>Huang</keyname><forenames>Ming-Deh</forenames></author><author><keyname>Narayanan</keyname><forenames>Anand Kumar</forenames></author></authors><title>Folded Algebraic Geometric Codes From Galois Extensions</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new class of list decodable codes based on Galois extensions of
function fields and present a list decoding algorithm. These codes are obtained
as a result of folding the set of rational places of a function field using
certain elements (automorphisms) from the Galois group of the extension. This
work is an extension of Folded Reed Solomon codes to the setting of Algebraic
Geometric codes. We describe two constructions based on this framework
depending on if the order of the automorphism used to fold the code is large or
small compared to the block length. When the automorphism is of large order,
the codes have polynomially bounded list size in the worst case. This
construction gives codes of rate $R$ over an alphabet of size independent of
block length that can correct a fraction of $1-R-\epsilon$ errors subject to
the existence of asymptotically good towers of function fields with large
automorphisms. The second construction addresses the case when the order of the
element used to fold is small compared to the block length. In this case a
heuristic analysis shows that for a random received word, the expected list
size and the running time of the decoding algorithm are bounded by a polynomial
in the block length. When applied to the Garcia-Stichtenoth tower, this yields
codes of rate $R$ over an alphabet of size
$(\frac{1}{\epsilon^2})^{O(\frac{1}{\epsilon})}$, that can correct a fraction
of $1-R-\epsilon$ errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1181</identifier>
 <datestamp>2009-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1181</id><created>2009-01-09</created><updated>2009-01-12</updated><authors><author><keyname>Alagoz</keyname><forenames>B. Baykant</forenames></author></authors><title>Fault Masking By Probabilistic Voting</title><categories>cs.OH</categories><journal-ref>OncuBilim Algorithm And Systems Labs. Vol.09, Art.No:01,(2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, we introduced a probabilistic voter, regarding symbol
probabilities in decision process besides majority consensus. Conventional
majority voter is independent of functionality of redundant modules. In our
study, proposed probabilistic voter is designed corresponding to functionality
of the redundant module. We tested probabilistic voter for 3 and 5 redundant
modules with random transient errors inserted the wires and it was seen from
simulation results that Multi-Modular Redundancy (M-MR) with Probabilistic
Voting (PV) had been shown better availability performance than conventional
majority voter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1230</identifier>
 <datestamp>2009-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1230</id><created>2009-01-09</created><authors><author><keyname>De Koninck</keyname><forenames>Leslie</forenames></author></authors><title>Logical Algorithms meets CHR: A meta-complexity result for Constraint
  Handling Rules with rule priorities</title><categories>cs.PL cs.AI cs.CC</categories><comments>To appear in Theory and Practice of Logic Programming (TPLP)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the relationship between the Logical Algorithms
language (LA) of Ganzinger and McAllester and Constraint Handling Rules (CHR).
We present a translation schema from LA to CHR-rp: CHR with rule priorities,
and show that the meta-complexity theorem for LA can be applied to a subset of
CHR-rp via inverse translation. Inspired by the high-level implementation
proposal for Logical Algorithm by Ganzinger and McAllester and based on a new
scheduling algorithm, we propose an alternative implementation for CHR-rp that
gives strong complexity guarantees and results in a new and accurate
meta-complexity theorem for CHR-rp. It is furthermore shown that the
translation from Logical Algorithms to CHR-rp combined with the new CHR-rp
implementation, satisfies the required complexity for the Logical Algorithms
meta-complexity result to hold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1244</identifier>
 <datestamp>2009-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1244</id><created>2009-01-09</created><authors><author><keyname>Chen</keyname><forenames>Eric Z.</forenames></author></authors><title>Constructions of Quasi-Twisted Two-Weight Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A code is said to be two-weight if the non-zero codewords have only two
different a weight w1 and w2. Two-weight codes are closely related to strongly
regular graphs. In this paper. It is shown that a consta-cyclic code of
composite length can be put in the quasi-twisted form. Based on this
transformation, a new construction method of quasi-twisted (QT) two-weight
codes is presented. A large amount of QT two-weight codes are found, and some
new codes are also constructed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1257</identifier>
 <datestamp>2009-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1257</id><created>2009-01-09</created><authors><author><keyname>Luetticke</keyname><forenames>Rainer</forenames></author><author><keyname>Cinar</keyname><forenames>Ridvan</forenames></author></authors><title>An Internet-based Audience Response System for the Improvement of
  Teaching</title><categories>cs.CY cs.NI</categories><comments>2 pages, accepted for presentation at International Conference for
  the Learning Sciences - ICLS2008, Utrecht, the Netherlands, June 2008. On
  request poster is available</comments><acm-class>K.3.1, C.2.4, C.2.5, H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have developed an Internet-based audience response system (called ARSBO).
In this way we combine the advantages of common audience response systems using
handheld devices and the easy and cheap access to the Internet. Evaluations of
audience response systems in the literature have shown their success:
encouraging participation of the students as well as immediate feedback to
answers to the whole group for evaluational purposes of the teacher. However,
commercial systems are relatively expensive and the number of students in such
a teaching-learning scenario is limited. ARSBO solves these problems. Using the
Internet (e.g. in computer rooms or by wireless Internet access) there are no
special costs and the number of participating students is not limited. ARSBO is
very easy to use for students as well as for the construction of new questions
with possible answers and for the visualization of statistical results to
questions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1287</identifier>
 <datestamp>2009-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1287</id><created>2009-01-09</created><authors><author><keyname>Kim</keyname><forenames>Dae San</forenames></author></authors><title>Infinite families of recursive formulas generating power moments of
  Kloosterman sums: O^- (2n, 2^r) case</title><categories>math.NT cs.IT math.IT</categories><msc-class>11T23; 20G40; 94B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we construct eight infinite families of binary linear codes
associated with double cosets with respect to certain maximal parabolic
subgroup of the special orthogonal group $SO^-(2n,2^r)$. Then we obtain four
infinite families of recursive formulas for the power moments of Kloosterman
sums and four those of 2-dimensional Kloosterman sums in terms of the
frequencies of weights in the codes. This is done via Pless power moment
identity and by utilizing the explicit expressions of exponential sums over
those double cosets related to the evaluations of &quot;Gauss sums&quot; for the
orthogonal groups $O^-(2n,2^r)$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1288</identifier>
 <datestamp>2014-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1288</id><created>2009-01-09</created><updated>2010-01-29</updated><authors><author><keyname>Aggarwal</keyname><forenames>Vaneet</forenames></author><author><keyname>Sabharwal</keyname><forenames>Ashutosh</forenames></author></authors><title>Power-Controlled Feedback and Training for Two-way MIMO Channels</title><categories>cs.IT math.IT</categories><comments>in IEEE Transactions on Information Theory, 2010</comments><journal-ref>IEEE Transactions on Information Theory, vol.56, no.7,
  pp.3310,3331, July 2010</journal-ref><doi>10.1109/TIT.2010.2048472</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most communication systems use some form of feedback, often related to
channel state information. The common models used in analyses either assume
perfect channel state information at the receiver and/or noiseless state
feedback links. However, in practical systems, neither is the channel estimate
known perfectly at the receiver and nor is the feedback link perfect. In this
paper, we study the achievable diversity multiplexing tradeoff using i.i.d.
Gaussian codebooks, considering the errors in training the receiver and the
errors in the feedback link for FDD systems, where the forward and the feedback
are independent MIMO channels.
  Our key result is that the maximum diversity order with one-bit of feedback
information is identical to systems with more feedback bits. Thus,
asymptotically in $\mathsf{SNR}$, more than one bit of feedback does not
improve the system performance at constant rates. Furthermore, the one-bit
diversity-multiplexing performance is identical to the system which has perfect
channel state information at the receiver along with noiseless feedback link.
This achievability uses novel concepts of power controlled feedback and
training, which naturally surface when we consider imperfect channel estimation
and noisy feedback links. In the process of evaluating the proposed training
and feedback protocols, we find an asymptotic expression for the joint
probability of the $\mathsf{SNR}$ exponents of eigenvalues of the actual
channel and the estimated channel which may be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1289</identifier>
 <datestamp>2009-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1289</id><created>2009-01-09</created><authors><author><keyname>Smarandache</keyname><forenames>Florentin</forenames></author></authors><title>N-norm and N-conorm in Neutrosophic Logic and Set, and the Neutrosophic
  Topologies</title><categories>cs.AI</categories><comments>11 pages, 3 diagrams</comments><acm-class>I.2.3</acm-class><journal-ref>In author's book A Unifying Field in Logics: Neutrosophic Logic;
  Neutrosophic Set, Neutrosophic Probability and Statistics (fourth edition),
  2005; Review of the Air Force Academy, No. 1 (14), pp. 05-11, 2009.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present the N-norms/N-conorms in neutrosophic logic and set
as extensions of T-norms/T-conorms in fuzzy logic and set. Also, as an
extension of the Intuitionistic Fuzzy Topology we present the Neutrosophic
Topologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1307</identifier>
 <datestamp>2009-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1307</id><created>2009-01-09</created><authors><author><keyname>Collange</keyname><forenames>Sylvain</forenames><affiliation>ELIAUS</affiliation></author><author><keyname>Dandass</keyname><forenames>Yoginder</forenames><affiliation>CSE</affiliation></author><author><keyname>Daumas</keyname><forenames>Marc</forenames><affiliation>ELIAUS</affiliation></author><author><keyname>Defour</keyname><forenames>David</forenames><affiliation>ELIAUS</affiliation></author></authors><title>Using Graphics Processors for Parallelizing Hash-based Data Carving</title><categories>cs.DC</categories><proxy>ccsd hal-00350962</proxy><journal-ref>42nd Hawaii International Conference on System Sciences, Waikoloa
  : \'Etats-Unis d'Am\'erique (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to detect fragments of deleted image files and to reconstruct
these image files from all available fragments on disk is a key activity in the
field of digital forensics. Although reconstruction of image files from the
file fragments on disk can be accomplished by simply comparing the content of
sectors on disk with the content of known files, this brute-force approach can
be time consuming. This paper presents results from research into the use of
Graphics Processing Units (GPUs) in detecting specific image file byte patterns
in disk clusters. Unique identifying pattern for each disk sector is compared
against patterns in known images. A pattern match indicates the potential
presence of an image and flags the disk sector for further in-depth examination
to confirm the match. The GPU-based implementation outperforms the software
implementation by a significant margin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1312</identifier>
 <datestamp>2010-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1312</id><created>2009-01-09</created><updated>2010-05-28</updated><authors><author><keyname>Bui</keyname><forenames>Loc</forenames></author><author><keyname>Srikant</keyname><forenames>R.</forenames></author><author><keyname>Stolyar</keyname><forenames>Alexander</forenames></author></authors><title>Novel Architectures and Algorithms for Delay Reduction in Back-pressure
  Scheduling and Routing</title><categories>cs.NI</categories><comments>A short version of this paper is accepted to the INFOCOM 2009
  Mini-Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The back-pressure algorithm is a well-known throughput-optimal algorithm.
However, its delay performance may be quite poor even when the traffic load is
not close to network capacity due to the following two reasons. First, each
node has to maintain a separate queue for each commodity in the network, and
only one queue is served at a time. Second, the back-pressure routing algorithm
may route some packets along very long routes. In this paper, we present
solutions to address both of the above issues, and hence, improve the delay
performance of the back-pressure algorithm. One of the suggested solutions also
decreases the complexity of the queueing data structures to be maintained at
each node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1315</identifier>
 <datestamp>2009-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1315</id><created>2009-01-09</created><authors><author><keyname>Rodriguez</keyname><forenames>Abel</forenames></author><author><keyname>Gzyl</keyname><forenames>Henryk</forenames></author><author><keyname>Molina</keyname><forenames>German</forenames></author><author><keyname>ter Horst</keyname><forenames>Enrique</forenames></author></authors><title>Stochastic Volatility Models Including Open, Close, High and Low Prices</title><categories>q-fin.ST cs.CE cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mounting empirical evidence suggests that the observed extreme prices within
a trading period can provide valuable information about the volatility of the
process within that period. In this paper we define a class of stochastic
volatility models that uses opening and closing prices along with the minimum
and maximum prices within a trading period to infer the dynamics underlying the
volatility process of asset prices and compares it with similar models that
have been previously presented in the literature. The paper also discusses
sequential Monte Carlo algorithms to fit this class of models and illustrates
its features using both a simulation study and data form the SP500 index.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1322</identifier>
 <datestamp>2009-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1322</id><created>2009-01-09</created><authors><author><keyname>Abbott</keyname><forenames>Timothy G.</forenames></author><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Gassend</keyname><forenames>Blaise</forenames></author></authors><title>A Generalized Carpenter's Rule Theorem for Self-Touching Linkages</title><categories>cs.CG cs.FL</categories><comments>20 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Carpenter's Rule Theorem states that any chain linkage in the plane can
be folded continuously between any two configurations while preserving the bar
lengths and without the bars crossing. However, this theorem applies only to
strictly simple configurations, where bars intersect only at their common
endpoints. We generalize the theorem to self-touching configurations, where
bars can touch but not properly cross. At the heart of our proof is a new
definition of self-touching configurations of planar linkages, based on an
annotated configuration space and limits of nontouching configurations. We show
that this definition is equivalent to the previously proposed definition of
self-touching configurations, which is based on a combinatorial description of
overlapping features. Using our new definition, we prove the generalized
Carpenter's Rule Theorem using a topological argument. We believe that our
topological methodology provides a powerful tool for manipulating many kinds of
self-touching objects, such as 3D hinged assemblies of polygons and rigid
origami. In particular, we show how to apply our methodology to extend to
self-touching configurations universal reconfigurability results for open
chains with slender polygonal adornments, and single-vertex rigid origami with
convex cones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1397</identifier>
 <datestamp>2009-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1397</id><created>2009-01-12</created><authors><author><keyname>Guay-Paquet</keyname><forenames>Mathieu</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>Avoiding Squares and Overlaps Over the Natural Numbers</title><categories>math.CO cs.FL</categories><comments>16 pages, 2 tables</comments><msc-class>68R15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider avoiding squares and overlaps over the natural numbers, using a
greedy algorithm that chooses the least possible integer at each step; the word
generated is lexicographically least among all such infinite words. In the case
of avoiding squares, the word is 01020103..., the familiar ruler function, and
is generated by iterating a uniform morphism. The case of overlaps is more
challenging. We give an explicitly-defined morphism phi : N* -&gt; N* that
generates the lexicographically least infinite overlap-free word by iteration.
Furthermore, we show that for all h,k in N with h &lt;= k, the word phi^{k-h}(h)
is the lexicographically least overlap-free word starting with the letter h and
ending with the letter k, and give some of its symmetry properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1407</identifier>
 <datestamp>2009-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1407</id><created>2009-01-10</created><authors><author><keyname>Yan</keyname><forenames>Bin</forenames></author><author><keyname>Lu</keyname><forenames>Zheming</forenames></author><author><keyname>Guo</keyname><forenames>Yinjing</forenames></author></authors><title>Condition for Energy Efficient Watermarking with Random Vector Model
  without WSS Assumption</title><categories>cs.MM cs.CR</categories><comments>10 pages, 2 figures, submitted to IEEE Signal Processing Letter for
  review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy efficient watermarking preserves the watermark energy after linear
attack as much as possible. We consider in this letter non-stationary signal
models and derive conditions for energy efficient watermarking under random
vector model without WSS assumption. We find that the covariance matrix of the
energy efficient watermark should be proportional to host covariance matrix to
best resist the optimal linear removal attacks. In WSS process our result
reduces to the well known power spectrum condition. Intuitive geometric
interpretation of the results are also discussed which in turn also provide
more simpler proof of the main results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1408</identifier>
 <datestamp>2009-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1408</id><created>2009-01-10</created><updated>2009-10-15</updated><authors><author><keyname>Zhu</keyname><forenames>Yan</forenames></author><author><keyname>Guo</keyname><forenames>Dongning</forenames></author><author><keyname>Honig</keyname><forenames>Michael L.</forenames></author></authors><title>A Message-Passing Approach for Joint Channel Estimation, Interference
  Mitigation and Decoding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel uncertainty and co-channel interference are two major challenges in
the design of wireless systems such as future generation cellular networks.
This paper studies receiver design for a wireless channel model with both
time-varying Rayleigh fading and strong co-channel interference of similar form
as the desired signal. It is assumed that the channel coefficients of the
desired signal can be estimated through the use of pilots, whereas no pilot for
the interference signal is available, as is the case in many practical wireless
systems. Because the interference process is non-Gaussian, treating it as
Gaussian noise generally often leads to unacceptable performance. In order to
exploit the statistics of the interference and correlated fading in time, an
iterative message-passing architecture is proposed for joint channel
estimation, interference mitigation and decoding. Each message takes the form
of a mixture of Gaussian densities where the number of components is limited so
that the overall complexity of the receiver is constant per symbol regardless
of the frame and code lengths. Simulation of both coded and uncoded systems
shows that the receiver performs significantly better than conventional
receivers with linear channel estimation, and is robust with respect to
mismatch in the assumed fading model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1413</identifier>
 <datestamp>2009-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1413</id><created>2009-01-10</created><authors><author><keyname>Boothby</keyname><forenames>Tomas J.</forenames></author><author><keyname>Bradshaw</keyname><forenames>Robert W.</forenames></author></authors><title>Bitslicing and the Method of Four Russians Over Larger Finite Fields</title><categories>cs.MS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method of computing with matrices over very small finite fields
of size larger than 2. Specifically, we show how the Method of Four Russians
can be efficiently adapted to these larger fields, and introduce a row-wise
matrix compression scheme that both reduces memory requirements and allows one
to vectorize element operations. We also present timings which confirm the
efficiency of these methods and exceed the speed of the fastest implementations
the authors are aware of.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1427</identifier>
 <datestamp>2009-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1427</id><created>2009-01-11</created><authors><author><keyname>Chakraborty</keyname><forenames>Sourav</forenames></author><author><keyname>Devanur</keyname><forenames>Nikhil</forenames></author></authors><title>An Online Multi-unit Auction with Improved Competitive Ratio</title><categories>cs.GT cs.CC cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We improve the best known competitive ratio (from 1/4 to 1/2), for the online
multi-unit allocation problem, where the objective is to maximize the
single-price revenue. Moreover, the competitive ratio of our algorithm tends to
1, as the bid-profile tends to ``smoothen''. This algorithm is used as a
subroutine in designing truthful auctions for the same setting: the allocation
has to be done online, while the payments can be decided at the end of the day.
Earlier, a reduction from the auction design problem to the allocation problem
was known only for the unit-demand case. We give a reduction for the general
case when the bidders have decreasing marginal utilities. The problem is
inspired by sponsored search auctions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1444</identifier>
 <datestamp>2011-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1444</id><created>2009-01-11</created><updated>2011-12-15</updated><authors><author><keyname>Vasudevan</keyname><forenames>Dinkar</forenames></author><author><keyname>Kudekar</keyname><forenames>Shrinivas</forenames></author></authors><title>Algebraic gossip on Arbitrary Networks</title><categories>cs.IT math.IT</categories><comments>Paper has been withdrawn due to an error in the main proof</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a network of nodes where each node has a message to communicate to
all other nodes. For this communication problem, we analyze a gossip based
protocol where coded messages are exchanged. This problem was studied by Aoyama
and Shah where a bound to the dissemination time based on the spectral
properties of the underlying communication graph is provided. Our contribution
is a uniform bound that holds for arbitrary networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1462</identifier>
 <datestamp>2009-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1462</id><created>2009-01-11</created><authors><author><keyname>Chavent</keyname><forenames>Guy</forenames><affiliation>INRIA Rocquencourt, Ceremade</affiliation></author></authors><title>A Fully Equivalent Global Pressure Formulation for Three-Phase
  Compressible Flow</title><categories>cs.NA math.AP physics.class-ph</categories><proxy>ccsd inria-00350459</proxy><report-no>RR-6788</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new global pressure formulation for immiscible three-phase
compressible flows in porous media which is fully equivalent to the original
equations, unlike the one introduced in \cite{CJ86}. In this formulation, the
total volumetric flow of the three fluids and the global pressure follow a
classical Darcy law, which simplifies the resolution of the pressure equation.
However, this global pressure formulation exists only for Total Differential
(TD) three-phase data, which depend only on two functions of saturations and
global pressure: the global capillary pressure and the global mobility. Hence
we introduce a class of interpolation which constructs such TD-three-phase data
from any set of three two-phase data (for each pair of fluids) which satisfy a
TD-compatibility condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1473</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1473</id><created>2009-01-11</created><updated>2009-08-20</updated><authors><author><keyname>Lomnitz</keyname><forenames>Yuval</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author></authors><title>Communication over Individual Channels</title><categories>cs.IT math.IT</categories><comments>Cleanup, Editorial changes, Additional commentary</comments><journal-ref>IEEE Trans. Information Theory, vol. 57, no. 11, pp. 7333 --7358,
  Nov. 2011</journal-ref><doi>10.1109/TIT.2011.2169130</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of communicating over a channel for which no
mathematical model is specified. We present achievable rates as a function of
the channel input and output known a-posteriori for discrete and continuous
channels, as well as a rate-adaptive scheme employing feedback which achieves
these rates asymptotically without prior knowledge of the channel behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1479</identifier>
 <datestamp>2009-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1479</id><created>2009-01-11</created><authors><author><keyname>Kurant</keyname><forenames>Maciej</forenames></author></authors><title>Exploiting the Path Propagation Time Differences in Multipath
  Transmission with FEC</title><categories>cs.NI</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a transmission of a delay-sensitive data stream from a single
source to a single destination. The reliability of this transmission may suffer
from bursty packet losses - the predominant type of failures in today's
Internet. An effective and well studied solution to this problem is to protect
the data by a Forward Error Correction (FEC) code and send the FEC packets over
multiple paths.
  In this paper we show that the performance of such a multipath FEC scheme can
often be further improved. Our key observation is that the propagation times on
the available paths often significantly differ, typically by 10-100ms.
  We propose to exploit these differences by appropriate packet scheduling that
we call `Spread'. We evaluate our solution with a precise, analytical
formulation and trace-driven simulations. Our studies show that Spread
substantially outperforms the state-of-the-art solutions. It typically achieves
two- to five-fold improvement (reduction) in the effective loss rate. Or
conversely, keeping the same level of effective loss rate, Spread significantly
decreases the observed delays and helps fighting the delay jitter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1492</identifier>
 <datestamp>2009-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1492</id><created>2009-01-11</created><updated>2009-12-11</updated><authors><author><keyname>Jog</keyname><forenames>Varun</forenames></author><author><keyname>Nair</keyname><forenames>Chandra</forenames></author></authors><title>An information inequality for the BSSC channel</title><categories>cs.IT math.IT</categories><comments>A new proof of the inequality is presented. It can be used to close
  the gap of the earlier argument; though it is not explained here</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish an information theoretic inequality concerning the binary
skew-symmetric broadcast channel that was conjectured by one of the authors.
This inequality helps to quantify the gap between the sum rate obtained by the
inner bound and outer bound for the binary skew-symmetric broadcast channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1503</identifier>
 <datestamp>2009-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1503</id><created>2009-01-11</created><updated>2009-02-17</updated><authors><author><keyname>Xie</keyname><forenames>Liang-Liang</forenames></author></authors><title>A Greedy Omnidirectional Relay Scheme</title><categories>cs.IT math.IT</categories><comments>More details added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A greedy omnidirectional relay scheme is developed, and the corresponding
achievable rate region is obtained for the all-source all-cast problem. The
discussions are first based on the general discrete memoryless channel model,
and then applied to the additive white Gaussian noise (AWGN) models, with both
full-duplex and half-duplex modes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1563</identifier>
 <datestamp>2009-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1563</id><created>2009-01-12</created><authors><author><keyname>Bourgeois</keyname><forenames>Nicolas</forenames></author><author><keyname>Escoffier</keyname><forenames>Bruno</forenames></author><author><keyname>Paschos</keyname><forenames>Vangelis Th.</forenames></author><author><keyname>van Rooij</keyname><forenames>Johan M. M</forenames></author></authors><title>Fast Algorithms for Max Independent Set in Graphs of Small Average
  Degree</title><categories>cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Max Independent Set (MIS) is a paradigmatic problem in theoretical computer
science and numerous studies tackle its resolution by exact algorithms with
non-trivial worst-case complexity. The best such complexity is, to our
knowledge, the $O^*(1.1889^n)$ algorithm claimed by J.M. Robson (T.R. 1251-01,
LaBRI, Univ. Bordeaux I, 2001) in his unpublished technical report. We also
quote the $O^*(1.2210^n)$ algorithm by Fomin and al. (in Proc. SODA'06, pages
18-25, 2006), that is the best published result about MIS.
  In this paper we settle MIS in (connected) graphs with &quot;small&quot; average
degree, more precisely with average degree at most 3, 4, 5 and 6. Dealing with
graphs of average degree at most 3, the best bound known is the recent
$O^*(1.0977^n)$ bound by N. Bourgeois and al. in Proc. IWPEC'08, pages 55-65,
2008). Here we improve this result down to $O^*(1.0854^n)$ by proposing finer
and more powerful reduction rules.
  We then propose a generic method showing how improvement of the worst-case
complexity for MIS in graphs of average degree $d$ entails improvement of it in
any graph of average degree greater than $d$ and, based upon it, we tackle MIS
in graphs of average degree 4, 5 and 6.
  For MIS in graphs with average degree 4, we provide an upper complexity bound
of $O^*(1.1571^n)$ that outperforms the best known bound of $O^*(1.1713^n)$ by
R. Beigel (Proc. SODA'99, pages 856-857, 1999).
  For MIS in graphs of average degree at most 5 and 6, we provide bounds of
$O^*(1.1969^n)$ and $O^*(1.2149^n)$, respectively, that improve upon the
corresponding bounds of $O^*(1.2023^n)$ and $O^*(1.2172^n)$ in graphs of
maximum degree 5 and 6 by (Fomin et al., 2006).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1582</identifier>
 <datestamp>2009-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1582</id><created>2009-01-12</created><authors><author><keyname>Noble</keyname><forenames>Michael S.</forenames></author><author><keyname>Ji</keyname><forenames>Li</forenames></author><author><keyname>Young</keyname><forenames>Andrew</forenames></author><author><keyname>Lee</keyname><forenames>Julia</forenames></author></authors><title>Parallelizing the XSTAR Photoionization Code</title><categories>astro-ph.IM cs.DC</categories><comments>ADASS 2008 (Quebec) proceedings (4 pages, 1 figure)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe two means by which XSTAR, a code which computes physical
conditions and emission spectra of photoionized gases, has been parallelized.
The first is pvm_xstar, a wrapper which can be used in place of the serial
xstar2xspec script to foster concurrent execution of the XSTAR command line
application on independent sets of parameters. The second is PModel, a plugin
for the Interactive Spectral Interpretation System (ISIS) which allows
arbitrary components of a broad range of astrophysical models to be distributed
across processors during fitting and confidence limits calculations, by
scientists with little training in parallel programming. Plugging the XSTAR
family of analytic models into PModel enables multiple ionization states (e.g.,
of a complex absorber/emitter) to be computed simultaneously, alleviating the
often prohibitive expense of the traditional serial approach. Initial
performance results indicate that these methods substantially enlarge the
problem space to which XSTAR may be applied within practical timeframes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1610</identifier>
 <datestamp>2009-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1610</id><created>2009-01-12</created><authors><author><keyname>Misra</keyname><forenames>Janardan</forenames></author></authors><title>Towards a Framework for Observing Artificial Evolutionary Systems</title><categories>cs.NE cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Establishing the emergence of evolutionary behavior as a defining
characteristic of 'life' is a major step in the Artificial life (ALife)
studies. We present here an abstract formal framework for this aim based upon
the notion of high-level observations made on the ALife model at hand during
its simulations. An observation process is defined as a computable
transformation from the underlying dynamic structure of the model universe to a
tuple consisting of abstract components needed to establish the evolutionary
processes in the model. Starting with defining entities and their evolutionary
relationships observed during the simulations of the model, the framework
prescribes a series of definitions, followed by the axioms (conditions) that
must be met in order to establish the level of evolutionary behavior in the
model. The examples of Cellular Automata based Langton Loops and Lambda
calculus based Algorithmic Chemistry are used to illustrate the framework.
Generic design suggestions for the ALife research are also drawn based upon the
framework design and case study analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1629</identifier>
 <datestamp>2009-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1629</id><created>2009-01-12</created><authors><author><keyname>Levesque</keyname><forenames>Martin</forenames></author><author><keyname>Elbiaze</keyname><forenames>Halima</forenames></author><author><keyname>Aly</keyname><forenames>Wael Hosny Fouad</forenames></author></authors><title>Adaptive threshold-based decision for efficient hybrid deflection and
  retransmission scheme in OBS networks</title><categories>cs.NI</categories><comments>6 pages, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Burst contention is a well-known challenging problem in Optical Burst
Switching (OBS) networks. Deflection routing is used to resolve contention.
Burst retransmission is used to reduce the Burst Loss Ratio (BLR) by
retransmitting dropped bursts. Previous works show that combining deflection
and retransmission outperforms both pure deflection and pure retransmission
approaches. This paper proposes a new Adaptive Hybrid Deflection and
Retransmission (AHDR) approach that dynamically combines deflection and
retransmission approaches based on network conditions such as BLR and link
utilization. Network Simulator 2 (ns-2) is used to simulate the proposed
approach on different network topologies. Simulation results show that the
proposed approach outperforms static approaches in terms of BLR by using an
adaptive decision threshold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1655</identifier>
 <datestamp>2010-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1655</id><created>2009-01-12</created><authors><author><keyname>Nobrega</keyname><forenames>Roberto W.</forenames></author><author><keyname>Uchoa-Filho</keyname><forenames>Bartolomeu F.</forenames></author></authors><title>Multishot Codes for Network Coding: Bounds and a Multilevel Construction</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, submitted to ISIT 2009</comments><doi>10.1109/ISIT.2009.5205750</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The subspace channel was introduced by Koetter and Kschischang as an adequate
model for the communication channel from the source node to a sink node of a
multicast network that performs random linear network coding. So far, attention
has been given to one-shot subspace codes, that is, codes that use the subspace
channel only once. In contrast, this paper explores the idea of using the
subspace channel more than once and investigates the so called multishot
subspace codes. We present definitions for the problem, a motivating example,
lower and upper bounds for the size of codes, and a multilevel construction of
codes based on block-coded modulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1683</identifier>
 <datestamp>2009-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1683</id><created>2009-01-13</created><updated>2009-01-15</updated><authors><author><keyname>Dashmiz</keyname><forenames>Sh.</forenames></author><author><keyname>Pad</keyname><forenames>P.</forenames></author><author><keyname>Marvasti</keyname><forenames>F.</forenames></author></authors><title>New Bounds for Binary and Ternary Overloaded CDMA</title><categories>cs.IT cs.DM math.CO math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study binary and ternary matrices that are used for CDMA
applications that are injective on binary or ternary user vectors. In other
words, in the absence of additive noise, the interference of overloaded CDMA
can be removed completely. Some new algorithms are proposed for constructing
such matrices. Also, using an information theoretic approach, we conjecture the
extent to which such CDMA matrix codes exist. For overloaded case, we also show
that some of the codes derived from our algorithms perform better than the
binary Welch Bound Equality codes; the decoding is ML but of low complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1684</identifier>
 <datestamp>2009-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1684</id><created>2009-01-12</created><authors><author><keyname>Bayati</keyname><forenames>M.</forenames></author><author><keyname>Braunstein</keyname><forenames>A.</forenames></author><author><keyname>Zecchina</keyname><forenames>R.</forenames></author></authors><title>A rigorous analysis of the cavity equations for the minimum spanning
  tree</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.DS</categories><comments>5 pages, 1 figure</comments><journal-ref>J. Math. Phys. 49, 125206 (2008)</journal-ref><doi>10.1063/1.2982805</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze a new general representation for the Minimum Weight Steiner Tree
(MST) problem which translates the topological connectivity constraint into a
set of local conditions which can be analyzed by the so called cavity equations
techniques. For the limit case of the Spanning tree we prove that the fixed
point of the algorithm arising from the cavity equations leads to the global
optimum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1694</identifier>
 <datestamp>2009-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1694</id><created>2009-01-12</created><authors><author><keyname>Somaraju</keyname><forenames>Ram</forenames></author><author><keyname>Trumpf</keyname><forenames>Jochen</forenames></author></authors><title>Degrees of Freedom of a Communication Channel: Using Generalised
  Singular Values</title><categories>cs.IT math.IT</categories><comments>16 pages, 2 figures. Submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental problem in any communication system is: given a communication
channel between a transmitter and a receiver, how many &quot;independent&quot; signals
can be exchanged between them? Arbitrary communication channels that can be
described by linear compact channel operators mapping between normed spaces are
examined in this paper. The (well-known) notions of degrees of freedom at level
$\epsilon$ and essential dimension of such channels are developed in this
general setting. We argue that the degrees of freedom at level $\epsilon$ and
the essential dimension fundamentally limit the number of independent signals
that can be exchanged between the transmitter and the receiver. We also
generalise the concept of singular values of compact operators to be applicable
to compact operators defined on arbitrary normed spaces which do not
necessarily carry a Hilbert space structure. We show how these generalised
singular values can be used to calculate the degrees of freedom at level
$\epsilon$ and the essential dimension of compact operators that describe
communication channels. We describe physically realistic channels that require
such general channel models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1695</identifier>
 <datestamp>2009-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1695</id><created>2009-01-12</created><authors><author><keyname>Etkin</keyname><forenames>Raul</forenames></author><author><keyname>Ordentlich</keyname><forenames>Erik</forenames></author></authors><title>On the Degrees-of-Freedom of the K-User Gaussian Interference Channel</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory, June 18, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The degrees-of-freedom of a K-user Gaussian interference channel (GIFC) has
been defined to be the multiple of (1/2)log_2(P) at which the maximum sum of
achievable rates grows with increasing P. In this paper, we establish that the
degrees-of-freedom of three or more user, real, scalar GIFCs, viewed as a
function of the channel coefficients, is discontinuous at points where all of
the coefficients are non-zero rational numbers. More specifically, for all K&gt;2,
we find a class of K-user GIFCs that is dense in the GIFC parameter space for
which K/2 degrees-of-freedom are exactly achievable, and we show that the
degrees-of-freedom for any GIFC with non-zero rational coefficients is strictly
smaller than K/2. These results are proved using new connections with number
theory and additive combinatorics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1696</identifier>
 <datestamp>2009-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1696</id><created>2009-01-12</created><authors><author><keyname>Gustavson</keyname><forenames>Fred G.</forenames></author><author><keyname>Wasniewski</keyname><forenames>Jerzy</forenames></author><author><keyname>Dongarra</keyname><forenames>Jack J.</forenames></author><author><keyname>Langou</keyname><forenames>Julien</forenames></author></authors><title>Rectangular Full Packed Format for Cholesky's Algorithm: Factorization,
  Solution and Inversion</title><categories>cs.MS cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new data format for storing triangular, symmetric, and
Hermitian matrices called RFPF (Rectangular Full Packed Format). The standard
two dimensional arrays of Fortran and C (also known as full format) that are
used to represent triangular and symmetric matrices waste nearly half of the
storage space but provide high performance via the use of Level 3 BLAS.
Standard packed format arrays fully utilize storage (array space) but provide
low performance as there is no Level 3 packed BLAS. We combine the good
features of packed and full storage using RFPF to obtain high performance via
using Level 3 BLAS as RFPF is a standard full format representation. Also, RFPF
requires exactly the same minimal storage as packed format. Each LAPACK full
and/or packed triangular, symmetric, and Hermitian routine becomes a single new
RFPF routine based on eight possible data layouts of RFPF. This new RFPF
routine usually consists of two calls to the corresponding LAPACK full format
routine and two calls to Level 3 BLAS routines. This means {\it no} new
software is required. As examples, we present LAPACK routines for Cholesky
factorization, Cholesky solution and Cholesky inverse computation in RFPF to
illustrate this new work and to describe its performance on several commonly
used computer platforms. Performance of LAPACK full routines using RFPF versus
LAPACK full routines using standard format for both serial and SMP parallel
processing is about the same while using half the storage. Performance gains
are roughly one to a factor of 43 for serial and one to a factor of 97 for SMP
parallel times faster using vendor LAPACK full routines with RFPF than with
using vendor and/or reference packed routines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1703</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1703</id><created>2009-01-12</created><updated>2010-06-29</updated><authors><author><keyname>Jose</keyname><forenames>Jubin</forenames></author><author><keyname>Ashikhmin</keyname><forenames>Alexei</forenames></author><author><keyname>Marzetta</keyname><forenames>Thomas L.</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Pilot Contamination and Precoding in Multi-Cell TDD Systems</title><categories>cs.IT math.IT</categories><comments>23 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a multi-cell multiple antenna system with precoding used
at the base stations for downlink transmission. For precoding at the base
stations, channel state information (CSI) is essential at the base stations. A
popular technique for obtaining this CSI in time division duplex (TDD) systems
is uplink training by utilizing the reciprocity of the wireless medium. This
paper mathematically characterizes the impact that uplink training has on the
performance of such multi-cell multiple antenna systems. When non-orthogonal
training sequences are used for uplink training, the paper shows that the
precoding matrix used by the base station in one cell becomes corrupted by the
channel between that base station and the users in other cells in an
undesirable manner. This paper analyzes this fundamental problem of pilot
contamination in multi-cell systems. Furthermore, it develops a new multi-cell
MMSE-based precoding method that mitigate this problem. In addition to being a
linear precoding method, this precoding method has a simple closed-form
expression that results from an intuitive optimization problem formulation.
Numerical results show significant performance gains compared to certain
popular single-cell precoding methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1705</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1705</id><created>2009-01-12</created><updated>2010-04-18</updated><authors><author><keyname>Timo</keyname><forenames>Roy</forenames></author><author><keyname>Chan</keyname><forenames>Terence</forenames></author><author><keyname>Grant</keyname><forenames>Alexander</forenames></author></authors><title>Rate-Distortion with Side-Information at Many Decoders</title><categories>cs.IT math.IT</categories><comments>36 pages. Submitted to IEEE Transactions on Information Theory. In
  proc. ISIT 2010.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new inner bound for the rate region of the $t$-stage
successive-refinement problem with side-information. We also present a new
upper bound for the rate-distortion function for lossy-source coding with
multiple decoders and side-information. Characterising this rate-distortion
function is a long-standing open problem, and it is widely believed that the
tightest upper bound is provided by Theorem 2 of Heegard and Berger's paper
&quot;Rate Distortion when Side Information may be Absent&quot;, \emph{IEEE Trans.
Inform. Theory}, 1985. We give a counterexample to Heegard and Berger's result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1708</identifier>
 <datestamp>2009-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1708</id><created>2009-01-12</created><authors><author><keyname>Tadaki</keyname><forenames>Kohtaro</forenames></author></authors><title>A statistical mechanical interpretation of instantaneous codes</title><categories>cs.IT math.IT</categories><comments>5 pages, Proceedings of the 2007 IEEE International Symposium on
  Information Theory, pp.1906 - 1910, Nice, France, June 24 - 29, 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we develop a statistical mechanical interpretation of the
noiseless source coding scheme based on an absolutely optimal instantaneous
code. The notions in statistical mechanics such as statistical mechanical
entropy, temperature, and thermal equilibrium are translated into the context
of noiseless source coding. Especially, it is discovered that the temperature 1
corresponds to the average codeword length of an instantaneous code in this
statistical mechanical interpretation of noiseless source coding scheme. This
correspondence is also verified by the investigation using box-counting
dimension. Using the notion of temperature and statistical mechanical
arguments, some information-theoretic relations can be derived in the manner
which appeals to intuition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1732</identifier>
 <datestamp>2009-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1732</id><created>2009-01-13</created><updated>2009-08-20</updated><authors><author><keyname>Lomnitz</keyname><forenames>Yuval</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author></authors><title>Feedback Communication over Individual Channels</title><categories>cs.IT math.IT</categories><comments>Final ISIT 2009 version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of communicating over a channel for which no
mathematical model is specified. We present achievable rates as a function of
the channel input and output sequences known a-posteriori for discrete and
continuous channels. Furthermore we present a rate-adaptive scheme employing
feedback which achieves these rates asymptotically without prior knowledge of
the channel behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1737</identifier>
 <datestamp>2009-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1737</id><created>2009-01-13</created><updated>2009-08-20</updated><authors><author><keyname>Lomnitz</keyname><forenames>Yuval</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author></authors><title>Power Adaptive Feedback Communication over an Additive Individual Noise
  Sequence Channel</title><categories>cs.IT math.IT</categories><comments>Final ISIT 2009 version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a real-valued additive channel with an individual unknown noise
sequence. We present a simple sequential communication scheme based on the
celebrated Schalkwijk-Kailath scheme, which varies the transmit power according
to the power of the sequence, so that asymptotically the relation between the
SNR and the rate matches the Gaussian channel capacity 1/2 log(1+SNR)for almost
every noise sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1753</identifier>
 <datestamp>2009-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1753</id><created>2009-01-13</created><authors><author><keyname>Aditya</keyname><forenames>S. T.</forenames></author><author><keyname>Dabeer</keyname><forenames>Onkar</forenames></author><author><keyname>Dey</keyname><forenames>Bikash Kumar</forenames></author></authors><title>A Channel Coding Perspective of Recommendation Systems</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by recommendation systems, we consider the problem of estimating
block constant binary matrices (of size $m \times n$) from sparse and noisy
observations. The observations are obtained from the underlying block constant
matrix after unknown row and column permutations, erasures, and errors. We
derive upper and lower bounds on the achievable probability of error. For fixed
erasure and error probability, we show that there exists a constant $C_1$ such
that if the cluster sizes are less than $C_1 \ln(mn)$, then for any algorithm
the probability of error approaches one as $m, n \tends \infty$. On the other
hand, we show that a simple polynomial time algorithm gives probability of
error diminishing to zero provided the cluster sizes are greater than $C_2
\ln(mn)$ for a suitable constant $C_2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1761</identifier>
 <datestamp>2009-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1761</id><created>2009-01-13</created><authors><author><keyname>Gfeller</keyname><forenames>Beat</forenames></author><author><keyname>Sanders</keyname><forenames>Peter</forenames></author></authors><title>Towards Optimal Range Medians</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following problem: given an unsorted array of $n$ elements,
and a sequence of intervals in the array, compute the median in each of the
subarrays defined by the intervals. We describe a simple algorithm which uses
O(n) space and needs $O(n\log k + k\log n)$ time to answer the first $k$
queries. This improves previous algorithms by a logarithmic factor and matches
a lower bound for $k=O(n)$.
  Since the algorithm decomposes the range of element values rather than the
array, it has natural generalizations to higher dimensional problems -- it
reduces a range median query to a logarithmic number of range counting queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1762</identifier>
 <datestamp>2009-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1762</id><created>2009-01-13</created><updated>2009-01-19</updated><authors><author><keyname>Lee</keyname><forenames>Ki-Moon</forenames></author><author><keyname>Radha</keyname><forenames>Hayder</forenames></author><author><keyname>Kim</keyname><forenames>Beom-Jin</forenames></author></authors><title>A Tight Estimate for Decoding Error-Probability of LT Codes Using
  Kovalenko's Rank Distribution</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>Submitted to ISIT 2009, Seoul, Korea</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A new approach for estimating the Decoding Error-Probability (DEP) of LT
codes with dense rows is derived by using the conditional Kovalenko's rank
distribution. The estimate by the proposed approach is very close to the DEP
approximated by Gaussian Elimination, and is significantly less complex. As a
key application, we utilize the estimates for obtaining optimal LT codes with
dense rows, whose DEP is very close to the Kovalenko's Full-Rank Limit within a
desired error-bound. Experimental evidences which show the viability of the
estimates are also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1782</identifier>
 <datestamp>2009-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1782</id><created>2009-01-13</created><authors><author><keyname>Casetti</keyname><forenames>Claudio</forenames></author><author><keyname>Chiasserini</keyname><forenames>Carla-Fabiana</forenames></author><author><keyname>Fiore</keyname><forenames>Marco</forenames></author><author><keyname>La</keyname><forenames>Chi-Anh</forenames></author><author><keyname>Michiardi</keyname><forenames>Pietro</forenames></author></authors><title>A Holistic Approach to Information Distribution in Ad Hoc Networks</title><categories>cs.NI cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the problem of spreading information contents in a wireless ad
hoc network with mechanisms embracing the peer-to-peer paradigm. In our vision,
information dissemination should satisfy the following requirements: (i) it
conforms to a predefined distribution and (ii) it is evenly and fairly carried
by all nodes in their turn. In this paper, we observe the dissemination effects
when the information moves across nodes according to two well-known mobility
models, namely random walk and random direction. Our approach is fully
distributed and comes at a very low cost in terms of protocol overhead; in
addition, simulation results show that the proposed solution can achieve the
aforementioned goals under different network scenarios, provided that a
sufficient number of information replicas are injected into the network. This
observation calls for a further step: in the realistic case where the user
content demand varies over time, we need a content replication/drop strategy to
adapt the number of information replicas to the changes in the information
query rate. We therefore devise a distributed, lightweight scheme that performs
efficiently in a variety of scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1821</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1821</id><created>2009-01-13</created><updated>2011-01-28</updated><authors><author><keyname>Henrion</keyname><forenames>Didier</forenames><affiliation>LAAS, CTU/FEE</affiliation></author></authors><title>Semidefinite representation of convex hulls of rational varieties</title><categories>math.OC cs.SY math.AG</categories><proxy>ccsd</proxy><report-no>Rapport LAAS No. 09001</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using elementary duality properties of positive semidefinite moment matrices
and polynomial sum-of-squares decompositions, we prove that the convex hull of
rationally parameterized algebraic varieties is semidefinite representable
(that is, it can be represented as a projection of an affine section of the
cone of positive semidefinite matrices) in the case of (a) curves; (b)
hypersurfaces parameterized by quadratics; and (c) hypersurfaces parameterized
by bivariate quartics; all in an ambient space of arbitrary dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1824</identifier>
 <datestamp>2009-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1824</id><created>2009-01-13</created><authors><author><keyname>Bracken</keyname><forenames>Carl</forenames></author><author><keyname>Leander</keyname><forenames>Gregor</forenames></author></authors><title>A Highly Nonlinear Differentially 4 Uniform Power Mapping That Permutes
  Fields of Even Degree</title><categories>cs.IT math.IT</categories><comments>10 pages, submitted to Finite Fields and Their Applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Functions with low differential uniformity can be used as the s-boxes of
symmetric cryptosystems as they have good resistance to differential attacks.
The AES (Advanced Encryption Standard) uses a differentially-4 uniform function
called the inverse function. Any function used in a symmetric cryptosystem
should be a permutation. Also, it is required that the function is highly
nonlinear so that it is resistant to Matsui's linear attack. In this article we
demonstrate that a highly nonlinear permutation discovered by Hans Dobbertin
has differential uniformity of four and hence, with respect to differential and
linear cryptanalysis, is just as suitable for use in a symmetric cryptosystem
as the inverse function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1827</identifier>
 <datestamp>2009-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1827</id><created>2009-01-13</created><authors><author><keyname>Bracken</keyname><forenames>Carl</forenames></author><author><keyname>Helleseth</keyname><forenames>Tor</forenames></author></authors><title>Triple-Error-Correcting BCH-Like Codes</title><categories>cs.IT math.IT</categories><comments>7 pages, submitted to ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The binary primitive triple-error-correcting BCH code is a cyclic code of
minimum distance 7 with generator polynomial having zeros $\alpha$, $\alpha^3$
and $\alpha^5$ where $\alpha$ is a primitive root of unity. The zero set of the
code is said to be {1,3,5}. In the 1970's Kasami showed that one can construct
similar triple-error-correcting codes using zero sets consisting of different
triples than the BCH codes. Furthermore, in 2000 Chang et. al. found new
triples leading to triple-error-correcting codes. In this paper a new such
triple is presented. In addition a new method is presented that may be of
interest in finding further such triples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1848</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1848</id><created>2009-01-13</created><updated>2010-12-03</updated><authors><author><keyname>Giesbrecht</keyname><forenames>Mark</forenames></author><author><keyname>Roche</keyname><forenames>Daniel S.</forenames></author></authors><title>Detecting lacunary perfect powers and computing their roots</title><categories>cs.SC</categories><comments>to appear in Journal of Symbolic Computation (JSC), 2011</comments><acm-class>I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider solutions to the equation f = h^r for polynomials f and h and
integer r &gt; 1. Given a polynomial f in the lacunary (also called sparse or
super-sparse) representation, we first show how to determine if f can be
written as h^r and, if so, to find such an r. This is a Monte Carlo randomized
algorithm whose cost is polynomial in the number of non-zero terms of f and in
log(deg f), i.e., polynomial in the size of the lacunary representation, and it
works over GF(q)[x] (for large characteristic) as well as Q[x]. We also give
two deterministic algorithms to compute the perfect root h given f and r. The
first is output-sensitive (based on the sparsity of h) and works only over
Q[x]. A sparsity-sensitive Newton iteration forms the basis for the second
approach to computing h, which is extremely efficient and works over both
GF(q)[x] (for large characteristic) and Q[x], but depends on a number-theoretic
conjecture. Work of Erdos, Schinzel, Zannier, and others suggests that both of
these algorithms are unconditionally polynomial-time in the lacunary size of
the input polynomial f. Finally, we demonstrate the efficiency of the
randomized detection algorithm and the latter perfect root computation
algorithm with an implementation in the C++ library NTL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1849</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1849</id><created>2009-01-13</created><updated>2010-07-16</updated><authors><author><keyname>Doty</keyname><forenames>David</forenames></author></authors><title>Randomized Self-Assembly for Exact Shapes</title><categories>cs.CC cs.DS</categories><comments>Conference version accepted to FOCS 2009. Present version accepted to
  SIAM Journal on Computing, which adds new sections on arbitrary scaled
  shapes, smooth trade-off between specifying bits of n through concentrations
  versus hardcoded tile types, and construction that uses concentrations
  arbitrarily close to uniform to fix potential thermodynamic problems with
  model</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Working in Winfree's abstract tile assembly model, we show that a
constant-size tile assembly system can be programmed through relative tile
concentrations to build an n x n square with high probability, for any
sufficiently large n. This answers an open question of Kao and Schweller
(Randomized Self-Assembly for Approximate Shapes, ICALP 2008), who showed how
to build an approximately n x n square using tile concentration programming,
and asked whether the approximation could be made exact with high probability.
We show how this technique can be modified to answer another question of Kao
and Schweller, by showing that a constant-size tile assembly system can be
programmed through tile concentrations to assemble arbitrary finite *scaled
shapes*, which are shapes modified by replacing each point with a c x c block
of points, for some integer c. Furthermore, we exhibit a smooth tradeoff
between specifying bits of n via tile concentrations versus specifying them via
hard-coded tile types, which allows tile concentration programming to be
employed for specifying a fraction of the bits of &quot;input&quot; to a tile assembly
system, under the constraint that concentrations can only be specified to a
limited precision. Finally, to account for some unrealistic aspects of the tile
concentration programming model, we show how to modify the construction to use
only concentrations that are arbitrarily close to uniform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1853</identifier>
 <datestamp>2009-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1853</id><created>2009-01-13</created><updated>2009-01-28</updated><authors><author><keyname>Langberg</keyname><forenames>Michael</forenames></author><author><keyname>Jaggi</keyname><forenames>Sidharth</forenames></author><author><keyname>Dey</keyname><forenames>Bikash Kumar</forenames></author></authors><title>Binary Causal-Adversary Channels</title><categories>cs.IT math.IT</categories><comments>8 pages, 1 figure, extended version of paper submitted to the
  International Symposium on Information Theory, 2009 (ISIT2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we consider the communication of information in the presence of
a causal adversarial jammer. In the setting under study, a sender wishes to
communicate a message to a receiver by transmitting a codeword x=(x_1,...,x_n)
bit-by-bit over a communication channel. The adversarial jammer can view the
transmitted bits x_i one at a time, and can change up to a p-fraction of them.
However, the decisions of the jammer must be made in an online or causal
manner. Namely, for each bit x_i the jammer's decision on whether to corrupt it
or not (and on how to change it) must depend only on x_j for j &lt;= i. This is in
contrast to the &quot;classical&quot; adversarial jammer which may base its decisions on
its complete knowledge of x. We present a non-trivial upper bound on the amount
of information that can be communicated. We show that the achievable rate can
be asymptotically no greater than min{1-H(p),(1-4p)^+}. Here H(.) is the binary
entropy function, and (1-4p)^+ equals 1-4p for p &lt; 0.25, and 0 otherwise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1864</identifier>
 <datestamp>2009-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1864</id><created>2009-01-13</created><authors><author><keyname>Srinidhi</keyname><forenames>N.</forenames></author><author><keyname>Mohammed</keyname><forenames>Saif K.</forenames></author><author><keyname>Chockalingam</keyname><forenames>A.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Low-Complexity Near-ML Decoding of Large Non-Orthogonal STBCs using
  Reactive Tabu Search</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-orthogonal space-time block codes (STBC) with {\em large dimensions} are
attractive because they can simultaneously achieve both high spectral
efficiencies (same spectral efficiency as in V-BLAST for a given number of
transmit antennas) {\em as well as} full transmit diversity. Decoding of
non-orthogonal STBCs with large dimensions has been a challenge. In this paper,
we present a reactive tabu search (RTS) based algorithm for decoding
non-orthogonal STBCs from cyclic division algebras (CDA) having large
dimensions. Under i.i.d fading and perfect channel state information at the
receiver (CSIR), our simulation results show that RTS based decoding of
$12\times 12$ STBC from CDA and 4-QAM with 288 real dimensions achieves $i)$
$10^{-3}$ uncoded BER at an SNR of just 0.5 dB away from SISO AWGN performance,
and $ii)$ a coded BER performance close to within about 5 dB of the theoretical
MIMO capacity, using rate-3/4 turbo code at a spectral efficiency of 18 bps/Hz.
RTS is shown to achieve near SISO AWGN performance with less number of
dimensions than with LAS algorithm (which we reported recently) at some extra
complexity than LAS. We also report good BER performance of RTS when i.i.d
fading and perfect CSIR assumptions are relaxed by considering a spatially
correlated MIMO channel model, and by using a training based iterative RTS
decoding/channel estimation scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1866</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1866</id><created>2009-01-13</created><updated>2011-07-22</updated><authors><author><keyname>Cheraghchi</keyname><forenames>Mahdi</forenames></author></authors><title>Capacity Achieving Codes From Randomness Condensers</title><categories>cs.IT math.IT</categories><comments>Full version. A preliminary summary of this work appears (under the
  title &quot;Capacity Achieving Codes From Randomness~Conductors&quot;) in proceedings
  of the 2009 IEEE International Symposium on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish a general framework for construction of small ensembles of
capacity achieving linear codes for a wide range of (not necessarily
memoryless) discrete symmetric channels, and in particular, the binary erasure
and symmetric channels. The main tool used in our constructions is the notion
of randomness extractors and lossless condensers that are regarded as central
tools in theoretical computer science. Same as random codes, the resulting
ensembles preserve their capacity achieving properties under any change of
basis. Using known explicit constructions of condensers, we obtain specific
ensembles whose size is as small as polynomial in the block length. By applying
our construction to Justesen's concatenation scheme (Justesen, 1972) we obtain
explicit capacity achieving codes for BEC (resp., BSC) with almost linear time
encoding and almost linear time (resp., quadratic time) decoding and
exponentially small error probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1867</identifier>
 <datestamp>2009-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1867</id><created>2009-01-13</created><authors><author><keyname>Suneel</keyname><forenames>Madhekar</forenames></author><author><keyname>Som</keyname><forenames>Pritam</forenames></author><author><keyname>Chockalingam</keyname><forenames>A.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Belief Propagation Based Decoding of Large Non-Orthogonal STBCs</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a belief propagation (BP) based algorithm for
decoding non-orthogonal space-time block codes (STBC) from cyclic division
algebras (CDA) having {\em large dimensions}. The proposed approach involves
message passing on Markov random field (MRF) representation of the STBC MIMO
system. Adoption of BP approach to decode non-orthogonal STBCs of large
dimensions has not been reported so far. Our simulation results show that the
proposed BP-based decoding achieves increasingly closer to SISO AWGN
performance for increased number of dimensions. In addition, it also achieves
near-capacity turbo coded BER performance; for e.g., with BP decoding of
$24\times 24$ STBC from CDA using BPSK (i.e., 576 real dimensions) and rate-1/2
turbo code (i.e., 12 bps/Hz spectral efficiency), coded BER performance close
to within just about 2.5 dB from the theoretical MIMO capacity is achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1869</identifier>
 <datestamp>2009-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1869</id><created>2009-01-13</created><authors><author><keyname>Mohammed</keyname><forenames>Saif K.</forenames></author><author><keyname>Chockalingam</keyname><forenames>A.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Low-Complexity Near-ML Decoding of Large Non-Orthogonal STBCs Using PDA</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-orthogonal space-time block codes (STBC) from cyclic division algebras
(CDA) having large dimensions are attractive because they can simultaneously
achieve both high spectral efficiencies (same spectral efficiency as in V-BLAST
for a given number of transmit antennas) {\em as well as} full transmit
diversity. Decoding of non-orthogonal STBCs with hundreds of dimensions has
been a challenge. In this paper, we present a probabilistic data association
(PDA) based algorithm for decoding non-orthogonal STBCs with large dimensions.
Our simulation results show that the proposed PDA-based algorithm achieves near
SISO AWGN uncoded BER as well as near-capacity coded BER (within about 5 dB of
the theoretical capacity) for large non-orthogonal STBCs from CDA. We study the
effect of spatial correlation on the BER, and show that the performance loss
due to spatial correlation can be alleviated by providing more receive spatial
dimensions. We report good BER performance when a training-based iterative
decoding/channel estimation is used (instead of assuming perfect channel
knowledge) in channels with large coherence times. A comparison of the
performances of the PDA algorithm and the likelihood ascent search (LAS)
algorithm (reported in our recent work) is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1886</identifier>
 <datestamp>2009-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1886</id><created>2009-01-14</created><authors><author><keyname>Didier</keyname><forenames>Frederic</forenames></author></authors><title>Efficient erasure decoding of Reed-Solomon codes</title><categories>cs.IT cs.DS math.IT</categories><comments>4 pages, submitted to ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a practical algorithm to decode erasures of Reed-Solomon codes
over the q elements binary field in O(q \log_2^2 q) time where the constant
implied by the O-notation is very small. Asymptotically fast algorithms based
on fast polynomial arithmetic were already known, but even if their complexity
is similar, they are mostly impractical. By comparison our algorithm uses only
a few Walsh transforms and has been easily implemented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1892</identifier>
 <datestamp>2014-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1892</id><created>2009-01-13</created><updated>2014-03-28</updated><authors><author><keyname>Venkataramanan</keyname><forenames>Ramji</forenames></author><author><keyname>Pradhan</keyname><forenames>S. Sandeep</forenames></author></authors><title>A New Achievable Rate Region for the Discrete Memoryless Multiple-Access
  Channel with Noiseless Feedback</title><categories>cs.IT math.IT</categories><comments>appeared in IEEE Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. 57, no.12, pp.
  8038-8054, Dec. 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new single-letter achievable rate region is proposed for the two-user
discrete memoryless multiple-access channel(MAC) with noiseless feedback. The
proposed region includes the Cover-Leung rate region [1], and it is shown that
the inclusion is strict. The proof uses a block-Markov superposition strategy
based on the observation that the messages of the two users are correlated
given the feedback. The rates of transmission are too high for each encoder to
decode the other's message directly using the feedback, so they transmit
correlated information in the next block to learn the message of one another.
They then cooperate in the following block to resolve the residual uncertainty
of the decoder. The coding scheme may be viewed as a natural generalization of
the Cover-Leung scheme with a delay of one extra block and a pair of additional
auxiliary random variables. We compute the proposed rate region for two
different MACs and compare the results with other known rate regions for the
MAC with feedback. Finally, we show how the coding scheme can be extended to
obtain larger rate regions with more auxiliary random variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1898</identifier>
 <datestamp>2009-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1898</id><created>2009-01-13</created><updated>2009-05-01</updated><authors><author><keyname>Lee</keyname><forenames>Kiryung</forenames></author><author><keyname>Bresler</keyname><forenames>Yoram</forenames></author></authors><title>Efficient and Guaranteed Rank Minimization by Atomic Decomposition</title><categories>math.NA cs.IT math.IT</categories><comments>submitted to ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recht, Fazel, and Parrilo provided an analogy between rank minimization and
$\ell_0$-norm minimization. Subject to the rank-restricted isometry property,
nuclear norm minimization is a guaranteed algorithm for rank minimization. The
resulting semidefinite formulation is a convex problem but in practice the
algorithms for it do not scale well to large instances. Instead, we explore
missing terms in the analogy and propose a new algorithm which is
computationally efficient and also has a performance guarantee. The algorithm
is based on the atomic decomposition of the matrix variable and extends the
idea in the CoSaMP algorithm for $\ell_0$-norm minimization. Combined with the
recent fast low rank approximation of matrices based on randomization, the
proposed algorithm can efficiently handle large scale rank minimization
problems.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="5000" completeListSize="102538">1122234|6001</resumptionToken>
</ListRecords>
</OAI-PMH>
