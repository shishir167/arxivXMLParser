<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:47:10Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|17001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0279</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0279</id><created>2010-11-01</created><authors><author><keyname>Taghiloo</keyname><forenames>Majid</forenames></author><author><keyname>Agheli</keyname><forenames>Mohammad Ali</forenames></author><author><keyname>Rezaeinezhad</keyname><forenames>Mohammad Reza</forenames></author></authors><title>Mobile Based Secure Digital Wallet for Peer to Peer Payment System</title><categories>cs.CE</categories><journal-ref>International Journal of UbiComp (IJU), Vol.1, No.4, October 2010</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  E-commerce in today's conditions has the highest dependence on network
infrastructure of banking. However, when the possibility of communicating with
the Banking network is not provided, business activities will suffer. This
paper proposes a new approach of digital wallet based on mobile devices without
the need to exchange physical money or communicate with banking network. A
digital wallet is a software component that allows a user to make an electronic
payment in cash (such as a credit card or a digital coin), and hides the
low-level details of executing the payment protocol that is used to make the
payment. The main features of proposed architecture are secure awareness, fault
tolerance, and infrastructure-less protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0280</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0280</id><created>2010-11-01</created><authors><author><keyname>Ibrahim</keyname><forenames>Rosziati</forenames></author></authors><title>From UML Specification into Implementation using Object Mapping</title><categories>cs.SE</categories><comments>9 pages</comments><msc-class>www.ccsenet.org/cis</msc-class><journal-ref>Computer and Information Science, Vol 3, No 3, August 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In information systems, a system is analyzed using a modeling tool. Analysis
is an important phase prior to implementation in order to obtain the correct
requirements of the system. During the requirements phase, the software
requirements specification (SRS) is used to specify the system requirements.
Then, this requirements specification is used to implement the system. The
requirements specification can be represented using either a structure approach
or an object-oriented approach. A UML (Unified Modeling Language) specification
is a well-known for representation of requirements specification in an
object-oriented approach. In this paper, we present one case study and discuss
how mapping from UML specification into implementation is done. The case study
does not require advanced programming skills. However, it does require
familiarity in creating and instantiating classes, object-oriented programming
with inheritance, data structure, file processing and control loop. For the
case study, UML specification is used in requirements phase and Borland C++ is
used in implementation phase. Based on the case study, it shows that the
proposed approach improved the understanding of mapping from UML specification
into implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0298</identifier>
 <datestamp>2010-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0298</id><created>2010-11-01</created><authors><author><keyname>Mehmood</keyname><forenames>Nayyar</forenames></author><author><keyname>Qureshi</keyname><forenames>Imran Haider</forenames></author></authors><title>Intuitionistic Fuzzy Ideal Extensions of {\Gamma}-Semigroups</title><categories>cs.IT math.IT</categories><comments>Accepted, 11 pages</comments><msc-class>20M12, 03F55, 08A72</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the concept of the extensions of intuitionistic fuzzy ideals in
a semigroup has been extended to a {\Gamma}-Semigroups. Among other results
characterization of prime ideals in a {\Gamma}-Semigroups in terms of
intuitionistic fuzzy ideal extension has been obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0306</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0306</id><created>2010-11-01</created><authors><author><keyname>Gupta</keyname><forenames>Siddharth</forenames></author><author><keyname>Thakur</keyname><forenames>Narina</forenames></author></authors><title>Semantic Query Optimisation with Ontology Simulation</title><categories>cs.IR</categories><journal-ref>IJWEST October 2010 Volume 1, Number 4</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semantic Web is, without a doubt, gaining momentum in both industry and
academia. The word &quot;Semantic&quot; refers to &quot;meaning&quot; - a semantic web is a web of
meaning. In this fast changing and result oriented practical world, gone are
the days where an individual had to struggle for finding information on the
Internet where knowledge management was the major issue. The semantic web has a
vision of linking, integrating and analysing data from various data sources and
forming a new information stream, hence a web of databases connected with each
other and machines interacting with other machines to yield results which are
user oriented and accurate. With the emergence of Semantic Web framework the
na\&quot;ive approach of searching information on the syntactic web is clich\'e.
This paper proposes an optimised semantic searching of keywords exemplified by
simulation an ontology of Indian universities with a proposed algorithm which
ramifies the effective semantic retrieval of information which is easy to
access and time saving.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0313</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0313</id><created>2010-11-01</created><authors><author><keyname>G&#xfc;tschow</keyname><forenames>Johannes</forenames></author><author><keyname>Nesme</keyname><forenames>Vincent</forenames></author><author><keyname>Werner</keyname><forenames>Reinhard F.</forenames></author></authors><title>The fractal structure of cellular automata on Abelian groups</title><categories>cs.DM quant-ph</categories><comments>29 pages, 15 figures, preprint of a journal version</comments><msc-class>68Q80, 28A80</msc-class><acm-class>F.1.1; I.3.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well-known that the spacetime diagrams of some cellular automata have a
fractal structure: for instance Pascal's triangle modulo 2 generates a
Sierpinski triangle. Explaining the fractal structure of the spacetime diagrams
of cellular automata is a much explored topic, but virtually all of the results
revolve around a special class of automata, whose typical features include
irreversibility, an alphabet with a ring structure, a global evolution that is
a ring homomorphism, and a property known as (weakly) p-Fermat. The class of
automata that we study in this article has none of these properties. Their cell
structure is weaker, as it does not come with a multiplication, and they are
far from being p-Fermat, even weakly. However, they do produce fractal
spacetime diagrams, and we explain why and how.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0328</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0328</id><created>2010-11-01</created><authors><author><keyname>Ghosh</keyname><forenames>Soumadip</forenames></author><author><keyname>Biswas</keyname><forenames>Sushanta</forenames></author><author><keyname>Sarkar</keyname><forenames>Debasree</forenames></author><author><keyname>Sarkar</keyname><forenames>Partha Pratim</forenames></author></authors><title>Mining Frequent Itemsets Using Genetic Algorithm</title><categories>cs.DB</categories><journal-ref>International Journal of Artificial Intelligence &amp; Applications
  (IJAIA), Vol.1, No.4, October 2010</journal-ref><doi>10.5121/ijaia.2010.1411</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In general frequent itemsets are generated from large data sets by applying
association rule mining algorithms like Apriori, Partition, Pincer-Search,
Incremental, Border algorithm etc., which take too much computer time to
compute all the frequent itemsets. By using Genetic Algorithm (GA) we can
improve the scenario. The major advantage of using GA in the discovery of
frequent itemsets is that they perform global search and its time complexity is
less compared to other algorithms as the genetic algorithm is based on the
greedy approach. The main aim of this paper is to find all the frequent
itemsets from given data sets using genetic algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0330</identifier>
 <datestamp>2012-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0330</id><created>2010-11-01</created><updated>2012-03-11</updated><authors><author><keyname>Cederborg</keyname><forenames>Thomas</forenames></author><author><keyname>Oudeyer</keyname><forenames>Pierre-Yves</forenames></author></authors><title>Imitation learning of motor primitives and language bootstrapping in
  robots</title><categories>cs.AI</categories><comments>This paper has been withdrawn by the author due to several issues
  regarding the clarity of presentation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Imitation learning in robots, also called programing by demonstration, has
made important advances in recent years, allowing humans to teach context
dependant motor skills/tasks to robots. We propose to extend the usual contexts
investigated to also include acoustic linguistic expressions that might denote
a given motor skill, and thus we target joint learning of the motor skills and
their potential acoustic linguistic name. In addition to this, a modification
of a class of existing algorithms within the imitation learning framework is
made so that they can handle the unlabeled demonstration of several tasks/motor
primitives without having to inform the imitator of what task is being
demonstrated or what the number of tasks are, which is a necessity for language
learning, i.e; if one wants to teach naturally an open number of new motor
skills together with their acoustic names. Finally, a mechanism for detecting
whether or not linguistic input is relevant to the task is also proposed, and
our architecture also allows the robot to find the right framing for a given
identified motor primitive. With these additions it becomes possible to build
an imitator that bridges the gap between imitation learning and language
learning by being able to learn linguistic expressions using methods from the
imitation learning community. In this sense the imitator can learn a word by
guessing whether a certain speech pattern present in the context means that a
specific task is to be executed. The imitator is however not assumed to know
that speech is relevant and has to figure this out on its own by looking at the
demonstrations: indeed, the architecture allows the robot to transparently also
learn tasks which should not be triggered by an acoustic word, but for example
by the color or position of an object or a gesture made by someone in the
environment. To demonstrate this ability to find the ...
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0338</identifier>
 <datestamp>2010-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0338</id><created>2010-11-01</created><updated>2010-11-03</updated><authors><author><keyname>Alagoz</keyname><forenames>B. Baykant</forenames></author></authors><title>Effects of Sequence Partitioning on Compression Rate</title><categories>cs.IT math.IT</categories><comments>3 Figures, 6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the paper, a theoretical work is done for investigating effects of
splitting data sequence into packs of data set. We proved that a partitioning
of data sequence is possible to find such that the entropy rate at each
subsequence is lower than entropy rate of the source. Effects of sequence
partitioning on overall compression rate are argued on the bases of
partitioning statistics, and then, an optimization problem for an optimal
partition is defined to improve overall compression rate of a sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0344</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0344</id><created>2010-11-01</created><updated>2011-04-07</updated><authors><author><keyname>Sagraloff</keyname><forenames>Michael</forenames></author></authors><title>On the Complexity of Real Root Isolation</title><categories>cs.DS cs.CG cs.NA cs.SC math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new approach to isolate the real roots of a square-free
polynomial $F=\sum_{i=0}^n A_i x^i$ with real coefficients. It is assumed that
each coefficient of $F$ can be approximated to any specified error bound. The
presented method is exact, complete and deterministic. Due to its similarities
to the Descartes method, we also consider it practical and easy to implement.
Compared to previous approaches, our new method achieves a significantly better
bit complexity. It is further shown that the hardness of isolating the real
roots of $F$ is exclusively determined by the geometry of the roots and not by
the complexity or the size of the coefficients. For the special case where $F$
has integer coefficients of maximal bitsize $\tau$, our bound on the bit
complexity writes as $\tilde{O}(n^3\tau^2)$ which improves the best bounds
known for existing practical algorithms by a factor of $n=deg F$. The crucial
idea underlying the new approach is to run an approximate version of the
Descartes method, where, in each subdivision step, we only consider
approximations of the intermediate results to a certain precision. We give an
upper bound on the maximal precision that is needed for isolating the roots of
$F$. For integer polynomials, this bound is by a factor $n$ lower than that of
the precision needed when using exact arithmetic explaining the improved bound
on the bit complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0350</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0350</id><created>2010-11-01</created><authors><author><keyname>Juracz</keyname><forenames>Laszlo</forenames></author></authors><title>Developing courses with HoloRena, a framework for scenario- and game
  based e-learning environments</title><categories>cs.LG cs.HC cs.SE</categories><comments>18 pages</comments><journal-ref>International Journal of Software Engineering &amp; Applications
  (IJSEA), October 2010, Volume 1, Number 4</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  However utilizing rich, interactive solutions can make learning more
effective and attractive, scenario- and game-based educational resources on the
web are not widely used. Creating these applications is a complex, expensive
and challenging process. Development frameworks and authoring tools hardly
support reusable components, teamwork and learning management
system-independent courseware architecture. In this article we initiate the
concept of a low-level, thick-client solution addressing these problems. With
some example applications we try to demonstrate, how a framework, based on this
concept can be useful for developing scenario- and game-based e-learning
environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0351</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0351</id><created>2010-11-01</created><authors><author><keyname>Donders</keyname><forenames>Michael S.</forenames></author><author><keyname>Godbole</keyname><forenames>Anant P.</forenames></author></authors><title>$t$-Covering Arrays Generated by a Tiling Probability Model</title><categories>math.CO cs.DS math.PR</categories><comments>7 pages</comments><msc-class>05B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A $t-\a$ covering array is an $m\times n$ matrix, with entries from an
alphabet of size $\alpha$, such that for any choice of $t$ rows, and any
ordered string of $t$ letters of the alphabet, there exists a column such that
the &quot;values&quot; of the rows in that column match those of the string of letters.
We use the Lov\'asz Local Lemma in conjunction with a new tiling-based
probability model to improve the upper bound on the smallest number of columns
$N=N(m,t,\alpha)$ of a $t-\a$ covering array.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0354</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0354</id><created>2010-11-01</created><authors><author><keyname>Hatami</keyname><forenames>Pooya</forenames></author><author><keyname>Kulkarni</keyname><forenames>Raghav</forenames></author><author><keyname>Pankratov</keyname><forenames>Denis</forenames></author></authors><title>Variations on the Sensitivity Conjecture</title><categories>cs.CC</categories><comments>16 pages, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a selection of known as well as new variants of the Sensitivity
Conjecture and point out some weaker versions that are also open.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0362</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0362</id><created>2010-11-01</created><updated>2011-05-09</updated><authors><author><keyname>Makiguchi</keyname><forenames>Motohiro</forenames></author><author><keyname>Inoue</keyname><forenames>Jun-ichi</forenames></author></authors><title>Optimization of artificial flockings by means of anisotropy measurements</title><categories>physics.bio-ph cs.AI nlin.AO</categories><comments>41 pages, 28 figures, using elsart.cls</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An effective procedure to determine the optimal parameters appearing in
artificial flockings is proposed in terms of optimization problems. We
numerically examine genetic algorithms (GAs) to determine the optimal set of
parameters such as the weights for three essential interactions in BOIDS by
Reynolds (1987) under `zero-collision' and `no-breaking-up' constraints. As a
fitness function (the energy function) to be maximized by the GA, we choose the
so-called the $\gamma$-value of anisotropy which can be observed empirically in
typical flocks of starling. We confirm that the GA successfully finds the
solution having a large $\gamma$-value leading-up to a strong anisotropy. The
numerical experience shows that the procedure might enable us to make more
realistic and efficient artificial flocking of starling even in our personal
computers. We also evaluate two distinct types of interactions in agents,
namely, metric and topological definitions of interactions. We confirmed that
the topological definition can explain the empirical evidence much better than
the metric definition does.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0363</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0363</id><created>2010-11-01</created><authors><author><keyname>Kumar</keyname><forenames>K.</forenames></author><author><keyname>Begum</keyname><forenames>J. Nafeesa</forenames></author><author><keyname>Sumathy</keyname><forenames>V.</forenames></author></authors><title>A Novel Approach Towards Cost Effective Region-Based Group Key Agreement
  Protocol for Peer - to - Peer Information Sharing in Mobile Ad Hoc Networks</title><categories>cs.CR</categories><comments>19 pages</comments><journal-ref>International Journal of peer-to-peer networks (IJP2P) Vol.1,
  No.1, September 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Peer-to-peer systems have gained a lot of attention as information sharing
systems for the widespread exchange of resources and voluminous information
that is easily accessible among thousands of users. However, current
peer-to-peer information sharing systems work mostly on wired networks. With
the growing number of communication-equipped mobile devices that can
self-organize into infrastructure-less communication platform, namely mobile ad
hoc networks (MANETs), peer-to-peer information sharing over MANETs becomes a
promising research area. In this paper, we propose a Region-Based structure
that enables efficient and secure peer-to-peer information sharing over MANETs.
The implementation shows that the proposed scheme is Secure, scalable,
efficient, and adaptive to node mobility and provides Reliable information
sharing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0390</identifier>
 <datestamp>2011-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0390</id><created>2010-11-01</created><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author><author><keyname>Neubauer</keyname><forenames>Peter</forenames></author></authors><title>A Path Algebra for Multi-Relational Graphs</title><categories>cs.DM cs.FL</categories><acm-class>G.2.2; E.1</acm-class><journal-ref>2nd International Workshop on Graph Data Management (GDM'11), pp.
  128-131, IEEE, Hannover, Germany, April 2011</journal-ref><doi>10.1109/ICDEW.2011.5767613</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  A multi-relational graph maintains two or more relations over a vertex set.
This article defines an algebra for traversing such graphs that is based on an
$n$-ary relational algebra, a concatenative single-relational path algebra, and
a tensor-based multi-relational algebra. The presented algebra provides a
monoid, automata, and formal language theoretic foundation for the construction
of a multi-relational graph traversal engine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0397</identifier>
 <datestamp>2011-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0397</id><created>2010-11-01</created><updated>2011-07-08</updated><authors><author><keyname>Fearnley</keyname><forenames>John</forenames></author><author><keyname>Rabe</keyname><forenames>Markus</forenames></author><author><keyname>Schewe</keyname><forenames>Sven</forenames></author><author><keyname>Zhang</keyname><forenames>Lijun</forenames></author></authors><title>Efficient Approximation of Optimal Control for Markov Games</title><categories>cs.GT cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the time-bounded reachability problem for continuous-time Markov
decision processes (CTMDPs) and games (CTMGs). Existing techniques for this
problem use discretisation techniques to break time into discrete intervals,
and optimal control is approximated for each interval separately. Current
techniques provide an accuracy of O(\epsilon^2) on each interval, which leads
to an infeasibly large number of intervals. We propose a sequence of
approximations that achieve accuracies of O(\epsilon^3), O(\epsilon^4), and
O(\epsilon^5), that allow us to drastically reduce the number of intervals that
are considered. For CTMDPs, the performance of the resulting algorithms is
comparable to the heuristic approach given by Buckholz and Schulz, while also
being theoretically justified. All of our results generalise to CTMGs, where
our results yield the first practically implementable algorithms for this
problem. We also provide positional strategies for both players that achieve
similar error bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0399</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0399</id><created>2010-11-01</created><authors><author><keyname>More</keyname><forenames>Sara Miner</forenames></author><author><keyname>Naumov</keyname><forenames>Pavel</forenames></author></authors><title>Functional Dependence of Secrets in a Collaboration Network</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A collaboration network is a graph formed by communication channels between
parties. Parties communicate over these channels to establish secrets,
simultaneously enforcing interdependencies between the secrets. The paper
studies properties of these interdependencies that are induced by the topology
of the network. In previous work, the authors developed a complete logical
system for one such property, independence, also known in the information flow
literature as nondeducibility. This work describes a complete and decidable
logical system for the functional dependence relation between sets of secrets
over a collaboration network. The system extends Armstrong's system of axioms
for functional dependency in databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0404</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0404</id><created>2010-11-01</created><authors><author><keyname>AbdelRahman</keyname><forenames>Samir</forenames></author><author><keyname>Hassan</keyname><forenames>Basma</forenames></author><author><keyname>Bahgat</keyname><forenames>Reem</forenames></author></authors><title>A New Email Retrieval Ranking Approach</title><categories>cs.IR</categories><comments>20 pages</comments><journal-ref>International journal of computer science &amp; information Technology
  (IJCSIT), Vol.2, No.5, (October 2010) 44-63</journal-ref><doi>10.5121/ijcsit.2010.2504</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Email Retrieval task has recently taken much attention to help the user
retrieve the email(s) related to the submitted query. Up to our knowledge,
existing email retrieval ranking approaches sort the retrieved emails based on
some heuristic rules, which are either search clues or some predefined user
criteria rooted in email fields. Unfortunately, the user usually does not know
the effective rule that acquires best ranking related to his query. This paper
presents a new email retrieval ranking approach to tackle this problem. It
ranks the retrieved emails based on a scoring function that depends on crucial
email fields, namely subject, content, and sender. The paper also proposes an
architecture to allow every user in a network/group of users to be able, if
permissible, to know the most important network senders who are interested in
his submitted query words. The experimental evaluation on Enron corpus prove
that our approach outperforms known email retrieval ranking approaches
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0413</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0413</id><created>2010-11-01</created><authors><author><keyname>Bien</keyname><forenames>Jacob</forenames></author><author><keyname>Xu</keyname><forenames>Ya</forenames></author><author><keyname>Mahoney</keyname><forenames>Michael W.</forenames></author></authors><title>CUR from a Sparse Optimization Viewpoint</title><categories>cs.DS stat.AP stat.ML</categories><comments>9 pages; in NIPS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The CUR decomposition provides an approximation of a matrix $X$ that has low
reconstruction error and that is sparse in the sense that the resulting
approximation lies in the span of only a few columns of $X$. In this regard, it
appears to be similar to many sparse PCA methods. However, CUR takes a
randomized algorithmic approach, whereas most sparse PCA methods are framed as
convex optimization problems. In this paper, we try to understand CUR from a
sparse optimization viewpoint. We show that CUR is implicitly optimizing a
sparse regression objective and, furthermore, cannot be directly cast as a
sparse PCA method. We also observe that the sparsity attained by CUR possesses
an interesting structure, which leads us to formulate a sparse PCA method that
achieves a CUR-like sparsity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0415</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0415</id><created>2010-11-01</created><authors><author><keyname>Bento</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Ibrahimi</keyname><forenames>Morteza</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Learning Networks of Stochastic Differential Equations</title><categories>math.ST cond-mat.stat-mech cs.IT cs.LG math.IT stat.TH</categories><comments>This publication is to appear in NIPS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider linear models for stochastic dynamics. To any such model can be
associated a network (namely a directed graph) describing which degrees of
freedom interact under the dynamics. We tackle the problem of learning such a
network from observation of the system trajectory over a time interval $T$.
  We analyze the $\ell_1$-regularized least squares algorithm and, in the
setting in which the underlying network is sparse, we prove performance
guarantees that are \emph{uniform in the sampling rate} as long as this is
sufficiently high. This result substantiates the notion of a well defined `time
complexity' for the network inference problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0447</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0447</id><created>2010-11-01</created><updated>2010-11-25</updated><authors><author><keyname>Lisitsa</keyname><forenames>Alexei</forenames></author></authors><title>Finite Model Finding for Parameterized Verification</title><categories>cs.LO</categories><comments>17 pages, slightly different version of the paper is submitted to
  TACAS 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate to which extent a very simple and natural
&quot;reachability as deducibility&quot; approach, originated in the research in formal
methods in security, is applicable to the automated verification of large
classes of infinite state and parameterized systems. The approach is based on
modeling the reachability between (parameterized) states as deducibility
between suitable encodings of states by formulas of first-order predicate
logic. The verification of a safety property is reduced to a pure logical
problem of finding a countermodel for a first-order formula. The later task is
delegated then to the generic automated finite model building procedures. In
this paper we first establish the relative completeness of the finite
countermodel finding method (FCM) for a class of parameterized linear arrays of
finite automata. The method is shown to be at least as powerful as known
methods based on monotonic abstraction and symbolic backward reachability.
Further, we extend the relative completeness of the approach and show that it
can solve all safety verification problems which can be solved by the
traditional regular model checking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0450</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0450</id><created>2010-11-01</created><updated>2011-03-27</updated><authors><author><keyname>Kekatos</keyname><forenames>Vassilis</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>From Sparse Signals to Sparse Residuals for Robust Sensing</title><categories>stat.ML cs.IT cs.LG math.IT</categories><comments>Under review for publication in the IEEE Transactions on Signal
  Processing (revised version)</comments><doi>10.1109/TSP.2011.2141661</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the key challenges in sensor networks is the extraction of information
by fusing data from a multitude of distinct, but possibly unreliable sensors.
Recovering information from the maximum number of dependable sensors while
specifying the unreliable ones is critical for robust sensing. This sensing
task is formulated here as that of finding the maximum number of feasible
subsystems of linear equations, and proved to be NP-hard. Useful links are
established with compressive sampling, which aims at recovering vectors that
are sparse. In contrast, the signals here are not sparse, but give rise to
sparse residuals. Capitalizing on this form of sparsity, four sensing schemes
with complementary strengths are developed. The first scheme is a convex
relaxation of the original problem expressed as a second-order cone program
(SOCP). It is shown that when the involved sensing matrices are Gaussian and
the reliable measurements are sufficiently many, the SOCP can recover the
optimal solution with overwhelming probability. The second scheme is obtained
by replacing the initial objective function with a concave one. The third and
fourth schemes are tailored for noisy sensor data. The noisy case is cast as a
combinatorial problem that is subsequently surrogated by a (weighted) SOCP.
Interestingly, the derived cost functions fall into the framework of robust
multivariate linear regression, while an efficient block-coordinate descent
algorithm is developed for their minimization. The robust sensing capabilities
of all schemes are verified by simulated tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0468</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0468</id><created>2010-11-01</created><authors><author><keyname>Kolountzakis</keyname><forenames>Mihail N.</forenames></author><author><keyname>Miller</keyname><forenames>Gary L.</forenames></author><author><keyname>Peng</keyname><forenames>Richard</forenames></author><author><keyname>Tsourakakis</keyname><forenames>Charalampos E.</forenames></author></authors><title>Efficient Triangle Counting in Large Graphs via Degree-based Vertex
  Partitioning</title><categories>cs.DS cs.SI physics.soc-ph</categories><comments>1) 12 pages 2) To appear in the 7th Workshop on Algorithms and Models
  for the Web Graph (WAW 2010)</comments><doi>10.1007/978-3-642-18009-5_3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The number of triangles is a computationally expensive graph statistic which
is frequently used in complex network analysis (e.g., transitivity ratio), in
various random graph models (e.g., exponential random graph model) and in
important real world applications such as spam detection, uncovering of the
hidden thematic structure of the Web and link recommendation. Counting
triangles in graphs with millions and billions of edges requires algorithms
which run fast, use small amount of space, provide accurate estimates of the
number of triangles and preferably are parallelizable.
  In this paper we present an efficient triangle counting algorithm which can
be adapted to the semistreaming model. The key idea of our algorithm is to
combine the sampling algorithm of Tsourakakis et al. and the partitioning of
the set of vertices into a high degree and a low degree subset respectively as
in the Alon, Yuster and Zwick work treating each set appropriately. We obtain a
running time $O \left(m + \frac{m^{3/2} \Delta \log{n}}{t \epsilon^2} \right)$
and an $\epsilon$ approximation (multiplicative error), where $n$ is the number
of vertices, $m$ the number of edges and $\Delta$ the maximum number of
triangles an edge is contained.
  Furthermore, we show how this algorithm can be adapted to the semistreaming
model with space usage $O\left(m^{1/2}\log{n} + \frac{m^{3/2} \Delta \log{n}}{t
\epsilon^2} \right)$ and a constant number of passes (three) over the graph
stream. We apply our methods in various networks with several millions of edges
and we obtain excellent results. Finally, we propose a random projection based
method for triangle counting and provide a sufficient condition to obtain an
estimate with low variance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0472</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0472</id><created>2010-11-01</created><authors><author><keyname>Zhang</keyname><forenames>Xinhua</forenames></author><author><keyname>Saha</keyname><forenames>Ankan</forenames></author><author><keyname>Vishwanathan</keyname><forenames>S. V. N.</forenames></author></authors><title>Regularized Risk Minimization by Nesterov's Accelerated Gradient
  Methods: Algorithmic Extensions and Empirical Studies</title><categories>cs.LG</categories><comments>28 pages. Supplementary material for NIPS 2010 paper &quot;Lower Bounds on
  Rate of Convergence of Cutting Plane Methods&quot; by the same authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nesterov's accelerated gradient methods (AGM) have been successfully applied
in many machine learning areas. However, their empirical performance on
training max-margin models has been inferior to existing specialized solvers.
In this paper, we first extend AGM to strongly convex and composite objective
functions with Bregman style prox-functions. Our unifying framework covers both
the $\infty$-memory and 1-memory styles of AGM, tunes the Lipschiz constant
adaptively, and bounds the duality gap. Then we demonstrate various ways to
apply this framework of methods to a wide range of machine learning problems.
Emphasis will be given on their rate of convergence and how to efficiently
compute the gradient and optimize the models. The experimental results show
that with our extensions AGM outperforms state-of-the-art solvers on max-margin
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0474</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0474</id><created>2010-11-01</created><authors><author><keyname>Sarkiss</keyname><forenames>Mireille</forenames></author><author><keyname>Othman</keyname><forenames>Ghaya Rekaya-Ben</forenames></author><author><keyname>Damen</keyname><forenames>Mohamed Oussama</forenames></author><author><keyname>Belfiore</keyname><forenames>Jean-Claude</forenames></author></authors><title>Construction of New Delay-Tolerant Space-Time Codes</title><categories>cs.IT math.IT</categories><comments>33 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Perfect Space-Time Codes (STC) are optimal codes in their original
construction for Multiple Input Multiple Output (MIMO) systems. Based on Cyclic
Division Algebras (CDA), they are full-rate, full-diversity codes, have
Non-Vanishing Determinants (NVD) and hence achieve Diversity-Multiplexing
Tradeoff (DMT). In addition, these codes have led to optimal distributed
space-time codes when applied in cooperative networks under the assumption of
perfect synchronization between relays. However, they loose their diversity
when delays are introduced and thus are not delay-tolerant. In this paper,
using the cyclic division algebras of perfect codes, we construct new codes
that maintain the same properties as perfect codes in the synchronous case.
Moreover, these codes preserve their full-diversity in asynchronous
transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0487</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0487</id><created>2010-11-01</created><authors><author><keyname>Phillips</keyname><forenames>Andrew</forenames><affiliation>Microsoft Research</affiliation></author><author><keyname>Lakin</keyname><forenames>Matthew</forenames><affiliation>Microsoft Research</affiliation></author><author><keyname>Paulev&#xe9;</keyname><forenames>Lo&#xef;c</forenames><affiliation>Ecole Centrale de Nantes</affiliation></author></authors><title>Stochastic Simulation of Process Calculi for Biology</title><categories>cs.PL cs.CE q-bio.QM</categories><comments>In Proceedings MeCBIC 2010, arXiv:1011.0051</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 40, 2010, pp. 1-5</journal-ref><doi>10.4204/EPTCS.40.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Biological systems typically involve large numbers of components with
complex, highly parallel interactions and intrinsic stochasticity. To model
this complexity, numerous programming languages based on process calculi have
been developed, many of which are expressive enough to generate unbounded
numbers of molecular species and reactions. As a result of this expressiveness,
such calculi cannot rely on standard reaction-based simulation methods, which
require fixed numbers of species and reactions. Rather than implementing custom
stochastic simulation algorithms for each process calculus, we propose to use a
generic abstract machine that can be instantiated to a range of process calculi
and a range of reaction-based simulation algorithms. The abstract machine
functions as a just-in-time compiler, which dynamically updates the set of
possible reactions and chooses the next reaction in an iterative cycle. In this
short paper we give a brief summary of the generic abstract machine, and show
how it can be instantiated with the stochastic simulation algorithm known as
Gillespie's Direct Method. We also discuss the wider implications of such an
abstract machine, and outline how it can be used to simulate multiple calculi
simultaneously within a common framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0488</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0488</id><created>2010-11-01</created><authors><author><keyname>Bacci</keyname><forenames>Giorgio</forenames><affiliation>DiMI, University of Udine</affiliation></author><author><keyname>Miculan</keyname><forenames>Marino</forenames><affiliation>DiMI, University of Udine</affiliation></author></authors><title>Measurable Stochastics for Brane Calculus</title><categories>cs.CE</categories><comments>In Proceedings MeCBIC 2010, arXiv:1011.0051</comments><proxy>EPTCS</proxy><acm-class>D.3.1; G.3</acm-class><journal-ref>EPTCS 40, 2010, pp. 6-22</journal-ref><doi>10.4204/EPTCS.40.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a stochastic extension of the Brane Calculus, along the lines of
recent work by Cardelli and Mardare. In this presentation, the semantics of a
Brane process is a measure of the stochastic distribution of possible
derivations. To this end, we first introduce a labelled transition system for
Brane Calculus, proving its adequacy w.r.t. the usual reduction semantics.
Then, brane systems are presented as Markov processes over the measurable space
generated by terms up-to syntactic congruence, and where the measures are
indexed by the actions of this new LTS. Finally, we provide a SOS presentation
of this stochastic semantics, which is compositional and syntax-driven.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0489</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0489</id><created>2010-11-01</created><authors><author><keyname>Banks</keyname><forenames>Richard</forenames><affiliation>Newcastle University</affiliation></author><author><keyname>Steggles</keyname><forenames>L. Jason</forenames><affiliation>Newcastle University</affiliation></author></authors><title>An Abstraction Theory for Qualitative Models of Biological Systems</title><categories>cs.CE cs.DM</categories><comments>In Proceedings MeCBIC 2010, arXiv:1011.0051</comments><proxy>EPTCS</proxy><acm-class>J.3; F.1.1</acm-class><journal-ref>EPTCS 40, 2010, pp. 23-38</journal-ref><doi>10.4204/EPTCS.40.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-valued network models are an important qualitative modelling approach
used widely by the biological community. In this paper we consider developing
an abstraction theory for multi-valued network models that allows the state
space of a model to be reduced while preserving key properties of the model.
This is important as it aids the analysis and comparison of multi-valued
networks and in particular, helps address the well-known problem of state space
explosion associated with such analysis. We also consider developing techniques
for efficiently identifying abstractions and so provide a basis for the
automation of this task. We illustrate the theory and techniques developed by
investigating the identification of abstractions for two published MVN models
of the lysis-lysogeny switch in the bacteriophage lambda.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0490</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0490</id><created>2010-11-01</created><authors><author><keyname>Bao</keyname><forenames>Yifei</forenames><affiliation>Department of Computer Science, Stevens Institute of Technology</affiliation></author><author><keyname>Compagnoni</keyname><forenames>Adriana</forenames><affiliation>Department of Computer Science, Stevens Institute of Technology</affiliation></author><author><keyname>Glavy</keyname><forenames>Joseph</forenames><affiliation>Department of Chemical Biology and Biomedical Engineering, Stevens Institute of Technology</affiliation></author><author><keyname>White</keyname><forenames>Tommy</forenames><affiliation>Department of Chemical Biology and Biomedical Engineering, Stevens Institute of Technology</affiliation></author></authors><title>Computational Modeling for the Activation Cycle of G-proteins by
  G-protein-coupled Receptors</title><categories>cs.CE q-bio.QM</categories><comments>In Proceedings MeCBIC 2010, arXiv:1011.0051</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 40, 2010, pp. 39-53</journal-ref><doi>10.4204/EPTCS.40.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we survey five different computational modeling methods. For
comparison, we use the activation cycle of G-proteins that regulate cellular
signaling events downstream of G-protein-coupled receptors (GPCRs) as a driving
example. Starting from an existing Ordinary Differential Equations (ODEs)
model, we implement the G-protein cycle in the stochastic Pi-calculus using
SPiM, as Petri-nets using Cell Illustrator, in the Kappa Language using
Cellucidate, and in Bio-PEPA using the Bio-PEPA eclipse plug in. We also
provide a high-level notation to abstract away from communication primitives
that may be unfamiliar to the average biologist, and we show how to translate
high-level programs into stochastic Pi-calculus processes and chemical
reactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0491</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0491</id><created>2010-11-01</created><authors><author><keyname>Barbuti</keyname><forenames>Roberto</forenames><affiliation>Universit&#xe0; di Pisa</affiliation></author><author><keyname>Caravagna</keyname><forenames>Giulio</forenames><affiliation>Universit&#xe0; di Pisa</affiliation></author><author><keyname>Milazzo</keyname><forenames>Paolo</forenames><affiliation>Universit&#xe0; di Pisa</affiliation></author><author><keyname>Maggiolo-Schettini</keyname><forenames>Andrea</forenames><affiliation>Universit&#xe0; di Pisa</affiliation></author><author><keyname>Tini</keyname><forenames>Simone</forenames><affiliation>Universit&#xe0; dell'Insubria</affiliation></author></authors><title>Aspects of multiscale modelling in a process algebra for biological
  systems</title><categories>cs.LO cs.CE cs.FL</categories><comments>In Proceedings MeCBIC 2010, arXiv:1011.0051</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 40, 2010, pp. 54-69</journal-ref><doi>10.4204/EPTCS.40.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a variant of the CCS process algebra with new features aiming at
allowing multiscale modelling of biological systems. In the usual semantics of
process algebras for modelling biological systems actions are instantaneous.
When different scale levels of biological systems are considered in a single
model, one should take into account that actions at a level may take much more
time than actions at a lower level. Moreover, it might happen that while a
component is involved in one long lasting high level action, it is involved
also in several faster lower level actions. Hence, we propose a process algebra
with operations and with a semantics aimed at dealing with these aspects of
multiscale modelling. We study behavioural equivalences for such an algebra and
give some examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0492</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0492</id><created>2010-11-01</created><authors><author><keyname>Cacciagrano</keyname><forenames>Diletta</forenames><affiliation>School of Science and Technology - University of Camerino</affiliation></author><author><keyname>Corradini</keyname><forenames>Flavio</forenames><affiliation>School of Science and Technology - University of Camerino</affiliation></author><author><keyname>Merelli</keyname><forenames>Emanuela</forenames><affiliation>School of Science and Technology - University of Camerino</affiliation></author><author><keyname>Tesei</keyname><forenames>Luca</forenames><affiliation>School of Science and Technology - University of Camerino</affiliation></author></authors><title>Multiscale Bone Remodelling with Spatial P Systems</title><categories>cs.CE q-bio.QM</categories><comments>In Proceedings MeCBIC 2010, arXiv:1011.0051</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 40, 2010, pp. 70-84</journal-ref><doi>10.4204/EPTCS.40.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many biological phenomena are inherently multiscale, i.e. they are
characterized by interactions involving different spatial and temporal scales
simultaneously. Though several approaches have been proposed to provide
&quot;multilayer&quot; models, only Complex Automata, derived from Cellular Automata,
naturally embed spatial information and realize multiscaling with
well-established inter-scale integration schemas. Spatial P systems, a variant
of P systems in which a more geometric concept of space has been added, have
several characteristics in common with Cellular Automata. We propose such a
formalism as a basis to rephrase the Complex Automata multiscaling approach
and, in this perspective, provide a 2-scale Spatial P system describing bone
remodelling. The proposed model not only results to be highly faithful and
expressive in a multiscale scenario, but also highlights the need of a deep and
formal expressiveness study involving Complex Automata, Spatial P systems and
other promising multiscale approaches, such as our shape-based one already
resulted to be highly faithful.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0493</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0493</id><created>2010-11-01</created><authors><author><keyname>Caravagna</keyname><forenames>Giulio</forenames><affiliation>Dipartimento di Informatica, Universita di Pisa, italy.</affiliation></author><author><keyname>Hillston</keyname><forenames>Jane</forenames><affiliation>Laboratory for Foundations of Computer Science, The University of Edinburgh, Scotland.</affiliation></author></authors><title>Modeling biological systems with delays in Bio-PEPA</title><categories>cs.CE q-bio.QM</categories><comments>In Proceedings MeCBIC 2010, arXiv:1011.0051</comments><proxy>EPTCS</proxy><acm-class>D.2.1; F.3.1;</acm-class><journal-ref>EPTCS 40, 2010, pp. 85-101</journal-ref><doi>10.4204/EPTCS.40.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Delays in biological systems may be used to model events for which the
underlying dynamics cannot be precisely observed, or to provide abstraction of
some behavior of the system resulting more compact models. In this paper we
enrich the stochastic process algebra Bio-PEPA, with the possibility of
assigning delays to actions, yielding a new non-Markovian process algebra:
Bio-PEPAd. This is a conservative extension meaning that the original syntax of
Bio-PEPA is retained and the delay specification which can now be associated
with actions may be added to existing Bio-PEPA models. The semantics of the
firing of the actions with delays is the delay-as-duration approach, earlier
presented in papers on the stochastic simulation of biological systems with
delays. These semantics of the algebra are given in the Starting-Terminating
style, meaning that the state and the completion of an action are observed as
two separate events, as required by delays. Furthermore we outline how to
perform stochastic simulation of Bio-PEPAd systems and how to automatically
translate a Bio-PEPAd system into a set of Delay Differential Equations, the
deterministic framework for modeling of biological systems with delays. We end
the paper with two example models of biological systems with delays to
illustrate the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0494</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0494</id><created>2010-11-01</created><authors><author><keyname>Coppo</keyname><forenames>Mario</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author><author><keyname>Damiani</keyname><forenames>Ferruccio</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author><author><keyname>Drocco</keyname><forenames>Maurizio</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author><author><keyname>Grassi</keyname><forenames>Elena</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author><author><keyname>Sciacca</keyname><forenames>Eva</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author><author><keyname>Spinella</keyname><forenames>Salvatore</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author><author><keyname>Troina</keyname><forenames>Angelo</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author></authors><title>Hybrid Calculus of Wrapped Compartments</title><categories>cs.PL cs.CE q-bio.QM</categories><comments>In Proceedings MeCBIC 2010, arXiv:1011.0051</comments><proxy>EPTCS</proxy><acm-class>D.3.1 ; D.3.3 ; F.3.2 ; G.1.7 ; G.3 ; I.6.8 ; J.3</acm-class><journal-ref>EPTCS 40, 2010, pp. 102-120</journal-ref><doi>10.4204/EPTCS.40.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The modelling and analysis of biological systems has deep roots in
Mathematics, specifically in the field of ordinary differential equations
(ODEs). Alternative approaches based on formal calculi, often derived from
process algebras or term rewriting systems, provide a quite complementary way
to analyze the behaviour of biological systems. These calculi allow to cope in
a natural way with notions like compartments and membranes, which are not easy
(sometimes impossible) to handle with purely numerical approaches, and are
often based on stochastic simulation methods. Recently, it has also become
evident that stochastic effects in regulatory networks play a crucial role in
the analysis of such systems. Actually, in many situations it is necessary to
use stochastic models. For example when the system to be described is based on
the interaction of few molecules, when we are at the presence of a chemical
instability, or when we want to simulate the functioning of a pool of entities
whose compartmentalised structure evolves dynamically. In contrast, stable
metabolic networks, involving a large number of reagents, for which the
computational cost of a stochastic simulation becomes an insurmountable
obstacle, are efficiently modelled with ODEs. In this paper we define a hybrid
simulation method, combining the stochastic approach with ODEs, for systems
described in CWC, a calculus on which we can express the compartmentalisation
of a biological system whose evolution is defined by a set of rewrite rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0495</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0495</id><created>2010-11-01</created><authors><author><keyname>Dinneen</keyname><forenames>Michael J.</forenames><affiliation>University of Auckland</affiliation></author><author><keyname>Kim</keyname><forenames>Yun-Bum</forenames><affiliation>University of Auckland</affiliation></author><author><keyname>Nicolescu</keyname><forenames>Radu</forenames><affiliation>University of Auckland</affiliation></author></authors><title>Edge- and Node-Disjoint Paths in P Systems</title><categories>cs.DC cs.DS</categories><comments>In Proceedings MeCBIC 2010, arXiv:1011.0051</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 40, 2010, pp. 121-141</journal-ref><doi>10.4204/EPTCS.40.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we continue our development of algorithms used for topological
network discovery. We present native P system versions of two fundamental
problems in graph theory: finding the maximum number of edge- and node-disjoint
paths between a source node and target node. We start from the standard
depth-first-search maximum flow algorithms, but our approach is totally
distributed, when initially no structural information is available and each P
system cell has to even learn its immediate neighbors. For the node-disjoint
version, our P system rules are designed to enforce node weight capacities (of
one), in addition to edge capacities (of one), which are not readily available
in the standard network flow algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0496</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0496</id><created>2010-11-01</created><authors><author><keyname>Feret</keyname><forenames>Jerome</forenames><affiliation>INRIA, Paris, France</affiliation></author><author><keyname>Henzinger</keyname><forenames>Thomas</forenames><affiliation>Institute of Science and Technology, Vienna, Austria</affiliation></author><author><keyname>Koeppl</keyname><forenames>Heinz</forenames><affiliation>EPFL, Lausanne, Switzerland</affiliation></author><author><keyname>Petrov</keyname><forenames>Tatjana</forenames><affiliation>EPFL, Lausanne, Switzerland</affiliation></author></authors><title>Lumpability Abstractions of Rule-based Systems</title><categories>cs.CE</categories><comments>In Proceedings MeCBIC 2010, arXiv:1011.0051</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 40, 2010, pp. 142-161</journal-ref><doi>10.4204/EPTCS.40.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The induction of a signaling pathway is characterized by transient complex
formation and mutual posttranslational modification of proteins. To faithfully
capture this combinatorial process in a mathematical model is an important
challenge in systems biology. Exploiting the limited context on which most
binding and modification events are conditioned, attempts have been made to
reduce the combinatorial complexity by quotienting the reachable set of
molecular species, into species aggregates while preserving the deterministic
semantics of the thermodynamic limit. Recently we proposed a quotienting that
also preserves the stochastic semantics and that is complete in the sense that
the semantics of individual species can be recovered from the aggregate
semantics. In this paper we prove that this quotienting yields a sufficient
condition for weak lumpability and that it gives rise to a backward Markov
bisimulation between the original and aggregated transition system. We
illustrate the framework on a case study of the EGF/insulin receptor crosstalk.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0498</identifier>
 <datestamp>2010-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0498</id><created>2010-11-01</created><authors><author><keyname>Giavitto</keyname><forenames>Jean-Louis</forenames><affiliation>CNRS &amp; IBISC, University of Evry</affiliation></author><author><keyname>Klaudel</keyname><forenames>Hanna</forenames><affiliation>IBISC, University of Evry</affiliation></author><author><keyname>Pommereau</keyname><forenames>Franck</forenames><affiliation>IBISC, University of Evry</affiliation></author></authors><title>Qualitative modelling and analysis of regulations in multi-cellular
  systems using Petri nets and topological collections</title><categories>cs.CE</categories><comments>In Proceedings MeCBIC 2010, arXiv:1011.0051</comments><proxy>EPTCS</proxy><acm-class>J3; I.6.5; I.6.4; D.2.2</acm-class><journal-ref>EPTCS 40, 2010, pp. 162-177</journal-ref><doi>10.4204/EPTCS.40.11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we aim at modelling and analyzing the regulation processes in
multi-cellular biological systems, in particular tissues.
  The modelling framework is based on interconnected logical regulatory
networks a la Rene Thomas equipped with information about their spatial
relationships. The semantics of such models is expressed through colored Petri
nets to implement regulation rules, combined with topological collections to
implement the spatial information.
  Some constraints are put on the the representation of spatial information in
order to preserve the possibility of an enumerative and exhaustive state space
exploration.
  This paper presents the modelling framework, its semantics, as well as a
prototype implementation that allowed preliminary experimentation on some
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0502</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0502</id><created>2010-11-01</created><authors><author><keyname>AbdelRahman</keyname><forenames>Samir</forenames><affiliation>Department of Computer Science, Faculty of Computers and Information, Cairo University, Giza, Egypt</affiliation></author><author><keyname>Hassan</keyname><forenames>Basma</forenames><affiliation>Department of Computer Science, Faculty of Computers and Information, Fayoum University, Fayoum, Egypt</affiliation></author><author><keyname>Bahgat</keyname><forenames>Reem</forenames><affiliation>Department of Computer Science, Faculty of Computers and Information, Cairo University, Giza, Egypt</affiliation></author></authors><title>A New Email Retrieval Ranking Approach</title><categories>cs.IR</categories><report-no>100,101</report-no><journal-ref>International journal of computer science &amp; information Technology
  (IJCSIT) Vol.2, No.5, October 2010</journal-ref><doi>10.5121/ijcsit.2010.2504</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Email Retrieval task has recently taken much attention to help the user
retrieve the email(s) related to the submitted query. Up to our knowledge,
existing email retrieval ranking approaches sort the retrieved emails based on
some heuristic rules, which are either search clues or some predefined user
criteria rooted in email fields. Unfortunately, the user usually does not know
the effective rule that acquires best ranking related to his query. This paper
presents a new email retrieval ranking approach to tackle this problem. It
ranks the retrieved emails based on a scoring function that depends on crucial
email fields, namely subject, content, and sender. The paper also proposes an
architecture to allow every user in a network/group of users to be able, if
permissible, to know the most important network senders who are interested in
his submitted query words. The experimental evaluation on Enron corpus prove
that our approach outperforms known email retrieval ranking approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0506</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0506</id><created>2010-11-01</created><authors><author><keyname>Nikulin</keyname><forenames>Vladimir</forenames></author><author><keyname>Huang</keyname><forenames>Tian-Hsiang</forenames></author><author><keyname>Ng</keyname><forenames>Shu-Kay</forenames></author><author><keyname>Rathnayake</keyname><forenames>Suren I</forenames></author><author><keyname>McLachlan</keyname><forenames>Geoffrey J</forenames></author></authors><title>A Very Fast Algorithm for Matrix Factorization</title><categories>stat.CO cs.IR physics.data-an stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a very fast algorithm for general matrix factorization of a data
matrix for use in the statistical analysis of high-dimensional data via latent
factors. Such data are prevalent across many application areas and generate an
ever-increasing demand for methods of dimension reduction in order to undertake
the statistical analysis of interest. Our algorithm uses a gradient-based
approach which can be used with an arbitrary loss function provided the latter
is differentiable. The speed and effectiveness of our algorithm for dimension
reduction is demonstrated in the context of supervised classification of some
real high-dimensional data sets from the bioinformatics literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0507</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0507</id><created>2010-11-02</created><authors><author><keyname>Kumar</keyname><forenames>Manoj</forenames></author><author><keyname>Arya</keyname><forenames>Sandeep K.</forenames></author><author><keyname>Pandey</keyname><forenames>Sujata</forenames></author></authors><title>Level Shifter Design for Low Power Applications</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With scaling of Vt sub-threshold leakage power is increasing and expected to
become significant part of total power consumption In present work three new
configurations of level shifters for low power application in 0.35{\mu}m
technology have been presented. The proposed circuits utilize the merits of
stacking technique with smaller leakage current and reduction in leakage power.
Conventional level shifter has been improved by addition of three NMOS
transistors, which shows total power consumption of 402.2264pW as compared to
0.49833nW with existing circuit. Single supply level shifter has been modified
with addition of two NMOS transistors that gives total power consumption of
108.641pW as compared to 31.06nW. Another circuit, contention mitigated level
shifter (CMLS) with three additional transistors shows total power consumption
of 396.75pW as compared to 0.4937354nW. Three proposed circuit's shows better
performance in terms of power consumption with a little conciliation in delay.
Output level of 3.3V has been obtained with input pulse of 1.6V for all
proposed circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0517</identifier>
 <datestamp>2012-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0517</id><created>2010-11-02</created><updated>2012-10-17</updated><authors><author><keyname>Bhattacharya</keyname><forenames>Bhaswar B.</forenames></author><author><keyname>Das</keyname><forenames>Sandip</forenames></author></authors><title>Holes or Empty Pseudo-Triangles in Planar Point Sets</title><categories>math.CO cs.DM</categories><comments>A minor error in the proof of Theorem 2 fixed. Typos corrected. 19
  pages, 11 figures</comments><msc-class>52C10, 52A10</msc-class><journal-ref>Moscow Journal of Combinatorics and Number Theory, 16-46, Vol. 2
  (1), 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $E(k, \ell)$ denote the smallest integer such that any set of at least
$E(k, \ell)$ points in the plane, no three on a line, contains either an empty
convex polygon with $k$ vertices or an empty pseudo-triangle with $\ell$
vertices. The existence of $E(k, \ell)$ for positive integers $k, \ell\geq 3$,
is the consequence of a result proved by Valtr [Discrete and Computational
Geometry, Vol. 37, 565--576, 2007]. In this paper, following a series of new
results about the existence of empty pseudo-triangles in point sets with
triangular convex hulls, we determine the exact values of $E(k, 5)$ and $E(5,
\ell)$, and prove bounds on $E(k, 6)$ and $E(6, \ell)$, for $k, \ell\geq 3$. By
dropping the emptiness condition, we define another related quantity $F(k,
\ell)$, which is the smallest integer such that any set of at least $F(k,
\ell)$ points in the plane, no three on a line, contains a convex polygon with
$k$ vertices or a pseudo-triangle with $\ell$ vertices. Extending a result of
Bisztriczky and T\'oth [Discrete Geometry, Marcel Dekker, 49--58, 2003], we
obtain the exact values of $F(k, 5)$ and $F(k, 6)$, and obtain non-trivial
bounds on $F(k, 7)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0519</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0519</id><created>2010-11-02</created><authors><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>IDSL, INRIA Saclay - Ile de France</affiliation></author></authors><title>Stabilizing knowledge through standards - A perspective for the
  humanities</title><categories>cs.CL</categories><proxy>ccsd</proxy><journal-ref>Going Digital: Evolutionary and Revolutionary Aspects of
  Digitization, Karl Grandin (Ed.) (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is usual to consider that standards generate mixed feelings among
scientists. They are often seen as not really reflecting the state of the art
in a given domain and a hindrance to scientific creativity. Still, scientists
should theoretically be at the best place to bring their expertise into
standard developments, being even more neutral on issues that may typically be
related to competing industrial interests. Even if it could be thought of as
even more complex to think about developping standards in the humanities, we
will show how this can be made feasible through the experience gained both
within the Text Encoding Initiative consortium and the International
Organisation for Standardisation. By taking the specific case of lexical
resources, we will try to show how this brings about new ideas for designing
future research infrastructures in the human and social sciences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0520</identifier>
 <datestamp>2012-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0520</id><created>2010-11-02</created><updated>2012-08-16</updated><authors><author><keyname>Ny</keyname><forenames>Jerome Le</forenames></author><author><keyname>Pappas</keyname><forenames>George J.</forenames></author></authors><title>Adaptive Algorithms for Coverage Control and Space Partitioning in
  Mobile Robotic Networks</title><categories>math.OC cs.RO</categories><comments>16 pages, 4 figures. Long version of a manuscript to appear in the
  Transactions on Automatic Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers deployment problems where a mobile robotic network must
optimize its configuration in a distributed way in order to minimize a
steady-state cost function that depends on the spatial distribution of certain
probabilistic events of interest. Moreover, it is assumed that the event
location distribution is a priori unknown, and can only be progressively
inferred from the observation of the actual event occurrences. Three classes of
problems are discussed in detail: coverage control problems, spatial
partitioning problems, and dynamic vehicle routing problems. In each case,
distributed stochastic gradient algorithms optimizing the performance objective
are presented. The stochastic gradient view simplifies and generalizes
previously proposed solutions, and is applicable to new complex scenarios, such
as adaptive coverage involving heterogeneous agents. Remarkably, these
algorithms often take the form of simple distributed rules that could be
implemented on resource-limited platforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0523</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0523</id><created>2010-11-02</created><updated>2010-12-08</updated><authors><author><keyname>Duchamp</keyname><forenames>G&#xe9;rard Henry Edmond</forenames><affiliation>LIPN</affiliation></author><author><keyname>Minh</keyname><forenames>Vincel Hoang Ngoc</forenames><affiliation>LIPN</affiliation></author><author><keyname>Solomon</keyname><forenames>Allan I.</forenames><affiliation>LPTMC</affiliation></author><author><keyname>Goodenough</keyname><forenames>Silvia</forenames><affiliation>LIPN</affiliation></author></authors><title>An interface between physics and number theory</title><categories>math-ph cs.SC math.CO math.MP</categories><proxy>ccsd</proxy><doi>10.1088/1742-6596/284/1/012023</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the Hopf algebra description of a simple quantum system given
previously, to a more elaborate Hopf algebra, which is rich enough to encompass
that related to a description of perturbative quantum field theory (pQFT). This
provides a {\em mathematical} route from an algebraic description of
non-relativistic, non-field theoretic quantum statistical mechanics to one of
relativistic quantum field theory. Such a description necessarily involves
treating the algebra of polyzeta functions, extensions of the Riemann Zeta
function, since these occur naturally in pQFT. This provides a link between
physics, algebra and number theory. As a by-product of this approach, we are
led to indicate {\it inter alia} a basis for concluding that the Euler gamma
constant $\gamma$ may be rational.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0527</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0527</id><created>2010-11-02</created><authors><author><keyname>Balu</keyname><forenames>A.</forenames></author><author><keyname>Kuppusamy</keyname><forenames>K.</forenames></author></authors><title>Ciphertext Policy Attribute based Encryption with anonymous access
  policy</title><categories>cs.CR</categories><journal-ref>International journal of Peer to Peer Networks, pp1-8,Vol 1,
  Number 1, October 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Ciphertext Policy Attribute based Encryption scheme, the encryptor can fix
the policy, who can decrypt the encrypted message. The policy can be formed
with the help of attributes. In CP-ABE, access policy is sent along with the
ciphertext. We propose a method in which the access policy need not be sent
along with the ciphertext, by which we are able to preserve the privacy of the
encryptor. The proposed construction is provably secure under Decision Bilinear
Diffe-Hellman assumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0531</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0531</id><created>2010-11-02</created><authors><author><keyname>Bogdanov</keyname><forenames>Andrej</forenames></author><author><keyname>Li</keyname><forenames>Fan</forenames></author></authors><title>A better tester for bipartiteness?</title><categories>cs.DS</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alon and Krivelevich (SIAM J. Discrete Math. 15(2): 211-227 (2002)) show that
if a graph is {\epsilon}-far from bipartite, then the subgraph induced by a
random subset of O(1/{\epsilon}) vertices is bipartite with high probability.
We conjecture that the induced subgraph is {\Omega}~({\epsilon})-far from
bipartite with high probability. Gonen and Ron (RANDOM 2007) proved this
conjecture in the case when the degrees of all vertices are at most
O({\epsilon}n). We give a more general proof that works for any d-regular (or
almost d-regular) graph for arbitrary degree d. Assuming this conjecture, we
prove that bipartiteness is testable with one-sided error in time
O(1/{\epsilon}^c), where c is a constant strictly smaller than two, improving
upon the tester of Alon and Krivelevich. As it is known that non-adaptive
testers for bipartiteness require {\Omega}(1/{\epsilon}^2) queries (Bogdanov
and Trevisan, CCC 2004), our result shows, assuming the conjecture, that
adaptivity helps in testing bipartiteness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0539</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0539</id><created>2010-11-02</created><authors><author><keyname>Kalaiarasi</keyname><forenames>R.</forenames></author><author><keyname>Sara</keyname><forenames>Getsy S.</forenames></author><author><keyname>Pari</keyname><forenames>S. Neelavathy</forenames></author><author><keyname>Sridharan</keyname><forenames>D.</forenames></author></authors><title>Performance Analysis of Contention Window Cheating Misbehaviors in
  Mobile Ad Hoc Networks</title><categories>cs.NI</categories><comments>12 pages,4 figures, 1 table</comments><report-no>EFI-94-11</report-no><journal-ref>International journal of computer science &amp; information Technology
  (IJCSIT) Vol.2, No.5, October 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile Ad Hoc Network (MANET) is a collection of nodes that can be rapidly
deployed as a multi-hop network without the aid of any centralized
administration. Misbehavior is challenged by bandwidth and energy efficient
medium access control and fair share of throughput. Node misbehavior plays an
important role in MANET. In this survey, few of the contention window
misbehavior is reviewed and compared. The contention window cheating either
minimizes the active communication of the network or reduces bandwidth
utilization of a particular node. The classification presented is in no case
unique but summarizes the chief characteristics of many published proposals for
contention window cheating. After getting insight into the different contention
window misbehavior, few of the enhancements that can be done to improve the
existing contention window are suggested. The purpose of this paper is to
facilitate the research efforts in combining the existing solutions to offer
more efficient methods to reduce contention window cheating mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0551</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0551</id><created>2010-11-02</created><updated>2011-11-14</updated><authors><author><keyname>Ganty</keyname><forenames>Pierre</forenames></author><author><keyname>Majumdar</keyname><forenames>Rupak</forenames></author></authors><title>Algorithmic Verification of Asynchronous Programs</title><categories>cs.LO cs.FL</categories><comments>46 pages, 9 figures</comments><acm-class>D.2.4</acm-class><journal-ref>ACM Trans. Program. Lang. Syst. 34(1) (2012) 6:1-6:48</journal-ref><doi>10.1145/2160910.2160915</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Asynchronous programming is a ubiquitous systems programming idiom to manage
concurrent interactions with the environment. In this style, instead of waiting
for time-consuming operations to complete, the programmer makes a non-blocking
call to the operation and posts a callback task to a task buffer that is
executed later when the time-consuming operation completes. A co-operative
scheduler mediates the interaction by picking and executing callback tasks from
the task buffer to completion (and these callbacks can post further callbacks
to be executed later). Writing correct asynchronous programs is hard because
the use of callbacks, while efficient, obscures program control flow.
  We provide a formal model underlying asynchronous programs and study
verification problems for this model. We show that the safety verification
problem for finite-data asynchronous programs is expspace-complete. We show
that liveness verification for finite-data asynchronous programs is decidable
and polynomial-time equivalent to Petri Net reachability. Decidability is not
obvious, since even if the data is finite-state, asynchronous programs
constitute infinite-state transition systems: both the program stack and the
task buffer of pending asynchronous calls can be potentially unbounded.
  Our main technical construction is a polynomial-time semantics-preserving
reduction from asynchronous programs to Petri Nets and conversely. The
reduction allows the use of algorithmic techniques on Petri Nets to the
verification of asynchronous programs.
  We also study several extensions to the basic models of asynchronous programs
that are inspired by additional capabilities provided by implementations of
asynchronous libraries, and classify the decidability and undecidability of
verification questions on these extensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0594</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0594</id><created>2010-11-02</created><authors><author><keyname>Tahbildar</keyname><forenames>Hitesh</forenames></author><author><keyname>Kalita</keyname><forenames>Bichitra</forenames></author></authors><title>Heuristic Approach of Automated Test Data Generation for Program having
  Array of Different Dimensions and Loops with Variable Number of Iteration</title><categories>cs.SE</categories><comments>19 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Normally, program execution spends most of the time on loops. Automated test
data generation devotes special attention to loops for better coverage.
Automated test data generation for programs having loops with variable number
of iteration and variable length array is a challenging problem. It is so
because the number of paths may increase exponentially with the increase of
array size for some programming constructs, like merge sort. We propose a
method that finds heuristic for different types of programming constructs with
loops and arrays. Linear search, Bubble sort, merge sort, and matrix
multiplication programs are included in an attempt to highlight the difference
in execution between single loop, variable length array and nested loops with
one and two dimensional arrays. We have used two parameters/heuristics to
predict the minimum number of iterations required for generating automated test
data. They are longest path level (kL) and saturation level (kS). The
proceedings of our work includes the instrumentation of source code at the
elementary level, followed by the application of the random inputs until all
feasible paths or all paths having longest paths are collected. However,
duplicate paths are avoided by using a filter. Our test data is the random
numbers that cover each feasible path.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0596</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0596</id><created>2010-11-02</created><authors><author><keyname>Chaudhury</keyname><forenames>Ayan</forenames></author><author><keyname>Gupta</keyname><forenames>Abhishek</forenames></author><author><keyname>Manna</keyname><forenames>Sumita</forenames></author><author><keyname>Mukherjee</keyname><forenames>Subhadeep</forenames></author><author><keyname>Chakrabarti</keyname><forenames>Amlan</forenames></author></authors><title>Multiple View Reconstruction of Calibrated Images using Singular Value
  Decomposition</title><categories>cs.CV</categories><comments>In Proceedings of 4th IEEE international conference on Advanced
  Computing and Communication Technologies(ICACCT2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Calibration in a multi camera network has widely been studied for over
several years starting from the earlier days of photogrammetry. Many authors
have presented several calibration algorithms with their relative advantages
and disadvantages. In a stereovision system, multiple view reconstruction is a
challenging task. However, the total computational procedure in detail has not
been presented before. Here in this work, we are dealing with the problem that,
when a world coordinate point is fixed in space, image coordinates of that 3D
point vary for different camera positions and orientations. In computer vision
aspect, this situation is undesirable. That is, the system has to be designed
in such a way that image coordinate of the world coordinate point will be fixed
irrespective of the position &amp; orientation of the cameras. We have done it in
an elegant fashion. Firstly, camera parameters are calculated in its local
coordinate system. Then, we use global coordinate data to transfer all local
coordinate data of stereo cameras into same global coordinate system, so that
we can register everything into this global coordinate system. After all the
transformations, when the image coordinate of the world coordinate point is
calculated, it gives same coordinate value for all camera positions &amp;
orientations. That is, the whole system is calibrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0597</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0597</id><created>2010-11-02</created><updated>2011-01-29</updated><authors><author><keyname>Srikant</keyname><forenames>Shashank</forenames></author></authors><title>Parallelization of Weighted Sequence Comparison by using EBWT</title><categories>cs.DC cs.DS</categories><comments>This paper has been withdrawn by the authors. Extended Burrows
  Wheeler transform; CUDA; Molecular Weighted Sequence; arXiv Admin note:
  Author list truncated due to authorship dispute</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Extended Burrows Wheeler transform (EBWT) helps to find the distance
between two sequences. Implementation of an existing algorithm takes
considerable amount of time for small size sequences. In this paper, we give a
parallel implementation of this algorithm using NVIDIA Compute Unified Device
Architecture (CUDA). We have obtained, on an average, a 2X improvement in the
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0604</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0604</id><created>2010-11-02</created><authors><author><keyname>Majchrzak</keyname><forenames>Tim A.</forenames></author></authors><title>Improving the Technical Aspects of Software Testing in Enterprises</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many software developments projects fail due to quality problems. Software
testing enables the creation of high quality software products. Since it is a
cumbersome and expensive task, and often hard to manage, both its technical
background and its organizational implementation have to be well founded. We
worked with regional companies that develop software in order to learn about
their distinct weaknesses and strengths with regard to testing. Analyzing and
comparing the strengths, we derived best practices. In this paper we explain
the project's background and sketch the design science research methodology
used. We then introduce a graphical categorization framework that helps
companies in judging the applicability of recommendations. Eventually, we
present details on five recommendations for tech-nical aspects of testing. For
each recommendation we give im-plementation advice based on the categorization
framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0620</identifier>
 <datestamp>2012-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0620</id><created>2010-11-02</created><updated>2012-09-11</updated><authors><author><keyname>Basavaraju</keyname><forenames>Manu</forenames></author><author><keyname>Chandran</keyname><forenames>L. Sunil</forenames></author><author><keyname>Rajendraprasad</keyname><forenames>Deepak</forenames></author><author><keyname>Ramaswamy</keyname><forenames>Arunselvan</forenames></author></authors><title>Rainbow Connection Number and Radius</title><categories>math.CO cs.DM</categories><comments>Revised preprint with an extra section on an approximation algorithm.
  arXiv admin note: text overlap with arXiv:1101.5747</comments><msc-class>05C15, 05C40, 05C12 (Primary) 05C38, 05C85 (Secondary)</msc-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The rainbow connection number, rc(G), of a connected graph G is the minimum
number of colours needed to colour its edges, so that every pair of its
vertices is connected by at least one path in which no two edges are coloured
the same. In this note we show that for every bridgeless graph G with radius r,
rc(G) &lt;= r(r + 2). We demonstrate that this bound is the best possible for
rc(G) as a function of r, not just for bridgeless graphs, but also for graphs
of any stronger connectivity. It may be noted that for a general 1-connected
graph G, rc(G) can be arbitrarily larger than its radius (Star graph for
instance). We further show that for every bridgeless graph G with radius r and
chordality (size of a largest induced cycle) k, rc(G) &lt;= rk.
  It is known that computing rc(G) is NP-Hard [Chakraborty et al., 2009]. Here,
we present a (r+3)-factor approximation algorithm which runs in O(nm) time and
a (d+3)-factor approximation algorithm which runs in O(dm) time to rainbow
colour any connected graph G on n vertices, with m edges, diameter d and radius
r.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0628</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0628</id><created>2010-11-02</created><authors><author><keyname>Balakrishnan</keyname><forenames>Julie M. David And Kannan</forenames></author></authors><title>Significance of Classification Techniques in Prediction of Learning
  Disabilities</title><categories>cs.AI</categories><comments>10 pages, 3 tables and 2 figures</comments><journal-ref>International Journal of Artificial Intelligence&amp;Applications, Vol
  1, No.4, Oct. 2010, pp 111-120</journal-ref><doi>10.5121/ijaia.2010.1409</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this study is to show the importance of two classification
techniques, viz. decision tree and clustering, in prediction of learning
disabilities (LD) of school-age children. LDs affect about 10 percent of all
children enrolled in schools. The problems of children with specific learning
disabilities have been a cause of concern to parents and teachers for some
time. Decision trees and clustering are powerful and popular tools used for
classification and prediction in Data mining. Different rules extracted from
the decision tree are used for prediction of learning disabilities. Clustering
is the assignment of a set of observations into subsets, called clusters, which
are useful in finding the different signs and symptoms (attributes) present in
the LD affected child. In this paper, J48 algorithm is used for constructing
the decision tree and K-means algorithm is used for creating the clusters. By
applying these classification techniques, LD in any child can be identified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0630</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0630</id><created>2010-11-02</created><authors><author><keyname>Mihaljev</keyname><forenames>Tamara</forenames></author><author><keyname>de Arcangelis</keyname><forenames>Lucilla</forenames></author><author><keyname>Herrmann</keyname><forenames>Hans J.</forenames></author></authors><title>Inter-arrival times of message propagation on directed networks</title><categories>cond-mat.dis-nn cs.NI cs.SI physics.soc-ph</categories><comments>9 pages, 12 figures</comments><doi>10.1103/PhysRevE.84.026112</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the challenges in fighting cybercrime is to understand the dynamics of
message propagation on botnets, networks of infected computers used to send
viruses, unsolicited commercial emails (SPAM) or denial of service attacks. We
map this problem to the propagation of multiple random walkers on directed
networks and we evaluate the inter-arrival time distribution between successive
walkers arriving at a target. We show that the temporal organization of this
process, which models information propagation on unstructured peer to peer
networks, has the same features as SPAM arriving to a single user. We study the
behavior of the message inter-arrival time distribution on three different
network topologies using two different rules for sending messages. In all
networks the propagation is not a pure Poisson process. It shows universal
features on Poissonian networks and a more complex behavior on scale free
networks. Results open the possibility to indirectly learn about the process of
sending messages on networks with unknown topologies, by studying inter-arrival
times at any node of the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0636</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0636</id><created>2010-11-02</created><authors><author><keyname>Mekkia</keyname><forenames>Kouider</forenames></author></authors><title>Stability number and f-factors in graphs</title><categories>cs.DM</categories><msc-class>stability, factor</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new sufficient condition on stability number and toughness of
the graph to have an f-factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0640</identifier>
 <datestamp>2010-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0640</id><created>2010-10-30</created><authors><author><keyname>Celebi</keyname><forenames>M. Emre</forenames></author><author><keyname>Iyatomi</keyname><forenames>Hitoshi</forenames></author><author><keyname>Schaefer</keyname><forenames>Gerald</forenames></author><author><keyname>Stoecker</keyname><forenames>William V.</forenames></author></authors><title>Lesion Border Detection in Dermoscopy Images</title><categories>cs.CV</categories><comments>10 pages, 1 figure, 3 tables</comments><acm-class>I.4.6</acm-class><journal-ref>Computerized Medical Imaging and Graphics 33 (2009) 148--153</journal-ref><doi>10.1016/j.compmedimag.2008.11.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background: Dermoscopy is one of the major imaging modalities used in the
diagnosis of melanoma and other pigmented skin lesions. Due to the difficulty
and subjectivity of human interpretation, computerized analysis of dermoscopy
images has become an important research area. One of the most important steps
in dermoscopy image analysis is the automated detection of lesion borders.
Methods: In this article, we present a systematic overview of the recent border
detection methods in the literature paying particular attention to
computational issues and evaluation aspects. Conclusion: Common problems with
the existing approaches include the acquisition, size, and diagnostic
distribution of the test image set, the evaluation of the results, and the
inadequate description of the employed methods. Border determination by
dermatologists appears to depend upon higher-level knowledge, therefore it is
likely that the incorporation of domain knowledge in automated methods will
enable them to perform better, especially in sets of images with a variety of
diagnoses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0653</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0653</id><created>2010-11-02</created><authors><author><keyname>Chang</keyname><forenames>Ching-Lueh</forenames></author></authors><title>On reversible cascades in scale-free and Erd\H{o}s-R\'enyi random graphs</title><categories>cs.DM</categories><comments>22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the following cascading process on a simple undirected graph
$G(V,E)$ with diameter $\Delta$. In round zero, a set $S\subseteq V$ of
vertices, called the seeds, are active. In round $i+1,$ $i\in\mathbb{N},$ a
non-isolated vertex is activated if at least a $\rho\in(\,0,1\,]$ fraction of
its neighbors are active in round $i$; it is deactivated otherwise. For
$k\in\mathbb{N},$ let $\text{min-seed}^{(k)}(G,\rho)$ be the minimum number of
seeds needed to activate all vertices in or before round $k$. This paper
derives upper bounds on $\text{min-seed}^{(k)}(G,\rho)$. In particular, if $G$
is connected and there exist constants $C&gt;0$ and $\gamma&gt;2$ such that the
fraction of degree-$k$ vertices in $G$ is at most $C/k^\gamma$ for all
$k\in\mathbb{Z}^+,$ then
$\text{min-seed}^{(\Delta)}(G,\rho)=O(\lceil\rho^{\gamma-1}\,|\,V\,|\rceil)$.
Furthermore, for $n\in\mathbb{Z}^+,$ $p=\Omega((\ln{(e/\rho)})/(\rho n))$ and
with probability $1-\exp{(-n^{\Omega(1)})}$ over the Erd\H{o}s-R\'enyi random
graphs $G(n,p),$ $\text{min-seed}^{(1)}(G(n,p),\rho)=O(\rho n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0673</identifier>
 <datestamp>2012-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0673</id><created>2010-11-02</created><updated>2011-04-15</updated><authors><author><keyname>G&#xf3;mez</keyname><forenames>Vicen&#xe7;</forenames></author><author><keyname>Kappen</keyname><forenames>Hilbert J.</forenames></author><author><keyname>Kaltenbrunner</keyname><forenames>Andreas</forenames></author></authors><title>Modeling the structure and evolution of discussion cascades</title><categories>physics.data-an cs.SI physics.soc-ph</categories><comments>10 pages, 11 figures</comments><acm-class>J.4; G.2.2</acm-class><journal-ref>22nd ACM conference on hypertext and hypermedia (HT 2011)</journal-ref><doi>10.1145/1995966.1995992</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the structure and evolution of discussion cascades in four popular
websites: Slashdot, Barrapunto, Meneame and Wikipedia. Despite the big
heterogeneities between these sites, a preferential attachment (PA) model with
bias to the root can capture the temporal evolution of the observed trees and
many of their statistical properties, namely, probability distributions of the
branching factors (degrees), subtree sizes and certain correlations. The
parameters of the model are learned efficiently using a novel maximum
likelihood estimation scheme for PA and provide a figurative interpretation
about the communication habits and the resulting discussion cascades on the
four different websites.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0686</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0686</id><created>2010-11-02</created><updated>2011-03-16</updated><authors><author><keyname>Ross</keyname><forenames>Stephane</forenames></author><author><keyname>Gordon</keyname><forenames>Geoffrey J.</forenames></author><author><keyname>Bagnell</keyname><forenames>J. Andrew</forenames></author></authors><title>A Reduction of Imitation Learning and Structured Prediction to No-Regret
  Online Learning</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appearing in the 14th International Conference on Artificial
  Intelligence and Statistics (AISTATS 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequential prediction problems such as imitation learning, where future
observations depend on previous predictions (actions), violate the common
i.i.d. assumptions made in statistical learning. This leads to poor performance
in theory and often in practice. Some recent approaches provide stronger
guarantees in this setting, but remain somewhat unsatisfactory as they train
either non-stationary or stochastic policies and require a large number of
iterations. In this paper, we propose a new iterative algorithm, which trains a
stationary deterministic policy, that can be seen as a no regret algorithm in
an online learning setting. We show that any such no regret algorithm, combined
with additional reduction assumptions, must find a policy with good performance
under the distribution of observations it induces in such sequential settings.
We demonstrate that this new approach outperforms previous approaches on two
challenging imitation learning problems and a benchmark sequence labeling
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0688</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0688</id><created>2010-11-02</created><updated>2011-12-13</updated><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas A.</forenames></author><author><keyname>Prabhu</keyname><forenames>Vinayak S.</forenames></author></authors><title>Timed Parity Games: Complexity and Robustness</title><categories>cs.LO</categories><proxy>Logical Methods In Computer Science</proxy><report-no>LMCS-Journal-02</report-no><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 4 (December
  14, 2011) lmcs:1102</journal-ref><doi>10.2168/LMCS-7(4:08)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two-player games played in real time on game structures with
clocks where the objectives of players are described using parity conditions.
The games are \emph{concurrent} in that at each turn, both players
independently propose a time delay and an action, and the action with the
shorter delay is chosen. To prevent a player from winning by blocking time, we
restrict each player to play strategies that ensure that the player cannot be
responsible for causing a zeno run. First, we present an efficient reduction of
these games to \emph{turn-based} (i.e., not concurrent) \emph{finite-state}
(i.e., untimed) parity games. Our reduction improves the best known complexity
for solving timed parity games. Moreover, the rich class of algorithms for
classical parity games can now be applied to timed parity games. The states of
the resulting game are based on clock regions of the original game, and the
state space of the finite game is linear in the size of the region graph.
  Second, we consider two restricted classes of strategies for the player that
represents the controller in a real-time synthesis problem, namely,
\emph{limit-robust} and \emph{bounded-robust} winning strategies. Using a
limit-robust winning strategy, the controller cannot choose an exact
real-valued time delay but must allow for some nonzero jitter in each of its
actions. If there is a given lower bound on the jitter, then the strategy is
bounded-robust winning. We show that exact strategies are more powerful than
limit-robust strategies, which are more powerful than bounded-robust winning
strategies for any bound. For both kinds of robust strategies, we present
efficient reductions to standard timed automaton games. These reductions
provide algorithms for the synthesis of robust real-time controllers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0715</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0715</id><created>2010-11-02</created><authors><author><keyname>Miller</keyname><forenames>Zach</forenames></author><author><keyname>Bradley</keyname><forenames>Dan</forenames></author><author><keyname>Tannenbaum</keyname><forenames>Todd</forenames></author><author><keyname>Sfiligoi</keyname><forenames>Igor</forenames></author></authors><title>Flexible Session Management in a Distributed Environment</title><categories>cs.DC</categories><journal-ref>J.Phys.Conf.Ser.219:042017,2010</journal-ref><doi>10.1088/1742-6596/219/4/042017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many secure communication libraries used by distributed systems, such as SSL,
TLS, and Kerberos, fail to make a clear distinction between the authentication,
session, and communication layers. In this paper we introduce CEDAR, the secure
communication library used by the Condor High Throughput Computing software,
and present the advantages to a distributed computing system resulting from
CEDAR's separation of these layers. Regardless of the authentication method
used, CEDAR establishes a secure session key, which has the flexibility to be
used for multiple capabilities. We demonstrate how a layered approach to
security sessions can avoid round-trips and latency inherent in network
authentication. The creation of a distinct session management layer allows for
optimizations to improve scalability by way of delegating sessions to other
components in the system. This session delegation creates a chain of trust that
reduces the overhead of establishing secure connections and enables centralized
enforcement of system-wide security policies. Additionally, secure channels
based upon UDP datagrams are often overlooked by existing libraries; we show
how CEDAR's structure accommodates this as well. As an example of the utility
of this work, we show how the use of delegated security sessions and other
techniques inherent in CEDAR's architecture enables US CMS to meet their
scalability requirements in deploying Condor over large-scale, wide-area grid
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0755</identifier>
 <datestamp>2010-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0755</id><created>2010-11-02</created><authors><author><keyname>Stoianov</keyname><forenames>Nikolai Todorov</forenames></author><author><keyname>Tselkov</keyname><forenames>Veselin Tsenov</forenames></author></authors><title>E-Net Models of a Software System for Web Pages Security SECURITY</title><categories>cs.CR</categories><comments>6 pages, 3 figures, Mathematics and Education in Mathematics, 2003
  Proceedings of the Thirty Second Spring Conference of the Union of Bulgarian
  Mathematicians,pp.285-290, ISBN 954-8880-14-8</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents solutions for cryptography protection for web pages. The
solutions comprise the authors' experience in development and implementation of
systems for information security in the Automated Information Systems of
Bulgarian Armed Forces. The architecture, the models and the methods are being
explained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0774</identifier>
 <datestamp>2010-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0774</id><created>2010-11-02</created><authors><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Zaman</keyname><forenames>Tauhid</forenames></author></authors><title>Community Detection in Networks: The Leader-Follower Algorithm</title><categories>stat.ML cs.SI physics.soc-ph</categories><comments>13 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional spectral clustering methods cannot naturally learn the number of
communities in a network and often fail to detect smaller community structure
in dense networks because they are based upon external community connectivity
properties such as graph cuts. We propose an algorithm for detecting community
structure in networks called the leader-follower algorithm which is based upon
the natural internal structure expected of communities in social networks. The
algorithm uses the notion of network centrality in a novel manner to
differentiate leaders (nodes which connect different communities) from loyal
followers (nodes which only have neighbors within a single community). Using
this approach, it is able to naturally learn the communities from the network
structure and does not require the number of communities as an input, in
contrast to other common methods such as spectral clustering. We prove that it
will detect all of the communities exactly for any network possessing
communities with the natural internal structure expected in social networks.
More importantly, we demonstrate the effectiveness of the leader-follower
algorithm in the context of various real networks ranging from social networks
such as Facebook to biological networks such as an fMRI based human brain
network. We find that the leader-follower algorithm finds the relevant
community structure in these networks without knowing the number of communities
beforehand. Also, because the leader-follower algorithm detects communities
using their internal structure, we find that it can resolve a finer community
structure in dense networks than common spectral clustering methods based on
external community structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0786</identifier>
 <datestamp>2010-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0786</id><created>2010-11-02</created><authors><author><keyname>Han</keyname><forenames>Mr. Chong</forenames></author><author><keyname>Nevat</keyname><forenames>Dr. Ido</forenames></author><author><keyname>Peters</keyname><forenames>Dr. Gareth</forenames></author><author><keyname>Yuan</keyname><forenames>Prof. Jinhong</forenames></author></authors><title>Gaussian Process Techniques for Wireless Communications</title><categories>cs.IT math.IT</categories><comments>This is a Thesis A report submitted to School of Electrical
  Engineering &amp; Telecommunications, University of New South Wales, Australia,
  based on the work done in Semester 2, 2010. Research work is to be continued
  in Semester 1, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bayesian filtering is a general framework for recursively estimating the
state of a dynamical system. Classical solutions such that Kalman filter and
Particle filter are introduced in this report. Gaussian processes have been
introduced as a non-parametric technique for system estimation from supervision
learning. For the thesis project, we intend to propose a new, general
methodology for inference and learning in non-linear state-space models
probabilistically incorporating with the Gaussian process model estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0792</identifier>
 <datestamp>2010-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0792</id><created>2010-11-02</created><authors><author><keyname>Dhinakaran</keyname><forenames>Cynthia</forenames></author><author><keyname>Nagamalai</keyname><forenames>Dhinaharan</forenames></author><author><keyname>Lee</keyname><forenames>Jae Kwang</forenames></author></authors><title>An Empirical Study of Spam and Spam Vulnerable email Accounts</title><categories>cs.CR cs.NI</categories><comments>6 pages, 5 Figures, FGCN 2007, IEEE CS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spam messages muddle up users inbox, consume network resources, and build up
DDoS attacks, spread malware. Our goal is to present a definite figure about
the characteristics of spam and spam vulnerable email accounts. These
evaluations help us to enhance the existing technology to combat spam
effectively. We collected 400 thousand spam mails from a spam trap set up in a
corporate mail server for a period of 14 months form January 2006 to February
2007. Spammers use common techniques to spam end users regardless of corporate
server and public mail server. So we believe that our spam collection is a
sample of world wide spam traffic. Studying the characteristics of this sample
helps us to better understand the features of spam and spam vulnerable e-mail
accounts. We believe that this analysis is highly useful to develop more
efficient anti spam techniques. In our analysis we classified spam based on
attachment and contents. According to our study the four years old heavy users
email accounts attract more spam than four years oldlight users mail accounts.
The 14 months old relatively new email accounts don't receive spam. In some
special cases like DDoS attacks, the new email accounts receive spam. During
DDoS attack 14 months old heavy users email accounts have attracted more number
of spam than 14 months old light users mail accounts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0800</identifier>
 <datestamp>2010-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0800</id><created>2010-11-03</created><authors><author><keyname>Bhargavi</keyname><forenames>P.</forenames><affiliation>Department of CSE Madanapalli Institue of Tecnology and Science, Madanapalli</affiliation></author><author><keyname>Jyothi</keyname><forenames>S.</forenames><affiliation>Department of Computer Science Sri Padmavathi Mahila ViswaVidyalayam, Tirupati</affiliation></author></authors><title>Soil Classification Using GATree</title><categories>cs.NE</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper details the application of a genetic programming framework for
classification of decision tree of Soil data to classify soil texture. The
database contains measurements of soil profile data. We have applied GATree for
generating classification decision tree. GATree is a decision tree builder that
is based on Genetic Algorithms (GAs). The idea behind it is rather simple but
powerful. Instead of using statistic metrics that are biased towards specific
trees we use a more flexible, global metric of tree quality that try to
optimize accuracy and size. GATree offers some unique features not to be found
in any other tree inducers while at the same time it can produce better results
for many difficult problems. Experimental results are presented which
illustrate the performance of generating best decision tree for classifying
soil texture for soil data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0810</identifier>
 <datestamp>2010-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0810</id><created>2010-11-03</created><authors><author><keyname>Sedransk</keyname><forenames>Nell</forenames></author><author><keyname>Cox</keyname><forenames>Lawrence H.</forenames></author><author><keyname>Nolan</keyname><forenames>Deborah</forenames></author><author><keyname>Soper</keyname><forenames>Keith</forenames></author><author><keyname>Spiegelman</keyname><forenames>Cliff</forenames></author><author><keyname>Young</keyname><forenames>Linda J.</forenames></author><author><keyname>Kelner</keyname><forenames>Katrina L.</forenames></author><author><keyname>Moffitt</keyname><forenames>Robert A.</forenames></author><author><keyname>Thakar</keyname><forenames>Ani</forenames></author><author><keyname>Raddick</keyname><forenames>Jordan</forenames></author><author><keyname>Ungvarsky</keyname><forenames>Edward J.</forenames></author><author><keyname>Carlson</keyname><forenames>Richard W.</forenames></author><author><keyname>Apweiler</keyname><forenames>Rolf</forenames></author></authors><title>Make Research Data Public?---Not Always so Simple: A Dialogue for
  Statisticians and Science Editors</title><categories>stat.ME cs.DL physics.data-an</categories><comments>Published in at http://dx.doi.org/10.1214/10-STS320 the Statistical
  Science (http://www.imstat.org/sts/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-STS-STS320</report-no><journal-ref>Statistical Science 2010, Vol. 25, No. 1, 41-50</journal-ref><doi>10.1214/10-STS320</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Putting data into the public domain is not the same thing as making those
data accessible for intelligent analysis. A distinguished group of editors and
experts who were already engaged in one way or another with the issues inherent
in making research data public came together with statisticians to initiate a
dialogue about policies and practicalities of requiring published research to
be accompanied by publication of the research data. This dialogue carried
beyond the broad issues of the advisability, the intellectual integrity, the
scientific exigencies to the relevance of these issues to statistics as a
discipline and the relevance of statistics, from inference to modeling to data
exploration, to science and social science policies on these issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0835</identifier>
 <datestamp>2010-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0835</id><created>2010-11-03</created><authors><author><keyname>Lin</keyname><forenames>Ziheng</forenames></author><author><keyname>Ng</keyname><forenames>Hwee Tou</forenames></author><author><keyname>Kan</keyname><forenames>Min-Yen</forenames></author></authors><title>A PDTB-Styled End-to-End Discourse Parser</title><categories>cs.CL</categories><comments>15 pages, 5 figures, 7 tables</comments><report-no>TRB8/10</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have developed a full discourse parser in the Penn Discourse Treebank
(PDTB) style. Our trained parser first identifies all discourse and
non-discourse relations, locates and labels their arguments, and then
classifies their relation types. When appropriate, the attribution spans to
these relations are also determined. We present a comprehensive evaluation from
both component-wise and error-cascading perspectives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0851</identifier>
 <datestamp>2011-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0851</id><created>2010-11-03</created><updated>2011-07-15</updated><authors><author><keyname>Baayen</keyname><forenames>Jorn H.</forenames></author><author><keyname>Ockels</keyname><forenames>Wubbo J.</forenames></author></authors><title>Tracking control with adaption of kites</title><categories>math.OC cs.SY</categories><comments>20 pages, 12 figures</comments><msc-class>93C40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel tracking paradigm for flying geometric trajectories using tethered
kites is presented. It is shown how the differential-geometric notion of
turning angle can be used as a one-dimensional representation of the kite
trajectory, and how this leads to a single-input single-output (SISO) tracking
problem. Based on this principle a Lyapunov-based nonlinear adaptive controller
is developed that only needs control derivatives of the kite aerodynamic model.
The resulting controller is validated using simulations with a point-mass kite
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0935</identifier>
 <datestamp>2010-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0935</id><created>2010-11-03</created><updated>2010-11-05</updated><authors><author><keyname>Ding</keyname><forenames>Jianguo</forenames></author></authors><title>Probabilistic Inferences in Bayesian Networks</title><categories>cs.AI cs.NI</categories><comments>14 pages, 9 figures, book chapter</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Bayesian network is a complete model for the variables and their
relationships, it can be used to answer probabilistic queries about them. A
Bayesian network can thus be considered a mechanism for automatically applying
Bayes' theorem to complex problems. In the application of Bayesian networks,
most of the work is related to probabilistic inferences. Any variable updating
in any node of Bayesian networks might result in the evidence propagation
across the Bayesian networks. This paper sums up various inference techniques
in Bayesian networks and provide guidance for the algorithm calculation in
probabilistic inference in Bayesian networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0950</identifier>
 <datestamp>2010-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0950</id><created>2010-11-03</created><authors><author><keyname>Ghosh</keyname><forenames>Priyankar</forenames></author><author><keyname>Dasgupta</keyname><forenames>Pallab</forenames></author></authors><title>Detecting Ontological Conflicts in Protocols between Semantic Web
  Services</title><categories>cs.AI</categories><journal-ref>International Journal of Web \&amp; Semantic Technology (IJWest)
  Vol.1, Num.4, October 2010</journal-ref><doi>10.5121/ijwest.2010.1403</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The task of verifying the compatibility between interacting web services has
traditionally been limited to checking the compatibility of the interaction
protocol in terms of message sequences and the type of data being exchanged.
Since web services are developed largely in an uncoordinated way, different
services often use independently developed ontologies for the same domain
instead of adhering to a single ontology as standard. In this work we
investigate the approaches that can be taken by the server to verify the
possibility to reach a state with semantically inconsistent results during the
execution of a protocol with a client, if the client ontology is published.
Often database is used to store the actual data along with the ontologies
instead of storing the actual data as a part of the ontology description. It is
important to observe that at the current state of the database the semantic
conflict state may not be reached even if the verification done by the server
indicates the possibility of reaching a conflict state. A relational algebra
based decision procedure is also developed to incorporate the current state of
the client and the server databases in the overall verification procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0953</identifier>
 <datestamp>2010-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0953</id><created>2010-11-03</created><authors><author><keyname>Cebrian</keyname><forenames>Manuel</forenames></author><author><keyname>Alfonseca</keyname><forenames>Manuel</forenames></author><author><keyname>Ortega</keyname><forenames>Alfonso</forenames></author></authors><title>Overcoming Problems in the Measurement of Biological Complexity</title><categories>cs.CE cs.NE nlin.AO q-bio.PE</categories><comments>4 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a genetic algorithm, fluctuations of the entropy of a genome over time are
interpreted as fluctuations of the information that the genome's organism is
storing about its environment, being this reflected in more complex organisms.
The computation of this entropy presents technical problems due to the small
population sizes used in practice. In this work we propose and test an
alternative way of measuring the entropy variation in a population by means of
algorithmic information theory, where the entropy variation between two
generational steps is the Kolmogorov complexity of the first step conditioned
to the second one. As an example application of this technique, we report
experimental differences in entropy evolution between systems in which sexual
reproduction is present or absent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0971</identifier>
 <datestamp>2014-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0971</id><created>2010-11-03</created><updated>2014-02-20</updated><authors><author><keyname>Togni</keyname><forenames>Olivier</forenames><affiliation>Le2i</affiliation></author></authors><title>On Packing Colorings of Distance Graphs</title><categories>cs.DM math.CO</categories><proxy>ccsd</proxy><journal-ref>Discrete Applied Mathematics 167 (2014) 280-289</journal-ref><doi>10.1016/j.dam.2013.10.026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The {\em packing chromatic number} $\chi_{\rho}(G)$ of a graph $G$ is the
least integer $k$ for which there exists a mapping $f$ from $V(G)$ to
$\{1,2,\ldots ,k\}$ such that any two vertices of color $i$ are at distance at
least $i+1$. This paper studies the packing chromatic number of infinite
distance graphs $G(\mathbb{Z},D)$, i.e. graphs with the set $\mathbb{Z}$ of
integers as vertex set, with two distinct vertices $i,j\in \mathbb{Z}$ being
adjacent if and only if $|i-j|\in D$. We present lower and upper bounds for
$\chi_{\rho}(G(\mathbb{Z},D))$, showing that for finite $D$, the packing
chromatic number is finite. Our main result concerns distance graphs with
$D=\{1,t\}$ for which we prove some upper bounds on their packing chromatic
numbers, the smaller ones being for $t\geq 447$:
$\chi_{\rho}(G(\mathbb{Z},\{1,t\}))\leq 40$ if $t$ is odd and
$\chi_{\rho}(G(\mathbb{Z},\{1,t\}))\leq 81$ if $t$ is even.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0972</identifier>
 <datestamp>2014-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0972</id><created>2010-11-03</created><authors><author><keyname>Ch&#xe8;ze</keyname><forenames>Guillaume</forenames><affiliation>IMT</affiliation></author></authors><title>A recombination algorithm for the decomposition of multivariate rational
  functions</title><categories>cs.SC cs.DS math.AC</categories><proxy>ccsd</proxy><journal-ref>Mathematics of Computation 82 (2013) 1793--1812</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we show how we can compute in a deterministic way the
decomposition of a multivariate rational function with a recombination
strategy. The key point of our recombination strategy is the used of Darboux
polynomials. We study the complexity of this strategy and we show that this
method improves the previous ones. In appendix, we explain how the strategy
proposed recently by J. Berthomieu and G. Lecerf for the sparse factorization
can be used in the decomposition setting. Then we deduce a decomposition
algorithm in the sparse bivariate case and we give its complexity
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0997</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0997</id><created>2010-11-03</created><authors><author><keyname>Hunter</keyname><forenames>Blake</forenames></author><author><keyname>Strohmer</keyname><forenames>Thomas</forenames></author></authors><title>Performance Analysis of Spectral Clustering on Compressed, Incomplete
  and Inaccurate Measurements</title><categories>math.NA cs.CV math.FA stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectral clustering is one of the most widely used techniques for extracting
the underlying global structure of a data set. Compressed sensing and matrix
completion have emerged as prevailing methods for efficiently recovering sparse
and partially observed signals respectively. We combine the distance preserving
measurements of compressed sensing and matrix completion with the power of
robust spectral clustering. Our analysis provides rigorous bounds on how small
errors in the affinity matrix can affect the spectral coordinates and
clusterability. This work generalizes the current perturbation results of
two-class spectral clustering to incorporate multi-class clustering with k
eigenvectors. We thoroughly track how small perturbation from using compressed
sensing and matrix completion affect the affinity matrix and in succession the
spectral coordinates. These perturbation results for multi-class clustering
require an eigengap between the kth and (k+1)th eigenvalues of the affinity
matrix, which naturally occurs in data with k well-defined clusters. Our
theoretical guarantees are complemented with numerical results along with a
number of examples of the unsupervised organization and clustering of image
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1021</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1021</id><created>2010-11-03</created><authors><author><keyname>Pryor</keyname><forenames>Louise</forenames></author></authors><title>What's the point of documentation?</title><categories>cs.SE</categories><comments>4 Pages, 1 Colour Figure. Referenced by GJC in Nov 2010;
  ISBN:1-905617-08-9</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a brief characterisation of the purposes and forms of documentation
in and of spreadsheets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1030</identifier>
 <datestamp>2011-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1030</id><created>2010-11-03</created><updated>2011-10-17</updated><authors><author><keyname>Le</keyname><forenames>Dai Tri Man</forenames></author></authors><title>On Three Alternative Characterizations of Combined Traces</title><categories>cs.FL cs.DC</categories><comments>22 pages, preliminary version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The combined trace (i.e., comtrace) notion was introduced by Janicki and
Koutny in 1995 as a generalization of the Mazurkiewicz trace notion. Comtraces
are congruence classes of step sequences, where the congruence relation is
defined from two relations simultaneity and serializability on events. They
also showed that comtraces correspond to some class of labeled stratified order
structures, but left open the question of what class of labeled stratified
orders represents comtraces. In this work, we proposed a class of labeled
stratified order structures that captures exactly the comtrace notion. Our main
technical contributions are representation theorems showing that comtrace
quotient monoid, combined dependency graph (Kleijn and Koutny 2008) and our
labeled stratified order structure characterization are three different and yet
equivalent ways to represent comtraces. This paper is a revised and expanded
version of L\^e (in Proceedings of PETRI NETS 2010, LNCS 6128, pp. 104-124).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1035</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1035</id><created>2010-11-03</created><authors><author><keyname>Jayawardena</keyname><forenames>Srimal</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author><author><keyname>Brewer</keyname><forenames>Nathan</forenames></author></authors><title>Featureless 2D-3D Pose Estimation by Minimising an
  Illumination-Invariant Loss</title><categories>cs.CV</categories><comments>18 LaTeX pages, 7 figures</comments><journal-ref>Proc. 13th International Conf. on Digital Image Computing:
  Techniques and Applications (DICTA-2011) 37--44</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of identifying the 3D pose of a known object from a given 2D
image has important applications in Computer Vision ranging from robotic vision
to image analysis. Our proposed method of registering a 3D model of a known
object on a given 2D photo of the object has numerous advantages over existing
methods: It does neither require prior training nor learning, nor knowledge of
the camera parameters, nor explicit point correspondences or matching features
between image and model. Unlike techniques that estimate a partial 3D pose (as
in an overhead view of traffic or machine parts on a conveyor belt), our method
estimates the complete 3D pose of the object, and works on a single static
image from a given view, and under varying and unknown lighting conditions. For
this purpose we derive a novel illumination-invariant distance measure between
2D photo and projected 3D model, which is then minimised to find the best pose
parameters. Results for vehicle pose detection are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1036</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1036</id><created>2010-11-03</created><authors><author><keyname>Brillout</keyname><forenames>Angelo</forenames></author><author><keyname>Kroening</keyname><forenames>Daniel</forenames></author><author><keyname>Ruemmer</keyname><forenames>Philipp</forenames></author><author><keyname>Wahl</keyname><forenames>Thomas</forenames></author></authors><title>Beyond Quantifier-Free Interpolation in Extensions of Presburger
  Arithmetic (Extended Technical Report)</title><categories>cs.LO</categories><comments>extended version (including proofs, complete rules listings, etc) of
  a VMCAI 2011 proceedings version</comments><doi>10.1007/978-3-642-18275-4_8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Craig interpolation has emerged as an effective means of generating candidate
program invariants. We present interpolation procedures for the theories of
Presburger arithmetic combined with (i) uninterpreted predicates (QPA+UP), (ii)
uninterpreted functions (QPA+UF) and (iii) extensional arrays (QPA+AR). We
prove that none of these combinations can be effectively interpolated without
the use of quantifiers, even if the input formulae are quantifier-free. We go
on to identify fragments of QPA+UP and QPA+UF with restricted forms of guarded
quantification that are closed under interpolation. Formulae in these fragments
can easily be mapped to quantifier-free expressions with integer division. For
QPA+AR, we formulate a sound interpolation procedure that potentially produces
interpolants with unrestricted quantifiers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1040</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1040</id><created>2010-11-03</created><updated>2011-04-13</updated><authors><author><keyname>Ali</keyname><forenames>Mortuza</forenames></author><author><keyname>Kuijper</keyname><forenames>Margreta</forenames></author></authors><title>A parametric approach to list decoding of Reed-Solomon codes using
  interpolation</title><categories>cs.IT math.IT</categories><comments>Corrected Definition 2.3. Accepted for publication in IEEE
  Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. 57, no. 10, pp. 6718
  - 6728, 2011</journal-ref><doi>10.1109/TIT.2011.2165803</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a minimal list decoding algorithm for Reed-Solomon
(RS) codes. Minimal list decoding for a code $C$ refers to list decoding with
radius $L$, where $L$ is the minimum of the distances between the received word
$\mathbf{r}$ and any codeword in $C$. We consider the problem of determining
the value of $L$ as well as determining all the codewords at distance $L$. Our
approach involves a parametrization of interpolating polynomials of a minimal
Gr\&quot;obner basis $G$. We present two efficient ways to compute $G$. We also show
that so-called re-encoding can be used to further reduce the complexity. We
then demonstrate how our parametric approach can be solved by a computationally
feasible rational curve fitting solution from a recent paper by Wu. Besides, we
present an algorithm to compute the minimum multiplicity as well as the optimal
values of the parameters associated with this multiplicity which results in
overall savings in both memory and computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1043</identifier>
 <datestamp>2011-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1043</id><created>2010-11-03</created><authors><author><keyname>Liu</keyname><forenames>Xin</forenames></author><author><keyname>Murata</keyname><forenames>Tsuyoshi</forenames></author></authors><title>Detecting Communities in Tripartite Hypergraphs</title><categories>cs.SI physics.soc-ph</categories><comments>4 pages, 3 figures</comments><report-no>vol.26, no.5, pp.778-791</report-no><journal-ref>Journal of Computer Science and Technology, vol.26, no.5,
  pp.778-791, Sep 2011</journal-ref><doi>10.1007/s11390-011-0177-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In social tagging systems, also known as folksonomies, users collaboratively
manage tags to annotate resources. Naturally, social tagging systems can be
modeled as a tripartite hypergraph, where there are three different types of
nodes, namely users, resources and tags, and each hyperedge has three end
nodes, connecting a user, a resource and a tag that the user employs to
annotate the resource. Then, how can we automatically detect user, resource and
tag communities from the tripartite hypergraph? In this paper, by turning the
problem into a problem of finding an efficient compression of the hypergraph's
structure, we propose a quality function for measuring the goodness of
partitions of a tripartite hypergraph into communities. Later, we develop a
fast community detection algorithm based on minimizing the quality function. We
explain advantages of our method and validate it by comparing with various
state of the art techniques in a set of synthetic datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1050</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1050</id><created>2010-11-03</created><authors><author><keyname>Dhinakaran</keyname><forenames>Cynthia</forenames></author><author><keyname>Nagamalai</keyname><forenames>Dhinaharan</forenames></author><author><keyname>Lee</keyname><forenames>Jae Kwang</forenames></author></authors><title>Characterizing Spam traffic and Spammers</title><categories>cs.CR cs.NI</categories><comments>6 pages, 4 Figures, ICCIT 2007, IEEE CS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a tremendous increase in spam traffic these days. Spam messages
muddle up users inbox, consume network resources, and build up DDoS attacks,
spread worms and viruses. Our goal is to present a definite figure about the
characteristics of spam and spammers. Since spammers change their mode of
operation to counter anti spam technology,continues evaluation of the
characteristics of spam and spammers technology has become mandatory. These
evaluations help us to enhance the existing technology to combat spam
effectively. We collected 400 thousand spam mails from a spam trap set up in a
corporate mail server for a period of 14 months form January 2006 to February
2007. Spammers use common techniques to spam end users regardless of corporate
server and public mail server. So we believe that our spam collection is a
sample of world wide spam traffic. Studying the characteristics of this sample
helps us to better understand the features of spam and spammers technology. We
believe that this analysis could be useful to develop more efficient anti spam
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1058</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1058</id><created>2010-11-03</created><authors><author><keyname>Babu</keyname><forenames>S. Ajesh</forenames></author><author><keyname>Radhakrishnan</keyname><forenames>Jaikumar</forenames></author></authors><title>An entropy based proof of the Moore bound for irregular graphs</title><categories>cs.DM</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide proofs of the following theorems by considering the entropy of
random walks: Theorem 1.(Alon, Hoory and Linial) Let G be an undirected simple
graph with n vertices, girth g, minimum degree at least 2 and average degree d:
Odd girth: If g=2r+1,then n \geq 1 + d*(\Sum_{i=0}^{r-1}(d-1)^i) Even girth: If
g=2r,then n \geq 2*(\Sum_{i=0}^{r-1} (d-1)^i) Theorem 2.(Hoory) Let G =
(V_L,V_R,E) be a bipartite graph of girth g = 2r, with n_L = |V_L| and n_R =
|V_R|, minimum degree at least 2 and the left and right average degrees d_L and
d_R. Then, n_L \geq \Sum_{i=0}^{r-1}(d_R-1)^{i/2}(d_L-1)^{i/2} n_R \geq
\Sum_{i=0}^{r-1}(d_L-1)^{i/2}(d_R-1)^{i/2}
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1065</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1065</id><created>2010-11-04</created><updated>2013-05-05</updated><authors><author><keyname>Li</keyname><forenames>Shuqin</forenames></author><author><keyname>Huang</keyname><forenames>Jianwei</forenames></author></authors><title>Price Differentiation for Communication Networks</title><categories>cs.NI</categories><comments>Technical report for the paper of the same name to appear in IEEE/ACM
  Transactions on Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the optimal usage-based pricing problem in a resource-constrained
network with one profit-maximizing service provider and multiple groups of
surplus-maximizing users. With the assumption that the service provider knows
the utility function of each user (thus complete information), we find that the
complete price differentiation scheme can achieve a large revenue gain (e.g.,
50%) compared to no price differentiation, when the total network resource is
comparably limited and the high willingness to pay users are minorities.
However, the complete price differentiation scheme may lead to a high
implementational complexity. To trade off the revenue against the
implementational complexity, we further study the partial price differentiation
scheme, and design a polynomial-time algorithm that can compute the optimal
partial differentiation prices. We also consider the incomplete information
case where the service provider does not know which group each user belongs to.
We show that it is still possible to realize price differentiation under this
scenario, and provide the sufficient and necessary condition under which an
incentive compatible differentiation scheme can achieve the same revenue as
under complete information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1081</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1081</id><created>2010-11-04</created><authors><author><keyname>Tomassini</keyname><forenames>Marco</forenames></author><author><keyname>Pestelacci</keyname><forenames>Enea</forenames></author></authors><title>Evolution of Coordination in Social Networks: A Numerical Study</title><categories>physics.soc-ph cs.SI</categories><comments>preprint submitted to IJMPC</comments><doi>10.1142/S012918311001583X</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coordination games are important to explain efficient and desirable social
behavior. Here we study these games by extensive numerical simulation on
networked social structures using an evolutionary approach. We show that local
network effects may promote selection of efficient equilibria in both pure and
general coordination games and may explain social polarization. These results
are put into perspective with respect to known theoretical results. The main
insight we obtain is that clustering, and especially community structure in
social networks has a positive role in promoting socially efficient outcomes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1091</identifier>
 <datestamp>2011-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1091</id><created>2010-11-04</created><updated>2011-09-20</updated><authors><author><keyname>Hauenstein</keyname><forenames>Jonathan D.</forenames></author><author><keyname>Sottile</keyname><forenames>Frank</forenames></author></authors><title>alphaCertified: certifying solutions to polynomial systems</title><categories>math.NA cs.MS math.AG</categories><comments>21 pages</comments><msc-class>65G20, 65H05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smale's alpha-theory uses estimates related to the convergence of Newton's
method to give criteria implying that Newton iterations will converge
quadratically to solutions to a square polynomial system. The program
alphaCertified implements algorithms based on alpha-theory to certify solutions
to polynomial systems using both exact rational arithmetic and arbitrary
precision floating point arithmetic. It also implements an algorithm to certify
whether a given point corresponds to a real solution to a real polynomial
system, as well as algorithms to heuristically validate solutions to
overdetermined systems. Examples are presented to demonstrate the algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1119</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1119</id><created>2010-11-04</created><authors><author><keyname>Chertov</keyname><forenames>Oleg</forenames></author><author><keyname>Tavrov</keyname><forenames>Dan</forenames></author></authors><title>Group Anonymity</title><categories>cs.CR</categories><comments>10 pages, 2 tables. Published by Springer in &quot;Information Processing
  and Management of Uncertainty in Knowledge-Based Systems. Applications&quot;. The
  final publication is available at
  http://www.springerlink.com/content/u701148783683775/</comments><journal-ref>&quot;Information Processing and Management of Uncertainty in
  Knowledge-Based Systems. Applications&quot; (Communications in Computer and
  Information Science, Volume 81, Part 6, Part 9, 592-601), 2010</journal-ref><doi>10.1007/978-3-642-14058-7_61</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years the amount of digital data in the world has risen immensely.
But, the more information exists, the greater is the possibility of its
unwanted disclosure. Thus, the data privacy protection has become a pressing
problem of the present time. The task of individual privacy-preserving is being
thoroughly studied nowadays. At the same time, the problem of statistical
disclosure control for collective (or group) data is still open. In this paper
we propose an effective and relatively simple (wavelet-based) way to provide
group anonymity in collective data. We also provide a real-life example to
illustrate the method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1121</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1121</id><created>2010-11-04</created><authors><author><keyname>Chertov</keyname><forenames>Oleg</forenames></author><author><keyname>Tavrov</keyname><forenames>Dan</forenames></author></authors><title>Providing Group Anonymity Using Wavelet Transform</title><categories>cs.CR</categories><comments>12 pages, 2 tables. Accepted to be printed by Springer in BNCOD 2010
  proceedings (Lecture Notes in Computer Science series)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Providing public access to unprotected digital data can pose a threat of
unwanted disclosing the restricted information. The problem of protecting such
information can be divided into two main subclasses, namely, individual and
group data anonymity. By group anonymity we define protecting important data
patterns, distributions, and collective features which cannot be determined
through analyzing individual records only. An effective and comparatively
simple way of solving group anonymity problem is doubtlessly applying wavelet
transform. It's easy-to-implement, powerful enough, and might produce
acceptable results if used properly. In the paper, we present a novel method of
using wavelet transform for providing group anonymity; it is gained through
redistributing wavelet approximation values, along with simultaneous fixing
data mean value and leaving wavelet details unchanged (or proportionally
altering them). Moreover, we provide a comprehensive example to illustrate the
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1124</identifier>
 <datestamp>2010-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1124</id><created>2010-11-04</created><updated>2010-11-05</updated><authors><author><keyname>Demirel</keyname><forenames>G&#xfc;ven</forenames></author><author><keyname>Prizak</keyname><forenames>Roshan</forenames></author><author><keyname>Reddy</keyname><forenames>P. Nitish</forenames></author><author><keyname>Gross</keyname><forenames>Thilo</forenames></author></authors><title>Opinion formation and cyclic dominance in adaptive networks</title><categories>nlin.AO cond-mat.dis-nn cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Rock-Paper-Scissors(RPS) game is a paradigmatic model for cyclic
dominance in biological systems. Here we consider this game in the social
context of competition between opinions in a networked society. In our model,
every agent has an opinion which is drawn from the three choices: rock, paper
or scissors. In every timestep a link is selected randomly and the game is
played between the nodes connected by the link. The loser either adopts the
opinion of the winner or rewires the link. These rules define an adaptive
network on which the agent's opinions coevolve with the network topology of
social contacts. We show analytically and numerically that nonequilibrium phase
transitions occur as a function of the rewiring strength. The transitions
separate four distinct phases which differ in the observed dynamics of opinions
and topology. In particular, there is one phase where the population settles to
an arbitrary consensus opinion. We present a detailed analysis of the
corresponding transitions revealing an apparently paradoxial behavior. The
system approaches consensus states where they are unstable, whereas other
dynamics prevail when the consensus states are stable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1127</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1127</id><created>2010-11-04</created><authors><author><keyname>Chertov</keyname><forenames>Oleg</forenames></author><author><keyname>Tavrov</keyname><forenames>Dan</forenames></author></authors><title>Group Anonymity: Problems and Solutions</title><categories>cs.CR</categories><comments>13 pages, 6 figures, 1 table. Published by &quot;Lviv Polytechnica
  Publishing House&quot; in &quot;Information Systems and Networks&quot;
  (http://vlp.com.ua/taxonomy/term/3136)</comments><journal-ref>Information Systems and Networks, No. 673, pp. 3-15, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing methods of providing data anonymity preserve individual privacy,
but, the task of protecting respondent groups' information in publicly
available datasets remains open. Group anonymity lies in hiding (masking) data
patterns that cannot be revealed by analyzing individual records. We discuss
main corresponding problems, and provide methods for solving each one.
Keywords: group anonymity, wavelet transform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1132</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1132</id><created>2010-11-04</created><authors><author><keyname>Chertov</keyname><forenames>Oleg</forenames></author><author><keyname>Tavrov</keyname><forenames>Dan</forenames></author></authors><title>Providing Data Group Anonymity Using Concentration Differences</title><categories>cs.CR</categories><comments>10 pages, 2 figures, 2 tables. Published in &quot;Mathematical Machines
  and Systems&quot; (http://www.immsp.kiev.ua/publications/eng/2010_3/)</comments><journal-ref>Mathematical Machines and Systems, No. 3, pp. 34-44, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Public access to digital data can turn out to be a cause of undesirable
information disclosure. That's why it is vital to somehow protect the data
before publishing. There exist two main subclasses of such a task, namely,
providing individual and group anonymity. In the paper, we introduce a novel
method of protecting group data patterns. Also, we provide a comprehensive
illustrative example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1133</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1133</id><created>2010-11-04</created><authors><author><keyname>Chertov</keyname><forenames>Oleg</forenames></author><author><keyname>Tavrov</keyname><forenames>Dan</forenames></author></authors><title>Data Group Anonymity: General Approach</title><categories>cs.CR</categories><comments>8 pages, 2 figures, 1 table. Published in International Journal of
  Computer Science and Information Security
  (http://sites.google.com/site/ijcsis/vol-8-no-7-oct-2010)</comments><journal-ref>IJCSIS Vol.8 No.7, October 2010, pp. 1-8</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the recent time, the problem of protecting privacy in statistical data
before they are published has become a pressing one. Many reliable studies have
been accomplished, and loads of solutions have been proposed. Though, all these
researches take into consideration only the problem of protecting individual
privacy, i.e., privacy of a single person, household, etc. In our previous
articles, we addressed a completely new type of anonymity problems. We
introduced a novel kind of anonymity to achieve in statistical data and called
it group anonymity. In this paper, we aim at summarizing and generalizing our
previous results, propose a complete mathematical description of how to provide
group anonymity, and illustrate it with a couple of real-life examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1135</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1135</id><created>2010-11-04</created><updated>2011-05-03</updated><authors><author><keyname>Liu</keyname><forenames>Jian</forenames></author><author><keyname>Chiu</keyname><forenames>Dah Ming</forenames></author></authors><title>Reciprocating Preferences Stablize Matching: College Admissions
  Revisited</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In considering the college admissions problem, almost fifty years ago, Gale
and Shapley came up with a simple abstraction based on preferences of students
and colleges. They introduced the concept of stability and optimality; and
proposed the deferred acceptance (DA) algorithm that is proven to lead to a
stable and optimal solution. This algorithm is simple and computationally
efficient. Furthermore, in subsequent studies it is shown that the DA algorithm
is also strategy-proof, which means, when the algorithm is played out as a
mechanism for matching two sides (e.g. colleges and students), the parties
(colleges or students) have no incentives to act other than according to their
true preferences. Yet, in practical college admission systems, the DA algorithm
is often not adopted. Instead, an algorithm known as the Boston Mechanism (BM)
or its variants are widely adopted. In BM, colleges accept students without
deferral (considering other colleges' decisions), which is exactly the opposite
of Gale-Shapley's DA algorithm. To explain and rationalize this reality, we
introduce the notion of reciprocating preference to capture the influence of a
student's interest on a college's decision. This model is inspired by the
actual mechanism used to match students to universities in Hong Kong. The
notion of reciprocating preference defines a class of matching algorithms,
allowing different degrees of reciprocating preferences by the students and
colleges. DA and BM are but two extreme cases (with zero and a hundred percent
reciprocation) of this set. This model extends the notion of stability and
optimality as well. As in Gale-Shapley's original paper, we discuss how the
analogy can be carried over to the stable marriage problem, thus demonstrating
the model's general applicability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1157</identifier>
 <datestamp>2012-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1157</id><created>2010-11-04</created><authors><author><keyname>Bulteau</keyname><forenames>Laurent</forenames></author><author><keyname>Fertin</keyname><forenames>Guillaume</forenames></author><author><keyname>Rusu</keyname><forenames>Irena</forenames></author></authors><title>Sorting by Transpositions is Difficult</title><categories>cs.DS cs.CC</categories><doi>10.1137/110851390</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In comparative genomics, a transposition is an operation that exchanges two
consecutive sequences of genes in a genome. The transposition distance, that
is, the minimum number of transpositions needed to transform a genome into
another, is, according to numerous studies, a relevant evolutionary distance.
The problem of computing this distance when genomes are represented by
permutations, called the Sorting by Transpositions problem, has been introduced
by Bafna and Pevzner in 1995. It has naturally been the focus of a number of
studies, but the computational complexity of this problem has remained
undetermined for 15 years. In this paper, we answer this long-standing open
question by proving that the Sorting by Transpositions problem is NP-hard. As a
corollary of our result, we also prove that the following problem is NP-hard:
given a permutation pi, is it possible to sort pi using db(pi)/3 permutations,
where db(pi) is the number of breakpoints of pi?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1161</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1161</id><created>2010-11-04</created><updated>2013-06-18</updated><authors><author><keyname>Guha</keyname><forenames>Sudipto</forenames></author><author><keyname>Munagala</keyname><forenames>Kamesh</forenames></author><author><keyname>Pal</keyname><forenames>Martin</forenames></author></authors><title>Multiarmed Bandit Problems with Delayed Feedback</title><categories>cs.DS cs.LG</categories><comments>The results and presentation in this paper are subsumed by the
  article &quot;Approximation algorithms for Bayesian multi-armed bandit problems&quot;
  arXiv:1306.3525</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we initiate the study of optimization of bandit type problems
in scenarios where the feedback of a play is not immediately known. This arises
naturally in allocation problems which have been studied extensively in the
literature, albeit in the absence of delays in the feedback. We study this
problem in the Bayesian setting. In presence of delays, no solution with
provable guarantees is known to exist with sub-exponential running time.
  We show that bandit problems with delayed feedback that arise in allocation
settings can be forced to have significant structure, with a slight loss in
optimality. This structure gives us the ability to reason about the
relationship of single arm policies to the entangled optimum policy, and
eventually leads to a O(1) approximation for a significantly general class of
priors. The structural insights we develop are of key interest and carry over
to the setting where the feedback of an action is available instantaneously,
and we improve all previous results in this setting as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1168</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1168</id><created>2010-11-04</created><updated>2011-03-21</updated><authors><author><keyname>Svensson</keyname><forenames>Ola</forenames></author></authors><title>Santa Claus Schedules Jobs on Unrelated Machines</title><categories>cs.DS</categories><comments>22 pages, 1 figure; corrected typos and changed some notation</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the classic results in scheduling theory is the 2-approximation
algorithm by Lenstra, Shmoys, and Tardos for the problem of scheduling jobs to
minimize makespan on unrelated machines, i.e., job j requires time p_{ij} if
processed on machine i. More than two decades after its introduction it is
still the algorithm of choice even in the restricted model where processing
times are of the form p_{ij} in {p_j, \infty}. This problem, also known as the
restricted assignment problem, is NP-hard to approximate within a factor less
than 1.5 which is also the best known lower bound for the general version.
  Our main result is a polynomial time algorithm that estimates the optimal
makespan of the restricted assignment problem within a factor 33/17 + \epsilon
\approx 1.9412 + \epsilon, where \epsilon &gt; 0 is an arbitrarily small constant.
The result is obtained by upper bounding the integrality gap of a certain
strong linear program, known as configuration LP, that was previously
successfully used for the related Santa Claus problem. Similar to the strongest
analysis for that problem our proof is based on a local search algorithm that
will eventually find a schedule of the mentioned approximation guarantee, but
is not known to converge in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1172</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1172</id><created>2010-11-04</created><authors><author><keyname>Gutierrez</keyname><forenames>Julian</forenames></author></authors><title>Logics and Games for True Concurrency</title><categories>cs.LO</categories><comments>Technical report (LFCS, School of Informatics, University of
  Edinburgh)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the underlying mathematical properties of various partial order
models of concurrency based on transition systems, Petri nets, and event
structures, and show that the concurrent behaviour of these systems can be
captured in a uniform way by two simple and general dualities of local
behaviour. Such dualities are used to define new mu-calculi and logic games for
the analysis of concurrent systems with partial order semantics. Some results
of this work are: the definition of a number of mu-calculi which, in some
classes of systems, induce the same identifications as some of the best known
bisimulation equivalences for concurrency; and the definition of (infinite)
higher-order logic games for bisimulation and model-checking, where the players
of the games are given (local) monadic second-order power on the sets of
elements they are allowed to play. More specifically, we show that our games
are sound and complete, and therefore, determined; moreover, they are decidable
in the finite case and underpin novel decision procedures for bisimulation and
model-checking. Since these mu-calculi and logic games generalise well-known
fixpoint logics and game-theoretic decision procedures for concurrent systems
with interleaving semantics, the results herein give some of the groundwork for
the design of a logic-based, game-theoretic framework for studying, in a
uniform way, several concurrent systems regardless of whether they have an
interleaving or a partial order semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1173</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1173</id><created>2010-11-04</created><authors><author><keyname>Walder</keyname><forenames>Christian</forenames></author></authors><title>Rank k Cholesky Up/Down-dating on the GPU: gpucholmodV0.2</title><categories>cs.DC</categories><comments>7 pages</comments><acm-class>G.1.0</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this note we briefly describe our Cholesky modification algorithm for
streaming multiprocessor architectures. Our implementation is available in C++
with Matlab binding, using CUDA to utilise the graphics processing unit (GPU).
Limited speed ups are possible due to the bandwidth bound nature of the
problem. Furthermore, a complex dependency pattern must be obeyed, requiring
multiple kernels to be launched. Nonetheless, this makes for an interesting
problem, and our approach can reduce the computation time by a factor of around
7 for matrices of size 5000 by 5000 and k=16, in comparison with the LINPACK
suite running on a CPU of comparable vintage. Much larger problems can be
handled however due to the O(n) scaling in required GPU memory of our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1201</identifier>
 <datestamp>2014-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1201</id><created>2010-11-04</created><authors><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author><author><keyname>Freivalds</keyname><forenames>Rusins</forenames></author><author><keyname>Say</keyname><forenames>A. C. Cem</forenames></author><author><keyname>Agadzanyan</keyname><forenames>Ruben</forenames></author></authors><title>Quantum computation with devices whose contents are never read</title><categories>cs.CC cs.FL quant-ph</categories><comments>32 pages, a preliminary version of this work was presented in the 9th
  International Conference on Unconventional Computation (UC2010)</comments><journal-ref>Natural Computing, March 2012, Volume 11, Issue 1, pp 81-94</journal-ref><doi>10.1007/s11047-011-9270-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In classical computation, a &quot;write-only memory&quot; (WOM) is little more than an
oxymoron, and the addition of WOM to a (deterministic or probabilistic)
classical computer brings no advantage. We prove that quantum computers that
are augmented with WOM can solve problems that neither a classical computer
with WOM nor a quantum computer without WOM can solve, when all other resource
bounds are equal. We focus on realtime quantum finite automata, and examine the
increase in their power effected by the addition of WOMs with different access
modes and capacities. Some problems that are unsolvable by two-way
probabilistic Turing machines using sublogarithmic amounts of read/write memory
are shown to be solvable by these enhanced automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1202</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1202</id><created>2010-11-04</created><authors><author><keyname>Popa</keyname><forenames>Alexandru</forenames></author><author><keyname>Wong</keyname><forenames>Prudence W. H.</forenames></author><author><keyname>Yung</keyname><forenames>Fencol C. C.</forenames></author></authors><title>Hardness and Approximation of The Asynchronous Border Minimization
  Problem</title><categories>cs.DS</categories><acm-class>F.2; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a combinatorial problem arising from microarrays synthesis. The
synthesis is done by a light-directed chemical process. The objective is to
minimize unintended illumination that may contaminate the quality of
experiments. Unintended illumination is measured by a notion called border
length and the problem is called Border Minimization Problem (BMP). The
objective of the BMP is to place a set of probe sequences in the array and find
an embedding (deposition of nucleotides/residues to the array cells) such that
the sum of border length is minimized. A variant of the problem, called P-BMP,
is that the placement is given and the concern is simply to find the embedding.
Approximation algorithms have been previously proposed for the problem but it
is unknown whether the problem is NP-hard or not. In this paper, we give a
thorough study of different variations of BMP by giving NP-hardness proofs and
improved approximation algorithms. We show that P-BMP, 1D-BMP, and BMP are all
NP-hard. Contrast with the previous result that 1D-P-BMP is polynomial time
solvable, the interesting implications include (i) the array dimension (1D or
2D) differentiates the complexity of P-BMP; (ii) for 1D array, whether
placement is given differentiates the complexity of BMP; (iii) BMP is NP-hard
regardless of the dimension of the array. Another contribution of the paper is
improving the approximation for BMP from $O(n^{1/2} \log^2 n)$ to $O(n^{1/4}
\log^2 n)$, where $n$ is the total number of sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1212</identifier>
 <datestamp>2013-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1212</id><created>2010-11-04</created><updated>2013-01-06</updated><authors><author><keyname>Vilar</keyname><forenames>J. M. G.</forenames></author><author><keyname>Saiz</keyname><forenames>L.</forenames></author></authors><title>CplexA: a Mathematica package to study macromolecular-assembly control
  of gene expression</title><categories>q-bio.QM cond-mat.stat-mech cs.CE physics.bio-ph q-bio.MN</categories><comments>28 pages. Includes Mathematica, Matlab, and Python implementation
  tutorials. Software can be downloaded at http://cplexa.sourceforge.net/</comments><doi>10.1093/bioinformatics/btq328</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Summary: Macromolecular assembly vertebrates essential cellular processes,
such as gene regulation and signal transduction. A major challenge for
conventional computational methods to study these processes is tackling the
exponential increase of the number of configurational states with the number of
components. CplexA is a Mathematica package that uses functional programming to
efficiently compute probabilities and average properties over such
exponentially large number of states from the energetics of the interactions.
The package is particularly suited to study gene expression at complex
promoters controlled by multiple, local and distal, DNA binding sites for
transcription factors. Availability: CplexA is freely available together with
documentation at http://sourceforge.net/projects/cplexa/.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1225</identifier>
 <datestamp>2012-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1225</id><created>2010-11-04</created><updated>2012-09-05</updated><authors><author><keyname>Zhu</keyname><forenames>Fangfang</forenames></author><author><keyname>Shang</keyname><forenames>Xiaohu</forenames></author><author><keyname>Chen</keyname><forenames>Biao</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>On the Capacity of Multiple-Access-Z-Interference Channels</title><categories>cs.IT math.IT</categories><comments>31 pages, 4 figures, submitted to IEEE transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity of a network in which a multiple access channel (MAC) generates
interference to a single-user channel is studied. An achievable rate region
based on superposition coding and joint decoding is established for the
discrete case. If the interference is very strong, the capacity region is
obtained for both the discrete memoryless channel and the Gaussian channel. For
the strong interference case, the capacity region is established for the
discrete memoryless channel; for the Gaussian case, we attain a line segment on
the boundary of the capacity region. Moreover, the capacity region for the
Gaussian channel is identified for the case when one interference link being
strong, and the other being very strong. For a subclass of Gaussian channels
with mixed interference, a boundary point of the capacity region is determined.
Finally, for the Gaussian channel with weak interference, sum capacities are
obtained under various channel coefficient and power constraint conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1261</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1261</id><created>2010-11-04</created><updated>2011-04-19</updated><authors><author><keyname>Huang</keyname><forenames>Yen-Wei</forenames></author><author><keyname>Moulin</keyname><forenames>Pierre</forenames></author></authors><title>On the Saddle-point Solution and the Large-Coalition Asymptotics of
  Fingerprinting Games</title><categories>cs.IT cs.CR math.IT</categories><comments>submitted to IEEE Trans. on Information Forensics and Security</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a fingerprinting game in which the number of colluders and the
collusion channel are unknown. The encoder embeds fingerprints into a host
sequence and provides the decoder with the capability to trace back pirated
copies to the colluders.
  Fingerprinting capacity has recently been derived as the limit value of a
sequence of maximin games with mutual information as their payoff functions.
However, these games generally do not admit saddle-point solutions and are very
hard to solve numerically. Here under the so-called Boneh-Shaw marking
assumption, we reformulate the capacity as the value of a single two-person
zero-sum game, and show that it is achieved by a saddle-point solution.
  If the maximal coalition size is k and the fingerprinting alphabet is binary,
we show that capacity decays quadratically with k. Furthermore, we prove
rigorously that the asymptotic capacity is 1/(k^2 2ln2) and we confirm our
earlier conjecture that Tardos' choice of the arcsine distribution
asymptotically maximizes the mutual information payoff function while the
interleaving attack minimizes it. Along with the asymptotic behavior, numerical
solutions to the game for small k are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1263</identifier>
 <datestamp>2011-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1263</id><created>2010-11-04</created><updated>2011-04-22</updated><authors><author><keyname>Andoni</keyname><forenames>Alexandr</forenames></author><author><keyname>Krauthgamer</keyname><forenames>Robert</forenames></author><author><keyname>Onak</keyname><forenames>Krzysztof</forenames></author></authors><title>Streaming Algorithms from Precision Sampling</title><categories>cs.DS cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A technique introduced by Indyk and Woodruff [STOC 2005] has inspired several
recent advances in data-stream algorithms. We show that a number of these
results follow easily from the application of a single probabilistic method
called Precision Sampling. Using this method, we obtain simple data-stream
algorithms that maintain a randomized sketch of an input vector
$x=(x_1,...x_n)$, which is useful for the following applications. 1) Estimating
the $F_k$-moment of $x$, for $k&gt;2$. 2) Estimating the $\ell_p$-norm of $x$, for
$p\in[1,2]$, with small update time. 3) Estimating cascaded norms
$\ell_p(\ell_q)$ for all $p,q&gt;0$. 4) $\ell_1$ sampling, where the goal is to
produce an element $i$ with probability (approximately) $|x_i|/\|x\|_1$. It
extends to similarly defined $\ell_p$-sampling, for $p\in [1,2]$.
  For all these applications the algorithm is essentially the same: scale the
vector x entry-wise by a well-chosen random vector, and run a heavy-hitter
estimation algorithm on the resulting vector. Our sketch is a linear function
of x, thereby allowing general updates to the vector x.
  Precision Sampling itself addresses the problem of estimating a sum
$\sum_{i=1}^n a_i$ from weak estimates of each real $a_i\in[0,1]$. More
precisely, the estimator first chooses a desired precision $u_i\in(0,1]$ for
each $i\in[n]$, and then it receives an estimate of every $a_i$ within additive
$u_i$. Its goal is to provide a good approximation to $\sum a_i$ while keeping
a tab on the &quot;approximation cost&quot; $\sum_i (1/u_i)$. Here we refine previous
work [Andoni, Krauthgamer, and Onak, FOCS 2010] which shows that as long as
$\sum a_i=\Omega(1)$, a good multiplicative approximation can be achieved using
total precision of only $O(n\log n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1264</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1264</id><created>2010-11-04</created><updated>2011-06-01</updated><authors><author><keyname>Holenstein</keyname><forenames>Thomas</forenames></author><author><keyname>K&#xfc;nzler</keyname><forenames>Robin</forenames></author><author><keyname>Tessaro</keyname><forenames>Stefano</forenames></author></authors><title>Equivalence of the Random Oracle Model and the Ideal Cipher Model,
  Revisited</title><categories>cs.CR cs.CC cs.IT math.IT</categories><comments>Reduced number of rounds from 18 to 14 as this is sufficient for the
  proof, improved presentation of several lemmas and introduction</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the cryptographic problem of constructing an invertible random
permutation from a public random function (i.e., which can be accessed by the
adversary). This goal is formalized by the notion of indifferentiability of
Maurer et al. (TCC 2004). This is the natural extension to the public setting
of the well-studied problem of building random permutations from random
functions, which was first solved by Luby and Rackoff (Siam J. Comput., '88)
using the so-called Feistel construction.
  The most important implication of such a construction is the equivalence of
the random oracle model (Bellare and Rogaway, CCS '93) and the ideal cipher
model, which is typically used in the analysis of several constructions in
symmetric cryptography.
  Coron et al. (CRYPTO 2008) gave a rather involved proof that the six-round
Feistel construction with independent random round functions is
indifferentiable from an invertible random permutation. Also, it is known that
fewer than six rounds do not suffice for indifferentiability. The first
contribution (and starting point) of our paper is a concrete distinguishing
attack which shows that the indifferentiability proof of Coron et al. is not
correct. In addition, we provide supporting evidence that an
indifferentiability proof for the six-round Feistel construction may be very
hard to find.
  To overcome this gap, our main contribution is a proof that the Feistel
construction with eigthteen rounds is indifferentiable from an invertible
random permutation. The approach of our proof relies on assigning to each of
the rounds in the construction a unique and specific role needed in the proof.
This avoids many of the problems that appear in the six-round case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1273</identifier>
 <datestamp>2015-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1273</id><created>2010-11-04</created><authors><author><keyname>Castellana</keyname><forenames>Michele</forenames></author><author><keyname>Zdeborov&#xe1;</keyname><forenames>Lenka</forenames></author></authors><title>Adversarial Satisfiability Problem</title><categories>cs.CC cond-mat.dis-nn cond-mat.stat-mech</categories><journal-ref>Journal of Statistical Mechanics 2011(3), P03023 (2011)</journal-ref><doi>10.1088/1742-5468/2011/03/P03023</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the adversarial satisfiability problem, where the adversary can
choose whether variables are negated in clauses or not in order to make the
resulting formula unsatisfiable. This is one case of a general class of
adversarial optimization problems that often arise in practice and are
algorithmically much harder than the standard optimization problems. We use the
cavity method to compute large deviations of the entropy in the random
satisfiability problem with respect to the negation-configurations. We conclude
that in the thermodynamic limit the best strategy the adversary can adopt is
extremely close to simply balancing the number of times every variable is and
is not negated. We also conduct a numerical study of the problem, and find that
there are very strong pre-asymptotic effects that are due to the fact that for
small sizes exponential and factorial growth is hardly distinguishable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1279</identifier>
 <datestamp>2012-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1279</id><created>2010-11-04</created><updated>2012-05-14</updated><authors><author><keyname>Papadimitriou</keyname><forenames>Christos</forenames></author><author><keyname>Pierrakos</keyname><forenames>George</forenames></author></authors><title>Optimal Deterministic Auctions with Correlated Priors</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit the problem of designing the profit-maximizing single-item
auction, solved by Myerson in his seminal paper for the case in which bidder
valuations are independently distributed. We focus on general joint
distributions, seeking the optimal deterministic incentive compatible auction.
We give a geometric characterization of the optimal auction, resulting in a
duality theorem and an efficient algorithm for finding the optimal
deterministic auction in the two-bidder case and an NP-completeness result for
three or more bidders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1293</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1293</id><created>2010-11-04</created><authors><author><keyname>G&#xf3;mez-Garde&#xf1;es</keyname><forenames>J.</forenames></author><author><keyname>Romance</keyname><forenames>M.</forenames></author><author><keyname>Criado</keyname><forenames>R.</forenames></author><author><keyname>Vilone</keyname><forenames>D.</forenames></author><author><keyname>S&#xe1;nchez</keyname><forenames>A.</forenames></author></authors><title>Evolutionary Games defined at the Network Mesoscale: The Public Goods
  game</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>10 pages, 5 figures</comments><doi>10.1063/1.3535579</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The evolutionary dynamics of the Public Goods game addresses the emergence of
cooperation within groups of individuals. However, the Public Goods game on
large populations of interconnected individuals has been usually modeled
without any knowledge about their group structure. In this paper, by focusing
on collaboration networks, we show that it is possible to include the
mesoscopic information about the structure of the real groups by means of a
bipartite graph. We compare the results with the projected (coauthor) and the
original bipartite graphs and show that cooperation is enhanced by the
mesoscopic structure contained. We conclude by analyzing the influence of the
size of the groups in the evolutionary success of cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1295</identifier>
 <datestamp>2012-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1295</id><created>2010-11-04</created><updated>2012-06-07</updated><authors><author><keyname>Faigle</keyname><forenames>Ulrich</forenames></author><author><keyname>Sch&#xf6;nhuth</keyname><forenames>Alexander</forenames></author></authors><title>A Markovian Model for Joint Observations, Bell's Inequality and Hidden
  States</title><categories>cs.IT math.IT quant-ph</categories><comments>14 pages</comments><msc-class>60J99, 81P45, 81P68</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While the standard approach to quantum systems studies length preserving
linear transformations of wave functions, the Markov picture focuses on trace
preserving operators on the space of Hermitian (self-adjoint) matrices. The
Markov approach extends the standard one and provides a refined analysis of
measurements and quantum Markov chains. In particular, Bell's inequality
becomes structurally clear. It turns out that hidden state models are natural
in the Markov context. In particular, a violation of Bell's inequality is seen
to be compatible with the existence of hidden states. The Markov model moreover
clarifies the role of the &quot;negative probabilities&quot; in Feynman's analysis of the
EPR paradox.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1296</identifier>
 <datestamp>2011-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1296</id><created>2010-11-04</created><updated>2011-10-27</updated><authors><author><keyname>Gupta</keyname><forenames>Anupam</forenames></author><author><keyname>Hardt</keyname><forenames>Moritz</forenames></author><author><keyname>Roth</keyname><forenames>Aaron</forenames></author><author><keyname>Ullman</keyname><forenames>Jonathan</forenames></author></authors><title>Privately Releasing Conjunctions and the Statistical Query Barrier</title><categories>cs.DS cs.CR cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose we would like to know all answers to a set of statistical queries C
on a data set up to small error, but we can only access the data itself using
statistical queries. A trivial solution is to exhaustively ask all queries in
C. Can we do any better?
  + We show that the number of statistical queries necessary and sufficient for
this task is---up to polynomial factors---equal to the agnostic learning
complexity of C in Kearns' statistical query (SQ) model. This gives a complete
answer to the question when running time is not a concern.
  + We then show that the problem can be solved efficiently (allowing arbitrary
error on a small fraction of queries) whenever the answers to C can be
described by a submodular function. This includes many natural concept classes,
such as graph cuts and Boolean disjunctions and conjunctions.
  While interesting from a learning theoretic point of view, our main
applications are in privacy-preserving data analysis:
  Here, our second result leads to the first algorithm that efficiently
releases differentially private answers to of all Boolean conjunctions with 1%
average error. This presents significant progress on a key open problem in
privacy-preserving data analysis.
  Our first result on the other hand gives unconditional lower bounds on any
differentially private algorithm that admits a (potentially
non-privacy-preserving) implementation using only statistical queries. Not only
our algorithms, but also most known private algorithms can be implemented using
only statistical queries, and hence are constrained by these lower bounds. Our
result therefore isolates the complexity of agnostic learning in the SQ-model
as a new barrier in the design of differentially private algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1321</identifier>
 <datestamp>2010-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1321</id><created>2010-11-05</created><authors><author><keyname>Yang</keyname><forenames>Xiaoxiao</forenames></author></authors><title>Probabilistic Model Checking for Propositional Projection Temporal Logic</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Propositional Projection Temporal Logic (PPTL) is a useful formalism for
reasoning about period of time in hardware and software systems and can handle
both sequential and parallel compositions. In this paper, based on discrete
time Markov chains, we investigate the probabilistic model checking approach
for PPTL towards verifying arbitrary linear-time properties. We first define a
normal form graph, denoted by NFG_inf, to capture the infinite paths of PPTL
formulas. Then we present an algorithm to generate the NFG_inf. Since
discrete-time Markov chains are the deterministic probabilistic models, we
further give an algorithm to determinize and minimize the nondeterministic
NFG_inf following the Safra's construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1330</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1330</id><created>2010-11-05</created><authors><author><keyname>Duval</keyname><forenames>Dominique</forenames><affiliation>LJK</affiliation></author></authors><title>Deduction as Reduction</title><categories>cs.LO math.CT</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deduction systems and graph rewriting systems are compared within a common
categorical framework. This leads to an improved deduction method in
diagrammatic logics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1335</identifier>
 <datestamp>2010-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1335</id><created>2010-11-05</created><authors><author><keyname>David</keyname><forenames>Rene</forenames></author></authors><title>A short proof that adding some permutation rules to $\beta$ preserves
  $SN$</title><categories>cs.LO</categories><comments>Theoretical Computer Science, 2010</comments><doi>10.1016/j.tcs.2010.10.048</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I show that, if a term is $SN$ for $\beta$, it remains $SN$ when some
permutation rules are added.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1337</identifier>
 <datestamp>2010-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1337</id><created>2010-11-05</created><authors><author><keyname>Becker</keyname><forenames>Peter</forenames></author></authors><title>Optimal Binary Search Trees with Near Minimal Height</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose we have n keys, n access probabilities for the keys, and n+1 access
probabilities for the gaps between the keys. Let h_min(n) be the minimal height
of a binary search tree for n keys. We consider the problem to construct an
optimal binary search tree with near minimal height, i.e.\ with height h &lt;=
h_min(n) + Delta for some fixed Delta. It is shown, that for any fixed Delta
optimal binary search trees with near minimal height can be constructed in time
O(n^2). This is as fast as in the unrestricted case.
  So far, the best known algorithms for the construction of height-restricted
optimal binary search trees have running time O(L n^2), whereby L is the
maximal permitted height. Compared to these algorithms our algorithm is at
least faster by a factor of log n, because L is lower bounded by log n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1338</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1338</id><created>2010-11-05</created><authors><author><keyname>Dorn</keyname><forenames>Britta</forenames></author><author><keyname>Schlotter</keyname><forenames>Ildik&#xf3;</forenames></author></authors><title>Multivariate Analyis of Swap Bribery</title><categories>cs.CC cs.GT</categories><comments>20 pages. Conference version published at IPEC 2010</comments><doi>10.1007/978-3-642-17493-3_12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the computational complexity of a problem modeling bribery in the
context of voting systems. In the scenario of Swap Bribery, each voter assigns
a certain price for swapping the positions of two consecutive candidates in his
preference ranking. The question is whether it is possible, without exceeding a
given budget, to bribe the voters in a way that the preferred candidate wins in
the election. We initiate a parameterized and multivariate complexity analysis
of Swap Bribery, focusing on the case of k-approval. We investigate how
different cost functions affect the computational complexity of the problem. We
identify a special case of k-approval for which the problem can be solved in
polynomial time, whereas we prove NP-hardness for a slightly more general
scenario. We obtain fixed-parameter tractability as well as W[1]-hardness
results for certain natural parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1348</identifier>
 <datestamp>2010-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1348</id><created>2010-11-05</created><updated>2010-11-10</updated><authors><author><keyname>Wang</keyname><forenames>Kun-Yu</forenames></author><author><keyname>Chang</keyname><forenames>Tsung-Hui</forenames></author><author><keyname>Ma</keyname><forenames>Wing-Kin</forenames></author><author><keyname>So</keyname><forenames>Anthony Man-Cho</forenames></author><author><keyname>Chi</keyname><forenames>Chong-Yung</forenames></author></authors><title>Probabilistic Sinr Constrained Robust Transmit Beamforming: A
  Bernstein-Type Inequality Based Conservative Approach</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, robust transmit beamforming has drawn considerable attention
because it can provide guaranteed receiver performance in the presence of
channel state information (CSI) errors. Assuming complex Gaussian distributed
CSI errors, this paper investigates the robust beamforming design problem that
minimizes the transmission power subject to probabilistic
signal-to-interference-plus-noise ratio (SINR) constraints. The probabilistic
SINR constraints in general have no closed-form expression and are difficult to
handle. Based on a Bernstein-type inequality of complex Gaussian random
variables, we propose a conservative formulation to the robust beamforming
design problem. The semidefinite relaxation technique can be applied to
efficiently handle the proposed conservative formulation. Simulation results
show that, in comparison with the existing methods, the proposed method is more
power efficient and is able to support higher target SINR values for receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1350</identifier>
 <datestamp>2010-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1350</id><created>2010-11-05</created><authors><author><keyname>Buergisser</keyname><forenames>Peter</forenames></author><author><keyname>Ikenmeyer</keyname><forenames>Christian</forenames></author></authors><title>Geometric Complexity Theory and Tensor Rank</title><categories>cs.CC math.RT</categories><comments>Extended Abstract and Appendix</comments><msc-class>68Q17, 14L24, 20G05</msc-class><acm-class>F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mulmuley and Sohoni (GCT1 in SICOMP 2001, GCT2 in SICOMP 2008) proposed to
view the permanent versus determinant problem as a specific orbit closure
problem and to attack it by methods from geometric invariant and representation
theory. We adopt these ideas towards the goal of showing lower bounds on the
border rank of specific tensors, in particular for matrix multiplication. We
thus study specific orbit closure problems for the group $G = GL(W_1)\times
GL(W_2)\times GL(W_3)$ acting on the tensor product $W=W_1\otimes W_2\otimes
W_3$ of complex finite dimensional vector spaces. Let $G_s = SL(W_1)\times
SL(W_2)\times SL(W_3)$. A key idea from GCT2 is that the irreducible
$G_s$-representations occurring in the coordinate ring of the $G$-orbit closure
of a stable tensor $w\in W$ are exactly those having a nonzero invariant with
respect to the stabilizer group of $w$.
  However, we prove that by considering $G_s$-representations, as suggested in
GCT1-2, only trivial lower bounds on border rank can be shown. It is thus
necessary to study $G$-representations, which leads to geometric extension
problems that are beyond the scope of the subgroup restriction problems
emphasized in GCT1-2. We prove a very modest lower bound on the border rank of
matrix multiplication tensors using $G$-representations. This shows at least
that the barrier for $G_s$-representations can be overcome. To advance, we
suggest the coarser approach to replace the semigroup of representations of a
tensor by its moment polytope. We prove first results towards determining the
moment polytopes of matrix multiplication and unit tensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1352</identifier>
 <datestamp>2010-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1352</id><created>2010-11-05</created><authors><author><keyname>Duong</keyname><forenames>Trung Q.</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Zepernick</keyname><forenames>Hans-Jurgen</forenames></author><author><keyname>Lei</keyname><forenames>Xianfu</forenames></author></authors><title>Average Sum-Rate of Distributed Alamouti Space--Time Scheme in Two-Way
  Amplify-and-Forward Relay Networks</title><categories>cs.IT math.IT</categories><comments>Accepted at IEEE Global Communications Conference (GLOBECOM'10)
  Workshop on HeterWMN, Miami, USA, Dec. 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a distributed Alamouti space-time code (DASTC) for
two-way relay networks employing a single amplify-and-forward (AF) relay. We
first derive closed-form expressions for the approximated average sum-rate of
the proposed DASTC scheme. Our analysis is validated by a comparison against
the results of Monte-Carlo simulations. Numerical results verify the
effectiveness of our proposed scheme over the conventional DASTC with one-way
communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1368</identifier>
 <datestamp>2010-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1368</id><created>2010-11-05</created><authors><author><keyname>Krizhanovsky</keyname><forenames>A. A.</forenames></author></authors><title>Transformation of Wiktionary entry structure into tables and relations
  in a relational database schema</title><categories>cs.IR</categories><comments>10 pages, 7 figures, preprint</comments><msc-class>68W25, 90C35</msc-class><acm-class>I.7.2; I.7.3; I.7.5; H.3.1; H.3.3</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  This paper addresses the question of automatic data extraction from the
Wiktionary, which is a multilingual and multifunctional dictionary. Wiktionary
is a collaborative project working on the same principles as the Wikipedia. The
Wiktionary entry is a plain text from the text processing point of view.
Wiktionary guidelines prescribe the entry layout and rules, which should be
followed by editors of the dictionary. The presence of the structure of a
Wiktionary article and formatting rules allows transforming the Wiktionary
entry structure into tables and relations in a relational database schema,
which is a part of a machine-readable dictionary (MRD). The paper describes how
the flat text of the Wiktionary entry was extracted, converted, and stored in
the specially designed relational database. The MRD contains the definitions,
semantic relations, and translations extracted from the English and Russian
Wiktionaries. The parser software is released under the open source license
agreement (GPL), to facilitate its dissemination, modification and upgrades, to
draw researchers and programmers into parsing other Wiktionaries, not only
Russian and English.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1375</identifier>
 <datestamp>2011-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1375</id><created>2010-11-05</created><updated>2011-11-29</updated><authors><author><keyname>Ghosh</keyname><forenames>Arpita</forenames></author><author><keyname>Roth</keyname><forenames>Aaron</forenames></author></authors><title>Selling Privacy at Auction</title><categories>cs.GT cs.CR</categories><comments>Extended Abstract appeared in the proceedings of EC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We initiate the study of markets for private data, though the lens of
differential privacy. Although the purchase and sale of private data has
already begun on a large scale, a theory of privacy as a commodity is missing.
In this paper, we propose to build such a theory. Specifically, we consider a
setting in which a data analyst wishes to buy information from a population
from which he can estimate some statistic. The analyst wishes to obtain an
accurate estimate cheaply. On the other hand, the owners of the private data
experience some cost for their loss of privacy, and must be compensated for
this loss. Agents are selfish, and wish to maximize their profit, so our goal
is to design truthful mechanisms. Our main result is that such auctions can
naturally be viewed and optimally solved as variants of multi-unit procurement
auctions. Based on this result, we derive auctions for two natural settings
which are optimal up to small constant factors:
  1. In the setting in which the data analyst has a fixed accuracy goal, we
show that an application of the classic Vickrey auction achieves the analyst's
accuracy goal while minimizing his total payment.
  2. In the setting in which the data analyst has a fixed budget, we give a
mechanism which maximizes the accuracy of the resulting estimate while
guaranteeing that the resulting sum payments do not exceed the analysts budget.
  In both cases, our comparison class is the set of envy-free mechanisms, which
correspond to the natural class of fixed-price mechanisms in our setting.
  In both of these results, we ignore the privacy cost due to possible
correlations between an individuals private data and his valuation for privacy
itself. We then show that generically, no individually rational mechanism can
compensate individuals for the privacy loss incurred due to their reported
valuations for privacy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1377</identifier>
 <datestamp>2010-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1377</id><created>2010-11-05</created><authors><author><keyname>Guang</keyname><forenames>Xuan</forenames></author><author><keyname>Fu</keyname><forenames>Fang-Wei</forenames></author><author><keyname>Zhang</keyname><forenames>Zhen</forenames></author></authors><title>Construction of Network Error Correction Codes in Packet Networks</title><categories>cs.IT math.IT</categories><comments>14 pages, submitted in 4 Nov. 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, network error correction coding (NEC) has been studied extensively.
Several bounds in classical coding theory have been extended to network error
correction coding, especially the Singleton bound. In this paper, following the
research line using the extended global encoding kernels proposed in
\cite{zhang-correction}, the refined Singleton bound of NEC can be proved more
explicitly. Moreover, we give a constructive proof of the attainability of this
bound and indicate that the required field size for the existence of network
maximum distance separable (MDS) codes can become smaller further. By this
proof, an algorithm is proposed to construct general linear network error
correction codes including the linear network error correction MDS codes.
Finally, we study the error correction capability of random linear network
error correction coding. Motivated partly by the performance analysis of random
linear network coding \cite{Ho-etc-random}, we evaluate the different failure
probabilities defined in this paper in order to analyze the performance of
random linear network error correction coding. Several upper bounds on these
probabilities are obtained and they show that these probabilities will approach
to zero as the size of the base field goes to infinity. Using these upper
bounds, we slightly improve on the probability mass function of the minimum
distance of random linear network error correction codes in
\cite{zhang-random}, as well as the upper bound on the field size required for
the existence of linear network error correction codes with degradation at most
$d$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1403</identifier>
 <datestamp>2010-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1403</id><created>2010-11-05</created><authors><author><keyname>Mas&#xe1;kov&#xe1;</keyname><forenames>Z.</forenames></author><author><keyname>V&#xe1;vra</keyname><forenames>T.</forenames></author></authors><title>Arithmetics in numeration systems with negative quadratic base</title><categories>math.NT cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider positional numeration system with negative base $-\beta$, as
introduced by Ito and Sadahiro. In particular, we focus on arithmetical
properties of such systems when $\beta$ is a quadratic Pisot number. We study a
class of roots $\beta&gt;1$ of polynomials $x^2-mx-n$, $m\geq n\geq 1$, and show
that in this case the set ${\rm Fin}(-\beta)$ of finite $(-\beta)$-expansions
is closed under addition, although it is not closed under subtraction. A
particular example is $\beta=\tau=\frac12(1+\sqrt5)$, the golden ratio. For
such $\beta$, we determine the exact bound on the number of fractional digits
appearing in arithmetical operations. We also show that the set of
$(-\tau)$-integers coincides on the positive half-line with the set of
$(\tau^2)$-integers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1432</identifier>
 <datestamp>2010-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1432</id><created>2010-11-05</created><authors><author><keyname>Evers</keyname><forenames>Joep</forenames></author><author><keyname>Muntean</keyname><forenames>Adrian</forenames></author></authors><title>Modeling micro-macro pedestrian counterflow in heterogeneous domains</title><categories>math-ph cs.SI math.MP physics.soc-ph</categories><msc-class>35Q91, 35L65, 28A25, 91D30, 65L05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a micro-macro strategy able to describe the dynamics of crowds in
heterogeneous media. Herein we focus on the example of pedestrian counterflow.
The main working tools include the use of mass and porosity measures together
with their transport as well as suitable application of a version of
Radon-Nikodym Theorem formulated for finite measures. Finally, we illustrate
numerically our microscopic model and emphasize the effects produced by an
implicitly defined social velocity.
  Keywords: Crowd dynamics; mass measures; porosity measure; social networks
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1443</identifier>
 <datestamp>2011-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1443</id><created>2010-11-05</created><updated>2011-05-19</updated><authors><author><keyname>Childs</keyname><forenames>Andrew M.</forenames></author><author><keyname>Kothari</keyname><forenames>Robin</forenames></author></authors><title>Quantum query complexity of minor-closed graph properties</title><categories>quant-ph cs.CC cs.DS</categories><comments>v1: 25 pages, 2 figures. v2: 26 pages</comments><journal-ref>Proc. 28th Symposium on Theoretical Aspects of Computer Science
  (STACS 2011), Leibniz International Proceedings in Informatics 9, pp. 661-672</journal-ref><doi>10.4230/LIPIcs.STACS.2011.661</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the quantum query complexity of minor-closed graph properties, which
include such problems as determining whether an $n$-vertex graph is planar, is
a forest, or does not contain a path of a given length. We show that most
minor-closed properties---those that cannot be characterized by a finite set of
forbidden subgraphs---have quantum query complexity \Theta(n^{3/2}). To
establish this, we prove an adversary lower bound using a detailed analysis of
the structure of minor-closed properties with respect to forbidden topological
minors and forbidden subgraphs. On the other hand, we show that minor-closed
properties (and more generally, sparse graph properties) that can be
characterized by finitely many forbidden subgraphs can be solved strictly
faster, in o(n^{3/2}) queries. Our algorithms are a novel application of the
quantum walk search framework and give improved upper bounds for several
subgraph-finding problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1478</identifier>
 <datestamp>2012-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1478</id><created>2010-11-05</created><updated>2012-05-30</updated><authors><author><keyname>Ilic</keyname><forenames>Velimir M.</forenames></author><author><keyname>Mancev</keyname><forenames>Dejan I.</forenames></author><author><keyname>Todorovic</keyname><forenames>Branimir T.</forenames></author><author><keyname>Stankovic</keyname><forenames>Miomir S.</forenames></author></authors><title>Gradient Computation In Linear-Chain Conditional Random Fields Using The
  Entropy Message Passing Algorithm</title><categories>cs.AI</categories><comments>11 pages, 2 tables, 3 figures, 2 algorithms</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper proposes a numerically stable recursive algorithm for the exact
computation of the linear-chain conditional random field gradient. It operates
as a forward algorithm over the log-domain expectation semiring and has the
purpose of enhancing memory efficiency when applied to long observation
sequences. Unlike the traditional algorithm based on the forward-backward
recursions, the memory complexity of our algorithm does not depend on the
sequence length. The experiments on real data show that it can be useful for
the problems which deal with long sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1503</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1503</id><created>2010-11-05</created><authors><author><keyname>Soundararajan</keyname><forenames>Rajiv</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Quantization using Compressive Sensing</title><categories>cs.IT math.IT</categories><comments>10 pages, 1 figure, submitted to DCC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of compressing a real-valued sparse source using compressive
sensing techniques is studied. The rate distortion optimality of a coding
scheme in which compressively sensed signals are quantized and then
reconstructed is established when the reconstruction is also required to be
sparse. The result holds in general when the distortion constraint is on the
expected $p$-norm of error between the source and the reconstruction. A new
restricted isometry like property is introduced for this purpose and the
existence of matrices that satisfy this property is shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1508</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1508</id><created>2010-11-05</created><authors><author><keyname>Crowell</keyname><forenames>Sean</forenames></author><author><keyname>Lakshmivarahan</keyname><forenames>S.</forenames></author></authors><title>Forecast Bias Correction: A Second Order Method</title><categories>cs.CE math.DS math.OC</categories><comments>27 Pages, 3 figures, 8 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The difference between a model forecast and actual observations is called
forecast bias. This bias is due to either incomplete model assumptions and/or
poorly known parameter values and initial/boundary conditions. In this paper we
discuss a method for estimating corrections to parameters and initial
conditions that would account for the forecast bias. A set of simple
experiments with the logistic ordinary differential equation is performed using
an iterative version of a first order version of our method to compare with the
second order version of the method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1518</identifier>
 <datestamp>2010-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1518</id><created>2010-11-05</created><updated>2010-12-03</updated><authors><author><keyname>Hsu</keyname><forenames>Daniel</forenames></author><author><keyname>Kakade</keyname><forenames>Sham M.</forenames></author><author><keyname>Zhang</keyname><forenames>Tong</forenames></author></authors><title>Robust Matrix Decomposition with Outliers</title><categories>stat.ML cs.LG math.NA</categories><comments>Corrected comparisons to previous work of Candes et al (2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose a given observation matrix can be decomposed as the sum of a low-rank
matrix and a sparse matrix (outliers), and the goal is to recover these
individual components from the observed sum. Such additive decompositions have
applications in a variety of numerical problems including system
identification, latent variable graphical modeling, and principal components
analysis. We study conditions under which recovering such a decomposition is
possible via a combination of $\ell_1$ norm and trace norm minimization. We are
specifically interested in the question of how many outliers are allowed so
that convex programming can still achieve accurate recovery, and we obtain
stronger recovery guarantees than previous studies. Moreover, we do not assume
that the spatial pattern of outliers is random, which stands in contrast to
related analyses under such assumptions via matrix completion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1519</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1519</id><created>2010-11-05</created><authors><author><keyname>Mahendran</keyname><forenames>Nagalingam</forenames></author><author><keyname>Gurusamy</keyname><forenames>G.</forenames></author></authors><title>Fuzzy Controller for Matrix Converter System to Improve its Quality of
  Output</title><categories>cs.SY</categories><comments>11 pages</comments><doi>10.5121/ijaia.2010.1402</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, Fuzzy Logic controller is developed for ac/ac Matrix
Converter. Furthermore, Total Harmonic Distortion is reduced significantly.
Space Vector Algorithm is a method to improve power quality of the converter
output. But its quality is limited to 86.7%.We are introduced a Cross coupled
DQ axis controller to improve power quality. The Matrix Converter is an
attractive topology for High voltage transformation ratio. A Matlab / Simulink
simulation analysis of the Matrix Converter system is provided. The design and
implementation of fuzzy controlled Matrix Converter is described. This AC-AC
system is proposed as an effective replacement for the conventional AC-DC-AC
system which employs a two-step power conversion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1529</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1529</id><created>2010-11-05</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>A Survey on Wireless Sensor Network Security</title><categories>cs.CR cs.NI</categories><comments>24 pages, 4 figures, 2 tables</comments><journal-ref>International Journal of Vommunication Networks and Information
  Security (IJCNIS), Vol 1, No 2, pp. 55 - 78, August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor networks (WSNs) have recently attracted a lot of interest in
the research community due their wide range of applications. Due to distributed
nature of these networks and their deployment in remote areas, these networks
are vulnerable to numerous security threats that can adversely affect their
proper functioning. This problem is more critical if the network is deployed
for some mission-critical applications such as in a tactical battlefield.
Random failure of nodes is also very likely in real-life deployment scenarios.
Due to resource constraints in the sensor nodes, traditional security
mechanisms with large overhead of computation and communication are infeasible
in WSNs. Security in sensor networks is, therefore, a particularly challenging
task. This paper discusses the current state of the art in security mechanisms
for WSNs. Various types of attacks are discussed and their countermeasures
presented. A brief discussion on the future direction of research in WSN
security is also included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1531</identifier>
 <datestamp>2010-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1531</id><created>2010-11-05</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>An Agent-Based Intrusion Detection System for Local Area Networks</title><categories>cs.CR cs.NI</categories><comments>13 pages, 5 figures, 2 tables</comments><journal-ref>International Journal of Communication Networks and Information
  Security (IJCNIS), Vol 2, No 2, August 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since it is impossible to predict and identify all the vulnerabilities of a
network beforehand, and penetration into a system by malicious intruders cannot
always be prevented, intrusion detection systems (IDSs) are essential entities
to ensure the security of a networked system. To be effective in carrying out
their functions, the IDSs need to be accurate, adaptive, and extensible. Given
these stringent requirements and the high level of vulnerabilities of the
current days' networks, the design of an IDS has become a very challenging
task. Although, an extensive research has been done on intrusion detection in a
distributed environment, distributed IDSs suffer from a number of drawbacks
e.g., high rates of false positives, low detection efficiency etc. In this
paper, the design of a distributed IDS is proposed that consists of a group of
autonomous and cooperating agents. In addition to its ability to detect
attacks, the system is capable of identifying and isolating compromised nodes
in the network thereby introducing fault-tolerance in its operations. The
experiments conducted on the system have shown that it has a high detection
efficiency and low false positives compared to some of the currently existing
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1533</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1533</id><created>2010-11-05</created><authors><author><keyname>Milojevi&#x107;</keyname><forenames>Sta&#x161;a</forenames></author></authors><title>Power-law Distributions in Information Science - Making the Case for
  Logarithmic Binning</title><categories>physics.soc-ph cs.DL stat.ME</categories><comments>Accepted for publication in JASIST</comments><doi>10.1002/asi.21426</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We suggest partial logarithmic binning as the method of choice for uncovering
the nature of many distributions encountered in information science (IS).
Logarithmic binning retrieves information and trends &quot;not visible&quot; in noisy
power-law tails. We also argue that obtaining the exponent from logarithmically
binned data using a simple least square method is in some cases warranted in
addition to methods such as the maximum likelihood. We also show why often used
cumulative distributions can make it difficult to distinguish noise from
genuine features, and make it difficult to obtain an accurate power-law
exponent of the underlying distribution. The treatment is non-technical, aimed
at IS researchers with little or no background in mathematics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1539</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1539</id><created>2010-11-06</created><updated>2012-09-27</updated><authors><author><keyname>Sakzad</keyname><forenames>Amin</forenames></author><author><keyname>Sadeghi</keyname><forenames>Mohammad-Reza</forenames></author><author><keyname>Panario</keyname><forenames>Daniel</forenames></author></authors><title>Cycle structure of permutation functions over finite fields and their
  applications</title><categories>cs.IT math.IT</categories><comments>Accepted to appear in AMC</comments><journal-ref>Advances in Mathematics of Communications, vol. 6, pp. 347-361,
  2012</journal-ref><doi>10.3934/amc.2012.6.347</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we establish some new interleavers based on permutation
functions. The inverses of these interleavers are known over a finite field
$\mathbb{F}_q$. For the first time M\&quot;{o}bius and R\'edei functions are used to
give new deterministic interleavers. Furthermore we employ Skolem sequences in
order to find new interleavers with known cycle structure. In the case of
R\'edei functions an exact formula for the inverse function is derived. The
cycle structure of R\'edei functions is also investigated. The self-inverse and
non-self-inverse versions of these permutation functions can be used to
construct new interleavers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1547</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1547</id><created>2010-11-06</created><authors><author><keyname>Zhao</keyname><forenames>Jichang</forenames></author><author><keyname>Wu</keyname><forenames>Junjie</forenames></author><author><keyname>Liu</keyname><forenames>Guannan</forenames></author><author><keyname>Xu</keyname><forenames>Ke</forenames></author><author><keyname>Chen</keyname><forenames>Guoqing</forenames></author></authors><title>Being Rational or Aggressive? A Revisit to Dunbar's Number in Online
  Social Networks</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent years have witnessed the explosion of online social networks (OSNs).
They provide powerful IT-innovations for online social activities such as
organizing contacts, publishing contents, and sharing interests between friends
who may never meet before. As more and more people become the active users of
online social networks, one may ponder questions such as: (1) Do OSNs indeed
improve our sociability? (2) To what extent can we expand our offline social
spectrum in OSNs? (3) Can we identify some interesting user behaviors in OSNs?
Our work in this paper just aims to answer these interesting questions. To this
end, we pay a revisit to the well-known Dunbar's number in online social
networks. Our main research contributions are as follows. First, to our best
knowledge, our work is the first one that systematically validates the
existence of the online Dunbar's number in the range of [200,300]. To reach
this, we combine using local-structure analysis and user-interaction analysis
for extensive real-world OSNs. Second, we divide OSNs users into two
categories: rational and aggressive, and find that rational users intend to
develop close and reciprocated relationships, whereas aggressive users have no
consistent behaviors. Third, we build a simple model to capture the constraints
of time and cognition that affect the evolution of online social networks.
Finally, we show the potential use of our findings in viral marketing and
privacy management in online social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1549</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1549</id><created>2010-11-06</created><authors><author><keyname>Zhang</keyname><forenames>Qingyue</forenames></author></authors><title>Multivariate vector sampling expansions in shift invariant subspaces</title><categories>cs.IT math.IT</categories><comments>11 pages</comments><msc-class>42C15</msc-class><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study multivariate vector sampling expansions on general
finitely generated shift-invariant subspaces. Necessary and sufficient
conditions for a multivariate vector sampling theorem to hold are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1551</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1551</id><created>2010-11-06</created><authors><author><keyname>Pelliccione</keyname><forenames>Patrizio</forenames></author><author><keyname>Muccini</keyname><forenames>Henry</forenames></author><author><keyname>Guelfi</keyname><forenames>Nicolas</forenames></author><author><keyname>Romanovsky</keyname><forenames>Alexander</forenames></author></authors><title>An Introduction to Software Engineering and Fault Tolerance</title><categories>cs.SE</categories><journal-ref>Introduction chapter to the &quot;SOFTWARE ENGINEERING OF FAULT
  TOLERANT SYSTEMS&quot; book, Series on Software Engineering and Knowledge Eng.,
  2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This book consists of the chapters describing novel approaches to integrating
fault tolerance into software development process. They cover a wide range of
topics focusing on fault tolerance during the different phases of the software
development, software engineering techniques for verification and validation of
fault tolerance means, and languages for supporting fault tolerance
specification and implementation. Accordingly, the book is structured into the
following three parts: Part A: Fault tolerance engineering: from requirements
to code; Part B: Verification and validation of fault tolerant systems; Part C:
Languages and Tools for engineering fault tolerant systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1560</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1560</id><created>2010-11-06</created><authors><author><keyname>Ines</keyname><forenames>Ines Di Loreto</forenames></author><author><keyname>Goua&#xef;ch</keyname><forenames>Abdelkader</forenames></author></authors><title>Mixed Reality Serious Games: The Therapist Perspective</title><categories>cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of this paper is to present a Mixed Reality System (MRS) for
rehabilitation of the upper limb after stroke. The system answers the following
challenges: (i) increase motivation of patients by making the training a
personalized experience; (ii) take into account patients' impairments by
offering intuitive and easy to use interaction modalities; (iii) make it
possible to therapists to track patient's activities and to evaluate/track
their progress; (iv) open opportunities for telemedicine and tele
rehabilitation; (v) and provide an economically acceptable system by reducing
both equipment and management costs. In order to test this system a pilot study
has been conducted in conjunction with a French hospital in order to understand
the potential and benefits of mixed reality. The pilot involved 3 therapists
who 'played the role' of patients. Three sessions, one using conventional
rehabilitation, another using an ad hoc developed game on a PC, and another
using a mixed reality version of the same game were held. Results have shown
the MRS and the PC game to be accepted more than physical rehabilitation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1566</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1566</id><created>2010-11-06</created><updated>2011-09-30</updated><authors><author><keyname>Anandkumar</keyname><forenames>Amod J. G.</forenames></author><author><keyname>Anandkumar</keyname><forenames>Animashree</forenames></author><author><keyname>Lambotharan</keyname><forenames>Sangarapillai</forenames></author><author><keyname>Chambers</keyname><forenames>Jonathon A.</forenames></author></authors><title>Robust Rate-Maximization Game Under Bounded Channel Uncertainty</title><categories>cs.IT math.IT</categories><comments>accepted for publication in the IEEE Transactions on Vehicular
  Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of decentralized power allocation for competitive
rate-maximization in a frequency-selective Gaussian interference channel under
bounded channel uncertainty. We formulate a distribution-free robust framework
for the rate-maximization game. We present the robust-optimization equilibrium
for this game and derive sufficient conditions for its existence and
uniqueness. We show that an iterative waterfilling algorithm converges to this
equilibrium under certain sufficient conditions. We analyse the social
properties of the equilibrium under varying channel uncertainty bounds for the
two-user case. We also observe an interesting phenomenon that the equilibrium
moves towards a frequency-division multiple access solution for any set of
channel coefficients under increasing channel uncertainty bounds. We further
prove that increasing channel uncertainty can lead to a more efficient
equilibrium, and hence, a better sum rate in certain two-user communication
systems. Finally, we confirm, through simulations, this improvement in
equilibrium efficiency is also observed in systems with a higher number of
users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1576</identifier>
 <datestamp>2011-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1576</id><created>2010-11-06</created><updated>2011-06-18</updated><authors><author><keyname>Karampatziakis</keyname><forenames>Nikos</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author></authors><title>Online Importance Weight Aware Updates</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An importance weight quantifies the relative importance of one example over
another, coming up in applications of boosting, asymmetric classification
costs, reductions, and active learning. The standard approach for dealing with
importance weights in gradient descent is via multiplication of the gradient.
We first demonstrate the problems of this approach when importance weights are
large, and argue in favor of more sophisticated ways for dealing with them. We
then develop an approach which enjoys an invariance property: that updating
twice with importance weight $h$ is equivalent to updating once with importance
weight $2h$. For many important losses this has a closed form update which
satisfies standard regret guarantees when all examples have $h=1$. We also
briefly discuss two other reasonable approaches for handling large importance
weights. Empirically, these approaches yield substantially superior prediction
with similar computational performance while reducing the sensitivity of the
algorithm to the exact setting of the learning rate. We apply these to online
active learning yielding an extraordinarily fast active learning algorithm that
works even in the presence of adversarial noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1578</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1578</id><created>2010-11-06</created><authors><author><keyname>Carta-Gerardino</keyname><forenames>Edoardo</forenames></author></authors><title>The $z$-Transform and Automata-Recognizable Systems of Nonhomogeneous
  Linear Recurrence Equations over Semirings</title><categories>cs.SC cs.FL</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A nonhomogeneous system of linear recurrence equations can be recognized by
an automaton $\mathcal{A}$ over a one-letter alphabet $A = \{z\}$. Conversely,
the automaton $\mathcal{A}$ generates precisely this nonhomogeneous system of
linear recurrence equations. We present the solutions of these systems and
apply the $z$-transform to these solutions to obtain their series
representation. Finally, we show some results that simplify the series
representation of the $z$-transform of these solutions. We consider single
systems as well as the composition of two systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1581</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1581</id><created>2010-11-06</created><updated>2011-01-03</updated><authors><author><keyname>Travers</keyname><forenames>Nicholas F.</forenames></author><author><keyname>Crutchfield</keyname><forenames>James P.</forenames></author></authors><title>Asymptotic Synchronization for Finite-State Sources</title><categories>nlin.CD cs.IT math.DS math.IT stat.ML</categories><comments>13 pages, 4 figures:
  http://cse.ucdavis.edu/~cmg/compmech/pubs/asfs.htm; updates and corrections
  added</comments><doi>10.1007/s10955-011-0349-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend a recent synchronization analysis of exact finite-state sources to
nonexact sources for which synchronization occurs only asymptotically. Although
the proof methods are quite different, the primary results remain the same. We
find that an observer's average uncertainty in the source state vanishes
exponentially fast and, as a consequence, an observer's average uncertainty in
predicting future output converges exponentially fast to the source entropy
rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1584</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1584</id><created>2010-11-06</created><authors><author><keyname>Javaid</keyname><forenames>Nadeem</forenames></author><author><keyname>Bibi</keyname><forenames>Ayesha</forenames></author><author><keyname>Djouani</keyname><forenames>Karim</forenames></author></authors><title>Interference and Bandwidth Adjusted (ETX) in Wireless Multi-hop Networks</title><categories>cs.NI</categories><journal-ref>IEEE Globecom, SaCoNAS: Towards SmArt COmmunications and Network
  technologies applied on Autonomous Systems Workshop, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new quality link metric, interference and
bandwidth adjusted ETX (IBETX) for wireless multi-hop networks. As MAC layer
affects the link performance and consequently the route quality, the metric
therefore, tackles the issue by achieving twofold MAC-awareness. Firstly,
interference is calculated using cross-layered approach by sending probes to
MAC layer. Secondly, the nominal bit rate information is provided to all nodes
in the same contention domain by considering the bandwidth sharing mechanism of
802.11. Like ETX, our metric also calculates link delivery ratios that directly
affect throughput and selects those routes that bypass dense regions in the
network. Simulation results by NS-2 show that IBETX gives 19% higher throughput
than ETX and 10% higher than Expected Throughput (ETP). Our metric also
succeeds to reduce average end-to-end delay up to 16% less than Expected Link
Performance (ELP) and 24% less than ETX.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1589</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1589</id><created>2010-11-06</created><updated>2011-03-09</updated><authors><author><keyname>Jose</keyname><forenames>Manu</forenames></author><author><keyname>Majumdar</keyname><forenames>Rupak</forenames></author></authors><title>Cause Clue Clauses: Error Localization using Maximum Satisfiability</title><categories>cs.PL cs.SE</categories><comments>The pre-alpha version of the tool can be downloaded from
  http://bugassist.mpi-sws.org</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Much effort is spent everyday by programmers in trying to reduce long,
failing execution traces to the cause of the error. We present a new algorithm
for error cause localization based on a reduction to the maximal satisfiability
problem (MAX-SAT), which asks what is the maximum number of clauses of a
Boolean formula that can be simultaneously satisfied by an assignment. At an
intuitive level, our algorithm takes as input a program and a failing test, and
comprises the following three steps. First, using symbolic execution, we encode
a trace of a program as a Boolean trace formula which is satisfiable iff the
trace is feasible. Second, for a failing program execution (e.g., one that
violates an assertion or a post-condition), we construct an unsatisfiable
formula by taking the trace formula and additionally asserting that the input
is the failing test and that the assertion condition does hold at the end.
Third, using MAX-SAT, we find a maximal set of clauses in this formula that can
be satisfied together, and output the complement set as a potential cause of
the error. We have implemented our algorithm in a tool called bug-assist for C
programs. We demonstrate the surprising effectiveness of the tool on a set of
benchmark examples with injected faults, and show that in most cases,
bug-assist can quickly and precisely isolate the exact few lines of code whose
change eliminates the error. We also demonstrate how our algorithm can be
modified to automatically suggest fixes for common classes of errors such as
off-by-one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1595</identifier>
 <datestamp>2014-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1595</id><created>2010-11-06</created><updated>2011-07-17</updated><authors><author><keyname>Tropp</keyname><forenames>Joel A.</forenames></author></authors><title>Improved analysis of the subsampled randomized Hadamard transform</title><categories>math.NA cs.DS math.PR</categories><comments>8 pages. To appear, Advances in Adaptive Data Analysis, special issue
  &quot;Sparse Representation of Data and Images.&quot; v2--v4 include minor corrections</comments><msc-class>15B52</msc-class><journal-ref>Adv. Adapt. Data Anal., Vol. 3, num. 1-2, special issue, &quot;Sparse
  Representation of Data and Images,&quot; pp. 115-126, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an improved analysis of a structured dimension-reduction
map called the subsampled randomized Hadamard transform. This argument
demonstrates that the map preserves the Euclidean geometry of an entire
subspace of vectors. The new proof is much simpler than previous approaches,
and it offers---for the first time---optimal constants in the estimate on the
number of dimensions required for the embedding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1599</identifier>
 <datestamp>2010-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1599</id><created>2010-11-06</created><updated>2010-11-09</updated><authors><author><keyname>Abe</keyname><forenames>Hiroshi</forenames></author></authors><title>A Stable Explicit Scheme for Solving Non-Homogeneous Constant
  Coefficients Equation using Green's Function</title><categories>cs.NA</categories><comments>This paper has been withdrawn by the author. 15 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A numerical explicit method to evaluates transient solutions of linear
partial differential non-homogeneous equation with constant coefficients is
proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1602</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1602</id><created>2010-11-06</created><authors><author><keyname>Baldoni</keyname><forenames>Velleda</forenames></author><author><keyname>Berline</keyname><forenames>Nicole</forenames></author><author><keyname>De Loera</keyname><forenames>Jes&#xfa;s A.</forenames></author><author><keyname>K&#xf6;ppe</keyname><forenames>Matthias</forenames></author><author><keyname>Vergne</keyname><forenames>Mich&#xe8;le</forenames></author></authors><title>Computation of the highest coefficients of weighted Ehrhart
  quasi-polynomials of rational polyhedra</title><categories>math.CO cs.CG</categories><comments>34 pages, 2 figures</comments><msc-class>05A15 (Primary), 52C07, 68R05, 68U05, 52B20 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article concerns the computational problem of counting the lattice
points inside convex polytopes, when each point must be counted with a weight
associated to it. We describe an efficient algorithm for computing the highest
degree coefficients of the weighted Ehrhart quasi-polynomial for a rational
simple polytope in varying dimension, when the weights of the lattice points
are given by a polynomial function h. Our technique is based on a refinement of
an algorithm of A. Barvinok [Computing the Ehrhart quasi-polynomial of a
rational simplex, Math. Comp. 75 (2006), pp. 1449--1466] in the unweighted case
(i.e., h = 1). In contrast to Barvinok's method, our method is local, obtains
an approximation on the level of generating functions, handles the general
weighted case, and provides the coefficients in closed form as step polynomials
of the dilation. To demonstrate the practicality of our approach we report on
computational experiments which show even our simple implementation can compete
with state of the art software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1607</identifier>
 <datestamp>2012-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1607</id><created>2010-11-06</created><updated>2012-08-11</updated><authors><author><keyname>Asnani</keyname><forenames>Himanshu</forenames></author><author><keyname>Permuter</keyname><forenames>Haim</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>To Feed or Not to Feed Back</title><categories>cs.IT math.IT</categories><comments>Revised, a new algorithm to compute capacity, BAA-Action, added in
  Section XI, 26 pages, 12 figures, submitted to IEEE Transactions on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the communication over Finite State Channels (FSCs), where the
encoder and the decoder can control the availability or the quality of the
noise-free feedback. Specifically, the instantaneous feedback is a function of
an action taken by the encoder, an action taken by the decoder, and the channel
output. Encoder and decoder actions take values in finite alphabets, and may be
subject to average cost constraints. We prove capacity results for such a
setting by constructing a sequence of achievable rates, using a simple scheme
based on 'code tree' generation, that generates channel input symbols along
with encoder and decoder actions. We prove that the limit of this sequence
exists. For a given block length and probability of error, we give an upper
bound on the maximum achievable rate. Our upper and lower bounds coincide and
hence yield the capacity for the case where the probability of initial state is
positive for all states. Further, for stationary indecomposable channels
without intersymbol interference (ISI), the capacity is given as the limit of
normalized directed information between the input and output sequence,
maximized over an appropriate set of causally conditioned distributions. As an
important special case, we consider the framework of 'to feed or not to feed
back' where either the encoder or the decoder takes binary actions, which
determine whether current channel output will be fed back to the encoder, with
a constraint on the fraction of channel outputs that are fed back. As another
special case of our framework, we characterize the capacity of 'coding on the
backward link' in FSCs, i.e. when the decoder sends limited-rate instantaneous
coded noise-free feedback on the backward link. Finally, we propose an
extension of the Blahut-Arimoto algorithm for evaluating the capacity when
actions can be cost constrained, and demonstrate its application on a few
examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1625</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1625</id><created>2010-11-07</created><updated>2010-12-22</updated><authors><author><keyname>Basaldella</keyname><forenames>Michele</forenames><affiliation>RIMS, Kyoto University, Japan</affiliation></author><author><keyname>Terui</keyname><forenames>Kazushige</forenames><affiliation>RIMS, Kyoto University, Japan</affiliation></author></authors><title>On the meaning of logical completeness</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.3.2, F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 4 (December
  22, 2010) lmcs:1066</journal-ref><doi>10.2168/LMCS-6(4:11)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Goedel's completeness theorem is concerned with provability, while Girard's
theorem in ludics (as well as full completeness theorems in game semantics) are
concerned with proofs. Our purpose is to look for a connection between these
two disciplines. Following a previous work [3], we consider an extension of the
original ludics with contraction and universal nondeterminism, which play dual
roles, in order to capture a polarized fragment of linear logic and thus a
constructive variant of classical propositional logic. We then prove a
completeness theorem for proofs in this extended setting: for any behaviour
(formula) A and any design (proof attempt) P, either P is a proof of A or there
is a model M of the orthogonal of A which defeats P. Compared with proofs of
full completeness in game semantics, ours exhibits a striking similarity with
proofs of Goedel's completeness, in that it explicitly constructs a
countermodel essentially using Koenig's lemma, proceeds by induction on
formulas, and implies an analogue of Loewenheim-Skolem theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1634</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1634</id><created>2010-11-07</created><authors><author><keyname>Li</keyname><forenames>Yinglin</forenames></author><author><keyname>Xia</keyname><forenames>Bican</forenames></author><author><keyname>Zhang</keyname><forenames>Zhihai</forenames></author></authors><title>Zero Decomposition with Multiplicity of Zero-Dimensional Polynomial
  Systems</title><categories>cs.SC cs.LO math.AG</categories><comments>Key words: polynomial system, zero decomposition, multiplicity, Wu's
  method</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a zero decomposition theorem and an algorithm based on Wu's
method, which computes a zero decomposition with multiplicity for a given
zero-dimensional polynomial system. If the system satisfies some condition, the
zero decomposition is of triangular form.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1638</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1638</id><created>2010-11-07</created><authors><author><keyname>Desnos</keyname><forenames>Anthony</forenames></author><author><keyname>Erra</keyname><forenames>Robert</forenames></author><author><keyname>Filiol</keyname><forenames>Eric</forenames></author></authors><title>Processor-Dependent Malware... and codes</title><categories>cs.CR</categories><comments>13 pages - Extended version of the paper presented at the iAWACS 2009
  conference</comments><acm-class>C.1.0; C.5.3; D.4.6; K.6.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Malware usually target computers according to their operating system. Thus we
have Windows malwares, Linux malwares and so on ... In this paper, we consider
a different approach and show on a technical basis how easily malware can
recognize and target systems selectively, according to the onboard processor
chip. This technology is very easy to build since it does not rely on deep
analysis of chip logical gates architecture. Floating Point Arithmetic (FPA)
looks promising to define a set of tests to identify the processor or, more
precisely, a subset of possible processors. We give results for different
families of processors: AMD, Intel (Dual Core, Atom), Sparc, Digital Alpha,
Cell, Atom ... As a conclusion, we propose two {\it open problems} that are
new, to the authors' knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1660</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1660</id><created>2010-11-07</created><authors><author><keyname>Sagha</keyname><forenames>Hesam</forenames></author><author><keyname>Shouraki</keyname><forenames>Saeed Bagheri</forenames></author><author><keyname>Khasteh</keyname><forenames>Hosein</forenames></author><author><keyname>Kiaei</keyname><forenames>Ali Akbar</forenames></author></authors><title>Reinforcement Learning Based on Active Learning Method</title><categories>cs.AI</categories><comments>5 pages, 11 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new reinforcement learning approach is proposed which is
based on a powerful concept named Active Learning Method (ALM) in modeling. ALM
expresses any multi-input-single-output system as a fuzzy combination of some
single-input-singleoutput systems. The proposed method is an actor-critic
system similar to Generalized Approximate Reasoning based Intelligent Control
(GARIC) structure to adapt the ALM by delayed reinforcement signals. Our system
uses Temporal Difference (TD) learning to model the behavior of useful actions
of a control system. The goodness of an action is modeled on Reward-
Penalty-Plane. IDS planes will be updated according to this plane. It is shown
that the system can learn with a predefined fuzzy system or without it (through
random actions).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1662</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1662</id><created>2010-11-07</created><authors><author><keyname>Khasteh</keyname><forenames>Seyed Hossein</forenames></author><author><keyname>Shouraki</keyname><forenames>Saeid Bagheri</forenames></author><author><keyname>Kiaei</keyname><forenames>Ali Akbar</forenames></author></authors><title>A New Sufficient Condition for 1-Coverage to Imply Connectivity</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An effective approach for energy conservation in wireless sensor networks is
scheduling sleep intervals for extraneous nodes while the remaining nodes stay
active to provide continuous service. For the sensor network to operate
successfully the active nodes must maintain both sensing coverage and network
connectivity, It proved before if the communication range of nodes is at least
twice the sensing range, complete coverage of a convex area implies
connectivity among the working set of nodes. In this paper we consider a
rectangular region A = a *b, such that R a R b s s {\pounds}, {\pounds}, where
s R is the sensing range of nodes. and put a constraint on minimum allowed
distance between nodes(s). according to this constraint we present a new lower
bound for communication range relative to sensing range of sensors(s 2 + 3 *R)
that complete coverage of considered area implies connectivity among the
working set of nodes; also we present a new distribution method, that satisfy
our constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1677</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1677</id><created>2010-11-07</created><authors><author><keyname>Kar</keyname><forenames>Soummya</forenames></author><author><keyname>Moura</keyname><forenames>Jose' M. F.</forenames></author></authors><title>Convergence Rate Analysis of Distributed Gossip (Linear Parameter)
  Estimation: Fundamental Limits and Tradeoffs</title><categories>cs.IT math.IT math.OC math.PR</categories><comments>Submitted for publication, 30 pages</comments><doi>10.1109/JSTSP.2011.2127446</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper considers gossip distributed estimation of a (static) distributed
random field (a.k.a., large scale unknown parameter vector) observed by
sparsely interconnected sensors, each of which only observes a small fraction
of the field. We consider linear distributed estimators whose structure
combines the information \emph{flow} among sensors (the \emph{consensus} term
resulting from the local gossiping exchange among sensors when they are able to
communicate) and the information \emph{gathering} measured by the sensors (the
\emph{sensing} or \emph{innovations} term.) This leads to mixed time scale
algorithms--one time scale associated with the consensus and the other with the
innovations. The paper establishes a distributed observability condition
(global observability plus mean connectedness) under which the distributed
estimates are consistent and asymptotically normal. We introduce the
distributed notion equivalent to the (centralized) Fisher information rate,
which is a bound on the mean square error reduction rate of any distributed
estimator; we show that under the appropriate modeling and structural network
communication conditions (gossip protocol) the distributed gossip estimator
attains this distributed Fisher information rate, asymptotically achieving the
performance of the optimal centralized estimator. Finally, we study the
behavior of the distributed gossip estimator when the measurements fade (noise
variance grows) with time; in particular, we consider the maximum rate at which
the noise variance can grow and still the distributed estimator being
consistent, by showing that, as long as the centralized estimator is
consistent, the distributed estimator remains consistent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1701</identifier>
 <datestamp>2011-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1701</id><created>2010-11-07</created><updated>2011-06-10</updated><authors><author><keyname>Nozaki</keyname><forenames>Takayuki</forenames></author><author><keyname>Kasai</keyname><forenames>Kenta</forenames></author><author><keyname>Sakaniwa</keyname><forenames>Kohichi</forenames></author></authors><title>Analytical Solution of Covariance Evolution for Irregular LDPC Codes</title><categories>cs.IT math.IT</categories><comments>13pages, submitted to IEEE trans. on information theory, January 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A scaling law developed by Amraoui et al. is a powerful technique to estimate
the block error probability of finite length low-density parity-check (LDPC)
codes. Solving a system of differential equations called covariance evolution
is a method to obtain the scaling parameter. However, the covariance evolution
has not been analytically solved. In this paper, we present the analytical
solution of the covariance evolution for irregular LDPC code ensembles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1703</identifier>
 <datestamp>2013-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1703</id><created>2010-11-07</created><updated>2012-11-20</updated><authors><author><keyname>Perry</keyname><forenames>Patrick O.</forenames></author><author><keyname>Wolfe</keyname><forenames>Patrick J.</forenames></author></authors><title>Point process modeling for directed interaction networks</title><categories>stat.ME cs.SI math.ST stat.TH</categories><comments>36 pages, 13 figures; includes supplementary material</comments><journal-ref>Journal of the Royal Statistical Society, Series B, 2013</journal-ref><doi>10.1111/rssb.12013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network data often take the form of repeated interactions between senders and
receivers tabulated over time. A primary question to ask of such data is which
traits and behaviors are predictive of interaction. To answer this question, a
model is introduced for treating directed interactions as a multivariate point
process: a Cox multiplicative intensity model using covariates that depend on
the history of the process. Consistency and asymptotic normality are proved for
the resulting partial-likelihood-based estimators under suitable regularity
conditions, and an efficient fitting procedure is described. Multicast
interactions--those involving a single sender but multiple receivers--are
treated explicitly. The resulting inferential framework is then employed to
model message sending behavior in a corporate e-mail network. The analysis
gives a precise quantification of which static shared traits and dynamic
network effects are predictive of message recipient selection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1708</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1708</id><created>2010-11-07</created><updated>2012-02-18</updated><authors><author><keyname>Jansson</keyname><forenames>Jesper</forenames></author><author><keyname>Sadakane</keyname><forenames>Kunihiko</forenames></author><author><keyname>Sung</keyname><forenames>Wing-Kin</forenames></author></authors><title>CRAM: Compressed Random Access Memory</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new data structure called the \emph{Compressed Random Access
Memory} (CRAM) that can store a dynamic string $T$ of characters, e.g.,
representing the memory of a computer, in compressed form while achieving
asymptotically almost-optimal bounds (in terms of empirical entropy) on the
compression ratio. It allows short substrings of $T$ to be decompressed and
retrieved efficiently and, significantly, characters at arbitrary positions of
$T$ to be modified quickly during execution \emph{without decompressing the
entire string}. This can be regarded as a new type of data compression that can
update a compressed file directly. Moreover, at the cost of slightly increasing
the time spent per operation, the CRAM can be extended to also support
insertions and deletions. Our key observation that the empirical entropy of a
string does not change much after a small change to the string, as well as our
simple yet efficient method for maintaining an array of variable-length blocks
under length modifications, may be useful for many other applications as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1716</identifier>
 <datestamp>2011-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1716</id><created>2010-11-08</created><updated>2011-09-06</updated><authors><author><keyname>Hirani</keyname><forenames>Anil N.</forenames></author><author><keyname>Kalyanaraman</keyname><forenames>Kaushik</forenames></author><author><keyname>Watts</keyname><forenames>Seth</forenames></author></authors><title>Least Squares Ranking on Graphs</title><categories>cs.NA cs.LG math.NA</categories><comments>Added missing references, comparison of linear solvers overhauled,
  conclusion section added, some new figures added</comments><msc-class>65F10, 65F20, 58A14, 68T05, 05C50</msc-class><acm-class>G.1.3; F.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set of alternatives to be ranked, and some pairwise comparison data,
ranking is a least squares computation on a graph. The vertices are the
alternatives, and the edge values comprise the comparison data. The basic idea
is very simple and old: come up with values on vertices such that their
differences match the given edge data. Since an exact match will usually be
impossible, one settles for matching in a least squares sense. This formulation
was first described by Leake in 1976 for rankingfootball teams and appears as
an example in Professor Gilbert Strang's classic linear algebra textbook. If
one is willing to look into the residual a little further, then the problem
really comes alive, as shown effectively by the remarkable recent paper of
Jiang et al. With or without this twist, the humble least squares problem on
graphs has far-reaching connections with many current areas ofresearch. These
connections are to theoretical computer science (spectral graph theory, and
multilevel methods for graph Laplacian systems); numerical analysis (algebraic
multigrid, and finite element exterior calculus); other mathematics (Hodge
decomposition, and random clique complexes); and applications (arbitrage, and
ranking of sports teams). Not all of these connections are explored in this
paper, but many are. The underlying ideas are easy to explain, requiring only
the four fundamental subspaces from elementary linear algebra. One of our aims
is to explain these basic ideas and connections, to get researchers in many
fields interested in this topic. Another aim is to use our numerical
experiments for guidance on selecting methods and exposing the need for further
development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1735</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1735</id><created>2010-11-08</created><authors><author><keyname>Anderson</keyname><forenames>George</forenames></author><author><keyname>Marwala</keyname><forenames>Tshilidzi</forenames></author><author><keyname>Nelwamondo</keyname><forenames>Fulufhelo V.</forenames></author></authors><title>Use of Data Mining in Scheduler Optimization</title><categories>cs.OS</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The operating system's role in a computer system is to manage the various
resources. One of these resources is the Central Processing Unit. It is managed
by a component of the operating system called the CPU scheduler. Schedulers are
optimized for typical workloads expected to run on the platform. However, a
single scheduler may not be appropriate for all workloads. That is, a scheduler
may schedule a workload such that the completion time is minimized, but when
another type of workload is run on the platform, scheduling and therefore
completion time will not be optimal; a different scheduling algorithm, or a
different set of parameters, may work better. Several approaches to solving
this problem have been proposed. The objective of this survey is to summarize
the approaches based on data mining, which are available in the literature. In
addition to solutions that can be directly utilized for solving this problem,
we are interested in data mining research in related areas that have potential
for use in operating system scheduling. We also explain general technical
issues involved in scheduling in modern computers, including parallel
scheduling issues related to multi-core CPUs. We propose a taxonomy that
classifies the scheduling approaches we discuss into different categories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1738</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1738</id><created>2010-11-08</created><authors><author><keyname>Venkatarama</keyname><forenames>Harish Sheeranalli</forenames></author><author><keyname>Sekaran</keyname><forenames>Kandasamy Chandra</forenames></author></authors><title>Regulating Response Time in an Autonomic Computing System: A Comparision
  of Proportional Control and Fuzzy Control Approaches</title><categories>cs.SY</categories><comments>9 pages, 7 figures, 1 table</comments><journal-ref>International Journal of Artificial Intelligence &amp; Applications
  (IJAIA) Vol. 1, No. 4, October 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ecommerce is an area where an Autonomic Computing system could be very
effectively deployed. Ecommerce has created demand for high quality information
technology services and businesses are seeking quality of service guarantees
from their service providers. These guarantees are expressed as part of service
level agreements. Properly adjusting tuning parameters for enforcement of the
service level agreement is time-consuming and skills-intensive. Moreover, in
case of changes to the workload, the setting of the parameters may no longer be
optimum. In an ecommerce system, where the workload changes frequently, there
is a need to update the parameters at regular intervals. This paper describes
two approaches, one, using a proportional controller and two, using a fuzzy
controller, to automate the tuning of MaxClients parameter of Apache web server
based on the required response time and the current workload. This is an
illustration of the self-optimizing characteristic of an autonomic computing
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1742</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1742</id><created>2010-11-08</created><authors><author><keyname>Selvi</keyname><forenames>P.</forenames></author><author><keyname>Bnerjee</keyname><forenames>A. K.</forenames></author></authors><title>Automatic Short -Answer Grading System (ASAGS)</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic assessment needs short answer based evaluation and automated
assessment. Various techniques used are Ontology, Semantic similarity matching
and Statistical methods. An automatic short answer assessment system is
attempted in this paper. Through experiments performed on a data set, we show
that the semantic ASAGS outperforms methods based on simple lexical matching;
resulting is up to 59 percent with respect to the traditional vector-based
similarity metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1754</identifier>
 <datestamp>2014-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1754</id><created>2010-11-08</created><updated>2012-05-04</updated><authors><author><keyname>Briet</keyname><forenames>Jop</forenames></author><author><keyname>Filho</keyname><forenames>Fernando Mario de Oliveira</forenames></author><author><keyname>Vallentin</keyname><forenames>Frank</forenames></author></authors><title>Grothendieck inequalities for semidefinite programs with rank constraint</title><categories>math.OC cs.DS math.CO math.FA</categories><comments>22 pages</comments><msc-class>68W25, 90C22</msc-class><journal-ref>Theory of Computing 10 (2014), 77-105</journal-ref><doi>10.4086/toc.2014.v010a004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Grothendieck inequalities are fundamental inequalities which are frequently
used in many areas of mathematics and computer science. They can be interpreted
as upper bounds for the integrality gap between two optimization problems: a
difficult semidefinite program with rank-1 constraint and its easy semidefinite
relaxation where the rank constrained is dropped. For instance, the integrality
gap of the Goemans-Williamson approximation algorithm for MAX CUT can be seen
as a Grothendieck inequality. In this paper we consider Grothendieck
inequalities for ranks greater than 1 and we give two applications:
approximating ground states in the n-vector model in statistical mechanics and
XOR games in quantum information theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1755</identifier>
 <datestamp>2012-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1755</id><created>2010-11-08</created><updated>2011-06-26</updated><authors><author><keyname>Steiner</keyname><forenames>Wolfgang</forenames><affiliation>LIAFA</affiliation></author></authors><title>On the structure of ($-\beta$)-integers</title><categories>math.NT cs.DM</categories><proxy>ccsd</proxy><journal-ref>RAIRO - Theoretical Informatics and Applications 46, 1 (2012)
  181-200</journal-ref><doi>10.1051/ita/2011115</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The $(-\beta)$-integers are natural generalisations of the $\beta$-integers,
and thus of the integers, for negative real bases. When $\beta$ is the analogue
of a Parry number, we describe the structure of the set of $(-\beta)$-integers
by a fixed point of an anti-morphism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1783</identifier>
 <datestamp>2011-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1783</id><created>2010-11-08</created><updated>2011-09-27</updated><authors><author><keyname>Meurer</keyname><forenames>Benedikt</forenames></author></authors><title>OCamlJIT 2.0 - Faster Objective Caml</title><categories>cs.PL</categories><comments>23 pages, 12 figures</comments><acm-class>D.3.3; D.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the current state of an ongoing research project to
improve the performance of the OCaml byte-code interpreter using Just-In-Time
native code generation. Our JIT engine OCamlJIT2 currently runs on x86-64
processors, mimicing precisely the behavior of the OCaml virtual machine. Its
design and implementation is described, and performance measures are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1787</identifier>
 <datestamp>2012-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1787</id><created>2010-11-01</created><updated>2012-06-08</updated><authors><author><keyname>Schlei</keyname><forenames>B. R.</forenames></author></authors><title>Volume-Enclosing Surface Extraction</title><categories>cs.CG cs.GR nucl-th</categories><comments>24 pages, 33 figures, 4 tables, final version</comments><journal-ref>Computers and Graphics, Volume 36, Issue 2, 2012, Pages 111 - 130</journal-ref><doi>10.1016/j.cag.2011.12.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a new method, which allows for the construction of
triangular isosurfaces from three-dimensional data sets, such as 3D image data
and/or numerical simulation data that are based on regularly shaped, cubic
lattices. This novel volume-enclosing surface extraction technique, which has
been named VESTA, can produce up to six different results due to the nature of
the discretized 3D space under consideration. VESTA is neither template-based
nor it is necessarily required to operate on 2x2x2 voxel cell neighborhoods
only. The surface tiles are determined with a very fast and robust construction
technique while potential ambiguities are detected and resolved. Here, we
provide an in-depth comparison between VESTA and various versions of the
well-known and very popular Marching Cubes algorithm for the very first time.
In an application section, we demonstrate the extraction of VESTA isosurfaces
for various data sets ranging from computer tomographic scan data to simulation
data of relativistic hydrodynamic fireball expansions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1793</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1793</id><created>2010-11-08</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author><author><keyname>Goswami</keyname><forenames>Kaustav</forenames></author></authors><title>An Algorithm for Detection of Selfish Nodes in Wireless Mesh Networks</title><categories>cs.CR</categories><comments>6 pages, 6 figures, 3 tables. Conference: International Symposium on
  Intelligent Information Systems and Applications (IISA'09)</comments><report-no>ISBN 978-952-5726-04-6 (Print), 978-952-5726-05-3 (CD-ROM)</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless mesh networks (WMNs) are evolving as a key technology for
next-generation wireless networks showing raid progress and numerous
applications. These networks have the potential to provide robust and
high-throughput data delivery to wireless users. In a WMN, high speed routers
equipped with advanced antennas, communicate with each other in a multi-hop
fashion over wireless channels and form a broadband backhaul. However, the
throughput of a WMN may be severely degraded due to presence of some selfish
routers that avoid forwarding packets for other nodes even as they send their
own traffic through the network. This paper presents an algorithm for detection
of selfish nodes in a WMN. It uses statistical theory of inference for reliable
clustering of the nodes and is based on local observations by the nodes.
Simulation results show that the algorithm has a high detection rate while
having a low rate of false positives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1827</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1827</id><created>2010-11-08</created><authors><author><keyname>Grohe</keyname><forenames>Martin</forenames></author><author><keyname>Kawarabayashi</keyname><forenames>Ken-ichi</forenames></author><author><keyname>Marx</keyname><forenames>D&#xe1;niel</forenames></author><author><keyname>Wollan</keyname><forenames>Paul</forenames></author></authors><title>Finding topological subgraphs is fixed-parameter tractable</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that for every fixed undirected graph $H$, there is a $O(|V(G)|^3)$
time algorithm that tests, given a graph $G$, if $G$ contains $H$ as a
topological subgraph (that is, a subdivision of $H$ is subgraph of $G$). This
shows that topological subgraph testing is fixed-parameter tractable, resolving
a longstanding open question of Downey and Fellows from 1992. As a corollary,
for every $H$ we obtain an $O(|V(G)|^3)$ time algorithm that tests if there is
an immersion of $H$ into a given graph $G$. This answers another open question
raised by Downey and Fellows in 1992.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1828</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1828</id><created>2010-11-08</created><authors><author><keyname>Teixeira</keyname><forenames>Andr&#xe9;</forenames></author><author><keyname>D&#xe1;n</keyname><forenames>Gy&#xf6;rgy</forenames></author><author><keyname>Sandberg</keyname><forenames>Henrik</forenames></author><author><keyname>Johansson</keyname><forenames>Karl H.</forenames></author></authors><title>A Cyber Security Study of a SCADA Energy Management System: Stealthy
  Deception Attacks on the State Estimator</title><categories>math.OC cs.NI physics.soc-ph</categories><comments>Modified version submitted to the 18th IFAC World Congress, 2011. The
  paper has 11 pages and 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The electrical power network is a critical infrastructure in today's society,
so its safe and reliable operation is of major concern. State estimators are
commonly used in power networks, for example, to detect faulty equipment and to
optimally route power flows. The estimators are often located in control
centers, to which large numbers of measurements are sent over unencrypted
communication channels. Therefore cyber security for state estimators becomes
an important issue. In this paper we analyze the cyber security of state
estimators in supervisory control and data acquisition (SCADA) for energy
management systems (EMS) operating the power network. Current EMS state
estimation algorithms have bad data detection (BDD) schemes to detect outliers
in the measurement data. Such schemes are based on high measurement redundancy.
Although these methods may detect a set of basic cyber attacks, they may fail
in the presence of an intelligent attacker. We explore the latter by
considering scenarios where stealthy deception attacks are performed by sending
false information to the control center. We begin by presenting a recent
framework that characterizes the attack as an optimization problem with the
objective specified through a security metric and constraints corresponding to
the attack cost. The framework is used to conduct realistic experiments on a
state-of-the-art SCADA EMS software for a power network example with 14
substations, 27 buses, and 40 branches. The results indicate how state
estimators for power networks can be made more resilient to cyber security
attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1830</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1830</id><created>2010-11-08</created><authors><author><keyname>Dobzinski</keyname><forenames>Shahar</forenames></author></authors><title>An Impossibility Result for Truthful Combinatorial Auctions with
  Submodular Valuations</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that every universally truthful randomized mechanism for
combinatorial auctions with submodular valuations that provides $m^{\frac 1 2
-\epsilon}$ approximation to the social welfare and uses value queries only
must use exponentially many value queries, where $m$ is the number of items. In
contrast, ignoring incentives there exist constant ratio approximation
algorithms for this problem. Our approach is based on a novel \emph{direct
hardness} approach and completely skips the notoriously hard characterization
step. The characterization step was the main obstacle for proving impossibility
results in algorithmic mechanism design so far.
  We demonstrate two additional applications of our new technique: (1) an
impossibility result for universally-truthful polynomial time flexible
combinatorial public projects and (2) an impossibility result for
truthful-in-expectation mechanisms for exact combinatorial public projects. The
latter is the first result that bounds the power of polynomial-time truthful in
expectation mechanisms in any setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1841</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1841</id><created>2010-10-17</created><authors><author><keyname>Pensky</keyname><forenames>Oleg</forenames></author><author><keyname>Chernikov</keyname><forenames>Kirill</forenames></author></authors><title>Fundamentals of Mathematical Theory of Emotional Robots</title><categories>cs.RO cs.AI</categories><comments>95 pages, 12 figures</comments><msc-class>68T40</msc-class><acm-class>I.6.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this book we introduce a mathematically formalized concept of emotion,
robot's education and other psychological parameters of intelligent robots. We
also introduce unitless coefficients characterizing an emotional memory of a
robot. Besides, the effect of a robot's memory upon its emotional behavior is
studied, and theorems defining fellowship and conflicts in groups of robots are
proved. Also unitless parameters describing emotional states of those groups
are introduced, and a rule of making alternative (binary) decisions based on
emotional selection is given. We introduce a concept of equivalent educational
process for robots and a concept of efficiency coefficient of an educational
process, and suggest an algorithm of emotional contacts within a group of
robots. And generally, we present and describe a model of a virtual reality
with emotional robots. The book is meant for mathematical modeling specialists
and emotional robot software developers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1842</identifier>
 <datestamp>2010-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1842</id><created>2010-11-08</created><updated>2010-12-05</updated><authors><author><keyname>Tarasov</keyname><forenames>S.</forenames></author><author><keyname>Vyalyi</keyname><forenames>M.</forenames></author></authors><title>Orbits of linear maps and regular languages</title><categories>cs.FL math.NT</categories><comments>The text combines a journal publication and new results submitted to
  CSR 2011. 33 pages, 7 figures</comments><msc-class>68Q25, 11Y16</msc-class><acm-class>F.2; F.4.3; G.2.1</acm-class><journal-ref>Vyalyi M., Tarasov S. Orbits of linear maps and regular languages.
  Discrete analysis and operations research. 2010. Vol. 17, No 6. P. 20--49 (in
  Russian)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We settle the equivalence between the problem of hitting a polyhedral set by
the orbit of a linear map and the intersection of a regular language and a
language of permutations of binary words (the permutation filter realizability
problem). The decidability of the both problems is presently unknown and the
first one is a straightforward generalization of the famous Skolem problem and
the nonnegativity problem in the theory of linear recurrent sequences. To show
a `borderline' status of the permutation filter realizability problem with
respect to computability we present some decidable and undecidable problems
closely related to it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1868</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1868</id><created>2010-11-08</created><updated>2010-11-17</updated><authors><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author><author><keyname>Fouz</keyname><forenames>Mahmoud</forenames></author></authors><title>Asymptotically Optimal Randomized Rumor Spreading</title><categories>cs.DS cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new protocol solving the fundamental problem of disseminating a
piece of information to all members of a group of n players. It builds upon the
classical randomized rumor spreading protocol and several extensions. The main
achievements are the following:
  Our protocol spreads the rumor to all other nodes in the asymptotically
optimal time of (1 + o(1)) \log_2 n. The whole process can be implemented in a
way such that only O(n f(n)) calls are made, where f(n)= \omega(1) can be
arbitrary.
  In contrast to other protocols suggested in the literature, our algorithm
only uses push operations, i.e., only informed nodes take active actions in the
network. To the best of our knowledge, this is the first randomized push
algorithm that achieves an asymptotically optimal running time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1874</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1874</id><created>2010-11-08</created><authors><author><keyname>Quatrini</keyname><forenames>Davide</forenames></author><author><keyname>De Angelis</keyname><forenames>Roberta</forenames></author></authors><title>Reusing optical supports using a simple software</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we show how it is possible to reuse optical supports (CDs,
DVDs, etc.) without using chemical or physical transformation, only employing a
software that can easily run on domestic computers. This software can make
obsolete optical supports useful again, converting de facto WEEE (Waste
electric and electronic equipment) into EEE (Electric and electronic
equipment). A massive use of such a software can lead to a significant change
in EEE every-day use, reducing its production to sustainable levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1876</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1876</id><created>2010-11-08</created><authors><author><keyname>Inoue</keyname><forenames>Jun-ichi</forenames></author><author><keyname>Saika</keyname><forenames>Yohei</forenames></author><author><keyname>Okada</keyname><forenames>Masato</forenames></author></authors><title>Statistical mechanics of digital halftoning</title><categories>cond-mat.dis-nn cs.CV physics.comp-ph</categories><comments>20 pages, 27 figures, using revtex4</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of digital halftoning from the view point of
statistical mechanics. The digital halftoning is a sort of image processing,
namely, representing each grayscale in terms of black and white binary dots.
The digital halftoning is achieved by making use of the threshold mask, namely,
for each pixel, the halftoned binary pixel is determined as black if the
original grayscale pixel is greater than or equal to the mask value and is
determined as white vice versa. To determine the optimal value of the mask on
each pixel for a given original grayscale image, we first assume that the
human-eyes might recognize the black and white binary halftoned image as the
corresponding grayscale one by linear filters. The Hamiltonian is constructed
as a distance between the original and the recognized images which is written
in terms of the threshold mask. We are confirmed that the system described by
the Hamiltonian is regarded as a kind of antiferromagnetic Ising model with
quenched disorders. By searching the ground state of the Hamiltonian, we obtain
the optimal threshold mask and the resulting halftoned binary dots
simultaneously. From the power-spectrum analysis, we find that the binary dots
image is physiologically plausible from the view point of human-eyes modulation
properties. We also propose a theoretical framework to investigate statistical
performance of inverse digital halftoning, that is, the inverse process of
halftoning. From the Bayesian inference view point, we rigorously show that the
Bayes-optimal inverse-halftoning is achieved on a specific condition which is
very similar to the so-called Nishimori line in the research field of spin
glasses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1892</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1892</id><created>2010-11-08</created><authors><author><keyname>Blond</keyname><forenames>Stevens Le</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Legout</keyname><forenames>Arnaud</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Dabbous</keyname><forenames>Walid</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>Pushing BitTorrent Locality to the Limit</title><categories>cs.NI</categories><proxy>ccsd</proxy><journal-ref>Computer Networks (2010)</journal-ref><doi>10.1016/j.comnet.2010.09.014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Peer-to-peer (P2P) locality has recently raised a lot of interest in the
community. Indeed, whereas P2P content distribution enables financial savings
for the content providers, it dramatically increases the traffic on inter-ISP
links. To solve this issue, the idea to keep a fraction of the P2P traffic
local to each ISP was introduced a few years ago. Since then, P2P solutions
exploiting locality have been introduced. However, several fundamental issues
on locality still need to be explored. In particular, how far can we push
locality, and what is, at the scale of the Internet, the reduction of traffic
that can be achieved with locality? In this paper, we perform extensive
experiments on a controlled environment with up to 10,000 BitTorrent clients to
evaluate the impact of high locality on inter-ISP links traffic and peers
download completion time. We introduce two simple mechanisms that make high
locality possible in challenging scenarios and we show that we save up to
several orders of magnitude inter-ISP traffic compared to traditional locality
without adversely impacting peers download completion time. In addition, we
crawled 214,443 torrents representing 6,113,224 unique peers spread among 9,605
ASes. We show that whereas the torrents we crawled generated 11.6 petabytes of
inter-ISP traffic, our locality policy implemented for all torrents could have
reduced the global inter-ISP traffic by up to 40%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1917</identifier>
 <datestamp>2012-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1917</id><created>2010-11-08</created><updated>2012-02-27</updated><authors><author><keyname>Sunic</keyname><forenames>Zoran</forenames></author></authors><title>Normal art galleries: wall in - all in</title><categories>cs.CG</categories><msc-class>68U05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the notion of a normal gallery, a gallery in which any
configuration of guards that visually covers the walls covers the entire
gallery. We show that any star gallery is normal and any gallery with at most
two reflex corners is normal. A polynomial time algorithm is provided deciding
if, for a given polygon and a finite set of positions, there exists a
configuration of guards in some of these positions that visually covers the
walls but not the entire gallery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1933</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1933</id><created>2010-11-08</created><updated>2011-05-20</updated><authors><author><keyname>Blaum</keyname><forenames>Mario</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author></authors><title>Shortened Hamming Codes Maximizing Double Error Detection</title><categories>cs.DM cs.IT math.IT</categories><comments>We withdraw the paper since we found a reference from 1981 that
  solves exactly the same problem</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given $r\geq 3$ and $2^{r-1}+1\leq n&lt; 2^{r}-1$, an $[n,n-r,3]$ shortened
Hamming code that can detect a maximal number of double errors is constructed.
The optimality of the construction is proven.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1936</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1936</id><created>2010-11-08</created><authors><author><keyname>Abernethy</keyname><forenames>Jacob</forenames></author><author><keyname>Bartlett</keyname><forenames>Peter L.</forenames></author><author><keyname>Hazan</keyname><forenames>Elad</forenames></author></authors><title>Blackwell Approachability and Low-Regret Learning are Equivalent</title><categories>cs.LG cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the celebrated Blackwell Approachability Theorem for two-player
games with vector payoffs. We show that Blackwell's result is equivalent, via
efficient reductions, to the existence of &quot;no-regret&quot; algorithms for Online
Linear Optimization. Indeed, we show that any algorithm for one such problem
can be efficiently converted into an algorithm for the other. We provide a
useful application of this reduction: the first efficient algorithm for
calibrated forecasting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1939</identifier>
 <datestamp>2011-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1939</id><created>2010-11-08</created><updated>2011-09-26</updated><authors><author><keyname>Durham</keyname><forenames>Joseph W.</forenames></author><author><keyname>Carli</keyname><forenames>Ruggero</forenames></author><author><keyname>Frasca</keyname><forenames>Paolo</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>Discrete Partitioning and Coverage Control for Gossiping Robots</title><categories>cs.RO cs.SY math.OC</categories><comments>Accepted to IEEE TRO. 14 double-column pages, 10 figures. v2 is a
  thorough revision of v1, including new algorithms and revised mathematical
  and simulation results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose distributed algorithms to automatically deploy a team of mobile
robots to partition and provide coverage of a non-convex environment. To handle
arbitrary non-convex environments, we represent them as graphs. Our
partitioning and coverage algorithm requires only short-range, unreliable
pairwise &quot;gossip&quot; communication. The algorithm has two components: (1) a motion
protocol to ensure that neighboring robots communicate at least sporadically,
and (2) a pairwise partitioning rule to update territory ownership when two
robots communicate. By studying an appropriate dynamical system on the space of
partitions of the graph vertices, we prove that territory ownership converges
to a pairwise-optimal partition in finite time. This new equilibrium set
represents improved performance over common Lloyd-type algorithms.
Additionally, we detail how our algorithm scales well for large teams in large
environments and how the computation can run in anytime with limited resources.
Finally, we report on large-scale simulations in complex environments and
hardware experiments using the Player/Stage robot control system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1941</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1941</id><created>2010-11-08</created><authors><author><keyname>Abernethy</keyname><forenames>Jacob</forenames></author><author><keyname>Chen</keyname><forenames>Yiling</forenames></author><author><keyname>Vaughan</keyname><forenames>Jennifer Wortman</forenames></author></authors><title>An Optimization-Based Framework for Automated Market-Making</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Building on ideas from online convex optimization, we propose a general
framework for the design of efficient securities markets over very large
outcome spaces. The challenge here is computational. In a complete market, in
which one security is offered for each outcome, the market institution can not
efficiently keep track of the transaction history or calculate security prices
when the outcome space is large. The natural solution is to restrict the space
of securities to be much smaller than the outcome space in such a way that
securities can be priced efficiently. Recent research has focused on searching
for spaces of securities that can be priced efficiently by existing mechanisms
designed for complete markets. While there have been some successes, much of
this research has led to hardness results. In this paper, we take a drastically
different approach. We start with an arbitrary space of securities with bounded
payoff, and establish a framework to design markets tailored to this space. We
prove that any market satisfying a set of intuitive conditions must price
securities via a convex potential function and that the space of reachable
prices must be precisely the convex hull of the security payoffs. We then show
how the convex potential function can be defined in terms of an optimization
over the convex hull of the security payoffs. The optimal solution to the
optimization problem gives the security prices. Using this framework, we
provide an efficient market for predicting the landing location of an object on
a sphere. In addition, we show that we can relax our &quot;no-arbitrage&quot; condition
to design a new efficient market maker for pair betting, which is known to be
#P-hard to price using existing mechanisms. This relaxation also allows the
market maker to charge transaction fees so that the depth of the market can be
dynamically increased as the number of trades increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1956</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1956</id><created>2010-11-08</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>Mobility and Handoff Management in Wireless Networks</title><categories>cs.NI</categories><comments>28 pages, 11 figures</comments><journal-ref>Book Title: Trends in Telecommunications Technologies. Editor:
  Christos J Bouras. ISBN: 978-953-307-072-8. Year: 2010. Publisher: InTech</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increasing demands for new data and real-time services, wireless
networks should support calls with different traffic characteristics and
different Quality of Service (QoS)guarantees. In addition, various wireless
technologies and networks exist currently that can satisfy different needs and
requirements of mobile users. Since these different wireless networks act as
complementary to each other in terms of their capabilities and suitability for
different applications, integration of these networks will enable the mobile
users to be always connected to the best available access network depending on
their requirements. This integration of heterogeneous networks will, however,
lead to heterogeneities in access technologies and network protocols. To meet
the requirements of mobile users under this heterogeneous environment, a common
infrastructure to interconnect multiple access networks will be needed. In this
chapter, the design issues of a number of mobility management schemes have been
presented. Each of these schemes utilizes IP-based technologies to enable
efficient roaming in heterogeneous network. Efficient handoff mechanisms are
essential for ensuring seamless connectivity and uninterrupted service
delivery. A number of handoff schemes in a heterogeneous networking environment
are also presented in this chapter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1960</identifier>
 <datestamp>2012-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1960</id><created>2010-11-08</created><updated>2011-10-21</updated><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>Ubiquitous Computing: Potentials and Challenges</title><categories>cs.CY cs.NI</categories><comments>The biometric authentication and user privacy related sections in the
  paper are being augmented with some case studies and experimental results
  which are to be incorporated in a new chapter written by me. Hence the paper
  is withdrawn.</comments><report-no>ISBN: 978-81-8387-398-7</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The world is witnessing the birth of a revolutionary computing paradigm that
promises to have a profound effect on the way we interact with computers,
devices, physical spaces, and other people. This new technology, called
ubiquitous computing, envisions a world where embedded processors, computers,
sensors, and digital communications are inexpensive commodities that are
available everywhere. This paper presents a comprehensive discussion on the
central trends in ubiquitous computing considering them form technical, social
and economic perspectives. It clearly identifies different application areas
and sectors that will benefit from the potentials of ubiquitous computing. It
also brings forth the challenges of ubiquitous computing that require active
solutions and management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1970</identifier>
 <datestamp>2010-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1970</id><created>2010-11-08</created><updated>2010-11-17</updated><authors><author><keyname>McDaid</keyname><forenames>Aaron F.</forenames></author><author><keyname>Hurley</keyname><forenames>Neil J.</forenames></author></authors><title>Using Model-based Overlapping Seed Expansion to detect highly
  overlapping community structure</title><categories>physics.soc-ph cs.SI stat.ML</categories><comments>based on work accepted at ASONAM 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As research into community finding in social networks progresses, there is a
need for algorithms capable of detecting overlapping community structure. Many
algorithms have been proposed in recent years that are capable of assigning
each node to more than a single community. The performance of these algorithms
tends to degrade when the ground-truth contains a more highly overlapping
community structure, with nodes assigned to more than two communities. Such
highly overlapping structure is likely to exist in many social networks, such
as Facebook friendship networks. In this paper we present a scalable algorithm,
MOSES, based on a statistical model of community structure, which is capable of
detecting highly overlapping community structure, especially when there is
variance in the number of communities each node is in. In evaluation on
synthetic data MOSES is found to be superior to existing algorithms, especially
at high levels of overlap. We demonstrate MOSES on real social network data by
analyzing the networks of friendship links between students of five US
universities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1972</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1972</id><created>2010-11-08</created><updated>2011-04-11</updated><authors><author><keyname>Dutil</keyname><forenames>Nicolas</forenames></author><author><keyname>Hayden</keyname><forenames>Patrick</forenames></author></authors><title>Assisted Entanglement Distillation</title><categories>quant-ph cs.IT math.IT</categories><comments>25 pages, 4 figures</comments><report-no>Mittag-Leffler-2010fall</report-no><journal-ref>Quantum Information and Computation, Vol 11, No 5&amp;6, (2011)
  0496-0520</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the problem of designing quantum repeaters, we study
entanglement distillation between two parties, Alice and Bob, starting from a
mixed state and with the help of &quot;repeater&quot; stations. To treat the case of a
single repeater, we extend the notion of entanglement of assistance to
arbitrary mixed tripartite states and exhibit a protocol, based on a random
coding strategy, for extracting pure entanglement. The rates achievable by this
protocol formally resemble those achievable if the repeater station could merge
its state to one of Alice and Bob even when such merging is impossible. This
rate is provably better than the hashing bound for sufficiently pure tripartite
states. We also compare our assisted distillation protocol to a hierarchical
strategy consisting of entanglement distillation followed by entanglement
swapping. We demonstrate by the use of a simple example that our random
measurement strategy outperforms hierarchical distillation strategies when the
individual helper stations' states fail to individually factorize into portions
associated specifically with Alice and Bob. Finally, we use these results to
find achievable rates for the more general scenario, where many spatially
separated repeaters help two recipients distill entanglement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1974</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1974</id><created>2010-11-09</created><authors><author><keyname>Dutil</keyname><forenames>Nicolas</forenames></author><author><keyname>Hayden</keyname><forenames>Patrick</forenames></author></authors><title>One-shot Multiparty State Merging</title><categories>quant-ph cs.IT math.IT</categories><comments>41 pages, 3 figures</comments><report-no>Mittag-Leffler-2010fall</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a protocol for performing state merging when multiple parties
share a single copy of a mixed state, and analyze the entanglement cost in
terms of min- and max-entropies. Our protocol allows for interpolation between
corner points of the rate region without the need for time-sharing, a primitive
which is not available in the one-shot setting. We also compare our protocol to
the more naive strategy of repeatedly applying a single-party merging protocol
one party at a time, by performing a detailed analysis of the rates required to
merge variants of the embezzling states. Finally, we analyze a variation of
multiparty merging, which we call split-transfer, by considering two receivers
and many additional helpers sharing a mixed state. We give a protocol for
performing a split-transfer and apply it to the problem of assisted
entanglement distillation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.1979</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.1979</id><created>2010-11-09</created><updated>2011-02-05</updated><authors><author><keyname>Panigrahy</keyname><forenames>Rina</forenames></author></authors><title>Can Knowledge be preserved in the long run?</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Can (scientific) knowledge be reliably preserved over the long term? We have
today very efficient and reliable methods to encode, store and retrieve data in
a storage medium that is fault tolerant against many types of failures. But
does this guarantee -- or does it even seem likely -- that all knowledge can be
preserved over thousands of years and beyond? History shows that many types of
knowledge that were known before have been lost. We observe that the nature of
stored and communicated information and the way it is interpreted is such that
it always tends to decay and therefore must lost eventually in the long term.
The likely fundamental conclusion is that knowledge cannot be reliably
preserved indefinitely.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2009</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2009</id><created>2010-11-09</created><authors><author><keyname>Xu</keyname><forenames>Weichao</forenames></author><author><keyname>Hou</keyname><forenames>Yunhe</forenames></author><author><keyname>Hung</keyname><forenames>Y. S.</forenames></author><author><keyname>Zou</keyname><forenames>Yuexian</forenames></author></authors><title>Comparison of Spearman's rho and Kendall's tau in Normal and
  Contaminated Normal Models</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyzes the performances of the Spearman's rho (SR) and Kendall's
tau (KT) with respect to samples drawn from bivariate normal and bivariate
contaminated normal populations. The exact analytical formulae of the variance
of SR and the covariance between SR and KT are obtained based on the Childs's
reduction formula for the quadrivariate normal positive orthant probabilities.
Close form expressions with respect to the expectations of SR and KT are
established under the bivariate contaminated normal models. The bias, mean
square error (MSE) and asymptotic relative efficiency (ARE) of the three
estimators based on SR and KT to the Pearson's product moment correlation
coefficient (PPMCC) are investigated in both the normal and contaminated normal
models. Theoretical and simulation results suggest that, contrary to the
opinion of equivalence between SR and KT in some literature, the behaviors of
SR and KT are strikingly different in the aspects of bias effect, variance,
mean square error, and asymptotic relative efficiency. The new findings
revealed in this work provide not only deeper insights into the two most widely
used rank based correlation coefficients, but also a guidance for choosing
which one to use under the circumstances where the PPMCC fails to apply.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2024</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2024</id><created>2010-11-09</created><updated>2011-02-05</updated><authors><author><keyname>Diekert</keyname><forenames>Volker</forenames></author><author><keyname>Myasnikov</keyname><forenames>Alexei</forenames></author></authors><title>Group extensions over infinite words</title><categories>math.GR cs.DM cs.SC</categories><comments>42 pages</comments><msc-class>20F10, 68R15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct an extension $E(A,G)$ of a given group $G$ by infinite
non-Archimedean words over an discretely ordered abelian group like $Z^n$. This
yields an effective and uniform method to study various groups that &quot;behave
like $G$&quot;. We show that the Word Problem for f.g. subgroups in the extension is
decidable if and only if and only if the Cyclic Membership Problem in $G$ is
decidable.
  The present paper embeds the partial monoid of infinite words as defined by
Myasnikov, Remeslennikov, and Serbin (Contemp. Math., Amer. Math. Soc.,
378:37-77, 2005) into $E(A,G)$. Moreover, we define the extension group
$E(A,G)$ for arbitrary groups $G$ and not only for free groups as done in
previous work. We show some structural results about the group (existence and
type of torsion elements, generation by elements of order 2) and we show that
some interesting HNN extensions of $G$ embed naturally in the larger group
$E(A,G)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2039</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2039</id><created>2010-11-09</created><updated>2011-08-14</updated><authors><author><keyname>Xu</keyname><forenames>Jia</forenames></author><author><keyname>Yao</keyname><forenames>Yong</forenames></author></authors><title>An algorithm for determining copositive matrices</title><categories>math.RA cs.SC</categories><comments>15 pages</comments><msc-class>15A48 15A57 15A63 65F30</msc-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we present an algorithm of simple exponential growth called
COPOMATRIX for determining the copositivity of a real symmetric matrix. The
core of this algorithm is a decomposition theorem, which is used to deal with
simplicial subdivision of $\hat{T}^{-}=\{y\in \Delta_{m}| \beta^Ty\leq 0\}$ on
the standard simplex $\Delta_m$, where each component of the vector $\beta$ is
-1, 0 or 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2042</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2042</id><created>2010-11-09</created><authors><author><keyname>Andreyev</keyname><forenames>Sergey</forenames></author></authors><title>Excerpt from the book World of Movable Objects</title><categories>cs.HC</categories><comments>11 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This book is about the transformation of screen objects into movable and
resizable and about the design of applications entirely on the basis of such
elements. The screen objects have a wide variety of shapes; they can be either
graphical objects or controls; there are solitary objects and very complex
objects parts of which are involved in individual, synchronous, and related
movements. Objects can be involved in forward movements and rotation; they can
be resized and reconfigured; all these movements and situations are considered.
On the basis of total movability, the new type of programs - user-driven
applications - are designed. These applications continue to work according to
their main purposes, but the whole control of WHAT, WHEN, and HOW must appear
on the screen is passed from designers to users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2078</identifier>
 <datestamp>2012-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2078</id><created>2010-11-09</created><updated>2012-06-07</updated><authors><author><keyname>S&#xf8;rensen</keyname><forenames>Jesper H.</forenames></author><author><keyname>Popovski</keyname><forenames>Petar</forenames></author><author><keyname>&#xd8;stergaard</keyname><forenames>Jan</forenames></author></authors><title>Design and Analysis of LT Codes with Decreasing Ripple Size</title><categories>cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a new design of LT codes, which decreases the amount
of necessary overhead in comparison to existing designs. The design focuses on
a parameter of the LT decoding process called the ripple size. This parameter
was also a key element in the design proposed in the original work by Luby.
Specifically, Luby argued that an LT code should provide a constant ripple size
during decoding. In this work we show that the ripple size should decrease
during decoding, in order to reduce the necessary overhead. Initially we
motivate this claim by analytical results related to the redundancy within an
LT code. We then propose a new design procedure, which can provide any desired
achievable decreasing ripple size. The new design procedure is evaluated and
compared to the current state of the art through simulations. This reveals a
significant increase in performance with respect to both average overhead and
error probability at any fixed overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2103</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2103</id><created>2010-11-08</created><authors><author><keyname>Amiri</keyname><forenames>Moslem</forenames></author></authors><title>Evaluation of Lifetime Bounds of Wireless Sensor Networks</title><categories>cs.NI</categories><comments>10 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we estimate lifetime bounds of a network of motes which
communicate with each other using IEEE 802.15.4 standard. Different frame
structures of IEEE 802.15.4 along with CSMA/CA medium access mechanism are
investigated to discover the overhead of channel acquisition, header and footer
of data frame, and transfer reliability during packet transmission. This
overhead makes the fixed component, and the data payload makes the incremental
component of a linear equation to estimate the power consumed during every
packet transmission. Finally we input this per-packet power consumption in a
mathematical model which estimates the lower and upper bounds of routings in
the network. We also implemented a series of measurements on CC2420 radio used
in a wide range of sensor motes to find the fixed and incremental components,
and finally the lifetime of a network composed of the motes using this radio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2105</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2105</id><created>2010-11-06</created><authors><author><keyname>Srivastava</keyname><forenames>Dhruv</forenames></author></authors><title>Towards Greener and Safer Mines</title><categories>cs.OH</categories><comments>7 pages,9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Miniaturised sensors and networking are technical proven concepts. Both the
technologies are proven and various components e.g., sensors, controls, etc.
are commercially available. Technology scene in above areas presents enormous
possibilities for developing innovative applications for real life situations.
Mining operations in many countries have lot of scope for improving
environmental and safety measures. Efforts have been made to develop a system
to efficiently monitor a particular environment by deploying a wireless sensor
network using commercially available components. Wireless Sensor Network has
been integrated with telecom network through a gateway using a suitable
topology which can be selected at the application layer. The developed system
demonstrates a way to connect wireless sensor network to external network which
enables the distant administrator to access real time data and act expediently
from long-distance to improve the environmental situation or prevent a
disaster. Potentially, it can be used to avoid the awful situations leading to
terrible environment in underground mines. Keywords: Wireless sensor network,
Mine safety, Environment monitoring and telecom.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2107</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2107</id><created>2010-11-08</created><authors><author><keyname>Thomas</keyname><forenames>Janssoone</forenames><affiliation>TIMC</affiliation></author><author><keyname>Chevreau</keyname><forenames>Gr&#xe9;goire</forenames><affiliation>TIMC</affiliation></author><author><keyname>Vadcard</keyname><forenames>Lucile</forenames><affiliation>LSE</affiliation></author><author><keyname>Mozer</keyname><forenames>Pierre</forenames><affiliation>TIMC</affiliation></author><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author></authors><title>Biopsym : a learning environment for transrectal ultrasound guided
  prostate biopsies</title><categories>cs.OH</categories><proxy>ccsd</proxy><journal-ref>18th &quot;Medecine Meets Virtual Reality&quot;, Newport beach : United
  States (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a learning environment for image-guided prostate
biopsies in cancer diagnosis; it is based on an ultrasound probe simulator
virtually exploring real datasets obtained from patients. The aim is to make
the training of young physicians easier and faster with a tool that combines
lectures, biopsy simulations and recommended exercises to master this medical
gesture. It will particularly help acquiring the three-dimensional
representation of the prostate needed for practicing biopsy sequences. The
simulator uses a haptic feedback to compute the position of the virtual probe
from three-dimensional (3D) ultrasound recorded data. This paper presents the
current version of this learning environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2109</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2109</id><created>2010-11-09</created><authors><author><keyname>Awan</keyname><forenames>Zohaib Hassan</forenames></author><author><keyname>Zaidi</keyname><forenames>Abdellatif</forenames></author><author><keyname>Vandendorpe</keyname><forenames>Luc</forenames></author></authors><title>On Secure Transmission over Parallel Relay Eavesdropper Channel</title><categories>cs.IT math.IT</categories><comments>8 pages, Presented at the Forty-Eighth Annual Allerton Conference on
  Communication, Control, and Computing, September 29 - October 1, 2010,
  Monticello, IL, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a four terminal parallel relay-eavesdropper channel which consists
of multiple independent relay-eavesdropper channels as subchannels. For the
discrete memoryless case, we establish inner and outer bounds on the
rate-equivocation region. For each subchannel, secure transmission is obtained
through one of the two coding schemes at the relay: decoding-and-forwarding the
source message or confusing the eavesdropper through noise injection. The inner
bound allows relay mode selection. For the Gaussian model we establish lower
and upper bounds on the perfect secrecy rate. We show that the bounds meet in
some special cases, including when the relay does not hear the source. We
illustrate the analytical results through some numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2113</identifier>
 <datestamp>2012-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2113</id><created>2010-11-09</created><updated>2012-10-04</updated><authors><author><keyname>Nikitopoulos</keyname><forenames>Konstantinos</forenames></author><author><keyname>Ascheid</keyname><forenames>Gerd</forenames></author></authors><title>Complexity Adjusted Soft-Output Sphere Decoding by Adaptive LLR Clipping</title><categories>cs.IT math.IT</categories><comments>The final version of this paper appears in IEEE Communications
  Letters</comments><journal-ref>Nikitopoulos, K., Ascheid, G., &quot;Complexity Adjusted Soft-Output
  Sphere Decoding by Adaptive LLR Clipping,&quot; IEEE Communications Letters,
  vol.15, no.8, pp.810-812, Aug. 2011</journal-ref><doi>10.1109/LCOMM.2011.061011.110516</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A-posteriori probability (APP) receivers operating over multiple-input,
multiple-output channels provide enhanced bit error rate (BER) performance at
the cost of increased complexity. However, employing full APP processing over
favorable transmission environments, where less efficient approaches may
already provide the required performance at a reduced complexity, results in
unnecessary processing. For slowly varying channel statistics substantial
complexity savings can be achieved by simple adaptive schemes. Such schemes
track the BER performance and adjust the complexity of the soft output sphere
decoder by adaptively setting the related log-likelihood ratio (LLR) clipping
value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2115</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2115</id><created>2010-11-09</created><updated>2012-01-23</updated><authors><author><keyname>Awan</keyname><forenames>Zohaib Hassan</forenames></author><author><keyname>Zaidi</keyname><forenames>Abdellatif</forenames></author><author><keyname>Vandendorpe</keyname><forenames>Luc</forenames></author></authors><title>Secure Communication over Parallel Relay Channel</title><categories>cs.IT math.IT</categories><comments>To Appear in IEEE Transactions on Information Forensics and Security</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the problem of secure communication over parallel relay
channel in the presence of a passive eavesdropper. We consider a four terminal
relay-eavesdropper channel which consists of multiple relay-eavesdropper
channels as subchannels. For the discrete memoryless model, we establish outer
and inner bounds on the rate-equivocation region. The inner bound allows mode
selection at the relay. For each subchannel, secure transmission is obtained
through one of two coding schemes at the relay: decoding-and-forwarding the
source message or confusing the eavesdropper through noise injection. For the
Gaussian memoryless channel, we establish lower and upper bounds on the perfect
secrecy rate. Furthermore, we study a special case in which the relay does not
hear the source and show that under certain conditions the lower and upper
bounds coincide. The results established for the parallel Gaussian
relay-eavesdropper channel are then applied to study the fading
relay-eavesdropper channel. Analytical results are illustrated through some
numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2121</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2121</id><created>2010-11-09</created><updated>2010-11-17</updated><authors><author><keyname>Ashlagi</keyname><forenames>Itai</forenames></author><author><keyname>Braverman</keyname><forenames>Mark</forenames></author><author><keyname>Hassidim</keyname><forenames>Avinatan</forenames></author></authors><title>Matching with Couples Revisited</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that a stable matching in a many-to-one matching market with
couples need not exist. We introduce a new matching algorithm for such markets
and show that for a general class of large random markets the algorithm will
find a stable matching with high probability. In particular we allow the number
of couples to grow at a near-linear rate. Furthermore, truth-telling is an
approximated equilibrium in the game induced by the new matching algorithm. Our
results are tight: for markets in which the number of couples grows at a linear
rate, we show that with constant probability no stable matching exists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2136</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2136</id><created>2010-11-09</created><authors><author><keyname>Adler</keyname><forenames>Isolde</forenames></author><author><keyname>Krause</keyname><forenames>Philipp Klaus</forenames></author></authors><title>A lower bound for the tree-width of planar graphs with vital linkages</title><categories>cs.DS cs.DM</categories><comments>9 pages, 9 figures</comments><acm-class>G.2.2; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The disjoint paths problem asks, given an graph G and k + 1 pairs of
terminals (s_0,t_0), ...,(s_k,t_k), whether there are k+1 pairwise disjoint
paths P_0, ...,P_k, such that P_i connects s_i to t_i. Robertson and Seymour
have proven that the problem can be solved in polynomial time if k is fixed.
Nevertheless, the constants involved are huge, and the algorithm is far from
implementable. The algorithm uses a bound on the tree-width of graphs with
vital linkages, and deletion of irrelevant vertices. We give single exponential
lower bounds both for the tree-width of planar graphs with vital linkages, and
for the size of the grid necessary for finding irrelevant vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2152</identifier>
 <datestamp>2011-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2152</id><created>2010-11-09</created><updated>2011-03-03</updated><authors><author><keyname>Fraigniaud</keyname><forenames>Pierre</forenames></author><author><keyname>Korman</keyname><forenames>Amos</forenames></author><author><keyname>Peleg</keyname><forenames>David</forenames></author></authors><title>Local Distributed Decision</title><categories>cs.DC cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A central theme in distributed network algorithms concerns understanding and
coping with the issue of locality. Inspired by sequential complexity theory, we
focus on a complexity theory for distributed decision problems. In the context
of locality, solving a decision problem requires the processors to
independently inspect their local neighborhoods and then collectively decide
whether a given global input instance belongs to some specified language. This
paper introduces several classes of distributed decision problems, proves
separation among them and presents some complete problems. More specifically,
we consider the standard LOCAL model of computation and define LD (for local
decision) as the class of decision problems that can be solved in constant
number of communication rounds. We first study the intriguing question of
whether randomization helps in local distributed computing, and to what extent.
Specifically, we define the corresponding randomized class BPLD, and ask
whether LD=BPLD. We provide a partial answer to this question by showing that
in many cases, randomization does not help for deciding hereditary languages.
In addition, we define the notion of local many-one reductions, and introduce
the (nondeterministic) class NLD of decision problems for which there exists a
certificate that can be verified in constant number of communication rounds. We
prove that there exists an NLD-complete problem. We also show that there exist
problems not in NLD. On the other hand, we prove that the class NLD#n, which is
NLD assuming that each processor can access an oracle that provides the number
of nodes in the network, contains all (decidable) languages. For this class we
provide a natural complete problem as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2159</identifier>
 <datestamp>2012-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2159</id><created>2010-11-09</created><authors><author><keyname>Saeedi</keyname><forenames>Mehdi</forenames><affiliation>The first two authors contributed equally to this work</affiliation></author><author><keyname>Arabzadeh</keyname><forenames>Mona</forenames><affiliation>The first two authors contributed equally to this work</affiliation></author><author><keyname>Zamani</keyname><forenames>Morteza Saheb</forenames><affiliation>The first two authors contributed equally to this work</affiliation></author><author><keyname>Sedighi</keyname><forenames>Mehdi</forenames><affiliation>The first two authors contributed equally to this work</affiliation></author></authors><title>Block-based quantum-logic synthesis</title><categories>quant-ph cs.ET</categories><comments>15 pages, 8 figures, 5 tables, Quantum Information and Computation
  (QIC) Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the problem of constructing an efficient quantum circuit for
the implementation of an arbitrary quantum computation is addressed. To this
end, a basic block based on the cosine-sine decomposition method is suggested
which contains $l$ qubits. In addition, a previously proposed quantum-logic
synthesis method based on quantum Shannon decomposition is recursively applied
to reach unitary gates over $l$ qubits. Then, the basic block is used and some
optimizations are applied to remove redundant gates. It is shown that the exact
value of $l$ affects the number of one-qubit and CNOT gates in the proposed
method. In comparison to the previous synthesis methods, the value of $l$ is
examined consequently to improve either the number of CNOT gates or the total
number of gates. The proposed approach is further analyzed by considering the
nearest neighbor limitation. According to our evaluation, the number of CNOT
gates is increased by at most a factor of $\frac{5}{3}$ if the nearest neighbor
interaction is applied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2163</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2163</id><created>2010-11-09</created><authors><author><keyname>Bose</keyname><forenames>Debayan</forenames></author></authors><title>Component Based Development</title><categories>cs.SE</categories><comments>25 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Component Based Approach has been introduced in core engineering discipline
long back but the introduction to component based concept in software
perspective is recently developed by Object Management Group. Its benefits from
the re-usability point of view is enormous. The intertwining relationship of
domain engineering with component based software engineering is analyzed. The
object oriented approach and its basic difference with component approach is of
great concern. The present study highlights the life-cycle, cost effectiveness
and the basic study of component based software from application perspective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2173</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2173</id><created>2010-11-09</created><updated>2011-08-25</updated><authors><author><keyname>Abraham</keyname><forenames>Sheelu</forenames></author><author><keyname>Philip</keyname><forenames>Ninan Sajeeth</forenames></author><author><keyname>Kembhavi</keyname><forenames>Ajit</forenames></author><author><keyname>Wadadekar</keyname><forenames>Yogesh G</forenames></author><author><keyname>Sinha</keyname><forenames>Rita</forenames></author></authors><title>Photometric Catalogue of Quasars and Other Point Sources in the Sloan
  Digital Sky Survey</title><categories>astro-ph.IM cs.AI</categories><comments>16 pages, Ref. No. MN-10-2382-MJ.R2, accepted for publication in
  MNRAS Main Journal, April 2011</comments><doi>10.1111/j.1365-2966.2011.19674.x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a catalogue of about 6 million unresolved photometric detections
in the Sloan Digital Sky Survey Seventh Data Release classifying them into
stars, galaxies and quasars. We use a machine learning classifier trained on a
subset of spectroscopically confirmed objects from 14th to 22nd magnitude in
the SDSS {\it i}-band. Our catalogue consists of 2,430,625 quasars, 3,544,036
stars and 63,586 unresolved galaxies from 14th to 24th magnitude in the SDSS
{\it i}-band. Our algorithm recovers 99.96% of spectroscopically confirmed
quasars and 99.51% of stars to i $\sim$21.3 in the colour window that we study.
The level of contamination due to data artefacts for objects beyond $i=21.3$ is
highly uncertain and all mention of completeness and contamination in the paper
are valid only for objects brighter than this magnitude. However, a comparison
of the predicted number of quasars with the theoretical number counts shows
reasonable agreement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2178</identifier>
 <datestamp>2011-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2178</id><created>2010-11-09</created><updated>2011-06-16</updated><authors><author><keyname>Gebauer</keyname><forenames>Heidi</forenames></author></authors><title>Maker Can Construct a Sparse Graph on a Small Board</title><categories>math.CO cs.DM</categories><comments>7 pages</comments><acm-class>G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study Maker/Breaker games on the edges of sparse graphs. Maker and Breaker
take turns in claiming previously unclaimed edges of a given graph H. Maker
aims to occupy a given target graph G and Breaker tries to prevent Maker from
achieving his goal. We define a function f and show that for every d-regular
graph G on n vertices there is a graph H with at most f(d)n edges such that
Maker can occupy a copy of G in the game on H.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2180</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2180</id><created>2010-11-09</created><authors><author><keyname>Burnashev</keyname><forenames>M. V.</forenames></author><author><keyname>Yamamoto</keyname><forenames>H.</forenames></author></authors><title>On Reliability Function of BSC with Noisy Feedback</title><categories>cs.IT math.IT</categories><comments>24 pages, 4 figures</comments><journal-ref>published in Problems of Inform. Transm. vol. 46, no. 2, pp.
  3--23, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For information transmission a binary symmetric channel is used. There is
also another noisy binary symmetric channel (feedback channel), and the
transmitter observes without delay all the outputs of the forward channel via
that feedback channel. The transmission of an exponential number of messages
(i.e. the transmission rate is positive) is considered. The achievable decoding
error exponent for such a combination of channels is investigated. It is shown
that if the crossover probability of the feedback channel is less than a
certain positive value, then the achievable error exponent is better than the
decoding error exponent of the channel without feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2187</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2187</id><created>2010-11-09</created><authors><author><keyname>Fox</keyname><forenames>Kyle</forenames></author><author><keyname>Moseley</keyname><forenames>Benjamin</forenames></author></authors><title>Online Scheduling on Identical Machines using SRPT</title><categories>cs.DS</categories><comments>Accepted for publication at SODA. This version fixes an error in a
  preliminary version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to its optimality on a single machine for the problem of minimizing
average flow time, Shortest-Remaining-Processing-Time (\srpt) appears to be the
most natural algorithm to consider for the problem of minimizing average flow
time on multiple identical machines. It is known that $\srpt$ achieves the best
possible competitive ratio on multiple machines up to a constant factor. Using
resource augmentation, $\srpt$ is known to achieve total flow time at most that
of the optimal solution when given machines of speed $2- \frac{1}{m}$. Further,
it is known that $\srpt$'s competitive ratio improves as the speed increases;
$\srpt$ is $s$-speed $\frac{1}{s}$-competitive when $s \geq 2- \frac{1}{m}$.
  However, a gap has persisted in our understanding of $\srpt$. Before this
work, the performance of $\srpt$ was not known when $\srpt$ is given
$(1+\eps)$-speed when $0 &lt; \eps &lt; 1-\frac{1}{m}$, even though it has been
thought that $\srpt$ is $(1+\eps)$-speed $O(1)$-competitive for over a decade.
Resolving this question was suggested in Open Problem 2.9 from the survey
&quot;Online Scheduling&quot; by Pruhs, Sgall, and Torng \cite{PruhsST}, and we answer
the question in this paper. We show that $\srpt$ is \emph{scalable} on $m$
identical machines. That is, we show $\srpt$ is $(1+\eps)$-speed
$O(\frac{1}{\eps})$-competitive for $\eps &gt;0$. We complement this by showing
that $\srpt$ is $(1+\eps)$-speed $O(\frac{1}{\eps^2})$-competitive for the
objective of minimizing the $\ell_k$-norms of flow time on $m$ identical
machines. Both of our results rely on new potential functions that capture the
structure of \srpt. Our results, combined with previous work, show that $\srpt$
is the best possible online algorithm in essentially every aspect when
migration is permissible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2196</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2196</id><created>2010-11-09</created><authors><author><keyname>Ke</keyname><forenames>Lei</forenames></author><author><keyname>Wang</keyname><forenames>Zhengdao</forenames></author></authors><title>Degrees of Freedom Regions of Two-User MIMO Z and Full Interference
  Channels: The Benefit of Reconfigurable Antennas</title><categories>cs.IT math.IT</categories><comments>32 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the degrees of freedom (DoF) regions of two-user multiple-input
multiple-output (MIMO) Z and full interference channels in this paper. We
assume that the receivers always have perfect channel state information. We
first derive the DoF region of Z interference channel with channel state
information at transmitter (CSIT). For full interference channel without CSIT,
the DoF region has been fully characterized recently and it is shown that the
previously known outer bound is not achievable. In this work, we investigate
the no-CSIT case further by assuming that the transmitter has the ability of
antenna mode switching. We obtain the DoF region as a function of the number of
available antenna modes and reveal the incremental gain in DoF that each extra
antenna mode can bring. It is shown that in certain cases the reconfigurable
antennas can bring extra DoF gains. In these cases, the DoF region is maximized
when the number of modes is at least equal to the number of receive antennas at
the corresponding receiver, in which case the previously outer bound is
achieved. In all cases, we propose systematic constructions of the beamforming
and nulling matrices for achieving the DoF region. The constructions bear an
interesting space-frequency interpretation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2222</identifier>
 <datestamp>2011-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2222</id><created>2010-11-09</created><updated>2010-12-06</updated><authors><author><keyname>Khor</keyname><forenames>Susan</forenames></author></authors><title>Static and dynamic characteristics of protein contact networks</title><categories>cs.CE cs.SI physics.bio-ph q-bio.BM</categories><comments>Added Appendix B</comments><doi>10.1007/s12064-011-0135-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The principles underlying protein folding remains one of Nature's puzzles
with important practical consequences for Life. An approach that has gathered
momentum since the late 1990's, looks at protein hetero-polymers and their
folding process through the lens of complex network analysis. Consequently,
there is now a body of empirical studies describing topological characteristics
of protein macro-molecules through their contact networks and linking these
topological characteristics to protein folding. The present paper is primarily
a review of this rich area. But it delves deeper into certain aspects by
emphasizing short-range and long-range links, and suggests unconventional
places where &quot;power-laws&quot; may be lurking within protein contact networks.
Further, it considers the dynamical view of protein contact networks. This
closer scrutiny of protein contact networks raises new questions for further
research, and identifies new regularities which may be useful to parameterize a
network approach to protein folding. Preliminary experiments with such a model
confirm that the regularities we identified cannot be easily reproduced through
random effects. Indeed, the grand challenge of protein folding is to elucidate
the process(es) which not only generates the specific and diverse linkage
patterns of protein contact networks, but also reproduces the dynamic behavior
of proteins as they fold. Keywords: network analysis, protein contact networks,
protein folding
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2235</identifier>
 <datestamp>2012-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2235</id><created>2010-11-09</created><updated>2012-02-27</updated><authors><author><keyname>Tsianos</keyname><forenames>Konstantinos I.</forenames></author><author><keyname>Rabbat</keyname><forenames>Michael G.</forenames></author></authors><title>Multiscale Gossip for Efficient Decentralized Averaging in Wireless
  Packet Networks</title><categories>cs.DC</categories><comments>(under Review)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes and analyzes a hierarchical gossip algorithm for solving
the distributed average consensus problem in wireless sensor networks. The
network is recursively partitioned into subnetworks. Initially, nodes at the
finest scale gossip to compute local averages. Then, using geographic routing
to enable gossip between nodes that are not directly connected, these local
averages are progressively fused up the hierarchy until the global average is
computed. We show that the proposed hierarchical scheme with $k$ levels of
hierarchy is competitive with state-of-the-art randomized gossip algorithms, in
terms of message complexity, achieving $\epsilon$-accuracy with high
probability after $O\big(n \log \log n \log \frac{kn}{\epsilon} \big)$
messages. Key to our analysis is the way in which the network is recursively
partitioned. We find that the optimal scaling law is achieved when subnetworks
at scale $j$ contain $O(n^{(2/3)^j})$ nodes; then the message complexity at any
individual scale is $O(n \log \frac{kn}{\epsilon})$, and the total number of
scales in the hierarchy grows slowly, as $\Theta(\log \log n)$. Another
important consequence of hierarchical construction is that the longest distance
over which messages are exchanged is $O(n^{1/3})$ hops (at the highest scale),
and most messages (at lower scales) travel shorter distances. In networks that
use link-level acknowledgements, this results in less congestion and resource
usage by reducing message retransmissions. Simulations illustrate that the
proposed scheme is more message-efficient than existing state-of-the-art
randomized gossip algorithms based on averaging along paths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2238</identifier>
 <datestamp>2010-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2238</id><created>2010-11-09</created><authors><author><keyname>de Carvalho</keyname><forenames>Rogerio Atem</forenames></author><author><keyname>Manhaes</keyname><forenames>Rodrigo Soares</forenames></author><author><keyname>Silva</keyname><forenames>Fernando Luiz de Carvalho e</forenames></author></authors><title>Introducing Business Language Driven Development</title><categories>cs.SE</categories><comments>17 pages, 10 figures, original work</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A classical problem in Software Engineering is how to certify that every
system requirement is correctly implemented by source code. This problem,
albeit well studied, can still be considered an open one, given the problems
faced by software development organizations. Trying to solve this problem,
Behavior-Driven Development (BDD) is a specification technique that
automatically certifies that all functional requirements are treated properly
by source code, through the connection of the textual description of these
requirements to automated tests. However, in some areas, such as Enterprise
Information Systems, requirements are identified by Business Process Modeling -
which uses graphical notations of the underlying business processes. Therefore,
the aim of this paper is to present Business Language Driven Development
(BLDD), a method that aims to extend BDD, by connecting business process models
directly to source code, while keeping the expressiveness of text descriptions
when they are better fitted than graphical artifacts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2245</identifier>
 <datestamp>2010-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2245</id><created>2010-11-09</created><authors><author><keyname>Jamali</keyname><forenames>Mohsen</forenames></author></authors><title>A Distributed Method for Trust-Aware Recommendation in Social Networks</title><categories>cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper contains the details of a distributed trust-aware recommendation
system. Trust-base recommenders have received a lot of attention recently. The
main aim of trust-based recommendation is to deal the problems in traditional
Collaborative Filtering recommenders. These problems include cold start users,
vulnerability to attacks, etc.. Our proposed method is a distributed approach
and can be easily deployed on social networks or real life networks such as
sensor networks or peer to peer networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2246</identifier>
 <datestamp>2010-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2246</id><created>2010-11-09</created><authors><author><keyname>Zahedpour</keyname><forenames>Sina</forenames></author><author><keyname>Kalantari</keyname><forenames>Mehdi</forenames></author></authors><title>p-Norm Flow Optimization in a Network</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study information flow paths in a data network, where
traffic generated by servers (or sources) takes a multi-hop path in order to
reach its clients (destinations). Each node in the middle of this multi-hop
path should route the incoming traffic and the traffic generated by itself to
the next hop in such a way that the traffic reaches its destination while
avoiding congestion in the links. For simplicity, we will assume the network
only carries single commodity traffic, i.e., all of the traffic should be
routed to a single destination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2249</identifier>
 <datestamp>2010-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2249</id><created>2010-11-09</created><authors><author><keyname>Moitra</keyname><forenames>Ankur</forenames></author><author><keyname>O'Donnell</keyname><forenames>Ryan</forenames></author></authors><title>Pareto Optimal Solutions for Smoothed Analysts</title><categories>cs.DS</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider an optimization problem with $n$ binary variables and $d+1$ linear
objective functions. Each valid solution $x \in \{0,1\}^n$ gives rise to an
objective vector in $\R^{d+1}$, and one often wants to enumerate the Pareto
optima among them. In the worst case there may be exponentially many Pareto
optima; however, it was recently shown that in (a generalization of) the
smoothed analysis framework, the expected number is polynomial in $n$.
Unfortunately, the bound obtained had a rather bad dependence on $d$; roughly
$n^{d^d}$. In this paper we show a significantly improved bound of $n^{2d}$.
  Our proof is based on analyzing two algorithms. The first algorithm, on input
a Pareto optimal $x$, outputs a &quot;testimony&quot; containing clues about $x$'s
objective vector, $x$'s coordinates, and the region of space $B$ in which $x$'s
objective vector lies. The second algorithm can be regarded as a {\em
speculative} execution of the first -- it can uniquely reconstruct $x$ from the
testimony's clues and just \emph{some} of the probability space's outcomes. The
remainder of the probability space's outcomes are just enough to bound the
probability that $x$'s objective vector falls into the region $B$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2258</identifier>
 <datestamp>2010-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2258</id><created>2010-11-09</created><updated>2010-12-16</updated><authors><author><keyname>MacPherson</keyname><forenames>Robert</forenames></author><author><keyname>Schweinhart</keyname><forenames>Benjamin</forenames></author></authors><title>Measuring Shape with Topology</title><categories>math.AT cond-mat.mtrl-sci cs.CG math-ph math.MP</categories><comments>19 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a measure of shape which is appropriate for the study of a
complicated geometric structure, defined using the topology of neighborhoods of
the structure. One aspect of this measure gives a new notion of fractal
dimension. We demonstrate the utility and computability of this measure by
applying it to branched polymers, Brownian trees, and self-avoiding random
walks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2269</identifier>
 <datestamp>2010-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2269</id><created>2010-11-09</created><authors><author><keyname>Shao</keyname><forenames>Xingguo</forenames></author><author><keyname>Wang</keyname><forenames>Qingguo</forenames></author><author><keyname>Chen</keyname><forenames>Peter C Y</forenames></author><author><keyname>Zhu</keyname><forenames>Zhencai</forenames></author><author><keyname>Zi</keyname><forenames>Bin</forenames></author></authors><title>Forward Kinematics Analysis and Tension Distribution of a Cable-Driven
  Sinking Winches Mechanism</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper concerns the forward kinematics and tension distribution of
sinking winches mechanism, which is a type of four-cable-driven partly
constrained parallel robot. Conventional studies on forward kinematics of
cable-driven parallel robot assumed that all cables are taut. Actually, given
the lengths of four cables, some cables may be slack when the platform is in
static equilibrium. Therefore, in this paper, the tension state (tautness or
slackness) of cables is considered in the forward kinematics model. We propose
Traversal-Solving-Algorithm, which can indicate the tension state of cables,
and further determine the pose of the platform, if the lengths of four cables
are given. The effectiveness of the algorithm is verified by four examples. The
results of this paper can be used to control sinking winches mechanism to
achieve the level and stable motion of the platform, and to make the tension
distribution of cables as uniform as possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2272</identifier>
 <datestamp>2010-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2272</id><created>2010-11-09</created><authors><author><keyname>Reji</keyname><forenames>A. P.</forenames></author><author><keyname>Tessamma</keyname><forenames>Thomas</forenames></author></authors><title>Single Frame Image super Resolution using Learned Directionlets</title><categories>cs.CV</categories><comments>14 pages,6 figures</comments><journal-ref>International Journal of Artificial Intelligence &amp; Applications
  (IJAIA), Vol.1, No.4, October 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new directionally adaptive, learning based, single image
super resolution method using multiple direction wavelet transform, called
Directionlets is presented. This method uses directionlets to effectively
capture directional features and to extract edge information along different
directions of a set of available high resolution images .This information is
used as the training set for super resolving a low resolution input image and
the Directionlet coefficients at finer scales of its high-resolution image are
learned locally from this training set and the inverse Directionlet transform
recovers the super-resolved high resolution image. The simulation results
showed that the proposed approach outperforms standard interpolation techniques
like Cubic spline interpolation as well as standard Wavelet-based learning,
both visually and in terms of the mean squared error (mse) values. This method
gives good result with aliased images also.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2292</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2292</id><created>2010-11-10</created><updated>2011-05-23</updated><authors><author><keyname>Ameur</keyname><forenames>Hend Ben</forenames><affiliation>LAMSIN, INRIA Rocquencourt</affiliation></author><author><keyname>Chavent</keyname><forenames>Guy</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Cl&#xe9;ment</keyname><forenames>Francois</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Weis</keyname><forenames>Pierre</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Image Segmentation with Multidimensional Refinement Indicators</title><categories>math.NA cs.CV</categories><proxy>ccsd</proxy><report-no>RR-7446, RR-7446</report-no><journal-ref>N&amp;deg; RR-7446 (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We transpose an optimal control technique to the image segmentation problem.
The idea is to consider image segmentation as a parameter estimation problem.
The parameter to estimate is the color of the pixels of the image. We use the
adaptive parameterization technique which builds iteratively an optimal
representation of the parameter into uniform regions that form a partition of
the domain, hence corresponding to a segmentation of the image. We minimize an
error function during the iterations, and the partition of the image into
regions is optimally driven by the gradient of this error. The resulting
segmentation algorithm inherits desirable properties from its optimal control
origin: soundness, robustness, and flexibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2304</identifier>
 <datestamp>2010-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2304</id><created>2010-11-10</created><authors><author><keyname>Nowakowski</keyname><forenames>Samuel</forenames><affiliation>LORIA</affiliation></author><author><keyname>Bernier</keyname><forenames>C&#xe9;dric</forenames><affiliation>LORIA</affiliation></author><author><keyname>Boyer</keyname><forenames>Anne</forenames><affiliation>LORIA</affiliation></author></authors><title>Target tracking in the recommender space: Toward a new recommender
  system based on Kalman filtering</title><categories>cs.AI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new approach for recommender systems based on
target tracking by Kalman filtering. We assume that users and their seen
resources are vectors in the multidimensional space of the categories of the
resources. Knowing this space, we propose an algorithm based on a Kalman filter
to track users and to predict the best prediction of their future position in
the recommendation space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2306</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2306</id><created>2010-11-10</created><updated>2010-11-19</updated><authors><author><keyname>Karawia</keyname><forenames>A. A.</forenames></author></authors><title>A New Algorithm for Inverting General Cyclic Heptadiagonal Matrices
  Recursively</title><categories>cs.SC cs.NA math.NA</categories><comments>10 pages</comments><msc-class>15A15, 15A23, 68W30, 11Y05, 33F10, F.2.1, G.1.0</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we describe a reliable symbolic computational algorithm for
inverting general cyclic heptadiagonal matrices by using parallel computing
along with recursion. The algorithm is implementable to the Computer Algebra
System(CAS) such as MAPLE, Matlab and Mathematica . An example is presented for
the sake of illustration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2307</identifier>
 <datestamp>2010-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2307</id><created>2010-11-10</created><authors><author><keyname>Giulio</keyname><forenames>Manzonetto</forenames><affiliation>CS</affiliation></author></authors><title>What is a categorical model of the differential and the resource
  lambda-calculi?</title><categories>cs.LO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we provide an abstract model theory for the untyped
differential lambda-calculus and the resource calculus. In particular we
propose a general definition of model of these calculi, namely the notion of
linear reflexive object in a Cartesian closed differential category. Examples
of models based on relations are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2312</identifier>
 <datestamp>2010-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2312</id><created>2010-11-10</created><authors><author><keyname>Anceaume</keyname><forenames>Emmanuelle</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>D&#xe9;fago</keyname><forenames>Xavier</forenames><affiliation>JAIST</affiliation></author><author><keyname>Potop-Butucaru</keyname><forenames>Maria</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Roy</keyname><forenames>Matthieu</forenames><affiliation>LAAS</affiliation></author></authors><title>A framework for proving the self-organization of dynamic systems</title><categories>cs.DC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper aims at providing a rigorous definition of self- organization, one
of the most desired properties for dynamic systems (e.g., peer-to-peer systems,
sensor networks, cooperative robotics, or ad-hoc networks). We characterize
different classes of self-organization through liveness and safety properties
that both capture information re- garding the system entropy. We illustrate
these classes through study cases. The first ones are two representative P2P
overlays (CAN and Pas- try) and the others are specific implementations of
\Omega (the leader oracle) and one-shot query abstractions for dynamic
settings. Our study aims at understanding the limits and respective power of
existing self-organized protocols and lays the basis of designing robust
algorithm for dynamic systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2313</identifier>
 <datestamp>2011-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2313</id><created>2010-11-10</created><updated>2011-05-09</updated><authors><author><keyname>Wang</keyname><forenames>Jun</forenames></author><author><keyname>Urriza</keyname><forenames>Paulo</forenames></author><author><keyname>Han</keyname><forenames>Yuxing</forenames></author><author><keyname>&#x10c;abri&#x107;</keyname><forenames>Danijela</forenames></author></authors><title>Weighted Centroid Algorithm for Estimating Primary User Location:
  Theoretical Analysis and Distributed Implementation</title><categories>cs.PF cs.IT cs.NI math.IT</categories><comments>24 pages, 10 figures, resubmitted with major revisions to IEEE
  Transactions on Wireless Communications</comments><doi>10.1109/TWC.2011.11.102209</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information about primary transmitter location is crucial in enabling several
key capabilities in cognitive radio networks, including improved
spatio-temporal sensing, intelligent location-aware routing, as well as aiding
spectrum policy enforcement. Compared to other proposed non-interactive
localization algorithms, the weighted centroid localization (WCL) scheme uses
only the received signal strength information, which makes it simple to
implement and robust to variations in the propagation environment. In this
paper we present the first theoretical framework for WCL performance analysis
in terms of its localization error distribution parameterized by node density,
node placement, shadowing variance, correlation distance and inaccuracy of
sensor node positioning. Using this analysis, we quantify the robustness of WCL
to various physical conditions and provide design guidelines, such as node
placement and spacing, for the practical deployment of WCL. We also propose a
power-efficient method for implementing WCL through a distributed cluster-based
algorithm, that achieves comparable accuracy with its centralized counterpart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2314</identifier>
 <datestamp>2010-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2314</id><created>2010-11-10</created><authors><author><keyname>Timmer</keyname><forenames>Mark</forenames></author><author><keyname>Stoelinga</keyname><forenames>Mari&#xeb;lle</forenames></author><author><keyname>van de Pol</keyname><forenames>Jaco</forenames></author></authors><title>Confluence Reduction for Probabilistic Systems (extended version)</title><categories>cs.LO cs.DM cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel technique for state space reduction of
probabilistic specifications, based on a newly developed notion of confluence
for probabilistic automata. We prove that this reduction preserves branching
probabilistic bisimulation and can be applied on-the-fly. To support the
technique, we introduce a method for detecting confluent transitions in the
context of a probabilistic process algebra with data, facilitated by an earlier
defined linear format. A case study demonstrates that significant reductions
can be obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2324</identifier>
 <datestamp>2010-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2324</id><created>2010-11-10</created><authors><author><keyname>Argon</keyname><forenames>Oded</forenames></author><author><keyname>Bremler-Barr</keyname><forenames>Anat</forenames></author><author><keyname>Mokryn</keyname><forenames>Osnat</forenames></author><author><keyname>Schirman</keyname><forenames>Dvir</forenames></author><author><keyname>Shavitt</keyname><forenames>Yuval</forenames></author><author><keyname>Weinsberg</keyname><forenames>Udi</forenames></author></authors><title>On the Dynamics of IP Address Allocation and Availability of End-Hosts</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The availability of end-hosts and their assigned routable IP addresses has
impact on the ability to fight spammers and attackers, and on peer-to-peer
application performance. Previous works study the availability of hosts mostly
by using either active pinging or by studying access to a mail service, both
approaches suffer from inherent inaccuracies. We take a different approach by
measuring the IP addresses periodically reported by a uniquely identified group
of the hosts running the DIMES agent. This fresh approach provides a chance to
measure the true availability of end-hosts and the dynamics of their assigned
routable IP addresses. Using a two month study of 1804 hosts, we find that over
60% of the hosts have a fixed IP address and 90% median availability, while
some of the remaining hosts have more than 30 different IPs. For those that
have periodically changing IP addresses, we find that the median average period
per AS is roughly 24 hours, with a strong relation between the offline time and
the probability of altering IP address.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2336</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2336</id><created>2010-11-10</created><authors><author><keyname>Frisco</keyname><forenames>P.</forenames></author></authors><title>A network model with structured nodes</title><categories>cs.SI cs.CE physics.soc-ph q-bio.MN</categories><comments>match MRSA gene network not present because MRSA gene network still
  unpublished</comments><doi>10.1103/PhysRevE.84.021931</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a network model in which words over a specific alphabet, called
{\it structures}, are associated to each node and undirected edges are added
depending on some distance between different structures. It is shown that this
model can generate, without the use of preferential attachment or any other
heuristic, networks with topological features similar to biological networks:
power law degree distribution, clustering coefficient independent from the
network size, etc. Specific biological networks ({\it C. Elegans} neural
network and {\it E. Coli} protein-protein interaction network) are replicated
using this model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2348</identifier>
 <datestamp>2016-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2348</id><created>2010-11-10</created><updated>2011-09-19</updated><authors><author><keyname>Fercoq</keyname><forenames>Olivier</forenames></author><author><keyname>Akian</keyname><forenames>Marianne</forenames></author><author><keyname>Bouhtou</keyname><forenames>Mustapha</forenames></author><author><keyname>Gaubert</keyname><forenames>St&#xe9;phane</forenames></author></authors><title>Ergodic Control and Polyhedral approaches to PageRank Optimization</title><categories>math.OC cs.DS cs.SY</categories><comments>39 pages</comments><msc-class>49N90, 90C06</msc-class><journal-ref>IEEE-TAC, 58(1), pp. 134--148 (2013)</journal-ref><doi>10.1109/TAC.2012.2226103</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a general class of PageRank optimization problems which consist in
finding an optimal outlink strategy for a web site subject to design
constraints. We consider both a continuous problem, in which one can choose the
intensity of a link, and a discrete one, in which in each page, there are
obligatory links, facultative links and forbidden links. We show that the
continuous problem, as well as its discrete variant when there are no
constraints coupling different pages, can both be modeled by constrained Markov
decision processes with ergodic reward, in which the webmaster determines the
transition probabilities of websurfers. Although the number of actions turns
out to be exponential, we show that an associated polytope of transition
measures has a concise representation, from which we deduce that the continuous
problem is solvable in polynomial time, and that the same is true for the
discrete problem when there are no coupling constraints. We also provide
efficient algorithms, adapted to very large networks. Then, we investigate the
qualitative features of optimal outlink strategies, and identify in particular
assumptions under which there exists a &quot;master&quot; page to which all controlled
pages should point. We report numerical results on fragments of the real web
graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2361</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2361</id><created>2010-11-10</created><updated>2010-11-16</updated><authors><author><keyname>Shah</keyname><forenames>Nihar B.</forenames></author><author><keyname>Rashmi</keyname><forenames>K. V.</forenames></author><author><keyname>Kumar</keyname><forenames>P. Vijay</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>Distributed Storage Codes with Repair-by-Transfer and Non-achievability
  of Interior Points on the Storage-Bandwidth Tradeoff</title><categories>cs.IT cs.DC cs.NI math.IT</categories><comments>30 pages, 6 figures. Submitted to IEEE Transactions on Information
  Theory</comments><doi>10.1109/TIT.2011.2173792</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regenerating codes are a class of recently developed codes for distributed
storage that, like Reed-Solomon codes, permit data recovery from any subset of
k nodes within the n-node network. However, regenerating codes possess in
addition, the ability to repair a failed node by connecting to an arbitrary
subset of d nodes. It has been shown that for the case of functional-repair,
there is a tradeoff between the amount of data stored per node and the
bandwidth required to repair a failed node. A special case of functional-repair
is exact-repair where the replacement node is required to store data identical
to that in the failed node. Exact-repair is of interest as it greatly
simplifies system implementation. The first result of the paper is an explicit,
exact-repair code for the point on the storage-bandwidth tradeoff corresponding
to the minimum possible repair bandwidth, for the case when d=n-1. This code
has a particularly simple graphical description and most interestingly, has the
ability to carry out exact-repair through mere transfer of data and without any
need to perform arithmetic operations. Hence the term `repair-by-transfer'. The
second result of this paper shows that the interior points on the
storage-bandwidth tradeoff cannot be achieved under exact-repair, thus pointing
to the existence of a separate tradeoff under exact-repair. Specifically, we
identify a set of scenarios, termed `helper node pooling', and show that it is
the necessity to satisfy such scenarios that over-constrains the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2386</identifier>
 <datestamp>2010-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2386</id><created>2010-11-10</created><authors><author><keyname>Aumueller</keyname><forenames>David</forenames></author></authors><title>Usability Meets Instant Gratification on the Semantic Web</title><categories>cs.OH</categories><comments>Work from the year 2004</comments><acm-class>H.5.3; H.5.4; I.7.1; I.7.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a semantic wiki prototype application named SHAWN [later
WikSAR] that allows structuring concepts within a wiki environment. To entice
the use of Semantic Web technologies applications need to offer both high
usability and instant gratification. Concept creation is exceptionally easy in
SHAWN since metadata as well as plain text is entered within a single edit box
on each wiki page in a self-explaining fashion. The entered data is immediately
used for rendering sophisticated navigational means on the wiki. By editing
simple wiki pages ontologies emerge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2413</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2413</id><created>2010-11-10</created><authors><author><keyname>Dobzinski</keyname><forenames>Shahar</forenames></author><author><keyname>Fu</keyname><forenames>Hu</forenames></author><author><keyname>Kleinberg</keyname><forenames>Robert</forenames></author></authors><title>Optimal Auctions with Correlated Bidders are Easy</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of designing a revenue-maximizing auction for a
single item, when the values of the bidders are drawn from a correlated
distribution. We observe that there exists an algorithm that finds the optimal
randomized mechanism that runs in time polynomial in the size of the support.
We leverage this result to show that in the oracle model introduced by Ronen
and Saberi [FOCS'02], there exists a polynomial time truthful in expectation
mechanism that provides a $(\frac 3 2+\epsilon)$-approximation to the revenue
achievable by an optimal truthful-in-expectation mechanism, and a polynomial
time deterministic truthful mechanism that guarantees $\frac 5 3$ approximation
to the revenue achievable by an optimal deterministic truthful mechanism.
  We show that the $\frac 5 3$-approximation mechanism provides the same
approximation ratio also with respect to the optimal truthful-in-expectation
mechanism. This shows that the performance gap between truthful-in-expectation
and deterministic mechanisms is relatively small. En route, we solve an open
question of Mehta and Vazirani [EC'04].
  Finally, we extend some of our results to the multi-item case, and show how
to compute the optimal truthful-in-expectation mechanisms for bidders with more
complex valuations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2480</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2480</id><created>2010-11-10</created><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author></authors><title>Spin-the-bottle Sort and Annealing Sort: Oblivious Sorting via
  Round-robin Random Comparisons</title><categories>cs.DS</categories><comments>Full version of a paper appearing in ANALCO 2011, in conjunction with
  SODA 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study sorting algorithms based on randomized round-robin comparisons.
Specifically, we study Spin-the-bottle sort, where comparisons are
unrestricted, and Annealing sort, where comparisons are restricted to a
distance bounded by a \emph{temperature} parameter. Both algorithms are simple,
randomized, data-oblivious sorting algorithms, which are useful in
privacy-preserving computations, but, as we show, Annealing sort is much more
efficient. We show that there is an input permutation that causes
Spin-the-bottle sort to require $\Omega(n^2\log n)$ expected time in order to
succeed, and that in $O(n^2\log n)$ time this algorithm succeeds with high
probability for any input. We also show there is an implementation of Annealing
sort that runs in $O(n\log n)$ time and succeeds with very high probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2488</identifier>
 <datestamp>2010-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2488</id><created>2010-11-09</created><authors><author><keyname>Bartocci</keyname><forenames>Ezio</forenames></author><author><keyname>Cacciagrano</keyname><forenames>Diletta Romana</forenames></author><author><keyname>Di Berardini</keyname><forenames>Maria Rita</forenames></author><author><keyname>Merelli</keyname><forenames>Emanuela</forenames></author><author><keyname>Tesei</keyname><forenames>Luca</forenames></author></authors><title>Shape Calculus: Timed Operational Semantics and Well-formedness</title><categories>cs.PL cs.CE cs.CG</categories><comments>42 pages, 4 figures, extended version of Bartocci, E.; Cacciagrano,
  D. R.; Di Berardini, M. R.; Merelli, E. &amp; Tesei, L. Timed Operational
  Semantics and Well-formedness of Shape Calculus. Scientific Annals of
  Computer Science, 20, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Shape Calculus is a bio-inspired calculus for describing 3D shapes moving
in a space. A shape forms a 3D process when combined with a behaviour.
Behaviours are specified with a timed CCS-like process algebra using a notion
of channel that models naturally binding sites on the surface of shapes.
Processes can represent molecules or other mobile objects and can be part of
networks of processes that move simultaneously and interact in a given
geometrical space. The calculus embeds collision detection and response,
binding of compatible 3D processes and splitting of previously established
bonds. In this work the full formal timed operational semantics of the calculus
is provided, together with examples that illustrate the use of the calculus in
a well-known biological scenario. Moreover, a result of well-formedness about
the evolution of a given network of well-formed 3D processes is proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2511</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2511</id><created>2010-11-10</created><authors><author><keyname>Cormode</keyname><forenames>Graham</forenames></author></authors><title>Individual Privacy vs Population Privacy: Learning to Attack
  Anonymization</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the last decade there have been great strides made in developing
techniques to compute functions privately. In particular, Differential Privacy
gives strong promises about conclusions that can be drawn about an individual.
In contrast, various syntactic methods for providing privacy (criteria such as
kanonymity and l-diversity) have been criticized for still allowing private
information of an individual to be inferred. In this report, we consider the
ability of an attacker to use data meeting privacy definitions to build an
accurate classifier. We demonstrate that even under Differential Privacy, such
classifiers can be used to accurately infer &quot;private&quot; attributes in realistic
data. We compare this to similar approaches for inferencebased attacks on other
forms of anonymized data. We place these attacks on the same scale, and observe
that the accuracy of inference of private attributes for Differentially Private
data and l-diverse data can be quite similar.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2512</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2512</id><created>2010-11-10</created><updated>2011-01-17</updated><authors><author><keyname>Kiaei</keyname><forenames>Ali Akbar</forenames></author><author><keyname>Shouraki</keyname><forenames>Saeed Bagheri</forenames></author><author><keyname>Khasteh</keyname><forenames>Seyed Hossein</forenames></author><author><keyname>Khademi</keyname><forenames>Mahmoud</forenames></author><author><keyname>Samani</keyname><forenames>Alireza Ghatreh</forenames></author></authors><title>Extended Active Learning Method</title><categories>cs.AI</categories><comments>18 pages, 26 figures, 2 tables, submitted to the control engineering
  practice of Elsevier</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Active Learning Method (ALM) is a soft computing method which is used for
modeling and control, based on fuzzy logic. Although ALM has shown that it acts
well in dynamic environments, its operators cannot support it very well in
complex situations due to losing data. Thus ALM can find better membership
functions if more appropriate operators be chosen for it. This paper
substituted two new operators instead of ALM original ones; which consequently
renewed finding membership functions in a way superior to conventional ALM.
This new method is called Extended Active Learning Method (EALM).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2515</identifier>
 <datestamp>2010-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2515</id><created>2010-11-10</created><authors><author><keyname>Mani</keyname><forenames>Ankur</forenames><affiliation>Sandy</affiliation></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames><affiliation>Sandy</affiliation></author><author><keyname>Alex</keyname><affiliation>Sandy</affiliation></author><author><keyname>Pentland</keyname></author></authors><title>Existence of Stable Exclusive Bilateral Exchanges in Networks</title><categories>cs.GT cs.SI</categories><acm-class>J.4; G.1.6; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we show that when individuals in a bipartite network
exclusively choose partners and exchange valued goods with their partners, then
there exists a set of exchanges that are pair-wise stable. Pair-wise stability
implies that no individual breaks her partnership and no two neighbors in the
network can form a new partnership while breaking other partnerships if any so
that at least one of them improves her payoff and the other one does at least
as good. We consider a general class of continuous, strictly convex and
strongly monotone preferences over bundles of goods for individuals. Thus, this
work extends the general equilibrium framework from markets to networks with
exclusive exchanges. We present the complete existence proof using the
existence of a generalized stable matching in
\cite{Generalized-Stable-Matching}. The existence proof can be extended to
problems in social games as in \cite{Matching-Equilibrium} and
\cite{Social-Games}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2531</identifier>
 <datestamp>2010-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2531</id><created>2010-11-10</created><authors><author><keyname>Abe</keyname><forenames>Hiroshi</forenames></author></authors><title>A Stable Explicit Scheme for Solving Inhomogeneous Constant Coefficients
  Differential Equation using Green's Function</title><categories>cs.NA</categories><comments>15 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A numerical explicit method to evaluates transient solutions of linear
partial differential inhomogeneous equation with constant coefficients is
proposed. A general form of the scheme for a specific linear inhomogeneous
equation is shown. The method is applied to the wave equation and the diffuse
equation and is investigated by simulating simple models. The numerical
solutions of the proposed method show good agreement to the exact solutions.
Comparing with explicit FDM, FDM shows the instability by the violation of CFL
condition whereas the proposed method is always stable irrespective of any time
step width.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2538</identifier>
 <datestamp>2010-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2538</id><created>2010-11-10</created><authors><author><keyname>Carter</keyname><forenames>Scott</forenames></author><author><keyname>Denoue</keyname><forenames>Laurent</forenames></author><author><keyname>Adcock</keyname><forenames>John</forenames></author></authors><title>mVideoCast: Mobile, real time ROI detection and streaming</title><categories>cs.HC</categories><report-no>FXPAL-TR-10-003</report-no><acm-class>H.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A variety of applications are emerging to support streaming video from mobile
devices. However, many tasks can benefit from streaming specific content rather
than the full video feed which may include irrelevant, private, or distracting
content. We describe a system that allows users to capture and stream targeted
video content captured with a mobile device. The application incorporates a
variety of automatic and interactive techniques to identify and segment desired
content in the camera view, allowing the user to publish a more focused video.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2551</identifier>
 <datestamp>2010-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2551</id><created>2010-11-10</created><authors><author><keyname>Li</keyname><forenames>Xin</forenames></author></authors><title>On the Problem of Local Randomness in Privacy Amplification with an
  Active Adversary</title><categories>cs.CC cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of privacy amplification with an active adversary in the
information theoretic setting. In this setting, two parties Alice and Bob start
out with a shared $n$-bit weak random string $W$, and try to agree on a secret
random key $R$ over a public channel fully controlled by an active and
unbounded adversary. Typical assumptions are that these two parties have access
to local private uniform random bits. In this paper we seek to minimize the
requirements on the local randomness used by the two parties.
  We make two improvements over previous results. First, we reduce the number
of random bits needed for each party to $\Theta(\ell+\log n)$, where $\ell$ is
the security parameter, as long as $W$ has min-entropy $n^{\Omega(1)}$.
Previously, the best known result needs to use $\Theta((\ell+\log n)\log n)$
bits. Our result is also asymptotically optimal. Second, we generalize the
problem to the case where the two parties only have local weak random sources
instead of truly uniform random bits. We show that when each party has a local
weak random source with min-entropy $&gt; n/2$, there is an efficient privacy
amplification protocol that works nearly as good as if the two parties have
access to local uniform random bits. Next, in the case where each party only
has a weak random source with arbitrarily linear min-entropy, we give an
efficient privacy amplification protocol where we can achieve security
parameter up to $\Omega(\log k)$. Our results give the first protocols that
achieve privacy amplification when each party only has access to a local weak
random source.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2560</identifier>
 <datestamp>2010-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2560</id><created>2010-11-11</created><authors><author><keyname>Chaudhuri</keyname><forenames>Kaustuv</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Doligez</keyname><forenames>Damien</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Lamport</keyname><forenames>Leslie</forenames><affiliation>INRIA Lorraine</affiliation></author><author><keyname>Merz</keyname><forenames>Stephan</forenames><affiliation>INRIA Lorraine</affiliation></author></authors><title>Verifying Safety Properties With the TLA+ Proof System</title><categories>cs.LO</categories><proxy>ccsd</proxy><journal-ref>Fifth International Joint Conference on Automated Reasoning
  (IJCAR), Edinburgh : United Kingdom (2010)</journal-ref><doi>10.1007/978-3-642-14203-1_12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  TLAPS, the TLA+ proof system, is a platform for the development and
mechanical verification of TLA+ proofs written in a declarative style requiring
little background beyond elementary mathematics. The language supports
hierarchical and non-linear proof construction and verification, and it is
independent of any verification tool or strategy. A Proof Manager uses backend
verifiers such as theorem provers, proof assistants, SMT solvers, and decision
procedures to check TLA+ proofs. This paper documents the first public release
of TLAPS, distributed with a BSD-like license. It handles almost all the
non-temporal part of TLA+ as well as the temporal reasoning needed to prove
standard safety properties, in particular invariance and step simulation, but
not liveness properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2571</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2571</id><created>2010-11-11</created><authors><author><keyname>Braverman</keyname><forenames>Vladimir</forenames></author><author><keyname>Ostrovsky</keyname><forenames>Rafail</forenames></author></authors><title>Recursive Sketching For Frequency Moments</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a ground-breaking paper, Indyk and Woodruff (STOC 05) showed how to
compute $F_k$ (for $k&gt;2$) in space complexity $O(\mbox{\em poly-log}(n,m)\cdot
n^{1-\frac2k})$, which is optimal up to (large) poly-logarithmic factors in $n$
and $m$, where $m$ is the length of the stream and $n$ is the upper bound on
the number of distinct elements in a stream. The best known lower bound for
large moments is $\Omega(\log(n)n^{1-\frac2k})$. A follow-up work of
Bhuvanagiri, Ganguly, Kesh and Saha (SODA 2006) reduced the poly-logarithmic
factors of Indyk and Woodruff to $O(\log^2(m)\cdot (\log n+ \log m)\cdot
n^{1-{2\over k}})$. Further reduction of poly-log factors has been an elusive
goal since 2006, when Indyk and Woodruff method seemed to hit a natural
&quot;barrier.&quot; Using our simple recursive sketch, we provide a different yet simple
approach to obtain a $O(\log(m)\log(nm)\cdot (\log\log n)^4\cdot n^{1-{2\over
k}})$ algorithm for constant $\epsilon$ (our bound is, in fact, somewhat
stronger, where the $(\log\log n)$ term can be replaced by any constant number
of $\log $ iterations instead of just two or three, thus approaching $log^*n$.
Our bound also works for non-constant $\epsilon$ (for details see the body of
the paper). Further, our algorithm requires only $4$-wise independence, in
contrast to existing methods that use pseudo-random generators for computing
large frequency moments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2575</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2575</id><created>2010-11-11</created><authors><author><keyname>Katahira</keyname><forenames>Kentaro</forenames></author><author><keyname>Suzuki</keyname><forenames>Kenta</forenames></author><author><keyname>Okanoya</keyname><forenames>Kazuo</forenames></author><author><keyname>Okada</keyname><forenames>Masato</forenames></author></authors><title>Complex sequencing rules of birdsong can be explained by simple hidden
  Markov processes</title><categories>q-bio.NC cs.CL</categories><doi>10.1371/journal.pone.0024516</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex sequencing rules observed in birdsongs provide an opportunity to
investigate the neural mechanism for generating complex sequential behaviors.
To relate the findings from studying birdsongs to other sequential behaviors,
it is crucial to characterize the statistical properties of the sequencing
rules in birdsongs. However, the properties of the sequencing rules in
birdsongs have not yet been fully addressed. In this study, we investigate the
statistical propertiesof the complex birdsong of the Bengalese finch (Lonchura
striata var. domestica). Based on manual-annotated syllable sequences, we first
show that there are significant higher-order context dependencies in Bengalese
finch songs, that is, which syllable appears next depends on more than one
previous syllable. This property is shared with other complex sequential
behaviors. We then analyze acoustic features of the song and show that
higher-order context dependencies can be explained using first-order hidden
state transition dynamics with redundant hidden states. This model corresponds
to hidden Markov models (HMMs), well known statistical models with a large
range of application for time series modeling. The song annotation with these
models with first-order hidden state dynamics agreed well with manual
annotation, the score was comparable to that of a second-order HMM, and
surpassed the zeroth-order model (the Gaussian mixture model (GMM)), which does
not use context information. Our results imply that the hierarchical
representation with hidden state dynamics may underlie the neural
implementation for generating complex sequences with higher-order dependencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2586</identifier>
 <datestamp>2010-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2586</id><created>2010-11-11</created><authors><author><keyname>Raghavendra</keyname><forenames>Prasad</forenames></author><author><keyname>Steurer</keyname><forenames>David</forenames></author><author><keyname>Tulsiani</keyname><forenames>Madhur</forenames></author></authors><title>Reductions Between Expansion Problems</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Small-Set Expansion Hypothesis (Raghavendra, Steurer, STOC 2010) is a
natural hardness assumption concerning the problem of approximating the edge
expansion of small sets in graphs. This hardness assumption is closely
connected to the Unique Games Conjecture (Khot, STOC 2002). In particular, the
Small-Set Expansion Hypothesis implies the Unique Games Conjecture
(Raghavendra, Steurer, STOC 2010).
  Our main result is that the Small-Set Expansion Hypothesis is in fact
equivalent to a variant of the Unique Games Conjecture. More precisely, the
hypothesis is equivalent to the Unique Games Conjecture restricted to instance
with a fairly mild condition on the expansion of small sets. Alongside, we
obtain the first strong hardness of approximation results for the Balanced
Separator and Minimum Linear Arrangement problems. Before, no such hardness was
known for these problems even assuming the Unique Games Conjecture.
  These results not only establish the Small-Set Expansion Hypothesis as a
natural unifying hypothesis that implies the Unique Games Conjecture, all its
consequences and, in addition, hardness results for other problems like
Balanced Separator and Minimum Linear Arrangement, but our results also show
that the Small-Set Expansion Hypothesis problem lies at the combinatorial heart
of the Unique Games Conjecture.
  The key technical ingredient is a new way of exploiting the structure of the
Unique Games instances obtained from the Small-Set Expansion Hypothesis via
(Raghavendra, Steurer, 2010). This additional structure allows us to modify
standard reductions in a way that essentially destroys their local-gadget
nature. Using this modification, we can argue about the expansion in the graphs
produced by the reduction without relying on expansion properties of the
underlying Unique Games instance (which would be impossible for a local-gadget
reduction).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2590</identifier>
 <datestamp>2010-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2590</id><created>2010-11-11</created><authors><author><keyname>Braverman</keyname><forenames>Vladimir</forenames></author><author><keyname>Ostrovsky</keyname><forenames>Rafail</forenames></author><author><keyname>Rabani</keyname><forenames>Yuval</forenames></author></authors><title>Rademacher Chaos, Random Eulerian Graphs and The Sparse
  Johnson-Lindenstrauss Transform</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The celebrated dimension reduction lemma of Johnson and Lindenstrauss has
numerous computational and other applications. Due to its application in
practice, speeding up the computation of a Johnson-Lindenstrauss style
dimension reduction is an important question. Recently, Dasgupta, Kumar, and
Sarlos (STOC 2010) constructed such a transform that uses a sparse matrix. This
is motivated by the desire to speed up the computation when applied to sparse
input vectors, a scenario that comes up in applications. The sparsity of their
construction was further improved by Kane and Nelson (ArXiv 2010).
  We improve the previous bound on the number of non-zero entries per column of
Kane and Nelson from $O(1/\epsilon \log(1/\delta)\log(k/\delta))$ (where the
target dimension is $k$, the distortion is $1\pm \epsilon$, and the failure
probability is $\delta$) to $$ O\left({1\over\epsilon}
\left({\log(1/\delta)\log\log\log(1/\delta) \over
\log\log(1/\delta)}\right)^2\right). $$
  We also improve the amount of randomness needed to generate the matrix. Our
results are obtained by connecting the moments of an order 2 Rademacher chaos
to the combinatorial properties of random Eulerian multigraphs. Estimating the
chance that a random multigraph is composed of a given number of node-disjoint
Eulerian components leads to a new tail bound on the chaos. Our estimates may
be of independent interest, and as this part of the argument is decoupled from
the analysis of the coefficients of the chaos, we believe that our methods can
be useful in the analysis of other chaoses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2624</identifier>
 <datestamp>2011-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2624</id><created>2010-11-11</created><updated>2011-10-27</updated><authors><author><keyname>Fraiman</keyname><forenames>Ricardo</forenames></author><author><keyname>Ghattas</keyname><forenames>Badih</forenames></author><author><keyname>Svarc</keyname><forenames>Marcela</forenames></author></authors><title>Clustering using Unsupervised Binary Trees: CUBT</title><categories>stat.ME cs.LG stat.CO</categories><comments>This paper has been withdrawn by the author due to an involuntary
  double submission to the arxiv</comments><msc-class>62H30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We herein introduce a new method of interpretable clustering that uses
unsupervised binary trees. It is a three-stage procedure, the first stage of
which entails a series of recursive binary splits to reduce the heterogeneity
of the data within the new subsamples. During the second stage (pruning),
consideration is given to whether adjacent nodes can be aggregated. Finally,
during the third stage (joining), similar clusters are joined together, even if
they do not share the same parent originally. Consistency results are obtained,
and the procedure is used on simulated and real data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2644</identifier>
 <datestamp>2010-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2644</id><created>2010-11-11</created><authors><author><keyname>Rimoldi</keyname><forenames>Anna</forenames></author><author><keyname>Sala</keyname><forenames>Massimiliano</forenames></author><author><keyname>Bertolazzi</keyname><forenames>Enrico</forenames></author></authors><title>Do AES encryptions act randomly?</title><categories>cs.IT cs.CR math.IT</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Advanced Encryption Standard (AES) is widely recognized as the most
important block cipher in common use nowadays. This high assurance in AES is
given by its resistance to ten years of extensive cryptanalysis, that has shown
no weakness, not even any deviation from the statistical behaviour expected
from a random permutation. Only reduced versions of the ciphers have been
broken, but they are not usually implemented. In this paper we build a
distinguishing attack on the AES, exploiting the properties of a novel cipher
embedding. With our attack we give some statistical evidence that the set of
AES-$128$ encryptions acts on the message space in a way significantly
different than that of the set of random permutations acting on the same space.
While we feel that more computational experiments by independent third parties
are needed in order to validate our statistical results, we show that the
non-random behaviour is the same as we would predict using the property of our
embedding. Indeed, the embedding lowers the nonlinearity of the AES rounds and
therefore the AES encryptions tend, on average, to keep low the rank of
low-rank matrices constructed in the large space. Our attack needs $2^{23}$
plaintext-ciphertext pairs and costs the equivalent of $2^{48}$ encryptions.
  We expect our attack to work also for AES-$192$ and AES-$256$, as confirmed
by preliminary experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2652</identifier>
 <datestamp>2010-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2652</id><created>2010-11-11</created><authors><author><keyname>Fox</keyname><forenames>Jorge</forenames></author></authors><title>A Formal Model for Dynamically Adaptable Services</title><categories>cs.SE</categories><comments>7 pages, 5 figures, 3 listings</comments><acm-class>D.2.11; D.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The growing complexity of software systems as well as changing conditions in
their operating environment demand systems that are more flexible, adaptive and
dependable. The service-oriented computing paradigm is in widespread use to
support such adaptive systems, and, in many domains, adaptations may occur
dynamically and in real time. In addition, services from heterogeneous,
possibly unknown sources may be used. This motivates a need to ensure the
correct behaviour of the adapted systems, and its continuing compliance to time
bounds and other QoS properties. The complexity of dynamic adaptation (DA) is
significant, but currently not well understood or formally specified. This
paper elaborates a well-founded model and theory of DA, introducing formalisms
written using COWS. The model is evaluated for reliability and responsiveness
properties with the model checker CMC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2656</identifier>
 <datestamp>2012-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2656</id><created>2010-11-11</created><updated>2012-05-30</updated><authors><author><keyname>Bluemlein</keyname><forenames>Johannes</forenames></author><author><keyname>Klein</keyname><forenames>Sebastian</forenames></author><author><keyname>Schneider</keyname><forenames>Carsten</forenames></author><author><keyname>Stan</keyname><forenames>Flavia</forenames></author></authors><title>A Symbolic Summation Approach to Feynman Integral Calculus</title><categories>cs.SC hep-ph hep-th math-ph math.MP</categories><report-no>DESY 10-185, TTK-10-49, SFB-CPP/10-107</report-no><journal-ref>J. Symbolic Comput. 47, pp. 1267-1289. 2012</journal-ref><doi>10.1016/j.jsc.2011.12.044</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a Feynman parameter integral, depending on a single discrete variable
$N$ and a real parameter $\epsilon$, we discuss a new algorithmic framework to
compute the first coefficients of its Laurent series expansion in $\epsilon$.
In a first step, the integrals are expressed by hypergeometric multi-sums by
means of symbolic transformations. Given this sum format, we develop new
summation tools to extract the first coefficients of its series expansion
whenever they are expressible in terms of indefinite nested product-sum
expressions. In particular, we enhance the known multi-sum algorithms to derive
recurrences for sums with complicated boundary conditions, and we present new
algorithms to find formal Laurent series solutions of a given recurrence
relation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2685</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2685</id><created>2010-11-11</created><updated>2011-05-17</updated><authors><author><keyname>Lopes</keyname><forenames>Nuno P.</forenames></author><author><keyname>Aksoy</keyname><forenames>Levent</forenames></author><author><keyname>Manquinho</keyname><forenames>Vasco</forenames></author><author><keyname>Monteiro</keyname><forenames>Jos&#xe9;</forenames></author></authors><title>Optimally Solving the MCM Problem Using Pseudo-Boolean Satisfiability</title><categories>cs.LO math.LO math.OC</categories><report-no>INESC-ID RT/43/2010</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report, we describe three encodings of the multiple constant
multiplication (MCM) problem to pseudo-boolean satisfiability (PBS), and
introduce an algorithm to solve the MCM problem optimally. To the best of our
knowledge, the proposed encodings and the optimization algorithm are the first
formalization of the MCM problem in a PBS manner. This report evaluates the
complexity of the problem size and the performance of several PBS solvers over
three encodings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2686</identifier>
 <datestamp>2010-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2686</id><created>2010-11-11</created><authors><author><keyname>Xu</keyname><forenames>Ran</forenames></author><author><keyname>Woodward</keyname><forenames>Graeme</forenames></author><author><keyname>Morris</keyname><forenames>Kevin</forenames></author><author><keyname>Kocak</keyname><forenames>Taskin</forenames></author></authors><title>A Discrete Time Markov Chain Model for High Throughput Bidirectional
  Fano Decoders</title><categories>cs.IT math.IT</categories><comments>5 pages, 10 figures, accepted by GLOBECOM 2010, Miami, FL, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The bidirectional Fano algorithm (BFA) can achieve at least two times
decoding throughput compared to the conventional unidirectional Fano algorithm
(UFA). In this paper, bidirectional Fano decoding is examined from the queuing
theory perspective. A Discrete Time Markov Chain (DTMC) is employed to model
the BFA decoder with a finite input buffer. The relationship between the input
data rate, the input buffer size and the clock speed of the BFA decoder is
established. The DTMC based modelling can be used in designing a high
throughput parallel BFA decoding system. It is shown that there is a tradeoff
between the number of BFA decoders and the input buffer size, and an optimal
input buffer size can be chosen to minimize the hardware complexity for a
target decoding throughput in designing a high throughput parallel BFA decoding
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2689</identifier>
 <datestamp>2010-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2689</id><created>2010-11-11</created><authors><author><keyname>Do</keyname><forenames>Anne-Ly</forenames></author><author><keyname>Gross</keyname><forenames>Thilo</forenames></author></authors><title>Contact processes and moment closure on adaptive networks</title><categories>physics.soc-ph cs.SI</categories><comments>18 pages, 5 figures</comments><journal-ref>Thilo Gross and Hiroki Sayama (Eds.): Adaptive Networks, 191-208.
  Springer Verlag, New York, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Contact processes describe the transmission of distinct properties of nodes
via the links of a network. They provide a simple framework for many phenomena,
such as epidemic spreading and opinion formation. Combining contact processes
with rules for topological evolution yields an adaptive network in which the
states of the nodes can interact dynamically with the topological degrees of
freedom. By moment-closure approximation it is possible to derive
low-dimensional systems of ordinary differential equations that describe the
dynamics of the adaptive network on a coarse-grained level. In this chapter we
discuss the approximation technique itself as well as its applications to
adaptive networks. Thus, it can serve both as a tutorial as well as a review of
recent results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2719</identifier>
 <datestamp>2010-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2719</id><created>2010-11-11</created><authors><author><keyname>Fraigniaud</keyname><forenames>Pierre</forenames></author><author><keyname>Pelc</keyname><forenames>Andrzej</forenames></author></authors><title>Decidability Classes for Mobile Agents Computing</title><categories>cs.DC cs.CC cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish a classification of decision problems that are to be solved by
mobile agents operating in unlabeled graphs, using a deterministic protocol.
The classification is with respect to the ability of a team of agents to solve
the problem, possibly with the aid of additional information. In particular,
our focus is on studying differences between the decidability of a decision
problem by agents and its verifiability when a certificate for a positive
answer is provided to the agents. We show that the class MAV of mobile agents
verifiable problems is much wider than the class MAD of mobile agents decidable
problems. Our main result shows that there exist natural MAV-complete problems:
the most difficult problems in this class, to which all problems in MAV are
reducible. Our construction of a MAV-complete problem involves two main
ingredients in mobile agents computability: the topology of the quotient graph
and the number of operating agents. Beyond the class MAV we show that, for a
single agent, three natural oracles yield a strictly increasing chain of
relative decidability classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2730</identifier>
 <datestamp>2014-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2730</id><created>2010-11-11</created><updated>2012-11-19</updated><authors><author><keyname>Delgado</keyname><forenames>Frank Vega</forenames></author></authors><title>A Solution to the P versus NP Problem</title><categories>cs.CC</categories><comments>Admin note: withdrawn by arXiv admin because of the use of a
  pseudonym, in violation of arXiv policy</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The relationship between the complexity classes P and NP is a question that
has not yet been answered by the Theory of Computation. The existence of a
language in NP, proven not to belong to P, is sufficient evidence to establish
the separation of P from NP. If a language is not recursive, it can't belong to
the complexity class NP. We find a problem in NP which is not in P; because if
it would be present in that class, then it will imply that some undecidable
problem will be in NP too. That's why it can be confirmed by reduction ad
absurdum the following result: P doesn't equal NP. This new problem named
Certifying is to find a possible input given a particular deterministic Turing
machine named Certified Turing machine and its output.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2740</identifier>
 <datestamp>2010-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2740</id><created>2010-11-11</created><authors><author><keyname>Yu</keyname><forenames>Nam Yul</forenames></author></authors><title>Deterministic Compressed Sensing Matrices from Multiplicative Character
  Sequences</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing is a novel technique where one can recover sparse signals
from the undersampled measurements. In this paper, a $K \times N$ measurement
matrix for compressed sensing is deterministically constructed via
multiplicative character sequences. Precisely, a constant multiple of a cyclic
shift of an $M$-ary power residue or Sidelnikov sequence is arranged as a
column vector of the matrix, through modulating a primitive $M$-th root of
unity. The Weil bound is then used to show that the matrix has asymptotically
optimal coherence for large $K$ and $M$, and to present a sufficient condition
on the sparsity level for unique sparse solution. Also, the restricted isometry
property (RIP) is statistically studied for the deterministic matrix. Numerical
results show that the deterministic compressed sensing matrix guarantees
reliable matching pursuit recovery performance for both noiseless and noisy
measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2751</identifier>
 <datestamp>2011-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2751</id><created>2010-11-11</created><updated>2011-04-02</updated><authors><author><keyname>Brandao</keyname><forenames>Fernando G. S. L.</forenames></author><author><keyname>Christandl</keyname><forenames>Matthias</forenames></author><author><keyname>Yard</keyname><forenames>Jon</forenames></author></authors><title>A quasipolynomial-time algorithm for the quantum separability problem</title><categories>quant-ph cs.CC</categories><comments>9 pages, no figures; to appear in proceedings STOC '11</comments><journal-ref>Proceedings of ACM Symposium on Theory of Computation (STOC'11),
  June 2011, p. 343-351</journal-ref><doi>10.1145/1993636.1993683</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a quasipolynomial-time algorithm for solving the weak membership
problem for the convex set of separable, i.e. non-entangled, bipartite density
matrices. The algorithm decides whether a density matrix is separable or
whether it is eps-away from the set of the separable states in time
exp(O(eps^-2 log |A| log |B|)), where |A| and |B| are the local dimensions, and
the distance is measured with either the Euclidean norm, or with the so-called
LOCC norm. The latter is an operationally motivated norm giving the optimal
probability of distinguishing two bipartite quantum states, each shared by two
parties, using any protocol formed by quantum local operations and classical
communication (LOCC) between the parties. We also obtain improved algorithms
for optimizing over the set of separable states and for computing the
ground-state energy of mean-field Hamiltonians.
  The techniques we develop are also applied to quantum Merlin-Arthur games,
where we show that multiple provers are not more powerful than a single prover
when the verifier is restricted to LOCC protocols, or when the verification
procedure is formed by a measurement of small Euclidean norm. This answers a
question posed by Aaronson et al (Theory of Computing 5, 1, 2009) and provides
two new characterizations of the complexity class QMA, a quantum analog of NP.
Our algorithm uses semidefinite programming to search for a symmetric
extension, as first proposed by Doherty, Parrilo and Spedialieri (Phys. Rev. A,
69, 022308, 2004). The bound on the runtime follows from an improved de
Finetti-type bound quantifying the monogamy of quantum entanglement, proved in
(arXiv:1010.1750). This result, in turn, follows from a new lower bound on the
quantum conditional mutual information and the entanglement measure squashed
entanglement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2753</identifier>
 <datestamp>2010-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2753</id><created>2010-11-11</created><authors><author><keyname>Ayremlou</keyname><forenames>Ali</forenames></author><author><keyname>Tofighi</keyname><forenames>Mohammad</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>Compensating Interpolation Distortion by New Optimized Modular Method</title><categories>cs.MM</categories><comments>Submitted to International Conference on Telecommunications(ICT) 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A modular method was suggested before to recover a band limited signal from
the sample and hold and linearly interpolated (or, in general, an
nth-order-hold) version of the regular samples. In this paper a novel approach
for compensating the distortion of any interpolation based on modular method
has been proposed. In this method the performance of the modular method is
optimized by adding only some simply calculated coefficients. This approach
causes drastic improvement in terms of SNRs with fewer modules compared to the
classical modular method. Simulation results clearly confirm the improvement of
the proposed method and also its superior robustness against additive noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2787</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2787</id><created>2010-11-11</created><updated>2012-12-08</updated><authors><author><keyname>Gutoski</keyname><forenames>Gus</forenames></author><author><keyname>Wu</keyname><forenames>Xiaodi</forenames></author></authors><title>Parallel approximation of min-max problems</title><categories>quant-ph cs.CC</categories><comments>28 pages. Final version, compiled in letterpaper with reasonable
  margins</comments><journal-ref>Computational Complexity: Volume 22, Issue 2 (2013), Page 385-428</journal-ref><doi>10.1007/s00037-013-0065-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an efficient parallel approximation scheme for a new
class of min-max problems. The algorithm is derived from the matrix
multiplicative weights update method and can be used to find near-optimal
strategies for competitive two-party classical or quantum interactions in which
a referee exchanges any number of messages with one party followed by any
number of additional messages with the other. It considerably extends the class
of interactions which admit parallel solutions, demonstrating for the first
time the existence of a parallel algorithm for an interaction in which one
party reacts adaptively to the other.
  As a consequence, we prove that several competing-provers complexity classes
collapse to PSPACE such as QRG(2), SQG and two new classes called DIP and DQIP.
A special case of our result is a parallel approximation scheme for a specific
class of semidefinite programs whose feasible region consists of lists of
semidefinite matrices that satisfy a transcript-like consistency condition.
Applied to this special case, our algorithm yields a direct polynomial-space
simulation of multi-message quantum interactive proofs resulting in a
first-principles proof of QIP=PSPACE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2790</identifier>
 <datestamp>2010-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2790</id><created>2010-11-11</created><authors><author><keyname>Schumann</keyname><forenames>Andrew</forenames></author></authors><title>Towards Theory of Massive-Parallel Proofs. Cellular Automata Approach</title><categories>cs.LO math.LO</categories><comments>13 pages</comments><msc-class>I.2.3</msc-class><acm-class>F.4.1</acm-class><journal-ref>Bulletin of the Section of Logic 39/3-4, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the paper I sketch a theory of massively parallel proofs using cellular
automata presentation of deduction. In this presentation inference rules play
the role of cellular-automatic local transition functions. In this approach we
completely avoid axioms as necessary notion of deduction theory and therefore
we can use cyclic proofs without additional problems. As a result, a theory of
massive-parallel proofs within unconventional computing is proposed for the
first time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2795</identifier>
 <datestamp>2010-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2795</id><created>2010-11-11</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author><author><keyname>Ali-Eldin</keyname><forenames>Ahmed</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>A Distributed Data Collection Algorithm for Wireless Sensor Networks
  with Persistent Storage Nodes</title><categories>cs.NI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A distributed data collection algorithm to accurately store and forward
information obtained by wireless sensor networks is proposed. The proposed
algorithm does not depend on the sensor network topology, routing tables, or
geographic locations of sensor nodes, but rather makes use of uniformly
distributed storage nodes. Analytical and simulation results for this algorithm
show that, with high probability, the data disseminated by the sensor nodes can
be precisely collected by querying any small set of storage nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2797</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2797</id><created>2010-11-11</created><updated>2012-02-01</updated><authors><author><keyname>Barreiro</keyname><forenames>Andrea K.</forenames></author><author><keyname>Gjorgjieva</keyname><forenames>Julijana</forenames></author><author><keyname>Rieke</keyname><forenames>Fred</forenames></author><author><keyname>Shea-Brown</keyname><forenames>Eric</forenames></author></authors><title>When are microcircuits well-modeled by maximum entropy methods?</title><categories>q-bio.NC cond-mat.dis-nn cs.IT math.IT physics.data-an</categories><comments>Submitted Nov 1, 2010; Updated version submitted Feb 24, 2011;
  Revised version submitted Feb 1, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Describing the collective activity of neural populations is a daunting task:
the number of possible patterns grows exponentially with the number of cells,
resulting in practically unlimited complexity. Recent empirical studies,
however, suggest a vast simplification in how multi-neuron spiking occurs: the
activity patterns of some circuits are nearly completely captured by pairwise
interactions among neurons. Why are such pairwise models so successful in some
instances, but insufficient in others? Here, we study the emergence of
higher-order interactions in simple circuits with different architectures and
inputs. We quantify the impact of higher-order interactions by comparing the
responses of mechanistic circuit models vs. &quot;null&quot; descriptions in which all
higher-than-pairwise correlations have been accounted for by lower order
statistics, known as pairwise maximum entropy models.
  We find that bimodal input signals produce larger deviations from pairwise
predictions than unimodal inputs for circuits with local and global
connectivity. Moreover, recurrent coupling can accentuate these deviations, if
coupling strengths are neither too weak nor too strong. A circuit model based
on intracellular recordings from ON parasol retinal ganglion cells shows that a
broad range of light signals induce unimodal inputs to spike generators, and
that coupling strengths produce weak effects on higher-order interactions. This
provides a novel explanation for the success of pairwise models in this system.
Overall, our findings identify circuit-level mechanisms that produce and fail
to produce higher-order spiking statistics in neural ensembles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2807</identifier>
 <datestamp>2010-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2807</id><created>2010-11-11</created><authors><author><keyname>Wang</keyname><forenames>Jijie</forenames></author><author><keyname>Lin</keyname><forenames>Lei</forenames></author><author><keyname>Huang</keyname><forenames>Ting</forenames></author><author><keyname>Wang</keyname><forenames>Jingjing</forenames></author><author><keyname>He</keyname><forenames>Zengyou</forenames></author></authors><title>Efficient K-Nearest Neighbor Join Algorithms for High Dimensional Sparse
  Data</title><categories>cs.DB cs.DS</categories><comments>12 pages, This paper has been submitted to PAKDD2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The K-Nearest Neighbor (KNN) join is an expensive but important operation in
many data mining algorithms. Several recent applications need to perform KNN
join for high dimensional sparse data. Unfortunately, all existing KNN join
algorithms are designed for low dimensional data. To fulfill this void, we
investigate the KNN join problem for high dimensional sparse data.
  In this paper, we propose three KNN join algorithms: a brute force (BF)
algorithm, an inverted index-based(IIB) algorithm and an improved inverted
index-based(IIIB) algorithm. Extensive experiments on both synthetic and
real-world datasets were conducted to demonstrate the effectiveness of our
algorithms for high dimensional sparse data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2809</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2809</id><created>2010-11-11</created><updated>2010-11-14</updated><authors><author><keyname>Letzepis</keyname><forenames>Nick</forenames></author><author><keyname>Grant</keyname><forenames>Alex</forenames></author><author><keyname>Alexander</keyname><forenames>Paul</forenames></author><author><keyname>Haley</keyname><forenames>David</forenames></author></authors><title>Multipath Parameter Estimation from OFDM Signals in Mobile Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communications (26 pages,
  9 figures and 3 tables)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study multipath parameter estimation from orthogonal frequency division
multiplex signals transmitted over doubly dispersive mobile radio channels. We
are interested in cases where the transmission is long enough to suffer time
selectivity, but short enough such that the time variation can be accurately
modeled as depending only on per-tap linear phase variations due to Doppler
effects. We therefore concentrate on the estimation of the complex gain, delay
and Doppler offset of each tap of the multipath channel impulse response. We
show that the frequency domain channel coefficients for an entire packet can be
expressed as the superimposition of two-dimensional complex sinusoids. The
maximum likelihood estimate requires solution of a multidimensional non-linear
least squares problem, which is computationally infeasible in practice. We
therefore propose a low complexity suboptimal solution based on iterative
successive and parallel cancellation. First, initial delay/Doppler estimates
are obtained via successive cancellation. These estimates are then refined
using an iterative parallel cancellation procedure. We demonstrate via Monte
Carlo simulations that the root mean squared error statistics of our estimator
are very close to the Cramer-Rao lower bound of a single two-dimensional
sinusoid in Gaussian noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2834</identifier>
 <datestamp>2010-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2834</id><created>2010-11-12</created><authors><author><keyname>Barbier</keyname><forenames>Morgan</forenames><affiliation>LIX</affiliation></author></authors><title>New Set of Codes for the Maximum-Likelihood Decoding Problem</title><categories>cs.IT math.IT</categories><comments>in Yet Another Conference on Cryptography, Porquerolle : France
  (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The maximum-likelihood decoding problem is known to be NP-hard for general
linear and Reed-Solomon codes. In this paper, we introduce the notion of
A-covered codes, that is, codes that can be decoded through a polynomial time
algorithm A whose decoding bound is beyond the covering radius. For these
codes, we show that the maximum-likelihood decoding problem is reachable in
polynomial time in the code parameters. Focusing on bi- nary BCH codes, we were
able to find several examples of A-covered codes, including two codes for which
the maximum-likelihood decoding problem can be solved in quasi-quadratic time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2835</identifier>
 <datestamp>2010-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2835</id><created>2010-11-12</created><authors><author><keyname>Kannan</keyname><forenames>Sreeram</forenames></author><author><keyname>Raja</keyname><forenames>Adnan</forenames></author><author><keyname>Viswanath</keyname><forenames>Pramod</forenames></author></authors><title>Approximately Optimal Wireless Broadcasting</title><categories>cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a wireless broadcast network, where a single source reliably
communicates independent messages to multiple destinations, with the aid of
relays and cooperation between destinations. The wireless nature of the medium
is captured by the broadcast nature of transmissions as well as the
superposition of all transmit signals plus independent Gaussian noise at the
received signal at any radio. We propose a scheme that can achieve rate tuples
within a constant gap away from the cut-set bound, where the constant is
independent of channel coefficients and power constraints.
  The proposed scheme operates in two steps. The inner code, in which the
relays perform a quantize-and-encode operation, is constructed by lifting a
scheme designed for a corresponding discrete superposition network. The outer
code is a Marton code for the non-Gaussian vector broadcast channel induced by
the relaying scheme, and is constructed by adopting a ``receiver-centric''
viewpoint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2836</identifier>
 <datestamp>2010-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2836</id><created>2010-11-12</created><authors><author><keyname>Kuribayashi</keyname><forenames>Shin-ichi</forenames></author></authors><title>System Virtualization and Efficient ID Transmission Method for RFID Tag
  Infrastructure Network</title><categories>cs.NI</categories><comments>12 pages</comments><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC) Vol.2, No.6, November 2010</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The use of RFID tag which identifies a thing and an object will be expanded
with progress of ubiquitous society, and it is necessary to study how to
construct RFID network system as a social infrastructure like the Internet.
First, this paper proposes the virtualization method of RFID tag network system
to enable the same physical RFID network system to be used by multiple
different service systems. The system virtualization not only reduces the
system cost but also can dramatically reduce the installation space of physical
readers and the operation cost. It is proposed that all equipments in the RFID
network system except RFID tag could be shared with the conventional virtual
technologies. Then, this paper proposes the conditional tag ID processing and
the efficient tag ID transmission method which can greatly reduce the
processing time and processing load in RFID tag Infrastructure network The
conditional tag ID processing allows that tag ID is valid only at a certain
time zone of day or in a certain area. The efficient tag ID transmission method
uses the virtual network address of the service center as a part of the ID of
an RF tag, which allows the direct ID forwarding to the service center.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2843</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2843</id><created>2010-11-12</created><updated>2010-11-22</updated><authors><author><keyname>Italiano</keyname><forenames>Giuseppe F.</forenames></author><author><keyname>Sankowski</keyname><forenames>Piotr</forenames></author></authors><title>Improved Minimum Cuts and Maximum Flows in Undirected Planar Graphs</title><categories>cs.DS</categories><comments>This paper is being merged with the paper by Christian Wulff-Nilsen
  &quot;Min st-Cut of a Planar Graph in O(n loglog n) Time&quot;
  http://arxiv.org/abs/1007.3609</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study minimum cut and maximum flow problems on planar
graphs, both in static and in dynamic settings. First, we present an algorithm
that given an undirected planar graph computes the minimum cut between any two
given vertices in O(n log log n) time. Second, we show how to achieve the same
O(n log log n) bound for the problem of computing maximum flows in undirected
planar graphs. To the best of our knowledge, these are the first algorithms for
those two problems that break the O(n log n) barrier, which has been standing
for more than 25 years. Third, we present a fully dynamic algorithm that is
able to maintain information about minimum cuts and maximum flows in a plane
graph (i.e., a planar graph with a fixed embedding): our algorithm is able to
insert edges, delete edges and answer min-cut and max-flow queries between any
pair of vertices in O(n^(2/3) log^3 n) time per operation. This result is based
on a new dynamic shortest path algorithm for planar graphs which may be of
independent interest. We remark that this is the first known non-trivial
algorithm for min-cut and max-flow problems in a dynamic setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2879</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2879</id><created>2010-11-12</created><updated>2011-03-07</updated><authors><author><keyname>Wu</keyname><forenames>Zhouyun</forenames></author><author><keyname>Huang</keyname><forenames>Aiping</forenames></author><author><keyname>Zhou</keyname><forenames>Haojie</forenames></author><author><keyname>Hua</keyname><forenames>Cunqing</forenames></author><author><keyname>Qian</keyname><forenames>Jun</forenames></author></authors><title>Data Fusion Based Interference Matrix Generation for Cellular System
  Frequency Planning</title><categories>cs.NI</categories><comments>20 pages, 10 figures, accepted by International Journal of
  Communication Systems(IJCS)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference matrix (IM) has been widely used in frequency
planning/optimization of cellular systems because it describes the interaction
between any two cells. IM is generated from the source data gathered from the
cellular system, either mobile measurement reports (MMRs) or drive test (DT)
records. IM accuracy is not satisfactory since neither MMRs nor DT records
contain complete information on interference and traffic distribution. In this
paper, two IM generation algorithms based on source data fusion are proposed.
Data fusion in one algorithm is to reinforce MMRs data, using the
frequency-domain information of DT data from the same region. Data fusion in
another algorithm is to reshape DT data, using the traffic distribution
information extracted from MMRs from the same region. The fused data contains
more complete information so that more accurate IM can be obtained. Simulation
results have validated this conclusion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2887</identifier>
 <datestamp>2014-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2887</id><created>2010-11-12</created><updated>2014-09-28</updated><authors><author><keyname>Van Le</keyname><forenames>Hong</forenames></author></authors><title>Constructing elusive functions with help of evaluation mappings</title><categories>math.LO cs.CC</categories><comments>v. 5: 23 pages, misprints are corrected, a condition on $n$ and $r$
  in Proposition 4.11 is added, a proof of Corollary 4.12 is added, v. 6: 24
  pages, improved presentation, in particular Lemmas 4.8, 4.13 are added,
  Reference 5 is added (and commented)</comments><msc-class>03D15, 68Q17, 13P25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a method to construct elusive functions using techniques of
commutative algebra and algebraic geometry. The key notions of this method are
elusive subsets and evaluation mappings. We also develop the effective
elimination theory combined with algebraic number field theory in order to
construct concrete points outside the image of a polynomial mapping. Using the
developed methods, for $F = C \text{or} F = R$, we construct examples of
$(s,r)$-elusive functions whose monomial coefficients are algebraic numbers,
which give polynomials with algebraic number coefficients of large circuit
size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2893</identifier>
 <datestamp>2010-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2893</id><created>2010-11-12</created><authors><author><keyname>Seeling</keyname><forenames>Patrick</forenames></author></authors><title>Web Conferencing Traffic - An Analysis using DimDim as Example</title><categories>cs.NI cs.MM</categories><doi>10.5121/ijcnc.2010.2601</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an evaluation of the Ethernet traffic for host and
attendees of the popular opensource web conferencing system DimDim. While
traditional Internet-centric approaches such as the MBONE have been used over
the past decades, current trends for web-based conference systems make
exclusive use of application-layer multicast. To allow for network dimensioning
and QoS provisioning, an understanding of the underlying traffic
characteristics is required. We find in our exemplary evaluations that the host
of a web conference session produces a large amount of Ethernet traffic,
largely due to the required control of the conference session, that is
heavily-tailed distributed and exhibits additionally long-range dependence. For
different groups of activities within a web conference session, we find
distinctive characteristics of the generated traffic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2894</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2894</id><created>2010-11-12</created><updated>2015-05-17</updated><authors><author><keyname>Bodirsky</keyname><forenames>Manuel</forenames></author><author><keyname>Pinsker</keyname><forenames>Michael</forenames></author></authors><title>Schaefer's theorem for graphs</title><categories>cs.CC math.CO math.LO</categories><comments>54 pages</comments><msc-class>03D15, 68Q17, 68Q25, 05C80, 08A35, 08A40, 05C55, 03C40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Schaefer's theorem is a complexity classification result for so-called
Boolean constraint satisfaction problems: it states that every Boolean
constraint satisfaction problem is either contained in one out of six classes
and can be solved in polynomial time, or is NP-complete.
  We present an analog of this dichotomy result for the propositional logic of
graphs instead of Boolean logic. In this generalization of Schaefer's result,
the input consists of a set W of variables and a conjunction \Phi\ of
statements (&quot;constraints&quot;) about these variables in the language of graphs,
where each statement is taken from a fixed finite set \Psi\ of allowed
quantifier-free first-order formulas; the question is whether \Phi\ is
satisfiable in a graph.
  We prove that either \Psi\ is contained in one out of 17 classes of graph
formulas and the corresponding problem can be solved in polynomial time, or the
problem is NP-complete. This is achieved by a universal-algebraic approach,
which in turn allows us to use structural Ramsey theory. To apply the
universal-algebraic approach, we formulate the computational problems under
consideration as constraint satisfaction problems (CSPs) whose templates are
first-order definable in the countably infinite random graph. Our method to
classify the computational complexity of those CSPs is based on a
Ramsey-theoretic analysis of functions acting on the random graph, and we
develop general tools suitable for such an analysis which are of independent
mathematical interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2896</identifier>
 <datestamp>2012-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2896</id><created>2010-11-12</created><updated>2012-11-16</updated><authors><author><keyname>Cao</keyname><forenames>Zining</forenames></author></authors><title>Reducing Higher Order Pi-Calculus to Spatial Logics</title><categories>cs.LO</categories><comments>19 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, we show that theory of processes can be reduced to the theory
of spatial logic. Firstly, we propose a spatial logic SL for higher order
pi-calculus, and give an inference system of SL. The soundness and
incompleteness of SL are proved. Furthermore, we show that the structure
congruence relation and one-step transition relation can be described as the
logical relation of SL formulae. We also extend bisimulations for processes to
that for SL formulae. Then we extend all definitions and results of SL to a
weak semantics version of SL, called WL. At last, we add mu-operator to SL.
This new logic is named muSL. We show that WL is a sublogic of muSL and
replication operator can be expressed in muSL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2898</identifier>
 <datestamp>2010-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2898</id><created>2010-11-12</created><authors><author><keyname>Bailleux</keyname><forenames>Olivier</forenames></author></authors><title>Reified unit resolution and the failed literal rule</title><categories>cs.LO cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unit resolution can simplify a CNF formula or detect an inconsistency by
repeatedly assign the variables occurring in unit clauses. Given any CNF
formula sigma, we show that there exists a satisfiable CNF formula psi with
size polynomially related to the size of sigma such that applying unit
resolution to psi simulates all the effects of applying it to sigma. The
formula psi is said to be the reified counterpart of sigma. This approach can
be used to prove that the failed literal rule, which is an inference rule used
by some SAT solvers, can be entirely simulated by unit resolution. More
generally, it sheds new light on the expressive power of unit resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2918</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2918</id><created>2010-11-12</created><updated>2011-03-17</updated><authors><author><keyname>Gomes</keyname><forenames>Diogo A.</forenames></author><author><keyname>Mohr</keyname><forenames>Joana</forenames></author><author><keyname>Souza</keyname><forenames>Rafael R.</forenames></author></authors><title>Mean field limit of a continuous time finite state game</title><categories>math.OC cs.SY math.DS</categories><comments>22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mean field games is a recent area of study introduced by Lions and Lasry in a
series of seminal papers in 2006. Mean field games model situations of
competition between large number of rational agents that play non-cooperative
dynamic games under certain symmetry assumptions. They key step is to develop a
mean field model, in a similar way that what is done in statistical physics in
order to construct a mathematically tractable model. A main question that
arises in the study of such mean field problems is the rigorous justification
of the mean field models by a limiting procedure. In this paper we consider the
mean field limit of two-state Markov decision problem as the number of players
$N\to \infty$. First we establish the existence and uniqueness of a symmetric
partial information Markov perfect equilibrium. Then we derive a mean field
model and characterize its main properties. This mean field limit is a system
of coupled ordinary differential equations with initial-terminal data. Our main
result is the convergence as $N\to \infty$ of the $N$ player game to the mean
field model and an estimate of the rate of convergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2919</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2919</id><created>2010-11-12</created><authors><author><keyname>Leroux</keyname><forenames>Camille</forenames></author><author><keyname>Tal</keyname><forenames>Ido</forenames></author><author><keyname>Vardy</keyname><forenames>Alexander</forenames></author><author><keyname>Gross</keyname><forenames>Warren J.</forenames></author></authors><title>Hardware architectures for Successive Cancellation Decoding of Polar
  Codes</title><categories>cs.AR cs.IT math.IT</categories><comments>Submitted to ICASSP 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recently-discovered polar codes are widely seen as a major breakthrough
in coding theory. These codes achieve the capacity of many important channels
under successive cancellation decoding. Motivated by the rapid progress in the
theory of polar codes, we propose a family of architectures for efficient
hardware implementation of successive cancellation decoders. We show that such
decoders can be implemented with O(n) processing elements and O(n) memory
elements, while providing constant throughput. We also propose a technique for
overlapping the decoding of several consecutive codewords, thereby achieving a
significant speed-up factor. We furthermore show that successive cancellation
decoding can be implemented in the logarithmic domain, thereby eliminating the
multiplication and division operations and greatly reducing the complexity of
each processing element.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2922</identifier>
 <datestamp>2010-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2922</id><created>2010-11-12</created><authors><author><keyname>Vogel</keyname><forenames>Carl</forenames></author><author><keyname>Janssen</keyname><forenames>Jerom</forenames></author></authors><title>Emoticonsciousness</title><categories>cs.CL</categories><comments>COST Action 2102 and euCognition International School Vietri sul
  Mare, Italy, April 21-26, 2008 Revised Selected and Invited Papers</comments><report-no>TCD-CS-2010-09</report-no><msc-class>91C99</msc-class><acm-class>J.4; J.5</acm-class><doi>10.1007/978-3-642-12397-9_2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A temporal analysis of emoticon use in Swedish, Italian, German and English
asynchronous electronic communication is reported. Emoticons are classified as
positive, negative and neutral. Postings to newsgroups over a 66 week period
are considered. The aggregate analysis of emoticon use in newsgroups for
science and politics tend on the whole to be consistent over the entire time
period. Where possible, events that coincide with divergences from trends in
language-subject pairs are noted. Political discourse in Italian over the
period shows marked use of negative emoticons, and in Swedish, positive
emoticons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2945</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2945</id><created>2010-11-12</created><authors><author><keyname>Gaudilliere</keyname><forenames>Alexandre</forenames></author><author><keyname>Scoppola</keyname><forenames>Benedetto</forenames></author><author><keyname>Scoppola</keyname><forenames>Elisabetta</forenames></author><author><keyname>Viale</keyname><forenames>Massimiliano</forenames></author></authors><title>Phase transitions for the cavity approach to the clique problem on
  random graphs</title><categories>math.PR cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>36 pages, 4 figures</comments><msc-class>60C05, 82B26, 82B44</msc-class><doi>10.1007/s10955-011-0336-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a rigorous proof of two phase transitions for a disordered system
designed to find large cliques inside Erdos random graphs. Such a system is
associated with a conservative probabilistic cellular automaton inspired by the
cavity method originally introduced in spin glass theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2946</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2946</id><created>2010-11-12</created><authors><author><keyname>Sinha</keyname><forenames>Anshuman</forenames></author></authors><title>A Survey of System Security in Contactless Electronic Passports</title><categories>cs.CR</categories><comments>11 pages, 5 figures, 7 tables</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  A traditional paper-based passport contains a Machine- Readable Zone (MRZ)
and a Visual Inspection Zone (VIZ). The MRZ has two lines of the holder's
personal data, some document data, and verification characters encoded using
the Optical Character Recognition font B (OCRB). The encoded data includes the
holder's name, date of birth, and other identifying information for the holder
or the document. The VIZ contains the holder's photo and signature, usually on
the data page. However, the MRZ and VIZ can be easily duplicated with normal
document reproduction technology to produce a fake passport which can pass
traditional verification. Neither of these features actively verify the
holder's identity; nor do they bind the holder's identity to the document. A
passport also contains pages for stamps of visas and of country entry and exit
dates, which can be easily altered to produce fake permissions and travel
records. The electronic passport, supporting authentication using secure
credentials on a tamper-resistant chip, is an attempt to improve on the
security of the paper-based passport at minimum cost. This paper surveys the
security mechanisms built into the firstgeneration of authentication mechanisms
and compares them with second-generation passports. It analyzes and describes
the cryptographic protocols used in Basic Access Control (BAC) and Extended
Access Control (EAC).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2953</identifier>
 <datestamp>2010-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2953</id><created>2010-11-12</created><authors><author><keyname>Bernard</keyname><forenames>Thibault</forenames></author><author><keyname>Bui</keyname><forenames>Alain</forenames></author><author><keyname>Pilard</keyname><forenames>Laurence</forenames></author><author><keyname>Sohier</keyname><forenames>Devan</forenames></author></authors><title>A Distributed Clustering Algorithm for Dynamic Networks</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an algorithm that builds and maintains clusters over a network
subject to mobility. This algorithm is fully decentralized and makes all the
different clusters grow concurrently. The algorithm uses circulating tokens
that collect data and move according to a random walk traversal scheme. Their
task consists in (i) creating a cluster with the nodes it discovers and (ii)
managing the cluster expansion; all decisions affecting the cluster are taken
only by a node that owns the token. The size of each cluster is maintained
higher than $m$ nodes ($m$ is a parameter of the algorithm). The obtained
clustering is locally optimal in the sense that, with only a local view of each
clusters, it computes the largest possible number of clusters (\emph{ie} the
sizes of the clusters are as close to $m$ as possible). This algorithm is
designed as a decentralized control algorithm for large scale networks and is
mobility-adaptive: after a series of topological changes, the algorithm
converges to a clustering. This recomputation only affects nodes in clusters in
which topological changes happened, and in adjacent clusters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2973</identifier>
 <datestamp>2010-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2973</id><created>2010-11-12</created><authors><author><keyname>Pratt-Hartmann</keyname><forenames>Ian</forenames></author></authors><title>The Hamiltonian Syllogistic</title><categories>cs.LO</categories><comments>30 pages</comments><msc-class>03B65</msc-class><acm-class>F.4.1; I.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper undertakes a re-examination of Sir William Hamilton's doctrine of
the quantification of the predicate. Hamilton's doctrine comprises two theses.
First, the predicates of traditional syllogistic sentence-forms contain
implicit existential quantifiers, so that, for example, &quot;All p are q&quot; is to be
understood as &quot;All p are some q&quot;. Second, these implicit quantifiers can be
meaningfully dualized to yield novel sentence-forms, such as, for example, &quot;All
p are all q&quot;. Hamilton attempted to provide a deductive system for his
language, along the lines of the classical syllogisms. We show, using
techniques unavailable to Hamilton, that such a system does exist, though with
qualifications that distinguish it from its classical counterpart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2989</identifier>
 <datestamp>2010-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2989</id><created>2010-11-12</created><authors><author><keyname>Fosson</keyname><forenames>Sophie M.</forenames></author></authors><title>A Decoding Approach to Fault Tolerant Control of Linear Systems with
  Quantized Disturbance Input</title><categories>math.OC cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The aim of this paper is to propose an alternative method to solve a Fault
Tolerant Control problem. The model is a linear system affected by a
disturbance term: this represents a large class of technological faulty
processes. The goal is to make the system able to tolerate the undesired
perturbation, i.e., to remove or at least reduce its negative effects; such a
task is performed in three steps: the detection of the fault, its
identification and the consequent process recovery. When the disturbance
function is known to be \emph{quantized} over a finite number of levels, the
detection can be successfully executed by a recursive \emph{decoding}
algorithm, arising from Information and Coding Theory and suitably adapted to
the control framework. This technique is analyzed and tested in a flight
control issue; both theoretical considerations and simulations are reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.2996</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.2996</id><created>2010-11-12</created><authors><author><keyname>Hartmann</keyname><forenames>A. K.</forenames></author></authors><title>Large-deviation properties of largest component for random graphs</title><categories>cond-mat.dis-nn cs.SI physics.data-an physics.soc-ph</categories><comments>8 pages, 9 figures, a concise summary (1.3 pages) of this paper is
  available at the Papercore database at http://www.papercore.org/Hartmann2010</comments><doi>10.1140/epjb/e2011-10836-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributions of the size of the largest component, in particular the
large-deviation tail, are studied numerically for two graph ensembles, for
Erdoes-Renyi random graphs with finite connectivity and for two-dimensional
bond percolation. Probabilities as small as 10^-180 are accessed using an
artificial finite-temperature (Boltzmann) ensemble. The distributions for the
Erdoes-Renyi ensemble agree well with previously obtained analytical results.
The results for the percolation problem, where no analytical results are
available, are qualitatively similar, but the shapes of the distributions are
somehow different and the finite-size corrections are sometimes much larger.
Furthermore, for both problems, a first-order phase transition at low
temperatures T within the artificial ensemble is found in the percolating
regime, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3019</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3019</id><created>2010-11-12</created><authors><author><keyname>Sinha</keyname><forenames>Shriprakash</forenames></author><author><keyname>ter Horst</keyname><forenames>Gert J.</forenames></author></authors><title>Bounded Multivariate Surfaces On Monovariate Internal Functions</title><categories>cs.CV</categories><comments>23 pages, 15 figures, 1 table</comments><journal-ref>IEEE Intl. Conf. on Image Processing, Brussels, Sept. 11 to 14,
  2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Combining the properties of monovariate internal functions as proposed in
Kolmogorov superimposition theorem, in tandem with the bounds wielded by the
multivariate formulation of Chebyshev inequality, a hybrid model is presented,
that decomposes images into homogeneous probabilistically bounded multivariate
surfaces. Given an image, the model shows a novel way of working on reduced
image representation while processing and capturing the interaction among the
multidimensional information that describes the content of the same. Further,
it tackles the practical issues of preventing leakage by bounding the growth of
surface and reducing the problem sample size. The model if used, also sheds
light on how the Chebyshev parameter relates to the number of pixels and the
dimensionality of the feature space that associates with a pixel. Initial
segmentation results on the Berkeley image segmentation benchmark indicate the
effectiveness of the proposed decomposition algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3023</identifier>
 <datestamp>2013-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3023</id><created>2010-11-12</created><updated>2013-11-20</updated><authors><author><keyname>Bruna</keyname><forenames>Joan</forenames></author><author><keyname>Mallat</keyname><forenames>St&#xe9;phane</forenames></author></authors><title>Classification with Scattering Operators</title><categories>cs.CV</categories><comments>6 pages. CVPR 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A scattering vector is a local descriptor including multiscale and
multi-direction co-occurrence information. It is computed with a cascade of
wavelet decompositions and complex modulus. This scattering representation is
locally translation invariant and linearizes deformations. A supervised
classification algorithm is computed with a PCA model selection on scattering
vectors. State of the art results are obtained for handwritten digit
recognition and texture classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3027</identifier>
 <datestamp>2014-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3027</id><created>2010-11-12</created><updated>2011-11-23</updated><authors><author><keyname>Vershynin</keyname><forenames>Roman</forenames></author></authors><title>Introduction to the non-asymptotic analysis of random matrices</title><categories>math.PR cs.NA math.FA</categories><comments>62 pages. Minor corrections</comments><msc-class>60B20, 46B09</msc-class><journal-ref>Chapter 5 of: Compressed Sensing, Theory and Applications. Edited
  by Y. Eldar and G. Kutyniok. Cambridge University Press, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a tutorial on some basic non-asymptotic methods and concepts in
random matrix theory. The reader will learn several tools for the analysis of
the extreme singular values of random matrices with independent rows or
columns. Many of these methods sprung off from the development of geometric
functional analysis since the 1970's. They have applications in several fields,
most notably in theoretical computer science, statistics and signal processing.
A few basic applications are covered in this text, particularly for the problem
of estimating covariance matrices in statistics and for validating
probabilistic constructions of measurement matrices in compressed sensing.
These notes are written particularly for graduate students and beginning
researchers in different areas, including functional analysts, probabilists,
theoretical statisticians, electrical engineers, and theoretical computer
scientists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3049</identifier>
 <datestamp>2011-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3049</id><created>2010-11-12</created><updated>2011-10-15</updated><authors><author><keyname>Sarma</keyname><forenames>Atish Das</forenames></author><author><keyname>Holzer</keyname><forenames>Stephan</forenames></author><author><keyname>Kor</keyname><forenames>Liah</forenames></author><author><keyname>Korman</keyname><forenames>Amos</forenames></author><author><keyname>Nanongkai</keyname><forenames>Danupon</forenames></author><author><keyname>Pandurangan</keyname><forenames>Gopal</forenames></author><author><keyname>Peleg</keyname><forenames>David</forenames></author><author><keyname>Wattenhofer</keyname><forenames>Roger</forenames></author></authors><title>Distributed Verification and Hardness of Distributed Approximation</title><categories>cs.DC cs.DS</categories><comments>Submitted to Journal (special issue of STOC 2011)</comments><acm-class>C.2.4; F.0; F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the {\em verification} problem in distributed networks, stated as
follows. Let $H$ be a subgraph of a network $G$ where each vertex of $G$ knows
which edges incident on it are in $H$. We would like to verify whether $H$ has
some properties, e.g., if it is a tree or if it is connected. We would like to
perform this verification in a decentralized fashion via a distributed
algorithm. The time complexity of verification is measured as the number of
rounds of distributed communication. In this paper we initiate a systematic
study of distributed verification, and give almost tight lower bounds on the
running time of distributed verification algorithms for many fundamental
problems such as connectivity, spanning connected subgraph, and $s-t$ cut
verification. We then show applications of these results in deriving strong
unconditional time lower bounds on the {\em hardness of distributed
approximation} for many classical optimization problems including minimum
spanning tree, shortest paths, and minimum cut. Many of these results are the
first non-trivial lower bounds for both exact and approximate distributed
computation and they resolve previous open questions. Moreover, our
unconditional lower bound of approximating minimum spanning tree (MST) subsumes
and improves upon the previous hardness of approximation bound of Elkin [STOC
2004] as well as the lower bound for (exact) MST computation of Peleg and
Rubinovich [FOCS 1999]. Our result implies that there can be no distributed
approximation algorithm for MST that is significantly faster than the current
exact algorithm, for {\em any} approximation factor. Our lower bound proofs
show an interesting connection between communication complexity and distributed
computing which turns out to be useful in establishing the time complexity of
exact and approximate distributed computation of many problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3058</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3058</id><created>2010-11-12</created><authors><author><keyname>Borgs</keyname><forenames>Christian</forenames></author><author><keyname>Chayes</keyname><forenames>Jennifer T.</forenames></author><author><keyname>Tetali</keyname><forenames>Prasad</forenames></author></authors><title>Tight Bounds for Mixing of the Swendsen-Wang Algorithm at the Potts
  Transition Point</title><categories>math.PR cs.DM math-ph math.MP</categories><comments>45 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study two widely used algorithms for the Potts model on rectangular
subsets of the hypercubic lattice Z^d - heat bath dynamics and the
Swendsen-Wang algorithm - and prove that, under certain circumstances, the
mixing in these algorithms is torpid or slow. In particular, we show that for
heat bath dynamics throughout the region of phase coexistence, and for the
Swendsen-Wang algorithm at the transition point, the mixing time in a box of
side length L with periodic boundary conditions has upper and lower bounds
which are exponential in L^{d-1}. This work provides the first upper bound of
this form for the Swendsen-Wang algorithm, and gives lower bounds for both
algorithms which significantly improve the previous lower bounds that were
exponential in L/(log L)^2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3062</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3062</id><created>2010-11-12</created><authors><author><keyname>Mani</keyname><forenames>Ankur</forenames><affiliation>Sandy</affiliation></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames><affiliation>Sandy</affiliation></author><author><keyname>Alex</keyname><affiliation>Sandy</affiliation></author><author><keyname>Pentland</keyname></author></authors><title>Generalized Stable Matching in Bipartite Networks</title><categories>math.OC cs.DM cs.GT cs.SI</categories><acm-class>G.1.6; G.2; J.4; K.4.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the generalized version of weighted matching in
bipartite networks. Consider a weighted matching in a bipartite network in
which the nodes derive value from the split of the matching edge assigned to
them if they are matched. The value a node derives from the split depends both
on the split as well as the partner the node is matched to. We assume that the
value of a split to the node is continuous and strictly increasing in the part
of the split assigned to the node. A stable weighted matching is a matching and
splits on the edges in the matching such that no two adjacent nodes in the
network can split the edge between them so that both of them can derive a
higher value than in the matching. We extend the weighted matching problem to
this general case and study the existence of a stable weighted matching. We
also present an algorithm that converges to a stable weighted matching. The
algorithm generalizes the Hungarian algorithm for bipartite matching. Faster
algorithms can be made when there is more structure on the value functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3074</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3074</id><created>2010-11-12</created><authors><author><keyname>Tepedelenlioglu</keyname><forenames>Cihan</forenames></author><author><keyname>Dasarathan</keyname><forenames>Sivaraman</forenames></author></authors><title>Distributed Detection over Gaussian Multiple Access Channels with
  Constant Modulus Signaling</title><categories>cs.IT math.IT</categories><comments>30 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A distributed detection scheme where the sensors transmit with constant
modulus signals over a Gaussian multiple access channel is considered. The
deflection coefficient of the proposed scheme is shown to depend on the
characteristic function of the sensing noise and the error exponent for the
system is derived using large deviation theory. Optimization of the deflection
coefficient and error exponent are considered with respect to a transmission
phase parameter for a variety of sensing noise distributions including
impulsive ones. The proposed scheme is also favorably compared with existing
amplify-and-forward and detect-and-forward schemes. The effect of fading is
shown to be detrimental to the detection performance through a reduction in the
deflection coefficient depending on the fading statistics. Simulations
corroborate that the deflection coefficient and error exponent can be
effectively used to optimize the error probability for a wide variety of
sensing noise distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3077</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3077</id><created>2010-11-12</created><authors><author><keyname>Ballard</keyname><forenames>Grey</forenames></author><author><keyname>Demmel</keyname><forenames>James</forenames></author><author><keyname>Dumitriu</keyname><forenames>Ioana</forenames></author></authors><title>Minimizing Communication for Eigenproblems and the Singular Value
  Decomposition</title><categories>math.NA cs.DC cs.MS cs.NA</categories><comments>43 pages, 11 figures</comments><msc-class>65F15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithms have two costs: arithmetic and communication. The latter
represents the cost of moving data, either between levels of a memory
hierarchy, or between processors over a network. Communication often dominates
arithmetic and represents a rapidly increasing proportion of the total cost, so
we seek algorithms that minimize communication. In \cite{BDHS10} lower bounds
were presented on the amount of communication required for essentially all
$O(n^3)$-like algorithms for linear algebra, including eigenvalue problems and
the SVD. Conventional algorithms, including those currently implemented in
(Sca)LAPACK, perform asymptotically more communication than these lower bounds
require. In this paper we present parallel and sequential eigenvalue algorithms
(for pencils, nonsymmetric matrices, and symmetric matrices) and SVD algorithms
that do attain these lower bounds, and analyze their convergence and
communication costs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3087</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3087</id><created>2010-11-12</created><authors><author><keyname>Huang</keyname><forenames>Hongtao</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Wang</keyname><forenames>Jijie</forenames></author><author><keyname>Lei</keyname><forenames>Siyu</forenames></author><author><keyname>Wu</keyname><forenames>Guowei</forenames></author></authors><title>Leakage-Aware Reallocation for Periodic Real-Time Tasks on Multicore
  Processors</title><categories>cs.DC cs.OS</categories><comments>The 5th International Conference on Frontier of Computer Science and
  Technology (FCST), IEEE, Changchun, China, August 2010</comments><msc-class>68M20</msc-class><acm-class>C.3; D.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is an increasingly important issue to reduce the energy consumption of
computing systems. In this paper, we consider partition based energy-aware
scheduling of periodic real-time tasks on multicore processors. The scheduling
exploits dynamic voltage scaling (DVS) and core sleep scheduling to reduce both
dynamic and leakage energy consumption. If the overhead of core state switching
is non-negligible, however, the performance of this scheduling strategy in
terms of energy efficiency might degrade. To achieve further energy saving, we
extend the static task scheduling with run-time task reallocation. The basic
idea is to aggregate idle time among cores so that as many cores as possible
could be put into sleep in a way that the overall energy consumption is
reduced. Simulation results show that the proposed approach results in up to
20% energy saving over traditional leakage-aware DVS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3088</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3088</id><created>2010-11-12</created><authors><author><keyname>Xu</keyname><forenames>Ming</forenames></author><author><keyname>Ma</keyname><forenames>Longhua</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Yuan</keyname><forenames>Tengkai</forenames></author><author><keyname>Qian</keyname><forenames>Jixin</forenames></author><author><keyname>Shao</keyname><forenames>Meng</forenames></author></authors><title>Design and Implementation of a Wireless Sensor Network for Smart Homes</title><categories>cs.NI</categories><comments>International Workshop on Mobile Cyber-Physical Systems (MobiCPS
  2010), in conjunction with UIC2010, IEEE, Xi'an, China, 26 - 29 October, 2010</comments><msc-class>68M10</msc-class><acm-class>C.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor networks (WSNs) have become indispensable to the realization
of smart homes. The objective of this paper is to develop such a WSN that can
be used to construct smart home systems. The focus is on the design and
implementation of the wireless sensor node and the coordinator based on ZigBee
technology. A monitoring system is built by taking advantage of the GPRS
network. To support multi-hop communications, an improved routing algorithm
based on the Dijkstra algorithm is presented. Preliminary simulations have been
conducted to evaluate the performance of the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3090</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3090</id><created>2010-11-12</created><updated>2011-03-02</updated><authors><author><keyname>Tomioka</keyname><forenames>Ryota</forenames></author><author><keyname>Suzuki</keyname><forenames>Taiji</forenames></author></authors><title>Regularization Strategies and Empirical Bayesian Learning for MKL</title><categories>stat.ML cs.LG</categories><comments>19pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple kernel learning (MKL), structured sparsity, and multi-task learning
have recently received considerable attention. In this paper, we show how
different MKL algorithms can be understood as applications of either
regularization on the kernel weights or block-norm-based regularization, which
is more common in structured sparsity and multi-task learning. We show that
these two regularization strategies can be systematically mapped to each other
through a concave conjugate operation. When the kernel-weight-based regularizer
is separable into components, we can naturally consider a generative
probabilistic model behind MKL. Based on this model, we propose learning
algorithms for the kernel weights through the maximization of marginal
likelihood. We show through numerical experiments that $\ell_2$-norm MKL and
Elastic-net MKL achieve comparable accuracy to uniform kernel combination.
Although uniform kernel combination might be preferable from its simplicity,
$\ell_2$-norm MKL and Elastic-net MKL can learn the usefulness of the
information sources represented as kernels. In particular, Elastic-net MKL
achieves sparsity in the kernel weights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3091</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3091</id><created>2010-11-12</created><authors><author><keyname>Sun</keyname><forenames>Weifeng</forenames></author><author><keyname>Cong</keyname><forenames>Rong</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Chen</keyname><forenames>Xiao</forenames></author><author><keyname>Qin</keyname><forenames>Zhenquan</forenames></author></authors><title>R-CA: A Routing-based Dynamic Channel Assignment Algorithm for Wireless
  Mesh Networks</title><categories>cs.NI cs.DC</categories><comments>International Workshop on Mobile Cyber-Physical Systems (MobiCPS
  2010), in conjunction with UIC2010, IEEE, Xi'an, China, 26 - 29 October, 2010</comments><msc-class>68M10</msc-class><acm-class>C.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Even though channel assignment has been studied for years, the performance of
most IEEE 802.11-based multi-hop wireless networks such as wireless sensor
network (WSN), wireless mesh network (WMN), mobile ad hoc network (MANET) is
limited by channel interference. Properly assigning orthogonal channels to
wireless links can improve the throughput of multi-hop networks. To solve the
dynamic channel assignment problem, a routing-based channel assignment
algorithm called R-CA is proposed. R-CA can allocate channels for wireless
nodes when needed and free channels after data transmission. Thus more channel
resource can be explored by wireless nodes. Simulation results show that R-CA
can effectively enhance the network throughput and packet delivery rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3092</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3092</id><created>2010-11-12</created><authors><author><keyname>Wu</keyname><forenames>Guowei</forenames></author><author><keyname>Ren</keyname><forenames>Jiankang</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Yao</keyname><forenames>Lin</forenames></author><author><keyname>Xu</keyname><forenames>Zichuan</forenames></author></authors><title>Decentralized Inter-User Interference Suppression in Body Sensor
  Networks with Non-cooperative Game</title><categories>cs.NI cs.DC</categories><comments>International Workshop on Mobile Cyber-Physical Systems (MobiCPS
  2010), in conjunction with UIC2010, IEEE, Xi'an, China, 26 - 29 October, 2010</comments><msc-class>68M10</msc-class><acm-class>C.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Body Sensor Networks (BSNs) provide continuous health monitoring and analysis
of physiological parameters. A high degree of Quality-of-Service (QoS) for BSN
is extremely required. Inter-user interference is introduced by the
simultaneous communication of BSNs congregating in the same area. In this
paper, a decentralized inter-user interference suppression algorithm for BSN,
namely DISG, is proposed. Each BSN measures the SINR from other BSNs and then
adaptively selects the suitable channel and transmission power. By utilizing
non-cooperative game theory and no regret learning algorithm, DISG provides an
adaptive inter-user interference suppression strategy. The correctness and
effectiveness of DISG is theoretically proved, and the experimental results
show that DISG can reduce the effect of inter-user interference effectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3094</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3094</id><created>2010-11-12</created><authors><author><keyname>Ma</keyname><forenames>Longhua</forenames></author><author><keyname>Yuan</keyname><forenames>Tengkai</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Xu</keyname><forenames>Ming</forenames></author><author><keyname>Yao</keyname><forenames>Jun</forenames></author><author><keyname>Shao</keyname><forenames>Meng</forenames></author></authors><title>A High-confidence Cyber-Physical Alarm System: Design and Implementation</title><categories>cs.DC</categories><comments>IEEE/ACM Internet of Things Symposium (IOTS), in conjunction with
  GreenCom 2010, IEEE, Hangzhou, China, December 18-20, 2010</comments><msc-class>68M14</msc-class><acm-class>C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most traditional alarm systems cannot address security threats in a
satisfactory manner. To alleviate this problem, we developed a high-confidence
cyber-physical alarm system (CPAS), a new kind of alarm systems. This system
establishes the connection of the Internet (i.e. TCP/IP) through GPRS/CDMA/3G.
It achieves mutual communication control among terminal equipments, human
machine interfaces and users by using the existing mobile communication
network. The CPAS will enable the transformation in alarm mode from traditional
one-way alarm to two-way alarm. The system has been successfully applied in
practice. The results show that the CPAS could avoid false alarms and satisfy
residents' security needs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3096</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3096</id><created>2010-11-12</created><authors><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Chen</keyname><forenames>Zhikui</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Lv</keyname><forenames>Xiaoning</forenames></author><author><keyname>Bu</keyname><forenames>Fanyu</forenames></author></authors><title>A Trust Model Based on Service Classification in Mobile Services</title><categories>cs.DC cs.CR</categories><comments>IEEE/ACM Internet of Things Symposium (IOTS), in conjunction with
  GreenCom 2010, IEEE, Hangzhou, China, December 18-20, 2010</comments><msc-class>68M14</msc-class><acm-class>C.2; K.6.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet of Things (IoT) and B3G/4G communication are promoting the pervasive
mobile services with its advanced features. However, security problems are also
baffled the development. This paper proposes a trust model to protect the
user's security. The billing or trust operator works as an agent to provide a
trust authentication for all the service providers. The services are classified
by sensitive value calculation. With the value, the user's trustiness for
corresponding service can be obtained. For decision, three trust regions are
divided, which is referred to three ranks: high, medium and low. The trust
region tells the customer, with his calculated trust value, which rank he has
got and which authentication methods should be used for access. Authentication
history and penalty are also involved with reasons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3097</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3097</id><created>2010-11-12</created><authors><author><keyname>Huang</keyname><forenames>Tao</forenames></author><author><keyname>Chen</keyname><forenames>Zhikui</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Jin</keyname><forenames>Cheng</forenames></author><author><keyname>Li</keyname><forenames>Liang</forenames></author></authors><title>A Practical Localization Algorithm Based on Wireless Sensor Networks</title><categories>cs.NI cs.DC</categories><comments>IEEE/ACM Int Conf on Green Computing and Communications (GreenCom),
  IEEE, Hangzhou, China, December 18-20, 2010</comments><msc-class>68M10</msc-class><acm-class>C.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many localization algorithms and systems have been developed by means of
wireless sensor networks for both indoor and outdoor environments. To achieve
higher localization accuracy, extra hardware equipments are utilized by most of
the existing localization algorithms, which increase the cost and greatly limit
the range of location-based applications. In this paper we present a method
which can effectively meet different localization accuracy requirements of most
indoor and outdoor location services in realistic applications. Our algorithm
is composed of two phases: partition phase, in which the target region is split
into small grids and localization refinement phase in which a higher accuracy
location can be generated by applying a trick algorithm. A realistic demo
system using our algorithm has been developed to illustrate its feasibility and
availability. The results show that our algorithm can improve the localization
accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3098</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3098</id><created>2010-11-12</created><authors><author><keyname>Yao</keyname><forenames>Lin</forenames></author><author><keyname>Lin</keyname><forenames>Chi</forenames></author><author><keyname>Kong</keyname><forenames>Xiangwei</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Wu</keyname><forenames>Guowei</forenames></author></authors><title>A Clustering-based Location Privacy Protection Scheme for Pervasive
  Computing</title><categories>cs.CR</categories><comments>The 3rd IEEE/ACM Int Conf on Cyber, Physical and Social Computing
  (CPSCom), IEEE, Hangzhou, China, December 18-20, 2010</comments><msc-class>68M14</msc-class><acm-class>C.2; K.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In pervasive computing environments, Location- Based Services (LBSs) are
becoming increasingly important due to continuous advances in mobile networks
and positioning technologies. Nevertheless, the wide deployment of LBSs can
jeopardize the location privacy of mobile users. Consequently, providing
safeguards for location privacy of mobile users against being attacked is an
important research issue. In this paper a new scheme for safeguarding location
privacy is proposed. Our approach supports location K-anonymity for a wide
range of mobile users with their own desired anonymity levels by clustering.
The whole area of all users is divided into clusters recursively in order to
get the Minimum Bounding Rectangle (MBR). The exact location information of a
user is replaced by his MBR. Privacy analysis shows that our approach can
achieve high resilience to location privacy threats and provide more privacy
than users expect. Complexity analysis shows clusters can be adjusted in real
time as mobile users join or leave. Moreover, the clustering algorithms possess
strong robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3099</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3099</id><created>2010-11-12</created><authors><author><keyname>Cheng</keyname><forenames>Rui</forenames></author><author><keyname>Yang</keyname><forenames>Zhuo</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author></authors><title>iZone: A Location-Based Mobile Social Networking System</title><categories>cs.HC cs.DC</categories><comments>Third International Symposium on Parallel Architectures, Algorithms
  and Programming (PAAP), IEEE, December 18-20, 2010, Dalian, China</comments><msc-class>68M14</msc-class><acm-class>C.2.4; K.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapid development of wireless technology, the extensive use of mobile
phones and the availability of location information are facilitating
personalized location-based applications. Easy to carry, easy to use and easy
to buy, smart phones with certain software are of great advantage.
Consequently, mobile social networking (MSN) systems have emerged rapidly,
being a revolution for our everyday life. Based on the analysis of general
requirements of MSN and location-based services (LBS), this paper presents the
design of iZone, a mobile social networking system, as well as a prototype
implementation. This platform exploits mobile GIS (Geographic Information
Systems), LBS and J2ME technologies, combining geographical data to display map
on mobile phones. It can provide a number of social networking services via
smartphones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3101</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3101</id><created>2010-11-12</created><authors><author><keyname>Syamsuddin</keyname><forenames>Irfan</forenames></author><author><keyname>Hwang</keyname><forenames>Junseok</forenames></author></authors><title>A New Fuzzy MCDM Framework to Evaluate E-Government Security Strategy</title><categories>cs.CR</categories><comments>IEEE 4th International Conference on Application of Information and
  Communication Technologies AICT2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ensuring security of e-government applications and infrastructures is crucial
to maintain trust among stakeholders to store, process and exchange information
over the e-government systems. Due to dynamic and continuous threats on
e-government information security, policy makers need to perform evaluation on
existing information security strategy as to deliver trusted e-government
services. This paper presents an information security evaluation framework
based on new fuzzy multi criteria decision making (MCDM) to help policy makers
conduct comprehensive assessment of e-government security strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3115</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3115</id><created>2010-11-13</created><authors><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Kong</keyname><forenames>Xiangjie</forenames></author><author><keyname>Xu</keyname><forenames>Zhenzhen</forenames></author></authors><title>Cyber-Physical Control over Wireless Sensor and Actuator Networks with
  Packet Loss</title><categories>cs.NI cs.SY</categories><comments>in Book: Wireless Networking Based Control, edited by Sudip K.
  Mazumder, Springer, Dec 2010</comments><msc-class>68M10</msc-class><acm-class>C.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a growing interest in design and implementation of cyber-physical
control systems over wireless sensor and actuator networks (WSANs). Thanks to
the use of wireless communications and distributed architectures, these systems
encompass many advantages as compared to traditional networked control systems
using hard wirelines. While WSANs are enabling a new generation of control
systems, they also introduce considerable challenges for quality-of-service
(QoS) provisioning. In this chapter we examine some of the major QoS challenges
raised by WSANs, including resource constraints, platform heterogeneity,
dynamic network topology, and mixed traffic. These challenges make it difficult
to fulfill the requirements of cyber-physical control in terms of reliability
and real-time. The focus of this chapter is on addressing the problem of
network reliability. Specifically, we analyze the behavior of wireless channels
via simulations based on a realistic link-layer model. Packet loss rate (PLR)
is taken as a major metric for the analysis. The results confirm the
unreliability of wireless communications and the uncertainty of packet loss
over WSANs. To tackle packet loss, we present a simple solution that can take
advantage of existing prediction algorithms. Simulations are conducted to
evaluate the performance of several classical prediction algorithms used for
packet loss compensation. The results give some insights into how to deal with
packet loss in cyber-physical control systems over unreliable WSANs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3116</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3116</id><created>2010-11-13</created><authors><author><keyname>Wu</keyname><forenames>Guowei</forenames></author><author><keyname>Ren</keyname><forenames>Jiankang</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Xu</keyname><forenames>Zichuan</forenames></author></authors><title>An Adaptive Fault-Tolerant Communication Scheme for Body Sensor Networks</title><categories>cs.NI</categories><comments>10 figures, 19 pages</comments><msc-class>68M10</msc-class><acm-class>C.2</acm-class><journal-ref>Sensors, 2010(10): 9590-9608</journal-ref><doi>10.3390/s101109590</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A high degree of reliability for critical data transmission is required in
body sensor networks (BSNs). However, BSNs are usually vulnerable to channel
impairments due to body fading effect and RF interference, which may
potentially cause data transmission to be unreliable. In this paper, an
adaptive and flexible fault-tolerant communication scheme for BSNs, namely
AFTCS, is proposed. AFTCS adopts a channel bandwidth reservation strategy to
provide reliable data transmission when channel impairments occur. In order to
fulfill the reliability requirements of critical sensors, fault-tolerant
priority and queue are employed to adaptively adjust the channel bandwidth
allocation. Simulation results show that AFTCS can alleviate the effect of
channel impairments, while yielding lower packet loss rate and latency for
critical sensors at runtime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3120</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3120</id><created>2010-11-13</created><updated>2011-01-31</updated><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Rafols</keyname><forenames>Ismael</forenames></author></authors><title>The Local Emergence and Global Diffusion of Research Technologies: An
  Exploration of Patterns of Network Formation</title><categories>cs.DL cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Grasping the fruits of &quot;emerging technologies&quot; is an objective of many
government priority programs in a knowledge-based and globalizing economy. We
use the publication records (in the Science Citation Index) of two emerging
technologies to study the mechanisms of diffusion in the case of two innovation
trajectories: small interference RNA (siRNA) and nano-crystalline solar cells
(NCSC). Methods for analyzing and visualizing geographical and cognitive
diffusion are specified as indicators of different dynamics. Geographical
diffusion is illustrated with overlays to Google Maps; cognitive diffusion is
mapped using an overlay to a map based on the ISI Subject Categories. The
evolving geographical networks show both preferential attachment and
small-world characteristics. The strength of preferential attachment decreases
over time, while the network evolves into an oligopolistic control structure
with small-world characteristics. The transition from disciplinary-oriented
(&quot;mode-1&quot;) to transfer-oriented (&quot;mode-2&quot;) research is suggested as the crucial
difference in explaining the different rates of diffusion between siRNA and
NCSC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3148</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3148</id><created>2010-11-13</created><authors><author><keyname>Stoianov</keyname><forenames>Nikolai</forenames></author><author><keyname>Tselkov</keyname><forenames>Veselin</forenames></author></authors><title>E-net models for distribution, access and use of resources in security
  information systems</title><categories>cs.CR</categories><comments>2 figures, 2 definitions for interacting,</comments><journal-ref>Mathematics and Education in Mathematics, 2004 Proceedings of the
  Thirty Fourth Spring Conference of the Union of Bulgarian
  Mathematicians,pp.251 - 256 ISBN 954-8880-17-2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents solutions for distribution, access and use of resources
in information security systems. The solutions comprise the authors' experience
in development and implementation of systems for information security in the
Automated Information Systems. The models, the methods and the modus operandi
are being explained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3151</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3151</id><created>2010-11-13</created><updated>2011-02-23</updated><authors><author><keyname>Pita</keyname><forenames>Marcos</forenames></author><author><keyname>Privman</keyname><forenames>Vladimir</forenames></author><author><keyname>Arugula</keyname><forenames>Mary A.</forenames></author><author><keyname>Melnikov</keyname><forenames>Dmitriy</forenames></author><author><keyname>Bocharova</keyname><forenames>Vera</forenames></author><author><keyname>Katz</keyname><forenames>Evgeny</forenames></author></authors><title>Towards Biochemical Filter with Sigmoidal Response to pH Changes:
  Buffered Biocatalytic Signal Transduction</title><categories>cond-mat.soft cs.ET physics.bio-ph q-bio.MN</categories><comments>PDF, 23 pages</comments><journal-ref>Physical Chemistry Chemical Physics 13, 4507-4513 (2011)</journal-ref><doi>10.1039/c0cp02524k</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We realize a biochemical filtering process by introducing a buffer in a
biocatalytic signal-transduction logic system based on the function of an
enzyme, esterase. The input, ethyl butyrate, is converted into butyric acid-the
output signal, which in turn is measured by the drop in the pH value. The
developed approach offers a versatile &quot;network element&quot; for increasing the
complexity of biochemical information processing systems. Evaluation of an
optimal regime for quality filtering is accomplished in the framework of a
kinetic rate-equation model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3152</identifier>
 <datestamp>2015-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3152</id><created>2010-11-13</created><authors><author><keyname>Abouei</keyname><forenames>Jamshid</forenames></author><author><keyname>Brown</keyname><forenames>J. David</forenames></author><author><keyname>Plataniotis</keyname><forenames>Konstantinos N.</forenames></author><author><keyname>Pasupathy</keyname><forenames>Subbarayan</forenames></author></authors><title>On the Energy Efficiency of LT Codes in Proactive Wireless Sensor
  Networks</title><categories>cs.IT math.IT</categories><comments>accepted for publication in IEEE Transactions on Signal Processing</comments><report-no>November 9, 2010</report-no><doi>10.1109/TSP.2010.2094193</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an in-depth analysis on the energy efficiency of Luby
Transform (LT) codes with Frequency Shift Keying (FSK) modulation in a Wireless
Sensor Network (WSN) over Rayleigh fading channels with pathloss. We describe a
proactive system model according to a flexible duty-cycling mechanism utilized
in practical sensor apparatus. The present analysis is based on realistic
parameters including the effect of channel bandwidth used in the IEEE 802.15.4
standard, active mode duration and computation energy. A comprehensive
analysis, supported by some simulation studies on the probability mass function
of the LT code rate and coding gain, shows that among uncoded FSK and various
classical channel coding schemes, the optimized LT coded FSK is the most
energy-efficient scheme for distance d greater than the pre-determined
threshold level d_T , where the optimization is performed over coding and
modulation parameters. In addition, although the optimized uncoded FSK
outperforms coded schemes for d &lt; d_T , the energy gap between LT coded and
uncoded FSK is negligible for d &lt; d_T compared to the other coded schemes.
These results come from the flexibility of the LT code to adjust its rate to
suit instantaneous channel conditions, and suggest that LT codes are beneficial
in practical low-power WSNs with dynamic position sensor nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3168</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3168</id><created>2010-11-13</created><updated>2011-03-24</updated><authors><author><keyname>Rakhlin</keyname><forenames>Alexander</forenames></author><author><keyname>Sridharan</keyname><forenames>Karthik</forenames></author><author><keyname>Tewari</keyname><forenames>Ambuj</forenames></author></authors><title>Online Learning: Beyond Regret</title><categories>stat.ML cs.GT cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study online learnability of a wide class of problems, extending the
results of (Rakhlin, Sridharan, Tewari, 2010) to general notions of performance
measure well beyond external regret. Our framework simultaneously captures such
well-known notions as internal and general Phi-regret, learning with
non-additive global cost functions, Blackwell's approachability, calibration of
forecasters, adaptive regret, and more. We show that learnability in all these
situations is due to control of the same three quantities: a martingale
convergence term, a term describing the ability to perform well if future is
known, and a generalization of sequential Rademacher complexity, studied in
(Rakhlin, Sridharan, Tewari, 2010). Since we directly study complexity of the
problem instead of focusing on efficient algorithms, we are able to improve and
extend many known results which have been previously derived via an algorithmic
construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3170</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3170</id><created>2010-11-13</created><authors><author><keyname>Aspnes</keyname><forenames>James</forenames></author></authors><title>Slightly smaller splitter networks</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classic renaming protocol of Moir and Anderson (1995) uses a network of
Theta(n^2) splitters to assign unique names to n processes with unbounded
initial names. We show how to reduce this bound to Theta(n^{3/2}) splitters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3174</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3174</id><created>2010-11-13</created><authors><author><keyname>Li</keyname><forenames>Peihua</forenames></author></authors><title>Tensor-SIFT based Earth Mover's Distance for Contour Tracking</title><categories>cs.CV math.OC</categories><comments>28 pages, 9 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Contour tracking in adverse environments is a challenging problem due to
cluttered background, illumination variation, occlusion, and noise, among
others. This paper presents a robust contour tracking method by contributing to
some of the key issues involved, including (a) a region functional formulation
and its optimization; (b) design of a robust and effective feature; and (c)
development of an integrated tracking algorithm. First, we formulate a region
functional based on robust Earth Mover's distance (EMD) with kernel density for
distribution modeling, and propose a two-phase method for its optimization. In
the first phase, letting the candidate contour be fixed, we express EMD as the
transportation problem and solve it by the simplex algorithm. Next, using the
theory of shape derivative, we make a perturbation analysis of the contour
around the best solution to the transportation problem. This leads to a partial
differential equation (PDE) that governs the contour evolution. Second, we
design a novel and effective feature for tracking applications. We propose a
dimensionality reduction method by tensor decomposition, achieving a
low-dimensional description of SIFT features called Tensor-SIFT for
characterizing local image region properties. Applicable to both color and
gray-level images, Tensor-SIFT is very distinctive, insensitive to illumination
changes, and noise. Finally, we develop an integrated algorithm that combines
various techniques of the simplex algorithm, narrow-band level set and fast
marching algorithms. Particularly, we introduce an inter-frame initialization
method and a stopping criterion for the termination of PDE iteration.
Experiments in challenging image sequences show that the proposed work has
promising performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3177</identifier>
 <datestamp>2011-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3177</id><created>2010-11-13</created><updated>2011-07-15</updated><authors><author><keyname>Sousa</keyname><forenames>Ricardo</forenames></author><author><keyname>Cardoso</keyname><forenames>Jaime S.</forenames></author></authors><title>The Data Replication Method for the Classification with Reject Option</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classification is one of the most important tasks of machine learning.
Although the most well studied model is the two-class problem, in many
scenarios there is the opportunity to label critical items for manual revision,
instead of trying to automatically classify every item. In this paper we adapt
a paradigm initially proposed for the classification of ordinal data to address
the classification problem with reject option. The technique reduces the
problem of classifying with reject option to the standard two-class problem.
The introduced method is then mapped into support vector machines and neural
networks. Finally, the framework is extended to multiclass ordinal data with
reject option. An experimental study with synthetic and real data sets,
verifies the usefulness of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3182</identifier>
 <datestamp>2015-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3182</id><created>2010-11-13</created><updated>2015-08-13</updated><authors><author><keyname>Jacobs</keyname><forenames>Tim</forenames></author><author><keyname>Pandurangan</keyname><forenames>Gopal</forenames></author></authors><title>Stochastic Analysis of a Churn-Tolerant Structured Peer-to-Peer Scheme</title><categories>cs.DC cs.DS cs.NI</categories><journal-ref>Peer-to-Peer Networking and Applications, 6(1), 1-14, 2013</journal-ref><doi>10.1007/s12083-012-0124-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present and analyze a simple and general scheme to build a churn
(fault)-tolerant structured Peer-to-Peer (P2P) network. Our scheme shows how to
&quot;convert&quot; a static network into a dynamic distributed hash table(DHT)-based P2P
network such that all the good properties of the static network are guaranteed
with high probability (w.h.p). Applying our scheme to a cube-connected cycles
network, for example, yields a $O(\log N)$ degree connected network, in which
every search succeeds in $O(\log N)$ hops w.h.p., using $O(\log N)$ messages,
where $N$ is the expected stable network size. Our scheme has an constant
storage overhead (the number of nodes responsible for servicing a data item)
and an $O(\log N)$ overhead (messages and time) per insertion and essentially
no overhead for deletions. All these bounds are essentially optimal. While DHT
schemes with similar guarantees are already known in the literature, this work
is new in the following aspects:
  (1) It presents a rigorous mathematical analysis of the scheme under a
general stochastic model of churn and shows the above guarantees;
  (2) The theoretical analysis is complemented by a simulation-based analysis
that validates the asymptotic bounds even in moderately sized networks and also
studies performance under changing stable network size;
  (3) The presented scheme seems especially suitable for maintaining dynamic
structures under churn efficiently. In particular, we show that a spanning tree
of low diameter can be efficiently maintained in constant time and logarithmic
number of messages per insertion or deletion w.h.p.
  Keywords: P2P Network, DHT Scheme, Churn, Dynamic Spanning Tree, Stochastic
Analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3189</identifier>
 <datestamp>2015-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3189</id><created>2010-11-14</created><updated>2015-09-26</updated><authors><author><keyname>Fong</keyname><forenames>Chamberlain</forenames></author><author><keyname>Vogel</keyname><forenames>Brian K.</forenames></author></authors><title>Warping Peirce Quincuncial Panoramas</title><categories>cs.CV cs.GR</categories><comments>updated source code with figures and explanation of the software
  implementation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Peirce quincuncial projection is a mapping of the surface of a sphere to
the interior of a square. It is a conformal map except for four points on the
equator. These points of non-conformality cause significant artifacts in
photographic applications. In this paper, we propose an algorithm and
user-interface to mitigate these artifacts. Moreover, in order to facilitate an
interactive user-interface, we present a fast algorithm for calculating the
Peirce quincuncial projection of spherical imagery. We then promote the Peirce
quincuncial projection as a viable alternative to the more popular
stereographic projection in some scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3208</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3208</id><created>2010-11-14</created><updated>2010-12-31</updated><authors><author><keyname>Sun</keyname><forenames>Timothy</forenames></author><author><keyname>Ye</keyname><forenames>Chun</forenames></author></authors><title>Rigidity of Graph Joins and Hendrickson's Conjecture</title><categories>math.MG cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Whiteley \cite{wh} gives a complete characterization of the infinitesimal
flexes of complete bipartite frameworks. Our work generalizes a specific
infinitesimal flex to include joined graphs, a family of graphs that contain
the complete bipartite graphs. We use this characterization to identify new
families of counterexamples, including infinite families, in $\R^5$ and above
to Hendrickson's conjecture on generic global rigidity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3232</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3232</id><created>2010-11-14</created><updated>2010-12-13</updated><authors><author><keyname>Dobzinski</keyname><forenames>Shahar</forenames></author><author><keyname>Fu</keyname><forenames>Hu</forenames></author><author><keyname>Kleinberg</keyname><forenames>Robert</forenames></author></authors><title>Truthfulness via Proxies</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short note exhibits a truthful-in-expectation $O(\frac {\log m} {\log
\log m})$-approximation mechanism for combinatorial auctions with subadditive
bidders that uses polynomial communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3234</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3234</id><created>2010-11-14</created><authors><author><keyname>Saxena</keyname><forenames>Nitin</forenames></author><author><keyname>Seshadhri</keyname><forenames>C.</forenames></author></authors><title>Blackbox identity testing for bounded top fanin depth-3 circuits: the
  field doesn't matter</title><categories>cs.CC math.AC</categories><comments>14 pages, 1 figure, preliminary version</comments><msc-class>13P25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let C be a depth-3 circuit with n variables, degree d and top fanin k (called
sps(k,d,n) circuits) over base field F. It is a major open problem to design a
deterministic polynomial time blackbox algorithm that tests if C is identically
zero. Klivans &amp; Spielman (STOC 2001) observed that the problem is open even
when k is a constant. This case has been subjected to a serious study over the
past few years, starting from the work of Dvir &amp; Shpilka (STOC 2005).
  We give the first polynomial time blackbox algorithm for this problem. Our
algorithm runs in time poly(nd^k), regardless of the base field. The only field
for which polynomial time algorithms were previously known is F=Q (Kayal &amp;
Saraf, FOCS 2009, and Saxena &amp; Seshadhri, FOCS 2010). This is the first
blackbox algorithm for depth-3 circuits that does not use the rank based
approaches of Karnin &amp; Shpilka (CCC 2008).
  We prove an important tool for the study of depth-3 identities. We design a
blackbox polynomial time transformation that reduces the number of variables in
a sps(k,d,n) circuit to k variables, but preserves the identity structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3241</identifier>
 <datestamp>2011-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3241</id><created>2010-11-14</created><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author><author><keyname>Ganz</keyname><forenames>Adam</forenames></author><author><keyname>Reddington</keyname><forenames>Joe</forenames></author></authors><title>New Methods of Analysis of Narrative and Semantics in Support of
  Interactivity</title><categories>cs.AI cs.HC stat.AP</categories><comments>17 pages, 6 figures</comments><acm-class>G.3; I.2.1; H.1.2</acm-class><journal-ref>Entertainment Computing, 2, 115-121, 2011</journal-ref><doi>10.1016/j.entcom.2010.12.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our work has focused on support for film or television scriptwriting. Since
this involves potentially varied story-lines, we note the implicit or latent
support for interactivity. Furthermore the film, television, games, publishing
and other sectors are converging, so that cross-over and re-use of one form of
product in another of these sectors is ever more common. Technically our work
has been largely based on mathematical algorithms for data clustering and
display. Operationally, we also discuss how our algorithms can support
collective, distributed problem-solving.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3244</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3244</id><created>2010-11-14</created><updated>2011-03-21</updated><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>&quot;Meaning&quot; as a sociological concept: A review of the modeling, mapping,
  and simulation of the communication of knowledge and meaning</title><categories>nlin.AO cs.AI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of discursive knowledge presumes the communication of meaning
as analytically different from the communication of information. Knowledge can
then be considered as a meaning which makes a difference. Whereas the
communication of information is studied in the information sciences and
scientometrics, the communication of meaning has been central to Luhmann's
attempts to make the theory of autopoiesis relevant for sociology. Analytical
techniques such as semantic maps and the simulation of anticipatory systems
enable us to operationalize the distinctions which Luhmann proposed as relevant
to the elaboration of Husserl's &quot;horizons of meaning&quot; in empirical research:
interactions among communications, the organization of meaning in
instantiations, and the self-organization of interhuman communication in terms
of symbolically generalized media such as truth, love, and power. Horizons of
meaning, however, remain uncertain orders of expectations, and one should
caution against reification from the meta-biological perspective of systems
theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3245</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3245</id><created>2010-11-14</created><authors><author><keyname>Aaronson</keyname><forenames>Scott</forenames></author><author><keyname>Arkhipov</keyname><forenames>Alex</forenames></author></authors><title>The Computational Complexity of Linear Optics</title><categories>quant-ph cs.CC</categories><comments>94 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give new evidence that quantum computers -- moreover, rudimentary quantum
computers built entirely out of linear-optical elements -- cannot be
efficiently simulated by classical computers. In particular, we define a model
of computation in which identical photons are generated, sent through a
linear-optical network, then nonadaptively measured to count the number of
photons in each mode. This model is not known or believed to be universal for
quantum computation, and indeed, we discuss the prospects for realizing the
model using current technology. On the other hand, we prove that the model is
able to solve sampling problems and search problems that are classically
intractable under plausible assumptions. Our first result says that, if there
exists a polynomial-time classical algorithm that samples from the same
probability distribution as a linear-optical network, then P^#P=BPP^NP, and
hence the polynomial hierarchy collapses to the third level. Unfortunately,
this result assumes an extremely accurate simulation. Our main result suggests
that even an approximate or noisy classical simulation would already imply a
collapse of the polynomial hierarchy. For this, we need two unproven
conjectures: the &quot;Permanent-of-Gaussians Conjecture&quot;, which says that it is
#P-hard to approximate the permanent of a matrix A of independent N(0,1)
Gaussian entries, with high probability over A; and the &quot;Permanent
Anti-Concentration Conjecture&quot;, which says that |Per(A)|&gt;=sqrt(n!)/poly(n) with
high probability over A. We present evidence for these conjectures, both of
which seem interesting even apart from our application. This paper does not
assume knowledge of quantum optics. Indeed, part of its goal is to develop the
beautiful theory of noninteracting bosons underlying our model, and its
connection to the permanent function, in a self-contained way accessible to
theoretical computer scientists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3256</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3256</id><created>2010-11-14</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author><author><keyname>Majeed</keyname><forenames>Saman</forenames></author></authors><title>Towards Increase in Quality by Preprocessed Source Code and Measurement
  Analysis of Software Applications</title><categories>cs.SE cs.PL</categories><comments>6 Pages, 9 Figures, 2 Tables</comments><journal-ref>IST Transactions on Information Technology- Theory and
  Applications, Vol. 1, No. 1 (2) ISSN 1913-8822, pp.8-13, 2010</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper two intensive problems faced during software application's
analysis and development process arose by the software industry are briefly
conversed i.e. identification of fault proneness and increase in rate of
variability in the source code of traditional and product line applications. To
contribute in the field of software application analysis and development, and
to mitigate the aforementioned hurdles, a measurement analysis based approach
is discussed in this paper. Furthermore, a prototype is developed based on the
concepts of discussed approach i.e. analyzing preprocessed source code
characteristics, identifying additional level of complexities using several
procedural and object oriented source code measures and visualizing obtained
results in different diagrams e.g. bar charts, file maps and graphs etc.
Developed prototype is discussed in detail in this paper and validated by means
of an experiment as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3257</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3257</id><created>2010-11-14</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author><author><keyname>Popov</keyname><forenames>Vasil</forenames></author></authors><title>Integration of Flexible Web Based GUI in I-SOAS</title><categories>cs.HC cs.AI</categories><comments>In the proceedings of 6th I*PROMS Virtual International Conference on
  Innovative Production Machines and Systems (IPROMS 2010), Session Production
  Organisation and Management, Cardiff University, Whittles Publishing,
  Scotland UK, 15-26 November, 2010</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  It is necessary to improve the concepts of the present web based graphical
user interface for the development of more flexible and intelligent interface
to provide ease and increase the level of comfort at user end like most of the
desktop based applications. This research is conducted targeting the goal of
implementing flexible GUI consisting of a visual component manager with
different components by functionality, design and purpose. In this research
paper we present a Rich Internet Application (RIA) based graphical user
interface for web based product development, and going into the details we
present a comparison between existing RIA Technologies, adopted methodology in
the GUI development and developed prototype.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3258</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3258</id><created>2010-11-14</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author><author><keyname>Tacheva</keyname><forenames>Ina</forenames></author></authors><title>Integration of Agile Ontology Mapping towards NLP Search in I-SOAS</title><categories>cs.CL cs.IR</categories><comments>In 6th I*PROMS Virtual International Conference on Innovative
  Production Machines and Systems (IPROMS 2010), Session Intelligent
  Optimisation, Cardiff University, Whittles Publishing, Scotland UK, 15-26
  November, 2010</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this research paper we address the importance of Product Data Management
(PDM) with respect to its contributions in industry. Moreover we also present
some currently available major challenges to PDM communities and targeting some
of these challenges we present an approach i.e. I-SOAS, and briefly discuss how
this approach can be helpful in solving the PDM community's faced problems.
Furthermore, limiting the scope of this research to one challenge, we focus on
the implementation of a semantic based search mechanism in PDM Systems. Going
into the details, at first we describe the respective field i.e. Language
Technology (LT), contributing towards natural language processing, to take
advantage in implementing a search engine capable of understanding the semantic
out of natural language based search queries. Then we discuss how can we
practically take advantage of LT by implementing its concepts in the form of
software application with the use of semantic web technology i.e. Ontology.
Later, in the end of this research paper, we briefly present a prototype
application developed with the use of concepts of LT towards semantic based
search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3268</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3268</id><created>2010-11-14</created><authors><author><keyname>Lucier</keyname><forenames>Brendan</forenames></author><author><keyname>Leme</keyname><forenames>Renato Paes</forenames></author></authors><title>Improved Social Welfare Bounds for GSP at Equilibrium</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Generalized Second Price auction is the primary method by which sponsered
search advertisements are sold. We study the performance of this auction under
various equilibrium concepts. In particular, we demonstrate that the Bayesian
Price of Anarchy is at most $2(1-1/e)^{-1} \approx 3.16$, significantly
improving upon previously known bounds.
  Our techniques are intuitively straightforward and extend in a number of
ways. For one, our result extends to a bound on the performance of GSP at
coarse correlated equilibria, which captures (for example) a repeated-auction
setting in which agents apply regret-minimizing bidding strategies. In
addition, our analysis is robust against the presence of byzantine agents who
cannot be assumed to participate rationally.
  Additionally, we present tight bounds for the social welfare obtained at pure
NE for the special case of an auction for 3 slots, and discuss potential
methods for extending this analysis to an arbitrary number of slots.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3272</identifier>
 <datestamp>2010-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3272</id><created>2010-11-14</created><updated>2010-11-18</updated><authors><author><keyname>Ren</keyname><forenames>Tian Peng</forenames></author><author><keyname>Guan</keyname><forenames>Yong Liang</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Gunawan</keyname><forenames>Erry</forenames></author><author><keyname>Zhang</keyname><forenames>Er Yang</forenames></author></authors><title>Group-Decodable Space-Time Block Codes with Code Rate &gt; 1</title><categories>cs.IT math.IT</categories><comments>Accepted by IEEE Trans. Commun., including 25 pages, 6 figures and 2
  tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High-rate space-time block codes (STBC with code rate &gt; 1) in multi-input
multi-output (MIMO) systems are able to provide both spatial multiplexing gain
and diversity gain, but have high maximum likelihood (ML) decoding complexity.
Since group-decodable (quasi-orthogonal) code structure can reduce the decoding
complexity, we present in this paper systematic methods to construct
group-decodable high-rate STBC with full symbol-wise diversity gain for
arbitrary transmit antenna number and code length. We show that the proposed
group-decodable STBC can achieve high code rate that increases almost linearly
with the transmit antenna number, and the slope of this near-linear dependence
increases with the code length. Comparisons with existing low-rate and
high-rate codes (such as orthogonal STBC and algebraic STBC) are conducted to
show the decoding complexity reduction and good code performance achieved by
the proposed codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3279</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3279</id><created>2010-11-14</created><authors><author><keyname>Nagamalai</keyname><forenames>Dhinaharan</forenames></author><author><keyname>Dhinakaran</keyname><forenames>Beatrice Cynthia</forenames></author><author><keyname>Lee</keyname><forenames>Jae Kwang</forenames></author></authors><title>Bayesian Based Comment Spam Defending Tool</title><categories>cs.CR</categories><comments>14 Pages,4 Figures, International Journal of Network Security &amp; Its
  Applications (IJNSA), Vol.2, No.4, October 2010</comments><doi>10.5121/ijnsa.2010.2420</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spam messes up user's inbox, consumes network resources and spread worms and
viruses. Spam is flooding of unsolicited, unwanted e mail. Spam in blogs is
called blog spam or comment spam.It is done by posting comments or flooding
spams to the services such as blogs, forums,news,email archives and guestbooks.
Blog spams generally appears on guestbooks or comment pages where spammers fill
a comment box with spam words. In addition to wasting user's time with unwanted
comments, spam also consumes a lot of bandwidth. In this paper, we propose a
software tool to prevent such blog spams by using Bayesian Algorithm based
technique. It is derived from Bayes' Theorem. It gives an output which has a
probability that any comment is spam, given that it has certain words in it.
With using our past entries and a comment entry, this value is obtained and
compared with a threshold value to find if it exceeds the threshold value or
not. By using this concept, we developed a software tool to block comment spam.
The experimental results show that the Bayesian based tool is working well.
This paper has the major findings and their significance of blog spam filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3315</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3315</id><created>2010-11-15</created><updated>2011-06-03</updated><authors><author><keyname>WeiHua</keyname><forenames>Zhan</forenames></author><author><keyname>Zhongzhi</keyname><forenames>Zhang</forenames></author><author><keyname>Jihong</keyname><forenames>Guan</forenames></author><author><keyname>Shuigeng</keyname><forenames>Zhou</forenames></author></authors><title>Evolutionary method for finding communities in bipartite networks</title><categories>physics.data-an cond-mat.stat-mech cs.NE cs.SI physics.soc-ph</categories><comments>15 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important step in unveiling the relation between network structure and
dynamics defined on networks is to detect communities, and numerous methods
have been developed separately to identify community structure in different
classes of networks, such as unipartite networks, bipartite networks, and
directed networks. We show that both unipartite and directed networks can be
represented as bipartite networks, and their modularity is completely
consistent with that for bipartite networks, the detection of modular structure
on which can be reformulated as modularity maximization. To optimize the
bipartite modularity, we develop a modified adaptive genetic algorithm (MAGA),
which is shown to be especially efficient for community structure detection.
The high efficiency of the MAGA is based on the following three improvements we
make. First, we introduce a different measure for the informativeness of a
locus instead of the standard deviation, which can exactly determine which loci
mutate. This measure is the bias between the distribution of a locus over the
current population and the uniform distribution of the locus, i.e., the
Kullback-Leibler divergence between them. Second, we develop a reassignment
technique for differentiating the informative state a locus has attained from
the random state in the initial phase. Third, we present a modified mutation
rule which by incorporating related operation can guarantee the convergence of
the MAGA to the global optimum and can speed up the convergence process.
Experimental results show that the MAGA outperforms existing methods in terms
of modularity for both bipartite and unipartite networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3318</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3318</id><created>2010-11-15</created><authors><author><keyname>Osaki</keyname><forenames>Yusuke</forenames></author><author><keyname>Ishikawa</keyname><forenames>Ken-Ichi</forenames></author></authors><title>Domain Decomposition method on GPU cluster</title><categories>hep-lat cs.MS</categories><comments>7 pages, 1 figure, Lattice 2010 Proceeding</comments><report-no>HUPD-1006</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pallalel GPGPU computing for lattice QCD simulations has a bottleneck on the
GPU to GPU data communication due to the lack of the direct data exchanging
facility. In this work we investigate the performance of quark solver using the
restricted additive Schwarz (RAS) preconditioner on a low cost GPU cluster. We
expect that the RAS preconditioner with appropriate domaindecomposition and
task distribution reduces the communication bottleneck. The GPU cluster we
constructed is composed of four PC boxes, two GPU cards are attached to each
box, and we have eight GPU cards in total. The compute nodes are connected with
rather slow but low cost Gigabit-Ethernet. We include the RAS preconditioner in
the single-precision part of the mixedprecision nested-BiCGStab algorithm and
the single-precision task is distributed to the multiple GPUs. The benchmarking
is done with the O(a)-improved Wilson quark on a randomly generated gauge
configuration with the size of $32^4$. We observe a factor two improvment on
the solver performance with the RAS precoditioner compared to that without the
preconditioner and find that the improvment mainly comes from the reduction of
the communication bottleneck as we expected.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3347</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3347</id><created>2010-11-15</created><updated>2011-05-23</updated><authors><author><keyname>Bartoli</keyname><forenames>Daniele</forenames></author><author><keyname>Davydov</keyname><forenames>Alexander A.</forenames></author><author><keyname>Faina</keyname><forenames>Giorgio</forenames></author><author><keyname>Marcugini</keyname><forenames>Stefano</forenames></author><author><keyname>Pambianco</keyname><forenames>Fernanda</forenames></author></authors><title>On sizes of complete arcs in PG(2,q)</title><categories>math.CO cs.IT math.IT</categories><comments>27 pages, 4 figures, 5 tables</comments><msc-class>51E21, 51E22 (Primary), 94B05 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New upper bounds on the smallest size t_{2}(2,q) of a complete arc in the
projective plane PG(2,q) are obtained for 853 &lt;= q &lt;= 4561 and q\in T1\cup T2
where T1={173,181,193,229,243,257,271,277,293,343,373,409,443,449,457,
461,463,467,479,487,491,499,529,563,569,571,577,587,593,599,601,607,613,617,619,631,
641,661,673,677,683,691, 709},
T2={4597,4703,4723,4733,4789,4799,4813,4831,5003,5347,5641,5843,6011,8192}.
From these new bounds it follows that for q &lt;= 2593 and q=2693,2753, the
relation t_{2}(2,q) &lt; 4.5\sqrt{q} holds. Also, for q &lt;= 4561 we have t_{2}(2,q)
&lt; 4.75\sqrt{q}. It is showed that for 23 &lt;= q &lt;= 4561 and q\in T2\cup
{2^{14},2^{15},2^{18}}, the inequality t_{2}(2,q) &lt; \sqrt{q}ln^{0.75}q is true.
Moreover, the results obtained allow us to conjecture that this estimate holds
for all q &gt;= 23. The new upper bounds are obtained by finding new small
complete arcs with the help of a computer search using randomized greedy
algorithms. Also new constructions of complete arcs are proposed. These
constructions form families of k-arcs in PG(2,q) containing arcs of all sizes k
in a region k_{min} &lt;= k &lt;= k_{max} where k_{min} is of order q/3 or q/4 while
k_{max} has order q/2. The completeness of the arcs obtained by the new
constructions is proved for q &lt;= 1367 and 2003 &lt;= q &lt;= 2063. There is reason to
suppose that the arcs are complete for all q &gt; 1367. New sizes of complete arcs
in PG(2,q) are presented for 169 &lt;= q &lt;= 349 and q=1013,2003.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3362</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3362</id><created>2010-11-15</created><authors><author><keyname>D'Argenio</keyname><forenames>Pedro</forenames></author><author><keyname>Terraf</keyname><forenames>Pedro S&#xe1;nchez</forenames></author><author><keyname>Wolovick</keyname><forenames>Nicol&#xe1;s</forenames></author></authors><title>Bisimulations for Nondeterministic Labeled Markov Processes</title><categories>cs.LO</categories><msc-class>60Jxx</msc-class><acm-class>G.3; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the theory of labeled Markov processes with internal
nondeterminism, a fundamental concept for the further development of a process
theory with abstraction on nondeterministic continuous probabilistic systems.
We define nondeterministic labeled Markov processes (NLMP) and provide three
definition of bisimulations: a bisimulation following a traditional
characterization, a state based bisimulation tailored to our &quot;measurable&quot;
non-determinism, and an event based bisimulation. We show the relation between
them, including that the largest state bisimulation is also an event
bisimulation. We also introduce a variation of the Hennessy-Milner logic that
characterizes event bisimulation and that is sound w.r.t. the other
bisimulations for arbitrary NLMP. This logic, however, is infinitary as it
contains a denumerable $\lor$. We then introduce a finitary sublogic that
characterize all bisimulations for image finite NLMP whose underlying measure
space is also analytic. Hence, in this setting, all notions of bisimulation we
deal with turn out to be equal. Finally, we show that all notions of
bisimulations are different in the general case. The counterexamples that
separate them turn to be non-probabilistic NLMP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3373</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3373</id><created>2010-11-15</created><updated>2011-12-14</updated><authors><author><keyname>Ueckerdt</keyname><forenames>Torsten</forenames></author></authors><title>CAT-generation of ideals</title><categories>math.CO cs.DS</categories><comments>This paper has been withdrawn by the author due to a crucial error</comments><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of generating all ideals of a poset. It is a long
standing open problem, whether or not the ideals of any poset can be generated
in constant amortized time, CAT for short. We refine the tree traversal, a
method introduced by Pruesse and Ruskey in 1993, to obtain a CAT-generator for
two large classes of posets: posets of interval dimension at most two and so
called locally planar posets. This includes all posets for which a
CAT-generator was known before. Posets of interval dimension at most two
generalize both, interval orders and 2-dimensional posets. Locally planar
posets generalize for example posets with a planar cover graph.
  We apply our results to CAT-generate all c-orientations of a planar graph. As
a special case this is a CAT-generator for many combinatorial objects like
domino and lozenge tilings, planar spanning trees, planar bipartite perfect
matchings, Schnyder woods, and others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3380</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3380</id><created>2010-11-15</created><updated>2012-07-12</updated><authors><author><keyname>Passerieux</keyname><forenames>Jean-Michel</forenames></author><author><keyname>Socheleau</keyname><forenames>Francois-Xavier</forenames></author><author><keyname>Laot</keyname><forenames>Christophe</forenames></author></authors><title>Achievable Rates over Doubly Selective Rician-Fading Channels under
  Peak-Power Constraint</title><categories>cs.IT math.IT</categories><comments>paper withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this paper is to obtain a better knowledge of the achievable data
rate over noncoherent Rician fading channel with time and frequency memory. We
assume that the average-power as well as the peak-power of the input signal are
finite and the peak-power limitation is applied in the time domain. Expression
for this rate is based on a lower bound on mutual information that assume
independent and identically distributed input data symbols. The lower bound is
expressed as a difference of two terms. The first term is the information rate
of the coherent channel with a weighted signal-to-noise ratio that results from
the peak-power limitation. The second term is a penalty term, explicit in the
Doppler spectrum of the channel, that captures the effect of the channel
uncertainty induced by the noncoherent setting. Impact of channel parameters,
such as delay and Doppler spread, on the information rate are discussed and
numerical applications on an experimental Rician channel surveyed in an
acoustic underwater environment are also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3382</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3382</id><created>2010-11-15</created><authors><author><keyname>Amin</keyname><forenames>Md. Tanvir Al</forenames></author></authors><title>Multi-core: Adding a New Dimension to Computing</title><categories>cs.AR cs.DC</categories><comments>A short survey of trends in Multi-core Processors, 4 pages, 8 figures</comments><acm-class>C.1.2; C.5.3; D.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Invention of Transistors in 1948 started a new era in technology, called
Solid State Electronics. Since then, sustaining development and advancement in
electronics and fabrication techniques has caused the devices to shrink in size
and become smaller, paving the quest for increasing density and clock speed.
That quest has suddenly come to a halt due to fundamental bounds applied by
physical laws. But, demand for more and more computational power is still
prevalent in the computing world. As a result, the microprocessor industry has
started exploring the technology along a different dimension. Speed of a single
work unit (CPU) is no longer the concern, rather increasing the number of
independent processor cores packed in a single package has become the new
concern. Such processors are commonly known as multi-core processors. Scaling
the performance by using multiple cores has gained so much attention from the
academia and the industry, that not only desktops, but also laptops, PDAs, cell
phones and even embedded devices today contain these processors. In this paper,
we explore state of the art technologies for multi-core processors and existing
software tools to support parallelism. We also discuss present and future trend
of research in this field. From our survey, we conclude that next few decades
are going to be marked by the success of this &quot;Ubiquitous parallel processing&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3397</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3397</id><created>2010-11-15</created><authors><author><keyname>Tarasenko</keyname><forenames>Sergey</forenames></author></authors><title>The Inverse Task of the Reflexive Game Theory: Theoretical Matters,
  Practical Applications and Relationship with Other Issues</title><categories>cs.MA cs.AI cs.RO</categories><comments>27 pages, 6 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Reflexive Game Theory (RGT) has been recently proposed by Vladimir
Lefebvre to model behavior of individuals in groups. The goal of this study is
to introduce the Inverse task. We consider methods of solution together with
practical applications. We present a brief overview of the RGT for easy
understanding of the problem. We also develop the schematic representation of
the RGT inference algorithms to create the basis for soft- and hardware
solutions of the RGT tasks. We propose a unified hierarchy of schemas to
represent humans and robots. This hierarchy is considered as a unified
framework to solve the entire spectrum of the RGT tasks. We conclude by
illustrating how this framework can be applied for modeling of mixed groups of
humans and robots. All together this provides the exhaustive solution of the
Inverse task and clearly illustrates its role and relationships with other
issues considered in the RGT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3400</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3400</id><created>2010-11-15</created><updated>2010-11-26</updated><authors><author><keyname>Morton</keyname><forenames>Anthony B.</forenames></author></authors><title>Prize insights in probability, and one goat of a recycled error: Jason
  Rosenhouse's The Monty Hall Problem</title><categories>math.HO cs.AI math.PR math.ST stat.TH</categories><comments>Book review, 10 pages; updated with some additions and revisions to
  middle section</comments><msc-class>60A05, 97A20, 97K50 (Primary), 60C05, 62A01, 91A20, 91A35, 91A90,
  91E10, 97A80 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Monty Hall problem is the TV game scenario where you, the contestant, are
presented with three doors, with a car hidden behind one and goats hidden
behind the other two. After you select a door, the host (Monty Hall) opens a
second door to reveal a goat. You are then invited to stay with your original
choice of door, or to switch to the remaining unopened door, and claim whatever
you find behind it. Assuming your objective is to win the car, is your best
strategy to stay or switch, or does it not matter? Jason Rosenhouse has
provided the definitive analysis of this game, along with several intriguing
variations, and discusses some of its psychological and philosophical
implications. This extended review examines several themes from the book in
some detail from a Bayesian perspective, and points out one apparently
inadvertent error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3407</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3407</id><created>2010-11-15</created><authors><author><keyname>de Caso</keyname><forenames>Guido</forenames></author><author><keyname>Garbervetsky</keyname><forenames>Diego</forenames></author><author><keyname>Gor&#xed;n</keyname><forenames>Daniel</forenames></author></authors><title>Reducing the Number of Annotations in a Verification-oriented Imperative
  Language</title><categories>cs.PL cs.SE</categories><comments>15 pages, 8 figures</comments><journal-ref>Symposium on Automatic Program Verification 2009, informal
  proceedings (http://se.ethz.ch/apv/program.html)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated software verification is a very active field of research which has
made enormous progress both in theoretical and practical aspects. Recently, an
important amount of research effort has been put into applying these techniques
on top of mainstream programming languages. These languages typically provide
powerful features such as reflection, aliasing and polymorphism which are handy
for practitioners but, in contrast, make verification a real challenge. In this
work we present Pest, a simple experimental, while-style, multiprocedural,
imperative programming language which was conceived with verifiability as one
of its main goals. This language forces developers to concurrently think about
both the statements needed to implement an algorithm and the assertions
required to prove its correctness. In order to aid programmers, we propose
several techniques to reduce the number and complexity of annotations required
to successfully verify their programs. In particular, we show that high-level
iteration constructs may alleviate the need for providing complex loop
annotations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3436</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3436</id><created>2010-08-15</created><authors><author><keyname>Whitworth</keyname><forenames>B.</forenames></author></authors><title>The emergence of the physical world from information processing</title><categories>cs.OH</categories><journal-ref>Quantum Biosystems 2010, 2 (1) 221-249</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper links the conjecture that the physical world is a virtual reality
to the findings of modern physics. What is usually the subject of science
fiction is here proposed as a scientific theory open to empirical evaluation.
We know from physics how the world behaves, and from computing how information
behaves, so whether the physical world arises from ongoing information
processing is a question science can evaluate. A prima facie case for the
virtual reality conjecture is presented. If a photon is a pixel on a
multi-dimensional grid that gives rise to space, the speed of light could
reflect its refresh rate. If mass, charge and energy all arise from processing,
the many conservation laws of physics could reduce to a single law of dynamic
information conservation. If the universe is a virtual reality, then its big
bang creation could be simply when the system was booted up. Deriving core
physics from information processing could reconcile relativity and quantum
theory, with the former how processing creates the space-time operating system
and the latter how it creates energy and matter applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3441</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3441</id><created>2010-11-15</created><updated>2011-01-14</updated><authors><author><keyname>Belazzougui</keyname><forenames>Djamal</forenames></author></authors><title>Worst case efficient single and multiple string matching in the Word-RAM
  model</title><categories>cs.DS</categories><comments>Full version of an extended abstract presented at IWOCA 2010
  conference</comments><doi>10.1007/978-3-642-19222-7_10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we explore worst-case solutions for the problems of single and
multiple matching on strings in the word RAM model with word length w. In the
first problem, we have to build a data structure based on a pattern p of length
m over an alphabet of size sigma such that we can answer to the following
query: given a text T of length n, where each character is encoded using
log(sigma) bits return the positions of all the occurrences of p in T (in the
following we refer by occ to the number of reported occurrences). For the
multi-pattern matching problem we have a set S of d patterns of total length m
and a query on a text T consists in finding all positions of all occurrences in
T of the patterns in S. As each character of the text is encoded using log
sigma bits and we can read w bits in constant time in the RAM model, we assume
that we can read up to (w/log sigma) consecutive characters of the text in one
time step. This implies that the fastest possible query time for both problems
is O((n(log sigma/w)+occ). In this paper we present several different results
for both problems which come close to that best possible query time. We first
present two different linear space data structures for the first and second
problem: the first one answers to single pattern matching queries in time
O(n(1/m+log sigma/w)+occ) while the second one answers to multiple pattern
matching queries to O(n((log d+log y+log log d)/y+log sigma/w)+occ) where y is
the length of the shortest pattern in the case of multiple pattern-matching. We
then show how a simple application of the four russian technique permits to get
data structures with query times independent of the length of the shortest
pattern (the length of the only pattern in case of single string matching) at
the expense of using more space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3466</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3466</id><created>2010-11-15</created><authors><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author><author><keyname>Johannsen</keyname><forenames>Daniel</forenames></author><author><keyname>Winzen</keyname><forenames>Carola</forenames></author></authors><title>Non-Existence of Linear Universal Drift Functions</title><categories>cs.NE math.PR</categories><comments>19 pages; This work contains parts of the GECCO 2010 and CEC 2010
  papers of the same authors</comments><acm-class>F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Drift analysis has become a powerful tool to prove bounds on the runtime of
randomized search heuristics. It allows, for example, fairly simple proofs for
the classical problem how the (1+1) Evolutionary Algorithm (EA) optimizes an
arbitrary pseudo-Boolean linear function. The key idea of drift analysis is to
measure the progress via another pseudo-Boolean function (called drift
function) and use deeper results from probability theory to derive from this a
good bound for the runtime of the EA. Surprisingly, all these results manage to
use the same drift function for all linear objective functions.
  In this work, we show that such universal drift functions only exist if the
mutation probability is close to the standard value of $1/n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3479</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3479</id><created>2010-11-15</created><updated>2011-03-17</updated><authors><author><keyname>Pattinson</keyname><forenames>Dirk</forenames><affiliation>Imperial College London</affiliation></author><author><keyname>Schr&#xf6;der</keyname><forenames>Lutz</forenames><affiliation>DFKI</affiliation></author></authors><title>Generic Modal Cut Elimination Applied to Conditional Logics</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.4.1, I.2.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 1 (March 17,
  2011) lmcs:968</journal-ref><doi>10.2168/LMCS-7(1:4)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a general criterion for cut elimination in sequent calculi for
propositional modal logics, which rests on absorption of cut, contraction,
weakening and inversion by the purely modal part of the rule system. Our
criterion applies also to a wide variety of logics outside the realm of normal
modal logic. We give extensive example instantiations of our framework to
various conditional logics. For these, we obtain fully internalised calculi
which are substantially simpler than those known in the literature, along with
leaner proofs of cut elimination and complexity. In one case, conditional logic
with modus ponens and conditional excluded middle, cut elimination and
complexity were explicitly stated as open in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3480</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3480</id><created>2010-11-15</created><authors><author><keyname>Gagie</keyname><forenames>Travis</forenames></author><author><keyname>K&#xe4;rkk&#xe4;inen</keyname><forenames>Juha</forenames></author></authors><title>Counting Colours in Compressed Strings</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose we are asked to preprocess a string \(s [1..n]\) such that later,
given a substring's endpoints, we can quickly count how many distinct
characters it contains. In this paper we give a data structure for this problem
that takes \(n H_0 (s) + \Oh{n} + \oh{n H_0 (s)}\) bits, where \(H_0 (s)\) is
the 0th-order empirical entropy of $s$, and answers queries in $\Oh{\log^{1 +
\epsilon} n}$ time for any constant \(\epsilon &gt; 0\). We also show how our data
structure can be made partially dynamic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3482</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3482</id><created>2010-11-15</created><authors><author><keyname>Acharya</keyname><forenames>Srivathsa</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author><author><keyname>Dewangan</keyname><forenames>Vijay</forenames></author><author><keyname>Sankara</keyname><forenames>Navneet</forenames></author><author><keyname>Hegde</keyname><forenames>Malati</forenames></author><author><keyname>Anand</keyname><forenames>S. V. R.</forenames></author></authors><title>Distributed Construction of the Critical Geometric Graph in Dense
  Wireless Sensor Networks</title><categories>cs.NI</categories><comments>20 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor networks are often modeled in terms of a dense deployment of
smart sensor nodes in a two-dimensional region. Give a node deployment, the
\emph{critical geometric graph (CGG)} over these locations (i.e., the connected
\emph{geometric graph (GG)} with the smallest radius) is a useful structure
since it provides the most accurate proportionality between hop-count and
Euclidean distance. Hence, it can be used for GPS-free node localisation as
well as minimum distance packet forwarding. It is also known to be
asymptotically optimal for network transport capacity and power efficiency. In
this context, we propose DISCRIT, a distributed and asynchronous algorithm for
obtaining an approximation of the CGG on the node locations. The algorithm does
not require the knowledge of node locations or internode distances, nor does it
require pair-wise RSSI (Received Signal Strength Indication) measurements to be
made. Instead, the algorithm makes use of successful Hello receipt counts
(obtained during a Hello-protocol-based neighbour discovery process) as edge
weights, along with a simple distributed min-max computation algorithm. In this
paper, we first provide the theory for justifying the use of the above edge
weights. Then we provide extensive simulation results to demonstrate the
efficacy of DISCRIT in obtaining an approximation of the CGG. Finally, we show
how the CGG obtained from DISCRIT performs when used in certain network
self-organisation algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3491</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3491</id><created>2010-11-15</created><updated>2011-04-02</updated><authors><author><keyname>Gagie</keyname><forenames>Travis</forenames></author><author><keyname>Karhu</keyname><forenames>Kalle</forenames></author><author><keyname>K&#xe4;rkk&#xe4;inen</keyname><forenames>Juha</forenames></author><author><keyname>M&#xe4;kinen</keyname><forenames>Veli</forenames></author><author><keyname>Salmela</keyname><forenames>Leena</forenames></author></authors><title>Pattern Kits</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose we have just performed searches in a self-index for two patterns $A$
and $B$ and now we want to search for their concatenation \A B); how can we
best make use of our previous computations? In this paper we consider this
problem and, more generally, how we can store a dynamic library of patterns
that we can easily manipulate in interesting ways. We give a space- and
time-efficient data structure for this problem that is compatible with many of
the best self-indexes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3493</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3493</id><created>2010-11-15</created><updated>2011-03-02</updated><authors><author><keyname>Chen</keyname><forenames>Ho-Lin</forenames></author><author><keyname>Doty</keyname><forenames>David</forenames></author><author><keyname>Seki</keyname><forenames>Shinnosuke</forenames></author></authors><title>Program Size and Temperature in Self-Assembly</title><categories>cs.CC cs.DS</categories><comments>The previous version contained more sections, but we have split that
  paper into two. The other half will be posted as a separate paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Winfree's abstract Tile Assembly Model (aTAM) is a model of molecular
self-assembly of DNA complexes known as tiles, which float freely in solution
and attach one at a time to a growing &quot;seed&quot; assembly based on specific binding
sites on their four sides. We show that there is a polynomial-time algorithm
that, given an n x n square, finds the minimal tile system (i.e., the system
with the smallest number of distinct tile types) that uniquely self-assembles
the square, answering an open question of Adleman, Cheng, Goel, Huang, Kempe,
Moisset de Espanes, and Rothemund (&quot;Combinatorial Optimization Problems in
Self-Assembly&quot;, STOC 2002). Our investigation leading to this algorithm reveals
other positive and negative results about the relationship between the size of
a tile system and its &quot;temperature&quot; (the binding strength threshold required
for a tile to attach).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3494</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3494</id><created>2010-11-15</created><authors><author><keyname>Johnson</keyname><forenames>Jason K.</forenames></author><author><keyname>Netrapalli</keyname><forenames>Praneeth</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author></authors><title>Learning Planar Ising Models</title><categories>stat.ML cs.AI</categories><comments>11 pages, 4 figures, Submitted to 14th International Conference on
  Artificial Intelligence and Statistics (AISTATS 2011)</comments><report-no>LANL LA-UR 10-07656</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inference and learning of graphical models are both well-studied problems in
statistics and machine learning that have found many applications in science
and engineering. However, exact inference is intractable in general graphical
models, which suggests the problem of seeking the best approximation to a
collection of random variables within some tractable family of graphical
models. In this paper, we focus our attention on the class of planar Ising
models, for which inference is tractable using techniques of statistical
physics [Kac and Ward; Kasteleyn]. Based on these techniques and recent methods
for planarity testing and planar embedding [Chrobak and Payne], we propose a
simple greedy algorithm for learning the best planar Ising model to approximate
an arbitrary collection of binary random variables (possibly from sample data).
Given the set of all pairwise correlations among variables, we select a planar
graph and optimal planar Ising model defined on this graph to best approximate
that set of correlations. We demonstrate our method in some simulations and for
the application of modeling senate voting records.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3498</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3498</id><created>2010-11-15</created><authors><author><keyname>Li</keyname><forenames>Yao</forenames></author><author><keyname>Soljanin</keyname><forenames>Emina</forenames></author><author><keyname>Spasojevic</keyname><forenames>Predrag</forenames></author></authors><title>Effects of the Generation Size and Overlap on Throughput and Complexity
  in Randomized Linear Network Coding</title><categories>cs.IT cs.DM math.IT</categories><comments>To appear in IEEE Transactions on Information Theory Special Issue:
  Facets of Coding Theory: From Algorithms to Networks, Feb 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To reduce computational complexity and delay in randomized network coded
content distribution, and for some other practical reasons, coding is not
performed simultaneously over all content blocks, but over much smaller,
possibly overlapping subsets of these blocks, known as generations. A penalty
of this strategy is throughput reduction. To analyze the throughput loss, we
model coding over generations with random generation scheduling as a coupon
collector's brotherhood problem. This model enables us to derive the expected
number of coded packets needed for successful decoding of the entire content as
well as the probability of decoding failure (the latter only when generations
do not overlap) and further, to quantify the tradeoff between computational
complexity and throughput. Interestingly, with a moderate increase in the
generation size, throughput quickly approaches link capacity. Overlaps between
generations can further improve throughput substantially for relatively small
generation sizes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3516</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3516</id><created>2010-11-15</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>A statistical-mechanical view on source coding: physical compression and
  data compression</title><categories>cond-mat.stat-mech cs.IT math.IT</categories><comments>17 pages, 2 figures; submitted to the Journal of Statistical
  Mechanics: Theory and Experiment</comments><doi>10.1088/1742-5468/2011/01/P01029</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We draw a certain analogy between the classical information-theoretic problem
of lossy data compression (source coding) of memoryless information sources and
the statistical mechanical behavior of a certain model of a chain of connected
particles (e.g., a polymer) that is subjected to a contracting force. The free
energy difference pertaining to such a contraction turns out to be proportional
to the rate-distortion function in the analogous data compression model, and
the contracting force is proportional to the derivative this function. Beyond
the fact that this analogy may be interesting on its own right, it may provide
a physical perspective on the behavior of optimum schemes for lossy data
compression (and perhaps also, an information-theoretic perspective on certain
physical system models). Moreover, it triggers the derivation of lossy
compression performance for systems with memory, using analysis tools and
insights from statistical mechanics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3534</identifier>
 <datestamp>2010-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3534</id><created>2010-11-15</created><authors><author><keyname>Challacombe</keyname><forenames>Matt</forenames></author><author><keyname>Bock</keyname><forenames>Nicolas</forenames></author></authors><title>Fast Multiplication of Matrices with Decay</title><categories>cs.DS cond-mat.mtrl-sci cs.MS cs.NA</categories><report-no>LA-UR 10-07458</report-no><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  A fast algorithm for the approximate multiplication of matrices with decay is
introduced; the Sparse Approximate Matrix Multiply (SpAMM) reduces complexity
in the product space, a different approach from current methods that economize
within the matrix space through truncation or rank reduction. Matrix truncation
(element dropping) is compared to SpAMM for quantum chemical matrices with
approximate exponential and algebraic decay. For matched errors in the
electronic total energy, SpAMM is found to require fewer to far fewer floating
point operations relative to dropping. The challenges and opportunities
afforded by this new approach are discussed, including the potential for high
performance implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3542</identifier>
 <datestamp>2012-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3542</id><created>2010-11-15</created><updated>2012-06-15</updated><authors><author><keyname>D&#xed;az-Caro</keyname><forenames>Alejandro</forenames></author><author><keyname>Petit</keyname><forenames>Barbara</forenames></author></authors><title>Linearity in the non-deterministic call-by-value setting</title><categories>cs.LO</categories><comments>15 pages. To appear in WoLLIC 2012</comments><journal-ref>Lecture Notes in Computer Science 7456, 216-231 (2012)</journal-ref><doi>10.1007/978-3-642-32621-9_16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the non-deterministic extension of the call-by-value lambda
calculus, which corresponds to the additive fragment of the linear-algebraic
lambda-calculus. We define a fine-grained type system, capturing the right
linearity present in such formalisms. After proving the subject reduction and
the strong normalisation properties, we propose a translation of this calculus
into the System F with pairs, which corresponds to a non linear fragment of
linear logic. The translation provides a deeper understanding of the linearity
in our setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3550</identifier>
 <datestamp>2010-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3550</id><created>2010-11-15</created><authors><author><keyname>Kamal</keyname><forenames>Ahmed E.</forenames></author><author><keyname>Ramamoorthy</keyname><forenames>Aditya</forenames></author><author><keyname>Long</keyname><forenames>Long</forenames></author><author><keyname>Li</keyname><forenames>Shizheng</forenames></author></authors><title>Overlay Protection Against Link Failures Using Network Coding</title><categories>cs.IT math.IT</categories><comments>14 pages, 10 figures, accepted by IEEE/ACM Transactions on Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a network coding-based protection scheme against single
and multiple link failures. The proposed strategy ensures that in a connection,
each node receives two copies of the same data unit: one copy on the working
circuit, and a second copy that can be extracted from linear combinations of
data units transmitted on a shared protection path. This guarantees
instantaneous recovery of data units upon the failure of a working circuit. The
strategy can be implemented at an overlay layer, which makes its deployment
simple and scalable. While the proposed strategy is similar in spirit to the
work of Kamal '07 &amp; '10, there are significant differences. In particular, it
provides protection against multiple link failures. The new scheme is simpler,
less expensive, and does not require the synchronization required by the
original scheme. The sharing of the protection circuit by a number of
connections is the key to the reduction of the cost of protection. The paper
also conducts a comparison of the cost of the proposed scheme to the 1+1 and
shared backup path protection (SBPP) strategies, and establishes the benefits
of our strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3557</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3557</id><created>2010-11-15</created><authors><author><keyname>Plangprasopchok</keyname><forenames>Anon</forenames></author><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author><author><keyname>Getoor</keyname><forenames>Lise</forenames></author></authors><title>A Probabilistic Approach for Learning Folksonomies from Structured Data</title><categories>cs.AI cs.CY cs.LG</categories><comments>In Proceedings of the 4th ACM Web Search and Data Mining Conference
  (WSDM)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning structured representations has emerged as an important problem in
many domains, including document and Web data mining, bioinformatics, and image
analysis. One approach to learning complex structures is to integrate many
smaller, incomplete and noisy structure fragments. In this work, we present an
unsupervised probabilistic approach that extends affinity propagation to
combine the small ontological fragments into a collection of integrated,
consistent, and larger folksonomies. This is a challenging task because the
method must aggregate similar structures while avoiding structural
inconsistencies and handling noise. We validate the approach on a real-world
social media dataset, comprised of shallow personal hierarchies specified by
many individual users, collected from the photosharing website Flickr. Our
empirical results show that our proposed approach is able to construct deeper
and denser structures, compared to an approach using only the standard affinity
propagation algorithm. Additionally, the approach yields better overall
integration quality than a state-of-the-art approach based on incremental
relational clustering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3571</identifier>
 <datestamp>2010-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3571</id><created>2010-11-15</created><updated>2010-11-17</updated><authors><author><keyname>Ghosh</keyname><forenames>Rumi</forenames></author><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author></authors><title>A Framework for Quantitative Analysis of Cascades on Networks</title><categories>cs.SI cs.CY physics.soc-ph</categories><comments>In Proceedings of 4th ACM Conference on Web Search and Data Mining</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How does information flow in online social networks? How does the structure
and size of the information cascade evolve in time? How can we efficiently mine
the information contained in cascade dynamics? We approach these questions
empirically and present an efficient and scalable mathematical framework for
quantitative analysis of cascades on networks. We define a cascade generating
function that captures the details of the microscopic dynamics of the cascades.
We show that this function can also be used to compute the macroscopic
properties of cascades, such as their size, spread, diameter, number of paths,
and average path length. We present an algorithm to efficiently compute cascade
generating function and demonstrate that while significantly compressing
information within a cascade, it nevertheless allows us to accurately
reconstruct its structure. We use this framework to study information dynamics
on the social network of Digg. Digg allows users to post and vote on stories,
and easily see the stories that friends have voted on. As a story spreads on
Digg through voting, it generates cascades. We extract cascades of more than
3,500 Digg stories and calculate their macroscopic and microscopic properties.
We identify several trends in cascade dynamics: spreading via chaining,
branching and community. We discuss how these affect the spread of the story
through the Digg social network. Our computational framework is general and
offers a practical solution to quantitative analysis of the microscopic
structure of even very large cascades.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3580</identifier>
 <datestamp>2012-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3580</id><created>2010-11-15</created><updated>2012-09-14</updated><authors><author><keyname>Xiao</keyname><forenames>Yuanzhang</forenames></author><author><keyname>Zame</keyname><forenames>William R.</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Technology Choices and Pricing Policies in Public and Private Wireless
  Networks</title><categories>cs.GT</categories><comments>14 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the provision of a wireless network by a monopolistic
provider who may be either benevolent (seeking to maximize social welfare) or
selfish (seeking to maximize provider profit). The paper addresses questions
that do not seem to have been studied before in the engineering literature on
wireless networks: Under what circumstances is it feasible for a provider,
either benevolent or selfish, to operate a network in such a way as to cover
costs? How is the optimal behavior of a benevolent provider different from the
optimal behavior of a selfish provider, and how does this difference affect
social welfare? And, most importantly, how does the medium access control (MAC)
technology influence the answers to these questions? To address these
questions, we build a general model, and provide analysis and simulations for
simplified but typical scenarios; the focus in these scenarios is on the
contrast between the outcomes obtained under carrier-sensing multiple access
(CSMA) and outcomes obtained under time-division multiple access (TDMA).
Simulation results demonstrate that differences in MAC technology can have a
significant effect on social welfare, on provider profit, and even on the
(financial) feasibility of a wireless network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3583</identifier>
 <datestamp>2010-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3583</id><created>2010-11-15</created><authors><author><keyname>Bader</keyname><forenames>Michael</forenames></author><author><keyname>Bungartz</keyname><forenames>Hans-Joachim</forenames></author><author><keyname>Mudigere</keyname><forenames>Dheevatsa</forenames></author><author><keyname>Narasimhan</keyname><forenames>Srihari</forenames></author><author><keyname>Narayanan</keyname><forenames>Babu</forenames></author></authors><title>Fast GPGPU Data Rearrangement Kernels using CUDA</title><categories>cs.DC cs.GR cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many high performance-computing algorithms are bandwidth limited, hence the
need for optimal data rearrangement kernels as well as their easy integration
into the rest of the application. In this work, we have built a CUDA library of
fast kernels for a set of data rearrangement operations. In particular, we have
built generic kernels for rearranging m dimensional data into n dimensions,
including Permute, Reorder, Interlace/De-interlace, etc. We have also built
kernels for generic Stencil computations on a two-dimensional data using
templates and functors that allow application developers to rapidly build
customized high performance kernels. All the kernels built achieve or surpass
best-known performance in terms of bandwidth utilization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3588</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3588</id><created>2010-11-16</created><updated>2011-02-23</updated><authors><author><keyname>Wang</keyname><forenames>I-Hsiang</forenames></author></authors><title>Distributed Interference Cancellation in Multiple Access Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory. Corrected typos
  in the current version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a Gaussian multiple access channel with multiple
independent additive white Gaussian interferences. Each interference is known
to exactly one transmitter non-causally. The capacity region is characterized
to within a constant gap regardless of channel parameters. These results are
based on a layered modulo-lattice scheme which realizes distributed
interference cancellation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3594</identifier>
 <datestamp>2010-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3594</id><created>2010-11-16</created><authors><author><keyname>Jiang</keyname><forenames>Libin</forenames></author><author><keyname>Walrand</keyname><forenames>Jean</forenames></author></authors><title>Approaching Throughput-optimality in Distributed CSMA Scheduling
  Algorithms with Collisions</title><categories>cs.NI</categories><comments>To appear in IEEE/ACM Transactions on Networking. This is the longer
  version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It was shown recently that CSMA (Carrier Sense Multiple Access)-like
distributed algorithms can achieve the maximal throughput in wireless networks
(and task processing networks) under certain assumptions. One important, but
idealized assumption is that the sensing time is negligible, so that there is
no collision. In this paper, we study more practical CSMA-based scheduling
algorithms with collisions. First, we provide a Markov chain model and give an
explicit throughput formula which takes into account the cost of collisions and
overhead. The formula has a simple form since the Markov chain is &quot;almost&quot;
time-reversible. Second, we propose transmission-length control algorithms to
approach throughput optimality in this case. Sufficient conditions are given to
ensure the convergence and stability of the proposed algorithms. Finally, we
characterize the relationship between the CSMA parameters (such as the maximum
packet lengths) and the achievable capacity region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3595</identifier>
 <datestamp>2010-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3595</id><created>2010-11-16</created><authors><author><keyname>Shinavier</keyname><forenames>Joshua</forenames></author></authors><title>Optimizing real-time RDF data streams</title><categories>cs.AI cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Resource Description Framework (RDF) provides a common data model for the
integration of &quot;real-time&quot; social and sensor data streams with the Web and with
each other. While there exist numerous protocols and data formats for
exchanging dynamic RDF data, or RDF updates, these options should be examined
carefully in order to enable a Semantic Web equivalent of the high-throughput,
low-latency streams of typical Web 2.0, multimedia, and gaming applications.
This paper contains a brief survey of RDF update formats and a high-level
discussion of both TCP and UDP-based transport protocols for updates. Its main
contribution is the experimental evaluation of a UDP-based architecture which
serves as a real-world example of a high-performance RDF streaming application
in an Internet-scale distributed environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3632</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3632</id><created>2010-11-16</created><updated>2011-02-07</updated><authors><author><keyname>Dolev</keyname><forenames>Shlomi</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Dubois</keyname><forenames>Swan</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Potop-Butucaru</keyname><forenames>Maria</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6</affiliation></author></authors><title>Stabilizing data-link over non-FIFO channels with optimal
  fault-resilience</title><categories>cs.DC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-stabilizing systems have the ability to converge to a correct behavior
when started in any configuration. Most of the work done so far in the
self-stabilization area assumed either communication via shared memory or via
FIFO channels. This paper is the first to lay the bases for the design of
self-stabilizing message passing algorithms over unreliable non-FIFO channels.
We propose a fault-send-deliver optimal stabilizing data-link layer that
emulates a reliable FIFO communication channel over unreliable capacity bounded
non-FIFO channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3666</identifier>
 <datestamp>2010-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3666</id><created>2010-11-16</created><authors><author><keyname>Jost</keyname><forenames>Juergen</forenames></author><author><keyname>Li</keyname><forenames>Wei</forenames></author></authors><title>The tragedy of the commons in a multi-population complementarity game</title><categories>q-bio.PE cs.GT physics.soc-ph</categories><comments>4 pages, 2 figures, ECCS 09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a complementarity game with multiple populations whose members'
offered contributions are put together towards some common aim. When the sum of
the players' offers reaches or exceeds some threshold K, they each receive K
minus their own offers. Else, they all receive nothing. Each player tries to
offer as little as possible, hoping that the sum of the contributions still
reaches K, however. The game is symmetric at the individual level, but has many
equilibria that are more or less favorable to the members of certain
populations. In particular, it is possible that the members of one or several
populations do not contribute anything, a behavior called defecting, while the
others still contribute enough to reach the threshold. Which of these
equilibria then is attained is decided by the dynamics at the population level
that in turn depends on the strategic options the players possess. We find that
defecting occurs when more than 3 populations participate in the game, even
when the strategy scheme employed is very simple, if certain conditions for the
system parameters are satisfied. The results are obtained through systematic
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3668</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3668</id><created>2010-11-16</created><updated>2011-05-26</updated><authors><author><keyname>Roversi</keyname><forenames>Luca</forenames></author></authors><title>Linear lambda Calculus with Explicit Substitutions as Proof-Search in
  Deep Inference</title><categories>cs.LO</categories><comments>26 pages: Final technical report associated to the TLCA2011 paper
  &quot;Linear lambda calculus and deep inference&quot;</comments><acm-class>F.4.1</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  SBV is a deep inference system that extends the set of logical operators of
multiplicative linear logic with the non commutative operator Seq. We introduce
the logical system SBVr which extends SBV by adding a self-dual atom-renaming
operator to it. We prove that the cut elimination holds on SBVr. SBVr and its
cut free subsystem BVr are complete and sound with respect to linear lambda
calculus with explicit substitutions. Under any strategy, a sequence of
evaluation steps of any linear lambda-term M becomes a process of proof-search
in SBVr (BVr) once M is mapped into a formula of SBVr. Completeness and
soundness follow from simulating linear beta-reduction with explicit
substitutions as processes. The role of the new renaming operator of SBVr is to
rename channel-names on-demand. This simulates the substitution that occurs in
a beta-reduction. Despite SBVr is a minimal extension of SBV its proof-search
can compute all boolean functions, as linear lambda-calculus with explicit
substitutions can compute all boolean functions as well. So, proof search of
SBVr and BVr is at least ptime-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3674</identifier>
 <datestamp>2010-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3674</id><created>2010-11-16</created><authors><author><keyname>Jost</keyname><forenames>Juergen</forenames></author><author><keyname>Li</keyname><forenames>Wei</forenames></author></authors><title>Learning, evolution and population dynamics</title><categories>q-bio.PE cs.GT physics.soc-ph</categories><comments>26 pages, 13 figures</comments><journal-ref>Advances in Complex Systems 11 (6), 901-926, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a complementarity game as a systematic tool for the investigation of
the interplay between individual optimization and population effects and for
the comparison of different strategy and learning schemes. The game randomly
pairs players from opposite populations. The game is symmetric at the
individual level, but has many equilibria that are more or less favorable to
the members of the two populations. Which of these equilibria then is attained
is decided by the dynamics at the population level. Players play repeatedly,
but in each round with a new opponent. They can learn from their previous
encounters and translate this into their actions in the present round on the
basis of strategic schemes. The schemes can be quite simple, or very elaborate.
We can then break the symmetry in the game and give the members of the two
populations access to different strategy spaces. Typically, simpler strategy
types have an advantage because they tend to go more quickly towards a
favorable equilibrium which, once reached, the other population is forced to
accept. Also, populations with bolder individuals that may not fare so well at
the level of individual performance may obtain an advantage towards ones with
more timid players. By checking the effects of parameters such as the
generation length or the mutation rate, we are able to compare the relative
contributions of individual learning and evolutionary adaptations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3701</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3701</id><created>2010-11-16</created><updated>2010-11-21</updated><authors><author><keyname>Dinitz</keyname><forenames>Michael</forenames></author><author><keyname>Krauthgamer</keyname><forenames>Robert</forenames></author></authors><title>Directed Spanners via Flow-Based Linear Programs</title><categories>cs.DS</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine directed spanners through flow-based linear programming
relaxations. We design an $\~O(n^{2/3})$-approximation algorithm for the
directed $k$-spanner problem that works for all $k\geq 1$, which is the first
sublinear approximation for arbitrary edge-lengths. Even in the more restricted
setting of unit edge-lengths, our algorithm improves over the previous
$\~O(n^{1-1/k})$ approximation of Bhattacharyya et al. when $k\ge 4$. For the
special case of $k=3$ we design a different algorithm achieving an
$\~O(\sqrt{n})$-approximation, improving the previous $\~O(n^{2/3})$. Both of
our algorithms easily extend to the fault-tolerant setting, which has recently
attracted attention but not from an approximation viewpoint. We also prove a
nearly matching integrality gap of $\Omega(n^{\frac13 - \epsilon})$ for any
constant $\epsilon &gt; 0$.
  A virtue of all our algorithms is that they are relatively simple.
Technically, we introduce a new yet natural flow-based relaxation, and show how
to approximately solve it even when its size is not polynomial. The main
challenge is to design a rounding scheme that &quot;coordinates&quot; the choices of
flow-paths between the many demand pairs while using few edges overall. We
achieve this, roughly speaking, by randomization at the level of vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3708</identifier>
 <datestamp>2010-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3708</id><created>2010-11-16</created><authors><author><keyname>Bilotta</keyname><forenames>Stefano</forenames></author><author><keyname>Disanto</keyname><forenames>Filippo</forenames></author><author><keyname>Pinzani</keyname><forenames>Renzo</forenames></author><author><keyname>Rinaldi</keyname><forenames>Simone</forenames></author></authors><title>Catalan structures and Catalan pairs</title><categories>cs.DM</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Catalan pair is a pair of binary relations (S,R) satisfying certain axioms.
These objects are enumerated by the well-known Catalan numbers, and have been
introduced with the aim of giving a common language to most of the structures
counted by Catalan numbers. Here, we give a simple method to pass from the
recursive definition of a generic Catalan structure to the recursive definition
of the Catalan pair on the same structure, thus giving an automatic way to
interpret Catalan structures in terms of Catalan pairs. We apply our method to
many well-known Catalan structures, focusing on the meaning of the relations S
and R in each considered case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3710</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3710</id><created>2010-11-16</created><updated>2012-01-04</updated><authors><author><keyname>Gleeson</keyname><forenames>James P.</forenames></author><author><keyname>Melnik</keyname><forenames>Sergey</forenames></author><author><keyname>Ward</keyname><forenames>Jonathan A.</forenames></author><author><keyname>Porter</keyname><forenames>Mason A.</forenames></author><author><keyname>Mucha</keyname><forenames>Peter J.</forenames></author></authors><title>Accuracy of Mean-Field Theory for Dynamics on Real-World Networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>12 pages, 10 figures. This version (with title changed from &quot;How
  Accurate is Mean-Field Theory for Dynamics on Real-World Networks?&quot;) accepted
  to appear in Phys. Rev. E</comments><journal-ref>Phys. Rev. E, 85, 026106 (2012)</journal-ref><doi>10.1103/PhysRevE.85.026106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mean-field analysis is an important tool for understanding dynamics on
complex networks. However, surprisingly little attention has been paid to the
question of whether mean-field predictions are accurate, and this is
particularly true for real-world networks with clustering and modular
structure. In this paper, we compare mean-field predictions to numerical
simulation results for dynamical processes running on 21 real-world networks
and demonstrate that the accuracy of the theory depends not only on the mean
degree of the networks but also on the mean first-neighbor degree. We show that
mean-field theory can give (unexpectedly) accurate results for certain dynamics
on disassortative real-world networks even when the mean degree is as low as 4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3717</identifier>
 <datestamp>2012-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3717</id><created>2010-11-16</created><updated>2012-05-11</updated><authors><author><keyname>Couillet</keyname><forenames>Romain</forenames></author><author><keyname>Hoydis</keyname><forenames>Jakob</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Random Beamforming over Quasi-Static and Fading Channels: A
  Deterministic Equivalent Approach</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE Transactions on Information Theory, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we study the performance of random isometric precoders over
quasi-static and correlated fading channels. We derive deterministic
approximations of the mutual information and the
signal-to-interference-plus-noise ratio (SINR) at the output of the
minimum-mean-square-error (MMSE) receiver and provide simple provably
converging fixed-point algorithms for their computation. Although these
approximations are only proven exact in the asymptotic regime with infinitely
many antennas at the transmitters and receivers, simulations suggest that they
closely match the performance of small-dimensional systems. We exemplarily
apply our results to the performance analysis of multi-cellular communication
systems, multiple-input multiple-output multiple-access channels (MIMO-MAC),
and MIMO interference channels. The mathematical analysis is based on the
Stieltjes transform method. This enables the derivation of deterministic
equivalents of functionals of large-dimensional random matrices. In contrast to
previous works, our analysis does not rely on arguments from free probability
theory which enables the consideration of random matrix models for which
asymptotic freeness does not hold. Thus, the results of this work are also a
novel contribution to the field of random matrix theory and applicable to a
wide spectrum of practical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3718</identifier>
 <datestamp>2010-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3718</id><created>2010-11-16</created><authors><author><keyname>Dai</keyname><forenames>Wei</forenames></author></authors><title>Commutative-like Encryption: A New Characterization of ElGamal</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Commutative encryption is a useful but rather strict notion in cryptography.
In this paper, we deny a loose variation of commutative
encryption-commutative-like encryption and give an example: the generalization
of ElGamal scheme. The application of the new variation is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3721</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3721</id><created>2010-11-15</created><authors><author><keyname>Karawia</keyname><forenames>A. A.</forenames></author></authors><title>On the Inverse Of General Cyclic Heptadiagonal and Anti-Heptadiagonal
  Matrices</title><categories>cs.SC cs.NA</categories><comments>9 pages</comments><msc-class>15A15, 15A23, 68W30, 11Y05, 33F10, F.2.1, G.1.0</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the current work, the author present a symbolic algorithm for finding the
determinant of any general nonsingular cyclic heptadiagonal matrices and
inverse of anti-cyclic heptadiagonal matrices. The algorithms are mainly based
on the work presented in [A. A. KARAWIA, A New Algorithm for Inverting General
Cyclic Heptadiagonal Matrices Recursively, arXiv:1011.2306v1 [cs.SC]]. The
symbolic algorithms are suited for implementation using Computer Algebra
Systems (CAS) such as MATLAB, MAPLE and MATHEMATICA. An illustrative example is
given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3722</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3722</id><created>2010-11-16</created><updated>2011-02-02</updated><authors><author><keyname>Obuchi</keyname><forenames>Tomoyuki</forenames></author><author><keyname>Takahashi</keyname><forenames>Kazutaka</forenames></author><author><keyname>Takeda</keyname><forenames>Koujin</forenames></author></authors><title>Statistical mechanical analysis of a hierarchical random code ensemble
  in signal processing</title><categories>cond-mat.dis-nn cs.IT math.IT</categories><comments>24 pages, 4 figures</comments><journal-ref>J. Phys. A: Math. Theor. 44 (2011) 085002</journal-ref><doi>10.1088/1751-8113/44/8/085002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a random code ensemble with a hierarchical structure, which is
closely related to the generalized random energy model with discrete energy
values. Based on this correspondence, we analyze the hierarchical random code
ensemble by using the replica method in two situations: lossy data compression
and channel coding. For both the situations, the exponents of large deviation
analysis characterizing the performance of the ensemble, the distortion rate of
lossy data compression and the error exponent of channel coding in Gallager's
formalism, are accessible by a generating function of the generalized random
energy model. We discuss that the transitions of those exponents observed in
the preceding work can be interpreted as phase transitions with respect to the
replica number. We also show that the replica symmetry breaking plays an
essential role in these transitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3728</identifier>
 <datestamp>2010-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3728</id><created>2010-11-16</created><authors><author><keyname>Basso</keyname><forenames>Curzio</forenames></author><author><keyname>Santoro</keyname><forenames>Matteo</forenames></author><author><keyname>Verri</keyname><forenames>Alessandro</forenames></author><author><keyname>Villa</keyname><forenames>Silvia</forenames></author></authors><title>PADDLE: Proximal Algorithm for Dual Dictionaries LEarning</title><categories>cs.LG cs.IT math.IT stat.ML</categories><report-no>DISI-TR-2010-06</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, considerable research efforts have been devoted to the design of
methods to learn from data overcomplete dictionaries for sparse coding.
However, learned dictionaries require the solution of an optimization problem
for coding new data. In order to overcome this drawback, we propose an
algorithm aimed at learning both a dictionary and its dual: a linear mapping
directly performing the coding. By leveraging on proximal methods, our
algorithm jointly minimizes the reconstruction error of the dictionary and the
coding error of its dual; the sparsity of the representation is induced by an
$\ell_1$-based penalty on its coefficients. The results obtained on synthetic
data and real images show that the algorithm is capable of recovering the
expected dictionaries. Furthermore, on a benchmark dataset, we show that the
image features obtained from the dual matrix yield state-of-the-art
classification performance while being much less computational intensive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3754</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3754</id><created>2010-11-16</created><updated>2014-01-20</updated><authors><author><keyname>Mukherjee</keyname><forenames>Amitav</forenames></author><author><keyname>Fakoorian</keyname><forenames>S. A. A.</forenames></author><author><keyname>Huang</keyname><forenames>Jing</forenames></author><author><keyname>Swindlehurst</keyname><forenames>A. Lee</forenames></author></authors><title>Principles of Physical Layer Security in Multiuser Wireless Networks: A
  Survey</title><categories>cs.IT math.IT</categories><comments>23 pages, 10 figures, 303 refs. arXiv admin note: text overlap with
  arXiv:1303.1609 by other authors. IEEE Communications Surveys and Tutorials,
  2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides a comprehensive review of the domain of physical layer
security in multiuser wireless networks. The essential premise of
physical-layer security is to enable the exchange of confidential messages over
a wireless medium in the presence of unauthorized eavesdroppers without relying
on higher-layer encryption. This can be achieved primarily in two ways: without
the need for a secret key by intelligently designing transmit coding
strategies, or by exploiting the wireless communication medium to develop
secret keys over public channels. The survey begins with an overview of the
foundations dating back to the pioneering work of Shannon and Wyner on
information-theoretic security. We then describe the evolution of secure
transmission strategies from point-to-point channels to multiple-antenna
systems, followed by generalizations to multiuser broadcast, multiple-access,
interference, and relay networks. Secret-key generation and establishment
protocols based on physical layer mechanisms are subsequently covered.
Approaches for secrecy based on channel coding design are then examined, along
with a description of inter-disciplinary approaches based on game theory and
stochastic geometry. The associated problem of physical-layer message
authentication is also introduced briefly. The survey concludes with
observations on potential research directions in this area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3761</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3761</id><created>2010-11-16</created><updated>2010-11-21</updated><authors><author><keyname>Jalali</keyname><forenames>Shirin</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Lossy compression of discrete sources via Viterbi algorithm</title><categories>cs.IT math.IT</categories><comments>26 pages, 6 figures, Submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new lossy compressor for discrete-valued sources. For coding a
sequence $x^n$, the encoder starts by assigning a certain cost to each possible
reconstruction sequence. It then finds the one that minimizes this cost and
describes it losslessly to the decoder via a universal lossless compressor. The
cost of each sequence is a linear combination of its distance from the sequence
$x^n$ and a linear function of its $k^{\rm th}$ order empirical distribution.
The structure of the cost function allows the encoder to employ the Viterbi
algorithm to recover the minimizer of the cost. We identify a choice of the
coefficients comprising the linear function of the empirical distribution used
in the cost function which ensures that the algorithm universally achieves the
optimum rate-distortion performance of any stationary ergodic source in the
limit of large $n$, provided that $k$ diverges as $o(\log n)$. Iterative
techniques for approximating the coefficients, which alleviate the
computational burden of finding the optimal coefficients, are proposed and
studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3768</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3768</id><created>2010-11-16</created><authors><author><keyname>Ratkiewicz</keyname><forenames>Jacob</forenames></author><author><keyname>Conover</keyname><forenames>Michael</forenames></author><author><keyname>Meiss</keyname><forenames>Mark</forenames></author><author><keyname>Gon&#xe7;alves</keyname><forenames>Bruno</forenames></author><author><keyname>Patil</keyname><forenames>Snehal</forenames></author><author><keyname>Flammini</keyname><forenames>Alessandro</forenames></author><author><keyname>Menczer</keyname><forenames>Filippo</forenames></author></authors><title>Detecting and Tracking the Spread of Astroturf Memes in Microblog
  Streams</title><categories>cs.SI cs.CY</categories><journal-ref>Proceedings of the 20th international conference companion on
  World wide web, 249-252 (2011)</journal-ref><doi>10.1145/1963192.1963301</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online social media are complementing and in some cases replacing
person-to-person social interaction and redefining the diffusion of
information. In particular, microblogs have become crucial grounds on which
public relations, marketing, and political battles are fought. We introduce an
extensible framework that will enable the real-time analysis of meme diffusion
in social media by mining, visualizing, mapping, classifying, and modeling
massive streams of public microblogging events. We describe a Web service that
leverages this framework to track political memes in Twitter and help detect
astroturfing, smear campaigns, and other misinformation in the context of U.S.
political elections. We present some cases of abusive behaviors uncovered by
our service. Finally, we discuss promising preliminary results on the detection
of suspicious memes via supervised learning based on features extracted from
the topology of the diffusion networks, sentiment analysis, and crowdsourced
annotations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3770</identifier>
 <datestamp>2010-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3770</id><created>2010-11-16</created><updated>2010-11-17</updated><authors><author><keyname>Bhalgat</keyname><forenames>Anand</forenames></author><author><keyname>Chakrabarty</keyname><forenames>Deeparnab</forenames></author><author><keyname>Khanna</keyname><forenames>Sanjeev</forenames></author></authors><title>Optimal Lower Bounds for Universal and Differentially Private Steiner
  Tree and TSP</title><categories>cs.DS</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a metric space on n points, an {\alpha}-approximate universal algorithm
for the Steiner tree problem outputs a distribution over rooted spanning trees
such that for any subset X of vertices containing the root, the expected cost
of the induced subtree is within an {\alpha} factor of the optimal Steiner tree
cost for X. An {\alpha}-approximate differentially private algorithm for the
Steiner tree problem takes as input a subset X of vertices, and outputs a tree
distribution that induces a solution within an {\alpha} factor of the optimal
as before, and satisfies the additional property that for any set X' that
differs in a single vertex from X, the tree distributions for X and X' are
&quot;close&quot; to each other. Universal and differentially private algorithms for TSP
are defined similarly. An {\alpha}-approximate universal algorithm for the
Steiner tree problem or TSP is also an {\alpha}-approximate differentially
private algorithm. It is known that both problems admit O(logn)-approximate
universal algorithms, and hence O(log n)-approximate differentially private
algorithms as well. We prove an {\Omega}(logn) lower bound on the approximation
ratio achievable for the universal Steiner tree problem and the universal TSP,
matching the known upper bounds. Our lower bound for the Steiner tree problem
holds even when the algorithm is allowed to output a more general solution of a
distribution on paths to the root.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3794</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3794</id><created>2010-11-16</created><updated>2011-02-24</updated><authors><author><keyname>Helbing</keyname><forenames>Dirk</forenames></author><author><keyname>Balietti</keyname><forenames>Stefano</forenames></author></authors><title>How to Create an Innovation Accelerator</title><categories>cs.DL physics.soc-ph</categories><comments>32 pages, Visioneer White Paper, see http://www.visioneer.ethz.ch</comments><doi>10.1140/epjst/e2011-01403-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Too many policy failures are fundamentally failures of knowledge. This has
become particularly apparent during the recent financial and economic crisis,
which is questioning the validity of mainstream scholarly paradigms. We propose
to pursue a multi-disciplinary approach and to establish new institutional
settings which remove or reduce obstacles impeding efficient knowledge
creation. We provided suggestions on (i) how to modernize and improve the
academic publication system, and (ii) how to support scientific coordination,
communication, and co-creation in large-scale multi-disciplinary projects. Both
constitute important elements of what we envision to be a novel ICT
infrastructure called &quot;Innovation Accelerator&quot; or &quot;Knowledge Accelerator&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3812</identifier>
 <datestamp>2010-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3812</id><created>2010-11-16</created><authors><author><keyname>Yin</keyname><forenames>Huarui</forenames></author></authors><title>Comments on Degrees of freedom region for $K$-user interference channel
  with $M$ antennas</title><categories>cs.IT math.IT</categories><comments>2 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a $K$-user interference channel with $M$ antenna at each transmitter and
each receiver, the maximum total DoF of this channel has been previously
determined to be $\max \sum_{k=1}^K d_k = MK/2$. However, the DoF region
remains to be unknown. In this short note, through a simple time-sharing
argument, we obtain the degrees of freedom (DoF) region of this channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3834</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3834</id><created>2010-11-16</created><updated>2013-01-02</updated><authors><author><keyname>Laciana</keyname><forenames>Carlos E.</forenames></author><author><keyname>Rovere</keyname><forenames>Santiago L.</forenames></author></authors><title>Ising-like agent-based technology diffusion model: adoption patterns vs.
  seeding strategies</title><categories>physics.soc-ph cs.SI q-fin.TR</categories><comments>23 pages and 5 figures</comments><journal-ref>Physica A 390: 1139 (2011)</journal-ref><doi>10.1016/j.physa.2010.11.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The well-known Ising model used in statistical physics was adapted to a
social dynamics context to simulate the adoption of a technological innovation.
The model explicitly combines (a) an individual's perception of the advantages
of an innovation and (b) social influence from members of the decision-maker's
social network. The micro-level adoption dynamics are embedded into an
agent-based model that allows exploration of macro-level patterns of technology
diffusion throughout systems with different configurations (number and
distributions of early adopters, social network topologies). In the present
work we carry out many numerical simulations. We find that when the gap between
the individual's perception of the options is high, the adoption speed
increases if the dispersion of early adopters grows. Another test was based on
changing the network topology by means of stochastic connections to a common
opinion reference (hub), which resulted in an increment in the adoption speed.
Finally, we performed a simulation of competition between options for both
regular and small world networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3840</identifier>
 <datestamp>2010-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3840</id><created>2010-11-16</created><authors><author><keyname>Kintali</keyname><forenames>Shiva</forenames></author></authors><title>Realizable Paths and the NL vs L Problem</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A celebrated theorem of Savitch states that NSPACE(S) is contained in
DSPACE(S^2). In particular, Savitch gave a deterministic algorithm to solve
ST-CONNECTIVITY (an NL-complete problem) using O(log^2{n}) space, implying NL
is in DSPACE(log^2{n}). While Savitch's theorem itself has not been improved in
the last four decades, studying the space complexity of several special cases
of ST-CONNECTIVITY has provided new insights into the space-bounded complexity
classes.
  In this paper, we introduce new kind of graph connectivity problems which we
call graph realizability problems. All of our graph realizability problems are
generalizations of UNDIRECTED ST-CONNECTIVITY. ST-REALIZABILITY, the most
general graph realizability problem, is LogCFL-complete. We define the
corresponding complexity classes that lie between L and LogCFL and study their
relationships.
  As special cases of our graph realizability problems we define two natural
problems, BALANCED ST-CONNECTIVITY and POSITIVE BALANCED ST-CONNECTIVITY, that
lie between L and NL. We present a deterministic O(lognloglogn) space algorithm
for BALANCED ST-CONNECTIVITY. More generally we prove that SGSLogCFL, a
generalization of BALANCED ST-CONNECTIVITY, is contained in
DSPACE(lognloglogn). To achieve this goal we generalize several concepts (such
as graph squaring and transitive closure) and algorithms (such as parallel
algorithms) known in the context of UNDIRECTED ST-CONNECTIVITY.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3843</identifier>
 <datestamp>2010-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3843</id><created>2010-11-16</created><authors><author><keyname>Levy</keyname><forenames>Uri</forenames></author></authors><title>Magnetic Towers of Hanoi and their Optimal Solutions</title><categories>math.CO cs.DS</categories><comments>39 pages, 8 figures, 16 tables</comments><msc-class>05D99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Magnetic Tower of Hanoi puzzle - a modified &quot;base 3&quot; version of the
classical Tower of Hanoi puzzle as described in earlier papers, is actually a
small set of independent sister-puzzles, depending on the &quot;pre-coloring&quot;
combination of the tower's posts. Starting with Red facing up on a Source post,
working through an Intermediate - colored or Neutral post, and ending Blue
facing up on a Destination post, we identify the different pre-coloring
combinations in (S,I,D) order. The Tower's pre-coloring combinations are
{[(R,B,B) / (R,R,B)] ; [(R,B,N) / (N,R,B)] ; [(N,B,N) / (N,R,N)] ; [R,N,B] ;
[(R,N,N) / (N,N,B)] ; [N,N,N]}. In this paper we investigate these
sister-puzzles, identify the algorithm that optimally solves each pre-colored
puzzle, and prove its Optimality. As it turns out, five of the six algorithms,
challenging on their own, are part of the algorithm solving the &quot;natural&quot;, Free
Magnetic Tower of Hanoi puzzle [N,N,N]. We start by showing that the N-disk
Colored Tower [(R,B,B) / (R,R,B)] is solved by (3^N - 1)/2 moves. Defining
&quot;Algorithm Duration&quot; as the ratio of number of algorithm-moves solving the
puzzle to the number of algorithm-moves solving the Colored Tower, we find the
Duration-Limits for all sister-puzzles. In the order of the list above they are
{[1] ; [10/11] ; [10/11] ; [8/11] ; [7/11] ; [20/33]}. Thus, the Duration-Limit
of the Optimal Algorithm solving the Free Magnetic Tower of Hanoi puzzle is
20/33 or 606 0/00. On the road to optimally solve this colorful Magnetic
puzzle, we hit other &quot;forward-moving&quot; puzzle-solving algorithms. Overall we
looked at 10 pairs of integer sequences. Of the twenty integer sequences, five
are listed in the On-line Encyclopedia of Integer Sequences, the other fifteen
- not yet. The large set of different solutions is a clear indication to the
freedom-of-wondering that makes this Magnetic Tower of Hanoi puzzle so
colorful.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3852</identifier>
 <datestamp>2010-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3852</id><created>2010-11-12</created><authors><author><keyname>Lv</keyname><forenames>Ziyu</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Wu</keyname><forenames>Guowei</forenames></author><author><keyname>Yao</keyname><forenames>Lin</forenames></author><author><keyname>Chen</keyname><forenames>Zhikui</forenames></author></authors><title>iCare: A Mobile Health Monitoring System for the Elderly</title><categories>cs.OH</categories><comments>The 3rd IEEE/ACM Int Conf on Cyber, Physical and Social Computing
  (CPSCom), IEEE, Hangzhou, China, December 18-20, 2010</comments><msc-class>68M14</msc-class><acm-class>C.2.4; J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a mobile health monitoring system called iCare for the
elderly. We use wireless body sensors and smart phones to monitor the wellbeing
of the elderly. It can offer remote monitoring for the elderly anytime anywhere
and provide tailored services for each person based on their personal health
condition. When detecting an emergency, the smart phone will automatically
alert pre-assigned people who could be the old people's family and friends, and
call the ambulance of the emergency centre. It also acts as the personal health
information system and the medical guidance which offers one communication
platform and the medical knowledge database so that the family and friends of
the served people can cooperate with doctors to take care of him/her. The
system also features some unique functions that cater to the living demands of
the elderly, including regular reminder, quick alarm, medical guidance, etc.
iCare is not only a real-time health monitoring system for the elderly, but
also a living assistant which can make their lives more convenient and
comfortable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3854</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3854</id><created>2010-11-16</created><updated>2010-11-19</updated><authors><author><keyname>Candes</keyname><forenames>Emmanuel J.</forenames></author><author><keyname>Plan</keyname><forenames>Yaniv</forenames></author></authors><title>A probabilistic and RIPless theory of compressed sensing</title><categories>cs.IT math.IT</categories><comments>36 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a simple and very general theory of compressive
sensing. In this theory, the sensing mechanism simply selects sensing vectors
independently at random from a probability distribution F; it includes all
models - e.g. Gaussian, frequency measurements - discussed in the literature,
but also provides a framework for new measurement strategies as well. We prove
that if the probability distribution F obeys a simple incoherence property and
an isotropy property, one can faithfully recover approximately sparse signals
from a minimal number of noisy measurements. The novelty is that our recovery
results do not require the restricted isometry property (RIP) - they make use
of a much weaker notion - or a random model for the signal. As an example, the
paper shows that a signal with s nonzero entries can be faithfully recovered
from about s log n Fourier coefficients that are contaminated with noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3867</identifier>
 <datestamp>2010-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3867</id><created>2010-11-16</created><authors><author><keyname>Shin</keyname><forenames>Wonjae</forenames></author><author><keyname>Lee</keyname><forenames>Namyoon</forenames></author><author><keyname>Lim</keyname><forenames>Jong-Bu</forenames></author><author><keyname>Shin</keyname><forenames>Changyong</forenames></author><author><keyname>Jang</keyname><forenames>Kyunghun</forenames></author></authors><title>Interference Alignment Through User Cooperation for Two-cell MIMO
  Interfering Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>This paper will appear in IEEE GLOBECOM 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on two-cell multiple-input multiple-output (MIMO) Gaussian
interfering broadcast channels (MIMO-IFBC) with $K$ cooperating users on the
cell-boundary of each BS. It corresponds to a downlink scenario for cellular
networks with two base stations (BSs), and $K$ users equipped with Wi-Fi
interfaces enabling to cooperate among users on a peer-to-peer basis. In this
scenario, we propose a novel interference alignment (IA) technique exploiting
user cooperation. Our proposed algorithm obtains the achievable degrees of
freedom (DoF) of 2K when each BS and user have $M=K+1$ transmit antennas and
$N=K$ receive antennas, respectively. Furthermore, the algorithm requires only
a small amount of channel feedback information with the aid of the user
cooperation channels. The simulations demonstrate that not only are the
analytical results valid, but the achievable DoF of our proposed algorithm also
outperforms those of conventional techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3870</identifier>
 <datestamp>2010-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3870</id><created>2010-11-16</created><authors><author><keyname>Kim</keyname><forenames>Sukwon</forenames></author><author><keyname>Ho</keyname><forenames>Tracey</forenames></author><author><keyname>Effros</keyname><forenames>Michelle</forenames></author><author><keyname>Avestimehr</keyname><forenames>Amir Salman</forenames></author></authors><title>Network error correction with unequal link capacities</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the capacity of single-source single-sink noiseless
networks under adversarial or arbitrary errors on no more than z edges. Unlike
prior papers, which assume equal capacities on all links, arbitrary link
capacities are considered. Results include new upper bounds, network error
correction coding strategies, and examples of network families where our bounds
are tight. An example is provided of a network where the capacity is 50%
greater than the best rate that can be achieved with linear coding. While
coding at the source and sink suffices in networks with equal link capacities,
in networks with unequal link capacities, it is shown that intermediate nodes
may have to do coding, nonlinear error detection, or error correction in order
to achieve the network error correction capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3878</identifier>
 <datestamp>2011-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3878</id><created>2010-11-16</created><updated>2011-05-05</updated><authors><author><keyname>Dorfler</keyname><forenames>Florian</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>On the Critical Coupling for Kuramoto Oscillators</title><categories>math.DS cs.SY math-ph math.MP math.OC nlin.CD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Kuramoto model captures various synchronization phenomena in biological
and man-made systems of coupled oscillators. It is well-known that there exists
a critical coupling strength among the oscillators at which a phase transition
from incoherency to synchronization occurs. This paper features four
contributions. First, we characterize and distinguish the different notions of
synchronization used throughout the literature and formally introduce the
concept of phase cohesiveness as an analysis tool and performance index for
synchronization. Second, we review the vast literature providing necessary,
sufficient, implicit, and explicit estimates of the critical coupling strength
for finite and infinite-dimensional, and for first and second-order Kuramoto
models. Third, we present the first explicit necessary and sufficient condition
on the critical coupling to achieve synchronization in the finite-dimensional
Kuramoto model for an arbitrary distribution of the natural frequencies. The
multiplicative gap in the synchronization condition yields a practical
stability result determining the admissible initial and the guaranteed ultimate
phase cohesiveness as well as the guaranteed asymptotic magnitude of the order
parameter. Fourth and finally, we extend our analysis to multi-rate Kuramoto
models consisting of second-order Kuramoto oscillators with inertia and viscous
damping together with first-order Kuramoto oscillators with multiple time
constants. We prove that the multi-rate Kuramoto model is locally topologically
conjugate to a first-order Kuramoto model with scaled natural frequencies, and
we present necessary and sufficient conditions for almost global phase
synchronization and local frequency synchronization. Interestingly, these
conditions do not depend on the inertiae which contradicts prior observations
on the role of inertiae in synchronization of second-order Kuramoto models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3879</identifier>
 <datestamp>2010-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3879</id><created>2010-11-16</created><authors><author><keyname>Kim</keyname><forenames>MinJi</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Barros</keyname><forenames>Joao</forenames></author></authors><title>Algebraic Watchdog: Mitigating Misbehavior in Wireless Network Coding</title><categories>cs.CR cs.IT cs.NI math.IT</categories><comments>10 pages, 10 figures, Submitted to IEEE Journal on Selected Areas in
  Communications (JSAC) &quot;Advances in Military Networking and Communications&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a secure scheme for wireless network coding, called the algebraic
watchdog. By enabling nodes to detect malicious behaviors probabilistically and
use overheard messages to police their downstream neighbors locally, the
algebraic watchdog delivers a secure global self-checking network. Unlike
traditional Byzantine detection protocols which are receiver-based, this
protocol gives the senders an active role in checking the node downstream. The
key idea is inspired by Marti et al.'s watchdog-pathrater, which attempts to
detect and mitigate the effects of routing misbehavior.
  As an initial building block of a such system, we first focus on a two-hop
network. We present a graphical model to understand the inference process nodes
execute to police their downstream neighbors; as well as to compute, analyze,
and approximate the probabilities of misdetection and false detection. In
addition, we present an algebraic analysis of the performance using an
hypothesis testing framework that provides exact formulae for probabilities of
false detection and misdetection.
  We then extend the algebraic watchdog to a more general network setting, and
propose a protocol in which we can establish trust in coded systems in a
distributed manner. We develop a graphical model to detect the presence of an
adversarial node downstream within a general multi-hop network. The structure
of the graphical model (a trellis) lends itself to well-known algorithms, such
as the Viterbi algorithm, which can compute the probabilities of misdetection
and false detection. We show analytically that as long as the min-cut is not
dominated by the Byzantine adversaries, upstream nodes can monitor downstream
neighbors and allow reliable communication with certain probability. Finally,
we present simulation results that support our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3882</identifier>
 <datestamp>2010-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3882</id><created>2010-11-16</created><authors><author><keyname>Goldberg</keyname><forenames>Mark</forenames></author><author><keyname>Magdon-Ismail</keyname><forenames>Malik</forenames></author></authors><title>Embedding a Forest in a Graph</title><categories>math.CO cs.DM</categories><comments>Working paper, submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For \math{p\ge 1}, we prove that every forest with \math{p} trees whose sizes
are $a_1,..., a_p$ can be embedded in any graph containing at least
$\sum_{i=1}^p (a_i + 1)$ vertices and having a minimum degree at least
$\sum_{i=1}^p a_i$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3890</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3890</id><created>2010-11-17</created><updated>2010-11-29</updated><authors><author><keyname>Qiu</keyname><forenames>Jiaming</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Luo</keyname><forenames>Zhi-Quan</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Optimal Distributed Beamforming for MISO Interference Channels</title><categories>cs.IT math.IT</categories><comments>7 Pages, 6 figures, extended version for the one in Proceeding of
  Asilomar, CA, 2010</comments><doi>10.1109/TSP.2011.2163066</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of quantifying the Pareto optimal boundary in the
achievable rate region over multiple-input single-output (MISO) interference
channels, where the problem boils down to solving a sequence of convex
feasibility problems after certain transformations. The feasibility problem is
solved by two new distributed optimal beamforming algorithms, where the first
one is to parallelize the computation based on the method of alternating
projections, and the second one is to localize the computation based on the
method of cyclic projections. Convergence proofs are established for both
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3912</identifier>
 <datestamp>2010-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3912</id><created>2010-11-17</created><authors><author><keyname>Hamann</keyname><forenames>Heiko</forenames></author><author><keyname>Stradner</keyname><forenames>J&#xfc;rgen</forenames></author><author><keyname>Schmickl</keyname><forenames>Thomas</forenames></author><author><keyname>Crailsheim</keyname><forenames>Karl</forenames></author></authors><title>Artificial Hormone Reaction Networks: Towards Higher Evolvability in
  Evolutionary Multi-Modular Robotics</title><categories>cs.RO cs.AI cs.NE</categories><journal-ref>Artificial Life XII (ALife XII), Odense, Denmark, pp. 773-780, MIT
  Press, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The semi-automatic or automatic synthesis of robot controller software is
both desirable and challenging. Synthesis of rather simple behaviors such as
collision avoidance by applying artificial evolution has been shown multiple
times. However, the difficulty of this synthesis increases heavily with
increasing complexity of the task that should be performed by the robot. We try
to tackle this problem of complexity with Artificial Homeostatic Hormone
Systems (AHHS), which provide both intrinsic, homeostatic processes and
(transient) intrinsic, variant behavior. By using AHHS the need for pre-defined
controller topologies or information about the field of application is
minimized. We investigate how the principle design of the controller and the
hormone network size affects the overall performance of the artificial
evolution (i.e., evolvability). This is done by comparing two variants of AHHS
that show different effects when mutated. We evolve a controller for a robot
built from five autonomous, cooperating modules. The desired behavior is a form
of gait resulting in fast locomotion by using the modules' main hinges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3930</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3930</id><created>2010-11-17</created><updated>2010-11-18</updated><authors><author><keyname>Noual</keyname><forenames>Mathilde</forenames></author></authors><title>Dynamics in parallel of double Boolean automata circuits</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we give some results concerning the dynamics of double Boolean
automata circuits (dbac's for short), namely, networks associated to
interaction graphs composed of two side-circuits that share a node. More
precisely, we give formulas for the number of attractors of any period, as well
as the total number of attractors of these networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3944</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3944</id><created>2010-11-17</created><updated>2011-01-12</updated><authors><author><keyname>Romanov</keyname><forenames>V. F.</forenames></author></authors><title>Non-Orthodox Combinatorial Models Based on Discordant Structures</title><categories>cs.DS</categories><comments>19 pages; typeset in LaTeX, some typos fixed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel method for compact representation of sets of
n-dimensional binary sequences in a form of compact triplets structures (CTS),
supposing both logic and arithmetic interpretations of data. Suitable
illustration of CTS application is the unique graph-combinatorial model for the
classic intractable 3-Satisfiability problem and a polynomial algorithm for the
model synthesis. The method used for Boolean formulas analysis and
classification by means of the model is defined as a bijective mapping
principle for sets of components of discordant structures to a basic set. The
statistic computer-aided experiment showed efficiency of the algorithm in a
large scale of problem dimension parameters, including those that make
enumeration procedures of no use. The formulated principle expands resources of
constructive approach to investigation of intractable problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3964</identifier>
 <datestamp>2010-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3964</id><created>2010-11-17</created><authors><author><keyname>Rosa-Velardo</keyname><forenames>Fernando</forenames></author><author><keyname>de Frutos-Escrig</keyname><forenames>David</forenames></author></authors><title>Decision Problems for Petri Nets with Names</title><categories>cs.LO</categories><comments>20 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove several decidability and undecidability results for nu-PN, an
extension of P/T nets with pure name creation and name management. We give a
simple proof of undecidability of reachability, by reducing reachability in
nets with inhibitor arcs to it. Thus, the expressive power of nu-PN strictly
surpasses that of P/T nets. We prove that nu-PN are Well Structured Transition
Systems. In particular, we obtain decidability of coverability and termination,
so that the expressive power of Turing machines is not reached. Moreover, they
are strictly Well Structured, so that the boundedness problem is also
decidable. We consider two properties, width-boundedness and depth-boundedness,
that factorize boundedness. Width-boundedness has already been proven to be
decidable. We prove here undecidability of depth-boundedness. Finally, we
obtain Ackermann-hardness results for all our decidable decision problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3970</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3970</id><created>2010-11-17</created><updated>2011-02-24</updated><authors><author><keyname>Helbing</keyname><forenames>Dirk</forenames></author><author><keyname>Balietti</keyname><forenames>Stefano</forenames></author></authors><title>From Social Simulation to Integrative System Design</title><categories>cs.CY cs.CE physics.comp-ph physics.soc-ph</categories><comments>34 pages, Visioneer White Paper, see http://www.visioneer.ethz.ch</comments><doi>10.1140/epjst/e2011-01402-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the recent financial crisis showed, today there is a strong need to gain
&quot;ecological perspective&quot; of all relevant interactions in
socio-economic-techno-environmental systems. For this, we suggested to set-up a
network of Centers for integrative systems design, which shall be able to run
all potentially relevant scenarios, identify causality chains, explore feedback
and cascading effects for a number of model variants, and determine the
reliability of their implications (given the validity of the underlying
models). They will be able to detect possible negative side effect of policy
decisions, before they occur. The Centers belonging to this network of
Integrative Systems Design Centers would be focused on a particular field, but
they would be part of an attempt to eventually cover all relevant areas of
society and economy and integrate them within a &quot;Living Earth Simulator&quot;. The
results of all research activities of such Centers would be turned into
informative input for political Decision Arenas. For example, Crisis
Observatories (for financial instabilities, shortages of resources,
environmental change, conflict, spreading of diseases, etc.) would be connected
with such Decision Arenas for the purpose of visualization, in order to make
complex interdependencies understandable to scientists, decision-makers, and
the general public.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.3985</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.3985</id><created>2010-11-17</created><authors><author><keyname>Mayiami</keyname><forenames>Mahmoud Ramezani</forenames></author><author><keyname>Seyfe</keyname><forenames>Babak</forenames></author><author><keyname>Bafghi</keyname><forenames>Hamid G.</forenames></author></authors><title>Perfect Secrecy Using Compressed Sensing</title><categories>cs.IT cs.CR math.IT</categories><comments>3 pages</comments><doi>10.1109/IWCIT.2013.6555751</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the compressed sensing-based encryption and
proposed the conditions in which the perfect secrecy is obtained. We prove when
the Restricted Isometery Property (RIP) is hold and the number of measurements
is more than two times of sparsity level i.e. M \geq 2k, the perfect secrecy
condition introduced by Shannon is achievable if message block is not equal to
zero or we have infinite block length
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4016</identifier>
 <datestamp>2010-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4016</id><created>2010-11-17</created><authors><author><keyname>Adler</keyname><forenames>Hans</forenames></author><author><keyname>Adler</keyname><forenames>Isolde</forenames></author></authors><title>Nowhere dense graph classes, stability, and the independence property</title><categories>math.LO cs.DM cs.LO</categories><comments>9 pages</comments><msc-class>05C75 (Primary) 03C13, 03C45 (Secondary)</msc-class><acm-class>G.2.2; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A class of graphs is nowhere dense if for every integer r there is a finite
upper bound on the size of cliques that occur as (topological) r-minors. We
observe that this tameness notion from algorithmic graph theory is essentially
the earlier stability theoretic notion of superflatness. For subgraph-closed
classes of graphs we prove equivalence to stability and to not having the
independence property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4028</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4028</id><created>2010-11-17</created><updated>2012-01-08</updated><authors><author><keyname>Yu</keyname><forenames>Yang</forenames></author><author><keyname>Yao</keyname><forenames>Xin</forenames></author><author><keyname>Zhou</keyname><forenames>Zhi-Hua</forenames></author></authors><title>On the approximation ability of evolutionary optimization with
  application to minimum set cover</title><categories>cs.NE</categories><doi>10.1016/j.artint.2012.01.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Evolutionary algorithms (EAs) are heuristic algorithms inspired by natural
evolution. They are often used to obtain satisficing solutions in practice. In
this paper, we investigate a largely underexplored issue: the approximation
performance of EAs in terms of how close the solution obtained is to an optimal
solution. We study an EA framework named simple EA with isolated population
(SEIP) that can be implemented as a single- or multi-objective EA. We analyze
the approximation performance of SEIP using the partial ratio, which
characterizes the approximation ratio that can be guaranteed. Specifically, we
analyze SEIP using a set cover problem that is NP-hard. We find that in a
simple configuration, SEIP efficiently achieves an $H_n$-approximation ratio,
the asymptotic lower bound, for the unbounded set cover problem. We also find
that SEIP efficiently achieves an $(H_k-\frac{k-1}/{8k^9})$-approximation
ratio, the currently best-achievable result, for the k-set cover problem.
Moreover, for an instance class of the k-set cover problem, we disclose how
SEIP, using either one-bit or bit-wise mutation, can overcome the difficulty
that limits the greedy algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4058</identifier>
 <datestamp>2010-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4058</id><created>2010-11-17</created><authors><author><keyname>Cadieu</keyname><forenames>Charles F.</forenames></author><author><keyname>Koepsell</keyname><forenames>Kilian</forenames></author></authors><title>Modeling Image Structure with Factorized Phase-Coupled Boltzmann
  Machines</title><categories>cs.CV cond-mat.dis-nn q-bio.NC stat.ML</categories><comments>11 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a model for capturing the statistical structure of local
amplitude and local spatial phase in natural images. The model is based on a
recently developed, factorized third-order Boltzmann machine that was shown to
be effective at capturing higher-order structure in images by modeling
dependencies among squared filter outputs (Ranzato and Hinton, 2010). Here, we
extend this model to $L_p$-spherically symmetric subspaces. In order to model
local amplitude and phase structure in images, we focus on the case of two
dimensional subspaces, and the $L_2$-norm. When trained on natural images the
model learns subspaces resembling quadrature-pair Gabor filters. We then
introduce an additional set of hidden units that model the dependencies among
subspace phases. These hidden units form a combinatorial mixture of phase
coupling distributions, concentrated in the sum and difference of phase pairs.
When adapted to natural images, these distributions capture local spatial phase
structure in natural images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4071</identifier>
 <datestamp>2010-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4071</id><created>2010-11-17</created><authors><author><keyname>Backstrom</keyname><forenames>L.</forenames></author><author><keyname>Leskovec</keyname><forenames>J.</forenames></author></authors><title>Supervised Random Walks: Predicting and Recommending Links in Social
  Networks</title><categories>cs.SI cs.AI cs.DS physics.soc-ph stat.ML</categories><journal-ref>Proceedings of the Fourth ACM International Conference on Web
  Search and Data Mining (WSDM '11), February, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Predicting the occurrence of links is a fundamental problem in networks. In
the link prediction problem we are given a snapshot of a network and would like
to infer which interactions among existing members are likely to occur in the
near future or which existing interactions are we missing. Although this
problem has been extensively studied, the challenge of how to effectively
combine the information from the network structure with rich node and edge
attribute data remains largely open.
  We develop an algorithm based on Supervised Random Walks that naturally
combines the information from the network structure with node and edge level
attributes. We achieve this by using these attributes to guide a random walk on
the graph. We formulate a supervised learning task where the goal is to learn a
function that assigns strengths to edges in the network such that a random
walker is more likely to visit the nodes to which new links will be created in
the future. We develop an efficient training algorithm to directly learn the
edge strength estimation function.
  Our experiments on the Facebook social graph and large collaboration networks
show that our approach outperforms state-of-the-art unsupervised approaches as
well as approaches that are based on feature extraction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4093</identifier>
 <datestamp>2010-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4093</id><created>2010-11-17</created><authors><author><keyname>Kuruvada</keyname><forenames>Praveen</forenames></author><author><keyname>Asamoah</keyname><forenames>Daniel</forenames></author><author><keyname>Dalal</keyname><forenames>Nikunj</forenames></author><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>The Use of Rapid Digital Game Creation to Learn Computational Thinking</title><categories>cs.OH</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational Thinking (CT) has been described as a universally applicable
ability such as reading and writing. In this paper, we describe an innovative
pedagogy using Rapid Digital Game Creation (RDGC) for learning CT skills. RDGC
involves the rapid building of digital games with high-level software that
requires little or no programming knowledge. We analyze how RDGC supports
various CT concepts and how it may be mapped to equivalent Java concepts by
building the same game using both RDGC and Java. We discuss the potential
benefits of this approach for attracting computing majors, as a precursor to
learning formal programming languages, for learning domain knowledge, and for
bridging the digital divide. We present the implications of this work for
teachers and researchers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4098</identifier>
 <datestamp>2010-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4098</id><created>2010-11-17</created><authors><author><keyname>Kadloor</keyname><forenames>Sachin</forenames></author><author><keyname>Santhi</keyname><forenames>Nandakishore</forenames></author></authors><title>Understanding Cascading Failures in Power Grids</title><categories>cs.SI math.PR stat.AP</categories><comments>12 pages; 9 figures; being submitted to IEEE Trans. on Smart Grids</comments><report-no>LA-UR 10-07070</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the past, we have observed several large blackouts, i.e. loss of power to
large areas. It has been noted by several researchers that these large
blackouts are a result of a cascade of failures of various components. As a
power grid is made up of several thousands or even millions of components
(relays, breakers, transformers, etc.), it is quite plausible that a few of
these components do not perform their function as desired. Their
failure/misbehavior puts additional burden on the working components causing
them to misbehave, and thus leading to a cascade of failures.
  The complexity of the entire power grid makes it difficult to model each and
every individual component and study the stability of the entire system. For
this reason, it is often the case that abstract models of the working of the
power grid are constructed and then analyzed. These models need to be
computationally tractable while serving as a reasonable model for the entire
system. In this work, we construct one such model for the power grid, and
analyze it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4104</identifier>
 <datestamp>2012-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4104</id><created>2010-11-17</created><updated>2012-11-15</updated><authors><author><keyname>Mirzal</keyname><forenames>Andri</forenames></author></authors><title>Clustering and Latent Semantic Indexing Aspects of the Singular Value
  Decomposition</title><categories>cs.LG cs.NA math.SP</categories><comments>38 pages, submitted to Pattern Recognition</comments><msc-class>15A18, 65F15</msc-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper discusses clustering and latent semantic indexing (LSI) aspects of
the singular value decomposition (SVD). The purpose of this paper is twofold.
The first is to give an explanation on how and why the singular vectors can be
used in clustering. And the second is to show that the two seemingly unrelated
SVD aspects actually originate from the same source: related vertices tend to
be more clustered in the graph representation of lower rank approximate matrix
using the SVD than in the original semantic graph. Accordingly, the SVD can
improve retrieval performance of an information retrieval system since queries
made to the approximate matrix can retrieve more relevant documents and filter
out more irrelevant documents than the same queries made to the original
matrix. By utilizing this fact, we will devise an LSI algorithm that mimicks
SVD capability in clustering related vertices. Convergence analysis shows that
the algorithm is convergent and produces a unique solution for each input.
Experimental results using some standard datasets in LSI research show that
retrieval performances of the algorithm are comparable to the SVD's. In
addition, the algorithm is more practical and easier to use because there is no
need to determine decomposition rank which is crucial in driving retrieval
performance of the SVD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4109</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4109</id><created>2010-11-17</created><updated>2012-07-23</updated><authors><author><keyname>Rashidi</keyname><forenames>Moslem</forenames></author></authors><title>Design and simulation of a sigma delta ADC</title><categories>cs.IT cs.AR math.IT</categories><comments>This paper has been withdrawn by the author due to poor writing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report we describe the design and simulation of a Sigma Delta ADC in
Matlan/Simulink
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4114</identifier>
 <datestamp>2010-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4114</id><created>2010-11-17</created><authors><author><keyname>Dixon</keyname><forenames>Lucas</forenames></author><author><keyname>Kissinger</keyname><forenames>Aleks</forenames></author></authors><title>Open Graphs and Monoidal Theories</title><categories>math.CT cs.LO</categories><comments>31 pages, currently technical report, submitted to MSCS, waiting
  reviews</comments><acm-class>F.4; G.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  String diagrams are a powerful tool for reasoning about physical processes,
logic circuits, tensor networks, and many other compositional structures. The
distinguishing feature of these diagrams is that edges need not be connected to
vertices at both ends, and these unconnected ends can be interpreted as the
inputs and outputs of a diagram. In this paper, we give a concrete construction
for string diagrams using a special kind of typed graph called an open-graph.
While the category of open-graphs is not itself adhesive, we introduce the
notion of a selective adhesive functor, and show that such a functor embeds the
category of open-graphs into the ambient adhesive category of typed graphs.
Using this functor, the category of open-graphs inherits &quot;enough adhesivity&quot;
from the category of typed graphs to perform double-pushout (DPO) graph
rewriting. A salient feature of our theory is that it ensures rewrite systems
are &quot;type-safe&quot; in the sense that rewriting respects the inputs and outputs.
This formalism lets us safely encode the interesting structure of a
computational model, such as evaluation dynamics, with succinct, explicit
rewrite rules, while the graphical representation absorbs many of the tedious
details. Although topological formalisms exist for string diagrams, our
construction is discreet, finitary, and enjoys decidable algorithms for
composition and rewriting. We also show how open-graphs can be parametrised by
graphical signatures, similar to the monoidal signatures of Joyal and Street,
which define types for vertices in the diagrammatic language and constraints on
how they can be connected. Using typed open-graphs, we can construct free
symmetric monoidal categories, PROPs, and more general monoidal theories. Thus
open-graphs give us a handle for mechanised reasoning in monoidal categories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4128</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4128</id><created>2010-11-17</created><updated>2012-11-05</updated><authors><author><keyname>Phillipson</keyname><forenames>Kaitlyn</forenames></author><author><keyname>Rojas</keyname><forenames>J. Maurice</forenames></author></authors><title>Fewnomial Systems with Many Roots, and an Adelic Tau Conjecture</title><categories>math.AG cs.CC math.NT</categories><comments>23 pages, 9 illustrations, accepted for publication. Mainly fixing
  some dumb typos introduced in last version, particularly in Adelic Tau
  Conjecture</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a system F of n polynomials in n variables, with a total of n+k
distinct exponent vectors, over any local field L. We discuss conjecturally
tight bounds on the maximal number of non-degenerate roots F can have over L,
with all coordinates having fixed phase, as a function of n, k, and L only. In
particular, we give new explicit systems with number of roots approaching the
best known upper bounds. We also briefly review the background behind such
bounds, and their application, including connections to computational number
theory and variants of the Shub-Smale tau-Conjecture and the P vs. NP Problem.
One of our key tools is the construction of combinatorially constrained
tropical varieties with maximally many intersections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4135</identifier>
 <datestamp>2010-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4135</id><created>2010-11-17</created><authors><author><keyname>Han</keyname><forenames>Yunghsiang</forenames></author><author><keyname>Omiwade</keyname><forenames>Soji</forenames></author><author><keyname>Zheng</keyname><forenames>Rong</forenames></author></authors><title>Progressive Decoding for Data Availability and Reliability in
  Distributed Networked Storage</title><categories>cs.DC</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To harness the ever growing capacity and decreasing cost of storage,
providing an abstraction of dependable storage in the presence of crash-stop
and Byzantine failures is compulsory. We propose a decentralized Reed Solomon
coding mechanism with minimum communication overhead. Using a progressive data
retrieval scheme, a data collector contacts only the necessary number of
storage nodes needed to guarantee data integrity. The scheme gracefully adapts
the cost of successful data retrieval to the number of storage node failures.
Moreover, by leveraging the Welch-Berlekamp algorithm, it avoids unnecessary
computations. Compared to the state-of-the-art decoding scheme, the
implementation and evaluation results show that our progressive data retrieval
scheme has up to 35 times better computation performance for low Byzantine node
rates. Additionally, the communication cost in data retrieval is derived
analytically and corroborated by Monte-Carlo simulation results. Our
implementation is flexible in that the level of redundancy it provides is
independent of the number of data generating nodes, a requirement for
distributed storage systems
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4138</identifier>
 <datestamp>2011-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4138</id><created>2010-11-18</created><updated>2011-04-25</updated><authors><author><keyname>Rosenbaum</keyname><forenames>David</forenames></author></authors><title>Quantum Algorithms for Tree Isomorphism and State Symmetrization</title><categories>quant-ph cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The graph isomorphism problem is theoretically interesting and also has many
practical applications. The best known classical algorithms for graph
isomorphism all run in time super-polynomial in the size of the graph in the
worst case. An interesting open problem is whether quantum computers can solve
the graph isomorphism problem in polynomial time. In this paper, an algorithm
is shown which can decide if two rooted trees are isomorphic in polynomial
time. Although this problem is easy to solve efficiently on a classical
computer, the techniques developed may be useful as a basis for quantum
algorithms for deciding isomorphism of more interesting types of graphs. The
related problem of quantum state symmetrization is also studied. A polynomial
time algorithm for the problem of symmetrizing a set of orthonormal states over
an arbitrary permutation group is shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4147</identifier>
 <datestamp>2010-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4147</id><created>2010-11-18</created><authors><author><keyname>Andreyev</keyname><forenames>Sergey</forenames></author></authors><title>World of Movable Objects. Part 1</title><categories>cs.HC</categories><comments>213 pages, 89 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This book is about the transformation of screen objects into movable and
resizable and about the design of applications entirely on the basis of such
elements. The screen objects have a wide variety of shapes; they can be either
graphical objects or controls; there are solitary objects and very complex
objects parts of which are involved in individual, synchronous, and related
movements. Objects can be involved in forward movements and rotation; they can
be resized and reconfigured; all these movements and situations are considered.
On the basis of total movability, the new type of programs - user-driven
applications - are designed. These applications continue to work according to
their main purposes, but the whole control of WHAT, WHEN, and HOW must appear
on the screen is passed from designers to users. Due to the size restriction
used on CoRR, the book is divided here into two parts and one appendix is
deleted. At www.sourceforge.net in the project MoveableGraphics the whole book
is available in a single file together with the accompanying application and
source codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4155</identifier>
 <datestamp>2010-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4155</id><created>2010-11-18</created><authors><author><keyname>Marchand</keyname><forenames>Jonathan</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Guillaume</keyname><forenames>Bruno</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Perrier</keyname><forenames>Guy</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Motifs de graphe pour le calcul de d\'ependances syntaxiques compl\`etes</title><categories>cs.CL</categories><proxy>ccsd</proxy><journal-ref>Conf\'erence sur le Traitement Automatique des Langues Naturelles
  - TALN'10, Montr\'eal : Canada (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article describes a method to build syntactical dependencies starting
from the phrase structure parsing process. The goal is to obtain all the
information needed for a detailled semantical analysis. Interaction Grammars
are used for parsing; the saturation of polarities which is the core of this
formalism can be mapped to dependency relation. Formally, graph patterns are
used to express the set of constraints which control dependency creations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4157</identifier>
 <datestamp>2012-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4157</id><created>2010-11-18</created><updated>2012-07-23</updated><authors><author><keyname>Rashidi</keyname><forenames>Moslem</forenames></author><author><keyname>Hogrud</keyname><forenames>Mikael</forenames></author><author><keyname>Siaudinis</keyname><forenames>Donatas</forenames></author><author><keyname>Qamar</keyname><forenames>Affaq</forenames></author><author><keyname>Khan</keyname><forenames>Imran</forenames></author></authors><title>A full-custom ASIC design of a 8-bit, 25 MHz, Pipeline ADC using 0.35 um
  CMOS technology</title><categories>cs.AR</categories><comments>the paper needs to be withdrawn because of copyright conflicts</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this project was to design and implement a pipeline
Analog-to-Digital Converter using 0.35um CMOS technology. Initial requirements
of a 25-MHz conversion rate and 8-bits of resolution where the only given ones.
Although additional secondary goals such as low power consumption and small
area were stated. The architecture is based on a 1.5 bit per stage structure
utilizing digital correction for each stage [12]. A differential switched
capacitor circuit consisting of a cascade gm-C op-amp with 200MHz ft is used
for sampling and amplification in each stage [12]. Differential dynamic
comparators are used to implement the decision levels required for the 1.5-b
per stage structure. Correction of the pipeline is accomplished by using
digital correction circuit consist of D-latches and full-adders. Area and Power
consumption of whole design was 0.24mm2 and 35mW respectively. The maximum
sample rate at which the converter gave an adequate output was 33MHz.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4161</identifier>
 <datestamp>2014-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4161</id><created>2010-11-18</created><authors><author><keyname>Tumminello</keyname><forenames>Michele</forenames></author><author><keyname>Miccich&#xe8;</keyname><forenames>Salvatore</forenames></author><author><keyname>Lillo</keyname><forenames>Fabrizio</forenames></author><author><keyname>Varho</keyname><forenames>Jan</forenames></author><author><keyname>Piilo</keyname><forenames>Jyrki</forenames></author><author><keyname>Mantegna</keyname><forenames>Rosario N.</forenames></author></authors><title>Community characterization of heterogeneous complex systems</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>8 pages, 1 figure and 2 tables</comments><journal-ref>J. Stat. Mech., P01019, (2011)</journal-ref><doi>10.1088/1742-5468/2011/01/P01019</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an analytical statistical method to characterize the communities
detected in heterogeneous complex systems. By posing a suitable null
hypothesis, our method makes use of the hypergeometric distribution to assess
the probability that a given property is over-expressed in the elements of a
community with respect to all the elements of the investigated set. We apply
our method to two specific complex networks, namely a network of world movies
and a network of physics preprints. The characterization of the elements and of
the communities is done in terms of languages and countries for the movie
network and of journals and subject categories for papers. We find that our
method is able to characterize clearly the identified communities. Moreover our
method works well both for large and for small communities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4169</identifier>
 <datestamp>2011-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4169</id><created>2010-11-18</created><updated>2011-02-23</updated><authors><author><keyname>Burton</keyname><forenames>Benjamin A.</forenames></author></authors><title>The Pachner graph and the simplification of 3-sphere triangulations</title><categories>math.GT cs.CG math.CO</categories><comments>17 pages, 4 figures, 4 tables; v2: incorporate connectedness into
  Theorem 4, other minor revisions; to appear in SoCG 2011</comments><acm-class>F.2.2, G.2.1, G.2.2, D.1.3</acm-class><journal-ref>SCG '11: Proceedings of the Twenty-Seventh Annual Symposium on
  Computational Geometry, ACM, 2011, pp. 153-162</journal-ref><doi>10.1145/1998196.1998220</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is important to have fast and effective methods for simplifying 3-manifold
triangulations without losing any topological information. In theory this is
difficult: we might need to make a triangulation super-exponentially more
complex before we can make it smaller than its original size. Here we present
experimental work suggesting that for 3-sphere triangulations the reality is
far different: we never need to add more than two tetrahedra, and we never need
more than a handful of local modifications. If true in general, these extremely
surprising results would have significant implications for decision algorithms
and the study of triangulations in 3-manifold topology.
  The algorithms behind these experiments are interesting in their own right.
Key techniques include the isomorph-free generation of all 3-manifold
triangulations of a given size, polynomial-time computable signatures that
identify triangulations uniquely up to isomorphism, and parallel algorithms for
studying finite level sets in the infinite Pachner graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4199</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4199</id><created>2010-11-18</created><updated>2011-02-24</updated><authors><author><keyname>Moses</keyname><forenames>Melanie</forenames></author><author><keyname>Banerjee</keyname><forenames>Soumya</forenames></author></authors><title>Biologically Inspired Design Principles for Scalable, Robust, Adaptive,
  Decentralized Search and Automated Response (RADAR)</title><categories>cs.NE cs.DC cs.SY math.OC q-bio.QM</categories><comments>8 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed search problems are ubiquitous in Artificial Life (ALife). Many
distributed search problems require identifying a rare and previously unseen
event and producing a rapid response. This challenge amounts to finding and
removing an unknown needle in a very large haystack. Traditional computational
search models are unlikely to find, nonetheless, appropriately respond to,
novel events, particularly given data distributed across multiple platforms in
a variety of formats and sources with variable and unknown reliability.
Biological systems have evolved solutions to distributed search and response
under uncertainty. Immune systems and ant colonies efficiently scale up
massively parallel search with automated response in highly dynamic
environments, and both do so using distributed coordination without centralized
control. These properties are relevant to ALife, where distributed, autonomous,
robust and adaptive control is needed to design robot swarms, mobile computing
networks, computer security systems and other distributed intelligent systems.
They are also relevant for searching, tracking the spread of ideas, and
understanding the impact of innovations in online social networks. We review
design principles for Scalable Robust, Adaptive, Decentralized search with
Automated Response (Scalable RADAR) in biology. We discuss how biological RADAR
scales up efficiently, and then discuss in detail how modular search in the
immune system can be mimicked or built upon in ALife. Such search mechanisms
are particularly useful when components have limited capacity to communicate
and social or physical distance makes long distance communication more costly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4214</identifier>
 <datestamp>2010-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4214</id><created>2010-11-18</created><updated>2010-12-16</updated><authors><author><keyname>Babiak</keyname><forenames>Tom&#xe1;\vs</forenames></author><author><keyname>K\vret\'\insk&#xfd;</keyname><forenames>Mojm\'\ir</forenames></author><author><keyname>\vReh&#xe1;k</keyname><forenames>Vojt\vech</forenames></author><author><keyname>Strej\vcek</keyname><forenames>Jan</forenames></author></authors><title>A Short Story of a Subtle Error in LTL Formulas Reduction and Divine
  Incorrectness</title><categories>cs.LO cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We identify a subtle error in LTL formulas reduction method used as one
optimization step in an LTL to B\&quot;uchi automata translation. The error led to
some incorrect answers of the established model checker DiVinE. This paper
should help authors of other model checkers to avoid this error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4224</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4224</id><created>2010-11-18</created><updated>2010-12-10</updated><authors><author><keyname>Bodlaender</keyname><forenames>Hans L.</forenames></author><author><keyname>Jansen</keyname><forenames>Bart M. P.</forenames></author><author><keyname>Kratsch</keyname><forenames>Stefan</forenames></author></authors><title>Cross-Composition: A New Technique for Kernelization Lower Bounds</title><categories>cs.CC</categories><comments>Updated information based on final version submitted to STACS 2011</comments><acm-class>F.2.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We introduce a new technique for proving kernelization lower bounds, called
cross-composition. A classical problem L cross-composes into a parameterized
problem Q if an instance of Q with polynomially bounded parameter value can
express the logical OR of a sequence of instances of L. Building on work by
Bodlaender et al. (ICALP 2008) and using a result by Fortnow and Santhanam
(STOC 2008) we show that if an NP-complete problem cross-composes into a
parameterized problem Q then Q does not admit a polynomial kernel unless the
polynomial hierarchy collapses. Our technique generalizes and strengthens the
recent techniques of using OR-composition algorithms and of transferring the
lower bounds via polynomial parameter transformations. We show its
applicability by proving kernelization lower bounds for a number of important
graphs problems with structural (non-standard) parameterizations, e.g.,
Chromatic Number, Clique, and Weighted Feedback Vertex Set do not admit
polynomial kernels with respect to the vertex cover number of the input graphs
unless the polynomial hierarchy collapses, contrasting the fact that these
problems are trivially fixed-parameter tractable for this parameter. We have
similar lower bounds for Feedback Vertex Set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4237</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4237</id><created>2010-11-18</created><authors><author><keyname>Michel</keyname><forenames>Lo&#xef;c</forenames></author></authors><title>Variational and symplectic approach of the model-free control</title><categories>cs.SY math.OC</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We propose a theoretical development of the model-free control in order to
extend its robustness capabilities. The proposed method is based on the
auto-tuning of the model-free controller parameter using an optimal approach.
Some examples are discussed to illustrate our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4282</identifier>
 <datestamp>2010-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4282</id><created>2010-11-18</created><authors><author><keyname>Fr&#xe9;nod</keyname><forenames>Emmanuel</forenames><affiliation>LMAM</affiliation></author><author><keyname>Sonnendr&#xfc;cker</keyname><forenames>Eric</forenames><affiliation>INRIA Lorraine</affiliation></author></authors><title>Homogenization of the Vlasov Equation and of the Vlasov - Poisson System
  with a Strong External Magnetic Field</title><categories>math.AP cs.NA math.NA</categories><proxy>ccsd</proxy><report-no>RR-3227</report-no><journal-ref>Asymptotic Analysis 18, 3-4 (1998) 193--214</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the difficulty arising in the numerical simulation of the
movement of charged particles in presence of a large external magnetic field,
which adds an additional time scale and thus imposes to use a much smaller time
step, we perform in this paper a homogenization of the Vlasov equation and of
the Vlasov-Poisson system which yield approximate equations describing the mean
behavior of the particles. The convergence proof is based on the two scale
convergence tools introduced by N'Guetseng and Allaire. We also consider the
case where, in addition to the magnetic field, a large external electric field
orthogonal to the magnetic field and of the same magnitude is applied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4302</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4302</id><created>2010-11-18</created><updated>2011-03-01</updated><authors><author><keyname>zhang</keyname><forenames>chao</forenames></author><author><keyname>Yin</keyname><forenames>Huarui</forenames></author><author><keyname>Ren</keyname><forenames>Pinyi</forenames></author></authors><title>The Effects of Narrowband Interference on Finite-Resolution IR-UWB
  Digital Receiver</title><categories>cs.IT math.IT</categories><comments>3 pages,2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finite-resolution digital receiver is recently considered as a potential way
to Ultra Wide Band (UWB) communication systems due to its ability of mitigating
the challenge of Analog-Digital Converter (ADC). In this paper, the effects of
narrowband interference (NBI) are investigated when finite-resolution digital
receiver is used for Impulse Radio-UWB (IR-UWB) system. It is shown that
finite-resolution receiver enlarges the impact of NBI. The lower resolution of
the UWB receiver is, the more degradations NBI causes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4321</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4321</id><created>2010-11-18</created><authors><author><keyname>Zarandi</keyname><forenames>M. H. Fazel</forenames></author><author><keyname>Razaee</keyname><forenames>Zahra S.</forenames></author></authors><title>A Fuzzy Clustering Model for Fuzzy Data with Outliers</title><categories>cs.CV</categories><comments>18 pages, Journal paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a fuzzy clustering model for fuzzy data with outliers is
proposed. The model is based on Wasserstein distance between interval valued
data which is generalized to fuzzy data. In addition, Keller's approach is used
to identify outliers and reduce their influences. We have also defined a
transformation to change our distance to the Euclidean distance. With the help
of this approach, the problem of fuzzy clustering of fuzzy data is reduced to
fuzzy clustering of crisp data. In order to show the performance of the
proposed clustering algorithm, two simulation experiments are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4324</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4324</id><created>2010-11-18</created><updated>2012-09-11</updated><authors><author><keyname>Preciado</keyname><forenames>Victor M.</forenames></author><author><keyname>Jadbabaie</keyname><forenames>Ali</forenames></author></authors><title>Moment-Based Spectral Analysis of Large-Scale Networks Using Local
  Structural Information</title><categories>cs.SI cs.SY math.DS math.OC physics.data-an physics.soc-ph</categories><comments>To appear in IEEE Transactions on Networking. arXiv admin note: text
  overlap with arXiv:1103.5131</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The eigenvalues of matrices representing the structure of large-scale complex
networks present a wide range of applications, from the analysis of dynamical
processes taking place in the network to spectral techniques aiming to rank the
importance of nodes in the network. A common approach to study the relationship
between the structure of a network and its eigenvalues is to use synthetic
random networks in which structural properties of interest, such as degree
distributions, are prescribed. Although very common, synthetic models present
two major flaws: (\emph{i}) These models are only suitable to study a very
limited range of structural properties, and (\emph{ii}) they implicitly induce
structural properties that are not directly controlled and can deceivingly
influence the network eigenvalue spectrum. In this paper, we propose an
alternative approach to overcome these limitations. Our approach is not based
on synthetic models, instead, we use algebraic graph theory and convex
optimization to study how structural properties influence the spectrum of
eigenvalues of the network. Using our approach, we can compute with low
computational overhead global spectral properties of a network from its local
structural properties. We illustrate our approach by studying how structural
properties of online social networks influence their eigenvalue spectra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4328</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4328</id><created>2010-11-18</created><updated>2011-03-15</updated><authors><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Graphical Models Concepts in Compressed Sensing</title><categories>cs.IT math.IT</categories><comments>43 pages, 22 eps figures, typos corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper surveys recent work in applying ideas from graphical models and
message passing algorithms to solve large scale regularized regression
problems. In particular, the focus is on compressed sensing reconstruction via
ell_1 penalized least-squares (known as LASSO or BPDN). We discuss how to
derive fast approximate message passing algorithms to solve this problem.
Surprisingly, the analysis of such algorithms allows to prove exact
high-dimensional limit results for the LASSO risk.
  This paper will appear as a chapter in a book on `Compressed Sensing' edited
by Yonina Eldar and Gitta Kutyniok.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4330</identifier>
 <datestamp>2010-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4330</id><created>2010-11-16</created><authors><author><keyname>Salikhmetov</keyname><forenames>Anton</forenames></author></authors><title>Uniform Memory and Serialization for Lambda Calculus</title><categories>cs.LO cs.PL math.LO</categories><comments>24 pages, in Russian</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a special type of systems, defines their properties,
and then demonstrates that a reduction machine for pure untyped extensional
lambda calculus can be implemented as a system of the introduced type.
Specifically, we discuss uniform memory as a special kind of graphs and real
time operation of state machines that use the uniform memory as their state.
Also, we consider a special case of serialization, the latter being useful for
the mechanism that compares results during computation, not after the
computation is done. However, we start with detailed explanation of our
motivation for this work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4362</identifier>
 <datestamp>2010-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4362</id><created>2010-11-19</created><authors><author><keyname>Scherrer</keyname><forenames>Bruno</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Should one compute the Temporal Difference fix point or minimize the
  Bellman Residual? The unified oblique projection view</title><categories>cs.AI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate projection methods, for evaluating a linear approximation of
the value function of a policy in a Markov Decision Process context. We
consider two popular approaches, the one-step Temporal Difference fix-point
computation (TD(0)) and the Bellman Residual (BR) minimization. We describe
examples, where each method outperforms the other. We highlight a simple
relation between the objective function they minimize, and show that while BR
enjoys a performance guarantee, TD(0) does not in general. We then propose a
unified view in terms of oblique projections of the Bellman equation, which
substantially simplifies and extends the characterization of (schoknecht,2002)
and the recent analysis of (Yu &amp; Bertsekas, 2008). Eventually, we describe some
simulations that suggest that if the TD(0) solution is usually slightly better
than the BR solution, its inherent numerical instability makes it very bad in
some cases, and thus worse on average.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4363</identifier>
 <datestamp>2010-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4363</id><created>2010-11-19</created><authors><author><keyname>Hakiri</keyname><forenames>Akram</forenames><affiliation>LAAS</affiliation></author></authors><title>QoS-enabled ANFIS Dead Reckoning Algorithm for Distributed Interactive
  Simulation</title><categories>cs.NI</categories><proxy>ccsd</proxy><journal-ref>IEEE/ACM International Symposium on Distributed Simulation and
  Real Time Applications (DS-RT 2010) (2010) 33 - 42</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dead Reckoning mechanisms are usually used to estimate the position of
simulated entity in virtual environment. However, this technique often ignores
available contextual information that may be influential to the state of an
entity, sacrificing remote predictive accuracy in favor of low computational
complexity. A novel extension of Dead Reckoning is suggested in this paper to
increase the network availability and fulfill the required Quality of Service
in large scale distributed simulation application. The proposed algorithm is
referred to as ANFIS Dead Reckoning, which stands for Adaptive Neuro-based
Fuzzy Inference System Dead Reckoning is based on a fuzzy inference system
which is trained by the learning algorithm derived from the neuronal networks
and fuzzy inference theory. The proposed mechanism takes its based on the
optimization approach to calculate the error threshold violation in networking
games. Our model shows it primary benefits especially in the decision making of
the behavior of simulated entities and preserving the consistence of the
simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4366</identifier>
 <datestamp>2010-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4366</id><created>2010-11-19</created><authors><author><keyname>Treust</keyname><forenames>Mael Le</forenames></author><author><keyname>Tembine</keyname><forenames>Hamidou</forenames></author><author><keyname>Lasaulce</keyname><forenames>Samson</forenames></author><author><keyname>Debbah</keyname><forenames>M&#xe9;rouane</forenames></author></authors><title>Coverage games in small cells networks</title><categories>cs.GT cs.NI</categories><proxy>ccsd</proxy><journal-ref>Future Network and MobileSummit 2010, Italy (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of cooperative power control in distributed
small cell wireless networks. We introduce a novel framework, based on repeated
games, which models the interactions of the different transmit base stations in
the downlink. By exploiting the specific structure of the game, we show that we
can improve the system performance by selecting the Pareto optimal solution as
well as reduce the price of stability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4377</identifier>
 <datestamp>2010-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4377</id><created>2010-11-19</created><authors><author><keyname>Alviano</keyname><forenames>Mario</forenames></author><author><keyname>Faber</keyname><forenames>Wolfgang</forenames></author></authors><title>Dynamic Magic Sets for Super-Consistent Answer Set Programs</title><categories>cs.LO</categories><comments>15 pages, 3 figures, ASPOCP'10</comments><acm-class>F.4.1; I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For many practical applications of ASP, for instance data integration or
planning, query answering is important, and therefore query optimization
techniques for ASP are of great interest. Magic Sets are one of these
techniques, originally defined for Datalog queries (ASP without disjunction and
negation). Dynamic Magic Sets (DMS) are an extension of this technique, which
has been proved to be sound and complete for query answering over ASP programs
with stratified negation.
  A distinguishing feature of DMS is that the optimization can be exploited
also during the nondeterministic phase of ASP engines. In particular, after
some assumptions have been made during the computation, parts of the program
may become irrelevant to a query under these assumptions. This allows for
dynamic pruning of the search space, which may result in exponential
performance gains.
  In this paper, the correctness of DMS is formally established and proved for
brave and cautious reasoning over the class of super-consistent ASP programs
(ASP^{sc} programs). ASP^{sc} programs guarantee consistency (i.e., have answer
sets) when an arbitrary set of facts is added to them. This result generalizes
the applicability of DMS, since the class of ASP^{sc} programs is richer than
ASP programs with stratified negation, and in particular includes all
odd-cycle-free programs. DMS has been implemented as an extension of DLV, and
the effectiveness of DMS for ASP^{sc} programs is empirically confirmed by
experimental results with this system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4384</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4384</id><created>2010-11-19</created><updated>2010-12-25</updated><authors><author><keyname>Avron</keyname><forenames>Arnon</forenames><affiliation>Tel Aviv University</affiliation></author><author><keyname>Lahav</keyname><forenames>Ori</forenames><affiliation>Tel Aviv University</affiliation></author></authors><title>On Constructive Connectives and Systems</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.4.1, I.2.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 4 (December
  25, 2010) lmcs:967</journal-ref><doi>10.2168/LMCS-6(4:12)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Canonical inference rules and canonical systems are defined in the framework
of non-strict single-conclusion sequent systems, in which the succeedents of
sequents can be empty. Important properties of this framework are investigated,
and a general non-deterministic Kripke-style semantics is provided. This
general semantics is then used to provide a constructive (and very natural),
sufficient and necessary coherence criterion for the validity of the strong
cut-elimination theorem in such a system. These results suggest new syntactic
and semantic characterizations of basic constructive connectives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4394</identifier>
 <datestamp>2011-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4394</id><created>2010-11-19</created><updated>2011-03-23</updated><authors><author><keyname>Corominas-Murtra</keyname><forenames>Bernat</forenames></author><author><keyname>Go&#xf1;i</keyname><forenames>Joaqu&#xed;n</forenames></author><author><keyname>Rodr&#xed;guez-Caso</keyname><forenames>Carlos</forenames></author><author><keyname>Sol&#xe9;</keyname><forenames>Ricard</forenames></author></authors><title>Measuring the Hierarchy of Feedforward Networks</title><categories>physics.data-an cond-mat.dis-nn cs.SI nlin.AO physics.soc-ph</categories><comments>12 pages, 6 figures. Accepted for publication in Chaos Journal
  special issue &quot;Mesoscales in Complex Networks&quot;. Previous inconsistencies in
  the definition of the hierarchy index have been fixed</comments><doi>10.1063/1.3562548</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we explore the concept of hierarchy as a quantifiable
descriptor of ordered structures, departing from the definition of three
conditions to be satisfied for a hierarchical structure: {\em order}, {\em
predictability} and {\em pyramidal structure}. According to these principles we
define a hierarchical index taking concepts from graph and information theory.
This estimator allows to quantify the hierarchical character of any system
susceptible to be abstracted in a feedforward causal graph, i.e., a directed
acyclic graph defined in a single connected structure. Our hierarchical index
is a balance between this predictability and pyramidal condition by the
definition of two entropies: one attending the onward flow and other for the
backward reversion. We show how this index allows to identify hierarchical,
anti-hierarchical and non hierarchical structures. Our formalism reveals that
departing from the defined conditions for a hierarchical structure, feedforward
trees and the inverted tree graphs emerge as the only causal structures of
maximal hierarchical and anti-hierarchical systems, respectively. Conversely,
null values of the hierarchical index are attributed to a number of different
configuration networks; from linear chains, due to their lack of pyramid
structure, to full-connected feedforward graphs where the diversity of onward
pathways is canceled by the uncertainty (lack of predictability) when going
backwards. Some illustrative examples are provided for the distinction among
these three types of hierarchical causal graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4401</identifier>
 <datestamp>2010-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4401</id><created>2010-11-19</created><authors><author><keyname>Pal</keyname><forenames>Manjish</forenames></author></authors><title>Combinatorial Geometry of Graph Partitioning - I</title><categories>cs.DS math.MG</categories><comments>Extension of results in authors' previous paper, CoRR abs/0907.1369</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The {\sc $c$-Balanced Separator} problem is a graph-partitioning problem in
which given a graph $G$, one aims to find a cut of minimum size such that both
the sides of the cut have at least $cn$ vertices. In this paper, we present new
directions of progress in the {\sc $c$-Balanced Separator} problem. More
specifically, we propose a family of mathematical programs, that depend upon a
parameter $p &gt; 0$, and is an extension of the uniform version of the SDPs
proposed by Goemans and Linial for this problem. In fact for the case, when
$p=1$, if one can solve this program in polynomial time then simply using the
Goemans-Williamson's randomized rounding algorithm for {\sc Max Cut}
\cite{WG95} will give an $O(1)$-factor approximation algorithm for {\sc
$c$-Balanced Separator} improving the best known approximation factor of
$O(\sqrt{\log n})$ due to Arora, Rao and Vazirani \cite{ARV}. This family of
programs is not convex but one can transform them into so called
\emph{\textbf{concave programs}} in which one optimizes a concave function over
a convex feasible set. It is well known that the optima of such programs lie at
one of the extreme points of the feasible set \cite{TTT85}. Our main
contribution is a combinatorial characterization of some extreme points of the
feasible set of the mathematical program, for $p=1$ case, which to the best of
our knowledge is the first of its kind. We further demonstrate how this
characterization can be used to solve the program in a restricted setting.
Non-convex programs have recently been investigated by Bhaskara and
Vijayaraghvan \cite{BV11} in which they design algorithms for approximating
Matrix $p$-norms although their algorithmic techniques are analytical in
nature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4438</identifier>
 <datestamp>2010-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4438</id><created>2010-11-19</created><authors><author><keyname>Huang</keyname><forenames>Yun Bao</forenames></author></authors><title>Smooth infinite words over $n$-letter alphabets having same remainder
  when divided by $n$</title><categories>cs.FL cs.DM math.CO</categories><comments>25 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Brlek et al. (2008) studied smooth infinite words and established some
results on letter frequency, recurrence, reversal and complementation for
2-letter alphabets having same parity. In this paper, we explore smooth
infinite words over $n$-letter alphabet $\{a_1,a_2,...,a_n\}$, where
$a_1&lt;a_2&lt;...&lt;a_n$ are positive integers and have same remainder when divided by
$n$. And let $a_i=n\cdot q_i+r,\;q_i\in N$ for $i=1,2,...,n$, where
$r=0,1,2,...,n-1$. We use distinct methods to prove that (1) if $r=0$, the
letters frequency of two times differentiable well-proportioned infinite words
is $1/n$, which suggests that the letter frequency of the generalized Kolakoski
sequences is $1/2$ for 2-letter even alphabets; (2) the smooth infinite words
are recurrent; (3) if $r=0$ or $r&gt;0 \text{ and }n$ is an even number, the
generalized Kolakoski words are uniformly recurrent for the alphabet $\Sigma_n$
with the cyclic order; (4) the factor set of three times differentiable
infinite words is not closed under any nonidentical permutation. Brlek et al.'s
results are only the special cases of our corresponding results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4445</identifier>
 <datestamp>2011-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4445</id><created>2010-11-19</created><updated>2011-09-27</updated><authors><author><keyname>Takaguchi</keyname><forenames>Taro</forenames></author><author><keyname>Masuda</keyname><forenames>Naoki</forenames></author></authors><title>Voter model with non-Poissonian interevent intervals</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>18 pages, 8 figures</comments><journal-ref>Phys. Rev. E 84, 036115 (2011)</journal-ref><doi>10.1103/PhysRevE.84.036115</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent analysis of social communications among humans has revealed that the
interval between interactions for a pair of individuals and for an individual
often follows a long-tail distribution. We investigate the effect of such a
non-Poissonian nature of human behavior on dynamics of opinion formation. We
use a variant of the voter model and numerically compare the time to consensus
of all the voters with different distributions of interevent intervals and
different networks. Compared with the exponential distribution of interevent
intervals (i.e., the standard voter model), the power-law distribution of
interevent intervals slows down consensus on the ring. This is because of the
memory effect; in the power-law case, the expected time until the next update
event on a link is large if the link has not had an update event for a long
time. On the complete graph, the consensus time in the power-law case is close
to that in the exponential case. Regular graphs bridge these two results such
that the slowing down of the consensus in the power-law case as compared to the
exponential case is less pronounced as the degree increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4465</identifier>
 <datestamp>2010-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4465</id><created>2010-11-19</created><authors><author><keyname>Batz</keyname><forenames>Gernot Veit</forenames></author><author><keyname>Geisberger</keyname><forenames>Robert</forenames></author><author><keyname>Luxen</keyname><forenames>Dennis</forenames></author><author><keyname>Sanders</keyname><forenames>Peter</forenames></author></authors><title>Compressed Transmission of Route Descriptions</title><categories>cs.DS</categories><comments>7 pages, technical report</comments><acm-class>G.2.2; E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present two methods to compress the description of a route in a road
network, i.e., of a path in a directed graph. The first method represents a
path by a sequence of via edges. The subpaths between the via edges have to be
unique shortest paths. Instead of via edges also via nodes can be used, though
this requires some simple preprocessing. The second method uses contraction
hierarchies to replace subpaths of the original path by shortcuts. The two
methods can be combined with each other. Also, we propose the application to
mobile server based routing: We compute the route on a server which has access
to the latest information about congestions for example. Then we transmit the
computed route to the car using some mobile radio communication. There, we
apply the compression to save costs and transmission time. If the compression
works well, we can transmit routes even when the bandwidth is low. Although we
have not evaluated our ideas with realistic data yet, they are quite promising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4532</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4532</id><created>2010-11-19</created><authors><author><keyname>Gagie</keyname><forenames>Travis</forenames></author><author><keyname>Navarro</keyname><forenames>Gonzalo</forenames></author><author><keyname>Puglisi</keyname><forenames>Simon J.</forenames></author></authors><title>New Algorithms on Wavelet Trees and Applications to Information
  Retrieval</title><categories>cs.DS cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wavelet trees are widely used in the representation of sequences,
permutations, text collections, binary relations, discrete points, and other
succinct data structures. We show, however, that this still falls short of
exploiting all of the virtues of this versatile data structure. In particular
we show how to use wavelet trees to solve fundamental algorithmic problems such
as {\em range quantile} queries, {\em range next value} queries, and {\em range
intersection} queries. We explore several applications of these queries in
Information Retrieval, in particular {\em document retrieval} in hierarchical
and temporal documents, and in the representation of {\em inverted lists}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4535</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4535</id><created>2010-11-19</created><updated>2010-12-08</updated><authors><author><keyname>Xiao</keyname><forenames>Hongda</forenames></author><author><keyname>Yeh</keyname><forenames>Edmund</forenames></author></authors><title>Cascading Link Failure in the Power Grid: A Percolation-Based Analysis</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large-scale power blackouts caused by cascading failure are inflicting
enormous socioeconomic costs. We study the problem of cascading link failures
in power networks modelled by random geometric graphs from a percolation-based
viewpoint. To reflect the fact that links fail according to the amount of power
flow going through them, we introduce a model where links fail according to a
probability which depends on the number of neighboring links. We devise a
mapping which maps links in a random geometric graph to nodes in a
corresponding dual covering graph. This mapping enables us to obtain the
first-known analytical conditions on the existence and non-existence of a large
component of operational links after degree-dependent link failures. Next, we
present a simple but descriptive model for cascading link failure, and use the
degree-dependent link failure results to obtain the first-known analytical
conditions on the existence and non-existence of cascading link failures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4550</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4550</id><created>2010-11-19</created><authors><author><keyname>Reddy</keyname><forenames>P. Venkata Subba</forenames></author><author><keyname>Iyer</keyname><forenames>K. Viswanathan</forenames></author></authors><title>Algorithms for enumerating and counting D2CS of some graphs</title><categories>cs.DM</categories><comments>Six pages: Accepted for 15th annual conference of Gwalior academy of
  mathematical sciences,Dec.12-14, 2010,New Delhi</comments><msc-class>05C12, 05C30, 05C85</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A D2CS of a graph G is a set $S \subseteq V(G)$ with $diam(G[S]) \leq 2$. We
study the problem of counting and enumerating D2CS of a graph. First we give an
explicit formula for the number of D2CS in a complete k-ary tree, Fibonacci
tree, binary Fibonacci tree and the binomial tree. Next we give an algorithm
for enumerating and counting D2CS of a graph. We then give a linear time
algorithm for finding all maximal D2CS in a strongly chordal graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4558</identifier>
 <datestamp>2012-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4558</id><created>2010-11-20</created><updated>2012-07-05</updated><authors><author><keyname>Kerneis</keyname><forenames>Gabriel</forenames><affiliation>PPS</affiliation></author><author><keyname>Chroboczek</keyname><forenames>Juliusz</forenames><affiliation>PPS</affiliation></author></authors><title>Continuation-Passing C: compiling threads to events through
  continuations</title><categories>cs.PL</categories><comments>Higher-Order and Symbolic Computation (2012). arXiv admin note:
  substantial text overlap with arXiv:1202.3247</comments><proxy>ccsd</proxy><journal-ref>Higher-Order and Symbolic Computation 24(3): 239-279 (2011)</journal-ref><doi>10.1007/s10990-012-9084-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce Continuation Passing C (CPC), a programming
language for concurrent systems in which native and cooperative threads are
unified and presented to the programmer as a single abstraction. The CPC
compiler uses a compilation technique, based on the CPS transform, that yields
efficient code and an extremely lightweight representation for contexts. We
provide a proof of the correctness of our compilation scheme. We show in
particular that lambda-lifting, a common compilation technique for functional
languages, is also correct in an imperative language like C, under some
conditions enforced by the CPC compiler. The current CPC compiler is mature
enough to write substantial programs such as Hekate, a highly concurrent
BitTorrent seeder. Our benchmark results show that CPC is as efficient, while
using significantly less space, as the most efficient thread libraries
available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4580</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4580</id><created>2010-11-20</created><authors><author><keyname>Karawia</keyname><forenames>A. A.</forenames></author></authors><title>A New Algorithm for General Cyclic Heptadiagonal Linear Systems Using
  Sherman-Morrison-Woodbury formula</title><categories>cs.NA</categories><comments>8 pages</comments><msc-class>15A15, 15A23, 68W30, 11Y05, 33F10, F.2.1, G.1.0</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new efficient computational algorithm is presented for
solving cyclic heptadiagonal linear systems based on using of heptadiagonal
linear solver and Sherman-Morrison-Woodbury formula. The implementation of the
algorithm using computer algebra systems (CAS) such as MAPLE and MATLAB is
straightforward. Numerical example is presented for the sake of illustration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4597</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4597</id><created>2010-11-20</created><authors><author><keyname>Belmega</keyname><forenames>E. V.</forenames></author><author><keyname>Lasaulce</keyname><forenames>S.</forenames></author></authors><title>Energy-Efficient Precoding for Multiple-Antenna Terminals</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2010.2086451</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of energy-efficient precoding is investigated when the terminals
in the system are equipped with multiple antennas. Considering static and
fast-fading multiple-input multiple-output (MIMO) channels, the
energy-efficiency is defined as the transmission rate to power ratio and shown
to be maximized at low transmit power. The most interesting case is the one of
slow fading MIMO channels. For this type of channels, the optimal precoding
scheme is generally not trivial. Furthermore, using all the available transmit
power is not always optimal in the sense of energy-efficiency (which, in this
case, corresponds to the communication-theoretic definition of the
goodput-to-power (GPR) ratio). Finding the optimal precoding matrices is shown
to be a new open problem and is solved in several special cases: 1. when there
is only one receive antenna; 2. in the low or high signal-to-noise ratio
regime; 3. when uniform power allocation and the regime of large numbers of
antennas are assumed. A complete numerical analysis is provided to illustrate
the derived results and stated conjectures. In particular, the impact of the
number of antennas on the energy-efficiency is assessed and shown to be
significant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4598</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4598</id><created>2010-11-20</created><updated>2010-11-23</updated><authors><author><keyname>Belmega</keyname><forenames>E. V.</forenames></author><author><keyname>Lasaulce</keyname><forenames>S.</forenames></author><author><keyname>Debbah</keyname><forenames>M.</forenames></author><author><keyname>Jungers</keyname><forenames>M.</forenames></author><author><keyname>Dumont</keyname><forenames>J.</forenames></author></authors><title>Power Allocation Games in Wireless Networks of Multi-antenna Terminals</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider wireless networks that can be modeled by multiple access channels
in which all the terminals are equipped with multiple antennas. The propagation
model used to account for the effects of transmit and receive antenna
correlations is the unitary-invariant-unitary model, which is one of the most
general models available in the literature. In this context, we introduce and
analyze two resource allocation games. In both games, the mobile stations
selfishly choose their power allocation policies in order to maximize their
individual uplink transmission rates; in particular they can ignore some
specified centralized policies. In the first game considered, the base station
implements successive interference cancellation (SIC) and each mobile station
chooses his best space-time power allocation scheme; here, a coordination
mechanism is used to indicate to the users the order in which the receiver
applies SIC. In the second framework, the base station is assumed to implement
single-user decoding. For these two games a thorough analysis of the Nash
equilibrium is provided: the existence and uniqueness issues are addressed; the
corresponding power allocation policies are determined by exploiting random
matrix theory; the sum-rate efficiency of the equilibrium is studied
analytically in the low and high signal-to-noise ratio regimes and by
simulations in more typical scenarios. Simulations show that, in particular,
the sum-rate efficiency is high for the type of systems investigated and the
performance loss due to the use of the proposed suboptimum coordination
mechanism is very small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4602</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4602</id><created>2010-11-20</created><authors><author><keyname>Belmega</keyname><forenames>E. V.</forenames></author><author><keyname>Djeumou</keyname><forenames>B.</forenames></author><author><keyname>Lasaulce</keyname><forenames>S.</forenames></author></authors><title>Gaussian Broadcast Channels with an Orthogonal and Bidirectional
  Cooperation Link</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a system where one transmitter broadcasts a single
common message to two receivers linked by a bidirectional cooperation channel,
which is assumed to be orthogonal to the downlink channel. Assuming a
simplified setup where, in particular, scalar relaying protocols are used and
channel coding is not exploited, we want to provide elements of response to
several questions of practical interest. Here are the main underlying issues:
1. The way of recombining the signals at the receivers; 2. The optimal number
of cooperation rounds; 3. The way of cooperating (symmetrically or
asymmetrically; which receiver should start cooperating in the latter case); 4.
The influence of spectral resources. These issues are considered by studying
the performance of the assumed system through analytical results when they are
derivable and through simulation results. For the particular choices we made,
the results sometimes do not coincide with those available for the discrete
counterpart of the studied channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4609</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4609</id><created>2010-11-20</created><authors><author><keyname>Gagie</keyname><forenames>Travis</forenames></author></authors><title>Bounds from a Card Trick</title><categories>cs.IT math.IT</categories><comments>Submitted to a journal on 23/03/10</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new variation of a mathematical card trick, whose analysis
leads to new lower bounds for data compression and estimating the entropy of
Markov sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4615</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4615</id><created>2010-11-20</created><updated>2011-02-28</updated><authors><author><keyname>Ram</keyname><forenames>Idan</forenames></author><author><keyname>Elad</keyname><forenames>Michael</forenames></author><author><keyname>Cohen</keyname><forenames>Israel</forenames></author></authors><title>Generalized Tree-Based Wavelet Transform</title><categories>cs.CV</categories><comments>10 pages, 4 algorithms, 8 figures, 3 tables, submitted to IEEE
  Transactions on Signal Processing</comments><doi>10.1109/TSP.2011.2158428</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a new wavelet transform applicable to functions
defined on graphs, high dimensional data and networks. The proposed method
generalizes the Haar-like transform proposed in [1], and it is defined via a
hierarchical tree, which is assumed to capture the geometry and structure of
the input data. It is applied to the data using a modified version of the
common one-dimensional (1D) wavelet filtering and decimation scheme, which can
employ different wavelet filters. In each level of this wavelet decomposition
scheme, a permutation derived from the tree is applied to the approximation
coefficients, before they are filtered. We propose a tree construction method
that results in an efficient representation of the input function in the
transform domain. We show that the proposed transform is more efficient than
both the 1D and two-dimensional (2D) separable wavelet transforms in
representing images. We also explore the application of the proposed transform
to image denoising, and show that combined with a subimage averaging scheme, it
achieves denoising results which are similar to those obtained with the K-SVD
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4623</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4623</id><created>2010-11-20</created><authors><author><keyname>Moghaddam</keyname><forenames>Samaneh</forenames></author><author><keyname>Popowich</keyname><forenames>Fred</forenames></author></authors><title>Opinion Polarity Identification through Adjectives</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  &quot;What other people think&quot; has always been an important piece of information
during various decision-making processes. Today people frequently make their
opinions available via the Internet, and as a result, the Web has become an
excellent source for gathering consumer opinions. There are now numerous Web
resources containing such opinions, e.g., product reviews forums, discussion
groups, and Blogs. But, due to the large amount of information and the wide
range of sources, it is essentially impossible for a customer to read all of
the reviews and make an informed decision on whether to purchase the product.
It is also difficult for the manufacturer or seller of a product to accurately
monitor customer opinions. For this reason, mining customer reviews, or opinion
mining, has become an important issue for research in Web information
extraction. One of the important topics in this research area is the
identification of opinion polarity. The opinion polarity of a review is usually
expressed with values 'positive', 'negative' or 'neutral'. We propose a
technique for identifying polarity of reviews by identifying the polarity of
the adjectives that appear in them. Our evaluation shows the technique can
provide accuracy in the area of 73%, which is well above the 58%-64% provided
by naive Bayesian classifiers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4632</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4632</id><created>2010-11-20</created><authors><author><keyname>Boutsidis</keyname><forenames>Christos</forenames></author><author><keyname>Zouzias</keyname><forenames>Anastasios</forenames></author><author><keyname>Drineas</keyname><forenames>Petros</forenames></author></authors><title>Random Projections for $k$-means Clustering</title><categories>cs.AI cs.DS</categories><comments>Neural Information Processing Systems (NIPS) 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses the topic of dimensionality reduction for $k$-means
clustering. We prove that any set of $n$ points in $d$ dimensions (rows in a
matrix $A \in \RR^{n \times d}$) can be projected into $t = \Omega(k / \eps^2)$
dimensions, for any $\eps \in (0,1/3)$, in $O(n d \lceil \eps^{-2} k/ \log(d)
\rceil )$ time, such that with constant probability the optimal $k$-partition
of the point set is preserved within a factor of $2+\eps$. The projection is
done by post-multiplying $A$ with a $d \times t$ random matrix $R$ having
entries $+1/\sqrt{t}$ or $-1/\sqrt{t}$ with equal probability. A numerical
implementation of our technique and experiments on a large face images dataset
verify the speed and the accuracy of our theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4644</identifier>
 <datestamp>2012-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4644</id><created>2010-11-21</created><updated>2011-04-30</updated><authors><author><keyname>Choi</keyname><forenames>David S.</forenames></author><author><keyname>Wolfe</keyname><forenames>Patrick J.</forenames></author><author><keyname>Airoldi</keyname><forenames>Edoardo M.</forenames></author></authors><title>Stochastic blockmodels with growing number of classes</title><categories>math.ST cs.SI stat.ME stat.ML stat.TH</categories><comments>12 pages, 3 figures; revised version</comments><journal-ref>Biometrika, 99:273--284, 2012</journal-ref><doi>10.1093/biomet/asr053</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present asymptotic and finite-sample results on the use of stochastic
blockmodels for the analysis of network data. We show that the fraction of
misclassified network nodes converges in probability to zero under maximum
likelihood fitting when the number of classes is allowed to grow as the root of
the network size and the average network degree grows at least
poly-logarithmically in this size. We also establish finite-sample confidence
bounds on maximum-likelihood blockmodel parameter estimates from data
comprising independent Bernoulli random variates; these results hold uniformly
over class assignment. We provide simulations verifying the conditions
sufficient for our results, and conclude by fitting a logit parameterization of
a stochastic blockmodel with covariates to a network data example comprising a
collection of Facebook profiles, resulting in block estimates that reveal
residual structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4654</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4654</id><created>2010-11-21</created><updated>2010-11-26</updated><authors><author><keyname>Barcelo</keyname><forenames>Jaume</forenames></author><author><keyname>Bellalta</keyname><forenames>Boris</forenames></author><author><keyname>Cano</keyname><forenames>Cristina</forenames></author><author><keyname>Sfairopoulou</keyname><forenames>Anna</forenames></author><author><keyname>Oliver</keyname><forenames>Miquel</forenames></author><author><keyname>Verma</keyname><forenames>Kshitiz</forenames></author></authors><title>Towards a Collision-Free WLAN: Dynamic Parameter Adjustment in CSMA/E2CA</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Carrier Sense Multiple Access with Enhanced Collision Avoidance (CSMA/ECA) is
a distributed MAC protocol that allows collision-free access to the medium in
WLAN. The only difference between CSMA/ECA and the well-known CSMA/CA is that
the former uses a deterministic backoff after successful transmissions.
Collision-free operation is reached after a transient state during which some
collisions may occur. This article shows that the duration of the transient
state can be shortened by appropriately setting the contention parameters.
Standard absorbing Markov Chain theory can be used to describe the behaviour of
the system in the transient state and to predict the expected number of slots
to reach the collision-free operation.
  The article also introduces CSMA/E2CA, in which a deterministic backoff is
used two consecutive times after a successful transmission. CSMA/E2CA converges
quicker to collision-free operation and delivers higher performance than
CSMA/CA in harsh wireless scenarios with high frame error rates.
  To achieve collision-free operations when the number of contenders is large,
it may be necessary to dynamically adjust the contention parameter. The last
part of the article suggests an approach for such parameter adjustment which is
validated by simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4675</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4675</id><created>2010-11-21</created><authors><author><keyname>Demongeot</keyname><forenames>Jacques</forenames></author><author><keyname>Sen&#xe9;</keyname><forenames>Sylvain</forenames></author></authors><title>Nonlinear threshold Boolean automata networks and phase transitions</title><categories>cs.DM math.DS nlin.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report, we present a formal approach that addresses the problem of
emergence of phase transitions in stochastic and attractive nonlinear threshold
Boolean automata networks. Nonlinear networks considered are informally defined
on the basis of classical stochastic threshold Boolean automata networks in
which specific interaction potentials of neighbourhood coalition are taken into
account. More precisely, specific nonlinear terms compose local transition
functions that define locally the dynamics of such networks. Basing our study
on nonlinear networks, we exhibit new results, from which we derive conditions
of phase transitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4682</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4682</id><created>2010-11-21</created><authors><author><keyname>Roli</keyname><forenames>Andrea</forenames></author><author><keyname>Benedettini</keyname><forenames>Stefano</forenames></author><author><keyname>Serra</keyname><forenames>Roberto</forenames></author><author><keyname>Villani</keyname><forenames>Marco</forenames></author></authors><title>Analysis of attractor distances in Random Boolean Networks</title><categories>cs.NE nlin.CD physics.bio-ph q-bio.QM</categories><comments>9 pages, 6 figures. Presented at WIRN 2010 - Italian workshop on
  neural networks, May 2010. To appear in a volume published by IOS Press</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the properties of the distance between attractors in Random Boolean
Networks, a prominent model of genetic regulatory networks. We define three
distance measures, upon which attractor distance matrices are constructed and
their main statistic parameters are computed. The experimental analysis shows
that ordered networks have a very clustered set of attractors, while chaotic
networks' attractors are scattered; critical networks show, instead, a pattern
with characteristics of both ordered and chaotic networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4686</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4686</id><created>2010-11-21</created><authors><author><keyname>Gon&#xe7;alves</keyname><forenames>Carlos Pedro</forenames></author></authors><title>Chaos in Binary Category Computation</title><categories>math.CT cs.CC nlin.CD</categories><msc-class>18A15, 34C28, 03D15, 03D32</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Category computation theory deals with a web-based systemic processing that
underlies the morphic webs, which constitute the basis of categorial logical
calculus. It is proven that, for these structures, algorithmically
incompressible binary patterns can be morphically compressed, with respect to
the local connectivities, in a binary morphic program. From the local
connectivites, there emerges a global morphic connection that can be
characterized by a low length binary string, leading to the identification of
chaotic categorial dynamics, underlying the algorithmically random pattern. The
work focuses on infinite binary chains of C2, which is a category that
implements an X-OR-based categorial logical calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4718</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4718</id><created>2010-11-21</created><authors><author><keyname>Carreiro</keyname><forenames>Facundo</forenames></author></authors><title>Characterization and definability in modal first-order fragments</title><categories>cs.LO math.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Model theoretic results such as Characterization and Definability give
important information about different logics. It is well known that the proofs
of those results for several modal logics have, somehow, the same 'taste'. A
general proof for most modal logics below first order is still too ambitious.
In this thesis we plan to isolate sufficient conditions for the
characterization and definability theorems to hold in a wide range of logics.
Along with these conditions we will prove that, whichever logic that meets
them, satisfies both theorems. Therefore, one could give an unifying proof for
logics with already known results. Moreover, one will be able to prove
characterization and definability results for logics that have not yet been
investigated. In both cases, it is only needed to check that a logic meets the
requirements to automatically derive the desired results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4725</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4725</id><created>2010-11-21</created><authors><author><keyname>Timo</keyname><forenames>Roy</forenames></author><author><keyname>Grant</keyname><forenames>Alex</forenames></author><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author></authors><title>Lossy Broadcasting in Two-Way Relay Networks with Common Reconstructions</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The broadcast phase (downlink transmission) of the two-way relay network is
studied in the source coding and joint source-channel coding settings. The
rates needed for reliable communication are characterised for a number of
special cases including: small distortions, deterministic distortion measures,
and jointly Gaussian sources with quadratic distortion measures. The broadcast
problem is also studied with common-reconstruction decoding constraints, and
the rates needed for reliable communication are characterised for all discrete
memoryless sources and per-letter distortion measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4744</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4744</id><created>2010-11-22</created><authors><author><keyname>Richoux</keyname><forenames>Florian</forenames></author></authors><title>Complexity of Homogeneous Co-Boolean Constraint Satisfaction Problems</title><categories>cs.CC</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constraint Satisfaction Problems (CSP) constitute a convenient way to capture
many combinatorial problems. The general CSP is known to be NP-complete, but
its complexity depends on a template, usually a set of relations, upon which
they are constructed. Following this template, there exist tractable and
intractable instances of CSPs. It has been proved that for each CSP problem
over a given set of relations there exists a corresponding CSP problem over
graphs of unary functions belonging to the same complexity class. In this short
note we show a dichotomy theorem for every finite domain D of CSP built upon
graphs of homogeneous co-Boolean functions, i.e., unary functions sharing the
Boolean range {0, 1}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4748</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4748</id><created>2010-11-22</created><authors><author><keyname>Gai</keyname><forenames>Yi</forenames></author><author><keyname>Krishnamachari</keyname><forenames>Bhaskar</forenames></author><author><keyname>Jain</keyname><forenames>Rahul</forenames></author></authors><title>Combinatorial Network Optimization with Unknown Variables: Multi-Armed
  Bandits with Linear Rewards</title><categories>math.OC cs.LG cs.NI math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the classic multi-armed bandits problem, the goal is to have a policy for
dynamically operating arms that each yield stochastic rewards with unknown
means. The key metric of interest is regret, defined as the gap between the
expected total reward accumulated by an omniscient player that knows the reward
means for each arm, and the expected total reward accumulated by the given
policy. The policies presented in prior work have storage, computation and
regret all growing linearly with the number of arms, which is not scalable when
the number of arms is large. We consider in this work a broad class of
multi-armed bandits with dependent arms that yield rewards as a linear
combination of a set of unknown parameters. For this general framework, we
present efficient policies that are shown to achieve regret that grows
logarithmically with time, and polynomially in the number of unknown parameters
(even though the number of dependent arms may grow exponentially). Furthermore,
these policies only require storage that grows linearly in the number of
unknown parameters. We show that this generalization is broadly applicable and
useful for many interesting tasks in networks that can be formulated as
tractable combinatorial optimization problems with linear objective functions,
such as maximum weight matching, shortest path, and minimum spanning tree
computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4752</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4752</id><created>2010-11-22</created><authors><author><keyname>Dai</keyname><forenames>Wenhan</forenames></author><author><keyname>Gai</keyname><forenames>Yi</forenames></author><author><keyname>Krishnamachari</keyname><forenames>Bhaskar</forenames></author><author><keyname>Zhao</keyname><forenames>Qing</forenames></author></authors><title>The Non-Bayesian Restless Multi-Armed Bandit: a Case of Near-Logarithmic
  Regret</title><categories>math.OC cs.LG cs.NI math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the classic Bayesian restless multi-armed bandit (RMAB) problem, there are
$N$ arms, with rewards on all arms evolving at each time as Markov chains with
known parameters. A player seeks to activate $K \geq 1$ arms at each time in
order to maximize the expected total reward obtained over multiple plays. RMAB
is a challenging problem that is known to be PSPACE-hard in general. We
consider in this work the even harder non-Bayesian RMAB, in which the
parameters of the Markov chain are assumed to be unknown \emph{a priori}. We
develop an original approach to this problem that is applicable when the
corresponding Bayesian problem has the structure that, depending on the known
parameter values, the optimal solution is one of a prescribed finite set of
policies. In such settings, we propose to learn the optimal policy for the
non-Bayesian RMAB by employing a suitable meta-policy which treats each policy
from this finite set as an arm in a different non-Bayesian multi-armed bandit
problem for which a single-arm selection policy is optimal. We demonstrate this
approach by developing a novel sensing policy for opportunistic spectrum access
over unknown dynamic channels. We prove that our policy achieves
near-logarithmic regret (the difference in expected reward compared to a
model-aware genie), which leads to the same average reward that can be achieved
by the optimal policy under a known model. This is the first such result in the
literature for a non-Bayesian RMAB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4757</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4757</id><created>2010-11-22</created><updated>2011-01-11</updated><authors><author><keyname>Bodirsky</keyname><forenames>Manuel</forenames></author><author><keyname>Hermann</keyname><forenames>Miki</forenames></author><author><keyname>Richoux</keyname><forenames>Florian</forenames></author></authors><title>Complexity of Existential Positive First-Order Logic</title><categories>cs.CC cs.LO</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let gamma be a (not necessarily finite) structure with a finite relational
signature. We prove that deciding whether a given existential positive sentence
holds in gamma is in Logspace or complete for the class CSP(gamma)_NP under
deterministic polynomial-time many-one reductions. Here, CSP(gamma)_NP is the
class of problems that can be reduced to the Constraint Satisfaction Problem of
gamma under non-deterministic polynomial-time many-one reductions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4792</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4792</id><created>2010-11-22</created><authors><author><keyname>Yoon</keyname><forenames>Seokhyun</forenames></author><author><keyname>Heo</keyname><forenames>Jun</forenames></author></authors><title>Pair-wise Markov Random Fields Applied to the Design of Low Complexity
  MIMO Detectors</title><categories>cs.IT math.IT</categories><comments>32 pages, 10 figures Has been submitted to IEEE transactions on
  Information theory and, partially, to ICC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pair-wise Markov random fields (MRF) are considered for application to the
development of low complexity, iterative MIMO detection. Specifically, we
consider two types of MRF, namely, the fully-connected and ring-type. For the
edge potentials, we use the bivariate Gaussian function obtained by
marginalizing the posterior joint probability density under the Gaussian
assumption. Since the corresponding factor graphs are sparse, in the sense that
the number of edges connected to a factor node (edge degree) is only 2, the
computations are much easier than that of ML, which is similar to the belief
propagation (BP), or sum-product, algorithm that is run over the fully
connected factor graph. The BER performances for non-Gaussian input are
evaluated via simulation, and the results show the validity of the proposed
algorithms. We also customize the algorithm for Gaussian input to obtain the
Gaussian BP that is run over the two MRF and proves its convergence in mean to
the linear MMSE estimates. The result lies on the same line of those in [16]
and [24], but with differences in its graphical model and the message passing
rule. Since the MAP estimator for the Gaussian input is equivalent to the
linear MMSE estimator, it shows the optimality, in mean, of the scheme for
Gaussian input.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4810</identifier>
 <datestamp>2011-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4810</id><created>2010-11-22</created><updated>2011-03-22</updated><authors><author><keyname>Ladics</keyname><forenames>Tam&#xe1;s</forenames></author></authors><title>Application of Operator Splitting to Solve Reaction Diffusion Equations</title><categories>math.NA cs.NA</categories><comments>26 pages, 9 figures</comments><msc-class>65M99, 92D25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Approximate solutions of the Fisher equation obtained by different splitting
methods are investigated. The error of this nonlinear problem is analyzed. The
order of different splitting methods coupled with numerical methods of
different order is calculated numerically and symbolically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4829</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4829</id><created>2010-11-22</created><updated>2010-11-22</updated><authors><author><keyname>Liu</keyname><forenames>Guangcan</forenames></author><author><keyname>Sun</keyname><forenames>Ju</forenames></author><author><keyname>Yan</keyname><forenames>Shuicheng</forenames></author></authors><title>Closed-Form Solutions to A Category of Nuclear Norm Minimization
  Problems</title><categories>cs.IT cs.CV math.IT</categories><journal-ref>NIPS Workshop on Low-Rank Methods for Large-Scale Machine
  Learning, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is an efficient and effective strategy to utilize the nuclear norm
approximation to learn low-rank matrices, which arise frequently in machine
learning and computer vision. So the exploration of nuclear norm minimization
problems is gaining much attention recently. In this paper we shall prove that
the following Low-Rank Representation (LRR) \cite{icml_2010_lrr,lrr_extention}
problem: {eqnarray*} \min_{Z} \norm{Z}_*, &amp; {s.t.,} &amp; X=AZ, {eqnarray*} has a
unique and closed-form solution, where $X$ and $A$ are given matrices. The
proof is based on proving a lemma that allows us to get closed-form solutions
to a category of nuclear norm minimization problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4833</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4833</id><created>2010-11-22</created><authors><author><keyname>Cabalar</keyname><forenames>Pedro</forenames></author></authors><title>A Logical Charaterisation of Ordered Disjunction</title><categories>cs.LO cs.AI</categories><comments>ASPOCP 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider a logical treatment for the ordered disjunction
operator 'x' introduced by Brewka, Niemel\&quot;a and Syrj\&quot;anen in their Logic
Programs with Ordered Disjunctions (LPOD). LPODs are used to represent
preferences in logic programming under the answer set semantics. Their
semantics is defined by first translating the LPOD into a set of normal
programs (called split programs) and then imposing a preference relation among
the answer sets of these split programs. We concentrate on the first step and
show how a suitable translation of the ordered disjunction as a derived
operator into the logic of Here-and-There allows capturing the answer sets of
the split programs in a direct way. We use this characterisation not only for
providing an alternative implementation for LPODs, but also for checking
several properties (under strongly equivalent transformations) of the 'x'
operator, like for instance, its distributivity with respect to conjunction or
regular disjunction. We also make a comparison to an extension proposed by
K\&quot;arger, Lopes, Olmedilla and Polleres, that combines 'x' with regular
disjunction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4859</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4859</id><created>2010-11-22</created><updated>2011-04-04</updated><authors><author><keyname>Onnela</keyname><forenames>Jukka-Pekka</forenames></author><author><keyname>Arbesman</keyname><forenames>Samuel</forenames></author><author><keyname>Gonz&#xe1;lez</keyname><forenames>Marta C.</forenames></author><author><keyname>Barab&#xe1;si</keyname><forenames>Albert-L&#xe1;szl&#xf3;</forenames></author><author><keyname>Christakis</keyname><forenames>Nicholas A.</forenames></author></authors><title>Geographic constraints on social network groups</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI</categories><comments>10 pages, 5 figures</comments><doi>10.1371/journal.pone.0016939</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social groups are fundamental building blocks of human societies. While our
social interactions have always been constrained by geography, it has been
impossible, due to practical difficulties, to evaluate the nature of this
restriction on social group structure. We construct a social network of
individuals whose most frequent geographical locations are also known. We also
classify the individuals into groups according to a community detection
algorithm. We study the variation of geographical span for social groups of
varying sizes, and explore the relationship between topological positions and
geographic positions of their members. We find that small social groups are
geographically very tight, but become much more clumped when the group size
exceeds about 30 members. Also, we find no correlation between the topological
positions and geographic positions of individuals within network communities.
These results suggest that spreading processes face distinct structural and
spatial constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4879</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4879</id><created>2010-11-22</created><authors><author><keyname>Abbas</keyname><forenames>Ash Mohammad</forenames></author></authors><title>Analysis of Generalized Impact Factor and Indices of Journals</title><categories>cs.DL</categories><comments>7 pages, 5 figures, 3 tables</comments><msc-class>68M20</msc-class><acm-class>H.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analyzing the relationships among the parameters for quantifying the quality
of research published in journals is a challenging task. In this paper, we
analyze the relationships between impact factor, h-index, and g-index of a
journal. To keep our analysis simple and easy to understand, we consider a
generalized version of the impact factor where there is no time window. In the
absence of the time window, the impact factor converges to the number of
citations received per paper. This is not only justified for the impact factor,
it simplifies the analysis of h-index and g-index as well because addition of a
time window in the form of years complicates the computation of indices too. We
derive the expressions for the relationships among impact factor, h-index, and
g-index and validate them using a given set of publication-citation data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4910</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4910</id><created>2010-11-22</created><authors><author><keyname>Bajovic</keyname><forenames>Dragana</forenames></author><author><keyname>Sinopoli</keyname><forenames>Bruno</forenames></author><author><keyname>Xavier</keyname><forenames>Joao</forenames></author></authors><title>Sensor Selection for Event Detection in Wireless Sensor Networks</title><categories>cs.IT math.IT stat.AP</categories><comments>30 pages, journal, submitted</comments><doi>10.1109/TSP.2011.2160630</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of sensor selection for event detection in wireless
sensor networks (WSNs). We want to choose a subset of p out of n sensors that
yields the best detection performance. As the sensor selection optimality
criteria, we propose the Kullback-Leibler and Chernoff distances between the
distributions of the selected measurements under the two hypothesis. We
formulate the maxmin robust sensor selection problem to cope with the
uncertainties in distribution means. We prove that the sensor selection problem
is NP hard, for both Kullback-Leibler and Chernoff criteria. To (sub)optimally
solve the sensor selection problem, we propose an algorithm of affordable
complexity. Extensive numerical simulations on moderate size problem instances
(when the optimum by exhaustive search is feasible to compute) demonstrate the
algorithm's near optimality in a very large portion of problem instances. For
larger problems, extensive simulations demonstrate that our algorithm
outperforms random searches, once an upper bound on computational time is set.
We corroborate numerically the validity of the Kullback-Leibler and Chernoff
sensor selection criteria, by showing that they lead to sensor selections
nearly optimal both in the Neyman-Pearson and Bayes sense.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4935</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4935</id><created>2010-11-22</created><authors><author><keyname>Sherstov</keyname><forenames>Alexander A.</forenames></author></authors><title>Strong direct product theorems for quantum communication and query
  complexity</title><categories>cs.CC quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A strong direct product theorem (SDPT) states that solving n instances of a
problem requires Omega(n) times the resources for a single instance, even to
achieve success probability exp(-Omega(n)). We prove that quantum communication
complexity obeys an SDPT whenever the communication lower bound for a single
instance is proved by the generalized discrepancy method, the strongest
technique in that model. We prove that quantum query complexity obeys an SDPT
whenever the query lower bound for a single instance is proved by the
polynomial method, one of the two main techniques in that model. In both
models, we prove the corresponding XOR lemmas and threshold direct product
theorems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4955</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4955</id><created>2010-11-22</created><authors><author><keyname>Arthur</keyname><forenames>David</forenames></author><author><keyname>Oudot</keyname><forenames>Steve Y.</forenames></author></authors><title>Reverse Nearest Neighbors Search in High Dimensions using
  Locality-Sensitive Hashing</title><categories>cs.CG cs.DS</categories><report-no>INRIA RR-7084</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the problem of finding reverse nearest neighbors efficiently.
Although provably good solutions exist for this problem in low or fixed
dimensions, to this date the methods proposed in high dimensions are mostly
heuristic. We introduce a method that is both provably correct and efficient in
all dimensions, based on a reduction of the problem to one instance of
$\e$-nearest neighbor search plus a controlled number of instances of {\em
exhaustive $r$-\pleb}, a variant of {\em Point Location among Equal Balls}
where all the $r$-balls centered at the data points that contain the query
point are sought for, not just one. The former problem has been extensively
studied and elegantly solved in high dimensions using Locality-Sensitive
Hashing (LSH) techniques. By contrast, the latter problem has a complexity that
is still not fully understood. We revisit the analysis of the LSH scheme for
exhaustive $r$-\pleb using a somewhat refined notion of locality-sensitive
family of hash function, which brings out a meaningful output-sensitive term in
the complexity of the problem. Our analysis, combined with a non-isometric
lifting of the data, enables us to answer exhaustive $r$-\pleb queries (and
down the road reverse nearest neighbors queries) efficiently. Along the way, we
obtain a simple algorithm for answering exact nearest neighbor queries, whose
complexity is parametrized by some {\em condition number} measuring the
inherent difficulty of a given instance of the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4957</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4957</id><created>2010-11-22</created><authors><author><keyname>Verschae</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Wiese</keyname><forenames>Andreas</forenames></author></authors><title>On the Configuration-LP for Scheduling on Unrelated Machines</title><categories>cs.DM cs.DS</categories><comments>12 pages, 1 figure</comments><report-no>Report-no: 025-2010</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most important open problems in machine scheduling is the problem
of scheduling a set of jobs on unrelated machines to minimize the makespan. The
best known approximation algorithm for this problem guarantees an approximation
factor of 2. It is known to be NP-hard to approximate with a better ratio than
3/2. Closing this gap has been open for over 20 years. The best known
approximation factors are achieved by LP-based algorithms. The strongest known
linear program formulation for the problem is the configuration-LP. We show
that the configuration-LP has an integrality gap of 2 even for the special case
of unrelated graph balancing, where each job can be assigned to at most two
machines. In particular, our result implies that a large family of cuts does
not help to diminish the integrality gap of the canonical assignment-LP. Also,
we present cases of the problem which can be approximated with a better factor
than 2. They constitute valuable insights for constructing an NP-hardness
reduction which improves the known lower bound. Very recently Svensson studied
the restricted assignment case, where each job can only be assigned to a given
set of machines on which it has the same processing time. He shows that in this
setting the configuration-LP has an integrality gap of 33/17&lt;2. Hence, our
result imply that the unrelated graph balancing case is significantly more
complex than the restricted assignment case. Then we turn to another objective
function: maximizing the minimum machine load. For the case that every job can
be assigned to at most two machines we give a purely combinatorial
2-approximation algorithm which is best possible, unless P=NP. This improves on
the computationally costly LP-based (2+eps)-approximation algorithm by
Chakrabarty et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4969</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4969</id><created>2010-11-22</created><updated>2011-12-25</updated><authors><author><keyname>Liu</keyname><forenames>Haoyang</forenames></author><author><keyname>Liu</keyname><forenames>Keqin</forenames></author><author><keyname>Zhao</keyname><forenames>Qing</forenames></author></authors><title>Learning in A Changing World: Restless Multi-Armed Bandit with Unknown
  Dynamics</title><categories>math.OC cs.LG math.PR</categories><comments>33 pages, 5 figures, submitted to IEEE Transactions on Information
  Theory, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the restless multi-armed bandit (RMAB) problem with unknown
dynamics in which a player chooses M out of N arms to play at each time. The
reward state of each arm transits according to an unknown Markovian rule when
it is played and evolves according to an arbitrary unknown random process when
it is passive. The performance of an arm selection policy is measured by
regret, defined as the reward loss with respect to the case where the player
knows which M arms are the most rewarding and always plays the M best arms. We
construct a policy with an interleaving exploration and exploitation epoch
structure that achieves a regret with logarithmic order when arbitrary (but
nontrivial) bounds on certain system parameters are known. When no knowledge
about the system is available, we show that the proposed policy achieves a
regret arbitrarily close to the logarithmic order. We further extend the
problem to a decentralized setting where multiple distributed players share the
arms without information exchange. Under both an exogenous restless model and
an endogenous restless model, we show that a decentralized extension of the
proposed policy preserves the logarithmic regret order as in the centralized
setting. The results apply to adaptive learning in various dynamic systems and
communication networks, as well as financial investment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.4974</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.4974</id><created>2010-11-22</created><authors><author><keyname>Kritchman</keyname><forenames>Shira</forenames></author><author><keyname>Raz</keyname><forenames>Ran</forenames></author></authors><title>The Surprise Examination Paradox and the Second Incompleteness Theorem</title><categories>math.LO cs.CC cs.LO</categories><comments>8 pages</comments><journal-ref>Notices of the AMS volume 57 number 11 (December 2010), published
  by the American Mathematical Society</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new proof for Godel's second incompleteness theorem, based on
Kolmogorov complexity, Chaitin's incompleteness theorem, and an argument that
resembles the surprise examination paradox. We then go the other way around and
suggest that the second incompleteness theorem gives a possible resolution of
the surprise examination paradox. Roughly speaking, we argue that the flaw in
the derivation of the paradox is that it contains a hidden assumption that one
can prove the consistency of the mathematical theory in which the derivation is
done; which is impossible by the second incompleteness theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5015</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5015</id><created>2010-11-23</created><updated>2010-11-24</updated><authors><author><keyname>Xu</keyname><forenames>Ke</forenames></author><author><keyname>Liu</keyname><forenames>Hongying</forenames></author><author><keyname>Liu</keyname><forenames>Jiangchuan</forenames></author><author><keyname>Shen</keyname><forenames>Meng</forenames></author></authors><title>One More Weight is Enough: Toward the Optimal Traffic Engineering with
  OSPF</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traffic Engineering (TE) leverages information of network traffic to generate
a routing scheme optimizing the traffic distribution so as to advance network
performance. However, optimize the link weights for OSPF to the offered traffic
is an known NP-hard problem. In this paper, motivated by the fairness concept
of congestion control, we firstly propose a new generic objective function,
where various interests of providers can be extracted with different parameter
settings. And then, we model the optimal TE as the utility maximization of
multi-commodity flows with the generic objective function and theoretically
show that any given set of optimal routes corresponding to a particular
objective function can be converted to shortest paths with respect to a set of
positive link weights. This can be directly configured on OSPF-based protocols.
On these bases, we employ the Network Entropy Maximization(NEM) framework and
develop a new OSPF-based routing protocol, SPEF, to realize a flexible way to
split traffic over shortest paths in a distributed fashion. Actually, comparing
to OSPF, SPEF only needs one more weight for each link and provably achieves
optimal TE. Numerical experiments have been done to compare SPEF with the
current version of OSPF, showing the effectiveness of SPEF in terms of link
utilization and network load distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5021</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5021</id><created>2010-11-23</created><authors><author><keyname>Meghanathan</keyname><forenames>Natarajan</forenames></author></authors><title>Performance Comparison of Link, Node and Zone Disjoint Multi-path
  Routing Strategies and Minimum Hop Single Path Routing for Mobile Ad Hoc
  Networks</title><categories>cs.NI</categories><comments>17 pages</comments><doi>10.5121/ijwmn.2010.2402</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The high-level contribution of this paper is a simulation-based analysis to
evaluate the tradeoffs between lifetime and hop count of link-disjoint,
node-disjoint and zone-disjoint multi-path routes vis-\`a-vis single-path
minimum hop routes for mobile ad hoc networks. The link-disjoint, node-disjoint
and zone-disjoint algorithms proposed in this paper can be used to arrive at
benchmarks for the time between successive multi-path route discoveries, the
number of disjoint paths per multi-path set and the hop count per multi-path
set. We assume a multi-path set exists as long as at least one path in the set
exists. Simulation results indicate that the number of zone-disjoint paths per
multi-path set can be at most 2, which is far lower than the number of node and
link-disjoint paths available per multi-path set. Also, the time between
zone-disjoint multi-path discoveries would be far lower than the time between
node and link-disjoint multi-path route discoveries and can be at most 45% more
than the time between single minimum-hop path route discoveries. However, there
is no appreciable difference in the average hop counts per zone-disjoint,
node-disjoint and link-disjoint multi-path sets and it can be only at most 15%
more than the average minimum hop count determined using single-path routing.
We also observe that even though the number of link-disjoint paths per
multi-path set can be as large as 35-78% more than the number of node-disjoint
paths per multi-path set, the time between two successive link-disjoint
multi-path discoveries can be at most 15-25% more than the time between two
successive node-disjoint multi-path discoveries, without any significant
difference in the hop count per multi-path set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5039</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5039</id><created>2010-11-23</created><updated>2012-02-09</updated><authors><author><keyname>Ostrowski</keyname><forenames>Marcin</forenames></author></authors><title>Information and Interpretation of Quantum Mechanics</title><categories>quant-ph cs.IT math.IT</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work is a discussion on the concept of information. We define here
information as an abstraction that is able to be copied. We consider the
connection between the process of copying information in quantum systems and
the emergence of the so-called classical realism. The problem of interpretation
of quantum mechanics in this context is discussed as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5053</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5053</id><created>2010-11-23</created><updated>2012-04-05</updated><authors><author><keyname>Sabato</keyname><forenames>Sivan</forenames></author><author><keyname>Srebro</keyname><forenames>Nathan</forenames></author><author><keyname>Tishby</keyname><forenames>Naftali</forenames></author></authors><title>Tight Sample Complexity of Large-Margin Learning</title><categories>cs.LG math.PR math.ST stat.ML stat.TH</categories><comments>Appearing in Neural Information Processing Systems (NIPS) 2010; This
  is the full version, including appendix with proofs; Also with some
  corrections</comments><journal-ref>Advances in Neural Information Processing Systems 23 (NIPS),
  2038-2046, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We obtain a tight distribution-specific characterization of the sample
complexity of large-margin classification with L_2 regularization: We introduce
the \gamma-adapted-dimension, which is a simple function of the spectrum of a
distribution's covariance matrix, and show distribution-specific upper and
lower bounds on the sample complexity, both governed by the
\gamma-adapted-dimension of the source distribution. We conclude that this new
quantity tightly characterizes the true sample complexity of large-margin
classification. The bounds hold for a rich family of sub-Gaussian
distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5064</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5064</id><created>2010-11-23</created><authors><author><keyname>Bellur</keyname><forenames>Umesh</forenames></author><author><keyname>Rao</keyname><forenames>Chetan S</forenames></author><author><keyname>SD</keyname><forenames>Madhu Kumar</forenames></author></authors><title>Optimal Placement Algorithms for Virtual Machines</title><categories>cs.DC</categories><acm-class>C.2.4; G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing provides a computing platform for the users to meet their
demands in an efficient, cost-effective way. Virtualization technologies are
used in the clouds to aid the efficient usage of hardware. Virtual machines
(VMs) are utilized to satisfy the user needs and are placed on physical
machines (PMs) of the cloud for effective usage of hardware resources and
electricity in the cloud. Optimizing the number of PMs used helps in cutting
down the power consumption by a substantial amount.
  In this paper, we present an optimal technique to map virtual machines to
physical machines (nodes) such that the number of required nodes is minimized.
We provide two approaches based on linear programming and quadratic programming
techniques that significantly improve over the existing theoretical bounds and
efficiently solve the problem of virtual machine (VM) placement in data
centers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5065</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5065</id><created>2010-11-23</created><authors><author><keyname>Chang</keyname><forenames>Woohyuk</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author><author><keyname>Lee</keyname><forenames>Yong H.</forenames></author></authors><title>Gaussian Relay Channel Capacity to Within a Fixed Number of Bits</title><categories>cs.IT math.IT</categories><comments>6 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show that the capacity of the three-node Gaussian relay
channel can be achieved to within 1 and 2 bit/sec/Hz using compress-and-forward
and amplify-and-forward relaying, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5072</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5072</id><created>2010-11-23</created><authors><author><keyname>Asim</keyname><forenames>Muhammad</forenames></author><author><keyname>Mokhtar</keyname><forenames>Hala</forenames></author><author><keyname>Merabti</keyname><forenames>Madjid</forenames></author></authors><title>A self-managing fault management mechanism for wireless sensor networks</title><categories>cs.NI</categories><comments>14 pages, 5 figures, Journal</comments><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.2,
  No.4, November 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A sensor network can be described as a collection of sensor nodes which
co-ordinate with each other to perform some specific function. These sensor
nodes are mainly in large numbers and are densely deployed either inside the
phenomenon or very close to it. They can be used for various application areas
(e.g. health, military, home). Failures are inevitable in wireless sensor
networks due to inhospitable environment and unattended deployment. Therefore,
it is necessary that network failures are detected in advance and appropriate
measures are taken to sustain network operation. We previously proposed a
cellular approach for fault detection and recovery. In this paper we extend the
cellular approach and propose a new fault management mechanism to deal with
fault detection and recovery. We propose a hierarchical structure to properly
distribute fault management tasks among sensor nodes by introducing more
'self-managing' functions. The proposed failure detection and recovery
algorithm has been compared with some existing related work and proven to be
more energy efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5076</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5076</id><created>2010-11-23</created><authors><author><keyname>Rovenchak</keyname><forenames>Andrij</forenames></author><author><keyname>Buk</keyname><forenames>Solomija</forenames></author></authors><title>Application of a Quantum Ensemble Model to Linguistic Analysis</title><categories>physics.data-an cs.CL</categories><comments>13 pages; 4 figures; 1 table</comments><journal-ref>Physica A, Volume 390, Issue 7, Pages 1326-1331 (2011)</journal-ref><doi>10.1016/j.physa.2010.12.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new set of parameters to describe the word frequency behavior of texts is
proposed. The analogy between the word frequency distribution and the
Bose-distribution is suggested and the notion of &quot;temperature&quot; is introduced
for this case. The calculations are made for English, Ukrainian, and the
Guinean Maninka languages. The correlation between in-deep language structure
(the level of analyticity) and the defined parameters is shown to exist.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5105</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5105</id><created>2010-11-23</created><updated>2011-03-18</updated><authors><author><keyname>Maluszynski</keyname><forenames>Jan</forenames></author><author><keyname>Szalas</keyname><forenames>Andrzej</forenames></author></authors><title>Logical Foundations and Complexity of 4QL, a Query Language with
  Unrestricted Negation</title><categories>cs.LO cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper discusses properties of a DATALOG$^{\neg\neg}$-like query language
4QL, originally outlined in [MS10]. Negated literals in heads of rules
naturally lead to inconsistencies. On the other hand, rules do not have to
attach meaning to some literals. Therefore 4QL is founded on a four-valued
semantics, employing the logic introduced in [MSV08, VMS09] with truth values:
'true', 'false', 'inconsistent' and 'unknown'. 4QL allows one to use rules with
negation in heads and bodies of rules, it is based on a simple and intuitive
semantics and provides uniform tools for &quot;lightweight&quot; versions of known forms
of nonmonotonic reasoning. In addition, 4QL is tractable as regards its data
complexity and captures PTIME queries. Even if DATALOG$^{\neg\neg}$ is known as
a concept for the last 30 years, to our best knowledge no existing approach
enjoys these properties.
  In the current paper we: - investigate properties of well-supported models of
4QL - prove the correctness of the algorithm for computing well-supported
models - show that 4QL has PTIME data complexity and captures PTIME.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5113</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5113</id><created>2010-11-23</created><authors><author><keyname>Khodaian</keyname><forenames>Amir Mahdy</forenames></author><author><keyname>Khalaj</keyname><forenames>Babak H.</forenames></author></authors><title>State-Based Random Access: A Cross-Layer Approach</title><categories>cs.IT cs.NI math.IT</categories><comments>submitted icc2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose novel state-based algorithms which dynamically
control the random access network based on its current state such as channel
states of wireless links and backlog states of the queues. After formulating
the problem, corresponding algorithms with diverse control functions are
proposed. Consequently, it will be shown that the proposed state-based schemes
for control of the random access networks, results in significant performance
gains in comparison with previously proposed control algorithms. In order to
select an appropriate control function, performances of the state-based control
algorithms are compared for a wide range of traffic scenarios. It is also shown
that even an approximate knowledge of network statistics helps in selecting the
proper state dependent control function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5115</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5115</id><created>2010-11-23</created><authors><author><keyname>Khodaian</keyname><forenames>Amir Mahdi</forenames></author><author><keyname>Khalaj</keyname><forenames>Babak H.</forenames></author><author><keyname>Shah-mansouri</keyname><forenames>Hamed</forenames></author></authors><title>Optimal Utility-Energy tradeoff in Delay Constrained Random Access
  Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>5 pages, icc009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rate, energy and delay are three main parameters of interest in ad-hoc
networks. In this paper, we discuss the problem of maximizing network utility
and minimizing energy consumption while satisfying a given transmission delay
constraint for each packet. We formulate this problem in the standard convex
optimization form and subsequently discuss the tradeoff between utility, energy
and delay in such framework. Also, in order to adapt for the distributed nature
of the network, a distributed algorithm where nodes decide on choosing
transmission rates and probabilities based on their local information is
introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5117</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5117</id><created>2010-11-23</created><authors><author><keyname>Khodaian</keyname><forenames>Amirmahdi</forenames></author><author><keyname>Khalaj</keyname><forenames>Babak H.</forenames></author></authors><title>Energy and Utility Optimization in Wireless Networks with Random Access</title><categories>cs.IT math.IT</categories><comments>6 pages, icc07</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy consumption is a main issue of concern in wireless networks. Energy
minimization increases the time that networks' nodes work properly without
recharging or substituting batteries. Another criterion for network performance
is data transmission rate which is usually quantified by a network utility
function. There exists an inherent tradeoff between these criteria and
enhancing one of them can deteriorate the other one. In this paper, we consider
both Network Utility Maximization (NUM) and energy minimization in a
bi-criterion optimization problem. The problem is formulated for Random Access
(RA) Medium Access Control (MAC) for ad-hoc networks. First, we optimize
performance of the MAC and define utility as a monotonically increasing
function of link throughputs. We investigate the optimal tradeoff between
energy and utility in this part. In the second part, we define utility as a
function of end to end rates and optimize MAC and transport layers
simultaneously. We calculate optimal persistence probabilities and end-to-end
rates. Finally, by means of duality theorem, we decompose the problem into
smaller subproblems, which are solved at node and network layers separately.
This decomposition avoids need for a central unit while sustaining benefits of
layering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5119</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5119</id><created>2010-11-23</created><authors><author><keyname>Rouquier</keyname><forenames>Jean-Baptiste</forenames></author><author><keyname>Regnault</keyname><forenames>Damien</forenames></author><author><keyname>Thierry1</keyname><forenames>Eric</forenames></author></authors><title>Stochastic Minority on Graphs</title><categories>nlin.CG cs.DC cs.DM math.CO math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cellular automata have been mainly studied on very regular graphs carrying
the vertices (like lines or grids) and under synchronous dynamics (all vertices
update simultaneously). In this paper, we study how the asynchronism and the
graph act upon the dynamics of the classical Minority rule. Minority has been
well-studied for synchronous updates and is thus a reasonable choice to begin
with. Yet, beyond its apparent simplicity, this rule yields complex behaviors
when asynchronism is introduced. We investigate the transitory part as well as
the asymptotic behavior of the dynamics under full asynchronism (also called
sequential: only one random vertex updates at each time step) for several types
of graphs. Such a comparative study is a first step in understanding how the
asynchronous dynamics is linked to the topology (the graph).
  Previous analyses on the grid [1,2] have observed that Minority seems to
induce fast stabilization. We investigate here this property on arbitrary
graphs using tools such as energy, particles and random walks. We show that the
worst case convergence time is, in fact, strongly dependent on the topology. In
particular, we observe that the case of trees is non trivial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5122</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5122</id><created>2010-11-23</created><authors><author><keyname>Khodaian</keyname><forenames>Amir Mahdi</forenames></author><author><keyname>Khalaj</keyname><forenames>Babak H.</forenames></author><author><keyname>Talebi</keyname><forenames>Mohammad S.</forenames></author></authors><title>Utility Constrained Energy Minimization In Aloha Networks</title><categories>cs.IT math.IT</categories><comments>5 pages, ccnc07</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the issue of energy efficiency in random access
networks and show that optimizing transmission probabilities of nodes can
enhance network performance in terms of energy consumption and fairness. First,
we propose a heuristic power control method that improves throughput, and then
we model the Utility Constrained Energy Minimization (UCEM) problem in which
the utility constraint takes into account single and multi node performance.
UCEM is modeled as a convex optimization problem and Sequential Quadratic
Programming (SQP) is used to find optimal transmission probabilities. Numerical
results show that our method can achieve fairness, reduce energy consumption
and enhance lifetime of such networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5124</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5124</id><created>2010-11-23</created><authors><author><keyname>Khodaian</keyname><forenames>Amir M.</forenames></author><author><keyname>Khalaj</keyname><forenames>Babak H.</forenames></author></authors><title>Delay Constrained Utility Maximization in Multihop Random Access
  Networks</title><categories>cs.IT cs.NI cs.SY math.IT math.OC</categories><comments>22 pages, IET Communications, 2010, Vol 4., Iss 16</comments><report-no>p11p</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-hop random access networks have received much attention due to their
distributed nature which facilitates deploying many new applications over the
sensor and computer networks. Recently, utility maximization framework is
applied in order to optimize performance of such networks, however proposed
algorithms result in large transmission delays. In this paper, we will analyze
delay in random access multi-hop networks and solve the delay-constrained
utility maximization problem. We define the network utility as a combination of
rate utility and energy cost functions and solve the following two problems:
'optimal medium access control with link delay constraint' and, 'optimal
congestion and contention control with end-to-end delay constraint'. The
optimal tradeoff between delay, rate, and energy is achieved for different
values of delay constraint and the scaling factors between rate and energy.
Eventually linear and super-linear distributed optimization solutions are
proposed for each problem and their performance are compared in terms of
convergence and complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5164</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5164</id><created>2010-11-23</created><authors><author><keyname>Ferrara</keyname><forenames>Emilio</forenames></author><author><keyname>Fiumara</keyname><forenames>Giacomo</forenames></author><author><keyname>Pagano</keyname><forenames>Francesco</forenames></author></authors><title>Living City, a Collaborative Browser-based Massively Multiplayer Online
  Game</title><categories>cs.CY cs.SI</categories><comments>8 pages, 6 figures; SIMUTools '10: Proceedings of the 3rd
  International ICST Conference on Simulation Tools and Techniques</comments><acm-class>H.5.3; I.2.1</acm-class><journal-ref>Proceedings of the 3rd International ICST Conference on Simulation
  Tools and Techniques (SIMUTools '10), 2010</journal-ref><doi>10.4108/ICST.SIMUTOOLS2010.8730</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents the design and implementation of our Browser-based
Massively Multiplayer Online Game, Living City, a simulation game fully
developed at the University of Messina. Living City is a persistent and
real-time digital world, running in the Web browser environment and accessible
from users without any client-side installation. Today Massively Multiplayer
Online Games attract the attention of Computer Scientists both for their
architectural peculiarity and the close interconnection with the social network
phenomenon. We will cover these two aspects paying particular attention to some
aspects of the project: game balancing (e.g. algorithms behind time and money
balancing); business logic (e.g., handling concurrency, cheating avoidance and
availability) and, finally, social and psychological aspects involved in the
collaboration of players, analyzing their activities and interconnections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5167</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5167</id><created>2010-11-23</created><authors><author><keyname>Papalexis</keyname><forenames>Alex</forenames></author></authors><title>A Coder-Decoder model for use in Lossless Data Compression</title><categories>cs.IT math.IT</categories><comments>7 pages, 1 figure, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article describes a technique of using a trigonometric function and
combinatorial calculations to code or transform any finite sequence of binary
numbers (0s and 1s) of any length to a unique set of three Real numbers. In
reverse, these three Real numbers can be used independently to reconstruct the
original Binary sequence precisely. The main principles of this technique are
then applied in a proposal for a highly efficient model for Lossless Data
Compression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5168</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5168</id><created>2010-11-23</created><updated>2011-06-02</updated><authors><author><keyname>Catanese</keyname><forenames>Salvatore</forenames></author><author><keyname>De Meo</keyname><forenames>Pasquale</forenames></author><author><keyname>Ferrara</keyname><forenames>Emilio</forenames></author><author><keyname>Fiumara</keyname><forenames>Giacomo</forenames></author></authors><title>Analyzing the Facebook Friendship Graph</title><categories>cs.SI physics.soc-ph</categories><comments>6 pages, 1 figure; MIFI '10: Proceedings of the 1st International
  Workshop on Mining the Future Internet</comments><journal-ref>Proceedings of the 1st International Workshop on Mining the Future
  Internet (MIFI '10), 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online Social Networks (OSN) during last years acquired a huge and increasing
popularity as one of the most important emerging Web phenomena, deeply
modifying the behavior of users and contributing to build a solid substrate of
connections and relationships among people using the Web. In this preliminary
work paper, our purpose is to analyze Facebook, considering a significant
sample of data reflecting relationships among subscribed users. Our goal is to
extract, from this platform, relevant information about the distribution of
these relations and exploit tools and algorithms provided by the Social Network
Analysis (SNA) to discover and, possibly, understand underlying similarities
between the developing of OSN and real-life social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5188</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5188</id><created>2010-11-23</created><updated>2011-08-19</updated><authors><author><keyname>Haralambous</keyname><forenames>Yannis</forenames></author><author><keyname>Lavagnino</keyname><forenames>Elisa</forenames></author></authors><title>La r\'eduction de termes complexes dans les langues de sp\'ecialit\'e</title><categories>cs.CL</categories><comments>31 pages, 4 PNG figures, 1 PDF figure, uses XYpic, in French</comments><msc-class>68T50, 91F20</msc-class><acm-class>I.2.7</acm-class><journal-ref>Traitement Automatique de Langues 2011 (52/1)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our study applies statistical methods to French and Italian corpora to
examine the phenomenon of multi-word term reduction in specialty languages.
There are two kinds of reduction: anaphoric and lexical. We show that anaphoric
reduction depends on the discourse type (vulgarization, pedagogical,
specialized) but is independent of both domain and language; that lexical
reduction depends on domain and is more frequent in technical, rapidly evolving
domains; and that anaphoric reductions tend to follow full terms rather than
precede them. We define the notion of the anaphoric tree of the term and study
its properties. Concerning lexical reduction, we attempt to prove statistically
that there is a notion of term lifecycle, where the full form is progressively
replaced by a lexical reduction. ----- Nous \'etudions par des m\'ethodes
statistiques sur des corpus fran\c{c}ais et italiens, le ph\'enom\`ene de
r\'eduction des termes complexes dans les langues de sp\'ecialit\'e. Il existe
deux types de r\'eductions : anaphorique et lexicale. Nous montrons que la
r\'eduction anaphorique d\'epend du type de discours (de vulgarisation,
p\'edagogique, sp\'ecialis\'e) mais ne d\'epend ni du domaine, ni de la langue,
alors que la r\'eduction lexicale d\'epend du domaine et est plus fr\'equente
dans les domaines techniques \`a \'evolution rapide. D'autre part, nous
montrons que la r\'eduction anaphorique a tendance \`a suivre la forme pleine
du terme, nous d\'efinissons une notion d'arbre anaphorique de terme et nous
\'etudions ses propri\'et\'es. Concernant la r\'eduction lexicale, nous tentons
de d\'emontrer statistiquement qu'il existe une notion de cycle de vie de
terme, o\`u la forme pleine est progressivement remplac\'ee par une r\'eduction
lexicale.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5200</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5200</id><created>2010-11-23</created><updated>2011-05-07</updated><authors><author><keyname>Patrascu</keyname><forenames>Mihai</forenames></author><author><keyname>Thorup</keyname><forenames>Mikkel</forenames></author></authors><title>The Power of Simple Tabulation Hashing</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Randomized algorithms are often enjoyed for their simplicity, but the hash
functions used to yield the desired theoretical guarantees are often neither
simple nor practical. Here we show that the simplest possible tabulation
hashing provides unexpectedly strong guarantees.
  The scheme itself dates back to Carter and Wegman (STOC'77). Keys are viewed
as consisting of c characters. We initialize c tables T_1, ..., T_c mapping
characters to random hash codes. A key x=(x_1, ..., x_q) is hashed to T_1[x_1]
xor ... xor T_c[x_c].
  While this scheme is not even 4-independent, we show that it provides many of
the guarantees that are normally obtained via higher independence, e.g.,
Chernoff-type concentration, min-wise hashing for estimating set intersection,
and cuckoo hashing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5202</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5202</id><created>2010-11-23</created><authors><author><keyname>Heule</keyname><forenames>Marijn</forenames></author><author><keyname>J&#xe4;rvisalo</keyname><forenames>Matti</forenames></author><author><keyname>Biere</keyname><forenames>Armin</forenames></author></authors><title>Covered Clause Elimination</title><categories>cs.LO cs.AI</categories><comments>5 pages</comments><journal-ref>Short paper proceedings of LPAR-17, 17th International Conference
  on Logic for Programming, Artificial Intelligence and Reasoning, Yogyakarta,
  Indonesia, October 10th - 15th, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generalizing the novel clause elimination procedures developed in [M. Heule,
M. J\&quot;arvisalo, and A. Biere. Clause elimination procedures for CNF formulas.
In Proc. LPAR-17, volume 6397 of LNCS, pages 357-371. Springer, 2010.], we
introduce explicit (CCE), hidden (HCCE), and asymmetric (ACCE) variants of a
procedure that eliminates covered clauses from CNF formulas. We show that these
procedures are more effective in reducing CNF formulas than the respective
variants of blocked clause elimination, and may hence be interesting as new
preprocessing/simplification techniques for SAT solving.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5209</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5209</id><created>2010-11-23</created><updated>2011-01-29</updated><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Welbers</keyname><forenames>Kasper</forenames></author></authors><title>The semantic mapping of words and co-words in contexts</title><categories>cs.CL stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Meaning can be generated when information is related at a systemic level.
Such a system can be an observer, but also a discourse, for example,
operationalized as a set of documents. The measurement of semantics as
similarity in patterns (correlations) and latent variables (factor analysis)
has been enhanced by computer techniques and the use of statistics; for
example, in &quot;Latent Semantic Analysis&quot;. This communication provides an
introduction, an example, pointers to relevant software, and summarizes the
choices that can be made by the analyst. Visualization (&quot;semantic mapping&quot;) is
thus made more accessible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5239</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5239</id><created>2010-11-23</created><updated>2011-11-15</updated><authors><author><keyname>Ferretti</keyname><forenames>Luca</forenames></author><author><keyname>Cortelezzi</keyname><forenames>Michele</forenames></author></authors><title>Preferential attachment in growing spatial networks</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>9 pages, 12 figures, revtex, final version</comments><journal-ref>Phys. Rev. E. 84,016103 (2011)</journal-ref><doi>10.1103/PhysRevE.84.016103</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We obtain the degree distribution for a class of growing network models on
flat and curved spaces. These models evolve by preferential attachment weighted
by a function of the distance between nodes. The degree distribution of these
models is similar to the one of the fitness model of Bianconi and Barabasi,
with a fitness distribution dependent on the metric and the density of nodes.
We show that curvature singularities in these spaces can give rise to
asymptotic Bose-Einstein condensation, but transient condensation can be
observed also in smooth hyperbolic spaces with strong curvature. We provide
numerical results for spaces of constant curvature (sphere, flat and hyperbolic
space) and we discuss the conditions for the breakdown of this approach and the
critical points of the transition to distance-dominated attachment. Finally we
discuss the distribution of link lengths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5242</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5242</id><created>2010-11-23</created><authors><author><keyname>Broadbent</keyname><forenames>Anne</forenames></author><author><keyname>Jeffery</keyname><forenames>Stacey</forenames></author><author><keyname>Tapp</keyname><forenames>Alain</forenames></author></authors><title>Exact, Efficient and Information-Theoretically Secure Voting with an
  Arbitrary Number of Cheaters</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present three voting protocols with unconditional privacy and correctness,
without assuming any bound on the number of corrupt participants. All protocols
have polynomial complexity and require private channels and a simultaneous
broadcast channel. Unlike previously proposed protocols in this model, the
protocols that we present deterministically output the exact tally. Our first
protocol is a basic voting scheme which allows voters to interact in order to
compute the tally. Privacy of the ballot is unconditional in the sense that
regardless of the behavior of the dishonest participants nothing can be learned
through the protocol that could not be learned in an ideal realisation.
Unfortunately, a single dishonest participant can make the protocol abort, in
which case the dishonest participants can nevertheless learn the outcome of the
tally. Our second protocol introduces voting authorities which improves the
communication complexity by limiting interaction to be only between voters and
authorities and among the authorities themselves; the simultaneous broadcast is
also limited to the authorities. In the second protocol, as long as a single
authority is honest, the privacy is unconditional, however, a single corrupt
authority or a single corrupt voter can cause the protocol to abort. Our final
protocol provides a safeguard against corrupt voters by enabling a verification
technique to allow the authorities to revoke incorrect votes without aborting
the protocol. Finally, we discuss the implementation of a simultaneous
broadcast channel with the use of temporary computational assumptions, yielding
versions of our protocols that achieve everlasting security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5264</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5264</id><created>2010-11-20</created><authors><author><keyname>Giacomelli</keyname><forenames>Piero</forenames></author></authors><title>Wheel Random Apollonian Graphs</title><categories>cs.DM cond-mat.dis-nn math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a subset of High-Dimensional Random Apollonian networks, that
we called Wheel Random Apollonian Graphs (WRAG), is considered. We show how to
generate a Wheel Random Apollonian Graph from a wheel graph. We analyse some
basic graph properties like vertices and edges cardinality, some question
concerning cycles and the chromaticity in such type of graphs, we suggest
further work on this type of graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5270</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5270</id><created>2010-11-23</created><updated>2010-11-29</updated><authors><author><keyname>Carlsson</keyname><forenames>Gunnar</forenames></author><author><keyname>Memoli</keyname><forenames>Facundo</forenames></author></authors><title>Classifying Clustering Schemes</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many clustering schemes are defined by optimizing an objective function
defined on the partitions of the underlying set of a finite metric space. In
this paper, we construct a framework for studying what happens when we instead
impose various structural conditions on the clustering schemes, under the
general heading of functoriality. Functoriality refers to the idea that one
should be able to compare the results of clustering algorithms as one varies
the data set, for example by adding points or by applying functions to it. We
show that within this framework, one can prove a theorems analogous to one of
J. Kleinberg, in which for example one obtains an existence and uniqueness
theorem instead of a non-existence result.
  We obtain a full classification of all clustering schemes satisfying a
condition we refer to as excisiveness. The classification can be changed by
varying the notion of maps of finite metric spaces. The conditions occur
naturally when one considers clustering as the statistical version of the
geometric notion of connected components. By varying the degree of
functoriality that one requires from the schemes it is possible to construct
richer families of clustering schemes that exhibit sensitivity to density.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5274</identifier>
 <datestamp>2012-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5274</id><created>2010-11-23</created><updated>2012-09-25</updated><authors><author><keyname>Mukherjee</keyname><forenames>Amitav</forenames></author><author><keyname>Swindlehurst</keyname><forenames>A. Lee</forenames></author></authors><title>Jamming Games in the MIMO Wiretap Channel With an Active Eavesdropper</title><categories>cs.IT math.IT</categories><comments>27 pages, 8 figures. To appear, IEEE Transactions on Signal
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates reliable and covert transmission strategies in a
multiple-input multiple-output (MIMO) wiretap channel with a transmitter,
receiver and an adversarial wiretapper, each equipped with multiple antennas.
In a departure from existing work, the wiretapper possesses a novel capability
to act either as a passive eavesdropper or as an active jammer, under a
half-duplex constraint. The transmitter therefore faces a choice between
allocating all of its power for data, or broadcasting artificial interference
along with the information signal in an attempt to jam the eavesdropper
(assuming its instantaneous channel state is unknown). To examine the resulting
trade-offs for the legitimate transmitter and the adversary, we model their
interactions as a two-person zero-sum game with the ergodic MIMO secrecy rate
as the payoff function. We first examine conditions for the existence of
pure-strategy Nash equilibria (NE) and the structure of mixed-strategy NE for
the strategic form of the game.We then derive equilibrium strategies for the
extensive form of the game where players move sequentially under scenarios of
perfect and imperfect information. Finally, numerical simulations are presented
to examine the equilibrium outcomes of the various scenarios considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5287</identifier>
 <datestamp>2012-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5287</id><created>2010-11-23</created><updated>2012-06-12</updated><authors><author><keyname>Leong</keyname><forenames>Derek</forenames></author><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author><author><keyname>Ho</keyname><forenames>Tracey</forenames></author></authors><title>Distributed Storage Allocations</title><categories>cs.IT math.IT</categories><comments>Extended version of a journal paper in the IEEE Transactions on
  Information Theory. 21 pages, 10 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the problem of allocating a given total storage budget in a
distributed storage system for maximum reliability. A source has a single data
object that is to be coded and stored over a set of storage nodes; it is
allowed to store any amount of coded data in each node, as long as the total
amount of storage used does not exceed the given budget. A data collector
subsequently attempts to recover the original data object by accessing only the
data stored in a random subset of the nodes. By using an appropriate code,
successful recovery can be achieved whenever the total amount of data accessed
is at least the size of the original data object. The goal is to find an
optimal storage allocation that maximizes the probability of successful
recovery. This optimization problem is challenging in general because of its
combinatorial nature, despite its simple formulation. We study several
variations of the problem, assuming different allocation models and access
models. The optimal allocation and the optimal symmetric allocation (in which
all nonempty nodes store the same amount of data) are determined for a variety
of cases. Our results indicate that the optimal allocations often have
nonintuitive structure and are difficult to specify. We also show that
depending on the circumstances, coding may or may not be beneficial for
reliable storage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5289</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5289</id><created>2010-11-23</created><authors><author><keyname>Reddy</keyname><forenames>P. Venkata Subba</forenames></author><author><keyname>Iyer</keyname><forenames>K. Viswanathan</forenames></author></authors><title>On conditional coloring of some graphs</title><categories>cs.DM</categories><comments>9 pages: accepted for the 76th annual conference of the Indian
  Mathematical Society,27-30 December 2010,Surat,India</comments><msc-class>05C12, 05C30, 05C85</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For integers r and k &gt; 0(k&gt;r),a conditional (k, r)-coloring of a graph G is a
proper k-coloring of G such that every vertex v of G has at least min{r,d(v)}
differently colored neighbors, where d(v) is the degree of v. In this note, for
different values of r we obtain the conditional chromatic number of a grid
$G(2,n) \cong P_2 \ \Box \ P_n$, $C_n^2$ and the strong product of $P_n$ and
$P_m$ (n,m being positive integers). Also, for integers $n \geq 3$ and $t \geq
1$ the second order conditional chromatic number (also known as dynamic
chromatic number) of the (t,n)-web graph is obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5294</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5294</id><created>2010-11-23</created><authors><author><keyname>Katz</keyname><forenames>Daniel S.</forenames></author><author><keyname>Berriman</keyname><forenames>G. Bruce</forenames></author><author><keyname>Mann</keyname><forenames>Robert G.</forenames></author></authors><title>Collaborative Astronomical Image Mosaics</title><categories>astro-ph.IM cs.HC</categories><comments>16 pages, 3 figures. To be published in &quot;Reshaping Research and
  Development using Web 2.0-based technologies.&quot; Mark Baker, ed. Nova Science
  Publishers, Inc.(2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This chapter describes how astronomical imaging survey data have become a
vital part of modern astronomy, how these data are archived and then served to
the astronomical community through on-line data access portals. The Virtual
Observatory, now under development, aims to make all these data accessible
through a uniform set of interfaces. This chapter also describes the scientific
need for one common image processing task, that of composing individual images
into large scale mosaics and introduces Montage as a tool for this task.
Montage, as distributed, can be used in four ways: as a single thread/process
on a single CPU, in parallel using MPI to distribute similar tasks across a
parallel computer, in parallel using grid tools (Pegasus/DAGMan) to distributed
tasks across a grid, or in parallel using a script-driven approach (Swift). An
on-request web based Montage service is available for users who do not need to
build a local version. We also introduce some work on a new scripted version of
Montage, which offers ease of customization for users. Then, we discuss various
ideas where Web 2.0 technologies can help the Montage community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5295</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5295</id><created>2010-11-24</created><authors><author><keyname>Defrawy</keyname><forenames>Karim El</forenames></author><author><keyname>Capkun</keyname><forenames>Srdjan</forenames></author><author><keyname>Tsudik</keyname><forenames>Gene</forenames></author></authors><title>GDB: Group Distance Bounding Protocols</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secure distance bounding (DB) protocols allow one entity, the verifier, to
securely obtain an upper-bound on the distance to another entity, the prover.
Thus far, DB was considered mostly in the context of a single prover and a
single verifier. There has been no substantial prior work on secure DB in group
settings, where a set of provers interact with a set of verifiers. The need for
group distance bounding (GDB) is motivated by many practical scenarios,
including: group device pairing, location-based access control and secure
distributed localization. GDB is also useful in mission-critical networks and
automotive computer systems. This paper addresses, for the first time, GDB
protocols by utilizing the new passive DB primitive and the novel mutual
multi-party GDB protocol. We show how they can be used to construct secure and
efficient GDB protocols for various settings. We analyze security and
performance of our protocols and compare them with existing DB techniques when
applied to group settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5298</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5298</id><created>2010-11-24</created><updated>2011-06-12</updated><authors><author><keyname>Krishnamurthy</keyname><forenames>Vikram</forenames></author></authors><title>Bayesian Sequential Detection with Phase-Distributed Change Time and
  Nonlinear Penalty -- A POMDP Approach</title><categories>cs.IT math.IT stat.ME</categories><comments>accepted for publication in IEEE Transactions Information Theory,
  2011</comments><journal-ref>IEEE Transactions Information Theory, October 2011. Vol.57, No.10</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the optimal decision policy for several types of Bayesian
sequential detection problems has a threshold switching curve structure on the
space of posterior distributions. This is established by using lattice
programming and stochastic orders in a partially observed Markov decision
process (POMDP) framework. A stochastic gradient algorithm is presented to
estimate the optimal linear approximation to this threshold curve. We
illustrate these results by first considering quickest time detection with
phase-type distributed change time and a variance stopping penalty. Then it is
proved that the threshold switching curve also arises in several other Bayesian
decision problems such as quickest transient detection, exponential delay
(risk-sensitive) penalties, stopping time problems in social learning, and
multi-agent scheduling in a changing world. Using Blackwell dominance, it is
shown that for dynamic decision making problems, the optimal decision policy is
lower bounded by a myopic policy. Finally, it is shown how the achievable cost
of the optimal decision policy varies with change time distribution by imposing
a partial order on transition matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5311</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5311</id><created>2010-11-24</created><authors><author><keyname>Kamphuis</keyname><forenames>P.</forenames></author><author><keyname>van der Kruit</keyname><forenames>P. C.</forenames></author></authors><title>Citations and impact of Dutch astronomy</title><categories>astro-ph.IM cs.DL</categories><comments>37 pages, 21 figures, 9 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this study is to make a bibliometric comparison of the performance
of research astronomers in the Netherlands Research School for Astronomy (NOVA)
with astronomers elsewhere by using the NASA Astrophysics Data System (ADS). We
use various indices for bibliometric performance for a sample of NOVA
astronomers to compare to samples of astronomers worldwide, and from the United
States. We give much weight to normalising bibliometric measures by number of
authors, and number of years since first publication. In particular we
calculate the `Hirsh-index' normalized to number of authors and for
first-author papers. Secondly, we consider the results of the 'Nederlands
Observatorium van Wetenschap en Technologie' (NOWT; Netherlands Observatory of
Science and Technology), which regularly publishes a report 'Science and
Technology Indicators'. We reproduce those results using publication lists from
institutions in the Netherlands, again using ADS, and examine and discuss the
conclusions and indications in these reports. We find that the NOVA researchers
perform much better in bibliometric measures than samples drawn from IAU or AAS
membership lists. A more suitable comparison is one with the (tenured) staff of
the top-15 US institutions and there the NOVA staff performs in these respects
as good or almost as good as that of American top institutes. From a citation
analysis through the use of ADS we conclude that the impact ratio of Dutch
astronomical publications is rising which is opposite to what is reported by
NOWT. This difference is most likely caused by a better separation of astronomy
and physics in ADS than in World of Knowledge. ADS probably finds more
citations in conference proceedings, while the inclusion of citations to
articles with their pre-print identifier could also help explain the difference
(especially since the citation windows in the reports are short).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5314</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5314</id><created>2010-11-24</created><authors><author><keyname>Yeung</keyname><forenames>Man-Chung</forenames></author></authors><title>ML(n)BiCGStab: Reformulation, Analysis and Implementation</title><categories>math.NA cs.IT math.DS math.IT math.OC math.ST stat.TH</categories><comments>This paper is dedicated to the memory of Prof. Gene Golub. Most part
  of the paper was presented in Gene Golub Memorial Conference, Feb. 29-Mar. 1,
  2008, University of Massachusetts, Dartmouth, U.S.A</comments><msc-class>Numerical Analysis</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the aid of index functions, we re-derive the ML(n)BiCGStab algorithm in
a paper by Yeung and Chan in 1999 in a more systematic way. It turns out that
there are n ways to define the ML(n)BiCGStab residual vector. Each definition
will lead to a different ML(n)BiCGStab algorithm. We demonstrate this by
presenting a second algorithm which requires less storage. In theory, this
second algorithm serves as a bridge that connects the Lanczos-based BiCGStab
and the Arnoldi-based FOM while ML(n)BiCG a bridge connecting BiCG and FOM. We
also analyze the breakdown situations from the probabilistic point of view and
summarize some useful properties of ML(n)BiCGStab. Implementation issues are
also addressed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5317</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5317</id><created>2010-11-24</created><updated>2011-04-02</updated><authors><author><keyname>Bonald</keyname><forenames>Thomas</forenames></author><author><keyname>Feuillet</keyname><forenames>Mathieu</forenames></author></authors><title>Performance of CSMA in Multi-Channel Wireless Networks</title><categories>cs.NI cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the performance of CSMA in multi-channel wireless networks,
accounting for the random nature of traffic. Specifically, we assess the
ability of CSMA to fully utilize the radio resources and in turn to stabilize
the network in a dynamic setting with flow arrivals and departures. We prove
that CSMA is optimal in ad-hoc mode but not in infrastructure mode, when all
data flows originate from or are destined to some access points, due to the
inherent bias of CSMA against downlink traffic. We propose a slight
modification of CSMA, that we refer to as flow-aware CSMA, which corrects this
bias and makes the algorithm optimal in all cases. The analysis is based on
some time-scale separation assumption which is proved valid in the limit of
large flow sizes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5320</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5320</id><created>2010-11-24</created><authors><author><keyname>Chen</keyname><forenames>Wen-Haw</forenames></author><author><keyname>Chen</keyname><forenames>Sheng-Gwo</forenames></author></authors><title>Computation of the shortest path between two curves on a parametric
  surface by geodesic-like method</title><categories>cs.CG math.NA</categories><comments>11 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the geodesic-like algorithm for the computation of
the shortest path between two objects on NURBS surfaces and periodic surfaces.
This method can improve the distance problem not only on surfaces but in
$\mathbb{R}^3$. Moreover, the geodesic-like algorithm also provides an
efficient approach to simulate the minimal geodesic between two holes on a
NURBS surfaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5325</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5325</id><created>2010-11-24</created><authors><author><keyname>Andreyev</keyname><forenames>Sergey</forenames></author></authors><title>World of Movable Objects. Part 2</title><categories>cs.HC</categories><comments>145 pages, 103 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This book is about the transformation of screen objects into movable and
resizable and about the design of applications entirely on the basis of such
elements. The screen objects have a wide variety of shapes; they can be either
graphical objects or controls; there are solitary objects and very complex
objects parts of which are involved in individual, synchronous, and related
movements. Objects can be involved in forward movements and rotation; they can
be resized and reconfigured; all these movements and situations are considered.
On the basis of total movability, the new type of programs -- user-driven
applications -- are designed. These applications continue to work according to
their main purposes, but the whole control of what, when, and how must appear
on the screen is passed from designers to users. Due to the size restriction
used on CoRR, the book is divided here into two parts and one appendix is
deleted. At www.sourceforge.net in the project MoveableGraphics the whole book
is available in a single file together with the accompanying application with
all its source codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5326</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5326</id><created>2010-11-24</created><authors><author><keyname>Sara</keyname><forenames>Getsy S.</forenames></author><author><keyname>R</keyname><forenames>Kalaiarasi.</forenames></author><author><keyname>S</keyname><forenames>Neelavathy Pari.</forenames></author><author><keyname>D</keyname><forenames>Sridharan .</forenames></author></authors><title>Energy Efficient Clustering and Routing in Mobile Wireless Sensor
  Network</title><categories>cs.NI</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A critical need in Mobile Wireless Sensor Network (MWSN) is to achieve energy
efficiency during routing as the sensor nodes have scarce energy resource. The
nodes' mobility in MWSN poses a challenge to design an energy efficient routing
protocol. Clustering helps to achieve energy efficiency by reducing the
organization complexity overhead of the network which is proportional to the
number of nodes in the network. This paper proposes a novel hybrid multipath
routing algorithm with an efficient clustering technique. A node is selected as
cluster head if it has high surplus energy, better transmission range and least
mobility. The Energy Aware (EA) selection mechanism and the Maximal Nodal
Surplus Energy estimation technique incorporated in this algorithm improves the
energy performance during routing. Simulation results can show that the
proposed clustering and routing algorithm can scale well in dynamic and energy
deficient mobile sensor network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5332</identifier>
 <datestamp>2010-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5332</id><created>2010-11-24</created><authors><author><keyname>Wielemaker</keyname><forenames>Jan</forenames></author><author><keyname>Schrijvers</keyname><forenames>Tom</forenames></author><author><keyname>Triska</keyname><forenames>Markus</forenames></author><author><keyname>Lager</keyname><forenames>Torbj&#xf6;rn</forenames></author></authors><title>SWI-Prolog</title><categories>cs.PL</categories><comments>30 pages, 6 figures, 1 table. To appear in Theory and Practice of
  Logic Programming (TPLP)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  SWI-Prolog is neither a commercial Prolog system nor a purely academic
enterprise, but increasingly a community project. The core system has been
shaped to its current form while being used as a tool for building research
prototypes, primarily for \textit{knowledge-intensive} and \textit{interactive}
systems. Community contributions have added several interfaces and the
constraint (CLP) libraries. Commercial involvement has created the initial
garbage collector, added several interfaces and two development tools: PlDoc (a
literate programming documentation system) and PlUnit (a unit testing
environment).
  In this article we present SWI-Prolog as an integrating tool, supporting a
wide range of ideas developed in the Prolog community and acting as glue
between \textit{foreign} resources. This article itself is the glue between
technical articles on SWI-Prolog, providing context and experience in applying
them over a longer period.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5349</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5349</id><created>2010-11-24</created><authors><author><keyname>Hern&#xe1;ndez</keyname><forenames>Hugo</forenames></author><author><keyname>Blum</keyname><forenames>Christian</forenames></author></authors><title>Distributed Graph Coloring: An Approach Based on the Calling Behavior of
  Japanese Tree Frogs</title><categories>cs.AI</categories><msc-class>68 Computer Science</msc-class><acm-class>I.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph coloring, also known as vertex coloring, considers the problem of
assigning colors to the nodes of a graph such that adjacent nodes do not share
the same color. The optimization version of the problem concerns the
minimization of the number of used colors. In this paper we deal with the
problem of finding valid colorings of graphs in a distributed way, that is, by
means of an algorithm that only uses local information for deciding the color
of the nodes. Such algorithms prescind from any central control. Due to the
fact that quite a few practical applications require to find colorings in a
distributed way, the interest in distributed algorithms for graph coloring has
been growing during the last decade. As an example consider wireless ad-hoc and
sensor networks, where tasks such as the assignment of frequencies or the
assignment of TDMA slots are strongly related to graph coloring.
  The algorithm proposed in this paper is inspired by the calling behavior of
Japanese tree frogs. Male frogs use their calls to attract females.
Interestingly, groups of males that are located nearby each other desynchronize
their calls. This is because female frogs are only able to correctly localize
the male frogs when their calls are not too close in time. We experimentally
show that our algorithm is very competitive with the current state of the art,
using different sets of problem instances and comparing to one of the most
competitive algorithms from the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5364</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5364</id><created>2010-11-24</created><authors><author><keyname>Caruso</keyname><forenames>Fabrizio</forenames></author><author><keyname>Giuffrida</keyname><forenames>Giovanni</forenames></author></authors><title>Optimizing On-Line Advertising</title><categories>cs.IR</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We want to find the optimal strategy for displaying advertisements e.g.
banners, videos, in given locations at given times under some realistic dynamic
constraints. Our primary goal is to maximize the expected revenue in a given
period of time, i.e. the total profit produced by the impressions, which
depends on profit-generating events such as the impressions themselves, the
ensuing clicks and registrations. Moreover we must take into consideration the
possibility that the constraints could change in time in a way that cannot
always be foreseen.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5367</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5367</id><created>2010-11-24</created><authors><author><keyname>Miritello</keyname><forenames>Giovanna</forenames></author><author><keyname>Moro</keyname><forenames>Esteban</forenames></author><author><keyname>Lara</keyname><forenames>Rub&#xe9;n</forenames></author></authors><title>The dynamical strength of social ties in information spreading</title><categories>physics.soc-ph cs.SI</categories><doi>10.1103/PhysRevE.83.045102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the temporal patterns of human communication and its influence
on the spreading of information in social networks. The analysis of mobile
phone calls of 20 million people in one country shows that human communication
is bursty and happens in group conversations. These features have opposite
effects in information reach: while bursts hinder propagation at large scales,
conversations favor local rapid cascades. To explain these phenomena we define
the dynamical strength of social ties, a quantity that encompasses both the
topological and temporal patterns of human communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5369</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5369</id><created>2010-11-24</created><updated>2011-02-06</updated><authors><author><keyname>Berstel</keyname><forenames>Jean</forenames></author><author><keyname>De Felice</keyname><forenames>Clelia</forenames></author><author><keyname>Perrin</keyname><forenames>Dominique</forenames></author><author><keyname>Reutenauer</keyname><forenames>Christophe</forenames></author><author><keyname>Rindone</keyname><forenames>Giuseppina</forenames></author></authors><title>Bifix codes and Sturmian words</title><categories>math.CO cs.FL</categories><comments>70 pages + index</comments><journal-ref>Journal of Algebra, 369, 146-202, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove new results concerning the relation between bifix codes, episturmian
words and subgroups offree groups. We study bifix codes in factorial sets of
words. We generalize most properties of ordinary maximal bifix codes to bifix
codes maximal in a recurrent set $F$ of words ($F$-maximal bifix codes). In the
case of bifix codes contained in Sturmian sets of words, we obtain several new
results. Let $F$ be a Sturmian set of words, defined as the set of factors of a
strict episturmian word. Our results express the fact that an $F$-maximal bifix
code of degree $d$ behaves just as the set of words of $F$ of length $d$. An
$F$-maximal bifix code of degree $d$ in a Sturmian set of words on an alphabet
with $k$ letters has $(k-1)d+1$ elements. This generalizes the fact that a
Sturmian set contains $(k-1)d+1$ words of length $d$. Moreover, given an
infinite word $x$, if there is a finite maximal bifix code $X$ of degree $d$
such that $x$ has at most $d$ factors of length $d$ in $X$, then $x$ is
ultimately periodic. Our main result states that any $F$-maximal bifix code of
degree $d$ on the alphabet $A$ is the basis of a subgroup of index $d$ of the
free group on~$A$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5374</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5374</id><created>2010-11-24</created><authors><author><keyname>Kamaraju</keyname><forenames>M.</forenames></author><author><keyname>Tilak</keyname><forenames>A. V. N.</forenames></author><author><keyname>Kishore</keyname><forenames>K. Lal</forenames></author><author><keyname>Baburao</keyname><forenames>K.</forenames></author></authors><title>VHDL Implementation and Verification of ARINC-429 Core</title><categories>cs.OH</categories><comments>7 pages,15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern Avionics are controlled by sophisticated mission components in the
Aircraft. The control function is implemented via a standard ARINC-429 bus
interface. It is a two-wire point-topoint serial data bus for control
communications in Avionics. The bus operates 12.5 or 100kb/sec, the
implementation is envisaged for one transmits and receive channel respectively.
Further the code can be modified for more no of independent Tx and Rx channels.
An on chip memory allotment on the FPGA will provide a buffer bank for storing
the incoming or outgoing data. For this purpose SRAM based FPGAs are utilized.
This flexible ARINC429 solution gives exactly what is needed for real time
applications. The IP can be programmed to send an interrupt to the host and
also prepare it to process the data. Majority of the hardware function of
digital natures are embedded into a single FPGA by saving in terms of PCB board
space, power consumption and volume results. This paper deals with the
development, implementation, simulation, and verification of ARINC_429 formats.
The IP core development is described in VHDL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5384</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5384</id><created>2010-11-24</created><authors><author><keyname>Ahmad</keyname><forenames>Sahand</forenames></author><author><keyname>Tekin</keyname><forenames>Cem</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author><author><keyname>Southwell</keyname><forenames>Richard</forenames></author><author><keyname>Huang</keyname><forenames>Jianwei</forenames></author></authors><title>Spectrum Sharing as Spatial Congestion Games</title><categories>cs.GT</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present and analyze the properties of a new class of games
- the spatial congestion game (SCG), which is a generalization of the classical
congestion game (CG). In a classical congestion game, multiple users share the
same set of resources and a user's payoff for using any resource is a function
of the total number of users sharing it. As a potential game, this game enjoys
some very appealing properties, including the existence of a pure strategy Nash
equilibrium (NE) and that every improvement path is finite and leads to such a
NE (also called the finite improvement property or FIP). While it's tempting to
use this model to study spectrum sharing, it does not capture the spatial reuse
feature of wireless communication, where resources (interpreted as channels)
may be reused without increasing congestion provided that users are located far
away from each other. This motivates us to study an extended form of the
congestion game where a user's payoff for using a resource is a function of the
number of its interfering users sharing it. This naturally results in a spatial
congestion game (SCG), where users are placed over a network (or a conflict
graph). We study fundamental properties of a spatial congestion game; in
particular, we seek to answer under what conditions this game possesses the
finite improvement property or a Nash equilibrium. We also discuss the
implications of these results when applied to wireless spectrum sharing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5389</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5389</id><created>2010-11-24</created><authors><author><keyname>Barbuti</keyname><forenames>Roberto</forenames></author><author><keyname>Cignoni</keyname><forenames>Giovanni A.</forenames></author><author><keyname>Milazzo</keyname><forenames>Paolo</forenames></author></authors><title>A Model for Configuration Management of Open Software Systems</title><categories>cs.SE</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article proposes a model for the configuration management of open
systems. The model aims at validation of configurations against given
specifications. An extension of decision graphs is proposed to express
specifications. The proposed model can be used by software developers to
validate their own configurations across different versions of the components,
or to validate configurations that include components by third parties. The
model can also be used by end-users to validate compatibility among different
configurations of the same application. The proposed model is first discussed
in some application scenarios and then formally defined. Moreover, a type
discipline is given to formally define validation of a configuration against a
system specification
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5395</identifier>
 <datestamp>2013-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5395</id><created>2010-11-24</created><authors><author><keyname>Vainsencher</keyname><forenames>Daniel</forenames></author><author><keyname>Mannor</keyname><forenames>Shie</forenames></author><author><keyname>Bruckstein</keyname><forenames>Alfred M.</forenames></author></authors><title>The Sample Complexity of Dictionary Learning</title><categories>stat.ML cs.LG</categories><doi>10.1016/j.specom.2013.01.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A large set of signals can sometimes be described sparsely using a
dictionary, that is, every element can be represented as a linear combination
of few elements from the dictionary. Algorithms for various signal processing
applications, including classification, denoising and signal separation, learn
a dictionary from a set of signals to be represented. Can we expect that the
representation found by such a dictionary for a previously unseen example from
the same source will have L_2 error of the same magnitude as those for the
given examples? We assume signals are generated from a fixed distribution, and
study this questions from a statistical learning theory perspective.
  We develop generalization bounds on the quality of the learned dictionary for
two types of constraints on the coefficient selection, as measured by the
expected L_2 error in representation when the dictionary is used. For the case
of l_1 regularized coefficient selection we provide a generalization bound of
the order of O(sqrt(np log(m lambda)/m)), where n is the dimension, p is the
number of elements in the dictionary, lambda is a bound on the l_1 norm of the
coefficient vector and m is the number of samples, which complements existing
results. For the case of representing a new signal as a combination of at most
k dictionary elements, we provide a bound of the order O(sqrt(np log(m k)/m))
under an assumption on the level of orthogonality of the dictionary (low Babel
function). We further show that this assumption holds for most dictionaries in
high dimensions in a strong probabilistic sense. Our results further yield fast
rates of order 1/m as opposed to 1/sqrt(m) using localized Rademacher
complexity. We provide similar results in a general setting using kernels with
weak smoothness requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5425</identifier>
 <datestamp>2011-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5425</id><created>2010-11-24</created><updated>2011-10-14</updated><authors><author><keyname>Boldi</keyname><forenames>Paolo</forenames></author><author><keyname>Rosa</keyname><forenames>Marco</forenames></author><author><keyname>Santini</keyname><forenames>Massimo</forenames></author><author><keyname>Vigna</keyname><forenames>Sebastiano</forenames></author></authors><title>Layered Label Propagation: A MultiResolution Coordinate-Free Ordering
  for Compressing Social Networks</title><categories>cs.DS cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We continue the line of research on graph compression started with WebGraph,
but we move our focus to the compression of social networks in a proper sense
(e.g., LiveJournal): the approaches that have been used for a long time to
compress web graphs rely on a specific ordering of the nodes (lexicographical
URL ordering) whose extension to general social networks is not trivial. In
this paper, we propose a solution that mixes clusterings and orders, and devise
a new algorithm, called Layered Label Propagation, that builds on previous work
on scalable clustering and can be used to reorder very large graphs (billions
of nodes). Our implementation uses overdecomposition to perform aggressively on
multi-core architecture, making it possible to reorder graphs of more than 600
millions nodes in a few hours. Experiments performed on a wide array of web
graphs and social networks show that combining the order produced by the
proposed algorithm with the WebGraph compression framework provides a major
increase in compression with respect to all currently known techniques, both on
web graphs and on social networks. These improvements make it possible to
analyse in main memory significantly larger graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5435</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5435</id><created>2010-11-24</created><authors><author><keyname>Coelho</keyname><forenames>Andr&#xe9;</forenames></author><author><keyname>Ribeiro</keyname><forenames>Hugo</forenames></author><author><keyname>Silva</keyname><forenames>M&#xe1;rio</forenames></author><author><keyname>Jos&#xe9;</keyname><forenames>Rui</forenames></author></authors><title>A system for coarse-grained location-based synchronisation</title><categories>cs.HC</categories><comments>12 pages, 4 figures, INForum 2010 - II Simp\'osio de Inform\'atica,
  Lu\'is S. Barbosa, Miguel P. Correia (eds), 9-10 Setembro, 2010, pp. 367-378</comments><acm-class>H.5.1; K.4.2; K.8.m</acm-class><journal-ref>INForum 2010 - II Simp\'osio de Inform\'atica (2010) 367-378</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a system for supporting coarse-grained location-based
synchronisation. This type of synchronisation may occur when people need only
some awareness about the location of others within the specific context of an
on-going activity. We have identified a number of reference scenarios for this
type of synchronisation and we have implemented and deployed a prototype to
evaluate the type of support provided. The results of the evaluation suggest a
good acceptance of the overall concept, indicating that this might be a
valuable approach for many of the indicated scenarios, possibly replacing or
complementing existing synchronisation practices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5447</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5447</id><created>2010-11-24</created><authors><author><keyname>Lenhardt</keyname><forenames>Rastislav</forenames></author></authors><title>Proof of Concept: Fast Solutions to NP-problems by Using SAT and Integer
  Programming Solvers</title><categories>cs.DS cs.CC</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the last decade, the power of the state-of-the-art SAT and Integer
Programming solvers has dramatically increased. They implement many new
techniques and heuristics and since any NP problem can be converted to SAT or
ILP instance, we could take advantage of these techniques in general by
converting the instance of NP problem to SAT formula or Integer program. A
problem we consider, in this proof of concept, is finding a largest clique in a
graph. We ran several experiments on large random graphs and compared 3
approaches: Optimised backtrack solution, Translation to SAT and Translation to
Integer program. The last one was the fastest one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5452</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5452</id><created>2010-11-24</created><authors><author><keyname>Vanka</keyname><forenames>Sundaram</forenames></author><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author><author><keyname>Gupta</keyname><forenames>Vijay</forenames></author></authors><title>Convergence Speed of the Consensus Algorithm with Interference and
  Sparse Long-Range Connectivity</title><categories>cs.IT math.IT</categories><comments>27 pages, 4 figures</comments><doi>10.1109/JSTSP.2011.2118741</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the effect of interference on the convergence rate of average
consensus algorithms, which iteratively compute the measurement average by
message passing among nodes. It is usually assumed that these algorithms
converge faster with a greater exchange of information (i.e., by increased
network connectivity) in every iteration. However, when interference is taken
into account, it is no longer clear if the rate of convergence increases with
network connectivity. We study this problem for randomly-placed
consensus-seeking nodes connected through an interference-limited network. We
investigate the following questions: (a) How does the rate of convergence vary
with increasing communication range of each node? and (b) How does this result
change when each node is allowed to communicate with a few selected far-off
nodes? When nodes schedule their transmissions to avoid interference, we show
that the convergence speed scales with $r^{2-d}$, where $r$ is the
communication range and $d$ is the number of dimensions. This scaling is the
result of two competing effects when increasing $r$: Increased schedule length
for interference-free transmission vs. the speed gain due to improved
connectivity. Hence, although one-dimensional networks can converge faster from
a greater communication range despite increased interference, the two effects
exactly offset one another in two-dimensions. In higher dimensions, increasing
the communication range can actually degrade the rate of convergence. Our
results thus underline the importance of factoring in the effect of
interference in the design of distributed estimation algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5458</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5458</id><created>2010-11-24</created><authors><author><keyname>Hosseini</keyname><forenames>H.</forenames></author><author><keyname>Marvasti</keyname><forenames>N. B.</forenames></author><author><keyname>Marvasti</keyname><forenames>F.</forenames></author></authors><title>Image Inpainting Using Sparsity of the Transform Domain</title><categories>cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new image inpainting method based on the property
that much of the image information in the transform domain is sparse. We add a
redundancy to the original image by mapping the transform coefficients with
small amplitudes to zero and the resultant sparsity pattern is used as the side
information in the recovery stage. If the side information is not available,
the receiver has to estimate the sparsity pattern. At the end, the recovery is
done by consecutive projecting between two spatial and transform sets.
Experimental results show that our method works well for both structural and
texture images and outperforms other techniques in objective and subjective
performance measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5459</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5459</id><created>2010-11-24</created><updated>2011-05-06</updated><authors><author><keyname>Chmiel</keyname><forenames>Anna</forenames></author><author><keyname>Sobkowicz</keyname><forenames>Pawel</forenames></author><author><keyname>Sienkiewicz</keyname><forenames>Julian</forenames></author><author><keyname>Paltoglou</keyname><forenames>Georgios</forenames></author><author><keyname>Buckley</keyname><forenames>Kevan</forenames></author><author><keyname>Thelwall</keyname><forenames>Mike</forenames></author><author><keyname>Holyst</keyname><forenames>Janusz A.</forenames></author></authors><title>Negative emotions boost users activity at BBC Forum</title><categories>cs.HC physics.soc-ph</categories><comments>29 pages, 6 figures</comments><journal-ref>Physica A 390, 2936 (2011)</journal-ref><doi>10.1016/j.physa.2011.03.040</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an empirical study of user activity in online BBC discussion
forums, measured by the number of posts written by individual debaters and the
average sentiment of these posts. Nearly 2.5 million posts from over 18
thousand users were investigated. Scale free distributions were observed for
activity in individual discussion threads as well as for overall activity. The
number of unique users in a thread normalized by the thread length decays with
thread length, suggesting that thread life is sustained by mutual discussions
rather than by independent comments. Automatic sentiment analysis shows that
most posts contain negative emotions and the most active users in individual
threads express predominantly negative sentiments. It follows that the average
emotion of longer threads is more negative and that threads can be sustained by
negative comments. An agent based computer simulation model has been used to
reproduce several essential characteristics of the analyzed system. The model
stresses the role of discussions between users, especially emotionally laden
quarrels between supporters of opposite opinions, and represents many observed
statistics of the forum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5469</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5469</id><created>2010-11-24</created><authors><author><keyname>Zhang</keyname><forenames>Hao</forenames></author><author><keyname>Chen</keyname><forenames>Minghua</forenames></author><author><keyname>Parekh</keyname><forenames>Abhay</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>An Adaptive Multi-channel P2P Video-on-Demand System using Plug-and-Play
  Helpers</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a multi-channel P2P Video-on-Demand (VoD) system using
&quot;plug-and-play&quot; helpers. Helpers are heterogenous &quot;micro-servers&quot; with limited
storage, bandwidth and number of users they can serve simultaneously. Our
proposed system has the following salient features: (1) it minimizes the server
load; (2) it is distributed, and requires little or no maintenance overhead and
which can easily adapt to system dynamics; and (3) it is adaptable to varying
supply and demand patterns across multiple video channels irrespective of video
popularity. Our proposed solution jointly optimizes over helper-user topology,
video storage allocation and bandwidth allocation. The combinatorial nature of
the problem and the system demand for distributed algorithms makes the problem
uniquely challenging. By utilizing Lagrangian decomposition and Markov chain
approximation based arguments, we address this challenge by designing two
distributed algorithms running in tandem: a primal-dual storage and bandwidth
allocation algorithm and a &quot;soft-worst-neighbor-choking&quot; topology-building
algorithm. Our scheme provably converges to a near-optimal solution, and is
easy to implement in practice. Simulation results validate that the proposed
scheme achieves minimum sever load under highly heterogeneous combinations of
supply and demand patterns, and is robust to system dynamics of user/helper
churn, user/helper asynchrony, and random delays in the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5470</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5470</id><created>2010-11-24</created><authors><author><keyname>Kuhn</keyname><forenames>Fabian</forenames></author><author><keyname>Moscibroda</keyname><forenames>Thomas</forenames></author><author><keyname>Wattenhofer</keyname><forenames>Roger</forenames></author></authors><title>Local Computation: Lower and Upper Bounds</title><categories>cs.DC</categories><comments>53 pages, preliminary version in ACM PODC 2004 and ACM-SIAM SODA 2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The question of what can be computed, and how efficiently, are at the core of
computer science. Not surprisingly, in distributed systems and networking
research, an equally fundamental question is what can be computed in a
distributed fashion. More precisely, if nodes of a network must base their
decision on information in their local neighborhood only, how well can they
compute or approximate a global (optimization) problem? In this paper we give
the first substantial lower bound on such local computation for (optimization)
problems including minimum vertex cover, minimum (connected) dominating set,
maximum matching, maximal independent set, and maximal matching. In addition we
present a new distributed algorithm for solving general covering and packing
linear programs. For some problems this algorithm is tight with the lower
bounds, for others it is a distributed approximation scheme. Together, our
lower and upper bounds establish the local computability and approximability of
a large class of problems, characterizing how much local information is
required to solve these tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5480</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5480</id><created>2010-11-24</created><authors><author><keyname>Synnaeve</keyname><forenames>Gabriel</forenames><affiliation>LIG</affiliation></author><author><keyname>Bessiere</keyname><forenames>Pierre</forenames><affiliation>LPPA</affiliation></author></authors><title>Bayesian Modeling of a Human MMORPG Player</title><categories>cs.AI</categories><comments>30th international workshop on Bayesian Inference and Maximum
  Entropy, Chamonix : France (2010)</comments><proxy>ccsd</proxy><doi>10.1063/1.3573658</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes an application of Bayesian programming to the control of
an autonomous avatar in a multiplayer role-playing game (the example is based
on World of Warcraft). We model a particular task, which consists of choosing
what to do and to select which target in a situation where allies and foes are
present. We explain the model in Bayesian programming and show how we could
learn the conditional probabilities from data gathered during human-played
sessions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5481</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5481</id><created>2010-11-24</created><authors><author><keyname>Bouzarkouna</keyname><forenames>Zyed</forenames><affiliation>IFP, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Ding</keyname><forenames>Didier Yu</forenames><affiliation>IFP</affiliation></author><author><keyname>Auger</keyname><forenames>Anne</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author></authors><title>Using Evolution Strategy with Meta-models for Well Placement
  Optimization</title><categories>cs.CE</categories><comments>ECMOR XII - 12 th European Conference on the Mathematics of Oil
  Recovery, Oxford : Royaume-Uni (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimum implementation of non-conventional wells allows us to increase
considerably hydrocarbon recovery. By considering the high drilling cost and
the potential improvement in well productivity, well placement decision is an
important issue in field development. Considering complex reservoir geology and
high reservoir heterogeneities, stochastic optimization methods are the most
suitable approaches for optimum well placement. This paper proposes an
optimization methodology to determine optimal well location and trajectory
based upon the Covariance Matrix Adaptation - Evolution Strategy (CMA-ES) which
is a variant of Evolution Strategies recognized as one of the most powerful
derivative-free optimizers for continuous optimization. To improve the
optimization procedure, two new techniques are investigated: (1). Adaptive
penalization with rejection is developed to handle well placement constraints.
(2). A meta-model, based on locally weighted regression, is incorporated into
CMA-ES using an approximate ranking procedure. Therefore, we can reduce the
number of reservoir simulations, which are computationally expensive. Several
examples are presented. Our new approach is compared with a Genetic Algorithm
incorporating the Genocop III technique. It is shown that our approach
outperforms the genetic algorithm: it leads in general to both a higher NPV and
a significant reduction of the number of reservoir simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5496</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5496</id><created>2010-11-24</created><updated>2010-11-30</updated><authors><author><keyname>Feizi</keyname><forenames>Soheil</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>On Network Functional Compression</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider different aspects of the network functional
compression problem where computation of a function (or, some functions) of
sources located at certain nodes in a network is desired at receiver(s). The
rate region of this problem has been considered in the literature under certain
restrictive assumptions, particularly in terms of the network topology, the
functions and the characteristics of the sources. In this paper, we present
results that significantly relax these assumptions. Firstly, we consider this
problem for an arbitrary tree network and asymptotically lossless computation.
We show that, for depth one trees with correlated sources, or for general trees
with independent sources, a modularized coding scheme based on graph colorings
and Slepian-Wolf compression performs arbitrarily closely to rate lower bounds.
For a general tree network with independent sources, optimal computation to be
performed at intermediate nodes is derived. We introduce a necessary and
sufficient condition on graph colorings of any achievable coding scheme, called
coloring connectivity condition (C.C.C.).
  Secondly, we investigate the effect of having several functions at the
receiver. In this problem, we derive a rate region and propose a coding scheme
based on graph colorings. Thirdly, we consider the functional compression
problem with feedback. We show that, in this problem, unlike Slepian-Wolf
compression, by having feedback, one may outperform rate bounds of the case
without feedback. Fourthly, we investigate functional computation problem with
distortion. We compute a rate-distortion region for this problem. Then, we
propose a simple suboptimal coding scheme with a non-trivial performance
guarantee. Finally, we introduce cases where finding minimum entropy colorings
and therefore, optimal coding schemes can be performed in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5499</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5499</id><created>2010-11-25</created><authors><author><keyname>Whitworth</keyname><forenames>B.</forenames></author></authors><title>Simulating space and time</title><categories>cs.OH</categories><comments>Second paper of a series, see http://brianwhitworth.com/BW-VRT1.pdf
  for the first paper</comments><journal-ref>Prespacetime Journal, March 2010, Vol. 1, Issue 2, Page 218-243</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This chapter asks if a virtual space-time could appear to those within it as
our space-time does to us. A processing grid network is proposed to underlie
not just matter and energy, but also space and time. The suggested &quot;screen&quot; for
our familiar three dimensional world is a hyper-sphere surface simulated by a
grid network. Light and matter then travel, or are transmitted, in the
&quot;directions&quot; of the grid architecture. The processing sequences of grid nodes
create time, as the static states of movies run together emulate events. Yet
here what exists are not the static states, but the dynamic processing between
them. Quantum collapse is the irreversible event that gives time its direction.
In this model, empty space is null processing, directions are node links, time
is processing cycles, light is a processing wave, objects are wave tangles and
energy is the processing transfer rate. It describes a world where empty space
is not empty, space warps, time dilates, and everything began when this virtual
universe &quot;booted up&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5534</identifier>
 <datestamp>2011-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5534</id><created>2010-11-24</created><updated>2011-08-30</updated><authors><author><keyname>Dey</keyname><forenames>Dhananjoy</forenames></author><author><keyname>Mishra1</keyname><forenames>Prasanna Raghaw</forenames></author><author><keyname>Sengupta</keyname><forenames>Indranath</forenames></author></authors><title>GB-hash : Hash Functions Using Groebner Basis</title><categories>cs.CR math.AC</categories><comments>The paper has been withdrawn. The authors have found some weaknesses
  in this design</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper we present an improved version of HF-hash, viz., GB-hash : Hash
Functions Using Groebner Basis. In case of HF-hash, the compression function
consists of 32 polynomials with 64 variables which were taken from the first 32
polynomials of hidden field equations challenge-1 by forcing last 16 variables
as 0. In GB-hash we have designed the compression function in such way that
these 32 polynomials with 64 variables form a minimal Groebner basis of the
ideal generated by them with respect to graded lexicographical (grlex) ordering
as well as with respect to graded reverse lexicographical (grevlex) ordering.
In this paper we will prove that GB-hash is more secure than HF-hash as well as
more secure than SHA-256. We have also compared the efficiency of our GB-hash
with SHA-256 and HF-hash.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5535</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5535</id><created>2010-11-24</created><updated>2011-05-21</updated><authors><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author><author><keyname>Houshmand</keyname><forenames>Monireh</forenames></author><author><keyname>Hosseini-Khayat</keyname><forenames>Saied</forenames></author></authors><title>Examples of minimal-memory, non-catastrophic quantum convolutional
  encoders</title><categories>quant-ph cs.IT math.IT</categories><comments>5 pages, 2 figures, Accepted for the International Symposium on
  Information Theory 2011 (ISIT 2011), St. Petersburg, Russia; v2 has minor
  changes</comments><journal-ref>Proceedings of the International Symposium on Information Theory
  2011 (ISIT 2011), pp. 450--454, St. Petersburg, Russia</journal-ref><doi>10.1109/ISIT.2011.6034166</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most important open questions in the theory of quantum
convolutional coding is to determine a minimal-memory, non-catastrophic,
polynomial-depth convolutional encoder for an arbitrary quantum convolutional
code. Here, we present a technique that finds quantum convolutional encoders
with such desirable properties for several example quantum convolutional codes
(an exposition of our technique in full generality will appear elsewhere). We
first show how to encode the well-studied Forney-Grassl-Guha (FGG) code with an
encoder that exploits just one memory qubit (the former Grassl-Roetteler
encoder requires 15 memory qubits). We then show how our technique can find an
online decoder corresponding to this encoder, and we also detail the operation
of our technique on a different example of a quantum convolutional code.
Finally, the reduction in memory for the FGG encoder makes it feasible to
simulate the performance of a quantum turbo code employing it, and we present
the results of such simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5537</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5537</id><created>2010-11-24</created><updated>2011-12-05</updated><authors><author><keyname>Adlakha</keyname><forenames>Sachin</forenames></author><author><keyname>Johari</keyname><forenames>Ramesh</forenames></author><author><keyname>Weintraub</keyname><forenames>Gabriel Y.</forenames></author></authors><title>Equilibria of Dynamic Games with Many Players: Existence, Approximation,
  and Market Structure</title><categories>cs.GT</categories><comments>61 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study stochastic dynamic games with many players; these are
a fundamental model for a wide range of economic applications. The standard
solution concept for such games is Markov perfect equilibrium (MPE), but it is
well known that MPE computation becomes intractable as the number of players
increases. We instead consider the notion of stationary equilibrium (SE), where
players optimize assuming the empirical distribution of others' states remains
constant at its long run average. We make two main contributions. First, we
provide a rigorous justification for using SE. In particular, we provide a
parsimonious collection of exogenous conditions over model primitives that
guarantee existence of SE, and ensure that an appropriate approximation
property to MPE holds, in a general model with possibly unbounded state spaces.
Second, we draw a significant connection between the validity of SE, and market
structure: under the same conditions that imply SE exist and approximates MPE
well, the market becomes fragmented in the limit of many firms. To illustrate
this connection, we study in detail a series of dynamic oligopoly examples.
These examples show that our conditions enforce a form of &quot;decreasing returns
to larger states&quot;; this yields fragmented industries in the limit. By contrast,
violation of these conditions suggests &quot;increasing returns to larger states&quot;
and potential market concentration. In that sense, our work uses a fully
dynamic framework to also contribute to a longstanding issue in industrial
organization: understanding the determinants of market structure in different
industries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5545</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5545</id><created>2010-11-24</created><authors><author><keyname>Zhao</keyname><forenames>Shangwei</forenames></author><author><keyname>Feng</keyname><forenames>Ruyong</forenames></author><author><keyname>Gao</keyname><forenames>Xiao-Shan</forenames></author></authors><title>On Functional Decomposition of Multivariate Polynomials with
  Differentiation and Homogenization</title><categories>cs.CR cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we give a theoretical analysis for the algorithms to compute
functional decomposition for multivariate polynomials based on differentiation
and homogenization which are proposed by Ye, Dai, Lam (1999) and Faug$\mu$ere,
Perret (2006, 2008, 2009). We show that a degree proper functional
decomposition for a set of randomly decomposable quartic homogenous polynomials
can be computed using the algorithm with high probability. This solves a
conjecture proposed by Ye, Dai, and Lam (1999). We also propose a conjecture
such that the decomposition for a set of polynomials can be computed from that
of its homogenization with high probability. Finally, we prove that the right
decomposition factors for a set of polynomials can be computed from its right
decomposition factor space. Combining these results together, we prove that the
algorithm can compute a degree proper decomposition for a set of randomly
decomposable quartic polynomials with probability one when the base field is of
characteristic zero, and with probability close to one when the base field is a
finite field with sufficiently large number under the assumption that the
conjeture is correct.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5549</identifier>
 <datestamp>2011-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5549</id><created>2010-11-24</created><updated>2011-11-10</updated><authors><author><keyname>Mozes</keyname><forenames>Shay</forenames></author><author><keyname>Sommer</keyname><forenames>Christian</forenames></author></authors><title>Exact Distance Oracles for Planar Graphs</title><categories>cs.DS cs.DM</categories><comments>To appear in the proceedings of the 23rd ACM-SIAM Symposium on
  Discrete Algorithms, SODA 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present new and improved data structures that answer exact node-to-node
distance queries in planar graphs. Such data structures are also known as
distance oracles. For any directed planar graph on n nodes with non-negative
lengths we obtain the following:
  * Given a desired space allocation $S\in[n\lg\lg n,n^2]$, we show how to
construct in $\tilde O(S)$ time a data structure of size $O(S)$ that answers
distance queries in $\tilde O(n/\sqrt S)$ time per query.
  As a consequence, we obtain an improvement over the fastest algorithm for
k-many distances in planar graphs whenever $k\in[\sqrt n,n)$.
  * We provide a linear-space exact distance oracle for planar graphs with
query time $O(n^{1/2+eps})$ for any constant eps&gt;0. This is the first such data
structure with provable sublinear query time.
  * For edge lengths at least one, we provide an exact distance oracle of space
$\tilde O(n)$ such that for any pair of nodes at distance D the query time is
$\tilde O(min {D,\sqrt n})$. Comparable query performance had been observed
experimentally but has never been explained theoretically.
  Our data structures are based on the following new tool: given a
non-self-crossing cycle C with $c = O(\sqrt n)$ nodes, we can preprocess G in
$\tilde O(n)$ time to produce a data structure of size $O(n \lg\lg c)$ that can
answer the following queries in $\tilde O(c)$ time: for a query node u, output
the distance from u to all the nodes of C. This data structure builds on and
extends a related data structure of Klein (SODA'05), which reports distances to
the boundary of a face, rather than a cycle.
  The best distance oracles for planar graphs until the current work are due to
Cabello (SODA'06), Djidjev (WG'96), and Fakcharoenphol and Rao (FOCS'01). For
$\sigma\in(1,4/3)$ and space $S=n^\sigma$, we essentially improve the query
time from $n^2/S$ to $\sqrt{n^2/S}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5553</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5553</id><created>2010-11-25</created><updated>2013-08-13</updated><authors><author><keyname>Gortler</keyname><forenames>Steven J.</forenames></author><author><keyname>Gotsman</keyname><forenames>Craig</forenames></author><author><keyname>Liu</keyname><forenames>Ligang</forenames></author><author><keyname>Thurston</keyname><forenames>Dylan P.</forenames></author></authors><title>On affine rigidity</title><categories>cs.CG</categories><comments>Updated abstract</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We define the notion of affine rigidity of a hypergraph and prove a variety
of fundamental results for this notion. First, we show that affine rigidity can
be determined by the rank of a specific matrix which implies that affine
rigidity is a generic property of the hypergraph.Then we prove that if a graph
is is $(d+1)$-vertex-connected, then it must be &quot;generically neighborhood
affinely rigid&quot; in $d$-dimensional space. This implies that if a graph is
$(d+1)$-vertex-connected then any generic framework of its squared graph must
be universally rigid.
  Our results, and affine rigidity more generally, have natural applications in
point registration and localization, as well as connections to manifold
learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5566</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5566</id><created>2010-11-25</created><authors><author><keyname>Dau</keyname><forenames>Son Hoang</forenames></author><author><keyname>Skachek</keyname><forenames>Vitaly</forenames></author><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author></authors><title>Secure Index Coding with Side Information</title><categories>cs.IT cs.CR cs.NI math.IT</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Security aspects of the Index Coding with Side Information (ICSI) problem are
investigated. Building on the results of Bar-Yossef et al. (2006), the
properties of linear coding schemes for the ICSI problem are further explored.
The notion of weak security, considered by Bhattad and Narayanan (2005) in the
context of network coding, is generalized to block security. It is shown that
the coding scheme for the ICSI problem based on a linear code C of length n,
minimum distance d and dual distance d^\perp, is (d-1-t)-block secure (and
hence also weakly secure) if the adversary knows in advance t \le d - 2
messages, and is completely insecure if the adversary knows in advance more
than n - d^\perp messages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5567</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5567</id><created>2010-11-25</created><authors><author><keyname>Beimel</keyname><forenames>Amos</forenames></author><author><keyname>Omri</keyname><forenames>Eran</forenames></author><author><keyname>Orlov</keyname><forenames>Ilan</forenames></author></authors><title>Secure Multiparty Computation with Partial Fairness</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A protocol for computing a functionality is secure if an adversary in this
protocol cannot cause more harm than in an ideal computation where parties give
their inputs to a trusted party which returns the output of the functionality
to all parties. In particular, in the ideal model such computation is fair --
all parties get the output. Cleve (STOC 1986) proved that, in general, fairness
is not possible without an honest majority. To overcome this impossibility,
Gordon and Katz (Eurocrypt 2010) suggested a relaxed definition -- 1/p-secure
computation -- which guarantees partial fairness. For two parties, they
construct 1/p-secure protocols for functionalities for which the size of either
their domain or their range is polynomial (in the security parameter). Gordon
and Katz ask whether their results can be extended to multiparty protocols.
  We study 1/p-secure protocols in the multiparty setting for general
functionalities. Our main result is constructions of 1/p-secure protocols when
the number of parties is constant provided that less than 2/3 of the parties
are corrupt. Our protocols require that either (1) the functionality is
deterministic and the size of the domain is polynomial (in the security
parameter), or (2) the functionality can be randomized and the size of the
range is polynomial. If the size of the domain is constant and the
functionality is deterministic, then our protocol is efficient even when the
number of parties is O(log log n) (where n is the security parameter). On the
negative side, we show that when the number of parties is super-constant,
1/p-secure protocols are not possible when the size of the domain is
polynomial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5568</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5568</id><created>2010-11-25</created><authors><author><keyname>Heien</keyname><forenames>Eric M.</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Kondo</keyname><forenames>Derrick</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>David</keyname><forenames>Anderson</forenames><affiliation>SSL</affiliation></author></authors><title>Correlated Resource Models of Internet End Hosts</title><categories>cs.DC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding and modelling resources of Internet end hosts is essential for
the design of desktop software and Internet-distributed applications. In this
paper we develop a correlated resource model of Internet end hosts based on
real trace data taken from the SETI@home project. This data covers a 5-year
period with statistics for 2.7 million hosts. The resource model is based on
statistical analysis of host computational power, memory, and storage as well
as how these resources change over time and the correlations between them. We
find that resources with few discrete values (core count, memory) are well
modeled by exponential laws governing the change of relative resource
quantities over time. Resources with a continuous range of values are well
modeled with either correlated normal distributions (processor speed for
integer operations and floating point operations) or log-normal distributions
(available disk space). We validate and show the utility of the models by
applying them to a resource allocation problem for Internet-distributed
applications, and demonstrate their value over other models. We also make our
trace data and tool for automatically generating realistic Internet end hosts
publicly available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5599</identifier>
 <datestamp>2011-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5599</id><created>2010-11-25</created><updated>2011-01-26</updated><authors><author><keyname>Boldi</keyname><forenames>Paolo</forenames></author><author><keyname>Rosa</keyname><forenames>Marco</forenames></author><author><keyname>Vigna</keyname><forenames>Sebastiano</forenames></author></authors><title>HyperANF: Approximating the Neighbourhood Function of Very Large Graphs
  on a Budget</title><categories>cs.DS cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The neighbourhood function N(t) of a graph G gives, for each t, the number of
pairs of nodes &lt;x, y&gt; such that y is reachable from x in less that t hops. The
neighbourhood function provides a wealth of information about the graph (e.g.,
it easily allows one to compute its diameter), but it is very expensive to
compute it exactly. Recently, the ANF algorithm (approximate neighbourhood
function) has been proposed with the purpose of approximating NG(t) on large
graphs. We describe a breakthrough improvement over ANF in terms of speed and
scalability. Our algorithm, called HyperANF, uses the new HyperLogLog counters
and combines them efficiently through broadword programming; our implementation
uses overdecomposition to exploit multi-core parallelism. With HyperANF, for
the first time we can compute in a few hours the neighbourhood function of
graphs with billions of nodes with a small error and good confidence using a
standard workstation. Then, we turn to the study of the distribution of the
shortest paths between reachable nodes (that can be efficiently approximated by
means of HyperANF), and discover the surprising fact that its index of
dispersion provides a clear-cut characterisation of proper social networks vs.
web graphs. We thus propose the spid (Shortest-Paths Index of Dispersion) of a
graph as a new, informative statistics that is able to discriminate between the
above two types of graphs. We believe this is the first proposal of a
significant new non-local structural index for complex networks whose
computation is highly scalable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5606</identifier>
 <datestamp>2013-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5606</id><created>2010-11-25</created><updated>2013-04-22</updated><authors><author><keyname>Boudec</keyname><forenames>Jean-Yves Le</forenames></author><author><keyname>Tomozei</keyname><forenames>Dan-Cristian</forenames></author></authors><title>Stability of a Stochastic Model for Demand-Response</title><categories>cs.SY math.OC</categories><comments>Published in Stochastic Systems journal</comments><msc-class>60J05, 93E15</msc-class><acm-class>G.3</acm-class><doi>10.1214/11-SSY048</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the stability of a Markovian model of electricity production and
consumption that incorporates production volatility due to renewables and
uncertainty about actual demand versus planned production. We assume that the
energy producer targets a fixed energy reserve, subject to ramp-up and
ramp-down constraints, and that appliances are subject to demand-response
signals and adjust their consumption to the available production by delaying
their demand. When a constant fraction of the delayed demand vanishes over
time, we show that the general state Markov chain characterizing the system is
positive Harris and ergodic (i.e., delayed demand is bounded with high
probability). However, when delayed demand increases by a constant fraction
over time, we show that the Markov chain is non-positive (i.e., there exists a
non-zero probability that delayed demand becomes unbounded). We exhibit
Lyapunov functions to prove our claims. In addition, we provide examples of
heating appliances that, when delayed, have energy requirements corresponding
to the two considered cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5610</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5610</id><created>2010-11-25</created><authors><author><keyname>Mertikopoulos</keyname><forenames>Panayotis</forenames></author><author><keyname>Belmega</keyname><forenames>Elena V.</forenames></author><author><keyname>Moustakas</keyname><forenames>Aris L.</forenames></author><author><keyname>Lasaulce</keyname><forenames>Samson</forenames></author></authors><title>Dynamic Power Allocation Games in Parallel Multiple Access Channels</title><categories>cs.GT cs.NI</categories><comments>18 pages, 4 figures, submitted to Valuetools '11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the distributed power allocation problem in parallel multiple
access channels (MAC) by studying an associated non-cooperative game which
admits an exact potential. Even though games of this type have been the subject
of considerable study in the literature, we find that the sufficient conditions
which ensure uniqueness of Nash equilibrium points typically do not hold in
this context. Nonetheless, we show that the parallel MAC game admits a unique
equilibrium almost surely, thus establishing an important class of
counterexamples where these sufficient conditions are not necessary.
Furthermore, if the network's users employ a distributed learning scheme based
on the replicator dynamics, we show that they converge to equilibrium from
almost any initial condition, even though users only have local information at
their disposal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5640</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5640</id><created>2010-11-25</created><authors><author><keyname>Carlsson</keyname><forenames>Mats</forenames></author><author><keyname>Mildner</keyname><forenames>Per</forenames></author></authors><title>SICStus Prolog -- the first 25 years</title><categories>cs.PL</categories><comments>To appear in Theory and Practice of Logic Programming (TPLP)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  SICStus Prolog has evolved for nearly 25 years. This is an appropriate point
in time for revisiting the main language and design decisions, and try to
distill some lessons. SICStus Prolog was conceived in a context of multiple,
conflicting Prolog dialect camps and a fledgling standardization effort. We
reflect on the impact of this effort and role model implementations on our
development. After summarizing the development history, we give a guided tour
of the system anatomy, exposing some designs that were not published before. We
give an overview of our new interactive development environment, and describe a
sample of key applications. Finally, we try to identify key good and not so
good design decisions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5650</identifier>
 <datestamp>2011-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5650</id><created>2010-11-25</created><updated>2011-10-25</updated><authors><author><keyname>Chan</keyname><forenames>Ron T. L.</forenames></author><author><keyname>Hubbert</keyname><forenames>Simon</forenames></author></authors><title>A Numerical Study of Radial Basis Function Based Methods for Options
  Pricing under the One Dimension Jump-diffusion Model</title><categories>q-fin.CP cs.NA q-fin.PR</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The aim of this chapter is to show how option prices in jump-diffusion models
can be computed using meshless methods based on Radial Basis Function (RBF)
interpolation. The RBF technique is demonstrated by solving the partial
integro-differential equation (PIDE) in one-dimension for the American put and
the European vanilla call/put options on dividend-paying stocks in the Merton
and Kou jump-diffusion models. The radial basis function we select is the Cubic
Spline. We also propose a simple numerical algorithm for finding a finite
computational range of an improper integral term in the PIDE so that the
accuracy of approximation of the integral can be improved. Moreover, the
solution functions of the PIDE are approximated explicitly by RBFs which have
exact forms so we can easily compute the global integral by any kind of
numerical quadrature. Finally, we will not only show numerically that our
scheme is second order accurate in both spatial and time variables in a
European case but also second order accurate in spatial variables and first
order accurate in time variables in an American case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5656</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5656</id><created>2010-11-25</created><authors><author><keyname>Tolk</keyname><forenames>Andreas</forenames></author></authors><title>Using the C4ISR Architecture Framework as a Tool to Facilitate VV&amp;A for
  Simulation Systems within the Military Application Domain</title><categories>cs.OH</categories><comments>Foundations for V&amp;V in the 21st Century Workshop; Laurel, Maryland,
  October 2002</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To harmonize the individual architectures of the different commands,
services, and agencies dealing with the development and procurement of Command,
Control, Communications, Computing, Surveillance, Reconnaissance, and
Intelligence (C4ISR) systems, the C4ISR Architecture Framework was developed
based on existing and matured modeling techniques and methods. Within a short
period, NATO adapted this method family as the NATO Consultation, Command, and
Control (C3) System Architecture Framework to harmonize the efforts of the
different nations. Based on these products, for every system to be fielded to
be used in the US Armed Forces, a C4I Support Plan (C4ISP) has to be developed
enabling the integration of the special system into the integrated C4I
Architecture. The tool set proposed by these architecture frameworks connects
operational views of the military user, system views of the developers, and the
technical views for standards and integration methods needed to make the
network centric system of systems work. The tools are therefore logically a
valuable backbone for Verification, Validation, and Accreditation (VV&amp;A). Their
application is not limited to C4ISR systems; they can be used to define
requirements and connected solutions and algorithms of Modeling and Simulation
(M&amp;S) systems as well. Especially for M&amp;S systems to be used in connection with
C4ISR system, the use of the C4ISR Architecture Framework would not only be a
help, but can nearly be seen to be necessary to avoid double work and foster
reuse and interoperability from the first stages of a project on. To enable the
reader to build his own picture, the respective tools used and their
application in the context of VV&amp;A will be explained in form of an overview.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5661</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5661</id><created>2010-11-25</created><authors><author><keyname>Tolk</keyname><forenames>Andreas</forenames></author><author><keyname>Kunde</keyname><forenames>Dietmar</forenames></author></authors><title>Decision Support Systems - Technical Prerequisites and Military
  Requirements</title><categories>cs.OH</categories><comments>2000 Command and Control Research and Technology Symposium, Monterey,
  California, June 2000</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Decision Support Systems in the sense of online alternative course of action
(ACAO) development and analysis as well as tools for online Development of
Doctrine and Tactics Techniques, and Procedures (DTTP) for support to
operations make it possible to evaluate and forecast the command and control
processes and the performance capabilities of the friendly and enemy forces and
other decision relevant factors, support the military commander (brigade and
higher) and his staff in their headquarter by increasing their ability to
identify own opportunities, support all phases of the command and control
process, use computer based, automatic and closed models, that can be adapted
to the current situation.
  Objective of the paper is to present the results of studies conducted in
Germany on behalf of the German Ministry of Defense with the objective to work
out the conceptual basis for decision support systems and to evaluate, how this
technique will influence the command and control system of the army of the
federal armed forces. In addition, international works are considered as well.
In this paper, technical and operational requirements are derived and described
in detail that have to be met in order to support the warfighter by integrated
means of applied Operations Research ranging from simple optimization
algorithms to complex simulation federations comprising different systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5666</identifier>
 <datestamp>2011-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5666</id><created>2010-11-25</created><updated>2011-06-12</updated><authors><author><keyname>Dadush</keyname><forenames>Daniel</forenames></author><author><keyname>Peikert</keyname><forenames>Chris</forenames></author><author><keyname>Vempala</keyname><forenames>Santosh</forenames></author></authors><title>Enumerative Lattice Algorithms in Any Norm via M-Ellipsoid Coverings</title><categories>cs.DS cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a novel algorithm for enumerating lattice points in any convex body,
and give applications to several classic lattice problems, including the
Shortest and Closest Vector Problems (SVP and CVP, respectively) and Integer
Programming (IP). Our enumeration technique relies on a classical concept from
asymptotic convex geometry known as the M-ellipsoid, and uses as a crucial
subroutine the recent algorithm of Micciancio and Voulgaris (STOC 2010) for
lattice problems in the l_2 norm. As a main technical contribution, which may
be of independent interest, we build on the techniques of Klartag (Geometric
and Functional Analysis, 2006) to give an expected 2^O(n)-time algorithm for
computing an M-ellipsoid for any n-dimensional convex body.
  As applications, we give deterministic 2^{O(n)}-time and -space algorithms
for solving exact SVP, and exact CVP when the target point is sufficiently
close to the lattice, on n-dimensional lattices in any (semi-)norm given an
M-ellipsoid of the unit ball. In many norms of interest, including all l_p
norms, an M-ellipsoid is computable in deterministic poly(n) time, in which
case these algorithms are fully deterministic. Here our approach may be seen as
a derandomization of the &quot;AKS sieve&quot; for exact SVP and CVP (Ajtai, Kumar, and
Sivakumar; STOC 2001 and CCC 2002).
  As a further application of our SVP algorithm, we derive an expected
O(f*(n))^n-time algorithm for Integer Programming, where f*(n) denotes the
optimal bound in the so-called &quot;flatness theorem,&quot; which satisfies f*(n) =
O(n^{4/3} \polylog(n)) and is conjectured to be f*(n)=\Theta(n). Our runtime
improves upon the previous best of O(n^{2})^{n} by Hildebrand and Koppe (2010).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5668</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5668</id><created>2010-11-25</created><authors><author><keyname>Chernov</keyname><forenames>Alexey</forenames></author></authors><title>On Theorem 2.3 in &quot;Prediction, Learning, and Games&quot; by Cesa-Bianchi and
  Lugosi</title><categories>cs.LG</categories><comments>3 pages; excerpt from arXiv:1005.1918, simplified and rewritten using
  the notation of the monograph by Cesa-Bianchi and Lugosi</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The note presents a modified proof of a loss bound for the exponentially
weighted average forecaster with time-varying potential. The regret term of the
algorithm is upper-bounded by sqrt{n ln(N)} (uniformly in n), where N is the
number of experts and n is the number of steps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5674</identifier>
 <datestamp>2012-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5674</id><created>2010-11-25</created><updated>2012-11-06</updated><authors><author><keyname>Ji</keyname><forenames>Bo</forenames></author><author><keyname>Joo</keyname><forenames>Changhee</forenames></author><author><keyname>Shroff</keyname><forenames>Ness B.</forenames></author></authors><title>Delay-Based Back-Pressure Scheduling in Multihop Wireless Networks</title><categories>cs.NI cs.PF</categories><comments>Accepted for publication in IEEE/ACM Transactions on Networking. A
  preliminary version of this work was presented at the IEEE INFOCOM 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scheduling is a critical and challenging resource allocation mechanism for
multihop wireless networks. It is well known that scheduling schemes that favor
links with larger queue length can achieve high throughput performance.
However, these queue-length-based schemes could potentially suffer from large
(even infinite) packet delays due to the well-known last packet problem,
whereby packets belonging to some flows may be excessively delayed due to lack
of subsequent packet arrivals. Delay-based schemes have the potential to
resolve this last packet problem by scheduling the link based on the delay the
packet has encountered. However, characterizing throughput-optimality of these
delay-based schemes has largely been an open problem in multihop wireless
networks (except in limited cases where the traffic is single-hop.) In this
paper, we investigate delay-based scheduling schemes for multihop traffic
scenarios with fixed routes. We develop a scheduling scheme based on a new
delay metric, and show that the proposed scheme achieves optimal throughput
performance. Further, we conduct simulations to support our analytical results,
and show that the delay-based scheduler successfully removes excessive packet
delays, while it achieves the same throughput region as the queue-length-based
scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5677</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5677</id><created>2010-11-25</created><authors><author><keyname>Adlakha</keyname><forenames>Sachin</forenames></author><author><keyname>Johari</keyname><forenames>Ramesh</forenames></author></authors><title>Mean Field Equilibrium in Dynamic Games with Complementarities</title><categories>cs.GT</categories><comments>56 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a class of stochastic dynamic games that exhibit strategic
complementarities between players; formally, in the games we consider, the
payoff of a player has increasing differences between her own state and the
empirical distribution of the states of other players. Such games can be used
to model a diverse set of applications, including network security models,
recommender systems, and dynamic search in markets. Stochastic games are
generally difficult to analyze, and these difficulties are only exacerbated
when the number of players is large (as might be the case in the preceding
examples).
  We consider an approximation methodology called mean field equilibrium to
study these games. In such an equilibrium, each player reacts to only the long
run average state of other players. We find necessary conditions for the
existence of a mean field equilibrium in such games. Furthermore, as a simple
consequence of this existence theorem, we obtain several natural monotonicity
properties. We show that there exist a &quot;largest&quot; and a &quot;smallest&quot; equilibrium
among all those where the equilibrium strategy used by a player is
nondecreasing, and we also show that players converge to each of these
equilibria via natural myopic learning dynamics; as we argue, these dynamics
are more reasonable than the standard best response dynamics. We also provide
sensitivity results, where we quantify how the equilibria of such games move in
response to changes in parameters of the game (e.g., the introduction of
incentives to players).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5687</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5687</id><created>2010-11-25</created><authors><author><keyname>Andrey</keyname><forenames>Kudinov</forenames></author></authors><title>Topological Modal Logics with Difference Modality</title><categories>math.LO cs.LO</categories><comments>Advances in Modal Logic, Volume 6, 2006</comments><journal-ref>Topological modal logics with difference modality. Advances in
  Modal Logic, Volume 6,pp 319-332, 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider propositional modal logic with two modal operators $\Box$ and
$\D$. In topological semantics $\Box$ is interpreted as an interior operator
and $\D$ as difference. We show that some important topological properties are
expressible in this language. In addition, we present a few logics and proofs
of f.m.p. and of completeness theorems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5694</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5694</id><created>2010-11-25</created><authors><author><keyname>Tiwari</keyname><forenames>Kaushik K</forenames></author></authors><title>Formulation Of A N-Degree Polynomial For Depth Estimation using a Single
  Image</title><categories>cs.CV math-ph math.MP physics.comp-ph physics.ed-ph physics.pop-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The depth of a visible surface of a scene is the distance between the surface
and the sensor. Recovering depth information from two-dimensional images of a
scene is an important task in computer vision that can assist numerous
applications such as object recognition, scene interpretation, obstacle
avoidance, inspection and assembly. Various passive depth computation
techniques have been developed for computer vision applications. They can be
classified into two groups. The first group operates using just one image. The
second group requires more than one image which can be acquired using either
multiple cameras or a camera whose parameters and positioning can be changed.
This project is aimed to find the real depth of the object from the camera
which had been used to click the photograph. An n-degree polynomial was
formulated, which maps the pixel depth of an image to the real depth. In order
to find the coefficients of the polynomial, an experiment was carried out for a
particular lens and thus, these coefficients are a unique feature of a
particular camera. The procedure explained in this report is a monocular
approach for estimation of depth of a scene. The idea involves mapping the
Pixel Depth of the object photographed in the image with the Real Depth of the
object from the camera lens with an interpolation function. In order to find
the parameters of the interpolation function, a set of lines with predefined
distance from camera is used, and then the distance of each line from the
bottom edge of the picture (as the origin line) is calculated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5696</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5696</id><created>2010-11-25</created><updated>2010-12-18</updated><authors><author><keyname>Pavlovic</keyname><forenames>Dusko</forenames></author></authors><title>Quantifying and qualifying trust: Spectral decomposition of trust
  networks</title><categories>cs.CR cs.IR</categories><comments>18 pages, 4 figures; FAST 2010. Version 2: corrected several typos,
  added a missing arrow in Fig 1, added 2 sentences to the Abstract</comments><acm-class>D.4.6; H.3.3; K.4.4; K.6.5</acm-class><doi>10.1007/978-3-642-19751-2_1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a previous FAST paper, I presented a quantitative model of the process of
trust building, and showed that trust is accumulated like wealth: the rich get
richer. This explained the pervasive phenomenon of adverse selection of trust
certificates, as well as the fragility of trust networks in general. But a
simple explanation does not always suggest a simple solution. It turns out that
it is impossible to alter the fragile distribution of trust without sacrificing
some of its fundamental functions. A solution for the vulnerability of trust
must thus be sought elsewhere, without tampering with its distribution. This
observation was the starting point of the present paper. It explores a
different method for securing trust: not by redistributing it, but by mining
for its sources. The method used to break privacy is thus also used to secure
trust. A high level view of the mining methods that connect the two is provided
in terms of *similarity networks*, and *spectral decomposition* of similarity
preserving maps. This view may be of independent interest, as it uncovers a
common conceptual and structural foundation of mathematical classification
theory on one hand, and of the spectral methods of graph clustering and data
mining on the other hand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5699</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5699</id><created>2010-11-25</created><authors><author><keyname>Koyuncu</keyname><forenames>Erdem</forenames></author><author><keyname>Jafarkhani</keyname><forenames>Hamid</forenames></author></authors><title>The Necessity of Relay Selection</title><categories>cs.IT math.IT</categories><comments>29 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We determine necessary conditions on the structure of symbol error rate (SER)
optimal quantizers for limited feedback beamforming in wireless networks with
one transmitter-receiver pair and R parallel amplify-and-forward relays. We
call a quantizer codebook &quot;small&quot; if its cardinality is less than R, and
&quot;large&quot; otherwise. A &quot;d-codebook&quot; depends on the power constraints and can be
optimized accordingly, while an &quot;i-codebook&quot; remains fixed. It was previously
shown that any i-codebook that contains the single-relay selection (SRS)
codebook achieves the full-diversity order, R. We prove the following:
  Every full-diversity i-codebook contains the SRS codebook, and thus is
necessarily large. In general, as the power constraints grow to infinity, the
limit of an optimal large d-codebook contains an SRS codebook, provided that it
exists. For small codebooks, the maximal diversity is equal to the codebook
cardinality. Every diversity-optimal small i-codebook is an orthogonal
multiple-relay selection (OMRS) codebook. Moreover, the limit of an optimal
small d-codebook is an OMRS codebook.
  We observe that SRS is nothing but a special case of OMRS for codebooks with
cardinality equal to R. As a result, we call OMRS as &quot;the universal necessary
condition&quot; for codebook optimality. Finally, we confirm our analytical findings
through simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5705</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5705</id><created>2010-11-25</created><updated>2012-07-13</updated><authors><author><keyname>Whitworth</keyname><forenames>B.</forenames></author></authors><title>The Light of Existence</title><categories>cs.OH</categories><comments>This is the third in a series of papers, the previous ones are
  available at http://brianwhitworth.com/BW-VRT2.pdf and at
  http://brianwhitworth.com/BW-VRT1.pdf The latest version of this one is
  always available at http://brianwhitworth.com/BW-VRT3.pdf</comments><report-no>Centre for Discrete Mathematics and Theoretical Computer Science
  Research Report 390</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This chapter derives the properties of light from the properties of
processing, including its ability to be both a wave and a particle, to respond
to objects it doesn't physically touch, to take all paths to a destination, to
choose a route after it arrives, and to spin both ways at once as it moves.
Here a photon is an entity program spreading as a processing wave of instances.
It becomes a &quot;particle&quot; if any part of it overloads the grid network that runs
it, causing the photon program to reboot and restart at a new node. The
&quot;collapse of the wave function&quot; is how quantum processing creates what we call
a physical photon. This informational approach gives insights into issues like
the law of least action, entanglement, superposition, counterfactuals, the
holographic principle and the measurement problem. The conceptual cost is that
physical reality is a quantum processing output, i.e. virtual.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5737</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5737</id><created>2010-11-26</created><authors><author><keyname>Habib</keyname><forenames>Michel</forenames></author><author><keyname>Stacho</keyname><forenames>Juraj</forenames></author></authors><title>Unique perfect phylogeny is NP-hard</title><categories>q-bio.PE cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We answer, in the affirmative, the following question proposed by Mike Steel
as a $100 challenge: &quot;Is the following problem NP-hard? Given a ternary
phylogenetic X-tree T and a collection Q of quartet subtrees on X, is T the
only tree that displays Q ?&quot;
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5739</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5739</id><created>2010-11-26</created><updated>2012-02-01</updated><authors><author><keyname>Popovski</keyname><forenames>Petar</forenames></author><author><keyname>Utkovski</keyname><forenames>Zoran</forenames></author></authors><title>Protocol Coding through Reordering of User Resources: Applications and
  Capacity Results</title><categories>cs.IT cs.NI math.IT</categories><comments>Replaced with a two-part paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While there are continuous efforts to introduce new communication systems and
standards, it is legitimate to ask the question: how can one send additional
bits by minimally changing the systems that are already operating? This is of a
significant practical interest, since it has a potential to generate additional
value of the systems through, for example, introduction of new devices and only
a software update of the access points or base stations, without incurring
additional cost for infrastructure hardware installation. The place to look for
such an opportunity is the communication protocol and we use the term *protocol
coding* to refer to strategies for sending information by using the degrees of
freedom available when one needs to decide the actions taken by a particular
communication protocol. In this paper we consider protocol coding that gives a
rise to *secondary communication channels*, defined by combinatorial ordering
of the user resources (packets, channels) in a primary (legacy) communication
system. We introduce communication models that enable us to compute the
capacity of such secondary channels under suitable restrictions imposed by the
primary systems. We first show the relation to the capacity of channels with
causal channel state information at the transmitter (CSIT), originally
considered by Shannon. By using the specific communication setup, we develop an
alternative framework for achieving the capacity and we discuss coding
strategies that need to be used over the secondary channels. We also discuss
some practical features of the secondary channels and their applications that
add value to the existing wireless systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5778</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5778</id><created>2010-11-26</created><authors><author><keyname>Marschall</keyname><forenames>Tobias</forenames></author><author><keyname>Herms</keyname><forenames>Inke</forenames></author><author><keyname>Kaltenbach</keyname><forenames>Hans-Michael</forenames></author><author><keyname>Rahmann</keyname><forenames>Sven</forenames></author></authors><title>Probabilistic Arithmetic Automata and their Applications</title><categories>cs.FL q-bio.QM</categories><msc-class>62P10, 68W32, 68W40, 68Q87, 92B05, 92C40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present probabilistic arithmetic automata (PAAs), a general model to
describe chains of operations whose operands depend on chance, along with two
different algorithms to exactly calculate the distribution of the results
obtained by such probabilistic calculations. PAAs provide a unifying framework
to approach many problems arising in computational biology and elsewhere. Here,
we present five different applications, namely (1) pattern matching statistics
on random texts, including the computation of the distribution of occurrence
counts, waiting time and clump size under HMM background models; (2) exact
analysis of window-based pattern matching algorithms; (3) sensitivity of
filtration seeds used to detect candidate sequence alignments; (4) length and
mass statistics of peptide fragments resulting from enzymatic cleavage
reactions; and (5) read length statistics of 454 sequencing reads. The
diversity of these applications indicates the flexibility and unifying
character of the presented framework.
  While the construction of a PAA depends on the particular application, we
single out a frequently applicable construction method for pattern statistics:
We introduce deterministic arithmetic automata (DAAs) to model deterministic
calculations on sequences, and demonstrate how to construct a PAA from a given
DAA and a finite-memory random text model. We show how to transform a finite
automaton into a DAA and then into the corresponding PAA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5808</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5808</id><created>2010-11-26</created><authors><author><keyname>Pregui&#xe7;a</keyname><forenames>Nuno</forenames></author><author><keyname>Baquero</keyname><forenames>Carlos</forenames></author><author><keyname>Almeida</keyname><forenames>Paulo S&#xe9;rgio</forenames></author><author><keyname>Fonte</keyname><forenames>Victor</forenames></author><author><keyname>Gon&#xe7;alves</keyname><forenames>Ricardo</forenames></author></authors><title>Dotted Version Vectors: Logical Clocks for Optimistic Replication</title><categories>cs.DC</categories><comments>Preprint, submitted for publication. 12 pages</comments><acm-class>C.2.4; E.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In cloud computing environments, a large number of users access data stored
in highly available storage systems. To provide good performance to
geographically disperse users and allow operation even in the presence of
failures or network partitions, these systems often rely on optimistic
replication solutions that guarantee only eventual consistency. In this
scenario, it is important to be able to accurately and efficiently identify
updates executed concurrently. In this paper, first we review, and expose
problems with current approaches to causality tracking in optimistic
replication: these either lose information about causality or do not scale, as
they require replicas to maintain information that grows linearly with the
number of clients or updates. Then, we propose a novel solution that fully
captures causality while being very concise in that it maintains information
that grows linearly only with the number of servers that register updates for a
given data element, bounded by the degree of replication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5814</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5814</id><created>2010-11-26</created><updated>2011-03-25</updated><authors><author><keyname>Dutta</keyname><forenames>Sagarmoy</forenames></author><author><keyname>Kurur</keyname><forenames>Piyush P</forenames></author></authors><title>Quantum Cyclic Code of length dividing $p^{t}+1$</title><categories>cs.IT math.IT</categories><comments>Improvement on the previous papaer titled &quot;Quantum Cyclic Codes&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study cyclic stabiliser codes over $\mathbb{F}_p$ of length
dividing $p^t+1$ for some positive integer $t$. We call these $t$-Frobenius
codes or just Frobenius codes for short. We give methods to construct them and
show that they have efficient decoding algorithms. An important subclass of
stabiliser codes are the linear stabiliser codes. For linear Frobenius codes we
have stronger results: We completely characterise all linear Frobenius codes.
As a consequence, we show that for every integer $n$ that divides $p^t+1$ for
an odd $t$, there are no linear cyclic codes of length $n$. On the other hand
for even $t$, we give an explicit method to construct all of them. This gives
us a many explicit example of Frobenius codes which include the well studied
Laflamme code. We show that the classical notion of BCH distance can be
generalised to all the Frobenius codes that we construct, including the
non-linear ones, and show that the algorithm of Berlekamp can be generalised to
correct quantum errors within the BCH limit. This gives, for the first time, a
family of codes that are neither CSS nor linear for which efficient decoding
algorithm exits. The explicit examples that we construct are summarised in
Table \ref{tab:explicit-examples-short} and explained in detail in Tables
\ref{tab:explicit-examples-2} (linear case) and \ref{tab:explicit-examples-3}
(non-linear case).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5841</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5841</id><created>2010-11-26</created><authors><author><keyname>Lemoine</keyname><forenames>Julien</forenames></author><author><keyname>Viennot</keyname><forenames>Simon</forenames></author></authors><title>Nimbers are inevitable</title><categories>math.CO cs.GT</categories><comments>12 pages, 11 figures</comments><msc-class>91A46</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article concerns the resolution of impartial combinatorial games, and in
particular games that can be split in sums of independent positions. We prove
that in order to compute the outcome of a sum of independent positions, it is
always more efficient to compute separately the nimbers of each independent
position than to develop directly the game tree of the sum. The concept of
nimber is therefore inevitable to solve impartial games, even when we only try
to determinate the winning or losing outcome of a starting position. We also
describe algorithms to use nimbers efficiently and finally, we give a review of
the results obtained on two impartial games: Sprouts and Cram.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5866</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5866</id><created>2010-11-26</created><authors><author><keyname>Bailleux</keyname><forenames>Olivier</forenames></author></authors><title>Evolving difficult SAT instances thanks to local search</title><categories>cs.NE cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose to use local search algorithms to produce SAT instances which are
harder to solve than randomly generated k-CNF formulae. The first results,
obtained with rudimentary search algorithms, show that the approach deserves
further study. It could be used as a test of robustness for SAT solvers, and
could help to investigate how branching heuristics, learning strategies, and
other aspects of solvers impact there robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5894</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5894</id><created>2010-11-25</created><authors><author><keyname>Feier</keyname><forenames>Cristina</forenames></author><author><keyname>Heymans</keyname><forenames>Stijn</forenames></author></authors><title>An Optimization for Reasoning with Forest Logic Programs</title><categories>cs.LO</categories><comments>ASPOCP 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Open Answer Set Programming (OASP) is an attractive framework for integrating
ontologies and rules. In general OASP is undecidable. In previous work we
provided a tableau-based algorithm for satisfiability checking w.r.t. forest
logic programs, a decidable fragment of OASP, which has the forest model
property. In this paper we introduce an optimized version of that algorithm
achieved by means of a knowledge compilation technique. So-called unit
completion structures, which are possible building blocks of a forest model, in
the form of trees of depth 1, are computed in an initial step of the algorithm.
Repeated computations are avoided by using these structures in a
pattern-matching style when constructing a model. Furthermore we identify and
discard redundant unit completion structures: a structure is redundant if there
is another structure which can always replace the original structure in a
forest model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5914</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5914</id><created>2010-11-26</created><authors><author><keyname>Altshuler</keyname><forenames>Yaniv</forenames></author><author><keyname>Bruckstein</keyname><forenames>Alfred</forenames></author></authors><title>Static and Expanding Grid Coverage with Ant Robots : Complexity Results</title><categories>cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the strengths and limitations of collaborative teams
of simple agents. In particular, we discuss the efficient use of &quot;ant robots&quot;
for covering a connected region on the Z^{2} grid, whose area is unknown in
advance, and which expands at a given rate, where $n$ is the initial size of
the connected region.
  We show that regardless of the algorithm used, and the robots' hardware and
software specifications, the minimal number of robots required in order for
such coverage to be possible is \Omega({\sqrt{n}}).
  In addition, we show that when the region expands at a sufficiently slow
rate, a team of \Theta(\sqrt{n}) robots could cover it in at most O(n^{2} \ln
n) time.
  This completion time can even be achieved by myopic robots, with no ability
to directly communicate with each other, and where each robot is equipped with
a memory of size O(1) bits w.r.t the size of the region (therefore, the robots
cannot maintain maps of the terrain, nor plan complete paths).
  Regarding the coverage of non-expanding regions in the grid, we improve the
current best known result of O(n^{2}) by demonstrating an algorithm that
guarantees such a coverage with completion time of O(\frac{1}{k} n^{1.5} + n)
in the worst case, and faster for shapes of perimeter length which is shorter
than O(n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5920</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5920</id><created>2010-11-26</created><authors><author><keyname>Altshuler</keyname><forenames>Yaniv</forenames></author><author><keyname>Bruckstein</keyname><forenames>Alfred</forenames></author></authors><title>On Short Cuts - or - Fencing in Rectangular Strips</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider an isoperimetric inequality for the &quot;free
perimeter&quot; of a planar shape inside a rectangular domain, the free perimeter
being the length of the shape boundary that does not touch the border of the
domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5936</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5936</id><created>2010-11-26</created><authors><author><keyname>Wang</keyname><forenames>Meng</forenames></author><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Tang</keyname><forenames>Ao</forenames></author></authors><title>On the Performance of Sparse Recovery via L_p-minimization (0&lt;=p &lt;=1)</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that a high-dimensional sparse vector x* in R^n can be recovered
from low-dimensional measurements y= A^{m*n} x* (m&lt;n) . In this paper, we
investigate the recovering ability of l_p-minimization (0&lt;=p&lt;=1) as p varies,
where l_p-minimization returns a vector with the least l_p ``norm'' among all
the vectors x satisfying Ax=y. Besides analyzing the performance of strong
recovery where l_p-minimization needs to recover all the sparse vectors up to
certain sparsity, we also for the first time analyze the performance of
``weak'' recovery of l_p-minimization (0&lt;=p&lt;1) where the aim is to recover all
the sparse vectors on one support with fixed sign pattern. When m/n goes to 1,
we provide sharp thresholds of the sparsity ratio that differentiates the
success and failure via l_p-minimization. For strong recovery, the threshold
strictly decreases from 0.5 to 0.239 as p increases from 0 to 1. Surprisingly,
for weak recovery, the threshold is 2/3 for all p in [0,1), while the threshold
is 1 for l_1-minimization. We also explicitly demonstrate that l_p-minimization
(p&lt;1) can return a denser solution than l_1-minimization. For any m/n&lt;1, we
provide bounds of sparsity ratio for strong recovery and weak recovery
respectively below which l_p-minimization succeeds with overwhelming
probability. Our bound of strong recovery improves on the existing bounds when
m/n is large. Regarding the recovery threshold, l_p-minimization has a higher
threshold with smaller p for strong recovery; the threshold is the same for all
p for sectional recovery; and l_1-minimization can outperform l_p-minimization
for weak recovery. These are in contrast to traditional wisdom that
l_p-minimization has better sparse recovery ability than l_1-minimization since
it is closer to l_0-minimization. We provide an intuitive explanation to our
findings and use numerical examples to illustrate the theoretical predictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5950</identifier>
 <datestamp>2011-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5950</id><created>2010-11-27</created><authors><author><keyname>Danon</keyname><forenames>Leon</forenames></author><author><keyname>Ford</keyname><forenames>Ashley P.</forenames></author><author><keyname>House</keyname><forenames>Thomas</forenames></author><author><keyname>Jewell</keyname><forenames>Chris P.</forenames></author><author><keyname>Keeling</keyname><forenames>Matt J.</forenames></author><author><keyname>Roberts</keyname><forenames>Gareth O.</forenames></author><author><keyname>Ross</keyname><forenames>Joshua V.</forenames></author><author><keyname>Vernon</keyname><forenames>Matthew C.</forenames></author></authors><title>Networks and the Epidemiology of Infectious Disease</title><categories>physics.soc-ph cs.SI q-bio.PE</categories><comments>51 pages, 3 figure, submitted</comments><doi>10.1155/2011/284909</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The science of networks has revolutionised research into the dynamics of
interacting elements. It could be argued that epidemiology in particular has
embraced the potential of network theory more than any other discipline. Here
we review the growing body of research concerning the spread of infectious
diseases on networks, focusing on the interplay between network theory and
epidemiology. The review is split into four main sections, which examine: the
types of network relevant to epidemiology; the multitude of ways these networks
can be characterised; the statistical methods that can be applied to infer the
epidemiological parameters on a realised network; and finally simulation and
analytical methods to determine epidemic dynamics on a given network. Given the
breadth of areas covered and the ever-expanding number of publications, a
comprehensive review of all work is impossible. Instead, we provide a
personalised overview into the areas of network epidemiology that have seen the
greatest progress in recent years or have the greatest potential to provide
novel insights. As such, considerable importance is placed on analytical
approaches and statistical methods which are both rapidly expanding fields.
Throughout this review we restrict our attention to epidemiological issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5951</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5951</id><created>2010-11-27</created><authors><author><keyname>Saad</keyname><forenames>Emad</forenames></author></authors><title>Reinforcement Learning in Partially Observable Markov Decision Processes
  using Hybrid Probabilistic Logic Programs</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a probabilistic logic programming framework to reinforcement
learning, by integrating reinforce-ment learning, in POMDP environments, with
normal hybrid probabilistic logic programs with probabilistic answer set
seman-tics, that is capable of representing domain-specific knowledge. We
formally prove the correctness of our approach. We show that the complexity of
finding a policy for a reinforcement learning problem in our approach is
NP-complete. In addition, we show that any reinforcement learning problem can
be encoded as a classical logic program with answer set semantics. We also show
that a reinforcement learning problem can be encoded as a SAT problem. We
present a new high level action description language that allows the factored
representation of POMDP. Moreover, we modify the original model of POMDP so
that it be able to distinguish between knowledge producing actions and actions
that change the environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5962</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5962</id><created>2010-11-27</created><authors><author><keyname>Bouboulis</keyname><forenames>Pantelis</forenames></author><author><keyname>Theodoridis</keyname><forenames>Sergios</forenames></author></authors><title>Edge Preserving Image Denoising in Reproducing Kernel Hilbert Spaces</title><categories>cs.CV</categories><comments>This work has been selected for the Best Scientific Paper Award
  (Track III: Signal, Speech, Image and Video Processing) at the ICPR 2010</comments><journal-ref>Proceedings of the 20th International Conference on Pattern
  Recognition, Istanbul: Turkey, 23-26 August 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this paper is the development of a novel approach for the problem
of Noise Removal, based on the theory of Reproducing Kernels Hilbert Spaces
(RKHS). The problem is cast as an optimization task in a RKHS, by taking
advantage of the celebrated semiparametric Representer Theorem. Examples verify
that in the presence of gaussian noise the proposed method performs relatively
well compared to wavelet based technics and outperforms them significantly in
the presence of impulse or mixed noise.
  A more detailed version of this work has been published in the IEEE Trans.
Im. Proc. : P. Bouboulis, K. Slavakis and S. Theodoridis, Adaptive Kernel-based
Image Denoising employing Semi-Parametric Regularization, IEEE Transactions on
Image Processing, vol 19(6), 2010, 1465 - 1479.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5966</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5966</id><created>2010-11-27</created><authors><author><keyname>Asaeedi</keyname><forenames>Saeed</forenames></author><author><keyname>Didehvar</keyname><forenames>Farzad</forenames></author></authors><title>Enumeration Order complexity Equivalency</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Throughout this article we develop and change the definitions and the ideas
in &quot;arXiv:1006.4939&quot;, in order to consider the efficiency of functions and
complexity time problems. The central idea here is effective enumeration and
listing, and efficiency of function which is defined between two sets proposed
in basic definitions. More in detail, it might be that h and g were co-order
but the velocity of them be different.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5971</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5971</id><created>2010-11-27</created><authors><author><keyname>Mohammad-Nooria</keyname><forenames>M.</forenames></author><author><keyname>Ghareghanib</keyname><forenames>N.</forenames></author><author><keyname>Sharifani</keyname><forenames>P.</forenames></author></authors><title>On z-factorization and c-factorization of standard episturmian words</title><categories>cs.DM</categories><comments>10 pages</comments><msc-class>68R15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ziv-Lempel and Crochemore factorization are two kinds of factorizations of
words related to text processing. In this paper, we find these factorizations
for standard epiesturmian words. Thus the previously known c-factorization of
standard Sturmian words is provided as a special case. Moreover, the two
factorizations are compared.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.5987</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.5987</id><created>2010-11-27</created><authors><author><keyname>Lin</keyname><forenames>Shou-Pon</forenames></author><author><keyname>Jiang</keyname><forenames>Jhesyong</forenames></author><author><keyname>Lin</keyname><forenames>Wei-Ting</forenames></author><author><keyname>Yeh</keyname><forenames>Ping-Cheng</forenames></author><author><keyname>Su</keyname><forenames>Hsuan-Jung</forenames></author></authors><title>Prediction-based Adaptation (PRADA) Algorithm for Modulation and Coding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel adaptive modulation and coding (AMC)
algorithm dedicated to reduce the feedback frequency of the channel state
information (CSI). There have been already plenty of works on AMC so as to
exploit the bandwidth more efficiently with the CSI feedback to the
transmitter. However, in some occasions, frequent CSI feedback is not favorable
in these systems. This work considers finite-state Markov chain (FSMC) based
channel prediction to alleviate the feedback while maximizing the overall
throughput. We derive the close-form of the frame error rate (FER) based on
channel prediction using limited CSI feedback. In addition, instead of
switching settings according to the CSI, we also provide means to combine both
CSI and FER as the switching parameter. Numerical results illustrate that the
average throughput of the proposed algorithm has significant performance
improvement over fixed modulation and coding while the CSI feedback being
largely reduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6002</identifier>
 <datestamp>2014-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6002</id><created>2010-11-27</created><authors><author><keyname>Baldoni</keyname><forenames>Velleda</forenames></author><author><keyname>Berline</keyname><forenames>Nicole</forenames></author><author><keyname>K&#xf6;ppe</keyname><forenames>Matthias</forenames></author><author><keyname>Vergne</keyname><forenames>Mich&#xe8;le</forenames></author></authors><title>Intermediate Sums on Polyhedra: Computation and Real Ehrhart Theory</title><categories>math.CO cs.CG</categories><comments>24 pages, 3 figures</comments><msc-class>05A15 (Primary), 52C07, 68R05, 68U05, 52B20 (Secondary)</msc-class><doi>10.1112/S0025579312000101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study intermediate sums, interpolating between integrals and discrete
sums, which were introduced by A. Barvinok [Computing the Ehrhart
quasi-polynomial of a rational simplex, Math. Comp. 75 (2006), 1449--1466]. For
a given semi-rational polytope P and a rational subspace L, we integrate a
given polynomial function h over all lattice slices of the polytope P parallel
to the subspace L and sum up the integrals. We first develop an algorithmic
theory of parametric intermediate generating functions. Then we study the
Ehrhart theory of these intermediate sums, that is, the dependence of the
result as a function of a dilation of the polytope. We provide an algorithm to
compute the resulting Ehrhart quasi-polynomials in the form of explicit step
polynomials. These formulas are naturally valid for real (not just integer)
dilations and thus provide a direct approach to real Ehrhart theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6012</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6012</id><created>2010-11-27</created><authors><author><keyname>Fr&#xf6;schle</keyname><forenames>Sibylle</forenames><affiliation>University of Oldenburg</affiliation></author><author><keyname>Valencia</keyname><forenames>Frank D.</forenames><affiliation>CNRS and LIX &#xc9;cole Polytechnique</affiliation></author></authors><title>Proceedings 17th International Workshop on Expressiveness in Concurrency</title><categories>cs.LO</categories><proxy>EPTCS</proxy><acm-class>F.1.1; F.1.2; F.3.0; F.4.0</acm-class><journal-ref>EPTCS 41, 2010</journal-ref><doi>10.4204/EPTCS.41</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the 17th International Workshop on
Expressiveness in Concurrency (EXPRESS'10), which took place on 30th August
2010 in Paris, co-located with CONCUR'10. The EXPRESS workshop series aim at
bringing together researchers who are interested in the expressiveness and
comparison of formal models that broadly relate to concurrency. In particular,
this also includes emergent fields such as logic and interaction,
game-theoretic models, and service-oriented computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6017</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6017</id><created>2010-11-28</created><authors><author><keyname>Li</keyname><forenames>Di</forenames></author><author><keyname>Yin</keyname><forenames>Changchuan</forenames></author><author><keyname>Chen</keyname><forenames>Changhai</forenames></author></authors><title>A Selection Region Based Routing Protocol for Random Mobile ad hoc
  Networks with Directional Antennas</title><categories>cs.IT math.IT</categories><comments>5 pages, 5 figures, IEEE GLOBECOM 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a selection region based multihop routing protocol
with directional antennas for wireless mobile ad hoc networks, where the
selection region is defined by two parameters: a reference distance and the
beamwidth of the directional antenna. At each hop, we choose the nearest node
to the transmitter within the selection region as the next hop relay. By
maximizing the expected density of progress, we present an upper bound for the
optimum reference distance and derive the relationship between the optimum
reference distance and the optimum transmission probability. Compared with the
results with routing strategy using omnidirectional antennas in
\cite{Di:Relay-Region}, we find interestingly that the optimum transmission
probability is a constant independent of the beamwidth, the expected density of
progress with the new routing strategy is increased significantly, and the
computational complexity involved in the relay selection is also greatly
reduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6021</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6021</id><created>2010-11-28</created><authors><author><keyname>Ananth</keyname><forenames>Prabhanjan V.</forenames></author><author><keyname>Dukkipati</keyname><forenames>Ambedkar</forenames></author></authors><title>Border basis detection is NP-complete</title><categories>cs.CC</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Border basis detection (BBD) is described as follows: given a set of
generators of an ideal, decide whether that set of generators is a border basis
of the ideal with respect to some order ideal. The motivation for this problem
comes from a similar problem related to Gr\&quot;obner bases termed as Gr\&quot;obner
basis detection (GBD) which was proposed by Gritzmann and Sturmfels (1993). GBD
was shown to be NP-hard by Sturmfels and Wiegelmann (1996). In this paper, we
investigate the computational complexity of BBD and show that it is
NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6022</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6022</id><created>2010-11-28</created><updated>2011-07-18</updated><authors><author><keyname>Sher</keyname><forenames>Gene I.</forenames></author></authors><title>DXNN Platform: The Shedding of Biological Inefficiencies</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel type of memetic algorithm based Topology and
Weight Evolving Artificial Neural Network (TWEANN) system called DX Neural
Network (DXNN). DXNN implements a number of interesting features, amongst which
is: a simple and database friendly tuple based encoding method, a 2 phase
neuroevolutionary approach aimed at removing the need for speciation due to its
intrinsic population diversification effects, a new &quot;Targeted Tuning Phase&quot;
aimed at dealing with &quot;the curse of dimensionality&quot;, and a new Random Intensity
Mutation (RIM) method that removes the need for crossover algorithms. The paper
will discuss DXNN's architecture, mutation operators, and its built in feature
selection method that allows for the evolved systems to expand and incorporate
new sensors and actuators. I then compare DXNN to other state of the art
TWEANNs on the standard double pole balancing benchmark, and demonstrate its
superior ability to evolve highly compact solutions faster than its
competitors. Then a set of oblation experiments is performed to demonstrate how
each feature of DXNN effects its performance, followed by a set of experiments
which demonstrate the platform's ability to create NN populations with
exceptionally high diversity profiles. Finally, DXNN is used to evolve
artificial robots in a set of two dimensional open-ended food gathering and
predator-prey simulations, demonstrating the system's ability to produce ever
more complex Neural Networks, and the system's applicability to the domain of
robotics, artificial life, and coevolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6029</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6029</id><created>2010-11-28</created><authors><author><keyname>Legrand</keyname><forenames>Thomas</forenames><affiliation>IRISA</affiliation></author><author><keyname>Cousin</keyname><forenames>Bernard</forenames><affiliation>IRISA</affiliation></author><author><keyname>Brochier</keyname><forenames>Nicolas</forenames><affiliation>FT R&amp;D</affiliation></author></authors><title>Performance Evaluation of the Labelled OBS Architecture</title><categories>cs.NI</categories><proxy>ccsd</proxy><journal-ref>Seventh International Conference on Wireless and Optical
  Communications Networks (WOCN 2010), Colombo : Sri Lanka (2010)</journal-ref><doi>10.1109/WOCN.2010.5587310</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A comparison of three different Optical Burst Switching (OBS) architectures
is made, in terms of performance criteria, control and hardware complexity,
fairness, resource utilization, and burst loss probability. Regarding burst
losses, we distinguish the losses due to burst contentions from those due to
contentions of Burst Control Packets (BCP). The simulation results show that as
a counterpart of an its additional hardware complexity, the labelled OBS
(L-OBS) is an efficient OBS architecture compared to a Conventional OBS (C-OBS)
as well as in comparison with Offset Time-Emulated OBS (E-OBS).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6030</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6030</id><created>2010-11-28</created><authors><author><keyname>Jawhar</keyname><forenames>Shadi</forenames><affiliation>IRISA</affiliation></author><author><keyname>Cousin</keyname><forenames>Bernard</forenames><affiliation>IRISA</affiliation></author></authors><title>Optical Multicast Routing Under Light Splitter Constraints</title><categories>cs.NI</categories><proxy>ccsd</proxy><journal-ref>7th International Conference on Information Technology : New
  Generations (ITNG 2010), Las Vegas : United States (2010)</journal-ref><doi>10.1109/ITNG.2010.168</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During the past few years, we have observed the emergence of new applications
that use multicast transmission. For a multicast routing algorithm to be
applicable in optical networks, it must route data only to group members,
optimize and maintain loop-free routes, and concentrate the routes on a subset
of network links. For an all-optical switch to play the role of a branching
router, it must be equipped with a light splitter. Light splitters are
expensive equipments and therefore it will be very expensive to implement
splitters on all optical switches. Optical light splitters are only implemented
on some optical switches. That limited availability of light splitters raises a
new problem when we want to implement multicast protocols in optical network
(because usual multicast protocols make the assumption that all nodes have
branching capabilities). Another issue is the knowledge of the locations of
light splitters in the optical network. Nodes in the network should be able to
identify the locations of light splitters scattered in the optical network so
it can construct multicast trees. These problems must be resolved by
implementing a multicast routing protocol that must take into consideration
that not all nodes can be branching node. As a result, a new signaling process
must be implemented so that light paths can be created, spanning from source to
the group members.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6031</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6031</id><created>2010-11-28</created><authors><author><keyname>Cass&#xe9;</keyname><forenames>Hugues</forenames><affiliation>IRIT</affiliation></author><author><keyname>Heydemann</keyname><forenames>Karine</forenames><affiliation>LIP6</affiliation></author><author><keyname>Ozaktas</keyname><forenames>Haluk</forenames><affiliation>LIP6</affiliation></author><author><keyname>Ponroy</keyname><forenames>Jonathan</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Rochange</keyname><forenames>Christine</forenames><affiliation>IRIT</affiliation></author><author><keyname>Zendra</keyname><forenames>Olivier</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>A framework to experiment optimizations for real-time and embedded
  software</title><categories>cs.PF</categories><comments>International Conference on Embedded Real Time Software and Systems
  (ERTS2), Toulouse : France (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Typical constraints on embedded systems include code size limits, upper
bounds on energy consumption and hard or soft deadlines. To meet these
requirements, it may be necessary to improve the software by applying various
kinds of transformations like compiler optimizations, specific mapping of code
and data in the available memories, code compression, etc. However, a
transformation that aims at improving the software with respect to a given
criterion might engender side effects on other criteria and these effects must
be carefully analyzed. For this purpose, we have developed a common framework
that makes it possible to experiment various code transfor-mations and to
evaluate their impact of various criteria. This work has been carried out
within the French ANR MORE project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6044</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6044</id><created>2010-11-28</created><authors><author><keyname>Rakotondrainibe</keyname><forenames>Lahatra</forenames><affiliation>IETR</affiliation></author><author><keyname>Kokar</keyname><forenames>Yvan</forenames><affiliation>IETR</affiliation></author><author><keyname>Zaharia</keyname><forenames>Gheorghe</forenames><affiliation>IETR</affiliation></author><author><keyname>Grunfelder</keyname><forenames>Guy</forenames><affiliation>IETR</affiliation></author><author><keyname>Zein</keyname><forenames>Gha&#xef;s El</forenames><affiliation>IETR</affiliation></author></authors><title>Single Carrier Architecture for High Data Rate Wireless PAN
  Communications System</title><categories>cs.NI</categories><comments>Design, Experimentation, Measurement, Performance; IWCMC '10, Caen :
  France (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A 60 GHz wireless Gigabit Ethernet (G.E.) communication system is developed
at IETR. As the 60 GHz radio link operates only in a single-room configuration,
an additional Radio over Fibre (RoF) link is used to ensure the communications
in all the rooms of a residential environment. The realized system covers 2 GHz
bandwidth. Due to the hardware constraints, a symbol rate at 875 Mbps is
attained using simple single carrier architecture. In the baseband (BB)
processing block, an original byte/frame synchronization process is designed to
provide a smaller value of the preamble missing detection and false alarm
probabilities. Bit error rate (BER) measurements have been realized in a large
gym for line-of-sight (LOS) conditions. A Tx-Rx distance greater than 30 meters
was attained with low BER using high gain antennas and forward error correction
RS (255, 239) coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6045</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6045</id><created>2010-11-28</created><authors><author><keyname>Rakotondrainibe</keyname><forenames>Lahatra</forenames><affiliation>IETR</affiliation></author><author><keyname>Kokar</keyname><forenames>Yvan</forenames><affiliation>IETR</affiliation></author><author><keyname>Zaharia</keyname><forenames>Gheorghe</forenames><affiliation>IETR</affiliation></author><author><keyname>Grunfelder</keyname><forenames>Guy</forenames><affiliation>IETR</affiliation></author><author><keyname>Zein</keyname><forenames>Gha&#xef;s El</forenames><affiliation>IETR</affiliation></author></authors><title>Performance Analysis of a 60 GHz Near Gigabit System for WPAN
  Applications</title><categories>cs.NI</categories><proxy>ccsd</proxy><journal-ref>PIMRC 2010, Istambul : Turkey (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A 60 GHz wireless Gigabit Ethernet (G.E.) communication system capable of
near gigabit data rate has been developed at IETR. The realized system covers 2
GHz available bandwidth. This paper describes the design and realization of the
overall system including the baseband (BB), intermediate frequency (IF) and
radiofrequency (RF) blocks. A differential binary shift keying (DBPSK)
modulation and a differential demodulation are adopted at IF. In the BB
processing block, an original byte/frame synchronization technique is designed
to provide a small value of the preamble false alarm and missing probabilities.
For the system performances, two different real scenarios are investigated:
measurements carried out in a large gym and in hallways. Bit error rate (BER)
measurements have been performed in different configurations: with/without RS
(255, 239) coding, with frame synchronization using 32/64 bits preambles. As
shown by simulation, the 64 bits preamble provides sufficient robustness and
improves the system performance in term of BER. At a data rate of 875 Mbps, a
BER of 10-8 was measured at 30 m using high gain antennas for line of-sight
(LOS) conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6047</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6047</id><created>2010-11-28</created><authors><author><keyname>Nanz</keyname><forenames>Sebastian</forenames></author><author><keyname>Torshizi</keyname><forenames>Faraz</forenames></author><author><keyname>Pedroni</keyname><forenames>Michela</forenames></author><author><keyname>Meyer</keyname><forenames>Bertrand</forenames></author></authors><title>A Comparative Study of the Usability of Two Object-oriented Concurrent
  Programming Languages</title><categories>cs.PL</categories><journal-ref>Information and Software Technology, 55(7):1304-1315, Elsevier,
  2013</journal-ref><doi>10.1016/j.infsof.2012.08.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Concurrency has been rapidly gaining importance in general-purpose computing,
caused by the recent turn towards multicore processing architectures. As a
result, an increasing number of developers have to learn to write concurrent
programs, a task that is known to be hard even for the expert. Language
designers are therefore working on languages that promise to make concurrent
programming &quot;easier&quot; than using traditional thread libraries. However, the
claim that a new language is more usable than another cannot be supported by
purely theoretical considerations, but calls for empirical studies. In this
paper, we present the design of a study to compare concurrent programming
languages with respect to comprehending and debugging existing programs and
writing correct new programs. A critical challenge for such a study is avoiding
the bias that might be introduced during the training phase and when
interpreting participants' solutions. We address these issues by the use of
self-study material and an evaluation scheme that exposes any subjective
decisions of the corrector, or eliminates them altogether. We apply our design
to a comparison of two object-oriented languages for concurrency, multithreaded
Java and SCOOP (Simple Concurrent Object-Oriented Programming), in an academic
setting. We obtain results in favor of SCOOP even though the study participants
had previous training in Java Threads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6049</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6049</id><created>2010-11-28</created><authors><author><keyname>Houit</keyname><forenames>Thomas</forenames></author><author><keyname>Nielsen</keyname><forenames>Frank</forenames></author></authors><title>Video Stippling</title><categories>cs.GR cs.CG</categories><comments>12 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider rendering color videos using a non-photo-realistic
art form technique commonly called stippling. Stippling is the art of rendering
images using point sets, possibly with various attributes like sizes,
elementary shapes, and colors. Producing nice stippling is attractive not only
for the sake of image depiction but also because it yields a compact vectorial
format for storing the semantic information of media. Moreover, stippling is by
construction easily tunable to various device resolutions without suffering
from bitmap sampling artifacts when resizing. The underlying core technique for
stippling images is to compute a centroidal Voronoi tessellation on a
well-designed underlying density. This density relates to the image content,
and is used to compute a weighted Voronoi diagram. By considering videos as
image sequences and initializing properly the stippling of one image by the
result of its predecessor, one avoids undesirable point flickering artifacts
and can produce stippled videos that nevertheless still exhibit noticeable
artifacts. To overcome this, our method improves over the naive scheme by
considering dynamic point creation and deletion according to the current scene
semantic complexity, and show how to effectively vectorize video while
adjusting for both color and contrast characteristics. Furthermore, we explain
how to produce high quality stippled ``videos'' (eg., fully dynamic
spatio-temporal point sets) for media containing various fading effects, like
quick motions of objects or progressive shot changes. We report on practical
performances of our implementation, and present several stippled video results
rendered on-the-fly using our viewer that allows both spatio-temporal dynamic
rescaling (eg., upscale vectorially frame rate).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6057</identifier>
 <datestamp>2013-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6057</id><created>2010-11-28</created><updated>2013-01-23</updated><authors><author><keyname>Plaumann</keyname><forenames>Daniel</forenames></author><author><keyname>Sturmfels</keyname><forenames>Bernd</forenames></author><author><keyname>Vinzant</keyname><forenames>Cynthia</forenames></author></authors><title>Computing Linear Matrix Representations of Helton-Vinnikov Curves</title><categories>math.AG cs.CG math.OC</categories><comments>19 pages, 3 figures, minor revisions; Mathematical Methods in
  Systems, Optimization and Control, Birkhauser, Basel</comments><msc-class>14Q05</msc-class><journal-ref>Operator Theory: Advances and Applications, Vol 222, 2012, pp.
  259-277</journal-ref><doi>10.1007/978-3-0348-0411-0_19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Helton and Vinnikov showed that every rigidly convex curve in the real plane
bounds a spectrahedron. This leads to the computational problem of explicitly
producing a symmetric (positive definite) linear determinantal representation
for a given curve. We study three approaches to this problem: an algebraic
approach via solving polynomial equations, a geometric approach via contact
curves, and an analytic approach via theta functions. These are explained,
compared, and tested experimentally for low degree instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6075</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6075</id><created>2010-11-28</created><authors><author><keyname>Ekambaram</keyname><forenames>Venkatesan</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>Distributed High Accuracy Peer-to-Peer Localization in Mobile Multipath
  Environments</title><categories>cs.IT cs.DC cs.NI math.IT math.OC</categories><comments>5 pages, 5 figures, Accepted at IEEE Globecom 2010, Miami, FL</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of high accuracy localization of mobile
nodes in a multipath-rich environment where sub-meter accuracies are required.
We employ a peer to peer framework where the vehicles/nodes can get pairwise
multipath-degraded ranging estimates in local neighborhoods together with a
fixed number of anchor nodes. The challenge is to overcome the
multipath-barrier with redundancy in order to provide the desired accuracies
especially under severe multipath conditions when the fraction of received
signals corrupted by multipath is dominating. We invoke a message passing
analytical framework based on particle filtering and reveal its high accuracy
localization promise through simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6076</identifier>
 <datestamp>2014-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6076</id><created>2010-11-28</created><updated>2011-06-25</updated><authors><author><keyname>Arnaudon</keyname><forenames>Marc</forenames><affiliation>LMA</affiliation></author><author><keyname>Nielsen</keyname><forenames>Frank</forenames><affiliation>LIX</affiliation></author></authors><title>Medians and means in Finsler geometry</title><categories>math.DG cs.CG</categories><proxy>ccsd</proxy><doi>10.1112/S1461157010000513</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate existence and uniqueness of p-means and the median of a
probability measure on a Finsler manifold, in relation with the convexity of
the support of the measure. We prove that the p-mean is the limit point of a
continuous time gradient flow. Under some additional condition which is always
satisfied for larger than or equal to 2, a discretization of this path
converges to the p-mean. This provides an algorithm for determining those
Finsler center points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6086</identifier>
 <datestamp>2012-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6086</id><created>2010-11-28</created><authors><author><keyname>Theis</keyname><forenames>Lucas</forenames></author><author><keyname>Gerwinn</keyname><forenames>Sebastian</forenames></author><author><keyname>Sinz</keyname><forenames>Fabian</forenames></author><author><keyname>Bethge</keyname><forenames>Matthias</forenames></author></authors><title>In All Likelihood, Deep Belief Is Not Enough</title><categories>stat.ML cs.LG</categories><journal-ref>Journal of Machine Learning Research 12, 3071-3096, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statistical models of natural stimuli provide an important tool for
researchers in the fields of machine learning and computational neuroscience. A
canonical way to quantitatively assess and compare the performance of
statistical models is given by the likelihood. One class of statistical models
which has recently gained increasing popularity and has been applied to a
variety of complex data are deep belief networks. Analyses of these models,
however, have been typically limited to qualitative analyses based on samples
due to the computationally intractable nature of the model likelihood.
Motivated by these circumstances, the present article provides a consistent
estimator for the likelihood that is both computationally tractable and simple
to apply in practice. Using this estimator, a deep belief network which has
been suggested for the modeling of natural image patches is quantitatively
investigated and compared to other models of natural image patches. Contrary to
earlier claims based on qualitative results, the results presented in this
article provide evidence that the model under investigation is not a
particularly good model for natural images
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6100</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6100</id><created>2010-11-28</created><authors><author><keyname>Berman</keyname><forenames>Piotr</forenames></author><author><keyname>Bhattacharyya</keyname><forenames>Arnab</forenames></author><author><keyname>Grigorescu</keyname><forenames>Elena</forenames></author><author><keyname>Raskhodnikova</keyname><forenames>Sofya</forenames></author><author><keyname>Woodruff</keyname><forenames>David</forenames></author><author><keyname>Yaroslavtsev</keyname><forenames>Grigory</forenames></author></authors><title>Steiner Transitive-Closure Spanners of d-Dimensional Posets</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a directed graph G and an integer k &gt;= 1, a
k-transitive-closure-spanner (k-TCspanner) of G is a directed graph H that has
(1) the same transitive-closure as G and (2) diameter at most k. In some
applications, the shortcut paths added to the graph in order to obtain small
diameter can use Steiner vertices, that is, vertices not in the original graph
G. The resulting spanner is called a Steiner transitive-closure spanner
(Steiner TC-spanner).
  Motivated by applications to property reconstruction and access control
hierarchies, we concentrate on Steiner TC-spanners of directed acyclic graphs
or, equivalently, partially ordered sets. In these applications, the goal is to
find a sparsest Steiner k-TC-spanner of a poset G for a given k and G. The
focus of this paper is the relationship between the dimension of a poset and
the size of its sparsest Steiner TCspanner. The dimension of a poset G is the
smallest d such that G can be embedded into a d-dimensional directed hypergrid
via an order-preserving embedding.
  We present a nearly tight lower bound on the size of Steiner 2-TC-spanners of
d-dimensional directed hypergrids. It implies better lower bounds on the
complexity of local reconstructors of monotone functions and functions with low
Lipschitz constant. The proof of the lower bound constructs a dual solution to
a linear programming relaxation of the Steiner 2-TC-spanner problem. We also
show that one can efficiently construct a Steiner 2-TC-spanner, of size
matching the lower bound, for any low-dimensional poset. Finally, we present a
lower bound on the size of Steiner k-TC-spanners of d-dimensional posets that
shows that the best-known construction, due to De Santis et al., cannot be
improved significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6121</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6121</id><created>2010-11-28</created><authors><author><keyname>Park</keyname><forenames>Juho</forenames></author><author><keyname>Sung</keyname><forenames>Youngchul</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>On Beamformer Design for Multiuser MIMO Interference Channels</title><categories>cs.IT math.IT</categories><comments>30 pages, 5 figures. Submitted to IEEE Transactions on Information
  Theory</comments><acm-class>E.4; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers several linear beamformer design paradigms for multiuser
time-invariant multiple-input multiple-output interference channels. Notably,
interference alignment and sum-rate based algorithms such as the maximum
signal-to-interference-plus noise (max-SINR) algorithm are considered. Optimal
linear beamforming under interference alignment consists of two layers; an
inner precoder and decoder (or receive filter) accomplish interference
alignment to eliminate inter-user interference, and an outer precoder and
decoder diagonalize the effective single-user channel resulting from the
interference alignment by the inner precoder and decoder. The relationship
between this two-layer beamforming and the max-SINR algorithm is established at
high signal-to-noise ratio. Also, the optimality of the max-SINR algorithm
within the class of linear beamforming algorithms, and its local convergence
with exponential rate, are established at high signal-to-noise ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6127</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6127</id><created>2010-11-28</created><authors><author><keyname>Morbidi</keyname><forenames>Fabio</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author><author><keyname>Prattichizzo</keyname><forenames>Domenico</forenames></author></authors><title>Visibility maintenance via controlled invariance for leader-follower
  Dubins-like vehicles</title><categories>cs.MA</categories><comments>17 pages, 24 figures, extended version of the journal paper of the
  authors submitted to Automatica</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper studies the visibility maintenance problem (VMP) for a
leader-follower pair of Dubins-like vehicles with input constraints, and
proposes an original solution based on the notion of controlled invariance. The
nonlinear model describing the relative dynamics of the vehicles is interpreted
as linear uncertain system, with the leader robot acting as an external
disturbance. The VMP is then reformulated as a linear constrained regulation
problem with additive disturbances (DLCRP). Positive D-invariance conditions
for linear uncertain systems with parametric disturbance matrix are introduced
and used to solve the VMP when box bounds on the state, control input and
disturbance are considered. The proposed design procedure is shown to be easily
adaptable to more general working scenarios. Extensive simulation results are
provided to illustrate the theory and show the effectiveness of our approach
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6129</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6129</id><created>2010-11-29</created><authors><author><keyname>Agarwal</keyname><forenames>Sachin</forenames></author></authors><title>Toward a Push-Scalable Global Internet</title><categories>cs.NI</categories><comments>6 pages, also visit http://sites.google.com/site/sachinkagarwal/home</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Push message delivery, where a client maintains an ``always-on'' connection
with a server in order to be notified of a (asynchronous) message arrival in
real-time, is increasingly being used in Internet services. The key message in
this paper is that push message delivery on the World Wide Web is not scalable
for servers, intermediate network elements, and battery-operated mobile device
clients. We present a measurement analysis of a commercially deployed WWW push
email service to highlight some of these issues. Next, we suggest content-based
optimization to reduce the always-on connection requirement of push messaging.
Our idea is based on exploiting the periodic nature of human-to-human
messaging. We show how machine learning can accurately model the times of a day
or week when messages are least likely to arrive; and turn off always-on
connections these times. We apply our approach to a real email data set and our
experiments demonstrate that the number of hours of active always-on
connections can be cut by half while still achieving real-time message delivery
for up to 90% of all messages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6134</identifier>
 <datestamp>2012-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6134</id><created>2010-11-29</created><updated>2012-03-29</updated><authors><author><keyname>Wilkens</keyname><forenames>Christopher A.</forenames></author><author><keyname>Sivan</keyname><forenames>Balasubramanian</forenames></author></authors><title>Single-Call Mechanisms</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Truthfulness is fragile and demanding. It is oftentimes computationally
harder than solving the original problem. Even worse, truthfulness can be
utterly destroyed by small uncertainties in a mechanism's outcome. One obstacle
is that truthful payments depend on outcomes other than the one realized, such
as the lengths of non-shortest-paths in a shortest-path auction. Single-call
mechanisms are a powerful tool that circumvents this obstacle --- they
implicitly charge truthful payments, guaranteeing truthfulness in expectation
using only the outcome realized by the mechanism. The cost of such truthfulness
is a trade-off between the expected quality of the outcome and the risk of
large payments.
  We largely settle when and to what extent single-call mechanisms are
possible. The first single-call construction was discovered by Babaioff,
Kleinberg, and Slivkins [BKS10] in single-parameter domains. They give a
transformation that turns any monotone, single-parameter allocation rule into a
truthful-in-expectation single-call mechanism. Our first result is a natural
complement to [BKS10]: we give a new transformation that produces a single-call
VCG mechanism from any allocation rule for which VCG payments are truthful.
Second, in both the single-parameter and VCG settings, we precisely
characterize the possible transformations, showing that that a wide variety of
transformations are possible but that all take a very simple form. Finally, we
study the inherent trade-off between the expected quality of the outcome and
the risk of large payments. We show that our construction and that of [BKS10]
simultaneously optimize a variety of metrics in their respective domains.
  As an example, we analyze pay-per-click advertising auctions, where the
truthfulness of the standard VCG-based auction is easily broken when the
auctioneer's estimated click-through-rates are imprecise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6180</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6180</id><created>2010-11-29</created><authors><author><keyname>Bhatia</keyname><forenames>Gaurav</forenames></author><author><keyname>Kumar</keyname><forenames>Vivek</forenames></author></authors><title>Adapting MAC 802.11 Adapting MAC 802.11 for Performance Optimization of
  MANET using Cross Layer Interaction</title><categories>cs.NI</categories><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.2,
  No.4, November 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this research, we study the optimization challenges of MANET and
cross-layer technique to improve its performance. We propose an adaptive
retransmission limits algorithm for IEEE 802.11 MAC to reduce the false link
failures and predict the node mobility. We implemented cross layer interaction
between physical and MAC layers. The MAC layer utilizes the physical layer
information for differentiating false link failure from true link failure. The
MAC layer adaptively selects a retransmission limit (short and long) based on
the neighbour signal strength and sender node speed information from the
physical layer. The proposed approach tracks the signal strength of each node
in network and, while transmitting to a neighbour node, if it's received signal
strength is high and is received recently then Adaptive MAC persists in its
retransmission attempts. As there is high probability that neighbour node is
still in transmission range and may be not responding due to some problems
other then mobility. In this paper, we evaluate the performance of MANET and
show that how our Adaptive MAC greatly improves it. The simulation is done
using Network Simulator NS-2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6181</identifier>
 <datestamp>2011-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6181</id><created>2010-11-29</created><updated>2011-01-13</updated><authors><author><keyname>Yuster</keyname><forenames>Raphael</forenames></author></authors><title>Computing the diameter polynomially faster than APSP</title><categories>cs.DS</categories><comments>revised to handle negative weights; faster algorithm for positive
  weights; added observation regarding the unweighted case</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new randomized algorithm for computing the diameter of a
weighted directed graph. The algorithm runs in
$\Ot(M^{\w/(\w+1)}n^{(\w^2+3)/(\w+1)})$ time, where $\w &lt; 2.376$ is the
exponent of fast matrix multiplication, $n$ is the number of vertices of the
graph, and the edge weights are integers in $\{-M,...,0,...,M\}$. For bounded
integer weights the running time is $O(n^{2.561})$ and if $\w=2+o(1)$ it is
$\Ot(n^{7/3})$. This is the first algorithm that computes the diameter of an
integer weighted directed graph polynomially faster than any known All-Pairs
Shortest Paths (APSP) algorithm. For bounded integer weights, the fastest
algorithm for APSP runs in $O(n^{2.575})$ time for the present value of $\w$
and runs in $\Ot(n^{2.5})$ time if $\w=2+o(1)$.
  For directed graphs with {\em positive} integer weights in $\{1,...,M\}$ we
obtain a deterministic algorithm that computes the diameter in $\Ot(Mn^\w)$
time. This extends a simple $\Ot(n^\w)$ algorithm for computing the diameter of
an {\em unweighted} directed graph to the positive integer weighted setting and
is the first algorithm in this setting whose time complexity matches that of
the fastest known Diameter algorithm for {\em undirected} graphs.
  The diameter algorithms are consequences of a more general result. We
construct algorithms that for any given integer $d$, report all ordered pairs
of vertices having distance {\em at most} $d$. The diameter can therefore be
computed using binary search for the smallest $d$ for which all pairs are
reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6187</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6187</id><created>2010-11-29</created><authors><author><keyname>Schmidt</keyname><forenames>Jens M.</forenames></author></authors><title>Contractions, Removals and How to Certify 3-Connectivity in Linear Time</title><categories>cs.DS cs.DM</categories><comments>preliminary version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well-known as an existence result that every 3-connected graph G=(V,E)
on more than 4 vertices admits a sequence of contractions and a sequence of
removal operations to K_4 such that every intermediate graph is 3-connected. We
show that both sequences can be computed in optimal time, improving the
previously best known running times of O(|V|^2) to O(|V|+|E|). This settles
also the open question of finding a linear time 3-connectivity test that is
certifying and extends to a certifying 3-edge-connectivity test in the same
time. The certificates used are easy to verify in time O(|E|).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6218</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6218</id><created>2010-11-29</created><authors><author><keyname>Thai</keyname><forenames>Chan Dai Truyen</forenames></author><author><keyname>Popovski</keyname><forenames>Petar</forenames></author><author><keyname>Kaneko</keyname><forenames>Megumi</forenames></author><author><keyname>de Carvalho</keyname><forenames>Elisabeth</forenames></author></authors><title>Coordinated Transmissions to Direct and Relayed Users in Wireless
  Cellular Systems</title><categories>cs.IT cs.NI math.IT</categories><comments>5 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ideas of wireless network coding at the physical layer promise high
throughput gains in wireless systems with relays and multi-way traffic flows.
This gain can be ascribed to two principles: (1) joint transmission of multiple
communication flows and (2) usage of \emph{a priori} information to cancel the
interference. In this paper we use these principles to devise new transmission
schemes in wireless cellular systems that feature both users served directly by
the base stations (direct users) and users served through relays (relayed
users). We present four different schemes for \emph{coordinated transmission}
of uplink and downlink traffic in which one direct and one relayed user are
served. These schemes are then used as building blocks in multi-user scenarios,
where we present several schemes for scheduling pairs of users for coordinated
transmissions. The optimal scheme involves exhaustive search of the best user
pair in terms of overall rate. We propose several suboptimal scheduling
schemes, which perform closely to the optimal scheme. The numerical results
show a substantial increase in the system--level rate with respect to the
systems with non--coordinated transmissions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6220</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6220</id><created>2010-11-29</created><authors><author><keyname>Sasidhar</keyname><forenames>K.</forenames></author><author><keyname>Kakulapati</keyname><forenames>Vijaya L</forenames></author><author><keyname>Ramakrishna</keyname><forenames>Kolikipogu</forenames></author><author><keyname>KailasaRao</keyname><forenames>K.</forenames></author></authors><title>Multimodal Biometric Systems - Study to Improve Accuracy and Performance</title><categories>cs.AI</categories><comments>8 pages,5 figures, published in International Journal of Computer
  Science &amp; Engineering Survey (IJCSES) Vol.1, No.2, November 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Biometrics is the science and technology of measuring and analyzing
biological data of human body, extracting a feature set from the acquired data,
and comparing this set against to the template set in the database.
Experimental studies show that Unimodal biometric systems had many
disadvantages regarding performance and accuracy. Multimodal biometric systems
perform better than unimodal biometric systems and are popular even more
complex also. We examine the accuracy and performance of multimodal biometric
authentication systems using state of the art Commercial Off- The-Shelf (COTS)
products. Here we discuss fingerprint and face biometric systems, decision and
fusion techniques used in these systems. We also discuss their advantage over
unimodal biometric systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6223</identifier>
 <datestamp>2011-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6223</id><created>2010-11-29</created><updated>2011-09-27</updated><authors><author><keyname>Meurer</keyname><forenames>Benedikt</forenames></author></authors><title>Just-In-Time compilation of OCaml byte-code</title><categories>cs.PL cs.PF</categories><comments>15 pages, 6 figures, 3 tables</comments><acm-class>D.3.3; D.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents various improvements that were applied to OCamlJIT2, a
Just-In-Time compiler for the OCaml byte-code virtual machine. OCamlJIT2
currently runs on various Unix-like systems with x86 or x86-64 processors. The
improvements, including the new x86 port, are described in detail, and
performance measures are given, including a direct comparison of OCamlJIT2 to
OCamlJIT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6224</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6224</id><created>2010-11-29</created><authors><author><keyname>Britsch</keyname><forenames>Markward</forenames><affiliation>Max-Planck-Institut f&#xfc;r Kernphysik</affiliation></author><author><keyname>Gagunashvili</keyname><forenames>Nikolai</forenames><affiliation>University of Akureyri</affiliation></author><author><keyname>Schmelling</keyname><forenames>Michael</forenames><affiliation>Max-Planck-Institut f&#xfc;r Kernphysik</affiliation></author></authors><title>Classifying extremely imbalanced data sets</title><categories>physics.data-an cs.LG hep-ex stat.ML</categories><journal-ref>PoS ACAT2010:047,2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Imbalanced data sets containing much more background than signal instances
are very common in particle physics, and will also be characteristic for the
upcoming analyses of LHC data. Following up the work presented at ACAT 2008, we
use the multivariate technique presented there (a rule growing algorithm with
the meta-methods bagging and instance weighting) on much more imbalanced data
sets, especially a selection of D0 decays without the use of particle
identification. It turns out that the quality of the result strongly depends on
the number of background instances used for training. We discuss methods to
exploit this in order to improve the results significantly, and how to handle
and reduce the size of large training sets without loss of result quality in
general. We will also comment on how to take into account statistical
fluctuation in receiver operation characteristic curves (ROC) for comparing
classifier methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6232</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6232</id><created>2010-11-29</created><authors><author><keyname>Singha</keyname><forenames>Chitta Ranjan</forenames></author></authors><title>A Proximity based Retransmission Scheme for Power Line Ad-hoc LAN</title><categories>cs.NI</categories><comments>Already published in IJDPS</comments><journal-ref>International Journal of Distributed and Parallel Systems (IJDPS)
  Vol.1, No.2, November 2010</journal-ref><doi>10.5121/ijdps.2010.1203</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Power line as an alternative for data transmission is being explored, and
also being used to a certain extent. But from the data transfer point of view,
power line, as a channel is highly dynamic and hence not quite suitable. To
convert the office or home wiring system to a Local Area Network (LAN),
adaptive changes are to be made to the existing protocols. In this paper, a
slotted transmission scheme is suggested, in which usable timeslots are found
out by physically sensing the media. Common usable timeslots for the
sender-receiver pair are used for communication. But these will not ensure safe
packet delivery since packets may be corrupted on the way during propagation
from sender to receiver. Therefore, we also suggest a proximity based
retransmission scheme where each machine in the LAN, buffers good packet and
machines close to the receiver retransmit on receiving a NACK.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6239</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6239</id><created>2010-11-29</created><updated>2011-08-11</updated><authors><author><keyname>Cygan</keyname><forenames>Marek</forenames></author><author><keyname>Philip</keyname><forenames>Geevarghese</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Marcin</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Micha&#x142;</forenames></author><author><keyname>Wojtaszczyk</keyname><forenames>Jakub Onufry</forenames></author></authors><title>Dominating Set is Fixed Parameter Tractable in Claw-free Graphs</title><categories>cs.DS cs.CC</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the dominating set problem parameterized by solution size is
fixed-parameter tractable (FPT) in graphs that do not contain the claw
(K(1,3)), the complete bipartite graph on four vertices where the two parts
have one and three vertices, respectively) as an induced subgraph. We present
an algorithm that uses 2^O(k^2)n^O(1) time and polynomial space to decide
whether a claw-free graph on n vertices has a dominating set of size at most k.
Note that this parameterization of dominating set is W[2]-hard on the set of
all graphs, and thus is unlikely to have an FPT algorithm for graphs in
general. The most general class of graphs for which an FPT algorithm was
previously known for this parameterization of dominating set is the class of
K(i,j)-free graphs, which exclude, for some fixed i,j, the complete bipartite
graph K(i,j) as a subgraph. For i,i &gt;= 2, the class of claw-free graphs and any
class of K(i,j)-free graphs are not comparable with respect to set inclusion.
We thus extend the range of graphs over which this parameterization of
dominating set is known to be fixed-parameter tractable. We also show that, in
some sense, it is the presence of the claw that makes this parameterization of
the dominating set problem hard. More precisely, we show that for any t ?&gt;= 4,
the dominating set problem parameterized by the solution size is W[2]-hard in
graphs that exclude the t-claw K(1,t) as an induced subgraph. Our arguments
also imply that the related connected dominating set and dominating clique
problems are W[2]-hard in these graph classes. Finally, we show that for any t,
the clique problem parameterized by solution size, which is W[1]-hard on
general graphs, is FPT in t-claw-free graphs. Our results add to the small and
growing collection of FPT results for graph classes defined by excluded
subgraphs, rather than by excluded minors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6242</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6242</id><created>2010-11-29</created><authors><author><keyname>Cesmelioglu</keyname><forenames>Ayca</forenames></author><author><keyname>McGuire</keyname><forenames>Gary</forenames></author><author><keyname>Meidl</keyname><forenames>Wilfried</forenames></author></authors><title>A Construction of Weakly and Non-Weakly Regular Bent Functions</title><categories>math.CO cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article a technique for constructing $p$-ary bent functions from
near-bent functions is presented. Two classes of quadratic $p$-ary functions
are shown to be near-bent. Applying the construction of bent functions to these
classes of near-bent functions yields classes of non-quadratic bent functions.
We show that one construction in even dimension yields weakly regular bent
functions. For other constructions, we obtain both weakly regular and
non-weakly regular bent functions. In particular we present the first known
infinite class of non-weakly regular bent functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6266</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6266</id><created>2010-11-24</created><authors><author><keyname>Jensen</keyname><forenames>Pablo</forenames></author><author><keyname>Rouquier</keyname><forenames>Jean-Baptiste</forenames></author><author><keyname>Ovtracht</keyname><forenames>Nicolas</forenames></author><author><keyname>Robardet</keyname><forenames>C&#xe9;line</forenames></author></authors><title>Characterizing the speed and paths of shared bicycles in Lyon</title><categories>cs.SI</categories><journal-ref>Transportation Research Part D: Transport and Environment,
  15(8):522 - 524, 2010</journal-ref><doi>10.1016/j.trd.2010.07.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Thanks to numerical data gathered by Lyon's shared bicycling system V\'elo'v,
we are able to analyze 11.6 millions bicycle trips, leading to the first robust
characterization of urban bikers' behaviors. We show that bicycles outstrip
cars in downtown Lyon, by combining high speed and short paths.These data also
allows us to calculate V\'elo'v fluxes on all streets, pointing to interesting
locations for bike paths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6267</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6267</id><created>2010-11-29</created><authors><author><keyname>Razgon</keyname><forenames>Igor</forenames></author></authors><title>Computing multiway cut within the given excess over the largest minimum
  isolating cut</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $(G,T)$ be an instance of the (vertex) multiway cut problem where $G$ is
a graph and $T$ is a set of terminals. For $t \in T$, a set of nonterminal
vertices separating $t$ from $T \setminus \{T\}$ is called an \emph{isolating
cut} of $t$. The largest among all the smallest isolating cuts is a natural
lower bound for a multiway cut of $(G,T)$. Denote this lower bound by $m$ and
let $k$ be an integer.
  In this paper we propose an $O(kn^{k+3})$ algorithm that computes a multiway
cut of $(G,T)$ of size at most $m+k$ or reports that there is no such multiway
cut. The core of the proposed algorithm is the following combinatorial result.
Let $G$ be a graph and let $X,Y$ be two disjoint subsets of vertices of $G$.
Let $m$ be the smallest size of a vertex $X-Y$ separator. Then, for the given
integer $k$, the number of \emph{important} $X-Y$ separators \cite{MarxTCS} of
size at most $m+k$ is at most $\sum_{i=0}^k{n \choose i}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6268</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6268</id><created>2010-11-29</created><authors><author><keyname>Mitrovi&#x107;</keyname><forenames>Marija</forenames></author><author><keyname>Paltoglou</keyname><forenames>Georgios</forenames></author><author><keyname>Tadi&#x107;</keyname><forenames>Bosiljka</forenames></author></authors><title>Quantitative Analysis of Bloggers Collective Behavior Powered by
  Emotions</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><report-no>0143821</report-no><doi>10.1088/1742-5468/2011/02/P02005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large-scale data resulting from users online interactions provide the
ultimate source of information to study emergent social phenomena on the Web.
From individual actions of users to observable collective behaviors, different
mechanisms involving emotions expressed in the posted text play a role. Here we
combine approaches of statistical physics with machine-learning methods of text
analysis to study emergence of the emotional behavior among Web users. Mapping
the high-resolution data from digg.com onto bipartite network of users and
their comments onto posted stories, we identify user communities centered
around certain popular posts and determine emotional contents of the related
comments by the emotion-classifier developed for this type of texts. Applied
over different time periods, this framework reveals strong correlations between
the excess of negative emotions and the evolution of communities. We observe
avalanches of emotional comments exhibiting significant self-organized critical
behavior and temporal correlations. To explore robustness of these critical
states, we design a network automaton model on realistic network connections
and several control parameters, which can be inferred from the dataset.
Dissemination of emotions by a small fraction of very active users appears to
critically tune the collective states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6293</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6293</id><created>2010-11-29</created><updated>2011-07-28</updated><authors><author><keyname>Knowles</keyname><forenames>David</forenames></author><author><keyname>Ghahramani</keyname><forenames>Zoubin</forenames></author></authors><title>Nonparametric Bayesian sparse factor models with application to gene
  expression modeling</title><categories>stat.AP cs.AI stat.ML</categories><comments>Published in at http://dx.doi.org/10.1214/10-AOAS435 the Annals of
  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AOAS-AOAS435</report-no><journal-ref>Annals of Applied Statistics 2011, Vol. 5, No. 2B, 1534-1552</journal-ref><doi>10.1214/10-AOAS435</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A nonparametric Bayesian extension of Factor Analysis (FA) is proposed where
observed data $\mathbf{Y}$ is modeled as a linear superposition, $\mathbf{G}$,
of a potentially infinite number of hidden factors, $\mathbf{X}$. The Indian
Buffet Process (IBP) is used as a prior on $\mathbf{G}$ to incorporate sparsity
and to allow the number of latent features to be inferred. The model's utility
for modeling gene expression data is investigated using randomly generated data
sets based on a known sparse connectivity matrix for E. Coli, and on three
biological data sets of increasing complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6308</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6308</id><created>2010-11-29</created><updated>2011-03-22</updated><authors><author><keyname>hennessy</keyname><forenames>matthew</forenames><affiliation>Trinity College Dublin</affiliation></author></authors><title>A calculus for costed computations</title><categories>cs.LO cs.DC</categories><proxy>LMCS</proxy><acm-class>cs.DC</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 1 (March 23,
  2011) lmcs:1135</journal-ref><doi>10.2168/LMCS-7(1:5)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a version of the pi-calculus, picost, where channels are
interpreted as resources which have costs associated with them. Code runs under
the financial responsibility of owners; they must pay to use resources, but may
profit by providing them. We provide a proof methodology for processes
described in picost based on bisimulations. The underlying behavioural theory
is justified via a contextual characterisation. We also demonstrate its
usefulness via examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6326</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6326</id><created>2010-11-29</created><authors><author><keyname>Oymak</keyname><forenames>Samet</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>New Null Space Results and Recovery Thresholds for Matrix Rank
  Minimization</title><categories>math.OC cs.IT math.IT stat.ML</categories><comments>28 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nuclear norm minimization (NNM) has recently gained significant attention for
its use in rank minimization problems. Similar to compressed sensing, using
null space characterizations, recovery thresholds for NNM have been studied in
\cite{arxiv,Recht_Xu_Hassibi}. However simulations show that the thresholds are
far from optimal, especially in the low rank region. In this paper we apply the
recent analysis of Stojnic for compressed sensing \cite{mihailo} to the null
space conditions of NNM. The resulting thresholds are significantly better and
in particular our weak threshold appears to match with simulation results.
Further our curves suggest for any rank growing linearly with matrix size $n$
we need only three times of oversampling (the model complexity) for weak
recovery. Similar to \cite{arxiv} we analyze the conditions for weak, sectional
and strong thresholds. Additionally a separate analysis is given for special
case of positive semidefinite matrices. We conclude by discussing simulation
results and future research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6332</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6332</id><created>2010-11-29</created><authors><author><keyname>Woitaszek</keyname><forenames>Matthew</forenames><affiliation>National Center for Atmospheric Research</affiliation></author><author><keyname>Metcalfe</keyname><forenames>Travis</forenames><affiliation>National Center for Atmospheric Research</affiliation></author><author><keyname>Shorrock</keyname><forenames>Ian</forenames><affiliation>National Center for Atmospheric Research</affiliation></author></authors><title>AMP: A Science-driven Web-based Application for the TeraGrid</title><categories>astro-ph.IM astro-ph.SR cs.DC</categories><comments>7 pages, 2 figures, in Proceedings of the 5th Grid Computing
  Environments Workshop</comments><doi>10.1145/1658260.1658262</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Asteroseismic Modeling Portal (AMP) provides a web-based interface for
astronomers to run and view simulations that derive the properties of Sun-like
stars from observations of their pulsation frequencies. In this paper, we
describe the architecture and implementation of AMP, highlighting the
lightweight design principles and tools used to produce a functional
fully-custom web-based science application in less than a year. Targeted as a
TeraGrid science gateway, AMP's architecture and implementation are intended to
simplify its orchestration of TeraGrid computational resources. AMP's web-based
interface was developed as a traditional standalone database-backed web
application using the Python-based Django web development framework, allowing
us to leverage the Django framework's capabilities while cleanly separating the
user interface development from the grid interface development. We have found
this combination of tools flexible and effective for rapid gateway development
and deployment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6353</identifier>
 <datestamp>2014-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6353</id><created>2010-11-29</created><updated>2014-10-10</updated><authors><author><keyname>Szudzik</keyname><forenames>Matthew P.</forenames></author></authors><title>On the definability of functionals in G\&quot;odel's theory T</title><categories>math.LO cs.LO</categories><comments>13 pages, 0 figures; metadata updated, other minor changes</comments><msc-class>03B40 (Primary), 03D65, 03F10 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Godel's theory T can be understood as a theory of the simply-typed lambda
calculus that is extended to include the constant 0, the successor function S,
and the operator R_tau for primitive recursion on objects of type tau. It is
known that the functions from non-negative integers to non-negative integers
that can be defined in this theory are exactly the &lt;epsilon_0-recursive
functions of non-negative integers. As an extension of this result, we show
that when the domain and codomain are restricted to pure closed normal forms,
the functionals of arbitrary type that are definable in T can be encoded as
&lt;epsilon_0-recursive functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6397</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6397</id><created>2010-11-29</created><updated>2010-12-10</updated><authors><author><keyname>Meka</keyname><forenames>Raghu</forenames></author></authors><title>Almost Optimal Explicit Johnson-Lindenstrauss Transformations</title><categories>cs.DS cs.CC math.PR</categories><comments>Updated references to prior work and minor formatting changes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Johnson-Lindenstrauss lemma is a fundamental result in probability with
several applications in the design and analysis of algorithms in high
dimensional geometry. Most known constructions of linear embeddings that
satisfy the Johnson-Lindenstrauss property involve randomness. We address the
question of explicitly constructing such embedding families and provide a
construction with an almost optimal use of randomness: we use
O(log(n/delta)log(log(n/delta)/epsilon)) random bits for embedding n dimensions
to O(log(1/delta)/epsilon^2) dimensions with error probability at most delta,
and distortion at most epsilon.
  In particular, for delta = 1/poly(n) and fixed epsilon, we use O(log n loglog
n) random bits. Previous constructions required at least O(log^2 n) random bits
to get polynomially small error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6429</identifier>
 <datestamp>2015-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6429</id><created>2010-11-29</created><authors><author><keyname>Baeten</keyname><forenames>Jos C. M.</forenames><affiliation>Eindhoven University of Technology, The Netherlands</affiliation></author><author><keyname>Luttik</keyname><forenames>Bas</forenames><affiliation>Eindhoven University of Technology, The Netherlands</affiliation></author><author><keyname>Muller</keyname><forenames>Tim</forenames><affiliation>University of Luxembourg, Luxembourg</affiliation></author><author><keyname>van Tilburg</keyname><forenames>Paul</forenames><affiliation>Eindhoven University of Technology, The Netherlands</affiliation></author></authors><title>Expressiveness modulo Bisimilarity of Regular Expressions with Parallel
  Composition (Extended Abstract)</title><categories>cs.LO cs.FL</categories><comments>In Proceedings EXPRESS'10, arXiv:1011.6012</comments><proxy>EPTCS</proxy><acm-class>F.1.1; F.1.2; F.4.1</acm-class><journal-ref>EPTCS 41, 2010, pp. 1-15</journal-ref><doi>10.1017/S0960129514000309</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The languages accepted by finite automata are precisely the languages denoted
by regular expressions. In contrast, finite automata may exhibit behaviours
that cannot be described by regular expressions up to bisimilarity. In this
paper, we consider extensions of the theory of regular expressions with various
forms of parallel composition and study the effect on expressiveness. First we
prove that adding pure interleaving to the theory of regular expressions
strictly increases its expressiveness up to bisimilarity. Then, we prove that
replacing the operation for pure interleaving by ACP-style parallel composition
gives a further increase in expressiveness. Finally, we prove that the theory
of regular expressions with ACP-style parallel composition and encapsulation is
expressive enough to express all finite automata up to bisimilarity. Our
results extend the expressiveness results obtained by Bergstra, Bethke and
Ponse for process algebras with (the binary variant of) Kleene's star
operation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6430</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6430</id><created>2010-11-29</created><authors><author><keyname>Banti</keyname><forenames>Federico</forenames><affiliation>Dipartimento di Sistemi e Informatica, Universit&#xe0; degli Studi di Firenze</affiliation></author><author><keyname>Pugliese</keyname><forenames>Rosario</forenames><affiliation>Dipartimento di Sistemi e Informatica, Universit&#xe0; degli Studi di Firenze</affiliation></author><author><keyname>Tiezzi</keyname><forenames>Francesco</forenames><affiliation>Dipartimento di Sistemi e Informatica, Universit&#xe0; degli Studi di Firenze</affiliation></author></authors><title>A criterion for separating process calculi</title><categories>cs.LO cs.FL</categories><comments>In Proceedings EXPRESS'10, arXiv:1011.6012</comments><proxy>EPTCS</proxy><acm-class>F.1.1; F3.2; F.4.3</acm-class><journal-ref>EPTCS 41, 2010, pp. 16-30</journal-ref><doi>10.4204/EPTCS.41.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new criterion, replacement freeness, to discern the relative
expressiveness of process calculi. Intuitively, a calculus is strongly
replacement free if replacing, within an enclosing context, a process that
cannot perform any visible action by an arbitrary process never inhibits the
capability of the resulting process to perform a visible action. We prove that
there exists no compositional and interaction sensitive encoding of a not
strongly replacement free calculus into any strongly replacement free one. We
then define a weaker version of replacement freeness, by only considering
replacement of closed processes, and prove that, if we additionally require the
encoding to preserve name independence, it is not even possible to encode a non
replacement free calculus into a weakly replacement free one. As a consequence
of our encodability results, we get that many calculi equipped with priority
are not replacement free and hence are not encodable into mainstream calculi
like CCS and pi-calculus, that instead are strongly replacement free. We also
prove that variants of pi-calculus with match among names, pattern matching or
polyadic synchronization are only weakly replacement free, hence they are
separated both from process calculi with priority and from mainstream calculi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6431</identifier>
 <datestamp>2014-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6431</id><created>2010-11-29</created><authors><author><keyname>Lago</keyname><forenames>Ugo Dal</forenames><affiliation>INRIA and University of Bologna</affiliation></author><author><keyname>Martini</keyname><forenames>Simone</forenames><affiliation>INRIA and University of Bologna</affiliation></author><author><keyname>Sangiorgi</keyname><forenames>Davide</forenames><affiliation>INRIA and University of Bologna</affiliation></author></authors><title>Light Logics and Higher-Order Processes</title><categories>cs.LO cs.PL</categories><comments>In Proceedings EXPRESS'10, arXiv:1011.6012</comments><proxy>EPTCS</proxy><acm-class>F.4.1</acm-class><journal-ref>EPTCS 41, 2010, pp. 46-60</journal-ref><doi>10.1017/S0960129514000310</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the techniques for resource control that have been developed in
the so-called &quot;light logics&quot; can be fruitfully applied also to process
algebras. In particular, we present a restriction of Higher-Order pi-calculus
inspired by Soft Linear Logic. We prove that any soft process terminates in
polynomial time. We argue that the class of soft processes may be naturally
enlarged so that interesting processes are expressible, still maintaining the
polynomial bound on executions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6432</identifier>
 <datestamp>2014-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6432</id><created>2010-11-29</created><authors><author><keyname>Figueira</keyname><forenames>Diego</forenames><affiliation>INRIA, ENS Cachan, LSV, France</affiliation></author><author><keyname>Hofman</keyname><forenames>Piotr</forenames><affiliation>Institute of Informatics, University of Warsaw, Poland</affiliation></author><author><keyname>Lasota</keyname><forenames>S&#x142;awomir</forenames><affiliation>Institute of Informatics, University of Warsaw, Poland</affiliation></author></authors><title>Relating timed and register automata</title><categories>cs.FL cs.LO</categories><comments>In Proceedings EXPRESS'10, arXiv:1011.6012</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 41, 2010, pp. 61-75</journal-ref><doi>10.1017/S0960129514000322</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Timed automata and register automata are well-known models of computation
over timed and data words respectively. The former has clocks that allow to
test the lapse of time between two events, whilst the latter includes registers
that can store data values for later comparison. Although these two models
behave in appearance differently, several decision problems have the same
(un)decidability and complexity results for both models. As a prominent
example, emptiness is decidable for alternating automata with one clock or
register, both with non-primitive recursive complexity. This is not by chance.
  This work confirms that there is indeed a tight relationship between the two
models. We show that a run of a timed automaton can be simulated by a register
automaton, and conversely that a run of a register automaton can be simulated
by a timed automaton. Our results allow to transfer complexity and decidability
results back and forth between these two kinds of models. We justify the
usefulness of these reductions by obtaining new results on register automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6433</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6433</id><created>2010-11-29</created><authors><author><keyname>Gorrieri</keyname><forenames>Roberto</forenames></author><author><keyname>Versari</keyname><forenames>Cristian</forenames></author></authors><title>A Process Calculus for Expressing Finite Place/Transition Petri Nets</title><categories>cs.LO</categories><comments>In Proceedings EXPRESS'10, arXiv:1011.6012</comments><proxy>EPTCS</proxy><acm-class>F.3.2</acm-class><journal-ref>EPTCS 41, 2010, pp. 76-90</journal-ref><doi>10.4204/EPTCS.41.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the process calculus Multi-CCS, which extends conservatively CCS
with an operator of strong prefixing able to model atomic sequences of actions
as well as multiparty synchronization. Multi-CCS is equipped with a labeled
transition system semantics, which makes use of a minimal structural
congruence. Multi-CCS is also equipped with an unsafe P/T Petri net semantics
by means of a novel technique. This is the first rich process calculus,
including CCS as a subcalculus, which receives a semantics in terms of unsafe,
labeled P/T nets. The main result of the paper is that a class of Multi-CCS
processes, called finite-net processes, is able to represent all finite
(reduced) P/T nets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6434</identifier>
 <datestamp>2014-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6434</id><created>2010-11-29</created><authors><author><keyname>Lowe</keyname><forenames>Gavin</forenames><affiliation>Oxford University</affiliation></author></authors><title>Models for CSP with availability information</title><categories>cs.LO</categories><comments>In Proceedings EXPRESS'10, arXiv:1011.6012</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 41, 2010, pp. 91-105</journal-ref><doi>10.1017/S0960129514000334</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider models of CSP based on recording what events are available as
possible alternatives to the events that are actually performed. We present
many different varieties of such models. For each, we give a compositional
semantics, congruent to the operational semantics, and prove full abstraction
and no-junk results. We compare the expressiveness of the different models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6435</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6435</id><created>2010-11-29</created><authors><author><keyname>Mosses</keyname><forenames>Peter D.</forenames><affiliation>Department of Computer Science, Swansea University</affiliation></author><author><keyname>Mousavi</keyname><forenames>MohammadReza</forenames><affiliation>Department of Computer Science, Eindhoven University of Technology</affiliation></author><author><keyname>Reniers</keyname><forenames>Michel A.</forenames><affiliation>Department of Computer Science, Eindhoven University of Technology</affiliation></author></authors><title>Robustness of Equations Under Operational Extensions</title><categories>cs.LO</categories><comments>In Proceedings EXPRESS'10, arXiv:1011.6012</comments><proxy>EPTCS</proxy><acm-class>F.3.2; D.3.1; D.2.1</acm-class><journal-ref>EPTCS 41, 2010, pp. 106-120</journal-ref><doi>10.4204/EPTCS.41.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sound behavioral equations on open terms may become unsound after
conservative extensions of the underlying operational semantics. Providing
criteria under which such equations are preserved is extremely useful; in
particular, it can avoid the need to repeat proofs when extending the specified
language.
  This paper investigates preservation of sound equations for several notions
of bisimilarity on open terms: closed-instance (ci-)bisimilarity and
formal-hypothesis (fh-)bisimilarity, both due to Robert de Simone, and
hypothesis-preserving (hp-)bisimilarity, due to Arend Rensink. For both
fh-bisimilarity and hp-bisimilarity, we prove that arbitrary sound equations on
open terms are preserved by all disjoint extensions which do not add labels. We
also define slight variations of fh- and hp-bisimilarity such that all sound
equations are preserved by arbitrary disjoint extensions. Finally, we give two
sets of syntactic criteria (on equations, resp. operational extensions) and
prove each of them to be sufficient for preserving ci-bisimilarity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6436</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6436</id><created>2010-11-29</created><authors><author><keyname>Nielsen</keyname><forenames>Lasse</forenames><affiliation>DIKU, University of Copenhagen</affiliation></author><author><keyname>Yoshida</keyname><forenames>Nobuko</forenames><affiliation>Imperial College London</affiliation></author><author><keyname>Honda</keyname><forenames>Kohei</forenames><affiliation>Queen Mary, University of London</affiliation></author></authors><title>Multiparty Symmetric Sum Types</title><categories>cs.DC cs.PL</categories><comments>In Proceedings EXPRESS'10, arXiv:1011.6012</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 41, 2010, pp. 121-135</journal-ref><doi>10.4204/EPTCS.41.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new theory of multiparty session types based on
symmetric sum types, by which we can type non-deterministic orchestration
choice behaviours. While the original branching type in session types can
represent a choice made by a single participant and accepted by others
determining how the session proceeds, the symmetric sum type represents a
choice made by agreement among all the participants of a session. Such
behaviour can be found in many practical systems, including collaborative
workflow in healthcare systems for clinical practice guidelines (CPGs).
Processes using the symmetric sums can be embedded into the original branching
types using conductor processes. We show that this type-driven embedding
preserves typability, satisfies semantic soundness and completeness, and meets
the encodability criteria adapted to the typed setting. The theory leads to an
efficient implementation of a prototypical tool for CPGs which automatically
translates the original CPG specifications from a representation called the
Process Matrix to symmetric sum types, type checks programs and executes them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6437</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6437</id><created>2010-11-29</created><authors><author><keyname>Peters</keyname><forenames>Kirstin</forenames></author><author><keyname>Nestmann</keyname><forenames>Uwe</forenames></author></authors><title>Breaking Symmetries</title><categories>cs.LO</categories><comments>In Proceedings EXPRESS'10, arXiv:1011.6012</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 41, 2010, pp. 136-150</journal-ref><doi>10.4204/EPTCS.41.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A well-known result by Palamidessi tells us that \pimix (the \pi-calculus
with mixed choice) is more expressive than \pisep (its subset with only
separate choice). The proof of this result argues with their different
expressive power concerning leader election in symmetric networks. Later on,
Gorla offered an arguably simpler proof that, instead of leader election in
symmetric networks, employed the reducibility of incestual processes (mixed
choices that include both enabled senders and receivers for the same channel)
when running two copies in parallel. In both proofs, the role of breaking
(initial) symmetries is more or less apparent. In this paper, we shed more
light on this role by re-proving the above result - based on a proper
formalization of what it means to break symmetries without referring to another
layer of the distinguishing problem domain of leader election. Both Palamidessi
and Gorla rephrased their results by stating that there is no uniform and
reasonable encoding from \pimix into \pisep. We indicate how the respective
proofs can be adapted and exhibit the consequences of varying notions of
uniformity and reasonableness. In each case, the ability to break initial
symmetries turns out to be essential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6438</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6438</id><created>2010-11-29</created><authors><author><keyname>Cerone</keyname><forenames>Andrea</forenames><affiliation>Department of Computer Science, Trinity College Dublin</affiliation></author><author><keyname>Hennessy</keyname><forenames>Matthew</forenames><affiliation>Department of Computer Science, Trinity College Dublin</affiliation></author></authors><title>Process Behaviour: Formulae vs. Tests (Extended Abstract)</title><categories>cs.LO</categories><comments>In Proceedings EXPRESS'10, arXiv:1011.6012</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 41, 2010, pp. 31-45</journal-ref><doi>10.4204/EPTCS.41.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Process behaviour is often defined either in terms of the tests they satisfy,
or in terms of the logical properties they enjoy. Here we compare these two
approaches, using extensional testing in the style of DeNicola, Hennessy, and a
recursive version of the property logic HML. We first characterise subsets of
this property logic which can be captured by tests. Then we show that those
subsets of the property logic capture precisely the power of tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6441</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6441</id><created>2010-11-29</created><updated>2011-07-08</updated><authors><author><keyname>Wadayama</keyname><forenames>Tadashi</forenames></author><author><keyname>Hagiwara</keyname><forenames>Manabu</forenames></author></authors><title>LP Decodable Permutation Codes based on Linearly Constrained Permutation
  Matrices</title><categories>cs.IT math.CO math.IT math.RT</categories><comments>29 pages, 7 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A set of linearly constrained permutation matrices are proposed for
constructing a class of permutation codes. Making use of linear constraints
imposed on the permutation matrices, we can formulate a minimum Euclidian
distance decoding problem for the proposed class of permutation codes as a
linear programming (LP) problem. The main feature of this class of permutation
codes, called LP decodable permutation codes, is this LP decodability. It is
demonstrated that the LP decoding performance of the proposed class of
permutation codes is characterized by the vertices of the code polytope of the
code. Two types of linear constraints are discussed; one is structured
constraints and another is random constraints. The structured constraints such
as pure involution lead to an efficient encoding algorithm. On the other hand,
the random constraints enable us to use probabilistic methods for analyzing
several code properties such as the average cardinality and the average weight
distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6461</identifier>
 <datestamp>2011-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6461</id><created>2010-11-30</created><authors><author><keyname>Chung</keyname><forenames>Yoo</forenames></author></authors><title>Precisely Analyzing Loss in Interface Adapter Chains</title><categories>cs.SE</categories><comments>12 pages, 1 figure. Submitted to IASTED SE 2011</comments><acm-class>D.2.12</acm-class><doi>10.2316/P.2011.720-059</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interface adaptation allows code written for one interface to be used with a
software component with another interface. When multiple adapters are chained
together to make certain adaptations possible, we need a way to analyze how
well the adaptation is done in case there are more than one chains that can be
used. We introduce an approach to precisely analyzing the loss in an interface
adapter chain using a simple form of abstract interpretation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6481</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6481</id><created>2010-11-30</created><authors><author><keyname>Inkulu</keyname><forenames>Rajasekhar</forenames></author><author><keyname>Kapoor</keyname><forenames>Sanjiv</forenames></author><author><keyname>Maheshwari</keyname><forenames>S. N.</forenames></author></authors><title>A near optimal algorithm for finding Euclidean shortest path in
  polygonal domain</title><categories>cs.CG</categories><comments>50 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm to find an {\it Euclidean Shortest Path} from a
source vertex $s$ to a sink vertex $t$ in the presence of obstacles in $\Re^2$.
Our algorithm takes $O(T+m(\lg{m})(\lg{n}))$ time and $O(n)$ space. Here,
$O(T)$ is the time to triangulate the polygonal region, $m$ is the number of
obstacles, and $n$ is the number of vertices. This bound is close to the known
lower bound of $O(n+m\lg{m})$ time and $O(n)$ space. Our approach involve
progressing shortest path wavefront as in continuous Dijkstra-type method, and
confining its expansion to regions of interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6491</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6491</id><created>2010-11-30</created><updated>2011-09-21</updated><authors><author><keyname>Straubing</keyname><forenames>Howard</forenames><affiliation>Boston College</affiliation></author><author><keyname>Weil</keyname><forenames>Pascal</forenames><affiliation>LaBRI</affiliation></author></authors><title>An introduction to finite automata and their connection to logic</title><categories>cs.FL cs.LO</categories><proxy>ccsd</proxy><journal-ref>Modern Applications of Automata Theory (2012) 3-43</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a tutorial on finite automata. We present the standard material on
determinization and minimization, as well as an account of the equivalence of
finite automata and monadic second-order logic. We conclude with an
introduction to the syntactic monoid, and as an application give a proof of the
equivalence of first-order definability and aperiodicity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6495</identifier>
 <datestamp>2011-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6495</id><created>2010-11-30</created><updated>2011-01-26</updated><authors><author><keyname>Ma</keyname><forenames>Yue</forenames></author><author><keyname>Zhi</keyname><forenames>Lihong</forenames></author></authors><title>The Minimum-Rank Gram Matrix Completion via Modified Fixed Point
  Continuation Method</title><categories>math.OC cs.NA cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of computing a representation for a real polynomial as a sum of
minimum number of squares of polynomials can be casted as finding a symmetric
positive semidefinite real matrix (Gram matrix) of minimum rank subject to
linear equality constraints.
  In this paper, we propose algorithms for solving the minimum-rank Gram matrix
completion problem, and show the convergence of these algorithms. Our methods
are based on the modified fixed point continuation (FPC) method. We also use
the Barzilai-Borwein (BB) technique and a specific linear combination of two
previous iterates to accelerate the convergence of modified FPC algorithms. We
demonstrate the effectiveness of our algorithms for computing approximate and
exact rational sum of squares (SOS) decompositions of polynomials with rational
coefficients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6496</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6496</id><created>2010-11-30</created><authors><author><keyname>Xu</keyname><forenames>Xiaohui</forenames></author><author><keyname>Huang</keyname><forenames>Linpeng</forenames></author><author><keyname>Wang</keyname><forenames>Dejun</forenames></author><author><keyname>Chen</keyname><forenames>Junqing</forenames></author></authors><title>A Calculus of Consistent Component-based Software Updates</title><categories>cs.LO</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is important to enable reasoning about the meaning and possible effects of
updates to ensure that the updated system operates correctly. A formal,
mathematical model of dynamic update should be developed, in order to
understand by both users and implementors of update technology what design
choices can be considered. In this paper, we define a formal calculus
$update\pi$, a variant extension of higher-order $\pi$ calculus, to model
dynamic updates of component-based software, which is language and technology
independent. The calculus focuses on following main concepts: proper
granularity of update, timing of dynamic update, state transformation between
versions, update failure check and recovery. We describe a series of rule on
safe component updates to model some general processes of dynamic update and
discuss its reduction semantics coincides with a labelled transition system
semantics that illustrate the expressive power of these calculi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6497</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6497</id><created>2010-11-30</created><updated>2011-03-22</updated><authors><author><keyname>Papalamprou</keyname><forenames>Konstantinos</forenames></author><author><keyname>Pitsoulis</keyname><forenames>Leonidas</forenames></author></authors><title>Decomposition of Binary Signed-Graphic Matroids</title><categories>math.CO cs.DM</categories><msc-class>52B40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we employ Tutte's theory of bridges to derive a decomposition
theorem for binary matroids arising from signed graphs. The proposed
decomposition differs from previous decomposition results on matroids that have
appeared in the literature in the sense that it is not based on $k$-sums, but
rather on the operation of deletion of a cocircuit. Specifically, it is shown
that certain minors resulting from the deletion of a cocircuit of a binary
matroid will be graphic matroids apart from exactly one that will be
signed-graphic, if and only if the matroid is signed-graphic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6498</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6498</id><created>2010-11-30</created><authors><author><keyname>Inkulu</keyname><forenames>Rajasekhar</forenames></author><author><keyname>Kapoor</keyname><forenames>Sanjiv</forenames></author></authors><title>Approximate Shortest Path through a Weighted Planar Subdivision</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an approximation algorithm for finding a shortest path
between two points $s$ and $t$ in a weighted planar subdivision $\PS$. Each
face $f$ of $\PS$ is associated with a weight $w_f$, and the cost of travel
along a line segment on $f$ is $w_f$ multiplied by the Euclidean norm of that
line segment. The cost of a path which traverses across several faces of the
subdivision is the sum of the costs of travel along each face. Our algorithm
progreeses the discretized shortest path wavefront from source $s$, and takes
polynomial time in finding an $\epsilon$-approximate shortest path.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6505</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6505</id><created>2010-11-30</created><authors><author><keyname>Gao</keyname><forenames>Xiao-Shan</forenames></author><author><keyname>Huang</keyname><forenames>Zhenyu</forenames></author></authors><title>Efficient Characteristic Set Algorithms for Equation Solving in Finite
  Fields and Applications in Cryptanalysis</title><categories>cs.SC cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient characteristic set methods for computing solutions of polynomial
equation systems in a finite field are proposed. The concept of proper
triangular sets is introduced and an explicit formula for the number of
solutions of a proper and monic (or regular) triangular set is given. An
improved zero decomposition algorithm which can be used to reduce the zero set
of an equation system in general form to the union of zero sets of monic proper
triangular sets is proposed. As a consequence, we can give an explicit formula
for the number of solutions of an equation system. Bitsize complexity for the
algorithm is given in the case of Boolean polynomials. We also give a
multiplication free characteristic set method for Boolean polynomials, where
the sizes of the polynomials are effectively controlled. The algorithms are
implemented in the case of Boolean polynomials and extensive experiments show
that they are quite efficient for solving certain classes of Boolean equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6508</identifier>
 <datestamp>2010-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6508</id><created>2010-11-30</created><updated>2010-12-17</updated><authors><author><keyname>Pattanayak</keyname><forenames>Binod Kumar</forenames></author><author><keyname>Mishra</keyname><forenames>Manoj Kumar</forenames></author><author><keyname>Jagadev</keyname><forenames>Alok Kumar</forenames></author><author><keyname>Nayak</keyname><forenames>Manojranjan</forenames></author></authors><title>Multi-Hop Bandwidth Management Protocol for Mobile Ad Hoc Networks</title><categories>cs.NI</categories><comments>20 pages,30 figures</comments><journal-ref>International Journal of Managing Information technology, November
  2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An admission control scheme should play the role of a coordinator for flows
in a data communication network, to provide the guarantees as the medium is
shared. The nodes of a wired network can monitor the medium to know the
available bandwidth at any point of time. But, in wireless ad hoc networks, a
node must consume the bandwidth of neighboring nodes, during a communication.
Hence, the consumption of bandwidth by a flow and the availability of resources
to any wireless node strictly depend upon the neighboring nodes within its
transmission range. We present a scalable and efficient admission control
scheme, Multi-hop Bandwidth Management Protocol (MBMP), to support the QoS
requirements in multi-hop ad hoc networks. We simulate several options to
design MBMP and compare the performances of these options through mathematical
analysis and simulation results, and compare its effectiveness with the
existing admission control schemes through extensive simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6526</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6526</id><created>2010-11-30</created><authors><author><keyname>Mullikin</keyname><forenames>Arwen</forenames><affiliation>Shawon</affiliation></author><author><keyname>Syed</keyname><affiliation>Shawon</affiliation></author><author><keyname>Rahman</keyname><forenames>M.</forenames></author></authors><title>Ethical Dilemma of Governmental Wiretapping</title><categories>cs.CY</categories><comments>8 pages</comments><journal-ref>International Journal of Managing Information Technology (IJMIT)
  November 2010, Volume 2, Number 4</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  USA Government wiretapping activities is a very controversial issue.
Undoubtedly this technology can assist law enforced authority to detect /
identify unlawful or hostile activities; however, this task raises severe
privacy concerns. In this paper, we have discussed this complex information
technology issue of governmental wiretapping and how it effects both public and
private liberties. Legislation has had a major impact on the uses and the
stigma of wiretapping for the war on terrorism. This paper also analyzes the
ethical and legal concerns inherent when discussing the benefits and concerns
of wiretapping. The analysis has concluded with the effects of wiretapping laws
as they relate to future government actions in their fight against terrorists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6543</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6543</id><created>2010-11-30</created><updated>2011-01-22</updated><authors><author><keyname>Meglicki</keyname><forenames>Bartosz</forenames></author></authors><title>Generating functions partitioning algorithm for computing power indices
  in weighted voting games</title><categories>cs.GT cs.DS</categories><comments>15 pages, algorithm pessimistic complexity O(n 2^(n/2)),
  pseudopolynomial complexity O(nq), calculates Banzhaf indices of all players,
  #P-complete problem. Minor errors corrected. Explicit explanation of general
  (non-integer) case without pseudopolynomial complexity</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper new algorithm for calculating power indices is described. The
complexity class of the problem is #P-complete and even calculating power index
of the biggest player is NP-hard task. Constructed algorithm is a mix of ideas
of two algorithms: Klinz &amp; Woeginger partitioning algorithm and Mann &amp; Shapley
generating functions algorithm. Time and space complexities of the algorithm
are analysed and compared with other known algorithms for the problem.
Constructed algorithm has pessimistic time complexity O(n 2^(n/2))and
pseudopolynomial complexity O(nq), where q is quota of the voting game. This
paper also solves open problem stated by H. Aziz and M. Paterson - existence of
the algorithm for calculating Banzhaf power indices of all players with time
complexity lower than O(n^2 2^(n/2)). Not only is the answer positive but this
can be done keeping the pseudopolynomial complexity of generating functions
algorithm in case weights are integers. New open problems are stated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6590</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6590</id><created>2010-11-23</created><authors><author><keyname>Boldt</keyname><forenames>Axel</forenames></author></authors><title>Extending ArXiv.org to Achieve Open Peer Review and Publishing</title><categories>cs.OH</categories><comments>6 pages. To be published in the Journal of Scholarly Publishing</comments><acm-class>H.3.7; H.3.5; H.5.3; J.1; J.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Today's peer review process for scientific articles is unnecessarily opaque
and offers few incentives to referees. Likewise, the publishing process is
unnecessarily inefficient and its results are only rarely made freely available
to the public. Here we outline a comparatively simple extension of arXiv.org,
an online preprint archive widely used in the mathematical and physical
sciences, that addresses both of these problems. Under the proposal, editors
invite referees to write public and signed reviews to be attached to the posted
preprints, and then elevate selected articles to &quot;published&quot; status.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6594</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6594</id><created>2010-11-30</created><updated>2010-12-11</updated><authors><author><keyname>Arora</keyname><forenames>Dushyant</forenames></author><author><keyname>Feldmann</keyname><forenames>Anja</forenames></author><author><keyname>Schaffrath</keyname><forenames>Gregor</forenames></author><author><keyname>Schmid</keyname><forenames>Stefan</forenames></author></authors><title>On the Benefit of Virtualization: Strategies for Flexible Server
  Allocation</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Virtualization technology facilitates a dynamic, demand-driven allocation and
migration of servers. This paper studies how the flexibility offered by network
virtualization can be used to improve Quality-of-Service parameters such as
latency, while taking into account allocation costs. A generic use case is
considered where both the overall demand issued for a certain service (for
example, an SAP application in the cloud, or a gaming application) as well as
the origins of the requests change over time (e.g., due to time zone effects or
due to user mobility), and we present online and optimal offline strategies to
compute the number and location of the servers implementing this service. These
algorithms also allow us to study the fundamental benefits of dynamic resource
allocation compared to static systems. Our simulation results confirm our
expectations that the gain of flexible server allocation is particularly high
in scenarios with moderate dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6596</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6596</id><created>2010-11-30</created><authors><author><keyname>Jesus</keyname><forenames>Paulo</forenames></author><author><keyname>Baquero</keyname><forenames>Carlos</forenames></author><author><keyname>Almeida</keyname><forenames>Paulo S&#xe9;rgio</forenames></author></authors><title>Dependability in Aggregation by Averaging</title><categories>cs.DC</categories><comments>14 pages. Presented in Inforum 2009</comments><acm-class>C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aggregation is an important building block of modern distributed
applications, allowing the determination of meaningful properties (e.g. network
size, total storage capacity, average load, majorities, etc.) that are used to
direct the execution of the system. However, the majority of the existing
aggregation algorithms exhibit relevant dependability issues, when prospecting
their use in real application environments. In this paper, we reveal some
dependability issues of aggregation algorithms based on iterative averaging
techniques, giving some directions to solve them. This class of algorithms is
considered robust (when compared to common tree-based approaches), being
independent from the used routing topology and providing an aggregation result
at all nodes. However, their robustness is strongly challenged and their
correctness often compromised, when changing the assumptions of their working
environment to more realistic ones. The correctness of this class of algorithms
relies on the maintenance of a fundamental invariant, commonly designated as
&quot;mass conservation&quot;. We will argue that this main invariant is often broken in
practical settings, and that additional mechanisms and modifications are
required to maintain it, incurring in some degradation of the algorithms
performance. In particular, we discuss the behavior of three representative
algorithms Push-Sum Protocol, Push-Pull Gossip protocol and Distributed Random
Grouping under asynchronous and faulty (with message loss and node crashes)
environments. More specifically, we propose and evaluate two new versions of
the Push-Pull Gossip protocol, which solve its message interleaving problem
(evidenced even in a synchronous operation mode).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6599</identifier>
 <datestamp>2012-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6599</id><created>2010-11-30</created><updated>2011-03-29</updated><authors><author><keyname>Bubenik</keyname><forenames>Peter</forenames></author></authors><title>Simplicial models for concurrency</title><categories>cs.DC math.AT</categories><comments>12 pages, Section 4 from v1 omitted since quasi-category equivalences
  are too strong: they induce equivalences of path categories</comments><msc-class>68Q85, 55U10, 18D20, 55U35</msc-class><journal-ref>Electronic Notes in Theoretical Computer Science 283 (2012) 3-12</journal-ref><doi>10.1016/j.entcs.2012.05.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We model both concurrent programs and the possible executions from one state
to another in a concurrent program using simplices. The latter are calculated
using necklaces of simplices in the former.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6639</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6639</id><created>2010-11-30</created><updated>2012-12-08</updated><authors><author><keyname>Li</keyname><forenames>Min</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>Multiple Access Channels with States Causally Known at Transmitters</title><categories>cs.IT math.IT</categories><comments>Accepted by IEEE Transactions on Information Theory, November 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been recently shown by Lapidoth and Steinberg that strictly causal
state information can be beneficial in multiple access channels (MACs).
Specifically, it was proved that the capacity region of a two-user MAC with
independent states, each known strictly causally to one encoder, can be
enlarged by letting the encoders send compressed past state information to the
decoder. In this work, a generalization of the said strategy is proposed
whereby the encoders compress also the past transmitted codewords along with
the past state sequences. The proposed scheme uses a combination of
long-message encoding, compression of the past state sequences and codewords
without binning, and joint decoding over all transmission blocks. The proposed
strategy has been recently shown by Lapidoth and Steinberg to strictly improve
upon the original one. Capacity results are then derived for a class of
channels that include two-user modulo-additive state-dependent MACs. Moreover,
the proposed scheme is extended to state-dependent MACs with an arbitrary
number of users. Finally, output feedback is introduced and an example is
provided to illustrate the interplay between feedback and availability of
strictly causal state information in enlarging the capacity region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6644</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6644</id><created>2010-11-30</created><authors><author><keyname>Kim</keyname><forenames>Douglas</forenames></author><author><keyname>Torlak</keyname><forenames>Murat</forenames></author></authors><title>Interference Alignment via Improved Subspace Conditioning</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the K user, single input single output (SISO), frequency selective
interference channel, a new low complexity transmit beamforming design that
improves the achievable sum rate is presented. Jointly employing the
interference alignment (IA) scheme presented by Cadambe and Jafar in [1] and
linear minimum mean square error (MMSE) decoding at the transmitters and
receivers, respectively, the new IA precoding design improves the average sum
rate while preserving the achievable degrees of freedom of the Cadambe and
Jafar scheme, K/2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6656</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6656</id><created>2010-11-30</created><updated>2011-04-12</updated><authors><author><keyname>Tosic</keyname><forenames>Ivana</forenames></author><author><keyname>Olshausen</keyname><forenames>Bruno A.</forenames></author><author><keyname>Culpepper</keyname><forenames>Benjamin J.</forenames></author></authors><title>Learning sparse representations of depth</title><categories>cs.CV</categories><comments>12 pages</comments><doi>10.1109/JSTSP.2011.2158063</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new method for learning and inferring sparse
representations of depth (disparity) maps. The proposed algorithm relaxes the
usual assumption of the stationary noise model in sparse coding. This enables
learning from data corrupted with spatially varying noise or uncertainty,
typically obtained by laser range scanners or structured light depth cameras.
Sparse representations are learned from the Middlebury database disparity maps
and then exploited in a two-layer graphical model for inferring depth from
stereo, by including a sparsity prior on the learned features. Since they
capture higher-order dependencies in the depth structure, these priors can
complement smoothness priors commonly used in depth inference based on Markov
Random Field (MRF) models. Inference on the proposed graph is achieved using an
alternating iterative optimization technique, where the first layer is solved
using an existing MRF-based stereo matching algorithm, then held fixed as the
second layer is solved using the proposed non-stationary sparse coding
algorithm. This leads to a general method for improving solutions of state of
the art MRF-based depth estimation algorithms. Our experimental results first
show that depth inference using learned representations leads to state of the
art denoising of depth maps obtained from laser range scanners and a time of
flight camera. Furthermore, we show that adding sparse priors improves the
results of two depth estimation methods: the classical graph cut algorithm by
Boykov et al. and the more recent algorithm of Woodford et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6664</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6664</id><created>2010-11-30</created><authors><author><keyname>Hemmecke</keyname><forenames>Raymond</forenames></author><author><keyname>Lindner</keyname><forenames>Silvia</forenames></author><author><keyname>Studen&#xfd;</keyname><forenames>Milan</forenames></author></authors><title>Learning restricted Bayesian network structures</title><categories>math.OC cs.DS cs.IT math.IT</categories><msc-class>62F15, 68T05, 90C05, 90C09, 90C10, 9090C27, 90C60,</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bayesian networks are basic graphical models, used widely both in statistics
and artificial intelligence. These statistical models of conditional
independence structure are described by acyclic directed graphs whose nodes
correspond to (random) variables in consideration. A quite important topic is
the learning of Bayesian network structures, which is determining the best
fitting statistical model on the basis of given data. Although there are
learning methods based on statistical conditional independence tests,
contemporary methods are mainly based on maximization of a suitable quality
criterion that evaluates how good the graph explains the occurrence of the
observed data. This leads to a nonlinear combinatorial optimization problem
that is in general NP-hard to solve. In this paper we deal with the complexity
of learning restricted Bayesian network structures, that is, we wish to find
network structures of highest score within a given subset of all possible
network structures. For this, we introduce a new unique algebraic
representative for these structures, called the characteristic imset. We show
that these imsets are always 0-1-vectors and that they have many nice
properties that allow us to simplify long proofs for some known results and to
easily establish new complexity results for learning restricted Bayes network
structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6670</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6670</id><created>2010-11-30</created><authors><author><keyname>Tolk</keyname><forenames>Andreas</forenames></author></authors><title>Functional Categories of Support to Operations in Military Information
  Systems</title><categories>cs.OH</categories><comments>NATO Regional Conference on Military Communication and Information
  Systems 2000 (RCMCIS 2000), Zegrze, Poland, October 4-6, 2000</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to group the functional requirements for support to operations by
modern information systems systematically, the NATO Code of best Practise
(COBP) for C2 Assessment defines three domain areas: Battlespace Visualization,
Decision Making, and Battle Management Functions. In addition, within an domain
overlapping information grid of the information system, necessary functions for
assessing and disseminating the information are capsulated. For all three
domains, including the overlapping information grid, the respective
requirements for functional support have to be met be future command, control,
communications, and intelligence (C3I) systems.
  The paper describes the functional categories of the three domains having
been defined for article 5 operations, extends them to meet the requirements
for operations other than war (OOTW), and gives some examples how modules of
simulation systems can deliver respective support functions. In addition,
references defining migration procedures for legacy systems to enable a smooth
change from the old to the new C3I paradigm are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.6671</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.6671</id><created>2010-11-30</created><authors><author><keyname>Tolk</keyname><forenames>Andreas</forenames></author></authors><title>Avoiding another Green Elephant - A Proposal for the Next Generation HLA
  based on the Model Driven Architecture</title><categories>cs.OH</categories><comments>2002 Fall Simulation Interoperability Workshop, Orlando, Florida,
  September 2002</comments><report-no>02F-SIW-004</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When looking through the proceedings of the recent Simulation
Interoperability Workshops, a lot of papers - some of them even awarded by the
committee - are dealing with alternative concepts outside or beyond the High
Level Architecture (HLA): Web Services, the extensible Markup Language (XML),
Java Beans, Simple Object Access Protocol (SOAP), etc. Similarly, requirements
driven by interoperability issues have resulted in the need to use meta
modeling, adaptive models, and common repositories. The use of the Unified
Modeling Language (UML) as a model description language is also rapidly
becoming a standard. All these concepts have relations to the HLA, but they are
not part of it. There seems to be the danger that HLA is overrun by respective
developments of the free market and will become irrelevant finally. ... This
paper introduces the MDA concept and shows, how the HLA can be integrated to
become a standard stub for simulation applications of legacy systems, systems
under development, and systems of the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0006</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0006</id><created>2010-11-30</created><updated>2011-04-04</updated><authors><author><keyname>Sanders</keyname><forenames>Peter</forenames></author><author><keyname>Schulz</keyname><forenames>Christian</forenames></author></authors><title>Engineering Multilevel Graph Partitioning Algorithms</title><categories>cs.DS cs.DC</categories><comments>fixed a problem with the medium sized instances</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a multi-level graph partitioning algorithm using novel local
improvement algorithms and global search strategies transferred from the
multi-grid community. Local improvement algorithms are based max-flow min-cut
computations and more localized FM searches. By combining these techniques, we
obtain an algorithm that is fast on the one hand and on the other hand is able
to improve the best known partitioning results for many inputs. For example, in
Walshaw's well known benchmark tables we achieve 317 improvements for the
tables 1%, 3% and 5% imbalance. Moreover, in 118 additional cases we have been
able to reproduce the best cut in this benchmark.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0009</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0009</id><created>2010-11-30</created><updated>2012-02-17</updated><authors><author><keyname>Casteigts</keyname><forenames>Arnaud</forenames></author><author><keyname>Flocchini</keyname><forenames>Paola</forenames></author><author><keyname>Quattrociocchi</keyname><forenames>Walter</forenames></author><author><keyname>Santoro</keyname><forenames>Nicola</forenames></author></authors><title>Time-Varying Graphs and Dynamic Networks</title><categories>cs.DC cs.NI cs.SI physics.soc-ph</categories><comments>A short version appeared in ADHOC-NOW'11. This version is to be
  published in Internation Journal of Parallel, Emergent and Distributed
  Systems</comments><acm-class>C.2.4; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The past few years have seen intensive research efforts carried out in some
apparently unrelated areas of dynamic systems -- delay-tolerant networks,
opportunistic-mobility networks, social networks -- obtaining closely related
insights. Indeed, the concepts discovered in these investigations can be viewed
as parts of the same conceptual universe; and the formal models proposed so far
to express some specific concepts are components of a larger formal description
of this universe. The main contribution of this paper is to integrate the vast
collection of concepts, formalisms, and results found in the literature into a
unified framework, which we call TVG (for time-varying graphs). Using this
framework, it is possible to express directly in the same formalism not only
the concepts common to all those different areas, but also those specific to
each. Based on this definitional work, employing both existing results and
original observations, we present a hierarchical classification of TVGs; each
class corresponds to a significant property examined in the distributed
computing literature. We then examine how TVGs can be used to study the
evolution of network properties, and propose different techniques, depending on
whether the indicators for these properties are a-temporal (as in the majority
of existing studies) or temporal. Finally, we briefly discuss the introduction
of randomness in TVGs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0011</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0011</id><created>2010-11-30</created><authors><author><keyname>Qiao</keyname><forenames>Deli</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author><author><keyname>Velipasalar</keyname><forenames>Senem</forenames></author></authors><title>Secure Wireless Communication and Optimal Power Control under
  Statistical Queueing Constraints</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, secure transmission of information over fading broadcast
channels is studied in the presence of statistical queueing constraints.
Effective capacity is employed as a performance metric to identify the secure
throughput of the system, i.e., effective secure throughput. It is assumed that
perfect channel side information (CSI) is available at both the transmitter and
the receivers. Initially, the scenario in which the transmitter sends common
messages to two receivers and confidential messages to one receiver is
considered. For this case, effective secure throughput region, which is the
region of constant arrival rates of common and confidential messages that can
be supported by the buffer-constrained transmitter and fading broadcast
channel, is defined. It is proven that this effective throughput region is
convex. Then, the optimal power control policies that achieve the boundary
points of the effective secure throughput region are investigated and an
algorithm for the numerical computation of the optimal power adaptation schemes
is provided. Subsequently, the special case in which the transmitter sends only
confidential messages to one receiver, is addressed in more detail. For this
case, effective secure throughput is formulated and two different power
adaptation policies are studied. In particular, it is noted that opportunistic
transmission is no longer optimal under buffer constraints and the transmitter
should not wait to send the data at a high rate until the main channel is much
better than the eavesdropper channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0012</identifier>
 <datestamp>2016-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0012</id><created>2010-11-30</created><updated>2016-01-12</updated><authors><author><keyname>Hermelin</keyname><forenames>Danny</forenames></author><author><keyname>Mnich</keyname><forenames>Matthias</forenames></author><author><keyname>van Leeuwen</keyname><forenames>Erik Jan</forenames></author><author><keyname>Woeginger</keyname><forenames>Gerhard</forenames></author></authors><title>Domination When the Stars Are Out</title><categories>cs.DS cs.DM</categories><comments>Significantly expanded proofs and several additional results compared
  to v1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We algorithmize the recent structural characterization for claw-free graphs
by Chudnovsky and Seymour. Building on this result, we show that Dominating Set
on claw-free graphs is (i) fixed-parameter tractable and (ii) even possesses a
polynomial kernel. To complement these results, we establish that Dominating
Set is not fixed-parameter tractable on the slightly larger class of graphs
that exclude K_{1,4} as an induced subgraph (K_{1,4}-free graphs). We show that
our algorithmization can also be used to show that the related Connected
Dominating Set problem is fixed-parameter tractable on claw-free graphs. To
complement that result, we show that Connected Dominating Set has no polynomial
kernel on claw-free graphs and is not fixed-parameter tractable on K_{1,4}-free
graphs. Combined, our results provide a dichotomy for Dominating Set and
Connected Dominating Set on K_{1,L}-free graphs and show that the problem is
fixed-parameter tractable if and only if L &lt;= 3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0016</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0016</id><created>2010-11-30</created><authors><author><keyname>Zhou</keyname><forenames>Fen</forenames><affiliation>IRISA</affiliation></author><author><keyname>Molnar</keyname><forenames>Miklos</forenames><affiliation>IRISA</affiliation></author><author><keyname>Cousin</keyname><forenames>Bernard</forenames><affiliation>IRISA</affiliation></author></authors><title>Is Light-Tree Structure Optimal for Multicast Routing in Sparse Light
  Splitting WDM Networks?</title><categories>cs.NI</categories><proxy>ccsd</proxy><journal-ref>The 18th Internatonal Conference on Computer Communications and
  Networks (ICCCN 2009), 2009, San Francisco : United States (2009)</journal-ref><doi>10.1109/ICCCN.2009.5235386</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To minimize the number of wavelengths required by a multicast session in
sparse light splitting wavelength division multiplexing (WDM) networks, a
light-hierarchy structure, which occupies the same wavelength on all links, is
proposed to span as many destinations as possible. Different from a light-tree,
a light-hierarchy accepts cycles, which are used to traverse crosswise a
4-degree (or above) multicast incapable (MI) node twice (or above) and switch
two light signals on the same wavelengths to two destinations in the same
multicast session. In this paper, firstly, a graph renewal and distance
priority light-tree algorithm (GRDP-LT) is introduced to improve the quality of
light-trees built for a multicast request. Then, it is extended to compute
light-hierarchies. Obtained numerical results demonstrate the GRDP-LT
light-trees can achieve a much lower links stress, better wavelength channel
cost, and smaller average end-to-end delay as well as diameter than the
currently most efficient algorithm. Furthermore, compared to light-trees, the
performance in terms of link stress and network throughput is greatly improved
again by employing the light-hierarchy, while consuming the same amount of
wavelength channel cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0017</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0017</id><created>2010-11-30</created><authors><author><keyname>Zhou</keyname><forenames>Fen</forenames><affiliation>IRISA</affiliation></author><author><keyname>Molnar</keyname><forenames>Miklos</forenames><affiliation>IRISA</affiliation></author><author><keyname>Cousin</keyname><forenames>Bernard</forenames><affiliation>IRISA</affiliation></author></authors><title>Light-Hierarchy: The Optimal Structure for Multicast Routing in WDM Mesh
  Networks</title><categories>cs.NI</categories><proxy>ccsd</proxy><journal-ref>The 15th IEEE Symposium on Computers and Communications
  (ISCC2010), 2010, Riccione : Italie (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based on the false assumption that multicast incapable (MI) nodes could not
be traversed twice on the same wavelength, the light-tree structure was always
thought to be optimal for multicast routing in sparse splitting Wavelength
Division Multiplexing (WDM) networks. In fact, for establishing a multicast
session, an MI node could be crosswise visited more than once to switch a light
signal towards several destinations with only one wavelength through different
input and output pairs. This is called Cross Pair Switching (CPS). Thus, a new
multicast routing structure light-hierarchy is proposed for all-optical
multicast routing, which permits the cycles introduced by the CPS capability of
MI nodes. We proved that the optimal structure for minimizing the cost of
multicast routing is a set of light-hierarchies rather than the light-trees in
sparse splitting WDM networks. Integer linear programming (ILP) formulations
are developed to search the optimal light-hierarchies. Numerical results
verified that the light-hierarchy structure could save more cost than the
light-tree structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0018</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0018</id><created>2010-11-30</created><authors><author><keyname>Ostergaard</keyname><forenames>Jan</forenames></author><author><keyname>Heusdens</keyname><forenames>Richard</forenames></author><author><keyname>Jensen</keyname><forenames>Jesper</forenames></author></authors><title>n-Channel Asymmetric Entropy-Constrained Multiple-Description Lattice
  Vector Quantization</title><categories>cs.IT math.IT</categories><comments>49 pages, 4 figures. Accepted for publication in IEEE Transactions on
  Information Theory, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is about the design and analysis of an index-assignment (IA) based
multiple-description coding scheme for the n-channel asymmetric case. We use
entropy constrained lattice vector quantization and restrict attention to
simple reconstruction functions, which are given by the inverse IA function
when all descriptions are received or otherwise by a weighted average of the
received descriptions. We consider smooth sources with finite differential
entropy rate and MSE fidelity criterion. As in previous designs, our
construction is based on nested lattices which are combined through a single IA
function. The results are exact under high-resolution conditions and
asymptotically as the nesting ratios of the lattices approach infinity. For any
n, the design is asymptotically optimal within the class of IA-based schemes.
Moreover, in the case of two descriptions and finite lattice vector dimensions
greater than one, the performance is strictly better than that of existing
designs. In the case of three descriptions, we show that in the limit of large
lattice vector dimensions, points on the inner bound of Pradhan et al. can be
achieved. Furthermore, for three descriptions and finite lattice vector
dimensions, we show that the IA-based approach yields, in the symmetric case, a
smaller rate loss than the recently proposed source-splitting approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0023</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0023</id><created>2010-11-30</created><authors><author><keyname>Horv&#xe1;th</keyname><forenames>G&#xe9;za</forenames></author><author><keyname>Nagy</keyname><forenames>Benedek</forenames></author></authors><title>Pumping lemmas for linear and nonlinear context-free languages</title><categories>cs.FL</categories><msc-class>68Q45</msc-class><acm-class>F.4.3</acm-class><journal-ref>Acta Univ. Sapientiae Informatica, vol. 2, no. 2 (2010) 194-209</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pumping lemmas are created to prove that given languages are not belong to
certain language classes. There are several known pumping lemmas for the whole
class and some special classes of the context-free languages. In this paper we
prove new, interesting pumping lemmas for special linear and context-free
language classes. Some of them can be used to pump regular languages in two
place simultaneously. Other lemma can be used to pump context-free languages in
arbitrary many places.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0027</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0027</id><created>2010-11-30</created><authors><author><keyname>Zhou</keyname><forenames>Fen</forenames><affiliation>IRISA</affiliation></author><author><keyname>Molnar</keyname><forenames>Miklos</forenames><affiliation>IRISA</affiliation></author><author><keyname>Cousin</keyname><forenames>Bernard</forenames><affiliation>IRISA</affiliation></author></authors><title>Avoidance of multicast incapable branching nodes for multicast routing
  in WDM networks</title><categories>cs.NI</categories><proxy>ccsd</proxy><journal-ref>Photonic Network Communication 18, 3 (2009) 378-392</journal-ref><doi>10.1007/s11107-009-0200-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this articlewestudy themulticast routing problem in all-opticalWDMnetworks
under the spare light splitting constraint. To implement a multicast session,
several light-trees may have to be used due to the limited fanouts of network
nodes. Although many multicast routing algorithms have been proposed in order
to reduce the total number of wavelength channels used (total cost) for a
multicast session, the maximum number of wavelengths required in one fiber link
(link stress) and the end-to-end delay are two parameters which are not always
taken into consideration. It is known that the shortest path tree (SPT) results
in the optimal end-to-end delay, but it can not be employed directly for
multicast routing in sparse light splitting WDM networks. Hence, we propose a
novel wavelength routing algorithm which tries to avoid the multicast incapable
branching nodes (MIBs, branching nodes without splitting capability) in the
shortest-path-based multicast tree to diminish the link stress. Good parts of
the shortest-path-tree are retained by the algorithm to reduce the end-to-end
delay. The algorithm consists of tree steps: (1) aDijkstraPro algorithmwith
priority assignment and node adoption is introduced to produce a SPT with up to
38% fewer MIB nodes in the NSF topology and 46% fewerMIB nodes in the USA
Longhaul topology, (2) critical articulation and deepest branch heuristics are
used to process the MIB nodes, (3) a distance-based light-tree reconnection
algorithm is proposed to create the multicast light-trees. Extensive
simulations demonstrate the algorithm's efficiency in terms of link stress and
end-to-end delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0032</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0032</id><created>2010-11-30</created><authors><author><keyname>Iv&#xe1;nyi</keyname><forenames>Antal</forenames></author><author><keyname>Nov&#xe1;k</keyname><forenames>Bal&#xe1;zs</forenames></author></authors><title>Testing of sequences by simulation</title><categories>cs.DS</categories><msc-class>68M20</msc-class><acm-class>G.2.2</acm-class><journal-ref>Acta Univ. Sapientiae Informatica, vol. 2 no. 2 (2010) 135-153</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\xi$ be a random integer vector, having uniform distribution
\[\mathbf{P} \{\xi = (i_1,i_2,...,i_n) = 1/n^n \} \ \hbox{for} \ 1 \leq
i_1,i_2,...,i_n\leq n.\] A realization $(i_1,i_2,...,i_n)$ of $\xi$ is called
\textit{good}, if its elements are different. We present algorithms
\textsc{Linear}, \textsc{Backward}, \textsc{Forward}, \textsc{Tree},
\textsc{Garbage}, \textsc{Bucket} which decide whether a given realization is
good. We analyse the number of comparisons and running time of these algorithms
using simulation gathering data on all possible inputs for small values of $n$
and generating random inputs for large values of $n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0034</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0034</id><created>2010-11-30</created><authors><author><keyname>Pirzada</keyname><forenames>Shariefuddin</forenames></author><author><keyname>Zhou</keyname><forenames>Guofei</forenames></author><author><keyname>Iv&#xe1;nyi</keyname><forenames>Antal</forenames></author></authors><title>Score lists in multipartite hypertournaments</title><categories>cs.DM</categories><msc-class>05C65</msc-class><acm-class>G.2.2</acm-class><journal-ref>Acta Univ. Sapientiae Informatica vol. 2 no 2 (2010) 184-193</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given non-negative integers $n_{i}$ and $\alpha_{i}$ with $0 \leq \alpha_{i}
\leq n_i$ $(i=1,2,...,k)$, an
$[\alpha_{1},\alpha_{2},...,\alpha_{k}]$-$k$-partite hypertournament on
$\sum_{1}^{k}n_{i}$ vertices is a $(k+1)$-tuple $(U_{1},U_{2},...,U_{k},E)$,
where $U_{i}$ are $k$ vertex sets with $|U_{i}|=n_{i}$, and $E$ is a set of
$\sum_{1}^{k}\alpha_{i}$-tuples of vertices, called arcs, with exactly
$\alpha_{i}$ vertices from $U_{i}$, such that any $\sum_{1}^{k}\alpha_{i}$
subset $\cup_{1}^{k}U_{i}^{\prime}$ of $\cup_{1}^{k}U_{i}$, $E$ contains
exactly one of the $(\sum_{1}^{k} \alpha_{i})!$ $\sum_{1}^{k}\alpha_{i}$-tuples
whose entries belong to $\cup_{1}^{k}U_{i}^{\prime}$. We obtain necessary and
sufficient conditions for $k$ lists of non-negative integers in non-decreasing
order to be the losing score lists and to be the score lists of some
$k$-partite hypertournament.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0037</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0037</id><created>2010-11-30</created><authors><author><keyname>Zhou</keyname><forenames>Fen</forenames><affiliation>IRISA</affiliation></author><author><keyname>Molnar</keyname><forenames>Miklos</forenames><affiliation>IRISA</affiliation></author><author><keyname>Cousin</keyname><forenames>Bernard</forenames><affiliation>IRISA</affiliation></author></authors><title>Hypo-Steiner heuristic for multicast routing in all-optical WDM mesh
  networks</title><categories>cs.NI</categories><proxy>ccsd</proxy><journal-ref>Photonic Network Communication 20, 1 (2010) 33-42</journal-ref><doi>10.1007/s11107-010-0243-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In sparse light splitting all-optical WDM networks, the more destinations a
light-tree can accommodate, the fewer light-trees andwavelengths amulticast
session will require. In this article, a Hypo-Steiner light-tree algorithm
(HSLT) is proposed to construct a HSLT light-tree to include as many
destinations as possible. The upper bound cost of the light-trees built by HSLT
is given as N(N -1)/2, where N is the number of nodes in the network. The
analytical model proves that, under the same condition, more destinations could
be held in a HSLT than a Member-Only (Zhang et al., J. Lightware Technol,
18(12), 1917-1927 2000.) light-tree. Extensive simulations not only validate
the proof but also show that the proposed heuristic outperforms the existing
multicast routing algorithms by a large margin in terms of link stress,
throughput, and efficiency ofwavelength usage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0038</identifier>
 <datestamp>2010-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0038</id><created>2010-11-30</created><authors><author><keyname>Pataki</keyname><forenames>Norbert</forenames></author></authors><title>Testing by C++ template metaprograms</title><categories>cs.SE</categories><msc-class>62N03</msc-class><acm-class>D.2.5</acm-class><journal-ref>Acta Univ. Sapientiae Informatica, vol. 2 no. 2 (2010) 154-167</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Testing is one of the most indispensable tasks in software engineering. The
role of testing in software development has grown significantly because testing
is able to reveal defects in the code in an early stage of development. Many
unit test frameworks compatible with C/C++ code exist, but a standard one is
missing. Unfortunately, many unsolved problems can be mentioned with the
existing methods, for example usually external tools are necessary for testing
C++ programs.
  In this paper we present a new approach for testing C++ programs. Our
solution is based on C++ template metaprogramming facilities, so it can work
with the standard-compliant compilers. The metaprogramming approach ensures
that the overhead of testing is minimal at runtime. This approach also supports
that the specification language can be customized among other advantages.
Nevertheless, the only necessary tool is the compiler itself.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0042</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0042</id><created>2010-11-30</created><authors><author><keyname>Antal</keyname><forenames>Margit</forenames></author><author><keyname>Er\Hos</keyname><forenames>Levente</forenames></author><author><keyname>Imre</keyname><forenames>Attila</forenames></author></authors><title>Computerized adaptive testing: implementation issues</title><categories>cs.CY</categories><msc-class>97U50</msc-class><acm-class>K.3.1</acm-class><journal-ref>Acta Univ. Sapientiae Informatica, vol. 2 no. 2 (2010) 168-183</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the fastest evolving field among teaching and learning research is
students' performance evaluation. Computer based testing systems are
increasingly adopted by universities. However, the implementation and
maintenance of such a system and its underlying item bank is a challenge for an
inexperienced tutor. Therefore, this paper discusses the advantages and
disadvantages of Computer Adaptive Test (CAT) systems compared to Computer
Based Test systems. Furthermore, a few item selection strategies are compared
in order to overcome the item exposure drawback of such systems. The paper also
presents our CAT system along its development steps. Besides, an item
difficulty estimation technique is presented based on data taken from our
self-assessment system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0047</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0047</id><created>2010-11-30</created><authors><author><keyname>Jakub&#x10d;o</keyname><forenames>Peter</forenames></author><author><keyname>&#x160;imo&#x148;&#xe1;k</keyname><forenames>Slavom&#xed;r</forenames></author><author><keyname>&#xc1;d&#xe1;m</keyname><forenames>Norbert</forenames></author></authors><title>Communication model of emuStudio emulation platform</title><categories>cs.OH</categories><journal-ref>Acta Univ. Sapientiae Informatica, vol. 2 no. 2 (2010) 117-134</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Within the paper a description of communication model of plug-in based
emuStudio emulation platform is given. The platform mentioned above allows the
emulation of whole computer systems, configurable to the level of its
components, represented by the plug-in modules of the platform. Development
tasks still are in progress at the home institution of the authors. Currently
the platform is exploited for teaching purposes within subjects aimed at
machine-oriented languages and computer architectures. Versatility of the
platform, given by its plug-in based architecture is a big advantage, when used
as a teaching support tool. The paper briefly describes the emuStudio platform
at its introductory part and then the mechanisms of inter-module communication
are described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0058</identifier>
 <datestamp>2010-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0058</id><created>2010-11-30</created><authors><author><keyname>K&#xe1;tai</keyname><forenames>Zolt&#xe1;n</forenames></author></authors><title>Modelling dynamic programming problems by generalized d-graphs</title><categories>cs.DS</categories><msc-class>68W40</msc-class><acm-class>D.1</acm-class><journal-ref>Acta Univ. Sapientiae Informatica, vol. 2 no. 2 (2010) 210-230</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce the concept of generalized d-graph (admitting
cycles) as special dependency-graphs for modelling dynamic programming (DP)
problems. We describe the d-graph versions of three famous single-source
shortest algorithms (The algorithm based on the topological order of the
vertices, Dijkstra algorithm and Bellman-Ford algorithm), which can be viewed
as general DP strategies in the case of three different class of optimization
problems. The new modelling method also makes possible to classify DP problems
and the corresponding DP strategies in term of graph theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0065</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0065</id><created>2010-11-30</created><updated>2012-10-09</updated><authors><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author></authors><title>Counting in Graph Covers: A Combinatorial Characterization of the Bethe
  Entropy Function</title><categories>cs.IT cond-mat.stat-mech cs.AI math.CO math.IT</categories><comments>Submitted to IEEE Trans. Inf. Theory, Nov. 20, 2010; rev. Sep. 22,
  2012; current version, Oct. 9, 2012. Main changes from v1 to v2: new example
  (Example 34), new lemma (Lemma 35), changed some notation, changed the domain
  of the Gibbs free energy function and related functions, reordered some
  sections/appendices, fixed some typos, improved the background discussion,
  added some new references</comments><journal-ref>IEEE Trans. Inf. Theory, vol. 59, pp. 6018-6048, Sept. 2013</journal-ref><doi>10.1109/TIT.2013.2264715</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a combinatorial characterization of the Bethe entropy function of
a factor graph, such a characterization being in contrast to the original,
analytical, definition of this function. We achieve this combinatorial
characterization by counting valid configurations in finite graph covers of the
factor graph. Analogously, we give a combinatorial characterization of the
Bethe partition function, whose original definition was also of an analytical
nature. As we point out, our approach has similarities to the replica method,
but also stark differences. The above findings are a natural backdrop for
introducing a decoder for graph-based codes that we will call symbolwise
graph-cover decoding, a decoder that extends our earlier work on blockwise
graph-cover decoding. Both graph-cover decoders are theoretical tools that help
towards a better understanding of message-passing iterative decoding, namely
blockwise graph-cover decoding links max-product (min-sum) algorithm decoding
with linear programming decoding, and symbolwise graph-cover decoding links
sum-product algorithm decoding with Bethe free energy function minimization at
temperature one. In contrast to the Gibbs entropy function, which is a concave
function, the Bethe entropy function is in general not concave everywhere. In
particular, we show that every code picked from an ensemble of regular
low-density parity-check codes with minimum Hamming distance growing (with high
probability) linearly with the block length has a Bethe entropy function that
is convex in certain regions of its domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0081</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0081</id><created>2010-11-30</created><updated>2010-12-09</updated><authors><author><keyname>Srinivas</keyname><forenames>K. V.</forenames></author><author><keyname>Adve</keyname><forenames>Raviraj S.</forenames></author><author><keyname>Eckford</keyname><forenames>Andrew W.</forenames></author></authors><title>Molecular communication in fluid media: The additive inverse Gaussian
  noise channel</title><categories>cs.IT math.IT</categories><comments>28 pages, 8 figures. Submitted to IEEE Transactions on Information
  Theory. Corrects minor typos in the first version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider molecular communication, with information conveyed in the time of
release of molecules. The main contribution of this paper is the development of
a theoretical foundation for such a communication system. Specifically, we
develop the additive inverse Gaussian (IG) noise channel model: a channel in
which the information is corrupted by noise with an inverse Gaussian
distribution. We show that such a channel model is appropriate for molecular
communication in fluid media - when propagation between transmitter and
receiver is governed by Brownian motion and when there is positive drift from
transmitter to receiver. Taking advantage of the available literature on the IG
distribution, upper and lower bounds on channel capacity are developed, and a
maximum likelihood receiver is derived. Theory and simulation results are
presented which show that such a channel does not have a single quality measure
analogous to signal-to-noise ratio in the AWGN channel. It is also shown that
the use of multiple molecules leads to reduced error rate in a manner akin to
diversity order in wireless communications. Finally, we discuss some open
problems in molecular communications that arise from the IG system model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0084</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0084</id><created>2010-11-30</created><authors><author><keyname>C</keyname><forenames>Harshith</forenames></author><author><keyname>Shastry</keyname><forenames>Karthik R.</forenames></author><author><keyname>Ravindran</keyname><forenames>Manoj</forenames></author><author><keyname>Srikanth</keyname><forenames>M. V. V. N. S.</forenames></author><author><keyname>Lakshmikhanth</keyname><forenames>Naveen</forenames></author></authors><title>Survey on Various Gesture Recognition Techniques for Interfacing
  Machines Based on Ambient Intelligence</title><categories>cs.AI cs.CV cs.HC cs.RO</categories><comments>12 PAGES</comments><msc-class>68-02</msc-class><doi>10.5121/ijcses.2010.1203</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gesture recognition is mainly apprehensive on analyzing the functionality of
human wits. The main goal of gesture recognition is to create a system which
can recognize specific human gestures and use them to convey information or for
device control. Hand gestures provide a separate complementary modality to
speech for expressing ones ideas. Information associated with hand gestures in
a conversation is degree,discourse structure, spatial and temporal structure.
The approaches present can be mainly divided into Data-Glove Based and Vision
Based approaches. An important face feature point is the nose tip. Since nose
is the highest protruding point from the face. Besides that, it is not affected
by facial expressions.Another important function of the nose is that it is able
to indicate the head pose. Knowledge of the nose location will enable us to
align an unknown 3D face with those in a face database. Eye detection is
divided into eye position detection and eye contour detection. Existing works
in eye detection can be classified into two major categories: traditional
image-based passive approaches and the active IR based approaches. The former
uses intensity and shape of eyes for detection and the latter works on the
assumption that eyes have a reflection under near IR illumination and produce
bright/dark pupil effect. The traditional methods can be broadly classified
into three categories: template based methods,appearance based methods and
feature based methods. The purpose of this paper is to compare various human
Gesture recognition systems for interfacing machines directly to human wits
without any corporeal media in an ambient environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0096</identifier>
 <datestamp>2010-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0096</id><created>2010-12-01</created><updated>2010-12-02</updated><authors><author><keyname>van Hoeij</keyname><forenames>Mark</forenames></author><author><keyname>Pal</keyname><forenames>Vivek</forenames></author></authors><title>Isomorphisms of Algebraic Number Fields</title><categories>cs.SC math.NT</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\mathbb{Q}(\alpha)$ and $\mathbb{Q}(\beta)$ be algebraic number fields.
We describe a new method to find (if they exist) all isomorphisms,
$\mathbb{Q}(\beta) \rightarrow \mathbb{Q}(\alpha)$. The algorithm is
particularly efficient if the number of isomorphisms is one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0112</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0112</id><created>2010-12-01</created><authors><author><keyname>Dikaliotis</keyname><forenames>Theodoros K.</forenames></author><author><keyname>Ho</keyname><forenames>Tracey</forenames></author><author><keyname>Jaggi</keyname><forenames>Sidharth</forenames></author><author><keyname>Vyetrenko</keyname><forenames>Svitlana</forenames></author><author><keyname>Yao</keyname><forenames>Hongyi</forenames></author><author><keyname>Effros</keyname><forenames>Michelle</forenames></author><author><keyname>Kliewer</keyname><forenames>Joerg</forenames></author><author><keyname>Erez</keyname><forenames>Elona</forenames></author></authors><title>Multiple-access Network Information-flow and Correction Codes</title><categories>cs.IT math.IT</categories><comments>This journal paper is a continuation of the conference paper written
  by S. Vyetrenko, T. Ho, M. Effros, J. Kliewer, E Erez, &quot;Rate regions for
  coherent and noncoherent multisource network error correction,&quot; IEEE ISIT,
  Jun. 2009 and the conference paper written by H. Yao, T. K Dikaliotis, S.
  Jaggi, and T. Ho, &quot;Multi-source operator channels: Efficient
  capacity-achieving codes,&quot; IEEE ITW, Dublin 2010</comments><report-no>10-312</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work considers the multiple-access multicast error-correction scenario
over a packetized network with $z$ malicious edge adversaries. The network has
min-cut $m$ and packets of length $\ell$, and each sink demands all information
from the set of sources $\sources$. The capacity region is characterized for
both a &quot;side-channel&quot; model (where sources and sinks share some random bits
that are secret from the adversary) and an &quot;omniscient&quot; adversarial model
(where no limitations on the adversary's knowledge are assumed). In the
&quot;side-channel&quot; adversarial model, the use of a secret channel allows higher
rates to be achieved compared to the &quot;omniscient&quot; adversarial model, and a
polynomial-complexity capacity-achieving code is provided. For the &quot;omniscient&quot;
adversarial model, two capacity-achieving constructions are given: the first is
based on random subspace code design and has complexity exponential in $\ell
m$, while the second uses a novel multiple-field-extension technique and has
$O(\ell m^{|\sources|})$ complexity, which is polynomial in the network size.
Our code constructions are &quot;end-to-end&quot; in that all nodes except the sources
and sinks are oblivious to the adversaries and may simply implement predesigned
linear network codes (random or otherwise). Also, the sources act independently
without knowledge of the data from other sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0122</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0122</id><created>2010-12-01</created><authors><author><keyname>Azim</keyname><forenames>Md Enamul</forenames></author><author><keyname>Akbar</keyname><forenames>Md Mostofa</forenames></author><author><keyname>Kaykobad</keyname><forenames>M</forenames></author></authors><title>Some fascinating series and their sums</title><categories>cs.DM math.HO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present some interesting results involving summation of
series in particular trigonometric ones. We failed to locate these results in
existing literature or in the web like MathWorld
(http://mathworld.wolfram.com/) nor could we derive them using software for
analytical computation like Maple. The identities are beautiful and involve
finite series.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0126</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0126</id><created>2010-12-01</created><authors><author><keyname>Chaouech</keyname><forenames>Helmi</forenames></author><author><keyname>Bouallegue</keyname><forenames>Ridha</forenames></author></authors><title>Channel Estimation And Multiuser Detection In Asynchronous Satellite
  Communications</title><categories>cs.NI</categories><comments>14 pages, 9 figures</comments><journal-ref>International Journal of Wireless &amp; Mobile Networks, November 2010</journal-ref><doi>10.5121/ijwmn.2010.2411</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new method of channel estimation for asynchronous
additive white Gaussian noise channels in satellite communications. This method
is based on signals correlation and multiuser interference cancellation which
adopts a successive structure. Propagation delays and signals amplitudes are
jointly estimated in order to be used for data detection at the receiver. As, a
multiuser detector, a single stage successive interference cancellation (SIC)
architecture is analyzed and integrated to the channel estimation technique and
the whole system is evaluated. The satellite access method adopted is the
direct sequence code division multiple access (DS CDMA) one. To evaluate the
channel estimation and the detection technique, we have simulated a satellite
uplink with an asynchronous multiuser access.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0142</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0142</id><created>2010-12-01</created><authors><author><keyname>Mendes</keyname><forenames>R. S.</forenames></author><author><keyname>Ribeiro</keyname><forenames>H. V.</forenames></author><author><keyname>Freire</keyname><forenames>F. C. M.</forenames></author><author><keyname>Tateishi</keyname><forenames>A. A.</forenames></author><author><keyname>Lenzi</keyname><forenames>E. K.</forenames></author></authors><title>Universal patterns in sound amplitudes of songs and music genres</title><categories>physics.data-an cs.IR cs.SD</categories><comments>Accepted for publication as a Brief Report in Physical Review E</comments><journal-ref>Phys. Rev. E 83, 017101 (2011)</journal-ref><doi>10.1103/PhysRevE.83.017101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report a statistical analysis over more than eight thousand songs.
Specifically, we investigate the probability distribution of the normalized
sound amplitudes. Our findings seems to suggest a universal form of
distribution which presents a good agreement with a one-parameter stretched
Gaussian. We also argue that this parameter can give information on music
complexity, and consequently it goes towards classifying songs as well as music
genres. Additionally, we present statistical evidences that correlation aspects
of the songs are directly related with the non-Gaussian nature of their sound
amplitude distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0160</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0160</id><created>2010-12-01</created><authors><author><keyname>Plini</keyname><forenames>Paolo</forenames></author><author><keyname>Di Franco</keyname><forenames>Sabin</forenames></author><author><keyname>De Santis</keyname><forenames>Valentina</forenames></author><author><keyname>Uricchio</keyname><forenames>Vito F.</forenames></author><author><keyname>De Carlo</keyname><forenames>Dario</forenames></author><author><keyname>D'Arpa</keyname><forenames>Stefania</forenames></author><author><keyname>De Martino</keyname><forenames>Monica</forenames></author><author><keyname>Albertoni</keyname><forenames>Riccardo</forenames></author></authors><title>A Joint Initiative to Support the Semantic Interoperability within the
  GIIDA Project</title><categories>cs.DL</categories><acm-class>H.2.8; H.3.7</acm-class><journal-ref>Proceedings of the Gi4DM 2010 Conference: Geomatics for Crisis
  Management (Gi4DM 2010). Torino, Italy, Feb 2010, ISBN 978-88-903132-3-3</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The GIIDA project aims to develop a digital infrastructure for the spatial
information within CNR. It is foreseen to use semantic-oriented technologies to
ease information modeling and connecting, according to international standards
like the ISO/IEC 11179. Complex information management systems, like GIIDA,
will take benefit from the use of terminological tools like thesauri that make
available a reference lexicon for the indexing and retrieval of information.
Within GIIDA the goal is to make available the EARTh thesaurus (Environmental
Applications Reference Thesaurus), developed by the CNR-IIA-EKOLab. A web-based
software, developed by the CNR-Water Research Institute (IRSA) was implemented
to allow consultation and utilization of thesaurus through the web. This
service is a useful tool to ensure interoperability between thesaurus and other
systems of the indexing, with, the idea of cooperating to develop a
comprehensive system of knowledge organization, that could be defined
integrated, open, multi-functional and multilingual. Currently the system is
available in multiple languages mode (Italian - English) and navigation can be
done in the following ways: Alphabetical, Hierarchical and for Themes. A full
search allows to find any term by searching for the whole term or a part of it
and as well as allows to filter the results by themes. Within a collaborative
initiative with the CNR-Institute of Applied Mathematics and Information
Technology (IMATI) a SKOS (Simple Knowledge Organization System) version of
EARTh was developed. This will ensure the possibility to support the use of the
thesaurus within the framework of the Semantic Web in order to be used in
decentralized metadata applications
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0178</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0178</id><created>2010-12-01</created><updated>2011-07-26</updated><authors><author><keyname>Helbing</keyname><forenames>Dirk</forenames></author><author><keyname>Balietti</keyname><forenames>Stefano</forenames></author></authors><title>From Social Data Mining to Forecasting Socio-Economic Crisis</title><categories>cs.CY cs.DB cs.DC</categories><comments>65 pages, 1 figure, Visioneer White Paper, see
  http://www.visioneer.ethz.ch</comments><journal-ref>The European Physical Journal - Special Topics Volume 195, Number
  1, 3-68, DOI: 10.1140/epjst/e2011-01401-8</journal-ref><doi>10.1140/epjst/e2011-01401-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Socio-economic data mining has a great potential in terms of gaining a better
understanding of problems that our economy and society are facing, such as
financial instability, shortages of resources, or conflicts. Without
large-scale data mining, progress in these areas seems hard or impossible.
Therefore, a suitable, distributed data mining infrastructure and research
centers should be built in Europe. It also appears appropriate to build a
network of Crisis Observatories. They can be imagined as laboratories devoted
to the gathering and processing of enormous volumes of data on both natural
systems such as the Earth and its ecosystem, as well as on human
techno-socio-economic systems, so as to gain early warnings of impending
events. Reality mining provides the chance to adapt more quickly and more
accurately to changing situations. Further opportunities arise by individually
customized services, which however should be provided in a privacy-respecting
way. This requires the development of novel ICT (such as a self- organizing
Web), but most likely new legal regulations and suitable institutions as well.
As long as such regulations are lacking on a world-wide scale, it is in the
public interest that scientists explore what can be done with the huge data
available. Big data do have the potential to change or even threaten democratic
societies. The same applies to sudden and large-scale failures of ICT systems.
Therefore, dealing with data must be done with a large degree of responsibility
and care. Self-interests of individuals, companies or institutions have limits,
where the public interest is affected, and public interest is not a sufficient
justification to violate human rights of individuals. Privacy is a high good,
as confidentiality is, and damaging it would have serious side effects for
society.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0196</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0196</id><created>2010-12-01</created><updated>2011-03-23</updated><authors><author><keyname>Zeng</keyname><forenames>An</forenames></author><author><keyname>Lu</keyname><forenames>Linyuan</forenames></author></authors><title>Coarse Graining for Synchronization in Directed Networks</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI</categories><comments>9 pages, 7 figures</comments><journal-ref>Physical Review E 83, 056123 (2011)</journal-ref><doi>10.1103/PhysRevE.83.056123</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coarse graining model is a promising way to analyze and visualize large-scale
networks. The coarse-grained networks are required to preserve the same
statistical properties as well as the dynamic behaviors as the initial
networks. Some methods have been proposed and found effective in undirected
networks, while the study on coarse graining in directed networks lacks of
consideration. In this paper, we proposed a Topology-aware Coarse Graining
(TCG) method to coarse grain the directed networks. Performing the linear
stability analysis of synchronization and numerical simulation of the Kuramoto
model on four kinds of directed networks, including tree-like networks and
variants of Barab\'{a}si-Albert networks, Watts-Strogatz networks and
Erd\&quot;{o}s-R\'{e}nyi networks, we find our method can effectively preserve the
network synchronizability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0197</identifier>
 <datestamp>2012-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0197</id><created>2010-12-01</created><updated>2011-07-25</updated><authors><author><keyname>Gillis</keyname><forenames>Nicolas</forenames></author><author><keyname>Glineur</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>Low-Rank Matrix Approximation with Weights or Missing Data is NP-hard</title><categories>math.OC cs.SY math.NA</categories><comments>Proof of Lemma 4 (Lemma 3 in v1) has been corrected. Some remarks and
  comments have been added. Accepted in SIAM Journal on Matrix Analysis and
  Applications</comments><journal-ref>SIAM J. Matrix Anal. &amp; Appl. 32 (4), pp. 1149-1165, 2011</journal-ref><doi>10.1137/110820361</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Weighted low-rank approximation (WLRA), a dimensionality reduction technique
for data analysis, has been successfully used in several applications, such as
in collaborative filtering to design recommender systems or in computer vision
to recover structure from motion. In this paper, we study the computational
complexity of WLRA and prove that it is NP-hard to find an approximate
solution, even when a rank-one approximation is sought. Our proofs are based on
a reduction from the maximum-edge biclique problem, and apply to strictly
positive weights as well as binary weights (the latter corresponding to
low-rank matrix approximation with missing data).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0201</identifier>
 <datestamp>2013-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0201</id><created>2010-12-01</created><updated>2013-03-01</updated><authors><author><keyname>Raschke</keyname><forenames>Mathias</forenames></author><author><keyname>Schl&#xe4;pfer</keyname><forenames>Markus</forenames></author><author><keyname>Trantopoulos</keyname><forenames>Konstantinos</forenames></author></authors><title>Generation of degree-correlated networks using copulas</title><categories>physics.data-an cs.SI math-ph math.MP physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamical processes on complex networks such as information propagation,
innovation diffusion, cascading failures or epidemic spreading are highly
affected by their underlying topologies as characterized by, for instance,
degree-degree correlations. Here, we introduce the concept of copulas in order
to artificially generate random networks with an arbitrary degree distribution
and a rich a priori degree-degree correlation (or `association') structure. The
accuracy of the proposed formalism and corresponding algorithm is numerically
confirmed. The derived network ensembles can be systematically deployed as
proper null models, in order to unfold the complex interplay between the
topology of real networks and the dynamics on top of them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0203</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0203</id><created>2010-12-01</created><authors><author><keyname>Zeng</keyname><forenames>An</forenames></author><author><keyname>Son</keyname><forenames>Seung-Woo</forenames></author><author><keyname>Yeung</keyname><forenames>Chi Ho</forenames></author><author><keyname>Fan</keyname><forenames>Ying</forenames></author><author><keyname>Di</keyname><forenames>Zengru</forenames></author></authors><title>Enhancing synchronization by directionality in complex networks</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>4 pages, 5 figures</comments><journal-ref>Phys. Rev. E 83, 045101(R) (2011)</journal-ref><doi>10.1103/PhysRevE.83.045101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We proposed a method called residual edge-betweenness gradient (REBG) to
enhance synchronizability of networks by assignment of link direction while
keeping network topology and link weight unchanged. Direction assignment has
been shown to improve the synchronizability of undirected networks in general,
but we find that in some cases incommunicable components emerge and networks
fail to synchronize. We show that the REBG method can effectively avoid the
synchronization failure ($R=\lambda_{2}^{r}/\lambda_{N}^{r}=0$) which occurs in
the residual degree gradient (RDG) method proposed in Phys. Rev. Lett. 103,
228702 (2009). Further experiments show that REBG method enhance
synchronizability in networks with community structure as compared with the RDG
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0206</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0206</id><created>2010-12-01</created><authors><author><keyname>Havlin</keyname><forenames>S.</forenames></author><author><keyname>Araujo</keyname><forenames>N. A. M.</forenames></author><author><keyname>Buldyrev</keyname><forenames>S. V.</forenames></author><author><keyname>Dias</keyname><forenames>C. S.</forenames></author><author><keyname>Parshani</keyname><forenames>R.</forenames></author><author><keyname>Paul</keyname><forenames>G.</forenames></author><author><keyname>Stanley</keyname><forenames>H. E.</forenames></author></authors><title>Catastrophic Cascade of Failures in Interdependent Networks</title><categories>physics.data-an cond-mat.stat-mech cs.SI physics.comp-ph physics.soc-ph</categories><comments>15 pages, 10 figures, International School of Physics &quot;Enrico Fermi&quot;
  2010</comments><report-no>Varenna 2010</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern network-like systems are usually coupled in such a way that failures
in one network can affect the entire system. In infrastructures, biology,
sociology, and economy, systems are interconnected and events taking place in
one system can propagate to any other coupled system. Recent studies on such
coupled systems show that the coupling increases their vulnerability to random
failure. Properties for interdependent networks differ significantly from those
of single-network systems. In this article, these results are reviewed and the
main properties discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0223</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0223</id><created>2010-12-01</created><authors><author><keyname>Kannan</keyname><forenames>A.</forenames></author><author><keyname>Mohan</keyname><forenames>V.</forenames></author><author><keyname>Anbazhagan</keyname><forenames>N.</forenames></author></authors><title>An Effective Method of Image Retrieval using Image Mining Techniques</title><categories>cs.CV cs.MM</categories><doi>10.5121/ijma.2010.2402</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present research scholars are having keen interest in doing their
research activities in the area of Data mining all over the world. Especially,
[13]Mining Image data is the one of the essential features in this present
scenario since image data plays vital role in every aspect of the system such
as business for marketing, hospital for surgery, engineering for construction,
Web for publication and so on. The other area in the Image mining system is the
Content-Based Image Retrieval (CBIR) which performs retrieval based on the
similarity defined in terms of extracted features with more objectiveness. The
drawback in CBIR is the features of the query image alone are considered.
Hence, a new technique called Image retrieval based on optimum clusters is
proposed for improving user interaction with image retrieval systems by fully
exploiting the similarity information. The index is created by describing the
images according to their color characteristics, with compact feature vectors,
that represent typical color distributions [12].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0230</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0230</id><created>2010-12-01</created><authors><author><keyname>Moosa</keyname><forenames>Tanaeem M.</forenames></author><author><keyname>Rahman</keyname><forenames>M. Sohel</forenames></author></authors><title>Improved Algorithms for the Point-Set Embeddability problem for Plane
  3-Trees</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the point set embeddability problem, we are given a plane graph $G$ with
$n$ vertices and a point set $S$ with $n$ points. Now the goal is to answer the
question whether there exists a straight-line drawing of $G$ such that each
vertex is represented as a distinct point of $S$ as well as to provide an
embedding if one does exist. Recently, in \cite{DBLP:conf/gd/NishatMR10}, a
complete characterization for this problem on a special class of graphs known
as the plane 3-trees was presented along with an efficient algorithm to solve
the problem. In this paper, we use the same characterization to devise an
improved algorithm for the same problem. Much of the efficiency we achieve
comes from clever uses of the triangular range search technique. We also study
a generalized version of the problem and present improved algorithms for this
version of the problem as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0232</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0232</id><created>2010-12-01</created><updated>2011-02-16</updated><authors><author><keyname>Hugel</keyname><forenames>Thomas</forenames></author></authors><title>Kolmogorov-Loveland Sets and Advice Complexity Classes</title><categories>cs.CC</categories><comments>11 pages - typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Loveland complexity is a variant of Kolmogorov complexity, where it is asked
to output separately the bits of the desired string, instead of the string
itself. Similarly to the resource-bounded Kolmogorov sets we define Loveland
sets. We highlight a structural connection between resource-bounded Loveland
sets and some advice complexity classes. This structural connection enables us
to map to advice complexity classes some properties of Kolmogorov sets first
noticed by Hartmanis and thoroughly investigated in Longpr\'e's thesis: 1.
Non-inclusion properties of Loveland sets result in hierarchy properties on the
corresponding advice complexity classes; 2. Immunity properties of Loveland
sets result in the non-existence of natural proofs between the corresponding
advice complexity classes, in the sense of Razborov &amp; Rudich.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0253</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0253</id><created>2010-12-01</created><authors><author><keyname>Ammendola</keyname><forenames>Roberto</forenames></author><author><keyname>Biagioni</keyname><forenames>Andrea</forenames></author><author><keyname>Frezza</keyname><forenames>Ottorino</forenames></author><author><keyname>Cicero</keyname><forenames>Francesca Lo</forenames></author><author><keyname>Lonardo</keyname><forenames>Alessandro</forenames></author><author><keyname>Paolucci</keyname><forenames>Pier</forenames></author><author><keyname>Petronzio</keyname><forenames>Roberto</forenames></author><author><keyname>Rossetti</keyname><forenames>Davide</forenames></author><author><keyname>Salamon</keyname><forenames>Andrea</forenames></author><author><keyname>Salina</keyname><forenames>Gaetano</forenames></author><author><keyname>Simula</keyname><forenames>Francesco</forenames></author><author><keyname>Tantalo</keyname><forenames>Nazario</forenames></author><author><keyname>Tosoratto</keyname><forenames>Laura</forenames></author><author><keyname>Vicini</keyname><forenames>Piero</forenames></author></authors><title>APEnet+: a 3D toroidal network enabling Petaflops scale Lattice QCD
  simulations on commodity clusters</title><categories>hep-lat cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many scientific computations need multi-node parallelism for matching up both
space (memory) and time (speed) ever-increasing requirements. The use of GPUs
as accelerators introduces yet another level of complexity for the programmer
and may potentially result in large overheads due to the complex memory
hierarchy. Additionally, top-notch problems may easily employ more than a
Petaflops of sustained computing power, requiring thousands of GPUs
orchestrated with some parallel programming model. Here we describe APEnet+,
the new generation of our interconnect, which scales up to tens of thousands of
nodes with linear cost, thus improving the price/performance ratio on large
clusters. The project target is the development of the Apelink+ host adapter
featuring a low latency, high bandwidth direct network, state-of-the-art wire
speeds on the links and a PCIe X8 gen2 host interface. It features hardware
support for the RDMA programming model and experimental acceleration of GPU
networking. A Linux kernel driver, a set of low-level RDMA APIs and an OpenMPI
library driver are available, allowing for painless porting of standard
applications. Finally, we give an insight of future work and intended
developments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0255</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0255</id><created>2010-12-01</created><authors><author><keyname>Chuzhoy</keyname><forenames>Julia</forenames></author></authors><title>An Algorithm for the Graph Crossing Number Problem</title><categories>cs.DS cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the Minimum Crossing Number problem: given an $n$-vertex graph $G$,
the goal is to find a drawing of $G$ in the plane with minimum number of edge
crossings. This is one of the central problems in topological graph theory,
that has been studied extensively over the past three decades. The first
non-trivial efficient algorithm for the problem, due to Leighton and Rao,
achieved an $O(n\log^4n)$-approximation for bounded degree graphs. This
algorithm has since been improved by poly-logarithmic factors, with the best
current approximation ratio standing on $O(n \poly(d) \log^{3/2}n)$ for graphs
with maximum degree $d$. In contrast, only APX-hardness is known on the
negative side.
  In this paper we present an efficient randomized algorithm to find a drawing
of any $n$-vertex graph $G$ in the plane with $O(OPT^{10}\cdot \poly(d \log
n))$ crossings, where $OPT$ is the number of crossings in the optimal solution,
and $d$ is the maximum vertex degree in $G$. This result implies an
$\tilde{O}(n^{9/10} \poly(d))$-approximation for Minimum Crossing Number, thus
breaking the long-standing $\tilde{O}(n)$-approximation barrier for
bounded-degree graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0256</identifier>
 <datestamp>2015-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0256</id><created>2010-12-01</created><updated>2015-07-28</updated><authors><author><keyname>Efraimidis</keyname><forenames>Pavlos S.</forenames></author></authors><title>Weighted Random Sampling over Data Streams</title><categories>cs.DS</categories><comments>Corrected minor typos. Infeasible items are now additionally called
  &quot;overweight&quot; items (WRS-N-P). Enriched the Introduction (Section 1) with more
  text and references to related work. Revised the description of sampling with
  a bounded number of replacements (Section 4.2)</comments><report-no>Technical Report LPDP-2010-03</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we present a comprehensive treatment of weighted random
sampling (WRS) over data streams. More precisely, we examine two natural
interpretations of the item weights, describe an existing algorithm for each
case ([2, 4]), discuss sampling with and without replacement and show
adaptations of the algorithms for several WRS problems and evolving data
streams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0259</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0259</id><created>2010-12-01</created><authors><author><keyname>Efraimidis</keyname><forenames>Pavlos S.</forenames></author></authors><title>(\alpha, \beta) Fibonacci Search</title><categories>cs.DS</categories><report-no>Technical Report LPDP-2010-02</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knuth [12, Page 417] states that &quot;the (program of the) Fibonaccian search
technique looks very mysterious at first glance&quot; and that &quot;it seems to work by
magic&quot;. In this work, we show that there is even more magic in Fibonaccian (or
else Fibonacci) search. We present a generalized Fibonacci procedure that
follows perfectly the implicit optimal decision tree for search problems where
the cost of each comparison depends on its outcome.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0260</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0260</id><created>2010-12-01</created><authors><author><keyname>Basu</keyname><forenames>Prithwish</forenames></author><author><keyname>Bar-Noy</keyname><forenames>Amotz</forenames></author><author><keyname>Ramanathan</keyname><forenames>Ram</forenames></author><author><keyname>Johnson</keyname><forenames>Matthew P.</forenames></author></authors><title>Modeling and Analysis of Time-Varying Graphs</title><categories>cs.NI cs.DM cs.SI physics.soc-ph</categories><comments>11 pages, Twocolumn, 10pt font, 8 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We live in a world increasingly dominated by networks -- communications,
social, information, biological etc. A central attribute of many of these
networks is that they are dynamic, that is, they exhibit structural changes
over time. While the practice of dynamic networks has proliferated, we lag
behind in the fundamental, mathematical understanding of network dynamism.
Existing research on time-varying graphs ranges from preliminary algorithmic
studies (e.g., Ferreira's work on evolving graphs) to analysis of specific
properties such as flooding time in dynamic random graphs. A popular model for
studying dynamic graphs is a sequence of graphs arranged by increasing
snapshots of time. In this paper, we study the fundamental property of
reachability in a time-varying graph over time and characterize the latency
with respect to two metrics, namely store-or-advance latency and cut-through
latency. Instead of expected value analysis, we concentrate on characterizing
the exact probability distribution of routing latency along a randomly
intermittent path in two popular dynamic random graph models. Using this
analysis, we characterize the loss of accuracy (in a probabilistic setting)
between multiple temporal graph models, ranging from one that preserves all the
temporal ordering information for the purpose of computing temporal graph
properties to one that collapses various snapshots into one graph (an operation
called smashing), with multiple intermediate variants. We also show how some
other traditional graph theoretic properties can be extended to the temporal
domain. Finally, we propose algorithms for controlling the progress of a packet
in single-copy adaptive routing schemes in various dynamic random graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0280</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0280</id><created>2010-12-01</created><authors><author><keyname>Grabowski</keyname><forenames>Szymon</forenames></author><author><keyname>Faro</keyname><forenames>Simone</forenames></author><author><keyname>Giaquinta</keyname><forenames>Emanuele</forenames></author></authors><title>String Matching with Inversions and Translocations in Linear Average
  Time (Most of the Time)</title><categories>cs.DS</categories><comments>9 pages. A slightly shorter version of this manuscript was submitted
  to Information Processing Letters</comments><doi>10.1016/j.ipl.2011.02.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an efficient algorithm for finding all approximate occurrences of
a given pattern $p$ of length $m$ in a text $t$ of length $n$ allowing for
translocations of equal length adjacent factors and inversions of factors. The
algorithm is based on an efficient filtering method and has an
$\bigO(nm\max(\alpha, \beta))$-time complexity in the worst case and
$\bigO(\max(\alpha, \beta))$-space complexity, where $\alpha$ and $\beta$ are
respectively the maximum length of the factors involved in any translocation
and inversion. Moreover we show that under the assumptions of equiprobability
and independence of characters our algorithm has a $\bigO(n)$ average time
complexity, whenever $\sigma = \Omega(\log m / \log\log^{1-\epsilon} m)$, where
$\epsilon &gt; 0$ and $\sigma$ is the dimension of the alphabet. Experiments show
that the new proposed algorithm achieves very good results in practical cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0284</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0284</id><created>2010-12-01</created><authors><author><keyname>Johnson</keyname><forenames>L. F.</forenames></author></authors><title>Middle and Ripple, fast simple O(lg n) algorithms for Lucas Numbers</title><categories>cs.DM math.NT</categories><comments>5 pp</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fast simple O(\log n) iteration algorithm for individual Lucas numbers is
given. This is faster than using Fibonacci based methods because of the
structure of Lucas numbers. Using a sqrt 5 conversion factor on Lucus numbers
gives a faster Fibonacci algorithm. In addition, a fast simple recursive
algorithm for individual Lucas numbers is given that is O(log n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0322</identifier>
 <datestamp>2010-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0322</id><created>2010-12-01</created><authors><author><keyname>Schetinin</keyname><forenames>Vitaly</forenames></author><author><keyname>Fieldsend</keyname><forenames>Jonathan</forenames></author><author><keyname>Partridge</keyname><forenames>Derek</forenames></author><author><keyname>Krzanowski</keyname><forenames>Wojtek</forenames></author><author><keyname>Everson</keyname><forenames>Richard</forenames></author><author><keyname>Bailey</keyname><forenames>Trevor</forenames></author><author><keyname>Hernandez</keyname><forenames>Adolfo</forenames></author></authors><title>A Bayesian Methodology for Estimating Uncertainty of Decisions in
  Safety-Critical Systems</title><categories>cs.AI</categories><journal-ref>Frontiers in Artificial Intelligence and Applications. Volume 149,
  IOS Press Book, 2006. Integrated Intelligent Systems for Engineering Design.
  Edited by Xuan F. Zha, R.J. Howlett. ISBN 978-1-58603-675-1, pp. 82-96</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Uncertainty of decisions in safety-critical engineering applications can be
estimated on the basis of the Bayesian Markov Chain Monte Carlo (MCMC)
technique of averaging over decision models. The use of decision tree (DT)
models assists experts to interpret causal relations and find factors of the
uncertainty. Bayesian averaging also allows experts to estimate the uncertainty
accurately when a priori information on the favored structure of DTs is
available. Then an expert can select a single DT model, typically the Maximum a
Posteriori model, for interpretation purposes. Unfortunately, a priori
information on favored structure of DTs is not always available. For this
reason, we suggest a new prior on DTs for the Bayesian MCMC technique. We also
suggest a new procedure of selecting a single DT and describe an application
scenario. In our experiments on the Short-Term Conflict Alert data our
technique outperforms the existing Bayesian techniques in predictive accuracy
of the selected single DTs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0326</identifier>
 <datestamp>2010-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0326</id><created>2010-12-01</created><authors><author><keyname>Adl</keyname><forenames>Ammar</forenames></author><author><keyname>Badr</keyname><forenames>Amr</forenames></author><author><keyname>Farag</keyname><forenames>Ibrahim</forenames></author></authors><title>Towards a Spiking Neural P Systems OS</title><categories>cs.OH</categories><journal-ref>Computing and Information Systems Journal, Issue 3 Oct. 2010, P
  30-36</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is an attempt to incorporate the idea of spiking neural P systems
as an early seed into the area of Operating System Design, regarding their
capability to solve some classical computer science problems. It is reflecting
the power of such systems to simulate well known parallel computational models,
like logic gates, arithmetic operation, and sorting. In these devices, the time
(when the neurons fire and/or spike) plays an essential role. For instance, the
result of a computation is the time between the moments when a specified neuron
spikes. Seen as number computing devices, SN P systems are shown to be
computationally complete, and with such capabilities, arithmetic operations,
logic, and timing, some first steps could be taken towards an OS design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0335</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0335</id><created>2010-12-01</created><updated>2010-12-04</updated><authors><author><keyname>Roy</keyname><forenames>Sudeepa</forenames></author><author><keyname>Perduca</keyname><forenames>Vittorio</forenames></author><author><keyname>Tannen</keyname><forenames>Val</forenames></author></authors><title>Faster Query Answering in Probabilistic Databases using Read-Once
  Functions</title><categories>cs.DB</categories><comments>Accepted in ICDT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A boolean expression is in read-once form if each of its variables appears
exactly once. When the variables denote independent events in a probability
space, the probability of the event denoted by the whole expression in
read-once form can be computed in polynomial time (whereas the general problem
for arbitrary expressions is #P-complete). Known approaches to checking
read-once property seem to require putting these expressions in disjunctive
normal form. In this paper, we tell a better story for a large subclass of
boolean event expressions: those that are generated by conjunctive queries
without self-joins and on tuple-independent probabilistic databases. We first
show that given a tuple-independent representation and the provenance graph of
an SPJ query plan without self-joins, we can, without using the DNF of a result
event expression, efficiently compute its co-occurrence graph. From this, the
read-once form can already, if it exists, be computed efficiently using
existing techniques. Our second and key contribution is a complete, efficient,
and simple to implement algorithm for computing the read-once forms (whenever
they exist) directly, using a new concept, that of co-table graph, which can be
significantly smaller than the co-occurrence graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0356</identifier>
 <datestamp>2010-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0356</id><created>2010-12-01</created><authors><author><keyname>Crutchfield</keyname><forenames>James P.</forenames></author><author><keyname>Ellison</keyname><forenames>Christopher J.</forenames></author></authors><title>The Past and the Future in the Present</title><categories>nlin.CD cs.IT math.DS math.IT math.ST stat.TH</categories><comments>7 pages, 1 figure;
  http://cse.ucdavis.edu/~cmg/compmech/pubs/pafip.htm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how the shared information between the past and future---the excess
entropy---derives from the components of directional information stored in the
present---the predictive and retrodictive causal states. A detailed proof
allows us to highlight a number of the subtle problems in estimation and
analysis that impede accurate calculation of the excess entropy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0359</identifier>
 <datestamp>2010-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0359</id><created>2010-12-01</created><authors><author><keyname>Zhou</keyname><forenames>Ping</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Fractional counting of citations in research evaluation: An option for
  cross- and interdisciplinary assessments</title><categories>cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the case of the scientometric evaluation of multi- or interdisciplinary
units one risks to compare apples with oranges: each paper has to assessed in
comparison to an appropriate reference set. We suggest that the set of citing
papers first can be considered as the relevant representation of the field of
impact. In order to normalize for differences in citation behavior among
fields, citations can be fractionally counted proportionately to the length of
the reference lists in the citing papers. This new method enables us to compare
among units with different disciplinary affiliations at the paper level and
also to assess the statistical significance of differences among sets.
Twenty-seven departments of the Tsinghua University in Beijing are thus
compared. Among them, the Department of Chinese Language and Linguistics is
upgraded from the 19th to the second position in the ranking. The overall
impact of 19 of the 27 departments is not significantly different at the 5%
level when thus normalized for different citation potentials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0365</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0365</id><created>2010-12-01</created><updated>2010-12-26</updated><authors><author><keyname>Lin</keyname><forenames>Zhouchen</forenames></author><author><keyname>Wei</keyname><forenames>Siming</forenames></author></authors><title>A Block Lanczos with Warm Start Technique for Accelerating Nuclear Norm
  Minimization Algorithms</title><categories>cs.NA cs.AI math.OC</categories><report-no>Microsoft Technical Report #MSR-TR-2010-162</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent years have witnessed the popularity of using rank minimization as a
regularizer for various signal processing and machine learning problems. As
rank minimization problems are often converted to nuclear norm minimization
(NNM) problems, they have to be solved iteratively and each iteration requires
computing a singular value decomposition (SVD). Therefore, their solution
suffers from the high computation cost of multiple SVDs. To relieve this issue,
we propose using the block Lanczos method to compute the partial SVDs, where
the principal singular subspaces obtained in the previous iteration are used to
start the block Lanczos procedure. To avoid the expensive reorthogonalization
in the Lanczos procedure, the block Lanczos procedure is performed for only a
few steps. Our block Lanczos with warm start (BLWS) technique can be adopted by
different algorithms that solve NNM problems. We present numerical results on
applying BLWS to Robust PCA and Matrix Completion problems. Experimental
results show that our BLWS technique usually accelerates its host algorithm by
at least two to three times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0366</identifier>
 <datestamp>2012-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0366</id><created>2010-12-01</created><updated>2012-09-05</updated><authors><author><keyname>Belavkin</keyname><forenames>Roman V.</forenames></author></authors><title>Optimal measures and Markov transition kernels</title><categories>math.OC cs.CC cs.IT math-ph math.FA math.IT math.MP stat.ML</categories><comments>Replaced with a final and accepted draft; Journal of Global
  Optimization, Springer, Jan 1, 2012</comments><doi>10.1007/s10898-012-9851-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study optimal solutions to an abstract optimization problem for measures,
which is a generalization of classical variational problems in information
theory and statistical physics. In the classical problems, information and
relative entropy are defined using the Kullback-Leibler divergence, and for
this reason optimal measures belong to a one-parameter exponential family.
Measures within such a family have the property of mutual absolute continuity.
Here we show that this property characterizes other families of optimal
positive measures if a functional representing information has a strictly
convex dual. Mutual absolute continuity of optimal probability measures allows
us to strictly separate deterministic and non-deterministic Markov transition
kernels, which play an important role in theories of decisions, estimation,
control, communication and computation. We show that deterministic transitions
are strictly sub-optimal, unless information resource with a strictly convex
dual is unconstrained. For illustration, we construct an example where, unlike
non-deterministic, any deterministic kernel either has negatively infinite
expected utility (unbounded expected error) or communicates infinite
information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0367</identifier>
 <datestamp>2010-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0367</id><created>2010-12-01</created><authors><author><keyname>Abbe</keyname><forenames>Emmanuel</forenames></author></authors><title>Universal polar coding and sparse recovery</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates universal polar coding schemes. In particular, a
notion of ordering (called convolutional path) is introduced between
probability distributions to determine when a polar compression (or
communication) scheme designed for one distribution can also succeed for
another one. The original polar decoding algorithm is also generalized to an
algorithm allowing to learn information about the source distribution using the
idea of checkers. These tools are used to construct a universal compression
algorithm for binary sources, operating at the lowest achievable rate
(entropy), with low complexity and with guaranteed small error probability. In
a second part of the paper, the problem of sketching high dimensional discrete
signals which are sparse is approached via the polarization technique. It is
shown that the number of measurements required for perfect recovery is
competitive with the $O(k \log (n/k))$ bound (with optimal constant for binary
signals), meanwhile affording a deterministic low complexity measurement
matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0375</identifier>
 <datestamp>2010-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0375</id><created>2010-12-01</created><authors><author><keyname>Liang</keyname><forenames>Yan</forenames></author><author><keyname>Jiang</keyname><forenames>Chengling</forenames></author><author><keyname>Yang</keyname><forenames>Chunliang</forenames></author></authors><title>Dynamic Resource Coordination and Interference Management for Femtocell
  Networks</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Femtocell is emerging as a key technology to secure the coverage and capacity
in indoor environments. However the deployment of a new femtocell layer may
originate undesired interference to the whole system. This paper investigates
spectrum resource coordination and interference management for the femtocell
networks. A resource coordination scheme based on broadcasting resource
coordination request messages by the femto mobile is proposed to reduce the
system interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0378</identifier>
 <datestamp>2010-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0378</id><created>2010-12-01</created><authors><author><keyname>Kokalj-Filipovic</keyname><forenames>Silvija</forenames></author><author><keyname>Fessant</keyname><forenames>Fabrice Le</forenames></author><author><keyname>Spasojevic</keyname><forenames>Predrag</forenames></author></authors><title>Some Important Aspects of Source Location Protection in Globally
  Attacked Sensor Networks</title><categories>cs.CR</categories><comments>longer version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the problem of location anonymity of the events exposed to a global
eavesdropper, we highlight and analyze some aspects that are missing in the
prior work, which is especially relevant for the quality of secure sensing in
delay-intolerant applications monitoring rare and spatially sparse events, and
deployed as large wireless sensor networks with single data collector. We
propose an efficient scheme for generating fake network traffic to disguise the
real event notification. The efficiency of the scheme that provides statistical
source location anonymity is achieved by partitioning network nodes randomly
into several dummy source groups. Members of the same group collectively
emulate both temporal and spatial distribution of the event. Under such
dummy-traffic framework of the source anonymity protection, we aim to better
model the global eavesdropper, especially her way of using statistical tests to
detect the real event, and to present the quality of the location protection as
relative to the adversary's strength. In addition, our approach aims to reduce
the per-event work spent to generate the fake traffic while, most importantly,
providing a guaranteed latency in reporting the event. The latency is
controlled by decoupling the routing from the fake-traffic schedule. A good
dummy source group design also provides a robust protection of event bursts.
This is achieved at the expense of the significant overhead as the number of
dummy source groups must be increased to the reciprocal value of the false
alarm parameter used in the statistical test. We believe that the proposed
source anonymity protection strategy, and the evaluation framework, are well
justified by the abundance of the applications that monitor a rare event with
known temporal statistics, and uniform spatial distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0379</identifier>
 <datestamp>2010-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0379</id><created>2010-12-01</created><authors><author><keyname>Kokalj-Filipovic</keyname><forenames>Silvija</forenames></author><author><keyname>Fessant</keyname><forenames>Fabrice Le</forenames></author><author><keyname>Spasojevic</keyname><forenames>Predrag</forenames></author></authors><title>Quality of Source Location Protection in Globally Attacked Sensor
  Networks</title><categories>cs.CR math.PR math.ST stat.TH</categories><comments>shorter versiom</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an efficient scheme for generating fake network traffic to
disguise the real event notification in the presence of a global eavesdropper,
which is especially relevant for the quality of service in delay-intolerant
applications monitoring rare and spatially sparse events, and deployed as large
wireless sensor networks with single data collector. The efficiency of the
scheme that provides statistical source anonymity is achieved by partitioning
network nodes randomly into several node groups. Members of the same group
collectively emulate both temporal and spatial distribution of the event. Under
such dummy-traffic framework of the source anonymity protection, we aim to
better model the global eavesdropper, especially her way of using statistical
tests to detect the real event, and to present the quality of the location
protection as relative to the adversary's strength. In addition, our approach
aims to reduce the per-event work spent to generate the fake traffic while,
most importantly, providing a guaranteed latency in reporting the event. The
latency is controlled by decoupling the routing from the fake traffic schedule.
We believe that the proposed source anonymity protection strategy, and the
quality evaluation framework, are well justified by the abundance of the
applications that monitor a rare event with known temporal statistics, and
uniform spatial distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0384</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0384</id><created>2010-12-02</created><updated>2010-12-03</updated><authors><author><keyname>Afifi</keyname><forenames>Wessam</forenames></author><author><keyname>Sultan</keyname><forenames>Ahmed</forenames></author><author><keyname>Nafie</keyname><forenames>Mohammed</forenames></author></authors><title>Adaptive Sensing and Transmission Durations for Cognitive Radios</title><categories>math.OC cs.IT math-ph math.IT math.MP</categories><comments>9 pages, 9 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a cognitive radio setting, secondary users opportunistically access the
spectrum allocated to primary users. Finding the optimal sensing and
transmission durations for the secondary users becomes crucial in order to
maximize the secondary throughput while protecting the primary users from
interference and service disruption. In this paper an adaptive sensing and
transmission scheme for cognitive radios is proposed. We consider a channel
allocated to a primary user which operates in an unslotted manner switching
activity at random times. A secondary transmitter adapts its sensing and
transmission durations according to its belief regarding the primary user state
of activity. The objective is to maximize a secondary utility function. This
function has a penalty term for collisions with primary transmission. It
accounts for the reliability-throughput tradeoff by explicitly incorporating
the impact of sensing duration on secondary throughput and primary activity
detection reliability. It also accounts for throughput reduction that results
from data overhead. Numerical simulations of the system performance demonstrate
the effectiveness of adaptive sensing and transmission scheme over non-adaptive
approach in increasing the secondary user utility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0385</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0385</id><created>2010-12-02</created><updated>2011-03-30</updated><authors><author><keyname>Schulz</keyname><forenames>Henrik</forenames></author><author><keyname>&#xd3;dor</keyname><forenames>G&#xe9;za</forenames></author><author><keyname>&#xd3;dor</keyname><forenames>Gergely</forenames></author><author><keyname>Nagy</keyname><forenames>M&#xe1;t&#xe9; Ferenc</forenames></author></authors><title>Simulation of 1+1 dimensional surface growth and lattices gases using
  GPUs</title><categories>physics.comp-ph cond-mat.dis-nn cond-mat.stat-mech cs.DC nlin.CG</categories><comments>20 pages 12 figures, 1 table, to appear in Comp. Phys. Comm</comments><journal-ref>Computer Physics Communications 182 (2011) 1467-1476</journal-ref><doi>10.1016/j.cpc.2011.03.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Restricted solid on solid surface growth models can be mapped onto binary
lattice gases. We show that efficient simulation algorithms can be realized on
GPUs either by CUDA or by OpenCL programming. We consider a
deposition/evaporation model following Kardar-Parisi-Zhang growth in 1+1
dimensions related to the Asymmetric Simple Exclusion Process and show that for
sizes, that fit into the shared memory of GPUs one can achieve the maximum
parallelization speedup ~ x100 for a Quadro FX 5800 graphics card with respect
to a single CPU of 2.67 GHz). This permits us to study the effect of quenched
columnar disorder, requiring extremely long simulation times. We compare the
CUDA realization with an OpenCL implementation designed for processor clusters
via MPI. A two-lane traffic model with randomized turning points is also
realized and the dynamical behavior has been investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0392</identifier>
 <datestamp>2010-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0392</id><created>2010-12-02</created><authors><author><keyname>Gao</keyname><forenames>Fei</forenames></author><author><keyname>Ge</keyname><forenames>Gennian</forenames></author></authors><title>Supporting Information for the Paper: Optimal Ternary
  Constant-Composition Codes of Weight Four and Distance Five, IEEE Trans.
  Inform. Theory, To Appear</title><categories>cs.IT math.CO math.IT</categories><comments>9 pages, 7 tables. Supporting Information for the Paper: Optimal
  Ternary Constant-Composition Codes of Weight Four and Distance Five, IEEE
  Trans. Inform. Theory, To Appear</comments><msc-class>94B25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Supporting Information for the Paper: Optimal Ternary Constant-Composition
Codes of Weight Four and Distance Five, IEEE Trans. Inform. Theory, To Appear.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0397</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0397</id><created>2010-12-02</created><updated>2011-04-29</updated><authors><author><keyname>Madani</keyname><forenames>Ramtin</forenames></author><author><keyname>Ayremlou</keyname><forenames>Ali</forenames></author><author><keyname>Amini</keyname><forenames>Arash</forenames></author><author><keyname>Marvasti</keyname><forenames>Farrokh</forenames></author></authors><title>A proposed Optimized Spline Interpolation</title><categories>cs.MM</categories><comments>SampTA 2011, Accepted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this paper is to design compact support basis spline functions
that best approximate a given filter (e.g., an ideal Lowpass filter). The
optimum function is found by minimizing the least square problem ($\ell$2 norm
of the difference between the desired and the approximated filters) by means of
the calculus of variation; more precisely, the introduced splines give optimal
filtering properties with respect to their time support interval. Both
mathematical analysis and simulation results confirm the superiority of these
splines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0412</identifier>
 <datestamp>2012-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0412</id><created>2010-12-02</created><authors><author><keyname>Sharma</keyname><forenames>Naresh</forenames></author><author><keyname>Das</keyname><forenames>Smarajit</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>Siddharth</forenames></author></authors><title>Entropy power inequality for a family of discrete random variables</title><categories>cs.IT math.IT</categories><comments>18 pages, 1 figure</comments><doi>10.1109/ISIT.2011.6033891</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that the Entropy Power Inequality (EPI) always holds if the
random variables have density. Not much work has been done to identify discrete
distributions for which the inequality holds with the differential entropy
replaced by the discrete entropy. Harremo\&quot;{e}s and Vignat showed that it holds
for the pair (B(m,p), B(n,p)), m,n \in \mathbb{N}, (where B(n,p) is a Binomial
distribution with n trials each with success probability p) for p = 0.5. In
this paper, we considerably expand the set of Binomial distributions for which
the inequality holds and, in particular, identify n_0(p) such that for all m,n
\geq n_0(p), the EPI holds for (B(m,p), B(n,p)). We further show that the EPI
holds for the discrete random variables that can be expressed as the sum of n
independent identical distributed (IID) discrete random variables for large n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0416</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0416</id><created>2010-12-02</created><updated>2012-06-15</updated><authors><author><keyname>Raja</keyname><forenames>Adnan</forenames></author><author><keyname>Viswanath</keyname><forenames>Pramod</forenames></author></authors><title>Compress-and-Forward Scheme for Relay Networks: Backword Decoding and
  Connection to Bisubmodular Flows</title><categories>cs.IT math.IT</categories><comments>(updated to include layered/backward decoding; submitted revised
  version for review to IEEE transactions on Information Theory)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a compress-and-forward scheme with backward decoding is
presented for the unicast wireless relay network. The encoding at the source
and relay is a generalization of the noisy network coding scheme (NNC). While
it achieves the same reliable data rate as noisy network coding scheme, the
backward decoding allows for a better decoding complexity as compared to the
joint decoding of the NNC scheme. Characterizing the layered decoding scheme is
shown to be equivalent to characterizing an information flow for the wireless
network. A node-flow for a graph with bisubmodular capacity constraints is
presented and a max-flow min-cut theorem is proved for it. This generalizes
many well-known results of flows over capacity constrained graphs studied in
computer science literature. The results for the unicast relay network are
generalized to the network with multiple sources with independent messages
intended for a single destination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0452</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0452</id><created>2010-12-02</created><authors><author><keyname>Salim</keyname><forenames>Umer</forenames></author><author><keyname>Slock</keyname><forenames>Dirk</forenames></author></authors><title>Average Minimum Transmit Power to achieve SINR Targets: Performance
  Comparison of Various User Selection Algorithms</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In multi-user communication from one base station (BS) to multiple users, the
problem of minimizing the transmit power to achieve some target guaranteed
performance (rates) at users has been well investigated in the literature.
Similarly various user selection algorithms have been proposed and analyzed
when the BS has to transmit to a subset of the users in the system, mostly for
the objective of the sum rate maximization.
  We study the joint problem of minimizing the transmit power at the BS to
achieve specific signal-to-interference-and-noise ratio (SINR) targets at users
in conjunction with user scheduling. The general analytical results for the
average transmit power required to meet guaranteed performance at the users'
side are difficult to obtain even without user selection due to joint
optimization required over beamforming vectors and power allocation scalars. We
study the transmit power minimization problem with various user selection
algorithms, namely semi-orthogonal user selection (SUS), norm-based user
selection (NUS) and angle-based user selection (AUS). When the SINR targets to
achieve are relatively large, the average minimum transmit power expressions
are derived for NUS and SUS for any number of users. For the special case when
only two users are selected, similar expressions are further derived for AUS
and a performance upper bound which serves to benchmark the performance of
other selection schemes. Simulation results performed under various settings
indicate that SUS is by far the better user selection criterion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0467</identifier>
 <datestamp>2010-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0467</id><created>2010-12-02</created><authors><author><keyname>Laufs</keyname><forenames>Uwe</forenames></author><author><keyname>Ruff</keyname><forenames>Christopher</forenames></author><author><keyname>Zibuschka</keyname><forenames>Jan</forenames></author></authors><title>MT4j - A Cross-platform Multi-touch Development Framework</title><categories>cs.HC cs.GR</categories><comments>ACM EICS 2010, Workshop: Engineering patterns for multi-touch
  interfaces (2010), p. 52-57</comments><acm-class>H.5.2; D.2.11; D.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article describes requirements and challenges of crossplatform
multi-touch software engineering, and presents the open source framework
Multi-Touch for Java (MT4j) as a solution. MT4j is designed for rapid
development of graphically rich applications on a variety of contemporary
hardware, from common PCs and notebooks to large-scale ambient displays, as
well as different operating systems. The framework has a special focus on
making multi-touch software development easier and more efficient. Architecture
and abstractions used by MT4j are described, and implementations of several
common use cases are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0490</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0490</id><created>2010-12-02</created><updated>2011-01-10</updated><authors><author><keyname>Vidybida</keyname><forenames>Alexander K.</forenames></author></authors><title>Testing of information condensation in a model reverberating spiking
  neural network</title><categories>q-bio.NC cs.NE</categories><comments>12 pages, 9 figures, 40 references. Content of this work was
  partially published in an abstract form in the abstract book of the 2nd
  International Biophysics Congress and Biotechnology at GAP &amp; 21th National
  Biophysics Congress, (5-9 Oct. 2009) Diyarbakir, Turkey,
  http://www.ibc2009.org/. In v2 the ancillary file movie.pdf is added, which
  offers examples of neuronal network dynamics</comments><journal-ref>International Journal of Neural Systems (IJNS), Volume: 21, Issue:
  3 (June 2011), Page: 187-198</journal-ref><doi>10.1142/S0129065711002742</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information about external world is delivered to the brain in the form of
structured in time spike trains. During further processing in higher areas,
information is subjected to a certain condensation process, which results in
formation of abstract conceptual images of external world, apparently,
represented as certain uniform spiking activity partially independent on the
input spike trains details. Possible physical mechanism of condensation at the
level of individual neuron was discussed recently. In a reverberating spiking
neural network, due to this mechanism the dynamics should settle down to the
same uniform/periodic activity in response to a set of various inputs. Since
the same periodic activity may correspond to different input spike trains, we
interpret this as possible candidate for information condensation mechanism in
a network. Our purpose is to test this possibility in a network model
consisting of five fully connected neurons, particularly, the influence of
geometric size of the network, on its ability to condense information. Dynamics
of 20 spiking neural networks of different geometric sizes are modelled by
means of computer simulation. Each network was propelled into reverberating
dynamics by applying various initial input spike trains. We run the dynamics
until it becomes periodic. The Shannon's formula is used to calculate the
amount of information in any input spike train and in any periodic state found.
As a result, we obtain explicit estimate of the degree of information
condensation in the networks, and conclude that it depends strongly on the
net's geometric size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0498</identifier>
 <datestamp>2010-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0498</id><created>2010-12-02</created><authors><author><keyname>Sun</keyname><forenames>Mingxuan</forenames></author><author><keyname>Lebanon</keyname><forenames>Guy</forenames></author><author><keyname>Kidwell</keyname><forenames>Paul</forenames></author></authors><title>Estimating Probabilities in Recommendation Systems</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recommendation systems are emerging as an important business application with
significant economic impact. Currently popular systems include Amazon's book
recommendations, Netflix's movie recommendations, and Pandora's music
recommendations. In this paper we address the problem of estimating
probabilities associated with recommendation system data using non-parametric
kernel smoothing. In our estimation we interpret missing items as randomly
censored observations and obtain efficient computation schemes using
combinatorial properties of generating functions. We demonstrate our approach
with several case studies involving real world movie recommendation data. The
results are comparable with state-of-the-art techniques while also providing
probabilistic preference estimates outside the scope of traditional recommender
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0522</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0522</id><created>2010-12-02</created><authors><author><keyname>Mazzucco</keyname><forenames>Michele</forenames></author><author><keyname>Mazzara</keyname><forenames>Manuel</forenames></author><author><keyname>Dragoni</keyname><forenames>Nicola</forenames></author></authors><title>Design of QoS-aware Provisioning Systems</title><categories>cs.NI</categories><comments>Published and presented at NODES 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an architecture of a hosting system consisting of a set of hosted
Web Services subject to QoS constraints, and a certain number of servers used
to run users demand. The traffic is session-based, while provider and users
agree on SLAs specifying the expected level of service performance such that
the service provider is liable to compensate his/her customers if the level of
performance is not satisfactory. The system is driven by a utility function
which tries to optimize the average earned revenue per unit time. The
middleware collects demand and performance statistics, and estimates traffic
parameters in order to make dynamic decisions concerning server allocation and
admission control. We empirically evaluate the effects of admission policies,
resource allocation and service differentiation schemes on the achieved
revenues, and we find that our system is robust enough to successfully deal
with session-based traffic under different conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0524</identifier>
 <datestamp>2010-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0524</id><created>2010-12-02</created><authors><author><keyname>Grant</keyname><forenames>Elyot</forenames></author></authors><title>On Avoiding Sufficiently Long Abelian Squares</title><categories>math.CO cs.DM</categories><comments>5 pages</comments><msc-class>05D99</msc-class><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A finite word $w$ is an abelian square if $w = xx^\prime$ with $x^\prime$ a
permutation of $x$. In 1972, Entringer, Jackson, and Schatz proved that every
binary word of length $k^2 + 6k$ contains an abelian square of length $\geq
2k$. We use Cartesian lattice paths to characterize abelian squares in binary
sequences, and construct a binary word of length $q(q+1)$ avoiding abelian
squares of length $\geq 2\sqrt{2q(q+1)}$ or greater. We thus prove that the
length of the longest binary word avoiding abelian squares of length $2k$ is
$\Theta(k^2)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0529</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0529</id><created>2010-12-02</created><authors><author><keyname>Kuehn</keyname><forenames>R.</forenames></author><author><keyname>van Mourik</keyname><forenames>J. M.</forenames></author></authors><title>Spectra of Modular and Small-World Matrices</title><categories>cond-mat.dis-nn cs.SI physics.soc-ph</categories><comments>18 pages, 5 figures</comments><doi>10.1088/1751-8113/44/16/165205</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We compute spectra of symmetric random matrices describing graphs with
general modular structure and arbitrary inter- and intra-module degree
distributions, subject only to the constraint of finite mean connectivities. We
also evaluate spectra of a certain class of small-world matrices generated from
random graphs by introducing short-cuts via additional random connectivity
components. Both adjacency matrices and the associated graph Laplacians are
investigated. For the Laplacians, we find Lifshitz type singular behaviour of
the spectral density in a localised region of small $|\lambda|$ values. In the
case of modular networks, we can identify contributions local densities of
state from individual modules. For small-world networks, we find that the
introduction of short cuts can lead to the creation of satellite bands outside
the central band of extended states, exhibiting only localised states in the
band-gaps. Results for the ensemble in the thermodynamic limit are in excellent
agreement with those obtained via a cavity approach for large finite single
instances, and with direct diagonalisation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0531</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0531</id><created>2010-12-02</created><updated>2011-12-17</updated><authors><author><keyname>Biamonte</keyname><forenames>Jacob D.</forenames></author><author><keyname>Clark</keyname><forenames>Stephen R.</forenames></author><author><keyname>Jaksch</keyname><forenames>Dieter</forenames></author></authors><title>Categorical Tensor Network States</title><categories>quant-ph cond-mat.other cs.CC cs.LO math-ph math.MP</categories><comments>39 pages, 31 figures, published version</comments><journal-ref>AIP Advances 1(4), 042172 (2011)</journal-ref><doi>10.1063/1.3672009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the use of string diagrams and the mathematics of category theory
in the description of quantum states by tensor networks. This approach lead to
a unification of several ideas, as well as several results and methods that
have not previously appeared in either side of the literature. Our approach
enabled the development of a tensor network framework allowing a solution to
the quantum decomposition problem which has several appealing features.
Specifically, given an n-body quantum state S, we present a new and general
method to factor S into a tensor network of clearly defined building blocks. We
use the solution to expose a previously unknown and large class of quantum
states which we prove can be sampled efficiently and exactly. This general
framework of categorical tensor network states, where a combination of generic
and algebraically defined tensors appear, enhances the theory of tensor network
states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0548</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0548</id><created>2010-12-02</created><updated>2012-08-22</updated><authors><author><keyname>Dujmovic</keyname><forenames>Vida</forenames></author><author><keyname>Langerman</keyname><forenames>Stefan</forenames></author></authors><title>A Center Transversal Theorem for Hyperplanes and Applications to Graph
  Drawing</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by an open problem from graph drawing, we study several
partitioning problems for line and hyperplane arrangements. We prove a
ham-sandwich cut theorem: given two sets of n lines in R^2, there is a line l
such that in both line sets, for both halfplanes delimited by l, there are
n^{1/2} lines which pairwise intersect in that halfplane, and this bound is
tight; a centerpoint theorem: for any set of n lines there is a point such that
for any halfplane containing that point there are (n/3)^{1/2} of the lines
which pairwise intersect in that halfplane. We generalize those results in
higher dimension and obtain a center transversal theorem, a same-type lemma,
and a positive portion Erdos-Szekeres theorem for hyperplane arrangements. This
is done by formulating a generalization of the center transversal theorem which
applies to set functions that are much more general than measures. Back to
Graph Drawing (and in the plane), we completely solve the open problem that
motivated our search: there is no set of n labelled lines that are universal
for all n-vertex labelled planar graphs. As a side note, we prove that every
set of n (unlabelled) lines is universal for all n-vertex (unlabelled) planar
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0556</identifier>
 <datestamp>2010-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0556</id><created>2010-12-02</created><updated>2010-12-03</updated><authors><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author></authors><title>A Note on Nonuniform versus Uniform ACC^k Circuits for NE</title><categories>cs.CC</categories><report-no>URCS-TR-2010-964</report-no><msc-class>68Q15, 68Q17</msc-class><acm-class>F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We note that for each k \in {0,1,2, ...} the following holds: NE has
(nonuniform) ACC^k circuits if and only if NE has P^{NE}-uniform ACC^k
circuits. And we mention how to get analogous results for other circuit and
complexity classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0557</identifier>
 <datestamp>2010-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0557</id><created>2010-12-02</created><authors><author><keyname>Rumyantsev</keyname><forenames>Andrey</forenames></author></authors><title>Infinite computable version of Lovasz Local Lemma</title><categories>cs.DS cs.DM math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lov\'asz Local Lemma (LLL) is a probabilistic tool that allows us to prove
the existence of combinatorial objects in the cases when standard probabilistic
argument does not work (there are many partly independent conditions).
  LLL can be also used to prove the consistency of an infinite set of
conditions, using standard compactness argument (if an infinite set of
conditions is inconsistent, then some finite part of it is inconsistent, too,
which contradicts LLL). In this way we show that objects satisfying all the
conditions do exist (though the probability of this event equals~$0$). However,
if we are interested in finding a computable solution that satisfies all the
constraints, compactness arguments do not work anymore.
  Moser and Tardos recently gave a nice constructive proof of LLL. Lance
Fortnow asked whether one can apply Moser--Tardos technique to prove the
existence of a computable solution. We show that this is indeed possible (under
almost the same conditions as used in the non-constructive version).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0591</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0591</id><created>2010-12-02</created><updated>2011-10-30</updated><authors><author><keyname>Hoffmann</keyname><forenames>Michael</forenames></author><author><keyname>Sharir</keyname><forenames>Micha</forenames></author><author><keyname>Sheffer</keyname><forenames>Adam</forenames></author><author><keyname>T&#xf3;th</keyname><forenames>Csaba D.</forenames></author><author><keyname>Welzl</keyname><forenames>Emo</forenames></author></authors><title>Counting Plane Graphs: Flippability and its Applications</title><categories>cs.DM cs.CG</categories><acm-class>F.2.2; G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We generalize the notions of flippable and simultaneously flippable edges in
a triangulation of a set S of points in the plane to so-called
\emph{pseudo-simultaneously flippable edges}. Such edges are related to the
notion of convex decompositions spanned by S.
  We prove a worst-case tight lower bound for the number of
pseudo-simultaneously flippable edges in a triangulation in terms of the number
of vertices. We use this bound for deriving new upper bounds for the maximal
number of crossing-free straight-edge graphs that can be embedded on any fixed
set of N points in the plane. We obtain new upper bounds for the number of
spanning trees and forests as well.
  Specifically, let tr(N) denote the maximum number of triangulations on a set
of N points in the plane. Then we show (using the known bound tr(N) &lt; 30^N)
that any N-element point set admits at most 6.9283^N * tr(N) &lt; 207.85^N
crossing-free straight-edge graphs, O(4.7022^N) * tr(N) = O(141.07^N) spanning
trees, and O(5.3514^N) * tr(N) = O(160.55^N) forests. We also obtain upper
bounds for the number of crossing-free straight-edge graphs that have cN, fewer
than cN, or more than cN edges, for any constant parameter c, in terms of c and
N.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0599</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0599</id><created>2010-12-02</created><authors><author><keyname>Hucher</keyname><forenames>Charlotte</forenames></author><author><keyname>Sadeghi</keyname><forenames>Parastoo</forenames></author></authors><title>Towards a Low-Complexity Dynamic Decode-and-Forward Relay Protocol</title><categories>cs.IT math.IT</categories><comments>20 pages, 6 figures, submitted to Communications Magazine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dynamic decode-and-forward (DDF) relaying protocol is a relatively new
cooperative scheme which has been shown to achieve promising theoretical
results in terms of diversity-multiplexing gain tradeoff and error rates. The
case of a single relay has been extensively studied in the literature and
several techniques to approach the optimum performance have been proposed.
Until recently, however, a practical implementation for the case of several
relays had been considered to be much more challenging. A rotation-based DDF
technique, suitable for any number of relays, has been recently proposed which
promises to overcome important implementation hurdles. This article provides an
overview of the DDF protocol, describes different implementation techniques and
compares their performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0602</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0602</id><created>2010-12-02</created><updated>2011-12-11</updated><authors><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author><author><keyname>Smarandache</keyname><forenames>Roxana</forenames></author><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author></authors><title>LDPC Codes for Compressed Sensing</title><categories>cs.IT math.IT math.NA</categories><comments>To appear, IEEE Transactions on Information Theory, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a mathematical connection between channel coding and compressed
sensing. In particular, we link, on the one hand, \emph{channel coding linear
programming decoding (CC-LPD)}, which is a well-known relaxation o
maximum-likelihood channel decoding for binary linear codes, and, on the other
hand, \emph{compressed sensing linear programming decoding (CS-LPD)}, also
known as basis pursuit, which is a widely used linear programming relaxation
for the problem of finding the sparsest solution of an under-determined system
of linear equations. More specifically, we establis a tight connection between
CS-LPD based on a zero-one measurement matrix over the reals and CC-LPD of the
binary linear channel code that is obtained by viewing this measurement matrix
as a binary parity-check matrix. This connection allows the translation of
performance guarantees from one setup to the other. The main message of this
paper is that parity-check matrices of &quot;good&quot; channel codes can be used as
provably &quot;good&quot; measurement matrices under basis pursuit. In particular, we
provide the first deterministic construction of compressed sensing measurement
matrices with an order-optimal number of rows using high-girth low-density
parity-check (LDPC) codes constructed by Gallager.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0606</identifier>
 <datestamp>2010-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0606</id><created>2010-12-02</created><authors><author><keyname>Barmpoutis</keyname><forenames>Dionysios</forenames></author><author><keyname>Murray</keyname><forenames>Richard M.</forenames></author></authors><title>Quantification and Minimization of Crosstalk Sensitivity in Networks</title><categories>q-bio.MN cond-mat.dis-nn cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crosstalk is defined as the set of unwanted interactions among the different
entities of a network. Crosstalk is present in various degrees in every system
where information is transmitted through a means that is accessible by all the
individual units of the network. Using concepts from graph theory, we introduce
a quantifiable measure for sensitivity to crosstalk, and analytically derive
the structure of the networks in which it is minimized. It is shown that
networks with an inhomogeneous degree distribution are more robust to crosstalk
than corresponding homogeneous networks. We provide a method to construct the
graph with the minimum possible sensitivity to crosstalk, given its order and
size. Finally, for networks with a fixed degree sequence, we present an
algorithm to find the optimal interconnection structure among their vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0610</identifier>
 <datestamp>2010-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0610</id><created>2010-12-02</created><authors><author><keyname>Nagamalai</keyname><forenames>Dhinaharan</forenames></author><author><keyname>Dhinakaran</keyname><forenames>Cynthia</forenames></author><author><keyname>Lee</keyname><forenames>Jae-Kwang</forenames></author></authors><title>Novel Mechanism to Defend DDoS Attacks Caused by Spam</title><categories>cs.CR cs.NI</categories><comments>14 Pages, 6 Figures, IJSA Vol 1, No 2,July 2007</comments><journal-ref>IJSA Vol 1, No 2,July 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Corporate mail services are designed to perform better than public mail
services. Fast mail delivery, large size file transfer as an attachments, high
level spam and virus protection, commercial advertisement free environment are
some of the advantages worth to mention. But these mail services are frequent
target of hackers and spammers. Distributed Denial of service attacks are
becoming more common and sophisticated. The researchers have proposed various
solutions to the DDOS attacks. Can we stop these kinds of attacks with
available technology? These days the DDoS attack through spam has increased and
disturbed the mail services of various organizations. Spam penetrates through
all the filters to establish DDoS attacks, which causes serious problems to
users and the data. In this paper we propose a novel approach to defend DDoS
attack caused by spam mails. This approach is a combination of fine tuning of
source filters, content filters, strictly implementing mail policies,educating
user, network monitoring and logical solutions to the ongoing attack. We have
conducted several experiments in corporate mail services; the results show that
this approach is highly effective to prevent DDoS attack caused by spam. The
novel defense mechanism reduced 60% of the incoming spam traffic and repelled
many DDoS attacks caused by spam.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0623</identifier>
 <datestamp>2012-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0623</id><created>2010-12-02</created><authors><author><keyname>Chandrasekaran</keyname><forenames>Venkat</forenames></author><author><keyname>Parrilo</keyname><forenames>Pablo A.</forenames></author><author><keyname>Willsky</keyname><forenames>Alan S.</forenames></author></authors><title>Convex Graph Invariants</title><categories>math.OC cs.DM math.CO</categories><journal-ref>SIAM Review, 54(3), pp. 513-541, 2012</journal-ref><doi>10.1137/100816900</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The structural properties of graphs are usually characterized in terms of
invariants, which are functions of graphs that do not depend on the labeling of
the nodes. In this paper we study convex graph invariants, which are graph
invariants that are convex functions of the adjacency matrix of a graph. Some
examples include functions of a graph such as the maximum degree, the MAXCUT
value (and its semidefinite relaxation), and spectral invariants such as the
sum of the $k$ largest eigenvalues. Such functions can be used to construct
convex sets that impose various structural constraints on graphs, and thus
provide a unified framework for solving a number of interesting graph problems
via convex optimization. We give a representation of all convex graph
invariants in terms of certain elementary invariants, and describe methods to
compute or approximate convex graph invariants tractably. We also compare
convex and non-convex invariants, and discuss connections to robust
optimization. Finally we use convex graph invariants to provide efficient
convex programming solutions to graph problems such as the deconvolution of the
composition of two graphs into the individual components, hypothesis testing
between graph families, and the generation of graphs with certain desired
structural properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0634</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0634</id><created>2010-12-02</created><updated>2011-05-29</updated><authors><author><keyname>Shawi</keyname><forenames>Radwa El</forenames></author><author><keyname>Gudmundsson</keyname><forenames>Joachim</forenames></author><author><keyname>Levcopoulos</keyname><forenames>Christos</forenames></author></authors><title>Quickest Path Queries on Transportation Network</title><categories>cs.CG</categories><comments>16 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of finding a quickest path between two
points in the Euclidean plane in the presence of a transportation network. A
transportation network consists of a planar network where each road (edge) has
an individual speed. A traveller may enter and exit the network at any point on
the roads. Along any road the traveller moves with a fixed speed depending on
the road, and outside the network the traveller moves at unit speed in any
direction. We give an exact algorithm for the basic version of the problem:
given a transportation network of total complexity n in the Euclidean plane, a
source point s and a destination point t, and the quickest path between s and
t. We also show how the transportation network can be preprocessed in time
O(n^2 log n) into a data structure of size O(n^2) such that (1 +
\epsilon)-approximate cheapest path cost queries between any two points in the
plane can be answered in time O(1\epsilon^4 log n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0663</identifier>
 <datestamp>2010-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0663</id><created>2010-12-03</created><authors><author><keyname>Fard</keyname><forenames>Amin Milani</forenames></author><author><keyname>Wang</keyname><forenames>Ke</forenames></author></authors><title>An Effective Clustering Approach to Web Query Log Anonymization</title><categories>cs.DB cs.CR</categories><comments>9 pages</comments><journal-ref>Proc. 2010 International Conference on Security and Cryptography
  (SECRYPT'10), July 2010, Athens, Greece</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web query log data contain information useful to research; however, release
of such data can re-identify the search engine users issuing the queries. These
privacy concerns go far beyond removing explicitly identifying information such
as name and address, since non-identifying personal data can be combined with
publicly available information to pinpoint to an individual. In this work we
model web query logs as unstructured transaction data and present a novel
transaction anonymization technique based on clustering and generalization
techniques to achieve the k-anonymity privacy. We conduct extensive experiments
on the AOL query log data. Our results show that this method results in a
higher data utility compared to the state of-the-art transaction anonymization
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0672</identifier>
 <datestamp>2010-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0672</id><created>2010-12-03</created><authors><author><keyname>Giammarresi</keyname><forenames>Dora</forenames></author></authors><title>Tiling-Recognizable Two-Dimensional Languages: From Non-Determinism to
  Determinism through Unambiguity</title><categories>nlin.CG cs.CC</categories><comments>Journ\'ees Automates Cellulaires 2010, Turku : Finland (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tiling recognizable two-dimensional languages, also known as REC, generalize
recognizable string languages to two dimensions and share with them several
theoretical properties. Nevertheless REC is not closed under complementation
and the membership problem is NP-complete. This implies that this family REC is
intrinsically non-deterministic. The natural and immediate definition of
unambiguity corresponds to a family UREC of languages that is strictly
contained in REC. On the other hand this definition of unambiguity leads to an
undecidability result and therefore it cannot correspond to any deterministic
notion. We introduce the notion of line-unambiguous tiling recognizable
languages and prove that it corresponds or somehow naturally introduces
different notions of determin- ism that define a hierarchy inside REC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0674</identifier>
 <datestamp>2010-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0674</id><created>2010-12-03</created><authors><author><keyname>Worsch</keyname><forenames>Thomas</forenames></author><author><keyname>Nishio</keyname><forenames>Hidenosuke</forenames></author></authors><title>Real-Time Sorting of Binary Numbers on One-Dimensional CA</title><categories>nlin.CG cs.DS</categories><comments>Journ\'ees Automates Cellulaires 2010, Turku : Finland (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new fast (real time) sorter of binary numbers by one-dimensional cellular
automata is proposed. It sorts a list of n numbers represented by k-bits each
in exactly nk steps. This is only one step more than a lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0684</identifier>
 <datestamp>2010-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0684</id><created>2010-12-03</created><authors><author><keyname>Efimov</keyname><forenames>Denis</forenames></author><author><keyname>Ra&#xef;ssi</keyname><forenames>Tarek</forenames></author><author><keyname>Zolghadri</keyname><forenames>Ali</forenames></author></authors><title>Adaptive Set Observers Design for Nonlinear Continuous-Time Systems:
  Application to Fault Detection and Diagnosis</title><categories>cs.SY math.OC nlin.AO</categories><msc-class>34H05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper deals with joint state and parameter estimation for nonlinear
continuous-time systems. Based on a guaranteed LPV approximation, the set
adaptive observers design problem is solved avoiding the exponential complexity
obstruction usually met in the set-membership parameter estimation. Potential
application to fault diagnosis is considered. The efficacy of the proposed set
adaptive observers is demonstrated on several examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0726</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0726</id><created>2010-12-03</created><updated>2011-05-10</updated><authors><author><keyname>Tang</keyname><forenames>John</forenames></author><author><keyname>Mascolo</keyname><forenames>Cecilia</forenames></author><author><keyname>Musolesi</keyname><forenames>Mirco</forenames></author><author><keyname>Latora</keyname><forenames>Vito</forenames></author></authors><title>Exploiting Temporal Complex Network Metrics in Mobile Malware
  Containment</title><categories>cs.NI physics.soc-ph</categories><comments>9 Pages, 13 Figures, In Proceedings of IEEE 12th International
  Symposium on a World of Wireless, Mobile and Multimedia Networks (WOWMOM '11)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Malicious mobile phone worms spread between devices via short-range Bluetooth
contacts, similar to the propagation of human and other biological viruses.
Recent work has employed models from epidemiology and complex networks to
analyse the spread of malware and the effect of patching specific nodes. These
approaches have adopted a static view of the mobile networks, i.e., by
aggregating all the edges that appear over time, which leads to an approximate
representation of the real interactions: instead, these networks are inherently
dynamic and the edge appearance and disappearance is highly influenced by the
ordering of the human contacts, something which is not captured at all by
existing complex network measures. In this paper we first study how the
blocking of malware propagation through immunisation of key nodes (even if
carefully chosen through static or temporal betweenness centrality metrics) is
ineffective: this is due to the richness of alternative paths in these
networks. Then we introduce a time-aware containment strategy that spreads a
patch message starting from nodes with high temporal closeness centrality and
show its effectiveness using three real-world datasets. Temporal closeness
allows the identification of nodes able to reach most nodes quickly: we show
that this scheme can reduce the cellular network resource consumption and
associated costs, achieving, at the same time, a complete containment of the
malware in a limited amount of time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0729</identifier>
 <datestamp>2010-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0729</id><created>2010-12-03</created><authors><author><keyname>Feldman</keyname><forenames>Vitaly</forenames></author><author><keyname>Guruswami</keyname><forenames>Venkatesan</forenames></author><author><keyname>Raghavendra</keyname><forenames>Prasad</forenames></author><author><keyname>Wu</keyname><forenames>Yi</forenames></author></authors><title>Agnostic Learning of Monomials by Halfspaces is Hard</title><categories>cs.CC cs.AI cs.LG</categories><comments>37 pages, Preliminary version appeared in FOCS 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove the following strong hardness result for learning: Given a
distribution of labeled examples from the hypercube such that there exists a
monomial consistent with $(1-\eps)$ of the examples, it is NP-hard to find a
halfspace that is correct on $(1/2+\eps)$ of the examples, for arbitrary
constants $\eps &gt; 0$. In learning theory terms, weak agnostic learning of
monomials is hard, even if one is allowed to output a hypothesis from the much
bigger concept class of halfspaces. This hardness result subsumes a long line
of previous results, including two recent hardness results for the proper
learning of monomials and halfspaces. As an immediate corollary of our result
we show that weak agnostic learning of decision lists is NP-hard.
  Our techniques are quite different from previous hardness proofs for
learning. We define distributions on positive and negative examples for
monomials whose first few moments match. We use the invariance principle to
argue that regular halfspaces (all of whose coefficients have small absolute
value relative to the total $\ell_2$ norm) cannot distinguish between
distributions whose first few moments match. For highly non-regular subspaces,
we use a structural lemma from recent work on fooling halfspaces to argue that
they are ``junta-like'' and one can zero out all but the top few coefficients
without affecting the performance of the halfspace. The top few coefficients
form the natural list decoding of a halfspace in the context of dictatorship
tests/Label Cover reductions.
  We note that unlike previous invariance principle based proofs which are only
known to give Unique-Games hardness, we are able to reduce from a version of
Label Cover problem that is known to be NP-hard. This has inspired follow-up
work on bypassing the Unique Games conjecture in some optimal geometric
inapproximability results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0735</identifier>
 <datestamp>2011-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0735</id><created>2010-12-03</created><updated>2011-03-24</updated><authors><author><keyname>Balc&#xe1;zar</keyname><forenames>Jos&#xe9; L.</forenames></author><author><keyname>Garc&#xed;a-Saiz</keyname><forenames>Diego</forenames></author><author><keyname>G&#xf3;mez-P&#xe9;rez</keyname><forenames>Domingo</forenames></author><author><keyname>T&#xee;rn&#x103;uc&#x103;</keyname><forenames>Cristina</forenames></author></authors><title>Closed-set-based Discovery of Bases of Association Rules</title><categories>cs.LG cs.AI cs.LO math.LO</categories><comments>Shorter version in: Ali Khenchaf and Pascal Poncelet (eds.),
  Extraction et gestion des connaissances (EGC'2011)</comments><acm-class>H.2.8; I.2.3; F.4.1</acm-class><journal-ref>Revue des Nouvelles Technologies de l'Information RNTI-E-20
  (2011), pages 635-646</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The output of an association rule miner is often huge in practice. This is
why several concise lossless representations have been proposed, such as the
&quot;essential&quot; or &quot;representative&quot; rules. We revisit the algorithm given by
Kryszkiewicz (Int. Symp. Intelligent Data Analysis 2001, Springer-Verlag LNCS
2189, 350-359) for mining representative rules. We show that its output is
sometimes incomplete, due to an oversight in its mathematical validation. We
propose alternative complete generators and we extend the approach to an
existing closure-aware basis similar to, and often smaller than, the
representative rules, namely the basis B*.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0742</identifier>
 <datestamp>2010-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0742</id><created>2010-12-03</created><authors><author><keyname>Balc&#xe1;zar</keyname><forenames>Jos&#xe9; L.</forenames></author><author><keyname>T&#xee;rn&#x103;uc&#x103;</keyname><forenames>Cristina</forenames></author></authors><title>Border Algorithms for Computing Hasse Diagrams of Arbitrary Lattices</title><categories>cs.AI cs.LG math.LO</categories><acm-class>I.2.4; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Border algorithm and the iPred algorithm find the Hasse diagrams of FCA
lattices. We show that they can be generalized to arbitrary lattices. In the
case of iPred, this requires the identification of a join-semilattice
homomorphism into a distributive lattice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0746</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0746</id><created>2010-12-03</created><updated>2011-03-22</updated><authors><author><keyname>Kaminski</keyname><forenames>Mark</forenames><affiliation>Saarland University</affiliation></author><author><keyname>Schneider</keyname><forenames>Sigurd</forenames><affiliation>Saarland University</affiliation></author><author><keyname>Smolka</keyname><forenames>Gert</forenames><affiliation>Saarland University</affiliation></author></authors><title>Terminating Tableaux for Graded Hybrid Logic with Global Modalities and
  Role Hierarchies</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.4.1, I.2.3, I.2.4</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 1 (March 21,
  2011) lmcs:969</journal-ref><doi>10.2168/LMCS-7(1:5)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a terminating tableau calculus for graded hybrid logic with global
modalities, reflexivity, transitivity and role hierarchies. Termination of the
system is achieved through pattern-based blocking. Previous approaches to
related logics all rely on chain-based blocking. Besides being conceptually
simple and suitable for efficient implementation, the pattern-based approach
gives us a NExpTime complexity bound for the decision procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0759</identifier>
 <datestamp>2010-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0759</id><created>2010-12-03</created><authors><author><keyname>Damiani</keyname><forenames>Ernesto</forenames></author><author><keyname>Pagano</keyname><forenames>Francesco</forenames></author></authors><title>Handling Confidential Data on the Untrusted Cloud: An Agent-based
  Approach</title><categories>cs.CR cs.DC cs.MA</categories><comments>7 pages, 9 figures, Cloud Computing 2010</comments><acm-class>D.4.6; C.2.4; E.3</acm-class><journal-ref>CLOUD COMPUTING 2010 : The First International Conference on Cloud
  Computing, GRIDs, and Virtualization - ISBN: 978-1-61208-001-7</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Cloud computing allows shared computer and storage facilities to be used by a
multitude of clients. While cloud management is centralized, the information
resides in the cloud and information sharing can be implemented via
off-the-shelf techniques for multiuser databases. Users, however, are very
diffident for not having full control over their sensitive data. Untrusted
database-as-a-server techniques are neither readily extendable to the cloud
environment nor easily understandable by non-technical users. To solve this
problem, we present an approach where agents share reserved data in a secure
manner by the use of simple grant-and-revoke permissions on shared data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0774</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0774</id><created>2010-12-03</created><authors><author><keyname>Hein</keyname><forenames>Matthias</forenames></author><author><keyname>B&#xfc;hler</keyname><forenames>Thomas</forenames></author></authors><title>An Inverse Power Method for Nonlinear Eigenproblems with Applications in
  1-Spectral Clustering and Sparse PCA</title><categories>cs.LG math.OC stat.ML</categories><comments>Long version of paper accepted at NIPS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many problems in machine learning and statistics can be formulated as
(generalized) eigenproblems. In terms of the associated optimization problem,
computing linear eigenvectors amounts to finding critical points of a quadratic
function subject to quadratic constraints. In this paper we show that a certain
class of constrained optimization problems with nonquadratic objective and
constraints can be understood as nonlinear eigenproblems. We derive a
generalization of the inverse power method which is guaranteed to converge to a
nonlinear eigenvector. We apply the inverse power method to 1-spectral
clustering and sparse PCA which can naturally be formulated as nonlinear
eigenproblems. In both applications we achieve state-of-the-art results in
terms of solution quality and runtime. Moving beyond the standard eigenproblem
should be useful also in many other applications and our inverse power method
can be easily adapted to new problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0806</identifier>
 <datestamp>2011-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0806</id><created>2010-12-03</created><updated>2011-01-19</updated><authors><author><keyname>Frackiewicz</keyname><forenames>Piotr</forenames></author></authors><title>Application of the EWL protocol to decision problems with imperfect
  recall</title><categories>cs.GT quant-ph</categories><comments>13 pages, 2 figures</comments><msc-class>91A18, 81P45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate implementations of the Eisert-Wilkens-Lewenstein scheme be-
yond normal-form games. The scope of our research includes decision problems,
i.e., one-player extensive games. The research is based on the examination of
their features when the decision problems are carried out via the EWL protocol.
We prove that unitary operators can be adapted to play the role of strategies
in deci- sion problems with imperfect recall. Furthermore, we prove that
unitary operators provide the decision maker possibilities that are
inaccessible for classical strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0821</identifier>
 <datestamp>2013-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0821</id><created>2010-12-03</created><updated>2013-08-07</updated><authors><author><keyname>Gutoski</keyname><forenames>Gus</forenames></author></authors><title>Interactive proofs with competing teams of no-signaling provers</title><categories>cs.CC</categories><comments>24 pages. Final version published in CJTCS at
  http://cjtcs.cs.uchicago.edu/articles/2013/7/contents.html</comments><journal-ref>Chicago Journal of Theoretical Computer Science, article 7, 2013</journal-ref><doi>10.4086/cjtcs.2013.007</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper studies a generalization of multi-prover interactive proofs in
which a verifier interacts with two competing teams of provers: one team
attempts to convince the verifier to accept while the other attempts to
convince the verifier to reject. Each team consists of two provers who jointly
implement a no-signaling strategy. No-signaling strategies are a curious class
of joint strategy that cannot in general be implemented without communication
between the provers, yet cannot be used as a black box to establish
communication between them. Attention is restricted in this paper to two-turn
interactions in which the verifier asks questions of each of the four provers
and decides whether to accept or reject based on their responses.
  We prove that the complexity class of decision problems that admit two-turn
interactive proofs with competing teams of no-signaling provers is a subset of
PSPACE. This upper bound matches existing PSPACE lower bounds on the following
two disparate and weaker classes of interactive proof:
  1. Two-turn multi-prover interactive proofs with only one team of
no-signaling provers.
  2. Two-turn competing-prover interactive proofs with only one prover per
team.
  Our result implies that the complexity of these two models is unchanged by
the addition of a second competing team of no-signaling provers in the first
case and by the addition of a second no-signaling prover to each team in the
second case. Moreover, our result unifies and subsumes prior PSPACE upper
bounds on these classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0830</identifier>
 <datestamp>2010-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0830</id><created>2010-12-03</created><authors><author><keyname>Moinard</keyname><forenames>Yves</forenames><affiliation>INRIA - IRISA</affiliation></author></authors><title>Using ASP with recent extensions for causal explanations</title><categories>cs.AI</categories><proxy>ccsd</proxy><journal-ref>ASPOCP10, Answer Set Programming and Other Computing Paradigms
  Workshop, associated with ICLP, Edinburgh : United Kingdom (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the practicality for a user of using Answer Set Programming (ASP)
for representing logical formalisms. We choose as an example a formalism aiming
at capturing causal explanations from causal information. We provide an
implementation, showing the naturalness and relative efficiency of this
translation job. We are interested in the ease for writing an ASP program, in
accordance with the claimed ``declarative'' aspect of ASP. Limitations of the
earlier systems (poor data structure and difficulty in reusing pieces of
programs) made that in practice, the ``declarative aspect'' was more
theoretical than practical. We show how recent improvements in working ASP
systems facilitate a lot the translation, even if a few improvements could
still be useful.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0841</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0841</id><created>2010-12-03</created><authors><author><keyname>Malo</keyname><forenames>Pekka</forenames></author><author><keyname>Siitari</keyname><forenames>Pyry</forenames></author><author><keyname>Sinha</keyname><forenames>Ankur</forenames></author></authors><title>Automated Query Learning with Wikipedia and Genetic Programming</title><categories>cs.AI cs.IR cs.LG cs.NE</categories><comments>44 pages</comments><msc-class>68P20, 68Txx</msc-class><acm-class>H.3.1; H.3.3; G.1.6; H.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of the existing information retrieval systems are based on bag of words
model and are not equipped with common world knowledge. Work has been done
towards improving the efficiency of such systems by using intelligent
algorithms to generate search queries, however, not much research has been done
in the direction of incorporating human-and-society level knowledge in the
queries. This paper is one of the first attempts where such information is
incorporated into the search queries using Wikipedia semantics. The paper
presents an essential shift from conventional token based queries to concept
based queries, leading to an enhanced efficiency of information retrieval
systems. To efficiently handle the automated query learning problem, we propose
Wikipedia-based Evolutionary Semantics (Wiki-ES) framework where concept based
queries are learnt using a co-evolving evolutionary procedure. Learning concept
based queries using an intelligent evolutionary procedure yields significant
improvement in performance which is shown through an extensive study using
Reuters newswire documents. Comparison of the proposed framework is performed
with other information retrieval systems. Concept based approach has also been
implemented on other information retrieval systems to justify the effectiveness
of a transition from token based queries to concept based queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0854</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0854</id><created>2010-12-03</created><authors><author><keyname>Malo</keyname><forenames>Pekka</forenames></author><author><keyname>Siitari</keyname><forenames>Pyry</forenames></author><author><keyname>Ahlgren</keyname><forenames>Oskar</forenames></author><author><keyname>Wallenius</keyname><forenames>Jyrki</forenames></author><author><keyname>Korhonen</keyname><forenames>Pekka</forenames></author></authors><title>Semantic Content Filtering with Wikipedia and Ontologies</title><categories>cs.IR</categories><comments>9 pages, Third International Workshop on Semantic Aspects in Data
  Mining (SADM'10) in conjunction with the 2010 IEEE International Conference
  on Data Mining</comments><acm-class>H.3.1; H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of domain knowledge is generally found to improve query efficiency in
content filtering applications. In particular, tangible benefits have been
achieved when using knowledge-based approaches within more specialized fields,
such as medical free texts or legal documents. However, the problem is that
sources of domain knowledge are time-consuming to build and equally costly to
maintain. As a potential remedy, recent studies on Wikipedia suggest that this
large body of socially constructed knowledge can be effectively harnessed to
provide not only facts but also accurate information about semantic
concept-similarities. This paper describes a framework for document filtering,
where Wikipedia's concept-relatedness information is combined with a domain
ontology to produce semantic content classifiers. The approach is evaluated
using Reuters RCV1 corpus and TREC-11 filtering task definitions. In a
comparative study, the approach shows robust performance and appears to
outperform content classifiers based on Support Vector Machines (SVM) and C4.5
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0866</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0866</id><created>2010-12-03</created><updated>2014-08-01</updated><authors><author><keyname>Airoldi</keyname><forenames>Edoardo M.</forenames></author><author><keyname>Costa</keyname><forenames>Thiago</forenames></author><author><keyname>Bassetti</keyname><forenames>Federico</forenames></author><author><keyname>Leisen</keyname><forenames>Fabrizio</forenames></author><author><keyname>Guindani</keyname><forenames>Michele</forenames></author></authors><title>Generalized Species Sampling Priors with Latent Beta reinforcements</title><categories>math.ST cs.LG stat.ME stat.TH</categories><comments>For correspondence purposes, Edoardo M. Airoldi's email is
  airoldi@fas.harvard.edu; Federico Bassetti's email is
  federico.bassetti@unipv.it; Michele Guindani's email is
  mguindani@mdanderson.org ; Fabrizo Leisen's email is
  fabrizio.leisen@gmail.com. To appear in the Journal of the American
  Statistical Association</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many popular Bayesian nonparametric priors can be characterized in terms of
exchangeable species sampling sequences. However, in some applications,
exchangeability may not be appropriate. We introduce a {novel and
probabilistically coherent family of non-exchangeable species sampling
sequences characterized by a tractable predictive probability function with
weights driven by a sequence of independent Beta random variables. We compare
their theoretical clustering properties with those of the Dirichlet Process and
the two parameters Poisson-Dirichlet process. The proposed construction
provides a complete characterization of the joint process, differently from
existing work. We then propose the use of such process as prior distribution in
a hierarchical Bayes modeling framework, and we describe a Markov Chain Monte
Carlo sampler for posterior inference. We evaluate the performance of the prior
and the robustness of the resulting inference in a simulation study, providing
a comparison with popular Dirichlet Processes mixtures and Hidden Markov
Models. Finally, we develop an application to the detection of chromosomal
aberrations in breast cancer by leveraging array CGH data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0887</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0887</id><created>2010-12-04</created><updated>2012-01-31</updated><authors><author><keyname>Jagadev</keyname><forenames>Alok Kumar</forenames></author><author><keyname>Pattanayak</keyname><forenames>Binod Kumar</forenames></author><author><keyname>Mishra</keyname><forenames>Manoj Kumar</forenames></author><author><keyname>Nayak</keyname><forenames>Manojranjan</forenames></author></authors><title>Power and Delay Aware On-Demand Routing For Ad Hoc Networks</title><categories>cs.NI</categories><comments>7 pages, 9 figures</comments><journal-ref>International Journal on Computer Science and Engineering Vol. 02,
  No. 04, 2010, 917-923</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wide implementation of IEEE 802.11 based networks could lead to deployment of
localized wireless data communication environments with a limited number of
mobile hosts, called ad hoc networks. Implementation of a proper routing
methodology in ad hoc networks makes it efficient in terms of performance. A
wide spectrum of routing protocols has been contributed by several researchers.
Real time applications have been most popular among the applications, run by ad
hoc networks. Such applications strictly adhere to the Quality of Service (QoS)
requirements such as overall throughput, end-toend delay and power level.
Support of QoS requirements becomes more challenging due to dynamic nature of
MANETs, where mobility of nodes results in frequent change in topology. QoS
aware routing protocols can serve to the QoS support, which concentrate on
determining a path between source and destination with the QoS requirements of
the flow being satisfied. We propose a protocol, called Power and Delay aware
Temporally Ordered Routing Algorithm (PDTORA), based on Temporally Ordered
Routing Algorithm (TORA) Protocol, where verification of power and delay
requirements is carried out with a query packet at each node along the path
between source and destination. Simulations justify better performance of the
proposed new protocol in terms of network lifetime, end-to-end delay and packet
delivery ratio as compared to TORA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0898</identifier>
 <datestamp>2012-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0898</id><created>2010-12-04</created><authors><author><keyname>Harada</keyname><forenames>Masaaki</forenames></author><author><keyname>Munemasa</keyname><forenames>Akihiro</forenames></author></authors><title>Classification of quaternary Hermitian self-dual codes of length 20</title><categories>math.CO cs.IT math.IT</categories><comments>9 pages. To appear in IEEE Transactions on Information Theory</comments><msc-class>94B05</msc-class><journal-ref>IEEE Trans. Inform. Theory 57 (2011), 3758-3762</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A classification of quaternary Hermitian self-dual codes of length 20 is
given. Using this classification, a classification of extremal quaternary
Hermitian self-dual codes of length 22 is also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0900</identifier>
 <datestamp>2010-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0900</id><created>2010-12-04</created><authors><author><keyname>Yuen</keyname><forenames>Henry</forenames></author><author><keyname>Shimojo</keyname><forenames>Fuyuki</forenames></author><author><keyname>Zhang</keyname><forenames>Kevin J.</forenames></author><author><keyname>Nomura</keyname><forenames>Ken-ichi</forenames></author><author><keyname>Kalia</keyname><forenames>Rajiv K.</forenames></author><author><keyname>Nakano</keyname><forenames>Aiichiro</forenames></author><author><keyname>Vashishta</keyname><forenames>Priya</forenames></author></authors><title>DNA Sequencing via Quantum Mechanics and Machine Learning</title><categories>physics.bio-ph cs.CE q-bio.QM</categories><comments>19 pages, 7 figures</comments><journal-ref>International Journal of Computational Science, Vol. 4, No. 4,
  2010. pp. 352 - 370</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rapid sequencing of individual human genome is prerequisite to genomic
medicine, where diseases will be prevented by preemptive cures.
Quantum-mechanical tunneling through single-stranded DNA in a solid-state
nanopore has been proposed for rapid DNA sequencing, but unfortunately the
tunneling current alone cannot distinguish the four nucleotides due to large
fluctuations in molecular conformation and solvent. Here, we propose a
machine-learning approach applied to the tunneling current-voltage (I-V)
characteristic for efficient discrimination between the four nucleotides. We
first combine principal component analysis (PCA) and fuzzy c-means (FCM)
clustering to learn the &quot;fingerprints&quot; of the electronic density-of-states
(DOS) of the four nucleotides, which can be derived from the I-V data. We then
apply the hidden Markov model and the Viterbi algorithm to sequence a time
series of DOS data (i.e., to solve the sequencing problem). Numerical
experiments show that the PCA-FCM approach can classify unlabeled DOS data with
91% accuracy. Furthermore, the classification is found to be robust against
moderate levels of noise, i.e., 70% accuracy is retained with a signal-to-noise
ratio of 26 dB. The PCA-FCM-Viterbi approach provides a 4-fold increase in
accuracy for the sequencing problem compared with PCA alone. In conjunction
with recent developments in nanotechnology, this machine-learning method may
pave the way to the much-awaited rapid, low-cost genome sequencer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0929</identifier>
 <datestamp>2014-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0929</id><created>2010-12-04</created><updated>2011-03-11</updated><authors><author><keyname>Ilik</keyname><forenames>Danko</forenames></author></authors><title>Delimited control operators prove Double-negation Shift</title><categories>math.LO cs.LO</categories><journal-ref>Annals of Pure and Applied Logic 163(11), 2012</journal-ref><doi>10.1016/j.apal.2011.12.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an extension of minimal intuitionistic predicate logic, based on
delimited control operators, that can derive the predicate-logic version of the
Double-negation Shift schema, while preserving the disjunction and existence
properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0930</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0930</id><created>2010-12-04</created><updated>2012-08-02</updated><authors><author><keyname>Li</keyname><forenames>Nan</forenames></author><author><keyname>Tsang</keyname><forenames>Ivor W.</forenames></author><author><keyname>Zhou</keyname><forenames>Zhi-Hua</forenames></author></authors><title>Efficient Optimization of Performance Measures by Classifier Adaptation</title><categories>cs.LG cs.AI</categories><comments>30 pages, 5 figures, to appear in IEEE Transactions on Pattern
  Analysis and Machine Intelligence, 2012</comments><journal-ref>IEEE Transactions on Pattern Analysis and Machine Intelligence,
  2013, 35(6): 1370-1382</journal-ref><doi>10.1109/TPAMI.2012.172</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In practical applications, machine learning algorithms are often needed to
learn classifiers that optimize domain specific performance measures.
Previously, the research has focused on learning the needed classifier in
isolation, yet learning nonlinear classifier for nonlinear and nonsmooth
performance measures is still hard. In this paper, rather than learning the
needed classifier by optimizing specific performance measure directly, we
circumvent this problem by proposing a novel two-step approach called as CAPO,
namely to first train nonlinear auxiliary classifiers with existing learning
methods, and then to adapt auxiliary classifiers for specific performance
measures. In the first step, auxiliary classifiers can be obtained efficiently
by taking off-the-shelf learning algorithms. For the second step, we show that
the classifier adaptation problem can be reduced to a quadratic program
problem, which is similar to linear SVMperf and can be efficiently solved. By
exploiting nonlinear auxiliary classifiers, CAPO can generate nonlinear
classifier which optimizes a large variety of performance measures including
all the performance measure based on the contingency table and AUC, whilst
keeping high computational efficiency. Empirical studies show that CAPO is
effective and of high computational efficiency, and even it is more efficient
than linear SVMperf.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0952</identifier>
 <datestamp>2010-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0952</id><created>2010-12-04</created><authors><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author><author><keyname>Johannsen</keyname><forenames>Daniel</forenames></author><author><keyname>K&#xf6;tzing</keyname><forenames>Timo</forenames></author><author><keyname>Lehre</keyname><forenames>Per Kristian</forenames></author><author><keyname>Wagner</keyname><forenames>Markus</forenames></author><author><keyname>Winzen</keyname><forenames>Carola</forenames></author></authors><title>Faster Black-Box Algorithms Through Higher Arity Operators</title><categories>cs.NE</categories><comments>To appear at FOGA 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the work of Lehre and Witt (GECCO 2010) on the unbiased black-box
model by considering higher arity variation operators. In particular, we show
that already for binary operators the black-box complexity of \leadingones
drops from $\Theta(n^2)$ for unary operators to $O(n \log n)$. For \onemax, the
$\Omega(n \log n)$ unary black-box complexity drops to O(n) in the binary case.
For $k$-ary operators, $k \leq n$, the \onemax-complexity further decreases to
$O(n/\log k)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0955</identifier>
 <datestamp>2010-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0955</id><created>2010-12-04</created><authors><author><keyname>Feizi</keyname><forenames>Soheil</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Effros</keyname><forenames>Michelle</forenames></author></authors><title>Compressive Sensing Over Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we demonstrate some applications of compressive sensing over
networks. We make a connection between compressive sensing and traditional
information theoretic techniques in source coding and channel coding. Our
results provide an explicit trade-off between the rate and the decoding
complexity. The key difference of compressive sensing and traditional
information theoretic approaches is at their decoding side. Although optimal
decoders to recover the original signal, compressed by source coding have high
complexity, the compressive sensing decoder is a linear or convex optimization.
First, we investigate applications of compressive sensing on distributed
compression of correlated sources. Here, by using compressive sensing, we
propose a compression scheme for a family of correlated sources with a
modularized decoder, providing a trade-off between the compression rate and the
decoding complexity. We call this scheme Sparse Distributed Compression. We use
this compression scheme for a general multicast network with correlated
sources. Here, we first decode some of the sources by a network decoding
technique and then, we use a compressive sensing decoder to obtain the whole
sources. Then, we investigate applications of compressive sensing on channel
coding. We propose a coding scheme that combines compressive sensing and random
channel coding for a high-SNR point-to-point Gaussian channel. We call this
scheme Sparse Channel Coding. We propose a modularized decoder providing a
trade-off between the capacity loss and the decoding complexity. At the
receiver side, first, we use a compressive sensing decoder on a noisy signal to
obtain a noisy estimate of the original signal and then, we apply a traditional
channel coding decoder to find the original signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0956</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0956</id><created>2010-12-04</created><updated>2011-04-18</updated><authors><author><keyname>Paparrizos</keyname><forenames>Ioannis</forenames></author></authors><title>A tight bound on the worst-case number of comparisons for Floyd's heap
  construction algorithm</title><categories>cs.DS cs.CC</categories><comments>This (full) paper was accepted for publication in the 37th
  International Conference on Current Trends in Theory and Practice of Computer
  Science (SOFSEM2011), 22-28 January 2011, Novy Smokovec, Slovakia (9 pages)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a tight bound on the worst-case number of comparisons for
Floyd's well known heap construction algorithm, is derived. It is shown that at
most 2n-2{\mu}(n)-{\sigma}(n) comparisons are executed in the worst case, where
{\mu}(n) is the number of ones and {\sigma}(n) is the number of zeros after the
last one in the binary representation of the number of keys n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0975</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0975</id><created>2010-12-05</created><updated>2010-12-23</updated><authors><author><keyname>Ye</keyname><forenames>Gui-Bo</forenames></author><author><keyname>Cai</keyname><forenames>Jian-Feng</forenames></author><author><keyname>Xie</keyname><forenames>Xiaohui</forenames></author></authors><title>Split Bregman Method for Sparse Inverse Covariance Estimation with
  Matrix Iteration Acceleration</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of estimating the inverse covariance matrix by
maximizing the likelihood function with a penalty added to encourage the
sparsity of the resulting matrix. We propose a new approach based on the split
Bregman method to solve the regularized maximum likelihood estimation problem.
We show that our method is significantly faster than the widely used graphical
lasso method, which is based on blockwise coordinate descent, on both
artificial and real-world data. More importantly, different from the graphical
lasso, the split Bregman based method is much more general, and can be applied
to a class of regularization terms other than the $\ell_1$ norm
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.0993</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.0993</id><created>2010-12-05</created><updated>2011-09-21</updated><authors><author><keyname>Ndoundam</keyname><forenames>Rene</forenames></author><author><keyname>Sadie</keyname><forenames>Juvet Karnel</forenames></author><author><keyname>Nguembu</keyname><forenames>Patrick Nguening</forenames></author></authors><title>Hash function based on arithmetic coding and public-key cryptography</title><categories>cs.CR</categories><comments>This paper has been withdrawn by the authors due to the fact that the
  implementation of the ideas of the paper need a PKI</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a hash function based on arithmetic coding and public-key
cryptography. The resistance of the hash function to second preimage attack,
collision and differential cryptanalysis is based on the properties of
arithmetic coding as a non-linear dynamical system. The resistance of the hash
function to first preimage attack is based on the public-key cryptography. The
new hash function uses the strength of HMAC with the difference that it didn't
need a secret key for calculating the hash (in this step, it uses one, two or
three public -keys) and in the classical attack, an adversary need to break the
public key algorithm or to have all the secret keys to perform his attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1007</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1007</id><created>2010-12-05</created><updated>2012-05-22</updated><authors><author><keyname>Zhang</keyname><forenames>Lei</forenames></author><author><keyname>Luo</keyname><forenames>Jun</forenames></author><author><keyname>Guo</keyname><forenames>Dongning</forenames></author></authors><title>Neighbor Discovery for Wireless Networks via Compressed Sensing</title><categories>cs.NI cs.IT math.IT</categories><comments>29 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of neighbor discovery in wireless networks,
namely, each node wishes to discover and identify the network interface
addresses (NIAs) of those nodes within a single hop. A novel paradigm, called
compressed neighbor discovery is proposed, which enables all nodes to
simultaneously discover their respective neighborhoods with a single frame of
transmission, which is typically of a few thousand symbol epochs. The key
technique is to assign each node a unique on-off signature and let all nodes
simultaneously transmit their signatures. Despite that the radios are
half-duplex, each node observes a superposition of its neighbors' signatures
(partially) through its own off-slots. To identify its neighbors out of a large
network address space, each node solves a compressed sensing (or sparse
recovery) problem.
  Two practical schemes are studied. The first employs random on-off
signatures, and each node discovers its neighbors using a noncoherent detection
algorithm based on group testing. The second scheme uses on-off signatures
based on a deterministic second-order Reed-Muller code, and applies a chirp
decoding algorithm. The second scheme needs much lower signal-to-noise ratio
(SNR) to achieve the same error performance. The complexity of the chirp
decoding algorithm is sub-linear, so that it is in principle scalable to
networks with billions of nodes with 48-bit IEEE 802.11 MAC addresses. The
compressed neighbor discovery schemes are much more efficient than conventional
random-access discovery, where nodes have to retransmit over many frames with
random delays to be successfully discovered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1010</identifier>
 <datestamp>2011-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1010</id><created>2010-12-05</created><updated>2011-09-17</updated><authors><author><keyname>Ahrens</keyname><forenames>Benedikt</forenames></author><author><keyname>Zsido</keyname><forenames>Julianna</forenames></author></authors><title>Initial Semantics for higher-order typed syntax in Coq</title><categories>cs.LO math.LO</categories><comments>Article as published in JFR (cf. Journal ref). Features some more
  examples</comments><msc-class>68Q55, 03B70</msc-class><journal-ref>Journal of Formalized Reasoning, Vol. 4, No. 1 (2011), pp. 25-69</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Initial Semantics aims at characterizing the syntax associated to a signature
as the initial object of some category. We present an initial semantics result
for typed higher-order syntax together with its formalization in the Coq proof
assistant. The main theorem was first proved on paper in the second author's
PhD thesis in 2010, and verified formally shortly afterwards. To a simply-typed
binding signature S over a fixed set T of object types we associate a category
called the category of representations of S. We show that this category has an
initial object Sigma(S). From its construction it will be clear that the object
Sigma(S) merits the name abstract syntax associated to S. Our theorem is
implemented and proved correct in the proof assistant Coq through heavy use of
dependent types. The approach through monads gives rise to an implementation of
syntax where both terms and variables are intrinsically typed, i.e. where the
object types are reflected in the meta-level types. This article is to be seen
as a research article rather than about the formalization of a classical
mathematical result. The nature of our theorem - involving lengthy, technical
proofs and complicated algebraic structures - makes it particularly interesting
for formal verification. Our goal is to promote the use of computer theorem
provers as research tools, and, accordingly, a new way of publishing
mathematical results: a parallel description of a theorem and its formalization
should allow the verification of correct transcription of definitions and
statements into the proof assistant, and straightforward but technical proofs
should be well-hidden in a digital library. We argue that Coq's rich type
theory, combined with its various features such as implicit arguments, allows a
particularly readable formalization and is hence well-suited for communicating
mathematics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1095</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1095</id><created>2010-12-06</created><authors><author><keyname>Nguyen</keyname><forenames>Huy</forenames></author><author><keyname>Zheng</keyname><forenames>Guanbo</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Zheng</keyname><forenames>Rong</forenames></author></authors><title>Binary Inference for Primary User Separation in Cognitive Radio Networks</title><categories>cs.NI</categories><comments>Submitted to the IEEE Transactions on Wireless Communications on Nov.
  2010</comments><acm-class>C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum sensing receives much attention recently in the cognitive radio (CR)
network research, i.e., secondary users (SUs) constantly monitor channel
condition to detect the presence of the primary users (PUs). In this paper, we
go beyond spectrum sensing and introduce the PU separation problem, which
concerns with the issues of distinguishing and characterizing PUs in the
context of collaborative spectrum sensing and monitor selection. The
observations of monitors are modeled as boolean OR mixtures of underlying
binary sources for PUs. We first justify the use of the binary OR mixture model
as opposed to the traditional linear mixture model through simulation studies.
Then we devise a novel binary inference algorithm for PU separation. Not only
PU-SU relationship are revealed, but PUs' transmission statistics and
activities at each time slot can also be inferred. Simulation results show that
without any prior knowledge regarding PUs' activities, the algorithm achieves
high inference accuracy even in the presence of noisy measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1099</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1099</id><created>2010-12-06</created><authors><author><keyname>Cimini</keyname><forenames>Giulio</forenames></author><author><keyname>Medo</keyname><forenames>Matus</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author><author><keyname>Wei</keyname><forenames>Dong</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author></authors><title>Heterogeneity, quality, and reputation in an adaptive recommendation
  model</title><categories>physics.soc-ph cs.SI</categories><journal-ref>Eur. Phys. J. B 80, 201-208 (2011)</journal-ref><doi>10.1140/epjb/e2010-10716-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recommender systems help people cope with the problem of information
overload. A recently proposed adaptive news recommender model [Medo et al.,
2009] is based on epidemic-like spreading of news in a social network. By means
of agent-based simulations we study a &quot;good get richer&quot; feature of the model
and determine which attributes are necessary for a user to play a leading role
in the network. We further investigate the filtering efficiency of the model as
well as its robustness against malicious and spamming behaviour. We show that
incorporating user reputation in the recommendation process can substantially
improve the outcome.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1128</identifier>
 <datestamp>2010-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1128</id><created>2010-12-06</created><authors><author><keyname>Poupet</keyname><forenames>Victor</forenames><affiliation>LIF</affiliation></author></authors><title>Yet another aperiodic tile set</title><categories>cs.DM</categories><proxy>ccsd</proxy><journal-ref>Journ\'ees Automates Cellulaires 2010, Turku : Finland (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present here an elementary construction of an aperiodic tile set. Although
there already exist dozens of examples of aperiodic tile sets we believe this
construction introduces an approach that is different enough to be interesting
and that the whole construction and the proof of aperiodicity are hopefully
simpler than most existing techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1129</identifier>
 <datestamp>2010-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1129</id><created>2010-12-06</created><authors><author><keyname>Gardy</keyname><forenames>Dani&#xe8;le</forenames><affiliation>PRISM</affiliation></author><author><keyname>Ponty</keyname><forenames>Yann</forenames><affiliation>LIX, INRIA Saclay - Ile de France</affiliation></author></authors><title>Weighted random generation of context-free languages: Analysis of
  collisions in random urn occupancy models</title><categories>cs.DS</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present work analyzes the redundancy of sets of combinatorial objects
produced by a weighted random generation algorithm proposed by Denise et al.
This scheme associates weights to the terminals symbols of a weighted
context-free grammar, extends this weight definition multiplicatively on words,
and draws words of length $n$ with probability proportional their weight. We
investigate the level of redundancy within a sample of $k$ word, the proportion
of the total probability covered by $k$ words (coverage), the time (number of
generations) of the first collision, and the time of the full collection. For
these four questions, we use an analytic urn analogy to derive asymptotic
estimates and/or polynomially computable exact forms. We illustrate these tools
by an analysis of an RNA secondary structure statistical sampling algorithm
introduced by Ding et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1131</identifier>
 <datestamp>2010-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1131</id><created>2010-12-06</created><authors><author><keyname>Truong</keyname><forenames>Hien Thi Thu</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Ignat</keyname><forenames>Claudia-Lavinia</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>A Log Auditing Approach for Trust Management in Peer-to-Peer
  Collaboration</title><categories>cs.DC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays we are faced with an increasing popularity of social software
including wikis, blogs, micro-blogs and online social networks such as Facebook
and MySpace. Unfortunately, the mostly used social services are centralized and
personal information is stored at a single vendor. This results in potential
privacy problems as users do not have much control over how their private data
is disseminated. To overcome this limitation, some recent approaches envisioned
replacing the single authority centralization of services by a peer-to-peer
trust-based approach where users can decide with whom they want to share their
private data. In this peer-to-peer collaboration it is very difficult to ensure
that after data is shared with other peers, these peers will not misbehave and
violate data privacy. In this paper we propose a mechanism that addresses the
issue of data privacy violation due to data disclosure to malicious peers. In
our approach trust values between users are adjusted according to their
previous activities on the shared data. Users share their private data by
specifying some obligations the receivers must follow. We log modifications
done by users on the shared data as well as the obligations that must be
followed when data is shared. By a log-auditing mechanism we detect users that
misbehaved and we adjust their associated trust values by using any existing
decentralized trust model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1153</identifier>
 <datestamp>2010-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1153</id><created>2010-12-06</created><authors><author><keyname>Schneider</keyname><forenames>Patrick</forenames></author><author><keyname>Rossnagel</keyname><forenames>Heiko</forenames></author><author><keyname>Zibuschka</keyname><forenames>Jan</forenames></author></authors><title>Mobiles ortsbezogenes Projektmanagement</title><categories>cs.SE</categories><comments>5 pages, in German; preprint, to appear in GI/ITG KuVS Fachgespr\&quot;ach
  &quot;Ortsbezogene Anwendungen und Dienste&quot; 2010</comments><acm-class>H.4.1; A.1; J.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classic project management and its tools usually deal with the management of
three variables, and their relationships with each other. These are the factors
of time, resources (cost) and quality. If one of the variables is to be
improved, it always has negative effects on the other two. However, these
factors only partially describe the reality of project management. What current
project management tools often only consider implicitly is the location of an
activity. In this paper, the implications of using location data for project
management are clarified and a system that offers mobile support in planning
and implementing projects.
  -----
  Klassisches Projektmanagement und seine Werkzeuge befassen sich meist mit der
Verwaltung dreier Gr\&quot;o{\ss}en und ihrer Zusammenh\&quot;ange untereinander. Dabei
handelt es sich um die Faktoren Zeit, Ressourcen (Kosten) und Qualit\&quot;at. Falls
eine der Gr\&quot;o{\ss}en verbessert werden soll, hat dies immer negative
Auswirkungen auf die anderen beiden Gr\&quot;o{\ss}en. Diese Gr\&quot;o{\ss}en
beschreiben die Ph\&quot;anomene des Projektmanagement jedoch nur unvollst\&quot;andig.
Was bei Projektmanagementwerkzeugen bis dato oft nur implizit durch den
Projektleiter einbezogen wird ist ein Ortsbezug. In diesem Beitrag werden die
Implikationen durch diesen Ortsbezug konkretisiert und ein System dargestellt,
welches Projektleiter bei der Planung und Umsetzung von Projekten mobil wie
auch station\&quot;ar unterst\&quot;utzt.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1163</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1163</id><created>2010-12-06</created><authors><author><keyname>Brunsch</keyname><forenames>Tobias</forenames></author><author><keyname>Roeglin</keyname><forenames>Heiko</forenames></author></authors><title>Lower Bounds for the Smoothed Number of Pareto optimal Solutions</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 2009, Roeglin and Teng showed that the smoothed number of Pareto optimal
solutions of linear multi-criteria optimization problems is polynomially
bounded in the number $n$ of variables and the maximum density $\phi$ of the
semi-random input model for any fixed number of objective functions. Their
bound is, however, not very practical because the exponents grow exponentially
in the number $d+1$ of objective functions. In a recent breakthrough, Moitra
and O'Donnell improved this bound significantly to $O(n^{2d} \phi^{d(d+1)/2})$.
  An &quot;intriguing problem&quot;, which Moitra and O'Donnell formulate in their paper,
is how much further this bound can be improved. The previous lower bounds do
not exclude the possibility of a polynomial upper bound whose degree does not
depend on $d$. In this paper we resolve this question by constructing a class
of instances with $\Omega ((n \phi)^{(d-\log{d}) \cdot (1-\Theta{1/\phi})})$
Pareto optimal solutions in expectation. For the bi-criteria case we present a
higher lower bound of $\Omega (n^2 \phi^{1 - \Theta{1/\phi}})$, which almost
matches the known upper bound of $O(n^2 \phi)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1174</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1174</id><created>2010-12-06</created><updated>2011-03-24</updated><authors><author><keyname>Ferreira</keyname><forenames>Gilda</forenames><affiliation>Queen Mary University of London</affiliation></author><author><keyname>Oliva</keyname><forenames>Paulo</forenames><affiliation>Queen Mary University of London</affiliation></author></authors><title>Functional Interpretations of Intuitionistic Linear Logic</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>03F10, 03F52, 03F55</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 1 (March 27,
  2011) lmcs:1110</journal-ref><doi>10.2168/LMCS-7(1:9)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present three different functional interpretations of intuitionistic
linear logic ILL and show how these correspond to well-known functional
interpretations of intuitionistic logic IL via embeddings of IL into ILL. The
main difference from previous work of the second author is that in
intuitionistic linear logic (as opposed to classical linear logic) the
interpretations of !A are simpler and simultaneous quantifiers are no longer
needed for the characterisation of the interpretations. We then compare our
approach in developing these three proof interpretations with the one of de
Paiva around the Dialectica category model of linear logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1184</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1184</id><created>2010-12-06</created><authors><author><keyname>Dong</keyname><forenames>Weisheng</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author><author><keyname>Shi</keyname><forenames>Guangming</forenames></author><author><keyname>Wu</keyname><forenames>Xiaolin</forenames></author></authors><title>Image Deblurring and Super-resolution by Adaptive Sparse Domain
  Selection and Adaptive Regularization</title><categories>cs.CV cs.MM</categories><comments>35 pages. This paper is under review in IEEE TIP</comments><msc-class>68U10</msc-class><doi>10.1109/TIP.2011.2108306</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a powerful statistical image modeling technique, sparse representation has
been successfully used in various image restoration applications. The success
of sparse representation owes to the development of l1-norm optimization
techniques, and the fact that natural images are intrinsically sparse in some
domain. The image restoration quality largely depends on whether the employed
sparse domain can represent well the underlying image. Considering that the
contents can vary significantly across different images or different patches in
a single image, we propose to learn various sets of bases from a pre-collected
dataset of example image patches, and then for a given patch to be processed,
one set of bases are adaptively selected to characterize the local sparse
domain. We further introduce two adaptive regularization terms into the sparse
representation framework. First, a set of autoregressive (AR) models are
learned from the dataset of example image patches. The best fitted AR models to
a given patch are adaptively selected to regularize the image local structures.
Second, the image non-local self-similarity is introduced as another
regularization term. In addition, the sparsity regularization parameter is
adaptively estimated for better image restoration performance. Extensive
experiments on image deblurring and super-resolution validate that by using
adaptive sparse domain selection and adaptive regularization, the proposed
method achieves much better results than many state-of-the-art algorithms in
terms of both PSNR and visual perception.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1193</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1193</id><created>2010-12-06</created><authors><author><keyname>Peng</keyname><forenames>Bo</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author><author><keyname>Zhang</keyname><forenames>David</forenames></author></authors><title>Automatic Image Segmentation by Dynamic Region Merging</title><categories>cs.CV cs.RO</categories><comments>28 pages. This paper is under review in IEEE TIP</comments><msc-class>68T45</msc-class><doi>10.1109/TIP.2011.2157512</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the automatic image segmentation problem in a region
merging style. With an initially over-segmented image, in which the many
regions (or super-pixels) with homogeneous color are detected, image
segmentation is performed by iteratively merging the regions according to a
statistical test. There are two essential issues in a region merging algorithm:
order of merging and the stopping criterion. In the proposed algorithm, these
two issues are solved by a novel predicate, which is defined by the sequential
probability ratio test (SPRT) and the maximum likelihood criterion. Starting
from an over-segmented image, neighboring regions are progressively merged if
there is an evidence for merging according to this predicate. We show that the
merging order follows the principle of dynamic programming. This formulates
image segmentation as an inference problem, where the final segmentation is
established based on the observed image. We also prove that the produced
segmentation satisfies certain global properties. In addition, a faster
algorithm is developed to accelerate the region merging process, which
maintains a nearest neighbor graph in each iteration. Experiments on real
natural images are conducted to demonstrate the performance of the proposed
dynamic region merging algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1211</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1211</id><created>2010-12-06</created><authors><author><keyname>Lambiotte</keyname><forenames>R.</forenames></author><author><keyname>Sinatra</keyname><forenames>R.</forenames></author><author><keyname>Delvenne</keyname><forenames>J. -C.</forenames></author><author><keyname>Evans</keyname><forenames>T. S.</forenames></author><author><keyname>Barahona</keyname><forenames>M.</forenames></author><author><keyname>Latora</keyname><forenames>V.</forenames></author></authors><title>Flow graphs: interweaving dynamics and structure</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>4 pages, 1 figure</comments><doi>10.1103/PhysRevE.84.017102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The behavior of complex systems is determined not only by the topological
organization of their interconnections but also by the dynamical processes
taking place among their constituents. A faithful modeling of the dynamics is
essential because different dynamical processes may be affected very
differently by network topology. A full characterization of such systems thus
requires a formalization that encompasses both aspects simultaneously, rather
than relying only on the topological adjacency matrix. To achieve this, we
introduce the concept of flow graphs, namely weighted networks where dynamical
flows are embedded into the link weights. Flow graphs provide an integrated
representation of the structure and dynamics of the system, which can then be
analyzed with standard tools from network theory. Conversely, a structural
network feature of our choice can also be used as the basis for the
construction of a flow graph that will then encompass a dynamics biased by such
a feature. We illustrate the ideas by focusing on the mathematical properties
of generic linear processes on complex networks that can be represented as
biased random walks and also explore their dual consensus dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1213</identifier>
 <datestamp>2012-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1213</id><created>2010-12-06</created><authors><author><keyname>B&#xf6;hme</keyname><forenames>Gesa A.</forenames></author><author><keyname>Gross</keyname><forenames>Thilo</forenames></author></authors><title>Analytical calculation of fragmentation transitions in adaptive networks</title><categories>nlin.AO cond-mat.dis-nn cs.SI physics.soc-ph</categories><comments>4 pages, 4 figures</comments><doi>10.1103/PhysRevE.83.035101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In adaptive networks fragmentation transitions have been observed in which
the network breaks into disconnected components. We present an analytical
approach for calculating the transition point in general adaptive network
models. Using the example of an adaptive voter model, we demonstrate that the
proposed approach yields good agreement with numerical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1219</identifier>
 <datestamp>2010-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1219</id><created>2010-12-03</created><authors><author><keyname>Borello</keyname><forenames>Alex</forenames><affiliation>LIF</affiliation></author></authors><title>A Simulation of Oblivious Multi-Head One-Way Finite Automata by
  Real-Time Cellular Automata</title><categories>nlin.CG cs.DS cs.FL</categories><comments>Journ\'ees Automates Cellulaires 2010, Turku : Finland (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the simulation of a simple, yet significantly
powerful, sequential model by cellular automata. The simulated model is called
oblivious multi-head one-way finite automata and is characterized by having its
heads moving only forward, on a trajectory that only depends on the length of
the input. While the original finite automaton works in linear time, its
corresponding cellular automaton performs the same task in real time, that is,
exactly the length of the input. Although not truly a speed-up, the simulation
may be interesting and reminds us of the open question about the equivalence of
linear and real times on cellular automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1220</identifier>
 <datestamp>2010-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1220</id><created>2010-12-03</created><authors><author><keyname>Capobianco</keyname><forenames>Silvio</forenames></author><author><keyname>Uustalu</keyname><forenames>Tarmo</forenames></author></authors><title>A Categorical Outlook on Cellular Automata</title><categories>nlin.CG cs.LO math.CT</categories><comments>Journ\'ees Automates Cellulaires 2010, Turku : Finland (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In programming language semantics, it has proved to be fruitful to analyze
context-dependent notions of computation, e.g., dataflow computation and
attribute grammars, using comonads. We explore the viability and value of
similar modeling of cellular automata. We identify local behaviors of cellular
automata with coKleisli maps of the exponent comonad on the category of uniform
spaces and uniformly continuous functions and exploit this equivalence to
conclude some standard results about cellular automata as instances of basic
category-theoretic generalities. In particular, we recover
Ceccherini-Silberstein and Coornaert's version of the Curtis-Hedlund theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1221</identifier>
 <datestamp>2010-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1221</id><created>2010-12-03</created><authors><author><keyname>Givors</keyname><forenames>Fabien</forenames><affiliation>LIF</affiliation></author><author><keyname>Lafitte</keyname><forenames>Gr&#xe9;gory</forenames><affiliation>LIF</affiliation></author><author><keyname>Ollinger</keyname><forenames>Nicolas</forenames><affiliation>LIF</affiliation></author></authors><title>Infinite Time Cellular Automata: A Real Computation Model</title><categories>nlin.CG cs.CC cs.LO</categories><comments>Journ\'ees Automates Cellulaires 2010, Turku : Finland (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a new transfinite time model of computation, infinite time cellular
automata. The model is shown to be as powerful than infinite time Turing
machines, both on finite and infinite inputs; thus inheriting many of its
properties. We then show how to simulate the canonical real computation model,
BSS machines, with infinite time cellular automata in exactly \omega steps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1222</identifier>
 <datestamp>2010-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1222</id><created>2010-12-03</created><authors><author><keyname>Ballier</keyname><forenames>Alexis</forenames><affiliation>LIF</affiliation></author><author><keyname>Jeandel</keyname><forenames>Emmanuel</forenames><affiliation>LIF</affiliation></author></authors><title>Computing (or not) Quasi-Periodicity Functions of Tilings</title><categories>nlin.CG cs.LO math.DS</categories><comments>Journ\'ees Automates Cellulaires 2010, Turku : Finland (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We know that tilesets that can tile the plane always admit a quasi-periodic
tiling [4, 8], yet they hold many uncomputable properties [3, 11, 21, 25]. The
quasi-periodicity function is one way to measure the regularity of a
quasi-periodic tiling. We prove that the tilings by a tileset that admits only
quasi-periodic tilings have a recursively (and uniformly) bounded
quasi-periodicity function. This corrects an error from [6, theorem 9] which
stated the contrary. Instead we construct a tileset for which any
quasi-periodic tiling has a quasi-periodicity function that cannot be
recursively bounded. We provide such a construction for 1-dimensional effective
subshifts and obtain as a corollary the result for tilings of the plane via
recent links between these objects [1, 10].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1237</identifier>
 <datestamp>2012-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1237</id><created>2010-12-06</created><updated>2012-02-06</updated><authors><author><keyname>Chebolu</keyname><forenames>Prasad</forenames></author><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author><author><keyname>Martin</keyname><forenames>Russell</forenames></author></authors><title>The Complexity of Approximately Counting Stable Roommate Assignments</title><categories>cs.CC math.CO</categories><msc-class>68Q17</msc-class><acm-class>F.1.3</acm-class><journal-ref>JCSS 2012</journal-ref><doi>10.1016/j.jcss.2012.02.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the complexity of approximately counting stable roommate
assignments in two models: (i) the $k$-attribute model, in which the preference
lists are determined by dot products of &quot;preference vectors&quot; with &quot;attribute
vectors&quot; and (ii) the $k$-Euclidean model, in which the preference lists are
determined by the closeness of the &quot;positions&quot; of the people to their
&quot;preferred positions&quot;. Exactly counting the number of assignments is
#P-complete, since Irving and Leather demonstrated #P-completeness for the
special case of the stable marriage problem. We show that counting the number
of stable roommate assignments in the $k$-attribute model ($k \geq 4$) and the
3-Euclidean model($k \geq 3$) is interreducible, in an approximation-preserving
sense, with counting independent sets (of all sizes) (#IS) in a graph, or
counting the number of satisfying assignments of a Boolean formula (#SAT). This
means that there can be no FPRAS for any of these problems unless NP=RP. As a
consequence, we infer that there is no FPRAS for counting stable roommate
assignments (#SR) unless NP=RP. Utilizing previous results by the authors, we
give an approximation-preserving reduction from counting the number of
independent sets in a bipartite graph (#BIS) to counting the number of stable
roommate assignments both in the 3-attribute model and in the 2-Euclidean
model. #BIS is complete with respect to approximation-preserving reductions in
the logically-defined complexity class $#RH\Pi_1$. Hence, our result shows that
an FPRAS for counting stable roommate assignments in the 3-attribute model
would give an FPRAS for all of $#RH\Pi_1$. We also show that the 1-attribute
stable roommate problem always has either one or two stable roommate
assignments, so the number of assignments can be determined exactly in
polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1240</identifier>
 <datestamp>2010-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1240</id><created>2010-12-06</created><authors><author><keyname>Pach</keyname><forenames>J&#xe1;nos</forenames></author><author><keyname>Tardos</keyname><forenames>G&#xe1;bor</forenames></author></authors><title>Tight lower bounds for the size of epsilon-nets</title><categories>cs.DM cs.CG</categories><msc-class>52C35, 52C10, 68U05, 05B40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  According to a well known theorem of Haussler and Welzl (1987), any range
space of bounded VC-dimension admits an $\eps$-net of size
$O\left(\frac{1}{\eps}\log\frac1{\eps}\right)$. Using probabilistic techniques,
Pach and Woeginger (1990) showed that there exist range spaces of VC-dimension
2, for which the above bound can be attained. The only known range spaces of
small VC-dimension, in which the ranges are geometric objects in some Euclidean
space and the size of the smallest $\eps$-nets is superlinear in
$\frac1{\eps}$, were found by Alon (2010). In his examples, the size of the
smallest $\eps$-nets is $\Omega\left(\frac{1}{\eps}g(\frac{1}{\eps})\right)$,
where $g$ is an extremely slowly growing function, closely related to the
inverse Ackermann function.
  \smallskip
  We show that there exist geometrically defined range spaces, already of
VC-dimension $2$, in which the size of the smallest $\eps$-nets is
$\Omega\left(\frac{1}{\eps}\log\frac{1}{\eps}\right)$. We also construct range
spaces induced by axis-parallel rectangles in the plane, in which the size of
the smallest $\eps$-nets is
$\Omega\left(\frac{1}{\eps}\log\log\frac{1}{\eps}\right)$. By a theorem of
Aronov, Ezra, and Sharir (2010), this bound is tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1255</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1255</id><created>2010-12-06</created><updated>2012-09-28</updated><authors><author><keyname>Janicic</keyname><forenames>Predrag</forenames><affiliation>University of Belgrade</affiliation></author></authors><title>URSA: A System for Uniform Reduction to SAT</title><categories>cs.AI</categories><comments>39 pages, uses tikz.sty</comments><proxy>LMCS</proxy><acm-class>F.4.1, D.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 3 (September
  30, 2012) lmcs:1171</journal-ref><doi>10.2168/LMCS-8(3:30)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are a huge number of problems, from various areas, being solved by
reducing them to SAT. However, for many applications, translation into SAT is
performed by specialized, problem-specific tools. In this paper we describe a
new system for uniform solving of a wide class of problems by reducing them to
SAT. The system uses a new specification language URSA that combines imperative
and declarative programming paradigms. The reduction to SAT is defined
precisely by the semantics of the specification language. The domain of the
approach is wide (e.g., many NP-complete problems can be simply specified and
then solved by the system) and there are problems easily solvable by the
proposed system, while they can be hardly solved by using other programming
languages or constraint programming systems. So, the system can be seen not
only as a tool for solving problems by reducing them to SAT, but also as a
general-purpose constraint solving system (for finite domains). In this paper,
we also describe an open-source implementation of the described approach. The
performed experiments suggest that the system is competitive to
state-of-the-art related modelling systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1256</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1256</id><created>2010-12-06</created><updated>2012-06-20</updated><authors><author><keyname>Sassi</keyname><forenames>Mohamed Amin Ben</forenames></author><author><keyname>Girard</keyname><forenames>Antoine</forenames></author></authors><title>Computation of Polytopic Invariants for Polynomial Dynamical Systems
  using Linear Programming</title><categories>math.OC cs.SY math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the computation of polytopic invariant sets for
polynomial dynamical systems. An invariant set of a dynamical system is a
subset of the state space such that if the state of the system belongs to the
set at a given instant, it will remain in the set forever in the future.
Polytopic invariants for polynomial systems can be verified by solving a set of
optimization problems involving multivariate polynomials on bounded polytopes.
Using the blossoming principle together with properties of multi-affine
functions on rectangles and Lagrangian duality, we show that certified lower
bounds of the optimal values of such optimization problems can be computed
effectively using linear programs. This allows us to propose a method based on
linear programming for verifying polytopic invariant sets of polynomial
dynamical systems. Additionally, using sensitivity analysis of linear programs,
one can iteratively compute a polytopic invariant set. Finally, we show using a
set of examples borrowed from biological applications, that our approach is
effective in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1258</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1258</id><created>2010-12-06</created><authors><author><keyname>Rajagopal</keyname><forenames>Ram</forenames></author><author><keyname>Nguyen</keyname><forenames>XuanLong</forenames></author><author><keyname>Ergen</keyname><forenames>Sinem Coleri</forenames></author><author><keyname>Varaiya</keyname><forenames>Pravin</forenames></author></authors><title>Simultaneous Sequential Detection of Multiple Interacting Faults</title><categories>cs.IT cs.SY math.IT math.ST stat.TH</categories><comments>38 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single fault sequential change point problems have become important in
modeling for various phenomena in large distributed systems, such as sensor
networks. But such systems in many situations present multiple interacting
faults. For example, individual sensors in a network may fail and detection is
performed by comparing measurements between sensors, resulting in statistical
dependency among faults. We present a new formulation for multiple interacting
faults in a distributed system. The formulation includes specifications of how
individual subsystems composing the large system may fail, the information that
can be shared among these subsystems and the interaction pattern between
faults. We then specify a new sequential algorithm for detecting these faults.
The main feature of the algorithm is that it uses composite stopping rules for
a subsystem that depend on the decision of other subsystems. We provide
asymptotic false alarm and detection delay analysis for this algorithm in the
Bayesian setting and show that under certain conditions the algorithm is
optimal. The analysis methodology relies on novel detailed comparison
techniques between stopping times. We validate the approach with some
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1269</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1269</id><created>2010-12-06</created><authors><author><keyname>Havemann</keyname><forenames>Frank</forenames></author><author><keyname>Heinz</keyname><forenames>Michael</forenames></author><author><keyname>Struck</keyname><forenames>Alexander</forenames></author><author><keyname>Gl&#xe4;ser</keyname><forenames>Jochen</forenames></author></authors><title>Identification of overlapping communities and their hierarchy by locally
  calculating community-changing resolution levels</title><categories>physics.data-an cs.SI physics.soc-ph</categories><comments>25 pages, 10 figures</comments><acm-class>H.2.8</acm-class><journal-ref>Journal of Statistical Mechanics: Theory and Experiment (2011)
  P01023</journal-ref><doi>10.1088/1742-5468/2011/01/P01023</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We propose a new local, deterministic and parameter-free algorithm that
detects fuzzy and crisp overlapping communities in a weighted network and
simultaneously reveals their hierarchy. Using a local fitness function, the
algorithm greedily expands natural communities of seeds until the whole graph
is covered. The hierarchy of communities is obtained analytically by
calculating resolution levels at which communities grow rather than numerically
by testing different resolution levels. This analytic procedure is not only
more exact than its numerical alternatives such as LFM and GCE but also much
faster. Critical resolution levels can be identified by searching for intervals
in which large changes of the resolution do not lead to growth of communities.
We tested our algorithm on benchmark graphs and on a network of 492 papers in
information science. Combined with a specific post-processing, the algorithm
gives much more precise results on LFR benchmarks with high overlap compared to
other algorithms and performs very similar to GCE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1272</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1272</id><created>2010-12-06</created><authors><author><keyname>Barra</keyname><forenames>Adriano</forenames></author><author><keyname>Agliari</keyname><forenames>Elena</forenames></author></authors><title>A statistical mechanics approach to Granovetter theory</title><categories>physics.soc-ph cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we try to bridge breakthroughs in quantitative
sociology/econometrics pioneered during the last decades by Mac Fadden,
Brock-Durlauf, Granovetter and Watts-Strogats through introducing a minimal
model able to reproduce essentially all the features of social behavior
highlighted by these authors. Our model relies on a pairwise Hamiltonian for
decision maker interactions which naturally extends the multi-populations
approaches by shifting and biasing the pattern definitions of an Hopfield model
of neural networks. Once introduced, the model is investigated trough graph
theory (to recover Granovetter and Watts-Strogats results) and statistical
mechanics (to recover Mac-Fadden and Brock-Durlauf results). Due to internal
symmetries of our model, the latter is obtained as the relaxation of a proper
Markov process, allowing even to study its out of equilibrium properties. The
method used to solve its equilibrium is an adaptation of the Hamilton-Jacobi
technique recently introduced by Guerra in the spin glass scenario and the
picture obtained is the following: just by assuming that the larger the amount
of similarities among decision makers, the stronger their relative influence,
this is enough to explain both the different role of strong and weak ties in
the social network as well as its small world properties. As a result,
imitative interaction strengths seem essentially a robust request (enough to
break the gauge symmetry in the couplings), furthermore, this naturally leads
to a discrete choice modelization when dealing with the external influences and
to imitative behavior a la Curie-Weiss as the one introduced by Brock and
Durlauf.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1283</identifier>
 <datestamp>2010-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1283</id><created>2010-12-03</created><authors><author><keyname>Shen</keyname><forenames>Alexander</forenames><affiliation>LIF</affiliation></author></authors><title>Decomposition Complexity</title><categories>cs.FL cs.CC cs.DM</categories><comments>Journ\'ees Automates Cellulaires 2010, Turku : Finland (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a problem of decomposition of a ternary function into a
composition of binary ones from the viewpoint of communication complexity and
algorithmic information theory as well as some applications to cellular
automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1288</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1288</id><created>2010-12-06</created><updated>2016-02-10</updated><authors><author><keyname>Kim</keyname><forenames>Dohan</forenames></author></authors><title>Representations of task assignments in distributed systems using Young
  tableaux and symmetric groups</title><categories>cs.DC math.GR</categories><comments>This is an Accepted Manuscript of an article published by Taylor &amp;
  Francis Group in International Journal of Parallel, Emergent and Distributed
  Systems on 02/02/2015, available online:
  http://dx.doi.org/10.1080/17445760.2014.997729</comments><journal-ref>International Journal of Parallel, Emergent and Distributed
  Systems 31 (2016): 152-175</journal-ref><doi>10.1080/17445760.2014.997729</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel approach to representing task assignments for
partitioned agents (respectively, tasks) in distributed systems. A partition of
agents (respectively, tasks) is represented by a Young tableau, which is one of
the main tools in studying symmetric groups and combinatorics. In this paper we
propose a task, agent, and assignment tableau in order to represent a task
assignment for partitioned agents (respectively, tasks) in a distributed
system. This paper is concerned with representations of task assignments rather
than finding approximate or near optimal solutions for task assignments. A
Young tableau approach allows us to raise the expressiveness of partitioned
agents (respectively, tasks) and their task assignments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1295</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1295</id><created>2010-12-06</created><authors><author><keyname>Govindasamy</keyname><forenames>Siddhartan</forenames></author><author><keyname>Bliss</keyname><forenames>Daniel W.</forenames></author></authors><title>On the Spectral Efficiency of Links with Multi-antenna Receivers in
  Non-homogenous Wireless Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An asymptotic technique is developed to find the
Signal-to-Interference-plus-Noise-Ratio (SINR) and spectral efficiency of a
link with N receiver antennas in wireless networks with non-homogeneous
distributions of nodes. It is found that with appropriate normalization, the
SINR and spectral efficiency converge with probability 1 to asymptotic limits
as N increases. This technique is applied to networks with power-law node
intensities, which includes homogeneous networks as a special case, to find a
simple approximation for the spectral efficiency. It is found that for
receivers in dense clusters, the SINR grows with N at rates higher than that of
homogeneous networks and that constant spectral efficiencies can be maintained
if the ratio of N to node density is constant. This result also enables the
analysis of a new scaling regime where the distribution of nodes in the network
flattens rather than increases uniformly. It is found that in many cases in
this regime, N needs to grow approximately exponentially to maintain a constant
spectral efficiency. In addition to strengthening previously known results for
homogeneous networks, these results provide insight into the benefit of using
antenna arrays in non-homogeneous wireless networks, for which few results are
available in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1329</identifier>
 <datestamp>2010-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1329</id><created>2010-12-03</created><authors><author><keyname>Bruno</keyname><forenames>Durand</forenames><affiliation>LIF</affiliation></author><author><keyname>Shen</keyname><forenames>Alexander</forenames><affiliation>LIF</affiliation></author><author><keyname>Romashchenko</keyname><forenames>Andrei</forenames><affiliation>LIF</affiliation></author></authors><title>1D Effectively Closed Subshifts and 2D Tilings</title><categories>cs.DM cs.FL</categories><comments>Journ\'ees Automates Cellulaires, Turku : Finland (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Michael Hochman showed that every 1D effectively closed subshift can be
simulated by a 3D subshift of finite type and asked whether the same can be
done in 2D. It turned out that the answer is positive and necessary tools were
already developed in tilings theory. We discuss two alternative approaches:
first, developed by N. Aubrun and M. Sablik, goes back to Leonid Levin; the
second one, developed by the authors, goes back to Peter Gacs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1330</identifier>
 <datestamp>2010-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1330</id><created>2010-12-03</created><authors><author><keyname>Jeandel</keyname><forenames>Emmanuel</forenames><affiliation>LIF</affiliation></author><author><keyname>Vanier</keyname><forenames>Pascal</forenames><affiliation>LIF</affiliation></author></authors><title>Slopes of Tilings</title><categories>cs.DM cs.CC cs.FL</categories><comments>Journ\'ees Automates Cellulaires 2010, Turku : Finland (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study here slopes of periodicity of tilings. A tiling is of slope if it is
periodic along direction but has no other direction of periodicity. We
characterize in this paper the set of slopes we can achieve with tilings, and
prove they coincide with recursively enumerable sets of rationals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1332</identifier>
 <datestamp>2010-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1332</id><created>2010-12-03</created><authors><author><keyname>Moreira</keyname><forenames>Andr&#xe9;s</forenames></author><author><keyname>Gajardo</keyname><forenames>Anahi</forenames></author></authors><title>Time-Symmetric Cellular Automata</title><categories>cs.DM cs.FL nlin.CG</categories><comments>Journ\'ees Automates Cellulaires 2010, Turku : Finland (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Together with the concept of reversibility, another relevant physical notion
is time-symmetry, which expresses that there is no way of distinguishing
between backward and forward time directions. This notion, found in physical
theories, has been neglected in the area of discrete dynamical systems. Here we
formalize it in the context of cellular automata and establish some basic facts
and relations. We also state some open problems that may encourage further
research on the topic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1333</identifier>
 <datestamp>2010-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1333</id><created>2010-12-03</created><authors><author><keyname>Boyer</keyname><forenames>Laurent</forenames><affiliation>LAMA</affiliation></author><author><keyname>Delacourt</keyname><forenames>Martin</forenames><affiliation>LIF</affiliation></author><author><keyname>Sablik</keyname><forenames>Mathieu</forenames><affiliation>LATP</affiliation></author></authors><title>Construction of $\mu$-Limit Sets</title><categories>cs.DM cs.FL nlin.CG</categories><comments>Journ\'ees Automates Cellulaires 2010, Turku : Finland (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The $\mu$-limit set of a cellular automaton is a subshift whose forbidden
patterns are exactly those, whose probabilities tend to zero as time tends to
in- finity. In this article, for a given subshift in a large class of
subshifts, we propose the construction of a cellular automaton which realizes
this subshift as $\mu$-limit set where $\mu$ is the uniform Bernoulli measure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1334</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1334</id><created>2010-12-03</created><authors><author><keyname>Arrighi</keyname><forenames>Pablo</forenames><affiliation>LIG</affiliation></author><author><keyname>Nesme</keyname><forenames>Vincent Fabrice</forenames></author></authors><title>The Block Neighborhood</title><categories>cs.DM cs.FL nlin.CG quant-ph</categories><comments>Journ\'ees Automates Cellulaires 2010, Turku : Finland (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define the block neighborhood of a reversible CA, which is related both to
its decomposition into a product of block permutations and to quantum
computing. We give a purely combinatorial characterization of the block
neighborhood, which helps in two ways. First, it makes the computation of the
block neighborhood of a given CA relatively easy. Second, it allows us to
derive upper bounds on the block neighborhood: for a single CA as function of
the classical and inverse neighborhoods, and for the composition of several
CAs. One consequence of that is a characterization of a class of &quot;elementary&quot;
CAs that cannot be written as the composition of two simpler parts whose
neighborhoods and inverse neighborhoods would be reduced by one half.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1336</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1336</id><created>2010-12-06</created><updated>2010-12-08</updated><authors><author><keyname>Kane</keyname><forenames>Daniel M.</forenames></author></authors><title>Unary Subset-Sum is in Logspace</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a simple Logspace algorithm that solves the Unary Subset-Sum
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1338</identifier>
 <datestamp>2010-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1338</id><created>2010-12-06</created><authors><author><keyname>Cantone</keyname><forenames>Domenico</forenames></author><author><keyname>Faro</keyname><forenames>Simone</forenames></author></authors><title>On Tuning the Bad-Character Rule: the Worst-Character Rule</title><categories>cs.DS</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we present the worst-character rule, an efficient variation of
the bad-character heuristic for the exact string matching problem, firstly
introduced in the well-known Boyer-Moore algorithm. Our proposed rule selects a
position relative to the current shift which yields the largest average
advancement, according to the characters distribution in the text. Experimental
results show that the worst-character rule achieves very good results
especially in the case of long patterns or small alphabets in random texts and
in the case of texts in natural languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1344</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1344</id><created>2010-12-06</created><updated>2013-01-16</updated><authors><author><keyname>Gruber</keyname><forenames>Hermann</forenames></author></authors><title>On Balanced Separators, Treewidth, and Cycle Rank</title><categories>cs.DM math.CO</categories><comments>Version 2: revised version, 8 pages</comments><msc-class>05C40, 05C35</msc-class><journal-ref>Journal of Combinatorics, 3(4):669-681, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate relations between different width parameters of graphs, in
particular balanced separator number, treewidth, and cycle rank. Our main
result states that a graph with balanced separator number k has treewidth at
least k but cycle rank at most k(1 + log (n/k)), thus refining the previously
known bounds, as stated by Robertson and Seymour (1986) and by Bodlaender et
al. (1995). Furthermore, we show that the improved bounds are best possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1358</identifier>
 <datestamp>2011-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1358</id><created>2010-12-06</created><updated>2010-12-10</updated><authors><author><keyname>Richters</keyname><forenames>Oliver</forenames></author><author><keyname>Peixoto</keyname><forenames>Tiago P.</forenames></author></authors><title>Trust transitivity in social networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>11 pages, 9 figures (with minor corrections)</comments><journal-ref>PLoS ONE 6(4): e18384 (2011)</journal-ref><doi>10.1371/journal.pone.0018384</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Non-centralized recommendation-based decision making is a central feature of
several social and technological processes, such as market dynamics,
peer-to-peer file-sharing and the web of trust of digital certification. We
investigate the properties of trust propagation on networks, based on a simple
metric of trust transitivity. We investigate analytically the percolation
properties of trust transitivity in random networks with arbitrary degree
distribution, and compare with numerical realizations. We find that the
existence of a non-zero fraction of absolute trust (i.e. entirely confident
trust) is a requirement for the viability of global trust propagation in large
systems: The average pair-wise trust is marked by a discontinuous transition at
a specific fraction of absolute trust, below which it vanishes. Furthermore, we
perform an extensive analysis of the Pretty Good Privacy (PGP) web of trust, in
view of the concepts introduced. We compare different scenarios of trust
distribution: community- and authority-centered. We find that these scenarios
lead to sharply different patterns of trust propagation, due to the segregation
of authority hubs and densely-connected communities. While the
authority-centered scenario is more efficient, and leads to higher average
trust values, it favours weakly-connected &quot;fringe&quot; nodes, which are directly
trusted by authorities. The community-centered scheme, on the other hand,
favours nodes with intermediate degrees, in detriment of the authorities and
its &quot;fringe&quot; peers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1367</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1367</id><created>2010-12-06</created><updated>2012-01-31</updated><authors><author><keyname>Dekel</keyname><forenames>Ofer</forenames></author><author><keyname>Gilad-Bachrach</keyname><forenames>Ran</forenames></author><author><keyname>Shamir</keyname><forenames>Ohad</forenames></author><author><keyname>Xiao</keyname><forenames>Lin</forenames></author></authors><title>Optimal Distributed Online Prediction using Mini-Batches</title><categories>cs.LG cs.DC math.OC</categories><comments>Final version of paper to appear in Journal of Machine Learning
  Research (JMLR)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online prediction methods are typically presented as serial algorithms
running on a single processor. However, in the age of web-scale prediction
problems, it is increasingly common to encounter situations where a single
processor cannot keep up with the high rate at which inputs arrive. In this
work, we present the \emph{distributed mini-batch} algorithm, a method of
converting many serial gradient-based online prediction algorithms into
distributed algorithms. We prove a regret bound for this method that is
asymptotically optimal for smooth convex loss functions and stochastic inputs.
Moreover, our analysis explicitly takes into account communication latencies
between nodes in the distributed environment. We show how our method can be
used to solve the closely-related distributed stochastic optimization problem,
achieving an asymptotically linear speed-up over multiple processors. Finally,
we demonstrate the merits of our approach on a web-scale online prediction
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1370</identifier>
 <datestamp>2010-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1370</id><created>2010-12-06</created><authors><author><keyname>Dekel</keyname><forenames>Ofer</forenames></author><author><keyname>Gilad-Bachrach</keyname><forenames>Ran</forenames></author><author><keyname>Shamir</keyname><forenames>Ohad</forenames></author><author><keyname>Xiao</keyname><forenames>Lin</forenames></author></authors><title>Robust Distributed Online Prediction</title><categories>cs.LG math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The standard model of online prediction deals with serial processing of
inputs by a single processor. However, in large-scale online prediction
problems, where inputs arrive at a high rate, an increasingly common necessity
is to distribute the computation across several processors. A non-trivial
challenge is to design distributed algorithms for online prediction, which
maintain good regret guarantees. In \cite{DMB}, we presented the DMB algorithm,
which is a generic framework to convert any serial gradient-based online
prediction algorithm into a distributed algorithm. Moreover, its regret
guarantee is asymptotically optimal for smooth convex loss functions and
stochastic inputs. On the flip side, it is fragile to many types of failures
that are common in distributed environments. In this companion paper, we
present variants of the DMB algorithm, which are resilient to many types of
network failures, and tolerant to varying performance of the computing nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1375</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1375</id><created>2010-12-06</created><updated>2011-01-13</updated><authors><author><keyname>Abrams</keyname><forenames>Daniel M.</forenames></author><author><keyname>Yaple</keyname><forenames>Haley A.</forenames></author><author><keyname>Wiener</keyname><forenames>Richard J.</forenames></author></authors><title>A mathematical model of social group competition with application to the
  growth of religious non-affiliation</title><categories>physics.soc-ph cs.SI math.DS nlin.AO</categories><comments>5 pages, 4 figures (with 6 pages and 7 figures of supplementary
  material)</comments><msc-class>91D10, 91D30</msc-class><journal-ref>Phys. Rev. Lett. 107, 088701 (2011)</journal-ref><doi>10.1103/PhysRevLett.107.088701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When groups compete for members, the resulting dynamics of human social
activity may be understandable with simple mathematical models. Here, we apply
techniques from dynamical systems and perturbation theory to analyze a
theoretical framework for the growth and decline of competing social groups. We
present a new treatment of the competition for adherents between religious and
irreligious segments of modern secular societies and compile a new
international data set tracking the growth of religious non-affiliation. Data
suggest a particular case of our general growth law, leading to clear
predictions about possible future trends in society.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1403</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1403</id><created>2010-12-07</created><updated>2011-09-26</updated><authors><author><keyname>Du</keyname><forenames>Fanping</forenames></author></authors><title>Negative frequency communication</title><categories>cs.IT math.IT physics.pop-ph</categories><comments>21 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum is the most valuable resource in communication system, but
unfortunately, so far, a half of the spectrum has been wasted. In this paper,
we will see that the negative frequency not only has a physical meaning but
also can be used in communication. In fact, the complete description of a
frequency signal is a rotating complex-frequency signal, in a complete
description, positive and negative frequency signals are two distinguishable
and independent frequency signals, they can carry different information. But
the current carrier modulation and demodulation do not distinguish positive and
negative frequencies, so half of the spectrum resources and signal energy are
wasted. The complex-carrier modulation and demodulation, proposed by this
paper, use the complex-frequency signal as a carrier signal, the negative and
positive frequency can carry different information, so the spectrum resources
are fully used, the signal energy carried by complex-carrier modulation is
focused on a certain band, so the signal energy will not be lost by the
complex-carrier demodulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1425</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1425</id><created>2010-12-07</created><authors><author><keyname>Burshtein</keyname><forenames>David</forenames></author><author><keyname>Goldenberg</keyname><forenames>Idan</forenames></author></authors><title>Improved linear programming decoding of LDPC codes and bounds on the
  minimum and fractional distance</title><categories>cs.IT math.IT</categories><comments>17 pages, 8 figures, Submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine LDPC codes decoded using linear programming (LP). Four
contributions to the LP framework are presented. First, a new method of
tightening the LP relaxation, and thus improving the LP decoder, is proposed.
Second, we present an algorithm which calculates a lower bound on the minimum
distance of a specific code. This algorithm exhibits complexity which scales
quadratically with the block length. Third, we propose a method to obtain a
tight lower bound on the fractional distance, also with quadratic complexity,
and thus less than previously-existing methods. Finally, we show how the
fundamental LP polytope for generalized LDPC codes and nonbinary LDPC codes can
be obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1501</identifier>
 <datestamp>2011-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1501</id><created>2010-12-07</created><updated>2011-06-10</updated><authors><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>LIENS, INRIA Paris - Rocquencourt</affiliation></author></authors><title>Shaping Level Sets with Submodular Functions</title><categories>cs.LG stat.ML</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a class of sparsity-inducing regularization terms based on
submodular functions. While previous work has focused on non-decreasing
functions, we explore symmetric submodular functions and their \lova
extensions. We show that the Lovasz extension may be seen as the convex
envelope of a function that depends on level sets (i.e., the set of indices
whose corresponding components of the underlying predictor are greater than a
given constant): this leads to a class of convex structured regularization
terms that impose prior knowledge on the level sets, and not only on the
supports of the underlying predictors. We provide a unified set of optimization
algorithms, such as proximal operators, and theoretical guarantees (allowed
level sets and recovery conditions). By selecting specific submodular
functions, we give a new interpretation to known norms, such as the total
variation; we also define new norms, in particular ones that are based on order
statistics with application to clustering and outlier detection, and on noisy
cuts in graphs with application to change point detection in the presence of
outliers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1502</identifier>
 <datestamp>2010-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1502</id><created>2010-12-07</created><authors><author><keyname>Abu-Affash</keyname><forenames>A. Karim</forenames></author></authors><title>An Approximation Algorithm for the Euclidean Bottleneck Steiner Tree
  Problem</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given two sets of points in the plane, $P$ of $n$ terminals and $S$ of $m$
Steiner points, a Steiner tree of $P$ is a tree spanning all points of $P$ and
some (or none or all) points of $S$. A Steiner tree with length of longest edge
minimized is called a bottleneck Steiner tree. In this paper, we study the
Euclidean bottleneck Steiner tree problem: given two sets, $P$ and $S$, and a
positive integer $k \le m$, find a bottleneck Steiner tree of $P$ with at most
$k$ Steiner points. The problem has application in the design of wireless
communication networks.
  We first show that the problem is NP-hard and cannot be approximated within
factor $\sqrt{2}$, unless $P=NP$. Then, we present a polynomial-time
approximation algorithm with performance ratio 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1529</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1529</id><created>2010-12-07</created><updated>2013-01-05</updated><authors><author><keyname>Cicalese</keyname><forenames>Ferdinando</forenames></author><author><keyname>Milanic</keyname><forenames>Martin</forenames></author><author><keyname>Vaccaro</keyname><forenames>Ugo</forenames></author></authors><title>On the approximability and exact algorithms for vector domination and
  related problems in graphs</title><categories>cs.DM cs.DS math.CO</categories><comments>In the version published in DAM, weaker lower bounds for vector
  domination and total vector domination were stated. Being these problems
  generalization of domination and total domination, the lower bounds of 0.2267
  ln n and (1-epsilon) ln n clearly hold for both problems, unless P = NP or NP
  \subseteq DTIME(n^{O(log log n)}), respectively. The claims are corrected in
  the present version</comments><msc-class>68Q17, 68Q25, 68W25</msc-class><acm-class>F.2.2; G.2.2</acm-class><journal-ref>Discrete Applied Mathematics 2012 (online)</journal-ref><doi>10.1016/j.dam.2012.10.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two graph optimization problems called vector domination and
total vector domination. In vector domination one seeks a small subset S of
vertices of a graph such that any vertex outside S has a prescribed number of
neighbors in S. In total vector domination, the requirement is extended to all
vertices of the graph. We prove that these problems (and several variants
thereof) cannot be approximated to within a factor of clnn, where c is a
suitable constant and n is the number of the vertices, unless P = NP. We also
show that two natural greedy strategies have approximation factors ln D+O(1),
where D is the maximum degree of the input graph. We also provide exact
polynomial time algorithms for several classes of graphs. Our results extend,
improve, and unify several results previously known in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1531</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1531</id><created>2010-12-07</created><authors><author><keyname>Bartholdi</keyname><forenames>Laurent</forenames></author><author><keyname>Silva</keyname><forenames>Pedro V.</forenames></author></authors><title>Groups defined by automata</title><categories>cs.FL cs.DM math.GR</categories><comments>Chapter 24 in the handbook &quot;AutoMathA&quot;. With index</comments><msc-class>20F65, 20E08, 20F10, 20F67, 68Q45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is Chapter 24 in the &quot;AutoMathA&quot; handbook. Finite automata have been
used effectively in recent years to define infinite groups. The two main lines
of research have as their most representative objects the class of automatic
groups (including word-hyperbolic groups as a particular case) and automata
groups (singled out among the more general self-similar groups).
  The first approach implements in the language of automata some tight
constraints on the geometry of the group's Cayley graph, building strange,
beautiful bridges between far-off domains. Automata are used to define a normal
form for group elements, and to monitor the fundamental group operations.
  The second approach features groups acting in a finitely constrained manner
on a regular rooted tree. Automata define sequential permutations of the tree,
and represent the group elements themselves. The choice of particular classes
of automata has often provided groups with exotic behaviour which have
revolutioned our perception of infinite finitely generated groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1532</identifier>
 <datestamp>2010-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1532</id><created>2010-12-07</created><authors><author><keyname>Bartholdi</keyname><forenames>Laurent</forenames></author><author><keyname>Silva</keyname><forenames>Pedro V.</forenames></author></authors><title>Rational subsets of groups</title><categories>cs.FL cs.DM math.GR</categories><comments>Chapter 23 of the handbook &quot;AutoMathA&quot;. With index</comments><msc-class>20F10, 20E05, 68Q45, 68Q70</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This text, Chapter 23 in the &quot;AutoMathA&quot; handbook, is devoted to the study of
rational subsets of groups, with particular emphasis on the automata-theoretic
approach to finitely generated subgroups of free groups. Indeed, Stallings'
construction, associating a finite inverse automaton with every such subgroup,
inaugurated a complete rewriting of free group algorithmics, with connections
to other fields such as topology or dynamics.
  Another important vector in the chapter is the fundamental Benois' Theorem,
characterizing rational subsets of free groups. The theorem and its
consequences really explain why language theory can be successfully applied to
the study of free groups. Rational subsets of (free) groups can play a major
role in proving statements (a priori unrelated to the notion of rationality) by
induction. The chapter also includes related results for more general classes
of groups, such as virtually free groups or graph groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1539</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1539</id><created>2010-12-07</created><updated>2011-04-12</updated><authors><author><keyname>Zhang</keyname><forenames>Wenyi</forenames></author></authors><title>A General Framework for Transmission with Transceiver Distortion and
  Some Applications</title><categories>cs.IT math.IT</categories><comments>32 pages (including 4 figures, 5 tables, and auxiliary materials);
  submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general theoretical framework is presented for analyzing information
transmission over Gaussian channels with memoryless transceiver distortion,
which encompasses various nonlinear distortion models including transmit-side
clipping, receive-side analog-to-digital conversion, and others. The framework
is based on the so-called generalized mutual information (GMI), and the
analysis in particular benefits from the setup of Gaussian codebook ensemble
and nearest-neighbor decoding, for which it is established that the GMI takes a
general form analogous to the channel capacity of undistorted Gaussian
channels, with a reduced &quot;effective&quot; signal-to-noise ratio (SNR) that depends
on the nominal SNR and the distortion model. When applied to specific
distortion models, an array of results of engineering relevance is obtained.
For channels with transmit-side distortion only, it is shown that a
conventional approach, which treats the distorted signal as the sum of the
original signal part and a uncorrelated distortion part, achieves the GMI. For
channels with output quantization, closed-form expressions are obtained for the
effective SNR and the GMI, and related optimization problems are formulated and
solved for quantizer design. Finally, super-Nyquist sampling is analyzed within
the general framework, and it is shown that sampling beyond the Nyquist rate
increases the GMI for all SNR. For example, with a binary symmetric output
quantization, information rates exceeding one bit per channel use are
achievable by sampling the output at four times the Nyquist rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1547</identifier>
 <datestamp>2010-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1547</id><created>2010-12-07</created><authors><author><keyname>Hoefer</keyname><forenames>Martin</forenames></author><author><keyname>Penn</keyname><forenames>Michal</forenames></author><author><keyname>Polukarov</keyname><forenames>Maria</forenames></author><author><keyname>Skopalik</keyname><forenames>Alexander</forenames></author><author><keyname>V&#xf6;cking</keyname><forenames>Berhold</forenames></author></authors><title>Considerate Equilibrium</title><categories>cs.GT cs.DS cs.MA</categories><comments>12 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the existence and computational complexity of coalitional
stability concepts based on social networks. Our concepts represent a natural
and rich combinatorial generalization of a recent approach termed partition
equilibrium. We assume that players in a strategic game are embedded in a
social network, and there are coordination constraints that restrict the
potential coalitions that can jointly deviate in the game to the set of cliques
in the social network. In addition, players act in a &quot;considerate&quot; fashion to
ignore potentially profitable (group) deviations if the change in their
strategy may cause a decrease of utility to their neighbors.
  We study the properties of such considerate equilibria in application to the
class of resource selection games (RSG). Our main result proves existence of a
considerate equilibrium in all symmetric RSG with strictly increasing delays,
for any social network among the players. The existence proof is constructive
and yields an efficient algorithm. In fact, the computed considerate
equilibrium is a Nash equilibrium for the standard RSG showing that there
exists a state that is stable against selfish and considerate behavior
simultaneously. In addition, we show results on convergence of considerate
dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1552</identifier>
 <datestamp>2010-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1552</id><created>2010-12-07</created><authors><author><keyname>Saad</keyname><forenames>Emad</forenames></author></authors><title>Bridging the Gap between Reinforcement Learning and Knowledge
  Representation: A Logical Off- and On-Policy Framework</title><categories>cs.AI cs.LG cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowledge Representation is important issue in reinforcement learning. In
this paper, we bridge the gap between reinforcement learning and knowledge
representation, by providing a rich knowledge representation framework, based
on normal logic programs with answer set semantics, that is capable of solving
model-free reinforcement learning problems for more complex do-mains and
exploits the domain-specific knowledge. We prove the correctness of our
approach. We show that the complexity of finding an offline and online policy
for a model-free reinforcement learning problem in our approach is NP-complete.
Moreover, we show that any model-free reinforcement learning problem in MDP
environment can be encoded as a SAT problem. The importance of that is
model-free reinforcement
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1565</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1565</id><created>2010-12-07</created><updated>2010-12-20</updated><authors><author><keyname>oueslati</keyname><forenames>wided</forenames></author><author><keyname>akaichi</keyname><forenames>jalel</forenames></author></authors><title>A Survey on Data Warehouse Evolution</title><categories>cs.DB</categories><comments>14 pages</comments><journal-ref>International Journal of Database Management Systems ( IJDMS ),
  Vol.2, No.4, November 2010 pages 11-24</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The data warehouse (DW) technology was developed to integrate heterogeneous
information sources for analysis purposes. Information sources are more and
more autonomous and they often change their content due to perpetual
transactions (data changes) and may change their structure due to continual
users' requirements evolving (schema changes). Handling properly all type of
changes is a must. In fact, the DW which is considered as the core component of
the modern decision support systems has to be update according to different
type of evolution of information sources to reflect the real world subject to
analysis. The goal of this paper is to propose an overview and a comparative
study between different works related to the DW evolution problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1573</identifier>
 <datestamp>2014-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1573</id><created>2010-12-07</created><updated>2013-07-05</updated><authors><author><keyname>Foniok</keyname><forenames>Jan</forenames></author><author><keyname>G&#xe4;rtner</keyname><forenames>Bernd</forenames></author><author><keyname>Klaus</keyname><forenames>Lorenz</forenames></author><author><keyname>Sprecher</keyname><forenames>Markus</forenames></author></authors><title>Counting Unique-Sink Orientations</title><categories>math.CO cs.DM</categories><comments>13 pages; v2: proof of main theorem expanded, plus various other
  corrections. Now 16 pages; v3: minor corrections</comments><msc-class>90C33, 52B12, 05A16</msc-class><journal-ref>Discrete Appl. Math., 163/2, pp. 155-164, 2014</journal-ref><doi>10.1016/j.dam.2013.07.017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unique-sink orientations (USOs) are an abstract class of orientations of the
n-cube graph. We consider some classes of USOs that are of interest in
connection with the linear complementarity problem. We summarise old and show
new lower and upper bounds on the sizes of some such classes. Furthermore, we
provide a characterisation of K-matrices in terms of their corresponding USOs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1577</identifier>
 <datestamp>2014-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1577</id><created>2010-12-07</created><updated>2014-02-05</updated><authors><author><keyname>Kane</keyname><forenames>Daniel M.</forenames></author><author><keyname>Nelson</keyname><forenames>Jelani</forenames></author></authors><title>Sparser Johnson-Lindenstrauss Transforms</title><categories>cs.DS cs.CG cs.DM cs.IT math.IT math.PR</categories><comments>v6: journal version, minor changes, added Remark 23; v5: modified
  abstract, fixed typos, added open problem section; v4: simplified section 4
  by giving 1 analysis that covers both constructions; v3: proof of Theorem 25
  in v2 was written incorrectly, now fixed; v2: Added another construction
  achieving same upper bound, and added proof of near-tight lower bound for DKS
  scheme</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give two different and simple constructions for dimensionality reduction
in $\ell_2$ via linear mappings that are sparse: only an
$O(\varepsilon)$-fraction of entries in each column of our embedding matrices
are non-zero to achieve distortion $1+\varepsilon$ with high probability, while
still achieving the asymptotically optimal number of rows. These are the first
constructions to provide subconstant sparsity for all values of parameters,
improving upon previous works of Achlioptas (JCSS 2003) and Dasgupta, Kumar,
and Sarl\'{o}s (STOC 2010). Such distributions can be used to speed up
applications where $\ell_2$ dimensionality reduction is used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1581</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1581</id><created>2010-12-07</created><updated>2011-02-08</updated><authors><author><keyname>Scheidler</keyname><forenames>Alexander</forenames></author></authors><title>Dynamics of Majority Rule with Differential Latencies</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>4 pages, 5 figures</comments><report-no>TR/IRIDIA/2010-027</report-no><journal-ref>Phys. Rev. E 83, 031116 (2011)</journal-ref><doi>10.1103/PhysRevE.83.031116</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the dynamics of the majority-rule opinion formation model when
voters experience differential latencies. With this extension, voters that just
adopted an opinion go into a latent state during which they are excluded from
the opinion formation process. The duration of the latent state depends on the
opinion adopted by the voter. The net result is a bias towards consensus on the
opinion that is associated with the shorter latency. We determine the exit
probability and time to consensus for systems of $N$ voters. Additionally, we
derive an asymptotic characterisation of the time to consensus by means of a
continuum model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1609</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1609</id><created>2010-12-07</created><authors><author><keyname>Berlanga</keyname><forenames>R.</forenames></author><author><keyname>Jimenez-Ruiz</keyname><forenames>E.</forenames></author><author><keyname>Nebot</keyname><forenames>V.</forenames></author></authors><title>Building conceptual spaces for exploring and linking biomedical
  resources</title><categories>cs.IR</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The establishment of links between data (e.g., patient records) and Web
resources (e.g., literature) and the proper visualization of such discovered
knowledge is still a challenge in most Life Science domains (e.g.,
biomedicine). In this paper we present our contribution to the community in the
form of an infrastructure to annotate information resources, to discover
relationships among them, and to represent and visualize the new discovered
knowledge. Furthermore, we have also implemented a Web-based prototype tool
which integrates the proposed infrastructure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1614</identifier>
 <datestamp>2011-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1614</id><created>2010-12-07</created><updated>2011-11-10</updated><authors><author><keyname>Kane</keyname><forenames>Daniel M.</forenames></author></authors><title>$k$-Independent Gaussians Fool Polynomial Threshold Functions</title><categories>cs.CC math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that any $O_d(\epsilon^{-4d 7^d})$-independent family of Gaussians
$\epsilon$-fools any degree-$d$ polynomial threshold function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1615</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1615</id><created>2010-12-07</created><authors><author><keyname>McLeod</keyname><forenames>Kenneth</forenames></author><author><keyname>Ferguson</keyname><forenames>Gus</forenames></author><author><keyname>Burger</keyname><forenames>Albert</forenames></author></authors><title>Argudas: arguing with gene expression information</title><categories>cs.CE cs.AI</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In situ hybridisation gene expression information helps biologists identify
where a gene is expressed. However, the databases that republish the
experimental information are often both incomplete and inconsistent. This paper
examines a system, Argudas, designed to help tackle these issues. Argudas is an
evolution of an existing system, and so that system is reviewed as a means of
both explaining and justifying the behaviour of Argudas. Throughout the
discussion of Argudas a number of issues will be raised including the
appropriateness of argumentation in biology and the challenges faced when
integrating apparently similar online biological databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1617</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1617</id><created>2010-12-07</created><authors><author><keyname>Ranwez</keyname><forenames>Sylvie</forenames></author><author><keyname>Ranwez</keyname><forenames>Vincent</forenames></author><author><keyname>Sy</keyname><forenames>Mohameth-Fran&#xe7;ois</forenames></author><author><keyname>Montmain</keyname><forenames>Jacky</forenames></author><author><keyname>Crampes</keyname><forenames>Michel</forenames></author></authors><title>User Centered and Ontology Based Information Retrieval System for Life
  Sciences</title><categories>cs.IR</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Because of the increasing number of electronic data, designing efficient
tools to retrieve and exploit documents is a major challenge. Current search
engines suffer from two main drawbacks: there is limited interaction with the
list of retrieved documents and no explanation for their adequacy to the query.
Users may thus be confused by the selection and have no idea how to adapt their
query so that the results match their expectations. This paper describes a
request method and an environment based on aggregating models to assess the
relevance of documents annotated by concepts of ontology. The selection of
documents is then displayed in a semantic map to provide graphical indications
that make explicit to what extent they match the user's query; this man/machine
interface favors a more interactive exploration of data corpus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1619</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1619</id><created>2010-12-07</created><authors><author><keyname>Lopez-Garcia</keyname><forenames>Pablo</forenames></author></authors><title>Are SNOMED CT Browsers Ready for Institutions? Introducing MySNOM</title><categories>cs.AI</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  SNOMED Clinical Terms (SNOMED CT) is one of the most widespread ontologies in
the life sciences, with more than 300,000 concepts and relationships, but is
distributed with no associated software tools. In this paper we present MySNOM,
a web-based SNOMED CT browser. MySNOM allows organizations to browse their own
distribution of SNOMED CT under a controlled environment, focuses on navigating
using the structure of SNOMED CT, and has diagramming capabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1620</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1620</id><created>2010-12-07</created><authors><author><keyname>R&#xfc;ther</keyname><forenames>Maria</forenames></author><author><keyname>Bandholtz</keyname><forenames>Thomas</forenames></author><author><keyname>Logean</keyname><forenames>Antoine</forenames></author></authors><title>Linked Environment Data for the Life Sciences</title><categories>cs.OH q-bio.OT</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Environment Agencies from Europe and the US are setting up a network of
Linked Environment Data and are looking to crosslink it with Linked Data
contributions from the life sciences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1621</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1621</id><created>2010-12-07</created><authors><author><keyname>Briache</keyname><forenames>Abdelaali</forenames></author><author><keyname>Marrakchi</keyname><forenames>Kamar</forenames></author><author><keyname>Kerzazi</keyname><forenames>Amine</forenames></author><author><keyname>Navas-Delgado</keyname><forenames>Ismael</forenames></author><author><keyname>Montes</keyname><forenames>Jose F Aldana</forenames></author><author><keyname>Hassani</keyname><forenames>Badr D. Rossi</forenames></author><author><keyname>Lairini</keyname><forenames>Khalid</forenames></author></authors><title>YeastMed: an XML-Based System for Biological Data Integration of Yeast</title><categories>cs.DB</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A key goal of bioinformatics is to create database systems and software
platforms capable of storing and analysing large sets of biological data.
Hundreds of biological databases are now available and provide access to huge
amount of biological data. SGD, Yeastract, CYGD-MIPS, BioGrid and PhosphoGrid
are five of the most visited databases by the yeast community. These sources
provide complementary data on biological entities. Biologists are brought
systematically to query these data sources in order to analyse the results of
their experiments. Because of the heterogeneity of these sources, querying them
separately and then manually combining the returned result is a complex and
laborious task. To provide transparent and simultaneous access to these
sources, we have developed a mediator-based system called YeastMed. In this
paper, we present YeastMed focusing on its architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1623</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1623</id><created>2010-12-07</created><authors><author><keyname>Dalamagas</keyname><forenames>Theodore</forenames></author><author><keyname>Farmakakis</keyname><forenames>Tryfon</forenames></author><author><keyname>Maragkakis</keyname><forenames>Manolis</forenames></author><author><keyname>Hatzigeorgiou</keyname><forenames>Artemis</forenames></author></authors><title>FreePub: Collecting and Organizing Scientific Material Using Mindmaps</title><categories>cs.HC</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a creativity support tool, called FreePub, to collect and
organize scienti?c material using mindmaps. Mindmaps are visual, graph-based
represenations of concepts, ideas, notes, tasks, etc. They generally take a
hierarchical or tree branch format, with ideas branching into their
subsections. FreePub supports creativity cycles. A user starts such a cycle by
setting up her domain of interest using mindmaps. Then, she can browse mindmaps
and launch search tasks to gather relevant publications from several data
sources. FreePub, besides publications, identi?es helpful supporting material
(e.g., blog posts, presentations). All retrieved information from FreePub can
be imported and organized in mindmaps. FreePub has been fully implemented on
top of FreeMind, a popular open-source, mindmapping tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1632</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1632</id><created>2010-12-07</created><authors><author><keyname>Mironov</keyname><forenames>Vladimir</forenames></author><author><keyname>Seethappan</keyname><forenames>Nirmala</forenames></author><author><keyname>Blonde</keyname><forenames>Ward</forenames></author><author><keyname>Antezana</keyname><forenames>Erick</forenames></author><author><keyname>Lindi</keyname><forenames>Bjorn</forenames></author><author><keyname>Kuiper</keyname><forenames>Martin</forenames></author></authors><title>Benchmarking triple stores with biological data</title><categories>cs.DB</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have compared the performance of five non-commercial triple stores,
Virtuoso-open source, Jena SDB, Jena TDB, SWIFT-OWLIM and 4Store. We examined
three performance aspects: the query execution time, scalability and run-to-run
reproducibility. The queries we chose addressed different ontological or
biological topics, and we obtained evidence that individual store performance
was quite query specific. We identified three groups of queries displaying
similar behavior across the different stores: 1) relatively short response
time, 2) moderate response time and 3) relatively long response time. OWLIM
proved to be a winner in the first group, 4Store in the second and Virtuoso in
the third. Our benchmarking showed Virtuoso to be a very balanced performer -
its response time was better than average for all the 24 queries; it showed a
very good scalability and a reasonable run-to-run reproducibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1635</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1635</id><created>2010-12-07</created><authors><author><keyname>Tan</keyname><forenames>He</forenames></author></authors><title>A study on the relation between linguistics-oriented and domain-specific
  semantics</title><categories>cs.AI</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we dealt with the comparison and linking between lexical
resources with domain knowledge provided by ontologies. It is one of the issues
for the combination of the Semantic Web Ontologies and Text Mining. We
investigated the relations between the linguistics oriented and domain-specific
semantics, by associating the GO biological process concepts to the FrameNet
semantic frames. The result shows the gaps between the linguistics-oriented and
domain-specific semantics on the classification of events and the grouping of
target words. The result provides valuable information for the improvement of
domain ontologies supporting for text mining systems. And also, it will result
in benefits to language understanding technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1636</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1636</id><created>2010-12-07</created><authors><author><keyname>Huerga</keyname><forenames>Iker</forenames></author><author><keyname>Serna</keyname><forenames>Ainhoa</forenames></author><author><keyname>Gerrikagoitia</keyname><forenames>Jon Kepa</forenames></author></authors><title>Fundamentals of Semantic Web Technologies in Medical Environments: a
  case in breast cancer risk estimation</title><categories>cs.OH</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Risk estimation of developing breast cancer poses as the first prevention
method for early diagnosis. Furthermore, data integration from different
departments involved in the process plays a key role. In order to guarantee
patient safety, the whole process should be orchestrated and monitored
automatically. Support for the solution will be a linked data cloud, composed
by all the departments that take part in the process, combined with rule
engines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1638</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1638</id><created>2010-12-07</created><authors><author><keyname>Almeida</keyname><forenames>Pedro</forenames></author><author><keyname>Gomes</keyname><forenames>Paulo</forenames></author><author><keyname>Sales</keyname><forenames>Francisco</forenames></author><author><keyname>Nogueira</keyname><forenames>Ana</forenames></author><author><keyname>Dourado</keyname><forenames>Ant&#xf3;nio</forenames></author></authors><title>Ontology and Knowledge Management System on Epilepsy and Epileptic
  Seizures</title><categories>cs.DL</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Knowledge Management System developed for supporting creation, capture,
storage and dissemination of information about Epilepsy and Epileptic Seizures
is presented. We present an Ontology on Epilepsy and a Web-based prototype that
together create the KMS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1640</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1640</id><created>2010-12-07</created><authors><author><keyname>Lamprecht</keyname><forenames>Anna-Lena</forenames></author><author><keyname>Naujokat</keyname><forenames>Stefan</forenames></author><author><keyname>Steffen</keyname><forenames>Bernhard</forenames></author><author><keyname>Margaria</keyname><forenames>Tiziana</forenames></author></authors><title>Constraint-Guided Workflow Composition Based on the EDAM Ontology</title><categories>cs.SE</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Methods for the automatic composition of services into executable workflows
need detailed knowledge about the application domain,in particular about the
available services and their behavior in terms of input/output data
descriptions. In this paper we discuss how the EMBRACE data and methods
ontology (EDAM) can be used as background knowledge for the composition of
bioinformatics workflows. We show by means of a small example domain that the
EDAM knowledge facilitates finding possible workflows, but that additional
knowledge is required to guide the search towards actually adequate solutions.
We illustrate how the ability to flexibly formulate domain-specific and
problem-specific constraints supports the work ow development process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1641</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1641</id><created>2010-12-07</created><authors><author><keyname>Wang</keyname><forenames>Yibing</forenames></author></authors><title>A Generalized Streaming Model for Concurrent Computing</title><categories>cs.PL cs.DC</categories><comments>12 pages, 7 figures. unpublished draft for a high-level discussion of
  an abstract, parallel computing model</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Multicore parallel programming has some very difficult problems such as
deadlocks during synchronizations and race conditions brought by concurrency.
Added to the difficulty is the lack of a simple, well-accepted computing model
for multicore architectures--because of that it is hard to develop powerful
programming environments and debugging tools. To tackle the challenges, we
promote a generalized stream computing model, inspired by previous researches
on stream computing, that unifies parallelization strategies for programming
language design, compiler design and operating system design. Our model
provides a high-level abstraction in designing language constructs to convey
concepts of concurrent operations, in organizing a program's runtime layout for
parallel execution, and in scheduling concurrent instruction blocks through
runtime and/or operating systems. In this paper, we give a high-level
description of the proposed model: we define the foundation of the model, show
its simplicity through algebraic/computational operation analysis, illustrate a
programming framework enabled by the model, and demonstrate its potential
through powerful design options for programming languages, compilers and
operating systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1643</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1643</id><created>2010-12-07</created><authors><author><keyname>Paschke</keyname><forenames>Adrian</forenames></author><author><keyname>Zhao</keyname><forenames>Zhili</forenames></author></authors><title>Process Makna - A Semantic Wiki for Scientific Workflows</title><categories>cs.AI</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Virtual e-Science infrastructures supporting Web-based scientific workflows
are an example for knowledge-intensive collaborative and weakly-structured
processes where the interaction with the human scientists during process
execution plays a central role. In this paper we propose the lightweight
dynamic user-friendly interaction with humans during execution of scientific
workflows via the low-barrier approach of Semantic Wikis as an intuitive
interface for non-technical scientists. Our Process Makna Semantic Wiki system
is a novel combination of an business process management system adapted for
scientific workflows with a Corporate Semantic Web Wiki user interface
supporting knowledge intensive human interaction tasks during scientific
workflow execution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1645</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1645</id><created>2010-12-07</created><authors><author><keyname>Todor</keyname><forenames>Alexandru</forenames></author><author><keyname>Paschke</keyname><forenames>Adrian</forenames></author><author><keyname>Heineke</keyname><forenames>Stephan</forenames></author></authors><title>ChemCloud: Chemical e-Science Information Cloud</title><categories>cs.DB</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our Chemical e-Science Information Cloud (ChemCloud) - a Semantic Web based
eScience infrastructure - integrates and automates a multitude of databases,
tools and services in the domain of chemistry, pharmacy and bio-chemistry
available at the Fachinformationszentrum Chemie (FIZ Chemie), at the Freie
Universitaet Berlin (FUB), and on the public Web. Based on the approach of the
W3C Linked Open Data initiative and the W3C Semantic Web technologies for
ontologies and rules it semantically links and integrates knowledge from our
W3C HCLS knowledge base hosted at the FUB, our multi-domain knowledge base
DBpedia (Deutschland) implemented at FUB, which is extracted from Wikipedia
(De) providing a public semantic resource for chemistry, and our
well-established databases at FIZ Chemie such as ChemInform for organic
reaction data, InfoTherm the leading source for thermophysical data, Chemisches
Zentralblatt, the complete chemistry knowledge from 1830 to 1969, and
ChemgaPedia the largest and most frequented e-Learning platform for Chemistry
and related sciences in German language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1646</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1646</id><created>2010-12-07</created><authors><author><keyname>Huber</keyname><forenames>Richard</forenames></author><author><keyname>Hantelmann</keyname><forenames>Kirsten</forenames></author><author><keyname>Todor</keyname><forenames>Alexandru</forenames></author><author><keyname>Krebs</keyname><forenames>Sebastian</forenames></author><author><keyname>Heese</keyname><forenames>Ralf</forenames></author><author><keyname>Paschke</keyname><forenames>Adrian</forenames></author></authors><title>Use of semantic technologies for the development of a dynamic
  trajectories generator in a Semantic Chemistry eLearning platform</title><categories>cs.AI</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ChemgaPedia is a multimedia, webbased eLearning service platform that
currently contains about 18.000 pages organized in 1.700 chapters covering the
complete bachelor studies in chemistry and related topics of chemistry,
pharmacy, and life sciences. The eLearning encyclopedia contains some 25.000
media objects and the eLearning platform provides services such as virtual and
remote labs for experiments. With up to 350.000 users per month the platform is
the most frequently used scientific educational service in the German spoken
Internet. In this demo we show the benefit of mapping the static eLearning
contents of ChemgaPedia to a Linked Data representation for Semantic Chemistry
which allows for generating dynamic eLearning paths tailored to the semantic
profiles of the users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1648</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1648</id><created>2010-12-07</created><authors><author><keyname>Holford</keyname><forenames>Matt</forenames></author><author><keyname>McCusker</keyname><forenames>James</forenames></author><author><keyname>Cheung</keyname><forenames>Kei</forenames></author><author><keyname>Krauthammer</keyname><forenames>Michael</forenames></author></authors><title>Analysis Of Cancer Omics Data In A Semantic Web Framework</title><categories>cs.AI cs.CE</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our work concerns the elucidation of the cancer (epi)genome, transcriptome
and proteome to better understand the complex interplay between a cancer cell's
molecular state and its response to anti-cancer therapy. To study the problem,
we have previously focused on data warehousing technologies and statistical
data integration. In this paper, we present recent work on extending our
analytical capabilities using Semantic Web technology. A key new component
presented here is a SPARQL endpoint to our existing data warehouse. This
endpoint allows the merging of observed quantitative data with existing data
from semantic knowledge sources such as Gene Ontology (GO). We show how such
variegated quantitative and functional data can be integrated and accessed in a
universal manner using Semantic Web tools. We also demonstrate how Description
Logic (DL) reasoning can be used to infer previously unstated conclusions from
existing knowledge bases. As proof of concept, we illustrate the ability of our
setup to answer complex queries on resistance of cancer cells to Decitabine, a
demethylating agent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1650</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1650</id><created>2010-12-07</created><authors><author><keyname>Croset</keyname><forenames>Samuel</forenames></author><author><keyname>Grabm&#xfc;ller</keyname><forenames>Christoph</forenames></author><author><keyname>Li</keyname><forenames>Chen</forenames></author><author><keyname>Kavaliauskas</keyname><forenames>Silvestras</forenames></author><author><keyname>Rebholz-Schuhmann</keyname><forenames>Dietrich</forenames></author></authors><title>The CALBC RDF Triple Store: retrieval over large literature content</title><categories>cs.DL cs.DB</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Integration of the scientific literature into a biomedical research
infrastructure requires the processing of the literature, identification of the
contained named entities (NEs) and concepts, and to represent the content in a
standardised way. The CALBC project partners (PPs) have produced a large-scale
annotated biomedical corpus with four different semantic groups through the
harmonisation of annotations from automatic text mining solutions (Silver
Standard Corpus, SSC). The four semantic groups were chemical entities and
drugs (CHED), genes and proteins (PRGE), diseases and disorders (DISO) and
species (SPE). The content of the SSC has been fully integrated into RDF Triple
Store (4,568,678 triples) and has been aligned with content from the GeneAtlas
(182,840 triples), UniProtKb (12,552,239 triples for human) and the lexical
resource LexEBI (BioLexicon). RDF Triple Store enables querying the scientific
literature and bioinformatics resources at the same time for evidence of
genetic causes, such as drug targets and disease involvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1651</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1651</id><created>2010-12-07</created><authors><author><keyname>Paschke</keyname><forenames>Adrian</forenames></author><author><keyname>Zhao</keyname><forenames>Zhili</forenames></author></authors><title>The Rule Responder eScience Infrastructure</title><categories>cs.MA</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To a large degree information and services for chemical e-Science have become
accessible - anytime, anywhere - but not necessarily useful. The Rule Responder
eScience middleware is about providing information consumers with rule-based
agents to transform existing information into relevant information of practical
consequences, hence providing control to the end-users to express in a
declarative rule-based way how to turn existing information into personally
relevant information and how to react or make automated decisions on top of it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1652</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1652</id><created>2010-12-07</created><authors><author><keyname>Boekschoten</keyname><forenames>Paul</forenames></author><author><keyname>Burger</keyname><forenames>Kees</forenames></author><author><keyname>Mons</keyname><forenames>Barend</forenames></author><author><keyname>Chichester</keyname><forenames>Christine</forenames></author></authors><title>Import of ENZYME data into the ConceptWiki and its representation as RDF</title><categories>cs.DL</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solutions to the classic problems of dealing with heterogeneous data and
making entire collections interoperable while ensuring that any annotation,
which includes the recognition-and-reward system of scientific publishing, need
to fit into a seamless beginning to end to attract large numbers of end users.
The latest trend in Web applications encourages highly interactive Web sites
with rich user interfaces featuring content integrated from various sources
around the Web. The obvious potential of RDF, SPARQL, and OWL to provide
flexible data modeling, easier data integration, and networked data access may
be the answer to the classic problems. Using Semantic Web technologies we have
created a Web application, the ConceptWiki, as an end-to-end solution for
creating browserbased readwrite triples using RDF, which focus on data
integration and ease of use for the end user. Here we will demonstrate the
integration of a biological data source, the ENZYME database, into the
ConceptWiki and it's representation in RDF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1654</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1654</id><created>2010-12-07</created><authors><author><keyname>Groza</keyname><forenames>Adrian</forenames></author><author><keyname>Balaj</keyname><forenames>Radu</forenames></author></authors><title>Using Semantic Wikis for Structured Argument in Medical Domain</title><categories>cs.AI</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This research applies ideas from argumentation theory in the context of
semantic wikis, aiming to provide support for structured-large scale
argumentation between human agents. The implemented prototype is exemplified by
modelling the MMR vaccine controversy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1658</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1658</id><created>2010-12-07</created><authors><author><keyname>Dmitrieva</keyname><forenames>Julia</forenames></author><author><keyname>Verbeek</keyname><forenames>Fons J.</forenames></author></authors><title>Creating a new Ontology: a Modular Approach</title><categories>cs.AI</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Creating a new Ontology: a Modular Approach
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1659</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1659</id><created>2010-12-07</created><authors><author><keyname>Jimenez-Ruiz</keyname><forenames>Ernesto</forenames></author><author><keyname>Grau</keyname><forenames>Bernardo Cuenca</forenames></author><author><keyname>Berlanga</keyname><forenames>Rafael</forenames></author><author><keyname>Rebholz-Schuhmann</keyname><forenames>Dietrich</forenames></author></authors><title>First steps in the logic-based assessment of post-composed phenotypic
  descriptions</title><categories>cs.AI cs.LO</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a preliminary logic-based evaluation of the
integration of post-composed phenotypic descriptions with domain ontologies.
The evaluation has been performed using a description logic reasoner together
with scalable techniques: ontology modularization and approximations of the
logical difference between ontologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1660</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1660</id><created>2010-12-07</created><authors><author><keyname>Bolleman</keyname><forenames>Jerven</forenames></author><author><keyname>Gateau</keyname><forenames>Alain</forenames></author><author><keyname>Gehant</keyname><forenames>Sebastien</forenames></author><author><keyname>Redaschi</keyname><forenames>Nicole</forenames></author></authors><title>Provenance and evidence in UniProtKB</title><categories>cs.DB</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The primary mission of UniProt is to support biological research by
maintaining a stable, comprehensive, fully classified, richly and accurately
annotated protein sequence knowledgebase, with extensive cross-references to
external resources, that is freely available to the scientific community. To
enable users of the knowledgebase to accurately assess the reliability of the
information contained in this resource, the evidence for and provenance of the
information must be recorded. This paper discusses the user requirements for
this kind of metadata and the manner in which UniProtKB records it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1661</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1661</id><created>2010-12-07</created><authors><author><keyname>Canevet</keyname><forenames>Catherine</forenames></author><author><keyname>Lysenko</keyname><forenames>Artem</forenames></author><author><keyname>Splendiani</keyname><forenames>Andrea</forenames></author><author><keyname>Pocock</keyname><forenames>Matthew</forenames></author><author><keyname>Rawlings</keyname><forenames>Christopher</forenames></author></authors><title>Analysis and visualisation of RDF resources in Ondex</title><categories>cs.AI cs.CE</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ondex is a data integration and visualization platform developed to support
Systems Biology Research. At its core is a data model based on two main
principles: first, all information can be represented as a graph and, second,
all elements of the graph can be annotated with ontologies. This data model is
conformant to the Semantic Web framework, in particular to RDF, and therefore
Ondex is ideally positioned as a platform that can exploit the semantic web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1663</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1663</id><created>2010-12-07</created><authors><author><keyname>Kang</keyname><forenames>Ning</forenames></author><author><keyname>Barendse</keyname><forenames>Rogier</forenames></author><author><keyname>Afzal</keyname><forenames>Zubair</forenames></author><author><keyname>Singh</keyname><forenames>Bharat</forenames></author><author><keyname>Schuemie</keyname><forenames>Martijn J.</forenames></author><author><keyname>van Mulligen</keyname><forenames>Erik M.</forenames></author><author><keyname>Kors</keyname><forenames>Jan A.</forenames></author></authors><title>A Concept Annotation System for Clinical Records</title><categories>cs.IR</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unstructured information comprises a valuable source of data in clinical
records. For text mining in clinical records, concept extraction is the first
step in finding assertions and relationships. This study presents a system
developed for the annotation of medical concepts, including medical problems,
tests, and treatments, mentioned in clinical records. The system combines six
publicly available named entity recognition system into one framework, and uses
a simple voting scheme that allows to tune precision and recall of the system
to specific needs. The system provides both a web service interface and a UIMA
interface which can be easily used by other systems. The system was tested in
the fourth i2b2 challenge and achieved an F-score of 82.1% for the concept
exact match task, a score which is among the top-ranking systems. To our
knowledge, this is the first publicly available clinical record concept
annotation system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1664</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1664</id><created>2010-12-07</created><authors><author><keyname>Krause</keyname><forenames>Falko</forenames></author><author><keyname>Schulz</keyname><forenames>Marvin</forenames></author><author><keyname>Lubitz</keyname><forenames>Timo</forenames></author><author><keyname>Liebermeister</keyname><forenames>Wolfram</forenames></author></authors><title>semanticSBML 2.0 - A Collection of Online Services for SBML Models</title><categories>cs.OH</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  semanticSBML 2.0 is an online collection of services for the work with
biochemical network models in SBML format.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1665</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1665</id><created>2010-12-07</created><authors><author><keyname>Nagamalai</keyname><forenames>Dhinaharan</forenames></author><author><keyname>Dhinakaran</keyname><forenames>Beatrice Cynthia</forenames></author><author><keyname>Lee</keyname><forenames>Jae Kwang</forenames></author></authors><title>An In-depth Analysis of Spam and Spammers</title><categories>cs.CR cs.NI</categories><comments>14 pages, 8 Figures,5 tables, IJSA Vol 2, No 2, 2008</comments><journal-ref>International Journal of Security and its Applications,Vol. 2, No.
  2, April, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electronic mail services have become an important source of communication for
millions of people all over the world. Due to this tremendous growth, there has
been a significant increase in spam traffic. Spam messes up user's inbox,
consumes network resources and spread worms and viruses. In this paper we study
the characteristics of spam and the technology used by spammers. In order to
counter anti spam technology, spammers change their mode of operation,
therefore continues evaluation of the characteristics of spam and spammers
technology has become mandatory. These evaluations help us to enhance the
existing anti spam technology and thereby help us to combat spam effectively.
In order to characterize spam, we collected four hundred thousand spam mails
from a corporate mail server for a period of 14 months from January 2006 to
February 2007. For analysis we classified spam based on attachment and
contents. We observed that spammers use software tools to send spam with
attachment. The main features of this software are hiding sender's identity,
randomly selecting text messages, identifying open relay machines, mass mailing
capability and defining spamming duration. Spammers do not use spam software to
send spam without attachment. From our study we observed that, four years old
heavy users email accounts attract more spam than four years old light users
mail accounts. Relatively new email accounts which are 14 months old do not
receive spam. But in some special cases like DDoS attacks, we found that new
email accounts receive spam and 14 months old heavy users email accounts have
attracted more spam than 14 months old light users. We believe that this
analysis could be useful to develop more efficient anti spam techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1666</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1666</id><created>2010-12-07</created><authors><author><keyname>McCarthy</keyname><forenames>Luke</forenames></author><author><keyname>Vandervalk</keyname><forenames>Ben</forenames></author><author><keyname>Wilkinson</keyname><forenames>Mark</forenames></author></authors><title>SPARQL Assist Language-Neutral Query Composer</title><categories>cs.IR</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  SPARQL query composition is difficult for the lay-person or even the
experienced bioinformatician in cases where the data model is unfamiliar.
Established best-practices and internationalization concerns dictate that
semantic web ontologies should use terms with opaque identifiers, further
complicating the task. We present SPARQL Assist: a web application that
addresses these issues by providing context-sensitive type-ahead completion to
existing web forms. Ontological terms are suggested using their labels and
descriptions, leveraging existing XML support for internationalization and
language-neutrality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1667</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1667</id><created>2010-12-07</created><authors><author><keyname>Perez</keyname><forenames>Maria</forenames></author><author><keyname>Berlanga</keyname><forenames>Rafael</forenames></author><author><keyname>Sanz</keyname><forenames>Ismael</forenames></author></authors><title>A semantic approach for the requirement-driven discovery of web services
  in the Life Sciences</title><categories>cs.AI</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research in the Life Sciences depends on the integration of large,
distributed and heterogeneous data sources and web services. The discovery of
which of these resources are the most appropriate to solve a given task is a
complex research question, since there is a large amount of plausible
candidates and there is little, mostly unstructured, metadata to be able to
decide among them.We contribute a semi-automatic approach,based on semantic
techniques, to assist researchers in the discovery of the most appropriate web
services to full a set of given requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1671</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1671</id><created>2010-12-07</created><authors><author><keyname>Kurihara</keyname><forenames>Kazutaka</forenames></author><author><keyname>Nagano</keyname><forenames>Naoshi</forenames></author><author><keyname>Watanabe</keyname><forenames>Yuta</forenames></author><author><keyname>Fujimura</keyname><forenames>Yuichi</forenames></author><author><keyname>Minaduki</keyname><forenames>Akinori</forenames></author><author><keyname>Hayashi</keyname><forenames>Hidehiko</forenames></author><author><keyname>Tsuchiya</keyname><forenames>Yohei</forenames></author></authors><title>Localizing Audiences' Gaze using a Multi-touch Electronic Whiteboard
  with sPieMenu</title><categories>cs.HC</categories><acm-class>H.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Direct-touch presentation devices such as touch-sensitive electronic
whiteboards have two serious problems. First, the presenter's hand movements
tend to distract the audience's attention from content. Second, the presenter'
s manipulation tends to obscure content. In this paper we describe a new
electronic whiteboard system that supports multi-touch gestures and employs a
special pie menu interface named &quot;sPieMenu.&quot; This pie menu is displayed under
the presenter's palm and is thus invisible to the audience. A series of
experiments shows that the proposed system allows both novice and expert users
to efficiently manipulate the electronic whiteboard, and that the proposed
system decreases distraction to the audience compared to traditional
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1672</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1672</id><created>2010-12-07</created><authors><author><keyname>Park</keyname><forenames>Jaeok</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Designing Incentive Schemes Based on Intervention: The Case of Imperfect
  Monitoring</title><categories>cs.GT cs.SY</categories><comments>8 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an incentive scheme based on intervention to sustain cooperation
among self-interested users. In the proposed scheme, an intervention device
collects imperfect signals about the actions of the users for a test period,
and then chooses the level of intervention that degrades the performance of the
network for the remaining time period. We analyze the problems of designing an
optimal intervention rule given a test period and choosing an optimal length of
the test period. The intervention device can provide the incentive for
cooperation by exerting intervention following signals that involve a high
likelihood of deviation. Increasing the length of the test period has two
counteracting effects on the performance: It improves the quality of signals,
but at the same time it weakens the incentive for cooperation due to increased
delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1673</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1673</id><created>2010-12-07</created><authors><author><keyname>Park</keyname><forenames>Jaeok</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Designing Incentive Schemes Based on Intervention: The Case of Perfect
  Monitoring</title><categories>cs.GT</categories><comments>8 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a class of incentive schemes based on intervention, where
there exists an intervention device that is able to monitor the actions of
users and to take an action that affects the payoffs of users. We consider the
case of perfect monitoring, where the intervention device can immediately
observe the actions of users without errors. We also assume that there exist
actions of the intervention device that are most and least preferred by all the
users and the intervention device, regardless of the actions of users. We
derive analytical results about the outcomes achievable with intervention, and
illustrate our results with an example based on the Cournot model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1681</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1681</id><created>2010-12-07</created><authors><author><keyname>Xiong</keyname><forenames>Haozhi</forenames></author><author><keyname>Li</keyname><forenames>Ruogu</forenames></author><author><keyname>Eryilmaz</keyname><forenames>Atilla</forenames></author><author><keyname>Ekici</keyname><forenames>Eylem</forenames></author></authors><title>Delay-Aware Cross-Layer Design for Network Utility Maximization in
  Multi-hop Networks</title><categories>math.OC cs.NI</categories><comments>14 pages, JSAC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the problem of designing delay-aware joint flow control,
routing, and scheduling algorithms in general multi-hop networks for maximizing
network utilization. Since the end-to-end delay performance has a complex
dependence on the high-order statistics of cross-layer algorithms, earlier
optimization-based design methodologies that optimize the long term network
utilization are not immediately well-suited for delay-aware design. This
motivates us in this work to develop a novel design framework and alternative
methods that take advantage of several unexploited design choices in the
routing and the scheduling strategy spaces. In particular, we reveal and
exploit a crucial characteristic of back pressure-type controllers that enables
us to develop a novel link rate allocation strategy that not only optimizes
long-term network utilization, but also yields loop free multi-path routes}
between each source-destination pair. Moreover, we propose a regulated
scheduling strategy, based on a token-based service discipline, for shaping the
per-hop delay distribution to obtain highly desirable end-to-end delay
performance. We establish that our joint flow control, routing, and scheduling
algorithm achieves loop-free routes and optimal network utilization. Our
extensive numerical studies support our theoretical results, and further show
that our joint design leads to substantial end-to-end delay performance
improvements in multi-hop networks compared to earlier solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1689</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1689</id><created>2010-12-08</created><authors><author><keyname>Pattanayak</keyname><forenames>Binod Kumar</forenames></author><author><keyname>Jagadev</keyname><forenames>Alok Kumar</forenames></author><author><keyname>Mishra</keyname><forenames>Manoj Kumar</forenames></author><author><keyname>Nayak</keyname><forenames>Manoj Ranjan</forenames></author></authors><title>A Distributed Cluster Scheme For Bandwidth Management In Multi-hop
  MANETs</title><categories>cs.NI</categories><comments>7 pages, 5 figures</comments><journal-ref>IJCSNS International Journal of Computer Science and Network
  Security, VOL.9 No.10, October 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electronic collaboration among devices in a geographically localized
environment is made possible with the implementation of IEEE 802.11 based
wireless ad hoc networks. Dynamic nature of mobile ad hoc networks(MANETs) may
lead to unpredictable intervention of attacks or fault occurrence, which
consequently may partition the network, degrade its performance, violate the
QoS requirements and most importantly, affect bandwidth allocation to mobile
nodes in the network. In this paper, we propose a new distributed cluster
scheme for MANETs, especially in harsh environments, based on the concept of
survivability to support QoS requirements and to protect bandwidth efficiently.
With the incorporation of clustering algorithms in survivability technology, we
employ a simple network configuration and expect to reduce occurrences of
faults in MANETs. At the same time, we address the scalability problem, which
represents a great challenge to network configuration. We do expect a
simplification of accessing bandwidth allocation with required QoS support for
different applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1718</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1718</id><created>2010-12-08</created><authors><author><keyname>Pia</keyname><forenames>M. G.</forenames><affiliation>INFN, Sezione di Genova</affiliation></author><author><keyname>Basaglia</keyname><forenames>T.</forenames><affiliation>CERN</affiliation></author><author><keyname>Bell</keyname><forenames>Z. W.</forenames><affiliation>Oak Ridge National Laboratory</affiliation></author><author><keyname>Dressendorfer</keyname><forenames>P. V.</forenames><affiliation>IEEE</affiliation></author></authors><title>The Butterfly Effect: Correlations Between Modeling in Nuclear-Particle
  Physics and Socioeconomic Factors</title><categories>physics.comp-ph cs.DL physics.soc-ph</categories><comments>8 pages, to appear in proceedings of the Nuclear Science Symposium
  and Medical Imaging Conference 2010, Knoxville</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A scientometric analysis has been performed on selected physics journals to
estimate the presence of simulation and modeling in physics literature in the
past fifty years. Correlations between the observed trends and several social
and economical factors have been evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1743</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1743</id><created>2010-12-08</created><authors><author><keyname>Leclercq</keyname><forenames>Eric</forenames></author><author><keyname>Savonnet</keyname><forenames>Marinette</forenames></author></authors><title>Scientific Collaborations: principles of WikiBridge Design</title><categories>cs.AI</categories><comments>in Adrian Paschke, Albert Burger begin_of_the_skype_highlighting
  end_of_the_skype_highlighting, Andrea Splendiani, M. Scott Marshall, Paolo
  Romano: Proceedings of the 3rd International Workshop on Semantic Web
  Applications and Tools for the Life Sciences, Berlin,Germany, December 8-10,
  2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semantic wikis, wikis enhanced with Semantic Web technologies, are
appropriate systems for community-authored knowledge models. They are
particularly suitable for scientific collaboration. This paper details the
design principles ofWikiBridge, a semantic wiki.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1745</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1745</id><created>2010-12-08</created><authors><author><keyname>Jupp</keyname><forenames>Simon</forenames></author><author><keyname>Horridge</keyname><forenames>Matthew</forenames></author><author><keyname>Iannone</keyname><forenames>Luigi</forenames></author><author><keyname>Klein</keyname><forenames>Julie</forenames></author><author><keyname>Owen</keyname><forenames>Stuart</forenames></author><author><keyname>Schanstra</keyname><forenames>Joost</forenames></author><author><keyname>Stevens</keyname><forenames>Robert</forenames></author><author><keyname>Wolstencroft</keyname><forenames>Katy</forenames></author></authors><title>Populous: A tool for populating ontology templates</title><categories>cs.AI</categories><comments>in Adrian Paschke, Albert Burger begin_of_the_skype_highlighting
  end_of_the_skype_highlighting, Andrea Splendiani, M. Scott Marshall, Paolo
  Romano: Proceedings of the 3rd International Workshop on Semantic Web
  Applications and Tools for the Life Sciences, Berlin,Germany, December 8-10,
  2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present Populous, a tool for gathering content with which to populate an
ontology. Domain experts need to add content, that is often repetitive in its
form, but without having to tackle the underlying ontological representation.
Populous presents users with a table based form in which columns are
constrained to take values from particular ontologies; the user can select a
concept from an ontology via its meaningful label to give a value for a given
entity attribute. Populated tables are mapped to patterns that can then be used
to automatically generate the ontology's content. Populous's contribution is in
the knowledge gathering stage of ontology development. It separates knowledge
gathering from the conceptualisation and also separates the user from the
standard ontology authoring environments. As a result, Populous can allow
knowledge to be gathered in a straight-forward manner that can then be used to
do mass production of ontology content.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1749</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1749</id><created>2010-12-08</created><updated>2011-09-12</updated><authors><author><keyname>de Berg</keyname><forenames>Mark</forenames></author><author><keyname>Speckmann</keyname><forenames>Bettina</forenames></author><author><keyname>van der Weele</keyname><forenames>Vincent</forenames></author></authors><title>Treemaps with Bounded Aspect Ratio</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Treemaps are a popular technique to visualize hierarchical data. The input is
a weighted tree $\tree$ where the weight of each node is the sum of the weights
of its children. A treemap for $\tree$ is a hierarchical partition of a
rectangle into simply connected regions, usually rectangles. Each region
represents a node of $\tree$ and its area is proportional to the weight of the
corresponding node. An important quality criterion for treemaps is the aspect
ratio of its regions. One cannot bound the aspect ratio if the regions are
restricted to be rectangles. In contrast, \emph{polygonal partitions}, that use
convex polygons, have bounded aspect ratio. We are the first to obtain convex
partitions with optimal aspect ratio $O(\depth(\tree))$. However,
$\depth(\tree)$ still depends on the input tree. Hence we introduce a new type
of treemaps, namely \emph{orthoconvex treemaps}, where regions representing
leaves are rectangles, L-, and S-shapes, and regions representing internal
nodes are orthoconvex polygons. We prove that any input tree, irrespective of
the weights of the nodes and the depth of the tree, admits an orthoconvex
treemap of constant aspect ratio. We also obtain several specialized results
for single-level treemaps, that is, treemaps where the input tree has depth~1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1769</identifier>
 <datestamp>2014-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1769</id><created>2010-12-08</created><updated>2011-06-03</updated><authors><author><keyname>Wild</keyname><forenames>Marcel</forenames></author></authors><title>Compactly generating all satisfying truth assignments of a Horn formula</title><categories>cs.LO math.LO</categories><comments>Considerably improves upon the readibility of the previous version</comments><journal-ref>Journal on Satisfiability, Boolean Modeling and Computation 8
  (2012) 63-82</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As instance of an overarching principle of exclusion an algorithm is
presented that compactly (thus not one by one) generates all models of a Horn
formula. The principle of exclusion can be adapted to generate only the models
of weight $k$. We compare and contrast it with constraint programming, $0,1$
integer programming, and binary decision diagrams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1776</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1776</id><created>2010-12-08</created><authors><author><keyname>Guedes</keyname><forenames>Ello&#xe1; B.</forenames></author><author><keyname>de Assis</keyname><forenames>Francisco Marcos</forenames></author><author><keyname>Lula</keyname><forenames>Bernardo</forenames><suffix>Jr</suffix></author></authors><title>Examples of the Generalized Quantum Permanent Compromise Attack to the
  Blum-Micali Construction</title><categories>cs.IT cs.CR math.IT</categories><comments>8 pages, 1 figure, 2 attacks</comments><msc-class>68Q12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents examples of the quantum permanent compromise attack to
the Blum-Micali construction. Such attacks illustrate how a previous attack to
the Blum-Micali generator can be extended to the whole Blum-Micali
construction, including the Blum-Blum-Shub and Kaliski generators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1799</identifier>
 <datestamp>2013-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1799</id><created>2010-12-08</created><authors><author><keyname>Hossain</keyname><forenames>Md. Jahangir</forenames></author><author><keyname>Alvarado</keyname><forenames>Alex</forenames></author><author><keyname>Szczecinski</keyname><forenames>Leszek</forenames></author></authors><title>Towards Fully Optimized BICM Transceivers</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Communications</comments><journal-ref>IEEE Trans. Commun., vol. 59, no. 11, pp. 3027-3039, 2011</journal-ref><doi>10.1109/TCOMM.2011.091411.100746</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bit-interleaved coded modulation (BICM) transceivers often use equally spaced
constellations and a random interleaver. In this paper, we propose a new BICM
design, which considers hierarchical (nonequally spaced) constellations, a
bit-level multiplexer, and multiple interleavers. It is shown that this new
scheme increases the degrees of freedom that can be exploited in order to
improve its performance. Analytical bounds on the bit error rate (BER) of the
system in terms of the constellation parameters and the multiplexing rules are
developed for the additive white Gaussian Noise (AWGN) and Nakagami-$m$ fading
channels. These bounds are then used to design the BICM transceiver. Numerical
results show that, compared to conventional BICM designs, and for a target BER
of $10^{-6}$, gains up to 3 dB in the AWGN channel are obtained. For fading
channels, the gains depend on the fading parameter, and reach 2 dB for a target
BER of $10^{-7}$ and $m=5$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1802</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1802</id><created>2010-12-02</created><updated>2011-03-25</updated><authors><author><keyname>Tate</keyname><forenames>Ross</forenames><affiliation>University of California, San Diego</affiliation></author><author><keyname>Stepp</keyname><forenames>Michael</forenames><affiliation>University of California, San Diego</affiliation></author><author><keyname>Tatlock</keyname><forenames>Zachary</forenames><affiliation>University of California, San Diego</affiliation></author><author><keyname>Lerner</keyname><forenames>Sorin</forenames><affiliation>University of California, San Diego</affiliation></author></authors><title>Equality Saturation: A New Approach to Optimization</title><categories>cs.PL</categories><comments>80 pages, 39 figures</comments><proxy>LMCS</proxy><acm-class>D.3.4</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 1 (March 28,
  2011) lmcs:1016</journal-ref><doi>10.2168/LMCS-7(1:10)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimizations in a traditional compiler are applied sequentially, with each
optimization destructively modifying the program to produce a transformed
program that is then passed to the next optimization. We present a new approach
for structuring the optimization phase of a compiler. In our approach,
optimizations take the form of equality analyses that add equality information
to a common intermediate representation. The optimizer works by repeatedly
applying these analyses to infer equivalences between program fragments, thus
saturating the intermediate representation with equalities. Once saturated, the
intermediate representation encodes multiple optimized versions of the input
program. At this point, a profitability heuristic picks the final optimized
program from the various programs represented in the saturated representation.
Our proposed way of structuring optimizers has a variety of benefits over
previous approaches: our approach obviates the need to worry about optimization
ordering, enables the use of a global optimization heuristic that selects among
fully optimized programs, and can be used to perform translation validation,
even on compilers other than our own. We present our approach, formalize it,
and describe our choice of intermediate representation. We also present
experimental results showing that our approach is practical in terms of time
and space overhead, is effective at discovering intricate optimization
opportunities, and is effective at performing translation validation for a
realistic optimizer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1813</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1813</id><created>2010-12-08</created><authors><author><keyname>de Franciscis</keyname><forenames>Sebastiano</forenames></author><author><keyname>Johnson</keyname><forenames>Samuel</forenames></author><author><keyname>Torres</keyname><forenames>Joaqu&#xed;n J.</forenames></author></authors><title>Enhancing neural-network performance via assortativity</title><categories>cond-mat.dis-nn cs.PF physics.bio-ph q-bio.NC</categories><comments>9 pages, 7 figures</comments><doi>10.1103/PhysRevE.83.036114</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of attractor neural networks has been shown to depend
crucially on the heterogeneity of the underlying topology. We take this
analysis a step further by examining the effect of degree-degree correlations
-- or assortativity -- on neural-network behavior. We make use of a method
recently put forward for studying correlated networks and dynamics thereon,
both analytically and computationally, which is independent of how the topology
may have evolved. We show how the robustness to noise is greatly enhanced in
assortative (positively correlated) neural networks, especially if it is the
hub neurons that store the information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1824</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1824</id><created>2010-12-08</created><authors><author><keyname>Torquati</keyname><forenames>Massimo</forenames></author></authors><title>Single-Producer/Single-Consumer Queues on Shared Cache Multi-Core
  Systems</title><categories>cs.DS cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using efficient point-to-point communication channels is critical for
implementing fine grained parallel program on modern shared cache multi-core
architectures.
  This report discusses in detail several implementations of wait-free
Single-Producer/Single-Consumer queue (SPSC), and presents a novel and
efficient algorithm for the implementation of an unbounded wait-free SPSC queue
(uSPSC). The correctness proof of the new algorithm, and several performance
measurements based on simple synthetic benchmark and microbenchmark, are also
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1850</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1850</id><created>2010-12-08</created><authors><author><keyname>Gortz</keyname><forenames>Inge Li</forenames></author><author><keyname>Molinaro</keyname><forenames>Marco</forenames></author><author><keyname>Nagarajan</keyname><forenames>Viswanath</forenames></author><author><keyname>Ravi</keyname><forenames>R.</forenames></author></authors><title>Capacitated Vehicle Routing with Non-Uniform Speeds</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacitated vehicle routing problem (CVRP) involves distributing
(identical) items from a depot to a set of demand locations, using a single
capacitated vehicle. We study a generalization of this problem to the setting
of multiple vehicles having non-uniform speeds (that we call Heterogenous
CVRP), and present a constant-factor approximation algorithm.
  The technical heart of our result lies in achieving a constant approximation
to the following TSP variant (called Heterogenous TSP). Given a metric denoting
distances between vertices, a depot r containing k vehicles with possibly
different speeds, the goal is to find a tour for each vehicle (starting and
ending at r), so that every vertex is covered in some tour and the maximum
completion time is minimized. This problem is precisely Heterogenous CVRP when
vehicles are uncapacitated.
  The presence of non-uniform speeds introduces difficulties for employing
standard tour-splitting techniques. In order to get a better understanding of
this technique in our context, we appeal to ideas from the 2-approximation for
scheduling in parallel machine of Lenstra et al.. This motivates the
introduction of a new approximate MST construction called Level-Prim, which is
related to Light Approximate Shortest-path Trees. The last component of our
algorithm involves partitioning the Level-Prim tree and matching the resulting
parts to vehicles. This decomposition is more subtle than usual since now we
need to enforce correlation between the size of the parts and their distances
to the depot.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1882</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1882</id><created>2010-12-08</created><authors><author><keyname>Opitz</keyname><forenames>Jasmin</forenames></author><author><keyname>Parsia</keyname><forenames>Bijan</forenames></author><author><keyname>Sattler</keyname><forenames>Ulrike</forenames></author></authors><title>Evaluating Modelling Approaches for Medical Image Annotations</title><categories>cs.MM</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information system designers face many challenges w.r.t. selecting
appropriate semantic technologies and deciding on a modelling approach for
their system. However, there is no clear methodology yet to evaluate
&quot;semantically enriched&quot; information systems. In this paper we present a case
study on different modelling approaches for annotating medical images and
introduce a conceptual framework that can be used to analyse the fitness of
information systems and help designers to spot the strengths and weaknesses of
various modelling approaches as well as managing trade-offs between modelling
effort and their potential benefits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1886</identifier>
 <datestamp>2011-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1886</id><created>2010-12-08</created><updated>2011-07-14</updated><authors><author><keyname>Porat</keyname><forenames>Ely</forenames></author><author><keyname>Strauss</keyname><forenames>Martin J.</forenames></author></authors><title>Sublinear Time, Measurement-Optimal, Sparse Recovery For All</title><categories>cs.DS</categories><comments>Corrected argument with minor change to results</comments><acm-class>F.2.2; E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An approximate sparse recovery system in ell_1 norm formally consists of
parameters N, k, epsilon an m-by-N measurement matrix, Phi, and a decoding
algorithm, D. Given a vector, x, where x_k denotes the optimal k-term
approximation to x, the system approximates x by hat_x = D(Phi.x), which must
satisfy
  ||hat_x - x||_1 &lt;= (1+epsilon)||x - x_k||_1.
  Among the goals in designing such systems are minimizing m and the runtime of
D. We consider the &quot;forall&quot; model, in which a single matrix Phi is used for all
signals x.
  All previous algorithms that use the optimal number m=O(k log(N/k)) of
measurements require superlinear time Omega(N log(N/k)). In this paper, we give
the first algorithm for this problem that uses the optimum number of
measurements (up to a constant factor) and runs in sublinear time o(N) when
k=o(N), assuming access to a data structure requiring space and preprocessing
O(N).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1890</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1890</id><created>2010-12-08</created><authors><author><keyname>Abdallah</keyname><forenames>Samer A.</forenames></author><author><keyname>Plumbley</keyname><forenames>Mark D.</forenames></author></authors><title>A measure of statistical complexity based on predictive information</title><categories>math.ST cs.IT math.IT physics.data-an stat.TH</categories><comments>4 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an information theoretic measure of statistical structure,
called 'binding information', for sets of random variables, and compare it with
several previously proposed measures including excess entropy, Bialek et al.'s
predictive information, and the multi-information. We derive some of the
properties of the binding information, particularly in relation to the
multi-information, and show that, for finite sets of binary random variables,
the processes which maximises binding information are the 'parity' processes.
Finally we discuss some of the implications this has for the use of the binding
information as a measure of complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1895</identifier>
 <datestamp>2011-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1895</id><created>2010-12-08</created><authors><author><keyname>Mazumdar</keyname><forenames>Arya</forenames></author><author><keyname>Barg</keyname><forenames>Alexander</forenames></author><author><keyname>Kashyap</keyname><forenames>Navin</forenames></author></authors><title>Coding for High-Density Recording on a 1-D Granular Magnetic Medium</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. 57, issue 11, pp.
  7403-7417, 2011</journal-ref><doi>10.1109/TIT.2011.2158514</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In terabit-density magnetic recording, several bits of data can be replaced
by the values of their neighbors in the storage medium. As a result, errors in
the medium are dependent on each other and also on the data written. We
consider a simple one-dimensional combinatorial model of this medium. In our
model, we assume a setting where binary data is sequentially written on the
medium and a bit can erroneously change to the immediately preceding value. We
derive several properties of codes that correct this type of errors, focusing
on bounds on their cardinality.
  We also define a probabilistic finite-state channel model of the storage
medium, and derive lower and upper estimates of its capacity. A lower bound is
derived by evaluating the symmetric capacity of the channel, i.e., the maximum
transmission rate under the assumption of the uniform input distribution of the
channel. An upper bound is found by showing that the original channel is a
stochastic degradation of another, related channel model whose capacity we can
compute explicitly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1898</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1898</id><created>2010-12-08</created><authors><author><keyname>Howe</keyname><forenames>Doug</forenames></author><author><keyname>Pich</keyname><forenames>Christian</forenames></author></authors><title>Ontology Usage at ZFIN</title><categories>cs.DB</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Zebrafish Model Organism Database (ZFIN) provides a Web resource of
zebrafish genomic, genetic, developmental, and phenotypic data. Four different
ontologies are currently used to annotate data to the most specific term
available facilitating a better comparison between inter-species data. In
addition, ontologies are used to help users find and cluster data more quickly
without the need of knowing the exact technical name for a term.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1899</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1899</id><created>2010-12-08</created><authors><author><keyname>Erdogan</keyname><forenames>Halit</forenames></author><author><keyname>Oztok</keyname><forenames>Umut</forenames></author><author><keyname>Erdem</keyname><forenames>Yelda</forenames></author><author><keyname>Erdem</keyname><forenames>Esra</forenames></author></authors><title>Querying Biomedical Ontologies in Natural Language using Answer Set</title><categories>cs.AI</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we develop an intelligent user interface that allows users to
enter biomedical queries in a natural language, and that presents the answers
(possibly with explanations if requested) in a natural language. We develop a
rule layer over biomedical ontologies and databases, and use automated
reasoners to answer queries considering relevant parts of the rule layer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1908</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1908</id><created>2010-12-08</created><authors><author><keyname>Ahmadi</keyname><forenames>Amir Ali</forenames></author><author><keyname>Olshevsky</keyname><forenames>Alex</forenames></author><author><keyname>Parrilo</keyname><forenames>Pablo A.</forenames></author><author><keyname>Tsitsiklis</keyname><forenames>John N.</forenames></author></authors><title>NP-hardness of Deciding Convexity of Quartic Polynomials and Related
  Problems</title><categories>math.OC cs.CC</categories><comments>20 pages</comments><journal-ref>Mathematical Programming, Vol. 137, Issue 1-2, pp 453-476, 2013</journal-ref><doi>10.1007/s10107-011-0499-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that unless P=NP, there exists no polynomial time (or even
pseudo-polynomial time) algorithm that can decide whether a multivariate
polynomial of degree four (or higher even degree) is globally convex. This
solves a problem that has been open since 1992 when N. Z. Shor asked for the
complexity of deciding convexity for quartic polynomials. We also prove that
deciding strict convexity, strong convexity, quasiconvexity, and
pseudoconvexity of polynomials of even degree four or higher is strongly
NP-hard. By contrast, we show that quasiconvexity and pseudoconvexity of odd
degree polynomials can be decided in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1909</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1909</id><created>2010-12-08</created><authors><author><keyname>Mohaisen</keyname><forenames>Manar</forenames></author><author><keyname>Chang</keyname><forenames>KyungHi</forenames></author></authors><title>On Transmit Antenna Selection for Multiuser MIMO Systems with Dirty
  Paper Coding</title><categories>cs.IT math.IT</categories><comments>5 pages, 6 figures, 1 table, [The 20th Personal, Indoor and Mobile
  Radio Communications Symposium 2009 (PIMRC-09)]</comments><journal-ref>The 20th Personal, Indoor and Mobile Radio Communications
  Symposium 2009 (PIMRC-09)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the transmit antenna selection in multi-user MIMO
systems with precoding. The optimum and reduced complexity sub-optimum antenna
selection algorithms are introduced. QR-decomposition (QRD) based antenna
selection is investigated and the reason behind its sub-optimality is
analytically derived. We introduce the conventional QRD-based algorithm and
propose an efficient QRD-based transmit antenna scheme (maxR) that is both
implementation and performance efficient. Moreover, we derive explicit formulae
for the computational complexities of the aforementioned algorithms. Simulation
results and analysis demonstrate that the proposed maxR algorithm requires only
1% of the computational efforts required by the optimal algorithm for a
degradation of 1dB and 0.1dB in the case of linear zero-forcing and
Tomlinson-Harashima precoding schemes, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1912</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1912</id><created>2010-12-08</created><authors><author><keyname>Como</keyname><forenames>Giacomo</forenames></author><author><keyname>Y&#xfc;ksel</keyname><forenames>Serdar</forenames></author></authors><title>On the Capacity of Memoryless Finite-State Multiple-Access Channels with
  Asymmetric State Information at the Encoders</title><categories>cs.IT math.IT</categories><comments>8 pages, 1 figure, accepted for publication, in press</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A single-letter characterization is provided for the capacity region of
finite-state multiple-access channels, when the channel state process is an
independent and identically distributed sequence, the transmitters have access
to partial (quantized) state information, and complete channel state
information is available at the receiver. The partial channel state information
is assumed to be asymmetric at the encoders. As a main contribution, a tight
converse coding theorem is presented. The difficulties associated with the case
when the channel state has memory are discussed and connections to
decentralized stochastic control theory are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1919</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1919</id><created>2010-12-08</created><updated>2012-03-24</updated><authors><author><keyname>Deng</keyname><forenames>Yue</forenames></author><author><keyname>Dai</keyname><forenames>Qionghai</forenames></author><author><keyname>Liu</keyname><forenames>Risheng</forenames></author><author><keyname>Zhang</keyname><forenames>Zengke</forenames></author><author><keyname>Hu</keyname><forenames>Sanqing</forenames></author></authors><title>Low-Rank Structure Learning via Log-Sum Heuristic Recovery</title><categories>cs.NA cs.IT cs.LG math.IT</categories><comments>13 pages, 3 figures</comments><journal-ref>Neural Networks and Learning Systems, IEEE Transactions on,
  Volume:24 , Issue: 3, March, 2013</journal-ref><doi>10.1109/TNNLS.2012.2235082</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recovering intrinsic data structure from corrupted observations plays an
important role in various tasks in the communities of machine learning and
signal processing. In this paper, we propose a novel model, named log-sum
heuristic recovery (LHR), to learn the essential low-rank structure from
corrupted data. Different from traditional approaches, which directly utilize
$\ell_1$ norm to measure the sparseness, LHR introduces a more reasonable
log-sum measurement to enhance the sparsity in both the intrinsic low-rank
structure and in the sparse corruptions. Although the proposed LHR optimization
is no longer convex, it still can be effectively solved by a
majorization-minimization (MM) type algorithm, with which the non-convex
objective function is iteratively replaced by its convex surrogate and LHR
finally falls into the general framework of reweighed approaches. We prove that
the MM-type algorithm can converge to a stationary point after successive
iteration. We test the performance of our proposed model by applying it to
solve two typical problems: robust principal component analysis (RPCA) and
low-rank representation (LRR).
  For RPCA, we compare LHR with the benchmark Principal Component Pursuit (PCP)
method from both the perspectives of simulations and practical applications.
For LRR, we apply LHR to compute the low-rank representation matrix for motion
segmentation and stock clustering. Experimental results on low rank structure
learning demonstrate that the proposed Log-sum based model performs much better
than the $\ell_1$-based method on for data with higher rank and with denser
corruptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1938</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1938</id><created>2010-12-09</created><updated>2010-12-13</updated><authors><author><keyname>Harks</keyname><forenames>Tobias</forenames></author><author><keyname>Klimm</keyname><forenames>Max</forenames></author></authors><title>Congestion Games with Variable Demands</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We initiate the study of congestion games with variable demands where the
(variable) demand has to be assigned to exactly one subset of resources. The
players' incentives to use higher demands are stimulated by non-decreasing and
concave utility functions. The payoff for a player is defined as the difference
between the utility of the demand and the associated cost on the used
resources. Although this class of non-cooperative games captures many elements
of real-world applications, it has not been studied in this generality, to our
knowledge, in the past. We study the fundamental problem of the existence of
pure Nash equilibria (PNE for short) in congestion games with variable demands.
We call a set of cost functions C consistent if every congestion game with
variable demands and cost functions in C possesses a PNE. We say that C is FIP
consistent if every such game possesses the alpha-Finite Improvement Property
for every alpha&gt;0. Our main results are structural characterizations of
consistency and FIP consistency for twice continuously differentiable cost
functions. Specifically, we show 1. C is consistent if and only if C contains
either only affine functions or only homogeneously exponential functions (c(x)
= a exp(p x)). 2. C is FIP consistent if and only if C contains only affine
functions. Our results provide a complete characterization of consistency of
cost functions revealing structural differences to congestion games with fixed
demands (weighted congestion games), where in the latter even inhomogeneously
exponential functions are FIP consistent. Finally, we study consistency and FIP
consistency of cost functions in a slightly different class of games, where
every player experiences the same cost on a resource (uniform cost model). We
give a characterization of consistency and FIP consistency showing that only
homogeneously exponential functions are consistent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1939</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1939</id><created>2010-12-09</created><updated>2010-12-10</updated><authors><author><keyname>Aolan</keyname><forenames>Shi</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>What the Cited and Citing Environments Reveal of &quot;Advances in
  Atmospheric Sciences&quot;?</title><categories>cs.DL physics.ao-ph physics.soc-ph</categories><journal-ref>Advances in Atmospheric Physics, 28(1), 2011, 238-244</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The networking ability of journals reflects their academic influence among
peer journals. This paper analyzes the cited and citing environments of the
journal--Advances in Atmospheric Sciences--using methods from social network
analysis. The journal has been actively participating in the international
journal environment, but one has a tendency to cite papers published in
international journals. Advances in Atmospheric Sciences is intensely
interrelated with international peer journals in terms of similar citing
pattern. However, there is still room for an increase in its academic
visibility given the comparatively smaller reception in terms of cited
references.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1942</identifier>
 <datestamp>2012-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1942</id><created>2010-12-09</created><updated>2012-03-05</updated><authors><author><keyname>He</keyname><forenames>Jing</forenames></author><author><keyname>Liang</keyname><forenames>Hongyu</forenames></author></authors><title>On Rainbow-$k$-Connectivity of Random Graphs</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A path in an edge-colored graph is called a \emph{rainbow path} if all edges
on it have pairwise distinct colors. For $k\geq 1$, the
\emph{rainbow-$k$-connectivity} of a graph $G$, denoted $rc_k(G)$, is the
minimum number of colors required to color the edges of $G$ in such a way that
every two distinct vertices are connected by at least $k$ internally disjoint
rainbow paths. In this paper, we study rainbow-$k$-connectivity in the setting
of random graphs. We show that for every fixed integer $d\geq 2$ and every
$k\leq O(\log n)$, $p=\frac{(\log n)^{1/d}}{n^{(d-1)/d}}$ is a sharp threshold
function for the property $rc_k(G(n,p))\leq d$. This substantially generalizes
a result due to Caro et al., stating that $p=\sqrt{\frac{\log n}{n}}$ is a
sharp threshold function for the property $rc_1(G(n,p))\leq 2$. As a
by-product, we obtain a polynomial-time algorithm that makes $G(n,p)$
rainbow-$k$-connected using at most one more than the optimal number of colors
with probability $1-o(1)$, for all $k\leq O(\log n)$ and $p=n^{-\epsilon(1\pm
o(1))}$ for some constant $\epsilon\in[0,1)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1943</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1943</id><created>2010-12-09</created><authors><author><keyname>Pashkevich</keyname><forenames>Anatoly</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Klimchik</keyname><forenames>Alexandr</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Stiffness Analysis of Parallel Manipulators with Preloaded Passive
  Joints</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>12th International Symposium on Advances in Robot Kinematics,
  Slov\'enie : France (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents a methodology for the enhanced stiffness analysis of
parallel manipulators with internal preloading in passive joints. It also takes
into account influence of the external loading and allows computing both the
non-linear &quot;load-deflection&quot; relation and the stiffness matrices for any given
location of the end-platform or actuating drives. Using this methodology, it is
proposed the kinetostatic control algorithm that allows to improve accuracy of
the classical kinematic control and to compensate position errors caused by
elastic deformations in links/joints due to the external/internal loading. The
results are illustrated by an example that deals with a parallel manipulator of
the Orthoglide family where the internal preloading allows to eliminate the
undesired buckling phenomena and to improve the stiffness in the neighborhood
of its kinematic singularities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1947</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1947</id><created>2010-12-09</created><authors><author><keyname>Decreusefond</keyname><forenames>Laurent</forenames><affiliation>LTCI</affiliation></author><author><keyname>Martins</keyname><forenames>Philippe</forenames><affiliation>LTCI</affiliation></author><author><keyname>Vu</keyname><forenames>Thanh-Tung</forenames><affiliation>LTCI</affiliation></author></authors><title>On noise limited cellular networks</title><categories>math.PR cs.NI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a general theoretical framework to analyze noise
limited networks. More precisely, we consider two homogenous Poisson point
processes of base stations and users. General model of radio signal propagation
and effect of fading are also considered. The main difference of our model with
respect to other existing models is that a user connects to his best servers
but not necessarily the closest one. We provide general formula for the outage
probability. We study functionals related to the SNR as well as the sum of
these functionals over all users per cell. For the latter, the expectation and
bounds on the variance are obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1948</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1948</id><created>2010-12-09</created><authors><author><keyname>Pashkevich</keyname><forenames>Anatoly</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Klimchik</keyname><forenames>Alexandr</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Briot</keyname><forenames>S&#xe9;bastien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Performance evaluation of parallel manipulators for milling application</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>20th CIRP Design Conference, Nantes : France (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the performance evaluation of the parallel manipulators
for milling of composite materials. For this application the most significant
performance measurements, which denote the ability of the manipulator for the
machining are defined. In this case, optimal synthesis task is solved as a
multicriterion optimization problem with respect to the geometric, kinematic,
kinetostatic, elastostostatic, dynamic properties. It is shown that stiffness
is an important performance factor. Previous models operate with links
approximation and calculate stiffness matrix in the neighborhood of initial
point. This is a reason why a new way for stiffness matrix calculation is
proposed. This method is illustrated in a concrete industrial problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.1980</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.1980</id><created>2010-12-09</created><authors><author><keyname>Fisk</keyname><forenames>Ian</forenames></author></authors><title>First Experiences with LHC Grid Computing and Distributed Analysis</title><categories>physics.data-an cs.DC hep-ex</categories><comments>6 pages, 2 figures, Proceedings of the Hadron Collider Physics
  Symposium 2010 (HCP2010), Toronto Canada</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this presentation the experiences of the LHC experiments using grid
computing were presented with a focus on experience with distributed analysis.
After many years of development, preparation, exercises, and validation the LHC
(Large Hadron Collider) experiments are in operations. The computing
infrastructure has been heavily utilized in the first 6 months of data
collection. The general experience of exploiting the grid infrastructure for
organized processing and preparation is described, as well as the successes
employing the infrastructure for distributed analysis. At the end the expected
evolution and future plans are outlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2003</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2003</id><created>2010-12-09</created><authors><author><keyname>Castellano</keyname><forenames>Claudio</forenames></author><author><keyname>Pastor-Satorras</keyname><forenames>Romualdo</forenames></author></authors><title>Irrelevance of information outflow in opinion dynamics models</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>5 pages, 4 figures</comments><journal-ref>Phys. Rev. E 83, 016113 (2011)</journal-ref><doi>10.1103/PhysRevE.83.016113</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Sznajd model for opinion dynamics has attracted a large interest as a
simple realization of the psychological principle of social validation. As its
most salient feature, it has been claimed that the Sznajd model is
qualitatively different from other ordering processes, because it is the only
one featuring outflow of information as opposed to inflow. We show that this
claim is unfounded by presenting a generalized zero-temperature Glauber-type of
dynamics which yields results indistinguishable from those of the Sznajd model.
In one-dimension we also derive an exact expression for the exit probability of
the Sznajd model, that turns out to coincide with the result of an analytical
approach based on the Kirkwood approximation. This observation raises
interesting questions about the applicability and limitations of this approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2019</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2019</id><created>2010-12-09</created><authors><author><keyname>Kalmukov</keyname><forenames>Yordan</forenames></author><author><keyname>Rachev</keyname><forenames>Boris</forenames></author></authors><title>Comparative Analysis of Existing Methods and Algorithms for Automatic
  Assignment of Reviewers to Papers</title><categories>cs.DL</categories><journal-ref>Journal of Information Technologies and Control, 2/2010, ISSN
  1312-2622, pp. 20-31</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article focuses on the importance of the automatic assignment of
reviewers to papers for increasing the assignment accuracy therefore the
quality of the scientific event itself. It discusses the main aspects that
influence the assignment accuracy, performs a detailed analysis of the methods
of describing papers and reviewers' competences used by the existing conference
management systems and suggests some improvements in the way the similarity
factors are calculated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2034</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2034</id><created>2010-12-09</created><authors><author><keyname>Fortnow</keyname><forenames>Lance</forenames></author><author><keyname>Santhanam</keyname><forenames>Rahul</forenames></author></authors><title>Robust Simulations and Significant Separations</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define and study a new notion of &quot;robust simulations&quot; between complexity
classes which is intermediate between the traditional notions of
infinitely-often and almost-everywhere, as well as a corresponding notion of
&quot;significant separations&quot;. A language L has a robust simulation in a complexity
class C if there is a language in C which agrees with L on arbitrarily large
polynomial stretches of input lengths. There is a significant separation of L
from C if there is no robust simulation of L in C. The new notion of simulation
is a cleaner and more natural notion of simulation than the infinitely-often
notion. We show that various implications in complexity theory such as the
collapse of PH if NP = P and the Karp-Lipton theorem have analogues for robust
simulations. We then use these results to prove that most known separations in
complexity theory, such as hierarchy theorems, fixed polynomial circuit lower
bounds, time-space tradeoffs, and the theorems of Allender and Williams, can be
strengthened to significant separations, though in each case, an almost
everywhere separation is unknown.
  Proving our results requires several new ideas, including a completely
different proof of the hierarchy theorem for non-deterministic polynomial time
than the ones previously known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2042</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2042</id><created>2010-12-09</created><authors><author><keyname>Giannakopoulos</keyname><forenames>George</forenames><affiliation>NCSR Demokritos, Greece</affiliation></author><author><keyname>Vouros</keyname><forenames>George</forenames><affiliation>University of the Aegean, Greece</affiliation></author><author><keyname>Karkaletsis</keyname><forenames>Vangelis</forenames><affiliation>NCSR Demokritos, Greece</affiliation></author></authors><title>MUDOS-NG: Multi-document Summaries Using N-gram Graphs (Tech Report)</title><categories>cs.CL cs.AI</categories><comments>Technical Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report describes the MUDOS-NG summarization system, which applies a set
of language-independent and generic methods for generating extractive
summaries. The proposed methods are mostly combinations of simple operators on
a generic character n-gram graph representation of texts. This work defines the
set of used operators upon n-gram graphs and proposes using these operators
within the multi-document summarization process in such subtasks as document
analysis, salient sentence selection, query expansion and redundancy control.
Furthermore, a novel chunking methodology is used, together with a novel way to
assign concepts to sentences for query expansion. The experimental results of
the summarization system, performed upon widely used corpora from the Document
Understanding and the Text Analysis Conferences, are promising and provide
evidence for the potential of the generic methods introduced. This work aims to
designate core methods exploiting the n-gram graph representation, providing
the basis for more advanced summarization systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2057</identifier>
 <datestamp>2011-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2057</id><created>2010-12-09</created><updated>2011-02-14</updated><authors><author><keyname>Gayo-Avello</keyname><forenames>Daniel</forenames></author><author><keyname>Brenes</keyname><forenames>David J.</forenames></author><author><keyname>Fern&#xe1;ndez-Fern&#xe1;ndez</keyname><forenames>Diego</forenames></author><author><keyname>Fern&#xe1;ndez-Men&#xe9;ndez</keyname><forenames>Mar&#xed;a E.</forenames></author><author><keyname>Garc&#xed;a-Su&#xe1;rez</keyname><forenames>Rodrigo</forenames></author></authors><title>De retibus socialibus et legibus momenti</title><categories>cs.SI physics.soc-ph</categories><comments>Changes made for third revision: Brief description of the dataset
  employed added to Introduction. Minor changes to the description of
  preparation of the bit.ly datasets. Minor changes to the captions of Tables 1
  and 3. Brief addition in the Conclusions section (future line of work added).
  Added references 16 and 18. Some typos and grammar polished</comments><journal-ref>2011 EPL 94 38001</journal-ref><doi>10.1209/0295-5075/94/38001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online Social Networks (OSNs) are a cutting edge topic. Almost everybody
--users, marketers, brands, companies, and researchers-- is approaching OSNs to
better understand them and take advantage of their benefits. Maybe one of the
key concepts underlying OSNs is that of influence which is highly related,
although not entirely identical, to those of popularity and centrality.
Influence is, according to Merriam-Webster, &quot;the capacity of causing an effect
in indirect or intangible ways&quot;. Hence, in the context of OSNs, it has been
proposed to analyze the clicks received by promoted URLs in order to check for
any positive correlation between the number of visits and different &quot;influence&quot;
scores. Such an evaluation methodology is used in this paper to compare a
number of those techniques with a new method firstly described here. That new
method is a simple and rather elegant solution which tackles with influence in
OSNs by applying a physical metaphor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2062</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2062</id><created>2010-12-09</created><updated>2011-10-19</updated><authors><author><keyname>Lelarge</keyname><forenames>Marc</forenames></author></authors><title>Diffusion and Cascading Behavior in Random Networks</title><categories>math.PR cs.DM cs.GT cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The spread of new ideas, behaviors or technologies has been extensively
studied using epidemic models. Here we consider a model of diffusion where the
individuals' behavior is the result of a strategic choice. We study a simple
coordination game with binary choice and give a condition for a new action to
become widespread in a random network. We also analyze the possible equilibria
of this game and identify conditions for the coexistence of both strategies in
large connected sets. Finally we look at how can firms use social networks to
promote their goals with limited information. Our results differ strongly from
the one derived with epidemic models and show that connectivity plays an
ambiguous role: while it allows the diffusion to spread, when the network is
highly connected, the diffusion is also limited by high-degree nodes which are
very stable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2073</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2073</id><created>2010-12-09</created><authors><author><keyname>Khoozani</keyname><forenames>M. Heidari</forenames></author><author><keyname>Rashidinejad</keyname><forenames>A.</forenames></author><author><keyname>Froushani</keyname><forenames>M. H. Lotfi</forenames></author><author><keyname>Pad</keyname><forenames>P.</forenames></author><author><keyname>Marvasti</keyname><forenames>F.</forenames></author></authors><title>Almost-Optimum Signature Matrices in Binary-Input Synchronous Overloaded
  CDMA</title><categories>cs.IT math.IT</categories><comments>6 Pages, 5 Figures, Submitted to the International Conference on
  Telecommunications 2011 (ICT-2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The everlasting bandwidth limitations in wireless communication networks has
directed the researchers' thrust toward analyzing the prospect of overloaded
Code Division Multiple Access (CDMA). In this paper, we have proposed a Genetic
Algorithm in search of optimum signature matrices for binary-input synchronous
CDMA. The main measure of optimality considered in this paper, is the per-user
channel capacity of the overall multiple access system. Our resulting matrices
differ from the renowned Welch Bound Equality (WBE) codes, regarding the fact
that our attention is specifically aimed at binary, rather than Gaussian, input
distributions. Since design based on channel capacity is computationally
expensive, we have focused on introducing a set of alternative criteria that
not only speed up the matrix formation procedure, but also maintain optimality.
The Bit Error Rate (BER) and Constellation measures are our main criteria
propositions. Simulation results also verify our analytical justifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2081</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2081</id><created>2010-12-09</created><authors><author><keyname>Derksen</keyname><forenames>Harm</forenames></author></authors><title>The Graph Isomorphism Problem and approximate categories</title><categories>math.CO cs.CC math.AC math.RA</categories><comments>29 pages</comments><msc-class>05C60, 05C83, 68Q15, 68Q19, 03C13, 20G15, 13A50, 16G10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is unknown whether two graphs can be tested for isomorphism in polynomial
time. A classical approach to the Graph Isomorphism Problem is the
d-dimensional Weisfeiler-Lehman algorithm. The d-dimensional WL-algorithm can
distinguish many pairs of graphs, but the pairs of non-isomorphic graphs
constructed by Cai, Furer and Immerman it cannot distinguish. If d is fixed,
then the WL-algorithm runs in polynomial time. We will formulate the Graph
Isomorphism Problem as an Orbit Problem: Given a representation V of an
algebraic group G and two elements v_1,v_2 in V, decide whether v_1 and v_2 lie
in the same G-orbit. Then we attack the Orbit Problem by constructing certain
approximate categories C_d(V), d=1,2,3,... whose objects include the elements
of V. We show that v_1 and v_2 are not in the same orbit by showing that they
are not isomorphic in the category C_d(V) for some d. For every d this gives us
an algorithm for isomorphism testing. We will show that the WL-algorithms
reduce to our algorithms, but that our algorithms cannot be reduced to the
WL-algorithms. Unlike the Weisfeiler-Lehman algorithm, our algorithm can
distinguish the Cai-Furer-Immerman graphs in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2086</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2086</id><created>2010-12-09</created><authors><author><keyname>Peres</keyname><forenames>Yuval</forenames></author><author><keyname>Quas</keyname><forenames>Anthony</forenames></author></authors><title>Entropy Rate for Hidden Markov Chains with rare transitions</title><categories>cs.IT math.IT math.PR</categories><comments>To appear in Hidden Markov Processes by Marcus, Petersen and Weissman
  (eds); CUP</comments><msc-class>94A17</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider Hidden Markov Chains obtained by passing a Markov Chain with rare
transitions through a noisy memoryless channel. We obtain asymptotic estimates
for the entropy of the resulting Hidden Markov Chain as the transition rate is
reduced to zero.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2088</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2088</id><created>2010-12-09</created><updated>2010-12-10</updated><authors><author><keyname>Bre&#x161;ar</keyname><forenames>Bo&#x161;tjan</forenames></author><author><keyname>Kardo&#x161;</keyname><forenames>Franti&#x161;ek</forenames></author><author><keyname>Katreni&#x10d;</keyname><forenames>J&#xe1;n</forenames></author><author><keyname>Semani&#x161;in</keyname><forenames>Gabriel</forenames></author></authors><title>Minimum k-path vertex cover</title><categories>math.CO cs.CC cs.DM</categories><comments>submitted manuscript</comments><journal-ref>Discrete Applied Mathematics Volume 159, Issue 12, 28 July 2011,
  Pages 1189-1195</journal-ref><doi>10.1016/j.dam.2011.04.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A subset S of vertices of a graph G is called a k-path vertex cover if every
path of order k in G contains at least one vertex from S. Denote by \psi_k(G)
the minimum cardinality of a k-path vertex cover in G. It is shown that the
problem of determining \psi_k(G) is NP-hard for each k \geq 2, while for trees
the problem can be solved in linear time. We investigate upper bounds on the
value of \psi_k(G) and provide several estimations and exact values of
\psi_k(G). We also prove that \psi_3(G) \leq (2n + m)/6, for every graph G with
n vertices and m edges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2096</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2096</id><created>2010-12-09</created><authors><author><keyname>Albu</keyname><forenames>Roxana</forenames><affiliation>LAAS</affiliation></author><author><keyname>Labit</keyname><forenames>Yann</forenames><affiliation>LAAS</affiliation></author><author><keyname>Thierry</keyname><forenames>Gayraud</forenames><affiliation>LAAS</affiliation></author><author><keyname>Pascal</keyname><forenames>Berthou</forenames><affiliation>LAAS</affiliation></author></authors><title>An Energy-efficient Clock Synchronization Protocol for Wireless Sensor
  Networks</title><categories>cs.NI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The behavior of Wireless Sensor Networks (WSN) is nowadays widely analyzed.
One of the most important issues is related to their energy consumption, as
this has a major impact on the network lifetime. Another important application
requirement is to ensure data sensing synchronization, which leads to
additional energy consumption as a high number of messages is sent and received
at each node. Our proposal consists in implementing a combined synchronization
protocol based on the IEEE 1588 standard that was designed for wired networks
and the PBS (Pairwise Broadcast Synchronization) protocol that was designed for
sensor networks, as none of them is able to provide the needed synchronization
accuracy for our application on its own. The main goals of our new
synchronization protocol are: to ensure the accuracy of local clocks up to a
tenth of a microsecond and to provide an important energy saving. Our results
obtained using NS-2 (Network Simulator) show that the performance of our
solution (IEEE 1588-PBS) matches our application requirements with regard to
the synchronization, with a significant improvement in energy saving.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2112</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2112</id><created>2010-12-09</created><authors><author><keyname>Ambainis</keyname><forenames>Andris</forenames></author><author><keyname>Magnin</keyname><forenames>Lo&#xef;ck</forenames></author><author><keyname>Roetteler</keyname><forenames>Martin</forenames></author><author><keyname>Roland</keyname><forenames>J&#xe9;r&#xe9;mie</forenames></author></authors><title>Symmetry-assisted adversaries for quantum state generation</title><categories>quant-ph cs.CC</categories><comments>35 pages, 5 figures</comments><journal-ref>26th IEEE Conference on Computational Complexity (CCC'11), pages
  167-177, 2011</journal-ref><doi>10.1109/CCC.2011.24</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new quantum adversary method to prove lower bounds on the
query complexity of the quantum state generation problem. This problem
encompasses both, the computation of partial or total functions and the
preparation of target quantum states. There has been hope for quite some time
that quantum state generation might be a route to tackle the {\sc Graph
Isomorphism} problem. We show that for the related problem of {\sc Index
Erasure} our method leads to a lower bound of $\Omega(\sqrt N)$ which matches
an upper bound obtained via reduction to quantum search on $N$ elements. This
closes an open problem first raised by Shi [FOCS'02].
  Our approach is based on two ideas: (i) on the one hand we generalize the
known additive and multiplicative adversary methods to the case of quantum
state generation, (ii) on the other hand we show how the symmetries of the
underlying problem can be leveraged for the design of optimal adversary
matrices and dramatically simplify the computation of adversary bounds. Taken
together, these two ideas give the new result for {\sc Index Erasure} by using
the representation theory of the symmetric group. Also, the method can lead to
lower bounds even for small success probability, contrary to the standard
adversary method. Furthermore, we answer an open question due to \v{S}palek
[CCC'08] by showing that the multiplicative version of the adversary method is
stronger than the additive one for any problem. Finally, we prove that the
multiplicative bound satisfies a strong direct product theorem, extending a
result by \v{S}palek to quantum state generation problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2124</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2124</id><created>2010-12-09</created><authors><author><keyname>Cole</keyname><forenames>Richard</forenames></author><author><keyname>Fleischer</keyname><forenames>Lisa</forenames></author><author><keyname>Rastogi</keyname><forenames>Ashish</forenames></author></authors><title>Discrete Price Updates Yield Fast Convergence in Ongoing Markets with
  Finite Warehouses</title><categories>cs.GT</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper shows that in suitable markets, even with out-of-equilibrium trade
allowed, a simple price update rule leads to rapid convergence toward the
equilibrium. In particular, this paper considers a Fisher market repeated over
an unbounded number of time steps, with the addition of finite sized warehouses
to enable non-equilibrium trade. The main result is that suitable tatonnement
style price updates lead to convergence in a significant subset of markets
satisfying the Weak Gross Substitutes property. Throughout this process the
warehouse are always able to store or meet demand imbalances (the needed
capacity depends on the initial imbalances). Finally, our price update rule is
robust in a variety of regards: 1. The updates for each good depend only on
information about that good (its current price, its excess demand since its
last update) and occur asynchronously from updates to other prices. 2. The
process is resilient to error in the excess demand data. 3. Likewise, the
process is resilient to discreteness, i.e. a limit to divisibility, both of
goods and money.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2138</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2138</id><created>2010-12-09</created><updated>2010-12-13</updated><authors><author><keyname>Zografos</keyname><forenames>Vasileios</forenames></author><author><keyname>Nordberg</keyname><forenames>Klas</forenames></author><author><keyname>Ellis</keyname><forenames>Liam</forenames></author></authors><title>Sparse motion segmentation using multiple six-point consistencies</title><categories>cs.CV</categories><journal-ref>VECTaR workshop (with ACCV) 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method for segmenting an arbitrary number of moving objects in
image sequences using the geometry of 6 points in 2D to infer motion
consistency. The method has been evaluated on the Hopkins 155 database and
surpasses current state-of-the-art methods such as SSC, both in terms of
overall performance on two and three motions but also in terms of maximum
errors. The method works by finding initial clusters in the spatial domain, and
then classifying each remaining point as belonging to the cluster that
minimizes a motion consistency score. In contrast to most other motion
segmentation methods that are based on an affine camera model, the proposed
method is fully projective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2142</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2142</id><created>2010-12-09</created><authors><author><keyname>Banerjee</keyname><forenames>Sujogya</forenames></author><author><keyname>Shirazipourazad</keyname><forenames>Shahrzad</forenames></author><author><keyname>Ghosh</keyname><forenames>Pavel</forenames></author><author><keyname>Sen</keyname><forenames>Arunabha</forenames></author></authors><title>NP-completeness Proof: RBCDN Reduction Problem</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational complexity of the design problem for a network with a target
value of Region-Based Component Decomposition Number (RBCDN) has been proven to
be NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2148</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2148</id><created>2010-12-09</created><authors><author><keyname>Cao</keyname><forenames>Yongzhi</forenames></author><author><keyname>Chen</keyname><forenames>Guoqing</forenames></author><author><keyname>Kerre</keyname><forenames>Etienne</forenames></author></authors><title>Bisimulations for fuzzy transition systems</title><categories>cs.AI</categories><comments>13 double column pages</comments><journal-ref>IEEE Trans. Fuzzy Syst., vol. 19, no. 3, pp. 540-552, 2011</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  There has been a long history of using fuzzy language equivalence to compare
the behavior of fuzzy systems, but the comparison at this level is too coarse.
Recently, a finer behavioral measure, bisimulation, has been introduced to
fuzzy finite automata. However, the results obtained are applicable only to
finite-state systems. In this paper, we consider bisimulation for general fuzzy
systems which may be infinite-state or infinite-event, by modeling them as
fuzzy transition systems. To help understand and check bisimulation, we
characterize it in three ways by enumerating whole transitions, comparing
individual transitions, and using a monotonic function. In addition, we address
composition operations, subsystems, quotients, and homomorphisms of fuzzy
transition systems and discuss their properties connected with bisimulation.
The results presented here are useful for comparing the behavior of general
fuzzy systems. In particular, this makes it possible to relate an infinite
fuzzy system to a finite one, which is easier to analyze, with the same
behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2152</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2152</id><created>2010-12-09</created><updated>2011-05-02</updated><authors><author><keyname>Rieffel</keyname><forenames>Eleanor</forenames></author><author><keyname>Biehl</keyname><forenames>Jacob</forenames></author><author><keyname>van Melle</keyname><forenames>William</forenames></author><author><keyname>Lee</keyname><forenames>Adam J.</forenames></author></authors><title>Secured histories: computing group statistics on encrypted data while
  preserving individual privacy</title><categories>cs.CR</categories><comments>Technical aspects remain largely unchanged. Revised version gives
  greater emphasis to the application of these methods to presences systems
  that support workplace communication and collaboration. The writing is more
  succinct throughout: the revised version is 8 pages, plus references. The
  final version of this paper will be appear at SECOTS 2011 as &quot;Secured
  histories for presence systems.&quot;</comments><report-no>FXPAL-TR-10-007</report-no><msc-class>94A60</msc-class><acm-class>H.3.4; D.4.6</acm-class><journal-ref>SECOTS 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As sensors become ever more prevalent, more and more information will be
collected about each of us. A longterm research question is how best to support
beneficial uses while preserving individual privacy. Presence systems are an
emerging class of applications that support collaboration. These systems
leverage pervasive sensors to estimate end-user location, activities, and
available communication channels. Because such presence data are sensitive, to
achieve wide-spread adoption, sharing models must reflect the privacy and
sharing preferences of the users. To reflect users' collaborative relationships
and sharing desires, we introduce CollaPSE security, in which an individual has
full access to her own data, a third party processes the data without learning
anything about the data values, and users higher up in the hierarchy learn only
statistical information about the employees under them. We describe simple
schemes that efficiently realize CollaPSE security for time series data. We
implemented these protocols using readily available cryptographic functions,
and integrated the protocols with FXPAL's myUnity presence system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2162</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2162</id><created>2010-12-09</created><authors><author><keyname>Cao</keyname><forenames>Yongzhi</forenames></author><author><keyname>Ezawa</keyname><forenames>Yoshinori</forenames></author></authors><title>Nondeterministic fuzzy automata</title><categories>cs.AI</categories><comments>14 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Fuzzy automata have long been accepted as a generalization of
nondeterministic finite automata. A closer examination, however, shows that the
fundamental property---nondeterminism---in nondeterministic finite automata has
not been well embodied in the generalization. In this paper, we introduce
nondeterministic fuzzy automata with or without $\el$-moves and fuzzy languages
recognized by them. Furthermore, we prove that (deterministic) fuzzy automata,
nondeterministic fuzzy automata, and nondeterministic fuzzy automata with
$\el$-moves are all equivalent in the sense that they recognize the same class
of fuzzy languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2164</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2164</id><created>2010-12-09</created><authors><author><keyname>Chai</keyname><forenames>Chin Choy</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author></authors><title>On Two-way Communications for Cooperative Multiple Source Pairs Through
  a Multi-antenna Relay</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study amplified-and-forward (AF)-based two-way relaying (TWR) with
multiple source pairs, which are exchanging information through the relay. Each
source has single antenna and the relay has multi-antenna. The optimal
beamforming matrix structure that achieves maximum
signal-to-interference-plus-noise ratio (SINR) for TWR with multiple source
pairs is derived. We then present two new non-zero-forcing based beamforming
schemes for TWR, which take into consideration the tradeoff between preserving
the desired signals and suppressing inter-pair interference between different
source pairs. Joint grouping and beamforming scheme is proposed to achieve a
better signal-to-interference-plus-noise ratio (SINR) when the total number of
source pairs is large and the signal-to-noise ratio (SNR) at the relay is low.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2171</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2171</id><created>2010-12-09</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>A Robust and Efficient Trust Management Scheme for Peer-to-Peer Networks</title><categories>cs.DC cs.CR</categories><comments>15 pages, 8 figures, 1 table. 11th International Workshop on
  Information Security Applications (WISA 2010), Jeju Island, Korea, August 24
  - 26, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Studies on the large scale peer-to-peer (P2P) network like Gnutella have
shown the presence of large number of free riders. Moreover, the open and
decentralized nature of P2P network is exploited by malicious users who
distribute unauthentic or harmful contents. Despite the existence of a number
of trust management schemes in the literature for combating against free riding
and distribution of malicious files, these mechanisms are not scalable due to
their high computational, communication and storage overhead. These schemes
also do not consider effect of trust management on quality-of-service (QoS) of
the search. This paper presents a trust management scheme for P2P networks that
minimizes distribution of spurious files by a novel technique called topology
adaptation. It also reduces search time since most of the queries are resolved
within the community of trustworthy peers. Simulation results indicate that the
trust management overhead due to the pr oposed mechanism decreases considerably
as the network topology stabilizes. The mechanism is also found to be robust
even in presence of a large percentage of malicious peers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2177</identifier>
 <datestamp>2012-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2177</id><created>2010-12-09</created><updated>2012-05-04</updated><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>Privacy Preservation Technologies in Internet of Things</title><categories>cs.CR cs.NI</categories><comments>withdrawn by author. arXiv admin note: v1 significant text overlap
  with &quot;Internet of things and privacy preserving technologies&quot;, by V.
  Oleshchuk, without attribution</comments><journal-ref>International Journal BITM Transactions on EECC, Vol. 1, No. 4,
  pp. 496 - 504, August 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the beginning of the Internet thirty years ago, we have witnessed a
number of changes in the application of communication technologies. Today, the
Internet can be described to a large extent as a ubiquitous infrastructure that
is always accessible. After the era of connecting places and connecting people,
the Internet of the future will also connect things. The idea behind the
resulting Internet of Things is to seamlessly gather and use information about
objects of the real world during their entire lifecycle. In this paper, we
consider different approaches to technological protection of user data privacy
in the world of Internet of Things. In particular,we consider what kind of
security problems are being faced and what level of protection can be provided
by applying approaches based on secure multi-party computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2197</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2197</id><created>2010-12-10</created><authors><author><keyname>Ma</keyname><forenames>Liang</forenames><affiliation>IRCCyN, DIE</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Bennis</keyname><forenames>Fouad</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Hu</keyname><forenames>Bo</forenames><affiliation>DIE</affiliation></author><author><keyname>Zhang</keyname><forenames>Wei</forenames><affiliation>DIE</affiliation></author></authors><title>Integrating digital human modeling into virtual environment for
  ergonomic oriented design</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>World Conference on Innovative Virtual Reality, France (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Virtual human simulation integrated into virtual reality applications is
mainly used for virtual representation of the user in virtual environment or
for interactions between the user and the virtual avatar for cognitive tasks.
In this paper, in order to prevent musculoskeletal disorders, the integration
of virtual human simulation and VR application is presented to facilitate
physical ergonomic evaluation, especially for physical fatigue evaluation of a
given population. Immersive working environments are created to avoid expensive
physical mock-up in conventional evaluation methods. Peripheral motion capture
systems are used to capture natural movements and then to simulate the physical
operations in virtual human simulation. Physical aspects of human's movement
are then analyzed to determine the effort level of each key joint using inverse
kinematics. The physical fatigue level of each joint is further analyzed by
integrating a fatigue and recovery model on the basis of physical task
parameters. All the process has been realized based on VRHIT platform and a
case study is presented to demonstrate the function of the physical fatigue for
a given population and its usefulness for worker selection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2199</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2199</id><created>2010-12-10</created><authors><author><keyname>Pashkevich</keyname><forenames>Anatoly</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Klimchik</keyname><forenames>Alexandr</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Caro</keyname><forenames>St&#xe9;phane</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Stiffness modelling of parallelogram-based parallel manipulators</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>3-rd European Conference on Mechanism Science, Cluj-Napoca :
  Romania (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents a methodology to enhance the stiffness analysis of
parallel manipulators with parallelogram-based linkage. It directly takes into
account the influence of the external loading and allows computing both the
non-linear ``load-deflection&quot; relation and relevant rank-deficient stiffness
matrix. An equivalent bar-type pseudo-rigid model is also proposed to describe
the parallelogram stiffness by means of five mutually coupled virtual springs.
The contributions of this paper are highlighted with a parallelogram-type
linkage used in a manipulator from the Orthoglide family.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2202</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2202</id><created>2010-12-10</created><updated>2010-12-13</updated><authors><author><keyname>Matsakis</keyname><forenames>Nicolaos</forenames></author></authors><title>Transforming a random graph drawing into a Lombardi drawing</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The visualization of any graph plays important role in various aspects, such
as graph drawing software. Complex systems (like large databases or networks)
that have a graph structure should be properly visualized in order to avoid
obfuscation. One way to provide an aesthetic improvement to a graph
visualization is to apply a force-directed drawing algorithm to it. This
method, that emerged in the 60's views graphs as spring systems that exert
forces (repulsive or attractive) to the nodes.
  A Lombardi drawing of a graph is a drawing where the edges are drawn as
circular arcs (straight edges are considered circular arcs of infinite radius)
with perfect angular resolution. This means, that consecutive edges around a
vertex are equally spaced around it. In other words, each angle between the
tangents of two consecutive edges is equal to $2\pi/d$ where d is the degree of
that specific vertex. The requirement of using circular edges in graphs when we
want to provide perfect angular resolution is necessary, since even cycle
graphs cannot be drawn with straight edges when perfect angular resolution is
needed.
  In this survey, we provide an algorithm that takes as input a random drawing
of a graph and provides its Lombardi drawing, giving a proper visualization of
the graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2203</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2203</id><created>2010-12-10</created><authors><author><keyname>Kurganskyy</keyname><forenames>Oleksiy</forenames></author></authors><title>A collective of stateless automata in a $n$-dimensional environment as a
  distributed dynamic automaton-like object: a model and its corollaries</title><categories>cs.FL cs.DC</categories><comments>9 pages, 2 figures</comments><msc-class>68Q45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work a collective of interacting stateless automata in a discrete
geometric $n$-dimenstional environment is considered as an integral
automaton-like computational dynamic object. For such distributed on the
environment object different approaches to definition of the measure of state
transition are possible. We propose an approach for defining what a state is.
The approach is based on the concept of relativity in Poincar\'e's
interpretation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2248</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2248</id><created>2010-12-10</created><updated>2011-03-01</updated><authors><author><keyname>Jawurek</keyname><forenames>Marek</forenames></author><author><keyname>Johns</keyname><forenames>Martin</forenames></author><author><keyname>Kerschbaum</keyname><forenames>Florian</forenames></author></authors><title>Plug-in privacy for Smart Metering billing</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional electricity meters are replaced by Smart Meters in customers'
households. Smart Meters collects fine-grained utility consumption profiles
from customers, which in turn enables the introduction of dynamic, time-of-use
tariffs. However, the fine-grained usage data that is compiled in this process
also allows to infer the inhabitant's personal schedules and habits. We propose
a privacy-preserving protocol that enables billing with time-of-use tariffs
without disclosing the actual consumption profile to the supplier. Our approach
relies on a zero-knowledge proof based on Pedersen Commitments performed by a
plug-in privacy component that is put into the communication link between Smart
Meter and supplier's back-end system. We require no changes to the Smart Meter
hardware and only small changes to the software of Smart Meter and back-end
system. In this paper we describe the functional and privacy requirements, the
specification and security proof of our solution and give a performance
evaluation of a prototypical implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2251</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2251</id><created>2010-12-10</created><authors><author><keyname>Reddy</keyname><forenames>P. Venkata Subba</forenames></author><author><keyname>Iyer</keyname><forenames>K. Viswanathan</forenames></author></authors><title>Conditional coloring of some parameterized graphs</title><categories>cs.DM</categories><comments>Communicated to Utilitas Mathematica</comments><msc-class>68R10, 05C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For integers k&gt;0 and r&gt;0, a conditional (k,r)-coloring of a graph G is a
proper k-coloring of the vertices of G such that every vertex v of degree d(v)
in G is adjacent to vertices with at least min{r,d(v)} different colors. The
smallest integer k for which a graph G has a conditional (k,r)-coloring is
called the rth order conditional chromatic number, denoted by $\chi_r(G)$. For
different values of r we obtain $\chi_r(G)$ of certain parameterized graphs
viz., Windmill graph, line graph of Windmill graph, middle graph of Friendship
graph, middle graph of a cycle, line graph of Friendship graph, middle graph of
complete k-partite graph and middle graph of a bipartite graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2256</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2256</id><created>2010-12-10</created><authors><author><keyname>Orgerie</keyname><forenames>Anne-C&#xe9;cile</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme</affiliation></author><author><keyname>Lef&#xe8;vre</keyname><forenames>Laurent</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme</affiliation></author></authors><title>A year in the life of a large scale experimental distributed system: the
  Grid'5000 platform in 2008</title><categories>cs.NI cs.DC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report presents the usage results of Grid'5000 over year 2008. Usage of
the main operationnal Grid'5000 sites (Bordeaux, Lille, Lyon, Nancy, Orsay,
Rennes, Sophia-Antipolis, Toulouse) is presented and analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2270</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2270</id><created>2010-12-10</created><authors><author><keyname>Oberhuber</keyname><forenames>Tom&#xe1;&#x161;</forenames></author><author><keyname>Suzuki</keyname><forenames>Atsushi</forenames></author><author><keyname>Vacata</keyname><forenames>Jan</forenames></author></authors><title>New Row-grouped CSR format for storing the sparse matrices on GPU with
  implementation in CUDA</title><categories>cs.DC</categories><comments>21 pages, 8 figures, 7 tables</comments><acm-class>D.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we present a new format for storing sparse matrices. The
format is designed to perform well mainly on the GPU devices. We present its
implementation in CUDA. The performance has been tested on 1,600 different
types of matrices and we compare our format with the Hybrid format. We give
detailed comparison of both formats and show their strong and weak parts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2273</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2273</id><created>2010-12-10</created><authors><author><keyname>Hasta</keyname><forenames>D. T.</forenames></author><author><keyname>Mutiara</keyname><forenames>A. B.</forenames></author></authors><title>Performance Evaluation of Parallel Message Passing and Thread
  Programming Model on Multicore Architectures</title><categories>cs.DC</categories><comments>46 pages 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current trend of multicore architectures on shared memory systems
underscores the need of parallelism. While there are some programming model to
express parallelism, thread programming model has become a standard to support
these system such as OpenMP, and POSIX threads. MPI (Message Passing Interface)
which remains the dominant model used in high-performance computing today faces
this challenge.
  Previous version of MPI which is MPI-1 has no shared memory concept, and
Current MPI version 2 which is MPI-2 has a limited support for shared memory
systems. In this research, MPI-2 version of MPI will be compared with OpenMP to
see how well does MPI perform on multicore / SMP (Symmetric Multiprocessor)
machines.
  Comparison between OpenMP for thread programming model and MPI for message
passing programming model will be conducted on multicore shared memory machine
architectures to see who has a better performance in terms of speed and
throughput. Application used to assess the scalability of the evaluated
parallel programming solutions is matrix multiplication with customizable
matrix dimension.
  Many research done on a large scale parallel computing which using high scale
benchmark such as NSA Parallel Benchmark (NPB) for their testing standarization
[1]. This research will be conducted on a small scale parallel computing that
emphasize more on the performance evaluation between MPI and OpenMPI parallel
programming model using self created benchmark.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2283</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2283</id><created>2010-12-10</created><authors><author><keyname>Galam</keyname><forenames>Serge</forenames></author><author><keyname>Martins</keyname><forenames>Andre C. R.</forenames></author></authors><title>Artifacts of opinion dynamics at one dimension</title><categories>physics.soc-ph cs.SI</categories><comments>4 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dynamics of a one dimensional Ising spin system is investigated using
three families of local update rules, the Galam majority rules, Glauber inflow
influences and Sznadj outflow drives. Given an initial density p of up spins
the probability to reach a final state with all spins up is calculated exactly
for each choice. The various formulas are compared to a series of previous
calculations obtained analytically using the Kirkwood approximation. They turn
out to be identical. The apparent discrepancy with the Galam unifying frame is
addressed. The difference in the results seems to stem directly from the
implementation of the local update rule used to perform the associated
numerical simulations. The findings lead to view the non stepwise exit
probability as an artifact of the one dimensional finite size system with fixed
spins. The suitability and the significance to perform numerical simulations to
model social behavior without solid constraints is discussed and the question
of what it means to have a mean field result in this context is addressed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2289</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2289</id><created>2010-12-10</created><authors><author><keyname>Eisenbrand</keyname><forenames>Friedrich</forenames></author><author><keyname>H&#xe4;hnle</keyname><forenames>Nicolai</forenames></author><author><keyname>Niemeier</keyname><forenames>Martin</forenames></author></authors><title>Covering Cubes and the Closest Vector Problem</title><categories>cs.DS cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide the currently fastest randomized (1+epsilon)-approximation
algorithm for the closest vector problem in the infinity norm. The running time
of our method depends on the dimension n and the approximation guarantee
epsilon by 2^O(n) (log 1/epsilon)^O(n)$ which improves upon the
(2+1/epsilon)^O(n) running time of the previously best algorithm by Bl\&quot;omer
and Naewe.
  Our algorithm is based on a solution of the following geometric covering
problem that is of interest of its own: Given epsilon in (0,1), how many
ellipsoids are necessary to cover the cube [-1+epsilon, 1-epsilon]^n such that
all ellipsoids are contained in the standard unit cube [-1,1]^n? We provide an
almost optimal bound for the case where the ellipsoids are restricted to be
axis-parallel.
  We then apply our covering scheme to a variation of this covering problem
where one wants to cover [-1+epsilon,1-epsilon]^n with parallelepipeds that, if
scaled by two, are still contained in the unit cube. Thereby, we obtain a
method to boost any 2-approximation algorithm for closest-vector in the
infinity norm to a (1+epsilon)-approximation algorithm that has the desired
running time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2291</identifier>
 <datestamp>2011-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2291</id><created>2010-12-10</created><updated>2011-07-15</updated><authors><author><keyname>Wullschleger</keyname><forenames>J&#xfc;rg</forenames></author></authors><title>Bitwise Quantum Min-Entropy Sampling and New Lower Bounds for Random
  Access Codes</title><categories>quant-ph cs.CC</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Min-entropy sampling gives a bound on the min-entropy of a randomly chosen
subset of a string, given a bound on the min-entropy of the whole string.
K\&quot;onig and Renner showed a min-entropy sampling theorem that holds relative to
quantum knowledge. Their result achieves the optimal rate, but it can only be
applied if the bits are sampled in blocks, and only gives weak bounds for the
non-smooth min-entropy. We give two new quantum min-entropy sampling theorems
that do not have the above weaknesses. The first theorem shows that the result
by K\&quot;onig and Renner also applies to bitwise sampling, and the second theorem
gives a strong bound for the non-smooth min-entropy. Our results imply a new
lower bound for k-out-of-n random access codes: while previous results by
Ben-Aroya, Regev, and de Wolf showed that the decoding probability is
exponentially small in k if the storage rate is smaller than 0.7, our results
imply that this holds for any storage rate strictly smaller than 1, which is
optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2294</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2294</id><created>2010-12-10</created><updated>2011-08-15</updated><authors><author><keyname>Obua</keyname><forenames>Steven</forenames></author></authors><title>Syntax and Semantics of Babel-17</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present Babel-17, the first programming language for purely functional
structured programming (PFSP). Earlier work illustrated PFSP in the framework
of a toy research language. Babel-17 takes this earlier work to a new level by
showing how PFSP can be combined with pattern matching, object oriented
programming, and features like concurrency, lazy evaluation, memoization and
support for lenses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2299</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2299</id><created>2010-12-10</created><authors><author><keyname>Drabent</keyname><forenames>Wlodzimierz</forenames></author></authors><title>A Simple Correctness Proof for Magic Transformation</title><categories>cs.LO cs.DB cs.PL</categories><comments>Submitted to &quot;Theory and Practice of Logic Programming&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents a simple and concise proof of correctness of the magic
transformation. We believe it may provide a useful example of formal reasoning
about logic programs.
  The correctness property concerns the declarative semantics. The proof,
however, refers to the operational semantics (LD-resolution) of the source
programs. Its conciseness is due to applying a suitable proof method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2321</identifier>
 <datestamp>2011-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2321</id><created>2010-12-10</created><updated>2011-11-30</updated><authors><author><keyname>Lonati</keyname><forenames>Violetta</forenames></author><author><keyname>Mandrioli</keyname><forenames>Dino</forenames></author><author><keyname>Pradella</keyname><forenames>Matteo</forenames></author></authors><title>Precedence Automata and Languages</title><categories>cs.FL</categories><comments>Extended version of the paper which appeared in Proceedings of CSR
  2011, Lecture Notes in Computer Science, vol. 6651, pp. 291-304, 2011.
  Theorem 1 has been corrected and a complete proof is given in Appendix</comments><msc-class>68Q5, 68Q45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Operator precedence grammars define a classical Boolean and deterministic
context-free family (called Floyd languages or FLs). FLs have been shown to
strictly include the well-known visibly pushdown languages, and enjoy the same
nice closure properties. We introduce here Floyd automata, an equivalent
operational formalism for defining FLs. This also permits to extend the class
to deal with infinite strings to perform for instance model checking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2332</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2332</id><created>2010-12-10</created><updated>2011-03-02</updated><authors><author><keyname>Cho</keyname><forenames>Jeong-woo</forenames></author><author><keyname>Yi</keyname><forenames>Yung</forenames></author></authors><title>On the Shapley-like Payoff Mechanisms in Peer-Assisted Services with
  Multiple Content Providers</title><categories>cs.GT cs.NI</categories><comments>13 pages, 4 figures, an extended version of the paper to be presented
  in ICST GameNets 2011, Shanghai, China, April 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies an incentive structure for cooperation and its stability
in peer-assisted services when there exist multiple content providers, using a
coalition game theoretic approach. We first consider a generalized coalition
structure consisting of multiple providers with many assisting peers, where
peers assist providers to reduce the operational cost in content distribution.
To distribute the profit from cost reduction to players (i.e., providers and
peers), we then establish a generalized formula for individual payoffs when a
&quot;Shapley-like&quot; payoff mechanism is adopted. We show that the grand coalition is
unstable, even when the operational cost functions are concave, which is in
sharp contrast to the recently studied case of a single provider where the
grand coalition is stable. We also show that irrespective of stability of the
grand coalition, there always exist coalition structures which are not
convergent to the grand coalition. Our results give us an important insight
that a provider does not tend to cooperate with other providers in
peer-assisted services, and be separated from them. To further study the case
of the separated providers, three examples are presented; (i) underpaid peers,
(ii) service monopoly, and (iii) oscillatory coalition structure. Our study
opens many new questions such as realistic and efficient incentive structures
and the tradeoffs between fairness and individual providers' competition in
peer-assisted services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2350</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2350</id><created>2010-12-10</created><authors><author><keyname>Gou</keyname><forenames>Tiangao</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author><author><keyname>Jeon</keyname><forenames>Sang-Woon</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author></authors><title>Aligned Interference Neutralization and the Degrees of Freedom of the
  2x2x2 Interference Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the 2x2x2 interference channel, i.e., the multihop interference
channel formed by concatenation of two 2-user interference channels achieves
the min-cut outer bound value of 2 DoF, for almost all values of channel
coefficients, for both time-varying or fixed channel coefficients. The key to
this result is a new idea, called aligned interference neutralization, that
provides a way to align interference terms over each hop in a manner that
allows them to be cancelled over the air at the last hop.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2363</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2363</id><created>2010-12-10</created><updated>2011-05-04</updated><authors><author><keyname>Lancichinetti</keyname><forenames>Andrea</forenames></author><author><keyname>Radicchi</keyname><forenames>Filippo</forenames></author><author><keyname>Ramasco</keyname><forenames>Jose' Javier</forenames></author><author><keyname>Fortunato</keyname><forenames>Santo</forenames></author></authors><title>Finding statistically significant communities in networks</title><categories>physics.soc-ph cs.IR cs.SI q-bio.QM</categories><comments>24 pages, 25 figures, 1 table. Final version published in PLoS One.
  The code of OSLOM is freely available at http://www.oslom.org</comments><journal-ref>PLoS One 6(4), e18961 (2011)</journal-ref><doi>10.1371/journal.pone.0018961</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Community structure is one of the main structural features of networks,
revealing both their internal organization and the similarity of their
elementary units. Despite the large variety of methods proposed to detect
communities in graphs, there is a big need for multi-purpose techniques, able
to handle different types of datasets and the subtleties of community
structure. In this paper we present OSLOM (Order Statistics Local Optimization
Method), the first method capable to detect clusters in networks accounting for
edge directions, edge weights, overlapping communities, hierarchies and
community dynamics. It is based on the local optimization of a fitness function
expressing the statistical significance of clusters with respect to random
fluctuations, which is estimated with tools of Extreme and Order Statistics.
OSLOM can be used alone or as a refinement procedure of partitions/covers
delivered by other techniques. We have also implemented sequential algorithms
combining OSLOM with other fast techniques, so that the community structure of
very large networks can be uncovered. Our method has a comparable performance
as the best existing algorithms on artificial benchmark graphs. Several
applications on real networks are shown as well. OSLOM is implemented in a
freely available software (http://www.oslom.org), and we believe it will be a
valuable tool in the analysis of networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2377</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2377</id><created>2010-12-10</created><authors><author><keyname>Fu</keyname><forenames>Bin</forenames></author></authors><title>Multivariate Polynomial Integration and Derivative Are Polynomial Time
  Inapproximable unless P=NP</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the complexity of integration and derivative for multivariate
polynomials in the standard computation model. The integration is in the unit
cube $[0,1]^d$ for a multivariate polynomial, which has format $f(x_1,\cdots,
x_d)=p_1(x_1,\cdots, x_d)p_2(x_1,\cdots, x_d)\cdots p_k(x_1,\cdots, x_d)$,
where each $p_i(x_1,\cdots, x_d)=\sum_{j=1}^d q_j(x_j)$ with all single
variable polynomials $q_j(x_j)$ of degree at most two and constant
coefficients. We show that there is no any factor polynomial time approximation
for the integration $\int_{[0,1]^d}f(x_1,\cdots,x_d)d_{x_1}\cdots d_{x_d}$
unless $P=NP$. For the complexity of multivariate derivative, we consider the
functions with the format $f(x_1,\cdots, x_d)=p_1(x_1,\cdots,
x_d)p_2(x_1,\cdots, x_d)\cdots p_k(x_1,\cdots, x_d),$ where each
$p_i(x_1,\cdots, x_d)$ is of degree at most $2$ and $0,1$ coefficients. We also
show that unless $P=NP$, there is no any factor polynomial time approximation
to its derivative ${\partial f^{(d)}(x_1,\cdots, x_d)\over \partial x_1\cdots
\partial x_d}$ at the origin point $(x_1,\cdots, x_d)=(0,\cdots,0)$. Our
results show that the derivative may not be easier than the integration in high
dimension. We also give some tractable cases of high dimension integration and
derivative.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2381</identifier>
 <datestamp>2012-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2381</id><created>2010-12-10</created><updated>2012-03-04</updated><authors><author><keyname>Bodirsky</keyname><forenames>Manuel</forenames></author><author><keyname>Pinsker</keyname><forenames>Michael</forenames></author><author><keyname>Tsankov</keyname><forenames>Todor</forenames></author></authors><title>Decidability of definability</title><categories>math.LO cs.LO</categories><comments>full journal version (17 pages)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a fixed countably infinite structure \Gamma\ with finite relational
signature \tau, we study the following computational problem: input are
quantifier-free \tau-formulas \phi_0,\phi_1,...,\phi_n that define relations
R_0,R_1,...,R_n over \Gamma. The question is whether the relation R_0 is
primitive positive definable from R_1,...,R_n, i.e., definable by a first-order
formula that uses only relation symbols for R_1,..., R_n, equality,
conjunctions, and existential quantification (disjunction, negation, and
universal quantification are forbidden).
  We show decidability of this problem for all structures \Gamma\ that have a
first-order definition in an ordered homogeneous structure \Delta\ with a
finite relational signature whose age is a Ramsey class and determined by
finitely many forbidden substructures. Examples of structures \Gamma\ with this
property are the order of the rationals, the random graph, the homogeneous
universal poset, the random tournament, all homogeneous universal C-relations,
and many more. We also obtain decidability of the problem when we replace
primitive positive definability by existential positive, or existential
definability. Our proof makes use of universal algebraic and model theoretic
concepts, Ramsey theory, and a recent characterization of Ramsey classes in
topological dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2384</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2384</id><created>2010-12-10</created><updated>2011-01-05</updated><authors><author><keyname>Foster</keyname><forenames>David V.</forenames></author><author><keyname>Foster</keyname><forenames>Jacob G.</forenames></author><author><keyname>Grassberger</keyname><forenames>Peter</forenames></author><author><keyname>Paczuski</keyname><forenames>Maya</forenames></author></authors><title>Clustering Drives Assortativity and Community Structure in Ensembles of
  Networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>4 pages, 4 figures</comments><doi>10.1103/PhysRevE.84.066117</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clustering, assortativity, and communities are key features of complex
networks. We probe dependencies between these attributes and find that
ensembles with strong clustering display both high assortativity by degree and
prominent community structure, while ensembles with high assortativity are much
less biased towards clustering or community structure. Further, clustered
networks can amplify small homophilic bias for trait assortativity. This marked
asymmetry suggests that transitivity, rather than homophily, drives the
standard nonsocial/social network dichotomy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2394</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2394</id><created>2010-12-10</created><authors><author><keyname>Fu</keyname><forenames>Bin</forenames></author></authors><title>NE is not NP Turing Reducible to Nonexpoentially Dense NP Sets</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A long standing open problem in the computational complexity theory is to
separate NE from BPP, which is a subclass of $NP_T(NP\cap P/poly)$. In this
paper, we show that $NE\not\subseteq NP_(NP \cap$
Nonexponentially-Dense-Class), where Nonexponentially-Dense-Class is the class
of languages A without exponential density (for each constant c&gt;0,$|A^{\le
n}|\le 2^{n^c}$ for infinitely many integers n).
  Our result implies $NE\not\subseteq NP_T({pad(NP, g(n))})$ for every time
constructible super-polynomial function g(n) such as
$g(n)=n^{\ceiling{\log\ceiling{\log n}}}$, where Pad(NP, g(n)) is class of all
languages $L_B=\{s10^{g(|s|)-|s|-1}:s\in B\}$ for $B\in NP$. We also show
$NE\not\subseteq NP_T(P_{tt}(NP)\cap Tally)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2405</identifier>
 <datestamp>2011-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2405</id><created>2010-12-10</created><updated>2011-05-19</updated><authors><author><keyname>Tsomokos</keyname><forenames>Dimitris I.</forenames></author></authors><title>Quantum walks on complex networks with connection instabilities and
  community structure</title><categories>quant-ph cond-mat.dis-nn cs.SI physics.data-an physics.soc-ph</categories><comments>5.1 pages, 4 figures; Shift of focus towards quantum networks
  (published version)</comments><journal-ref>Phys. Rev. A 83, 052315 (2011)</journal-ref><doi>10.1103/PhysRevA.83.052315</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A continuous-time quantum walk is investigated on complex networks with the
characteristic property of community structure, which is shared by most
real-world networks. Motivated by the prospect of viable quantum networks, I
focus on the effects of network instabilities in the form of broken links, and
examine the response of the quantum walk to such failures. It is shown that the
reconfiguration of the quantum walk is determined by the community structure of
the network. In this context, quantum walks based on the adjacency and
Laplacian matrices of the network are compared, and their responses to link
failures is analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2422</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2422</id><created>2010-12-10</created><authors><author><keyname>Jiang</keyname><forenames>Shuai</forenames></author><author><keyname>Alekseyev</keyname><forenames>Max A.</forenames></author></authors><title>Weighted genomic distance can hardly impose a bound on the proportion of
  transpositions</title><categories>q-bio.GN cs.DM q-bio.PE</categories><comments>The 15th Annual International Conference on Research in Computational
  Molecular Biology (RECOMB), 2011. (to appear)</comments><journal-ref>Lecture Notes in Computer Science 6577 (2011), pp. 124-133</journal-ref><doi>10.1007/978-3-642-20036-6_13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Genomic distance between two genomes, i.e., the smallest number of genome
rearrangements required to transform one genome into the other, is often used
as a measure of evolutionary closeness of the genomes in comparative genomics
studies. However, in models that include rearrangements of significantly
different &quot;power&quot; such as reversals (that are &quot;weak&quot; and most frequent
rearrangements) and transpositions (that are more &quot;powerful&quot; but rare), the
genomic distance typically corresponds to a transformation with a large
proportion of transpositions, which is not biologically adequate.
  Weighted genomic distance is a traditional approach to bounding the
proportion of transpositions by assigning them a relative weight {\alpha} &gt; 1.
A number of previous studies addressed the problem of computing weighted
genomic distance with {\alpha} \leq 2.
  Employing the model of multi-break rearrangements on circular genomes, that
captures both reversals (modelled as 2-breaks) and transpositions (modelled as
3-breaks), we prove that for {\alpha} \in (1,2], a minimum-weight
transformation may entirely consist of transpositions, implying that the
corresponding weighted genomic distance does not actually achieve its purpose
of bounding the proportion of transpositions. We further prove that for
{\alpha} \in (1,2), the minimum-weight transformations do not depend on a
particular choice of {\alpha} from this interval. We give a complete
characterization of such transformations and show that they coincide with the
transformations that at the same time have the shortest length and make the
smallest number of breakages in the genomes.
  Our results also provide a theoretical foundation for the empirical
observation that for {\alpha} &lt; 2, transpositions are favored over reversals in
the minimum-weight transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2440</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2440</id><created>2010-12-11</created><authors><author><keyname>Chatzigiannakis</keyname><forenames>Ioannis</forenames></author><author><keyname>Michail</keyname><forenames>Othon</forenames></author><author><keyname>Nikolaou</keyname><forenames>Stavros</forenames></author><author><keyname>Pavlogiannis</keyname><forenames>Andreas</forenames></author><author><keyname>Spirakis</keyname><forenames>Paul G.</forenames></author></authors><title>Passively Mobile Communicating Machines that Use Restricted Space</title><categories>cs.CC cs.DC</categories><comments>17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new theoretical model for passively mobile Wireless Sensor
Networks, called PM, standing for Passively mobile Machines. The main
modification w.r.t. the Population Protocol model is that agents now, instead
of being automata, are Turing Machines. We provide general definitions for
unbounded memories, but we are mainly interested in computations upper-bounded
by plausible space limitations. However, we prove that our results hold for
more general cases. We focus on complete communication graphs and define the
complexity classes PMSPACE(f(n)) parametrically, consisting of all predicates
that are stably computable by some PM protocol that uses O(f(n)) memory on each
agent. We provide a protocol that generates unique ids from scratch only by
using O(log n) memory, and use it to provide an exact characterization for the
classes PMSPACE(f(n)) when f(n)={\Omega}(log n): they are precisely the classes
of all symmetric predicates in NSPACE(nf(n)). In this way, we provide a space
hierarchy for the PM model when the memory bounds are {\Omega}(log n). Finally,
we explore the computability of the PM model when the protocols use o(loglog n)
space per machine and prove that SEMILINEAR=PMSPACE(f(n)) when f(n)=o(loglog
n), where SEMILINEAR denotes the class of the semilinear predicates. In fact,
we prove that this bound acts as a threshold, so that SEMILINEAR is a proper
subset of PMSPACE(f(n)) when f(n)=O(loglog n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2453</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2453</id><created>2010-12-11</created><updated>2012-01-29</updated><authors><author><keyname>Thielemann</keyname><forenames>Henning</forenames></author></authors><title>How to refine polynomial functions</title><categories>math.FA cs.SC</categories><comments>16 pages, 2 figures, accepted by WSPC/WS-IJWMIP</comments><msc-class>65T60</msc-class><acm-class>G.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research on refinable functions in wavelet theory is mostly focused to
localized functions. However it is known, that polynomial functions are
refinable, too. In our paper we investigate on conversions between refinement
masks and polynomials and their uniqueness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2460</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2460</id><created>2010-12-11</created><authors><author><keyname>Kaminski</keyname><forenames>Marcin</forenames></author><author><keyname>Paulusma</keyname><forenames>Daniel</forenames></author><author><keyname>Thilikos</keyname><forenames>Dimitrios M.</forenames></author></authors><title>Contracting planar graphs to contractions of triangulations</title><categories>math.CO cs.DM</categories><comments>11 pages, 3 figues</comments><msc-class>68R10, 05C85</msc-class><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For every graph $H$, there exists a polynomial-time algorithm deciding if a
planar input graph $G$ can be contracted to~$H$. However, the degree of the
polynomial depends on the size of $H$. In this paper, we identify a class of
graphs $\cal C$ such that for every $H \in \cal C$, there exists an algorithm
deciding in time $f(|V(H)|) \cdot |V(G)|^{\bigO{1}}$ whether a planar graph $G$
can be contracted to~$H$. (The function $f(\cdot)$ does not depend on $G$.) The
class $\cal C$ is the closure of planar triangulated graphs under taking of
contractions. In fact, we prove that a graph $H \in \cal C$ if and only if
there exists a constant $c_H$ such that if the tree-width of a graph is at
least $c_H$, it contains $H$ as a contraction. We also provide a
characterization of $\cal C$ in terms of minimal forbidden contractions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2462</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2462</id><created>2010-12-11</created><updated>2011-02-01</updated><authors><author><keyname>Masuda</keyname><forenames>Naoki</forenames></author><author><keyname>Redner</keyname><forenames>S.</forenames></author></authors><title>Can Partisan Voting Lead to Truth?</title><categories>physics.soc-ph cs.SI</categories><comments>8 pages in IOP format, 3 figures; version 2 contains minor changes,
  for publication in JSTAT</comments><journal-ref>J. Stat. Mech. L02002 (2011)</journal-ref><doi>10.1088/1742-5468/2011/02/L02002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study an extension of the voter model in which each agent is endowed with
an innate preference for one of two states that we term as &quot;truth&quot; or
&quot;falsehood&quot;. Due to interactions with neighbors, an agent that innately prefers
truth can be persuaded to adopt a false opinion (and thus be discordant with
its innate preference) or the agent can possess an internally concordant &quot;true&quot;
opinion. Parallel states exist for agents that inherently prefer falsehood. We
determine the conditions under which a population of such agents can ultimately
reach a consensus for the truth, a consensus for falsehood, or reach an impasse
where an agent tends to adopt the opinion that is in internal concordance with
its innate preference so that consensus is never achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2464</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2464</id><created>2010-12-11</created><updated>2011-01-12</updated><authors><author><keyname>Karmeshu</keyname></author><author><keyname>Sharma</keyname><forenames>Shachi</forenames></author></authors><title>Long Tail Behavior of Queue Lengths in Broadband Networks: Tsallis
  Entropy Framework</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A maximum entropy framework based on Tsallis entropy is proposed to depict
long tail behavior of queue lengths in broadband networks. Queue length
expression as measured in terms of number of packets involves Hurwitz-zeta
function. When the entropy parameter q in Tsallis entropy is less than unity,
the distribution of packets yields power law behavior. In the limit q tending
to unity, Tsallis entropy expression reduces to one due to Shannon and
well-known results of M/M/1 queuing system are recovered. Relationship between
Tsallis entropy parameter q and Hurst parameter H (measure of self-similarity)
is postulated. A numerical procedure based on Newton-Raphson method is outlined
to compute Lagrange's parameter b. Various relationships between traffic
intensity r and Lagrange's parameter b are examined using data generated from
mean number of packets from storage model due to Norros. It is found that best
fit corresponds to r being a linear combination of decaying exponential and
power exponent in b for different values of entropy parameter q. Explicit
expression for the probability that queue size exceeds a certain value is
derived and it is established that it asymptotically follows power law for q
less than one. The system utilization shows an interesting behavior when the
parameter r is varied. It attains lower values than that of M/M/1 system for
smaller values of r whereas situation reverses for higher values of r.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2469</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2469</id><created>2010-12-11</created><authors><author><keyname>Amyot</keyname><forenames>Daniel</forenames></author><author><keyname>Echihabi</keyname><forenames>Ali</forenames></author><author><keyname>He</keyname><forenames>Yong</forenames></author></authors><title>UCMExporter: Supporting Scenario Transformations from Use Case Maps</title><categories>cs.SE</categories><comments>16 pages, 9 figures, Nouvelles TEchnnologies de la R\'Epartition
  (NOTERE'04), Sa\&quot;idia, Morocco, June 2004, pp. 390-405</comments><acm-class>D.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Use Case Maps (UCM) scenario notation is applicable to many requirements
engineering activities. However, other scenario notations, such as Message
Sequence Charts (MSC) and UML Sequence Diagrams (SD), have shown to be better
suited for detailed design. In order to use the notation that is best
appropriate for each phase in an efficient manner, a mechanism has to be
devised to automatically transfer the knowledge acquired during the
requirements analysis phase (using UCM) to the design phase (using MSC or SD).
This paper introduces UCMEXPORTER, a new tool that implements such a mechanism
and reduces the gap between high-level requirements and detailed design.
UCMEXPORTER automatically transforms individual UCM scenarios to UML Sequence
Diagrams, MSC scenarios, and even TTCN-3 test skeletons. We highlight the
current capabilities of the tool as well as architectural solutions addressing
the main challenges faced during such transformation, including the handling of
concurrent scenario paths, the generation of customized messages, and tool
interoperability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2491</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2491</id><created>2010-12-11</created><authors><author><keyname>Zografos</keyname><forenames>Vasileios</forenames></author><author><keyname>Buxton</keyname><forenames>Bernard</forenames></author></authors><title>Affine Invariant, Model-Based Object Recognition Using Robust Metrics
  and Bayesian Statistics</title><categories>cs.CV</categories><journal-ref>Image Analysis and Recognition Lecture Notes in Computer Science,
  2005, Volume 3656/2005, 407-414</journal-ref><doi>10.1007/11559573_51</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit the problem of model-based object recognition for intensity images
and attempt to address some of the shortcomings of existing Bayesian methods,
such as unsuitable priors and the treatment of residuals with a non-robust
error norm. We do so by using a refor- mulation of the Huber metric and
carefully chosen prior distributions. Our proposed method is invariant to
2-dimensional affine transforma- tions and, because it is relatively easy to
train and use, it is suited for general object matching problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2496</identifier>
 <datestamp>2010-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2496</id><created>2010-12-11</created><updated>2010-12-15</updated><authors><author><keyname>Diaz</keyname><forenames>Daniel</forenames></author><author><keyname>Abreu</keyname><forenames>Salvador</forenames></author><author><keyname>Codognet</keyname><forenames>Philippe</forenames></author></authors><title>On the Implementation of GNU Prolog</title><categories>cs.PL cs.AI</categories><comments>30 pages, 3 figures, To appear in Theory and Practice of Logic
  Programming (TPLP); Keywords: Prolog, logic programming system, GNU, ISO,
  WAM, native code compilation, Finite Domain constraints</comments><acm-class>D.3.4; D.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  GNU Prolog is a general-purpose implementation of the Prolog language, which
distinguishes itself from most other systems by being, above all else, a
native-code compiler which produces standalone executables which don't rely on
any byte-code emulator or meta-interpreter. Other aspects which stand out
include the explicit organization of the Prolog system as a multipass compiler,
where intermediate representations are materialized, in Unix compiler
tradition. GNU Prolog also includes an extensible and high-performance finite
domain constraint solver, integrated with the Prolog language but implemented
using independent lower-level mechanisms. This article discusses the main
issues involved in designing and implementing GNU Prolog: requirements, system
organization, performance and portability issues as well as its position with
respect to other Prolog system implementations and the ISO standardization
initiative.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2499</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2499</id><created>2010-12-11</created><authors><author><keyname>Akbar</keyname><forenames>Z.</forenames></author><author><keyname>Firmansyah</keyname><forenames>I.</forenames></author><author><keyname>Hermanto</keyname><forenames>B.</forenames></author><author><keyname>Handoko</keyname><forenames>L. T.</forenames></author></authors><title>openPC : a toolkit for public cluster with full ownership</title><categories>cs.DC</categories><comments>8 pages</comments><report-no>FISIKALIPI-10037</report-no><journal-ref>Int. J. Comput. Theor. Eng. 2 (2010) 978-985</journal-ref><doi>10.7763/IJCTE.2010.V2.273</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The openPC is a set of open source tools that realizes a parallel machine and
distributed computing environment divisible into several independent blocks of
nodes, and each of them is remotely but fully in any means accessible for users
with a full ownership policy. The openPC components address fundamental issues
relating to security, resource access, resource allocation, compatibilities
with heterogeneous middlewares, user-friendly and integrated web-based
interfaces, hardware control and monitoring systems. These components have been
deployed successfully to the LIPI Public Cluster which is open for public use.
In this paper, the unique characteristics of openPC due to its rare
requirements are introduced, its components and a brief performance analysis
are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2509</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2509</id><created>2010-12-11</created><authors><author><keyname>Asuncion</keyname><forenames>Arthur U.</forenames><affiliation>Department of Computer Science, University of California, Irvine</affiliation></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames><affiliation>Department of Computer Science, University of California, Irvine</affiliation></author></authors><title>Nonadaptive Mastermind Algorithms for String and Vector Databases, with
  Case Studies</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study sparsity-exploiting Mastermind algorithms for
attacking the privacy of an entire database of character strings or vectors,
such as DNA strings, movie ratings, or social network friendship data. Based on
reductions to nonadaptive group testing, our methods are able to take advantage
of minimal amounts of privacy leakage, such as contained in a single bit that
indicates if two people in a medical database have any common genetic
mutations, or if two people have any common friends in an online social
network. We analyze our Mastermind attack algorithms using theoretical
characterizations that provide sublinear bounds on the number of queries needed
to clone the database, as well as experimental tests on genomic information,
collaborative filtering data, and online social networks. By taking advantage
of the generally sparse nature of these real-world databases and modulating a
parameter that controls query sparsity, we demonstrate that relatively few
nonadaptive queries are needed to recover a large majority of each database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2510</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2510</id><created>2010-12-12</created><authors><author><keyname>Lakhtaria</keyname><forenames>Kamaljit I.</forenames></author></authors><title>Analyzing Zone Routing Protocol in MANET Applying Authentic Parameter</title><categories>cs.NI</categories><comments>5 Pages, 5 Figures</comments><report-no>GJCST Journal, Volume No 10, Issue 4, Year 2010</report-no><journal-ref>Kamaljit I. Lakhtaria, &quot;Analyzing Zone Routing Protocol in MANET
  Applying Authentic Parameter&quot;, in Global Journal of Computer Science &amp;
  Technology, Online ISSN: 0975-4172 Print ISSN: 0975-4350, Vol. 10, Issue 4,
  Year 2010, Page no. 114-118</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Routing is the main part of wireless adhoc network conventionally there are
two approaches first one is Proactive and another one is Reactive. Both these
approaches have some substantial disadvantage and to overcome hybrid routing
protocols designed. ZRP (Zone Routing Protocol) is one of the hybrid routing
protocols, it takes advantage of proactive approach by providing reliability
within the scalable zone, and for beyond the scalable zone it looks for the
reactive approach. It (ZRP) uses the proactive and the reactive routing
according to the need of the application at that particular instance of time
depending upon the prevailing scenario. This work revolves around the
performance of ZRP against realistic parameters by varying various attributes
such as Zone Radius of ZRP in different node density. Results vary as we change
the node density on Qualnet 4.0 network simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2514</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2514</id><created>2010-12-12</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author><author><keyname>Balamuralidhar</keyname><forenames>P.</forenames></author><author><keyname>Chandra</keyname><forenames>M. Girish</forenames></author><author><keyname>G.</keyname><forenames>Harihara S.</forenames></author><author><keyname>Reddy</keyname><forenames>Harish</forenames></author></authors><title>Context Aware End-to-End Connectivity Management</title><categories>cs.LG cs.NI</categories><comments>8 pages, 3 figures. Second International Conference on Embedded
  Systems, Mobile Communication and Computing (ICEMCC), pp. 85 - 95, Bangalore,
  August 2007, India</comments><report-no>ISSN: 0973-208X</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a dynamic heterogeneous environment, such as pervasive and ubiquitous
computing, context-aware adaptation is a key concept to meet the varying
requirements of different users. Connectivity is an important context source
that can be utilized for optimal management of diverse networking resources.
Application QoS (Quality of service) is another important issue that should be
taken into consideration for design of a context-aware system. This paper
presents connectivity from the view point of context awareness, identifies
various relevant raw connectivity contexts, and discusses how high-level
context information can be abstracted from the raw context information.
Further, rich context information is utilized in various policy representation
with respect to user profile and preference, application characteristics,
device capability, and network QoS conditions. Finally, a context-aware
end-to-end evaluation algorithm is presented for adaptive connectivity
management in a multi-access wireless network. Unlike the currently existing
algorithms, the proposed algorithm takes into account user QoS parameters, and
therefore, it is more practical.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2516</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2516</id><created>2010-12-12</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>An Efficient Security Mechanism for High-Integrity Wireless Sensor
  Networks</title><categories>cs.CR</categories><comments>9 pages, 1 figure. Proceedings of the International Conference on
  Advances in Information and Communication Technologies (ICICOT), Manipal,
  India, December 28-30, 2007, pp. 86 - 97</comments><report-no>ISBN: 0230-63437-0</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor networks (WSNs) have recently attracted a lot of interest in
the research community due their wide range of applications. Unfortunately,
these networks are vulnerable to numerous security threats that can adversely
affect their proper functioning. This problem is more critical if the network
is deployed for some mission-critical applications such as in a tactical
battlefield. Random failure of nodes and intentional compromise of nodes by an
insider attack in a WSN pose particularly difficult challenges to security
engineers as these attacks cannot be defended by traditional cryptography-based
mechanisms. In this paper, a security solution is proposed for detecting
compromised and faulty nodes in a WSN. The mechanism also isolates a
compromised node from the network so that it cannot participate in any network
activity. The proposed mechanism is based on misbehavior classification,
behaviour monitoring and trust management. It involves minimum computation and
communication overhead and is ideally suited for a resource-constrained,
high-integrity WSN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2518</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2518</id><created>2010-12-12</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Shomik</forenames></author></authors><title>A Survey on Cross-Layer Design Frameworks for Multimedia Applications
  over Wireless Networks</title><categories>cs.NI cs.MM</categories><comments>16 pages, 9 figures</comments><journal-ref>International Journal of Computer Science and Information
  Technology (IJCSIT), Vol: 1, No:1, pp. 29-42, June 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the last few years, the Internet throughput, usage and reliability have
increased almost exponentially. The introduction of broadband wireless mobile
ad hoc networks (MANETs) and cellular networks together with increased
computational power have opened the door for a new breed of applications to be
created, namely real-time multimedia applications. Delivering real-time
multimedia traffic over a complex network like the Internet is a particularly
challenging task since these applications have strict quality -of-service (QoS)
requirements on bandwidth, delay, and delay jitter. Traditional IP-based best
effort service will not be able to meet these stringent requirements. The
time-varying nature of wireless channels and resource constrained wireless
devices make the problem even more difficult. To improve perceived media
quality by end users over wireless Internet, QoS supports can be addressed in
different layers, including application layer, transport layer and link layer.
Cross layer design is a well-known approach to achieve this adaptation. In
cross-layer design, the challenges from the physical wireless medium and the
QoS-demands from the applications are taken into account so that the rate,
power, and coding at the physical layer can adapted to meet the requirements of
the applications given the current channel and network conditions. A number of
propositions for cross-layer designs exist in the literature. In this paper, an
extensive review has been made on these cross-layer architectures that combine
the application-layer, transport layer and the link layer controls.
Particularly the issues like channel estimation techniques, adaptive controls
at the application and link layers for energy efficiency, priority based
scheduling, transmission rate control at the transport layer, and adaptive
automatic repeat request (ARQ) are discussed in detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2519</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2519</id><created>2010-12-12</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>A Distributed Trust and Reputation Framework for Mobile Ad Hoc Networks</title><categories>cs.CR</categories><comments>10 pages, 7 figures, 1 table. Proceedings of the First International
  Workshop on Trust Management in Peer-to-Peer Systems (IWTMP2PS), pp. 538-547,
  July, 2010, Chennai, India</comments><report-no>Springer Communication and Information Control Systems (CCIS)
  Series, Vol. 89</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a multi-hop mobile ad hoc network (MANET), mobile nodes cooperate to form
a network without using any infrastructure such as access points or base
stations. The mobility of the nodes and the fundamentally limited capacity of
the wireless medium, together with wireless transmission effects such as
attenuation, multi-path propagation, and interference combine to create
sig-nificant challenges for security in MANETs. Traditional cryptographic
mecha-nisms such as authentication and encryption are not capable of handling
some kinds of attacks such as packet dropping by malicious nodes in MANETs.
This paper presents a mechanism for detecting malicious packet dropping attacks
in MANETs. The mechanism is depends on a trust module on each node, which is
based on the reputation value computed for that node by its neighbors. The
reputation value of a node is computed based on its packet forwarding behavior
in the network. The reputation information is gathered, stored and exchanged
between the nodes, and computed under different scenario. The proposed
pro-tocol has been simulated in a network simulator. The simulation results
show the efficiency of its performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2520</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2520</id><created>2010-12-12</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>A Trust-Based Detection Algorithm of Selfish Packet Dropping Nodes in a
  Peer-to-Peer Wireless Mesh Network</title><categories>cs.CR cs.NI</categories><comments>10 pages, 6 pages, 3 tables. Proceedings of the First Workshop on
  Trust Management in Peer-to-Peer Systems (IWTMP2PS), pp. 528- 537, July 2010,
  Chennai, India</comments><report-no>Springer Communication and Information Control Systems (CCIS)
  Series, Vol. 89</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless mesh networks (WMNs) are evolving as a key technology for
next-generation wireless networks showing raid progress and numerous
applications. These networks have the potential to provide robust and
high-throughput data delivery to wireless users. In a WMN, high speed routers
equipped with advanced antennas, communicate with each other in a multi-hop
fashion over wireless channels and form a broadband backhaul. However, the
throughput of a WMN may be severely degraded due to presence of some selfish
routers that avoid forwarding packets for other nodes even as they send their
own traffic through the network. This paper presents an algorithm for detection
of selfish nodes in a WMN that uses statistical theory of inference for
reliable clustering of the nodes based on local observations. Simulation
results show that the algorithm has a high detection rate and a low false
positive rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2524</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2524</id><created>2010-12-12</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author><author><keyname>Sayyad</keyname><forenames>Munir</forenames></author><author><keyname>Hooli</keyname><forenames>Basavaraj</forenames></author></authors><title>Convergence and Next Generation Networks</title><categories>cs.NI</categories><comments>67 pages, 11 figures, 4 tables. Bootk Chapter published in the book
  &quot;Future trends and Challenegs for ICT Standardization&quot;, pp. 107 - 192</comments><journal-ref>BooK: Future Trends and Challenges for ICT Standardization.
  Editor: Ramjee Prasad, River Publishers, Aalborg, Denmark, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The communications sector is undergoing significant changes, with the
emergence of a number of platforms available to provide a different range of
services. Some of these platforms are complementary to each other, while others
are competitive, or can provide a valid substitute for some of the services
provided. Up till now, the most important communications platform in most of
the developing countries has been the public switched telecommunication network
(PSTN) which provides access to all households and buildings. This universality
in providing access has also meant that the network has generally been
designated as one for universal service.This chapter focuses on the area where
the most significant changes are taking place in the communication sector. The
objective of this chapter is neither to give an overview of all communication
platforms, nor is it aimed to assess the relative extent to which different
platforms complement or compete with each other. The central theme of this
chapter is to examine the developments in what is commonly refereed to as next
generation access networks and next generation core networks and their role in
convergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2527</identifier>
 <datestamp>2010-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2527</id><created>2010-12-12</created><updated>2010-12-15</updated><authors><author><keyname>Matsakis</keyname><forenames>Nicolaos</forenames></author></authors><title>Solving the Rural Postman problem using the Adleman-Lipton model</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this survey we investigate the application of the Adleman-Lipton model on
Rural Postman problem, which given an undirected graph $G=(V,E)$ with positive
integer lengths on each of its edges and a subset $E^{'}\subseteq E$, asks
whether there exists a hamiltonian circuit that includes each edge of $E^{'}$
and has total cost (sum of edge lengths) less or equal to a given integer B (we
are allowed to use any edges of the set $E-E^{'}$, but we must use all edges of
the set $E'$). The Rural Postman problem (RPP) is a very interesting
NP-complete problem used, especially, in network optimization. RPP is actually
a special case of the Route Inspection problem, where we need to traverse all
edges of an undirected graph at a minimum total cost. As all NP-complete
problems, it currently admits no efficient solution and if actually $P\neq NP$
as it is widely accepted to be, it cannot admit a polynomial time algorithm to
solve it. The application of the Adleman-Lipton model on this problem, provides
an efficient way to solve RPP, as it is the fact for many other hard problems
on which the Adleman-Lipton model has been applied. In this survey, we provide
a polynomial algorithm based on the Lipton-Adleman model, which solves the RPP
in $\mathcal{O}(n^{2})$ time, where n refers to the input of the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2528</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2528</id><created>2010-12-12</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>A Secure Aggregation Protocol for Wireless Sensor Networks</title><categories>cs.CR cs.NI</categories><comments>5 pages, 3 figures, 1 table. Proceedings of the 10th International
  Symposium on Wireless Personal Multimedia Communications (WPMC'07), pp. 715 -
  719, Jaipur, India, December 3-6, 2007, Track: W-2F: Wireless Ad Hoc and
  Sensor Network Poster. Editors: Uday B. Desai, Sudhir Dixit, Shinsuke Hara,
  and Neeli R. Prasad</comments><report-no>ISSN: 1882- 5621</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of a wireless sensor network (WSN) is to provide the users with
access to the information of interest from data gathered by spatially
distributed sensors. Generally the users require only certain aggregate
functions of this distributed data. Computation of this aggregate data under
the end-to-end information flow paradigm by communicating all the relevant data
to a central collector node is a highly inefficient solution for this purpose.
An alternative proposition is to perform in-network computation. This, however,
raises questions such as: what is the optimal way to compute an aggregate
function from a set of statistically correlated values stored in different
nodes; what is the security of such aggregation as the results sent by a
compromised or faulty node in the network can adversely affect the accuracy of
the computed result. In this paper, we have presented an energy-efficient
aggregation algorithm for WSNs that is secure and robust against malicious
insider attack by any compromised or faulty node in the network. In contrast to
the traditional snapshot aggregation approach in WSNs, a node in the proposed
algorithm instead of unicasting its sensed information to its parent node,
broadcasts its estimate to all its neighbors. This makes the system more
fault-tolerant and increase the information availability in the network. The
simulations conducted on the proposed algorithm have produced results that
demonstrate its effectiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2529</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2529</id><created>2010-12-12</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>A Survey on Reputation and Trust-Based Systems for Wireless
  Communication Networks</title><categories>cs.CR cs.NI</categories><comments>16 pages, 3 figures</comments><report-no>ISBN: 81-89766-74-0</report-no><journal-ref>International Journal HIT Transaction on ECCN (Electronics,
  Communication, Computers and Networking), pp. 92-111. Volume 1, No: 2, April
  2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional approach of providing network security has been to borrow tools
and mechanisms from cryptography. However, the conventional view of security
based on cryptography alone is not sufficient for the defending against unique
and novel types of misbehavior exhibited by nodes encountered in wireless
communication networks. Reputation-based frameworks where nodes maintain
reputation of other nodes and use it to evaluate their trustworthiness are
deployed to provide scalable, diverse and a generalized approach for countering
different types of misbehavior resulting form malicious and selfish nodes in
these networks. In this paper, we present a comprehensive discussion on
reputation and trust-based systems for wireless communication networks.
Different classes of reputation system are described along with their unique
characteristics and working principles. A number of currently used reputation
systems are critically reviewed and compared with respect to their
effectiveness and efficiency of performance. Some open problems in the area of
reputation and trust-based system within the domain of wireless communication
networks are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2547</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2547</id><created>2010-12-12</created><authors><author><keyname>Faro</keyname><forenames>Simone</forenames></author><author><keyname>Lecroq</keyname><forenames>Thierry</forenames></author></authors><title>The Exact String Matching Problem: a Comprehensive Experimental
  Evaluation</title><categories>cs.DS</categories><comments>22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the online exact string matching problem which consists
in finding all occurrences of a given pattern p in a text t. It is an
extensively studied problem in computer science, mainly due to its direct
applications to such diverse areas as text, image and signal processing, speech
analysis and recognition, data compression, information retrieval,
computational biology and chemistry. Since 1970 more than 80 string matching
algorithms have been proposed, and more than 50% of them in the last ten years.
In this note we present a comprehensive list of all string matching algorithms
and present experimental results in order to compare them from a practical
point of view. From our experimental evaluation it turns out that the
performance of the algorithms are quite different for different alphabet sizes
and pattern length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2553</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2553</id><created>2010-12-12</created><authors><author><keyname>Zhao</keyname><forenames>Jianhua</forenames></author><author><keyname>Li</keyname><forenames>Xuandong</forenames></author></authors><title>Scope Logic with Local Reasoning and Pre/Post-State Properties</title><categories>cs.LO</categories><comments>30 pages, with two non-trival examples in the appendix</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper presents an extension to Hoare logic for pointer program
verification. Logic formulas with user-defined recursive functions are used to
specify properties on the program states before/after program executions.
  Three basic functions are introduced to represents memory access,
record-field access and array-element access. Some axioms are introduced to
specify these basic functions in our logic.
  The concept Memory Scope Function (MSF) is introduced in our logic. Given a
recursive function $f$, the MSF of $f$ computes the set of memory units
accessed during the evaluation of $f$. A set of rules are given to derive the
definition of this MSF syntactically from the definition of $f$. As MSFs are
also recursive functions, they also have their MSFs. An axiom is given to
specify that an MSF contains its MSF. Based on this axiom, local reasoning is
supported with predicate variables.
  Pre-state terms are used to specify the relations between pre-states and
post-states. People can use pre-state terms in post-conditions to represents
the values on the pre-state.
  The axiom of assignment statements in Hoare's logic is modified to deal with
pointers. The basic idea is that during the program execution, a recursive
function is evaluated to the same value as long as no memory unit in its memory
scope is modified. Another proof rule is added for memory allocation
statements.
  We use a simple example to show that our logic can deal with pointer programs
in this paper. In the appendix, the Shorre-Waite algorithm is proved using our
logic. We also use the selection-sort program to show that our logic can be
used to prove program with indirectly-specified components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2573</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2573</id><created>2010-12-12</created><authors><author><keyname>Cardinal</keyname><forenames>Jean</forenames></author><author><keyname>Karpinski</keyname><forenames>Marek</forenames></author><author><keyname>Schmied</keyname><forenames>Richard</forenames></author><author><keyname>Viehmann</keyname><forenames>Claus</forenames></author></authors><title>Approximating Vertex Cover in Dense Hypergraphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the minimum vertex cover problem in hypergraphs in which every
hyperedge has size k (also known as minimum hitting set problem, or minimum set
cover with element frequency k). Simple algorithms exist that provide
k-approximations, and this is believed to be the best possible approximation
achievable in polynomial time. We show how to exploit density and regularity
properties of the input hypergraph to break this barrier. In particular, we
provide a randomized polynomial-time algorithm with approximation factor k/(1
+(k-1)d/(k Delta)), where d and Delta are the average and maximum degree,
respectively, and Delta must be Omega(n^{k-1}/log n). The proposed algorithm
generalizes the recursive sampling technique of Imamura and Iwama (SODA'05) for
vertex cover in dense graphs. As a corollary, we obtain an approximation factor
k/(2-1/k) for subdense regular hypergraphs, which is shown to be the best
possible under the unique games conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2596</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2596</id><created>2010-12-12</created><authors><author><keyname>Yilmaz</keyname><forenames>Ferkan</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>A Unified MGF-Based Capacity Analysis of Diversity Combiners over
  Generalized Fading Channels</title><categories>cs.IT math.IT math.ST stat.OT stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unified exact average capacity results for L-branch coherent diversity
receivers including equal-gain combining (EGC) and maximal-ratio combining
(MRC) are not known. This paper develops a novel generic framework for the
capacity analysis of $L$-branch EGC/MRC over generalized fading channels. The
framework is used to derive new results for the Gamma shadowed generalized
Nakagami-m fading model which can be a suitable model for the fading
environments encountered by high frequency (60 GHz and above) communications.
The mathematical formalism is illustrated with some selected numerical and
simulation results confirming the correctness of our newly proposed framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2598</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2598</id><created>2010-12-12</created><authors><author><keyname>Yilmaz</keyname><forenames>Ferkan</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Extended Generalized-K (EGK): A New Simple and General Model for
  Composite Fading Channels</title><categories>cs.IT math.IT math.PR math.ST stat.TH</categories><comments>Composite fading distribution, generalized-K distribution,
  probability density function, cumulative distribution function, fractional
  moments, level crossing rate, amount of fade duration, moments, amount of
  fading, average bit error probability, average capacity</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a generalized composite fading distribution
(termed extended generalized-K (EGK)) to model the envelope and the power of
the received signal in millimeter wave (60 GHz or above) and free-space optical
channels. We obtain the first and the second-order statistics of the received
signal envelope characterized by the EGK composite fading distribution. In
particular, expressions for probability density function, cumulative
distribution function, level crossing rate and average fade duration, and
fractional moments are derived. In addition performance measures such as amount
of fading, average bit error probability, outage probability, average capacity,
and outage capacity are offered in closed-form. Selected numerical and computer
simulation examples validate the accuracy of the presented mathematical
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2599</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2599</id><created>2010-12-12</created><authors><author><keyname>Brochu</keyname><forenames>Eric</forenames></author><author><keyname>Cora</keyname><forenames>Vlad M.</forenames></author><author><keyname>de Freitas</keyname><forenames>Nando</forenames></author></authors><title>A Tutorial on Bayesian Optimization of Expensive Cost Functions, with
  Application to Active User Modeling and Hierarchical Reinforcement Learning</title><categories>cs.LG</categories><acm-class>G.1.6; G.3; I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a tutorial on Bayesian optimization, a method of finding the
maximum of expensive cost functions. Bayesian optimization employs the Bayesian
technique of setting a prior over the objective function and combining it with
evidence to get a posterior function. This permits a utility-based selection of
the next observation to make on the objective function, which must take into
account both exploration (sampling from areas of high uncertainty) and
exploitation (sampling areas likely to offer improvement over the current best
observation). We also present two detailed extensions of Bayesian optimization,
with experiments---active user modelling with preferences, and hierarchical
reinforcement learning---and a discussion of the pros and cons of Bayesian
optimization based on our experiences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2603</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2603</id><created>2010-12-12</created><authors><author><keyname>Li</keyname><forenames>Hanxi</forenames></author><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author><author><keyname>Shi</keyname><forenames>Qinfeng</forenames></author></authors><title>Real-time Visual Tracking Using Sparse Representation</title><categories>cs.CV</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The $\ell_1$ tracker obtains robustness by seeking a sparse representation of
the tracking object via $\ell_1$ norm minimization \cite{Xue_ICCV_09_Track}.
However, the high computational complexity involved in the $ \ell_1 $ tracker
restricts its further applications in real time processing scenario. Hence we
propose a Real Time Compressed Sensing Tracking (RTCST) by exploiting the
signal recovery power of Compressed Sensing (CS). Dimensionality reduction and
a customized Orthogonal Matching Pursuit (OMP) algorithm are adopted to
accelerate the CS tracking. As a result, our algorithm achieves a real-time
speed that is up to $6,000$ times faster than that of the $\ell_1$ tracker.
Meanwhile, RTCST still produces competitive (sometimes even superior) tracking
accuracy comparing to the existing $\ell_1$ tracker. Furthermore, for a
stationary camera, a further refined tracker is designed by integrating a
CS-based background model (CSBM). This CSBM-equipped tracker coined as RTCST-B,
outperforms most state-of-the-arts with respect to both accuracy and
robustness. Finally, our experimental results on various video sequences, which
are verified by a new metric---Tracking Success Probability (TSP), show the
excellence of the proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2606</identifier>
 <datestamp>2012-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2606</id><created>2010-12-12</created><updated>2012-10-08</updated><authors><author><keyname>Gauvin</keyname><forenames>Laetitia</forenames></author><author><keyname>Vignes</keyname><forenames>Annick</forenames></author><author><keyname>Nadal</keyname><forenames>Jean-Pierre</forenames></author></authors><title>Modeling urban housing market dynamics: can the socio-spatial
  segregation preserve some social diversity?</title><categories>physics.soc-ph cs.SI</categories><comments>45 pages, 11 figures, updated and extended version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Addressing issues of social diversity, we introduce a model of housing
transactions between agents who are heterogeneous in their willingness to pay.
A key assumption is that agents' preferences for a location depend on both an
intrinsic attractiveness and on the social characteristics of the neighborhood.
The stationary space distribution of income is analytically and numerically
characterized. The main results are that socio-spatial segregation occurs if --
and only if -- the social influence is strong enough, but even so, some social
diversity is preserved at most locations. Comparison with data on the Paris
housing market shows that the results reproduce general trends of price
distribution and spatial income segregation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2609</identifier>
 <datestamp>2012-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2609</id><created>2010-12-12</created><updated>2012-06-05</updated><authors><author><keyname>Wang</keyname><forenames>Deqing</forenames></author><author><keyname>Zhang</keyname><forenames>Hui</forenames></author></authors><title>Inverse-Category-Frequency based supervised term weighting scheme for
  text categorization</title><categories>cs.LG cs.AI</categories><comments>18 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Term weighting schemes often dominate the performance of many classifiers,
such as kNN, centroid-based classifier and SVMs. The widely used term weighting
scheme in text categorization, i.e., tf.idf, is originated from information
retrieval (IR) field. The intuition behind idf for text categorization seems
less reasonable than IR. In this paper, we introduce inverse category frequency
(icf) into term weighting scheme and propose two novel approaches, i.e., tf.icf
and icf-based supervised term weighting schemes. The tf.icf adopts icf to
substitute idf factor and favors terms occurring in fewer categories, rather
than fewer documents. And the icf-based approach combines icf and relevance
frequency (rf) to weight terms in a supervised way. Our cross-classifier and
cross-corpus experiments have shown that our proposed approaches are superior
or comparable to six supervised term weighting schemes and three traditional
schemes in terms of macro-F1 and micro-F1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2621</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2621</id><created>2010-12-12</created><authors><author><keyname>Torabkhani</keyname><forenames>Nima</forenames></author><author><keyname>Vellambi</keyname><forenames>Badri N.</forenames></author><author><keyname>Fekri</keyname><forenames>Faramarz</forenames></author></authors><title>Throughput and Latency of Acyclic Erasure Networks with Feedback in a
  Finite Buffer Regime</title><categories>cs.IT math.IT</categories><comments>5 pages, 5 figures, ITW2010 Dublin</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The exact Markov modeling analysis of erasure networks with finite buffers is
an extremely hard problem due to the large number of states in the system. In
such networks, packets are lost due to either link erasures or blocking by the
full buffers. In this paper, we propose a novel method that iteratively
estimates the performance parameters of the network and more importantly
reduces the computational complexity compared to the exact analysis. This is
the first work that analytically studies the effect of finite memory on the
throughput and latency in general wired acyclic networks with erasure links. As
a case study, a random packet routing scheme with ideal feedback on the links
is used. The proposed framework yields a fairly accurate estimate of the
probability distribution of buffer occupancies at the intermediate nodes using
which we can not only identify the congested and starving nodes but also obtain
analytical expressions for throughput and average delay of a packet in the
network. The theoretical framework presented here can be applied to many wired
networks, from Internet to more futuristic applications such as
networks-on-chip under various communication and network coding scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2622</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2622</id><created>2010-12-12</created><authors><author><keyname>Torabkhani</keyname><forenames>Nima</forenames></author><author><keyname>Vellambi</keyname><forenames>Badri N.</forenames></author><author><keyname>Fekri</keyname><forenames>Faramarz</forenames></author></authors><title>Study of Throughput and Latency in Finite-buffer Coded Networks</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, Asilomar 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Exact queueing analysis of erasure networks with network coding in a finite
buffer regime is an extremely hard problem due to the large number of states in
the network. In such networks, packets are lost due to either link erasures or
due to blocking due to full buffers. In this paper, a block-by-block random
linear network coding scheme with feedback on the links is selected for
reliability and more importantly guaranteed decoding of each block. We propose
a novel method that iteratively estimates the performance parameters of the
network and more importantly reduces the computational complexity compared to
the exact analysis. The proposed framework yields an accurate estimate of the
distribution of buffer occupancies at the intermediate nodes using which we
obtain analytical expressions for network throughput and delay distribution of
a block of packets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2628</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2628</id><created>2010-12-12</created><authors><author><keyname>Vellambi</keyname><forenames>Badri N.</forenames></author><author><keyname>Torabkhani</keyname><forenames>Nima</forenames></author><author><keyname>Fekri</keyname><forenames>Faramarz</forenames></author></authors><title>Throughput and Latency in Finite-Buffer Line Networks</title><categories>cs.IT math.IT</categories><comments>19 pages, 14 figures, accepted in IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work investigates the effect of finite buffer sizes on the throughput
capacity and packet delay of line networks with packet erasure links that have
perfect feedback. These performance measures are shown to be linked to the
stationary distribution of an underlying irreducible Markov chain that models
the system exactly. Using simple strategies, bounds on the throughput capacity
are derived. The work then presents two iterative schemes to approximate the
steady-state distribution of node occupancies by decoupling the chain to
smaller queueing blocks. These approximate solutions are used to understand the
effect of buffer sizes on throughput capacity and the distribution of packet
delay. Using the exact modeling for line networks, it is shown that the
throughput capacity is unaltered in the absence of hop-by-hop feedback provided
packet-level network coding is allowed. Finally, using simulations, it is
confirmed that the proposed framework yields accurate estimates of the
throughput capacity and delay distribution and captures the vital trends and
tradeoffs in these networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2633</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2633</id><created>2010-12-13</created><authors><author><keyname>Gupta</keyname><forenames>Vishal</forenames></author><author><keyname>Saxena</keyname><forenames>Ashutosh</forenames></author></authors><title>Personalized Data Set for Analysis</title><categories>cs.DB cs.CR</categories><comments>8 pages, 3 Diagrams, 1 Table, International Journal of Database
  Management Systems (IJDMS)</comments><journal-ref>International Journal of Database Management Systems ( IJDMS ),
  Vol.2, No.4, November 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data Management portfolio within an organization has seen an upsurge in
initiatives for compliance, security, repurposing and storage within and
outside the organization. When such initiatives are being put to practice care
must be taken while granting access to data repositories for analysis and
mining activities. Also, initiatives such as Master Data Management, cloud
computing and self service business intelligence have raised concerns in the
arena of regulatory compliance and data privacy, especially when a large data
set of an organization are being outsourced for testing, consolidation and data
management. Here, an approach is presented where a new service layer is
introduced, by data governance group, in the architecture for data management
and can be used for preserving privacy of sensitive information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2648</identifier>
 <datestamp>2010-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2648</id><created>2010-12-13</created><authors><author><keyname>Abiteboul</keyname><forenames>S.</forenames></author><author><keyname>Gottlob</keyname><forenames>G.</forenames></author><author><keyname>Manna</keyname><forenames>M.</forenames></author></authors><title>Distributed XML Design</title><categories>cs.DB cs.CC cs.DC</categories><comments>&quot;56 pages, 4 figures&quot;</comments><msc-class>68M14 (Primary), 68P15 (Secondary)</msc-class><acm-class>C.2.4; H.2.1</acm-class><journal-ref>Proceedings of PODS '09 (2009) 247-258</journal-ref><doi>10.1145/1559795.1559833</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A distributed XML document is an XML document that spans several machines. We
assume that a distribution design of the document tree is given, consisting of
an XML kernel-document T[f1,...,fn] where some leaves are &quot;docking points&quot; for
external resources providing XML subtrees (f1,...,fn, standing, e.g., for Web
services or peers at remote locations). The top-down design problem consists
in, given a type (a schema document that may vary from a DTD to a tree
automaton) for the distributed document, &quot;propagating&quot; locally this type into a
collection of types, that we call typing, while preserving desirable
properties. We also consider the bottom-up design which consists in, given a
type for each external resource, exhibiting a global type that is enforced by
the local types, again with natural desirable properties. In the article, we
lay out the fundamentals of a theory of distributed XML design, analyze
problems concerning typing issues in this setting, and study their complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2661</identifier>
 <datestamp>2010-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2661</id><created>2010-12-13</created><authors><author><keyname>Amblard</keyname><forenames>Maxime</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Lecomte</keyname><forenames>Alain</forenames><affiliation>INRIA Bordeaux - Sud-Ouest, SFLTAMP</affiliation></author><author><keyname>Retor&#xe9;</keyname><forenames>Christian</forenames><affiliation>INRIA Bordeaux - Sud-Ouest, LaBRI</affiliation></author></authors><title>Categorial Minimalist Grammar</title><categories>cs.CL math.LO</categories><proxy>ccsd</proxy><journal-ref>Linguistic Analysis 36, 1--4 (2010) 273--308</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We first recall some basic notions on minimalist grammars and on categorial
grammars. Next we shortly introduce partially commutative linear logic, and our
representation of minimalist grammars within this categorial system, the
so-called categorial minimalist grammars. Thereafter we briefly present
\lambda\mu-DRT (Discourse Representation Theory) an extension of \lambda-DRT
(compositional DRT) in the framework of \lambda\mu calculus: it avoids type
raising and derives different readings from a single semantic representation,
in a setting which follows discourse structure. We run a complete example which
illustrates the various structures and rules that are needed to derive a
semantic representation from the categorial view of a transformational
syntactic analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2662</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2662</id><created>2010-12-13</created><authors><author><keyname>Moroz</keyname><forenames>Guillaume Inria</forenames><affiliation>INRIA Lorraine - LORIA, IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Rouiller</keyname><forenames>Fabrice</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Cusp points in the parameter space of RPR-2PRR parallel manipulator</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>3-rd European Conference on Mechanism Science, Cluj-Napoca :
  Romania (2010)</journal-ref><doi>10.1007/978-90-481-9689-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the existence conditions of cusp points in the design
parameter space of the R\underline{P}R-2P\underline{R}R parallel manipulators.
Cusp points make possible non-singular assembly-mode changing motion, which can
possibly increase the size of the aspect, i.e. the maximum singularity free
workspace. The method used is based on the notion of discriminant varieties and
Cylindrical Algebraic Decomposition, and resorts to Gr\&quot;obner bases for the
solutions of systems of equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2666</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2666</id><created>2010-12-13</created><authors><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Joint space and workspace analysis of a two-DOF closed-chain manipulator</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>Symposium on Robot Design, Dynamics, and Control, Udine : Italy
  (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to compute of the generalized aspects, i.e. the
maximal singularity-free domains in the Cartesian product of the joint space
and workspace, for a planar parallel mechanism in using quadtree model and
interval analysis based method. The parallel mechanisms can admit several
solutions to the inverses and the direct kinematic models. These singular
configurations divide the joint space and the workspace in several not
connected domains. To compute this domains, the quadtree model can be made by
using a discretization of the space. Unfortunately, with this method, some
singular configurations cannot be detected as a single point in the joint
space. The interval analysis based method allow us to assure that no
singularities are not found and to reduce the computing times. This approach is
tested on a simple planar parallel mechanism with two degrees of freedom.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2668</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2668</id><created>2010-12-13</created><authors><author><keyname>Moroz</keyname><forenames>Guillaume Inria</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Rouiller</keyname><forenames>Fabrice</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author></authors><title>On the determination of cusp points of 3-R\underline{P}R parallel
  manipulators</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>Mechanism and Machine Theory 45, 11 (2010) 1555-1567</journal-ref><doi>10.1016/j.mechmachtheory.2010.06.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the cuspidal configurations of 3-RPR parallel
manipulators that may appear on their singular surfaces in the joint space.
Cusp points play an important role in the kinematic behavior of parallel
manipulators since they make possible a non-singular change of assembly mode.
In previous works, the cusp points were calculated in sections of the joint
space by solving a 24th-degree polynomial without any proof that this
polynomial was the only one that gives all solutions. The purpose of this study
is to propose a rigorous methodology to determine the cusp points of
3-R\underline{P}R manipulators and to certify that all cusp points are found.
This methodology uses the notion of discriminant varieties and resorts to
Gr\&quot;obner bases for the solutions of systems of equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2673</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2673</id><created>2010-12-13</created><authors><author><keyname>S&#xf8;rensen</keyname><forenames>Jesper H.</forenames></author><author><keyname>Popovski</keyname><forenames>Petar</forenames></author><author><keyname>&#xd8;stergaard</keyname><forenames>Jan</forenames></author></authors><title>On the Role of Feedback in LT Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper concerns application of feedback in LT codes. The considered type
of feedback is acknowledgments, where information on which symbols have been
decoded is given to the transmitter. We identify an important adaptive
mechanism in standard LT codes, which is crucial to their ability to perform
well under any channel conditions. We show how precipitate application of
acknowledgments can interfere with this adaptive mechanism and lead to
significant performance degradation. Moreover, our analysis reveals that even
sensible use of acknowledgments has very low potential in standard LT codes.
Motivated by this, we analyze the impact of acknowledgments on multi layer LT
codes, i.e. LT codes with unequal error protection. In this case, feedback
proves advantageous. We show that by using only a single feedback message, it
is possible to achieve a noticeable performance improvement compared to
standard LT codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2674</identifier>
 <datestamp>2010-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2674</id><created>2010-12-13</created><authors><author><keyname>Guterl</keyname><forenames>Jerome</forenames><affiliation>IRMA</affiliation></author><author><keyname>Braeunig</keyname><forenames>Jean-Philippe</forenames><affiliation>CEA DIF, INRIA Lorraine / IECN / LSIIT / IRMA, LRC MESO</affiliation></author><author><keyname>Crouseilles</keyname><forenames>Nicolas</forenames><affiliation>IRMA, INRIA Lorraine / IECN / LSIIT / IRMA</affiliation></author><author><keyname>Grandgirard</keyname><forenames>Virginie</forenames><affiliation>IRFM</affiliation></author><author><keyname>Latu</keyname><forenames>Guillaume</forenames><affiliation>IRFM</affiliation></author><author><keyname>Mehrenberger</keyname><forenames>Michel</forenames><affiliation>IRMA, INRIA Lorraine / IECN / LSIIT / IRMA</affiliation></author><author><keyname>Sonnendr&#xfc;cker</keyname><forenames>Eric</forenames><affiliation>IRMA, INRIA Lorraine / IECN / LSIIT / IRMA</affiliation></author></authors><title>Test of some numerical limiters for the conservative PSM scheme for 4D
  Drift-Kinetic simulations</title><categories>cs.NA math-ph math.MP math.NA</categories><proxy>ccsd</proxy><report-no>RR-7467</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this work is simulation of magnetised plasmas in the ITER
project framework. In this context, Vlasov-Poisson like models are used to
simulate core turbulence in the tokamak in a toroidal geometry. This leads to
heavy simulation because a 6D dimensional problem has to be solved, 3D in space
and 3D in velocity. The model is reduced to a 5D gyrokinetic model, taking
advantage of the particular motion of particles due to the presence of a strong
magnetic field. However, accurate schemes, parallel algorithms need to be
designed to bear these simulations. This paper describes a Hermite formulation
of the conservative PSM scheme which is very generic and allows to implement
different semi-Lagrangian schemes. We also test and propose numerical limiters
which should improve the robustness of the simulations by diminishing spurious
oscillations. We only consider here the 4D drift-kinetic model which is the
backbone of the 5D gyrokinetic models and relevant to build a robust and
accurate numerical method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2694</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2694</id><created>2010-12-13</created><authors><author><keyname>Agarwal</keyname><forenames>Pankaj K.</forenames></author><author><keyname>Avraham</keyname><forenames>Rinat Ben</forenames></author><author><keyname>Sharir</keyname><forenames>Micha</forenames></author></authors><title>The 2-Center Problem in Three Dimensions</title><categories>cs.CG</categories><acm-class>F.2.2; I.5.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let P be a set of n points in R^3. The 2-center problem for P is to find two
congruent balls of minimum radius whose union covers P. We present two
randomized algorithms for computing a 2-center of P. The first algorithm runs
in O(n^3 log^5 n) expected time, and the second algorithm runs in O((n^2 log^5
n) /(1-r*/r_0)^3) expected time, where r* is the radius of the 2-center balls
of P and r_0 is the radius of the smallest enclosing ball of P. The second
algorithm is faster than the first one as long as r* is not too close to r_0,
which is equivalent to the condition that the centers of the two covering balls
be not too close to each other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2699</identifier>
 <datestamp>2013-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2699</id><created>2010-12-13</created><updated>2013-11-25</updated><authors><author><keyname>Stefanov</keyname><forenames>Stefan Z.</forenames></author></authors><title>Prognostic Watch of the Electric Power System</title><categories>cs.SI</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A prognostic watch of the electric power system (EPS)is framed up, which
detects the threat to EPS for a day ahead according to the characteristic times
for a day ahead and according to the droop for a day ahead. Therefore, a
prognostic analysis of the EPS development for a day ahead is carried out. Also
the power grid, the electricity marker state, the grid state and the level of
threat for a power grid are found for a day ahead. The accuracy of the built up
prognostic watch is evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2713</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2713</id><created>2010-12-13</created><authors><author><keyname>Zhou</keyname><forenames>Junping</forenames></author><author><keyname>Yin</keyname><forenames>Minghao</forenames></author></authors><title>Phase Transitions of Plan Modification in Conformant Planning</title><categories>cs.AI cs.CC</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We explore phase transitions of plan modification, which mainly focus on the
conformant planning problems. By analyzing features of plan modification in
conformant planning problems, quantitative results are obtained. If the number
of operators is less than, almost all conformant planning problems can't be
solved with plan modification. If the number of operators is more than, almost
all conformant planning problems can be solved with plan modification. The
results of the experiments also show that there exists an experimental
threshold of density (ratio of number of operators to number of propositions),
which separates the region where almost all conformant planning problems can't
be solved with plan modification from the region where almost all conformant
planning problems can be solved with plan modification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2720</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2720</id><created>2010-12-13</created><authors><author><keyname>Ghorbel-Talbi</keyname><forenames>Meriam Ben</forenames></author><author><keyname>Cuppens</keyname><forenames>Frederic</forenames></author><author><keyname>Cuppens-Boulahia</keyname><forenames>Nora</forenames></author><author><keyname>Bouhoula</keyname><forenames>Adel</forenames></author></authors><title>Managing Delegation in Access Control Models</title><categories>cs.CR</categories><journal-ref>Proceedings of the 15th International Conference on Advanced
  Computing and Communication (ADCOM'07), 2007</journal-ref><doi>10.1109/ADCOM.2007.105</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the field of access control, delegation is an important aspect that is
considered as a part of the administration mechanism. Thus, a complete access
control must provide a flexible administration model to manage delegation.
Unfortunately, to our best knowledge, there is no complete model for describing
all delegation requirements for role-based access control. Therefore, proposed
models are often extended to consider new delegation characteristics, which is
a complex task to manage and necessitate the redefinition of these models. In
this paper we describe a new delegation approach for extended role-based access
control models. We show that our approach is flexible and is sufficient to
manage all delegation requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2726</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2726</id><created>2010-12-13</created><authors><author><keyname>Cooper</keyname><forenames>Kathryn</forenames></author><author><keyname>Barahona</keyname><forenames>Mauricio</forenames></author></authors><title>Role-based similarity in directed networks</title><categories>physics.soc-ph cs.SI nlin.AO q-bio.MN</categories><comments>4 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The widespread relevance of increasingly complex networks requires methods to
extract meaningful coarse-grained representations of such systems. For
undirected graphs, standard community detection methods use criteria largely
based on density of connections to provide such representations. We propose a
method for grouping nodes in directed networks based on the role of the nodes
in the network, understood in terms of patterns of incoming and outgoing flows.
The role groupings are obtained through the clustering of a similarity matrix,
formed by the distances between feature vectors that contain the number of in
and out paths of all lengths for each node. Hence nodes operating in a similar
flow environment are grouped together although they may not themselves be
densely connected. Our method, which includes a scale factor that reveals
robust groupings based on increasingly global structure, provides an
alternative criterion to uncover structure in networks where there is an
implicit flow transfer in the system. We illustrate its application to a
variety of data from ecology, world trade and cellular metabolism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2738</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2738</id><created>2010-12-13</created><authors><author><keyname>Dinur</keyname><forenames>Irit</forenames></author><author><keyname>Kaufman</keyname><forenames>Tali</forenames></author></authors><title>Dense locally testable codes cannot have constant rate and distance</title><categories>cs.CC math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A q-query locally testable code (LTC) is an error correcting code that can be
tested by a randomized algorithm that reads at most q symbols from the given
word. An important question is whether there exist LTCs that have the
ccc-property: constant relative rate, constant relative distance, and that can
be tested with a constant number of queries. Such codes are sometimes referred
to as &quot;asymptotically good&quot;.
  We show that dense LTCs cannot be ccc. The density of a tester is roughly the
average number of distinct local views in which a coordinate participates. An
LTC is dense if it has a tester with density &gt;&gt; 1.
  More precisely, we show that a 3-query locally testable code with a tester of
density &gt;&gt; 1 cannot be ccc. Moreover, we show that a q-query locally testable
code (q&gt;3) with a tester of density &gt;&gt; n^{q-2} cannot be ccc. Our results hold
when the tester has the following two properties: 1) &quot;no weights&quot;: Every
q-tuple of queries occurs with the same probability. 2) &quot;last-one-fixed&quot;: In
every `test' of the tester, the value to any q-1 of the symbols determines the
value of the last symbol. (Linear codes have constraints of this type).
  We also show that several natural ways to quantitatively improve our results
would already resolve the general ccc-question, i.e. also for non-dense LTCs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2749</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2749</id><created>2010-12-13</created><authors><author><keyname>Guenin</keyname><forenames>Bertrand</forenames></author><author><keyname>Thomas</keyname><forenames>Robin</forenames></author></authors><title>Packing directed circuits exactly</title><categories>math.CO cs.DM</categories><comments>To appear in Combinatorica</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an &quot;excluded minor&quot; and a &quot;structural&quot; characterization of digraphs D
that have the property that for every subdigraph H of D, the maximum number of
disjoint circuits in H is equal to the minimum cardinality of a subset T of
V(H) such that H\T is acyclic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2751</identifier>
 <datestamp>2013-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2751</id><created>2010-12-13</created><updated>2013-03-20</updated><authors><author><keyname>Lomnitz</keyname><forenames>Yuval</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author></authors><title>Universal communication part I: modulo additive channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Which communication rates can be attained over a channel whose output is an
unknown (possibly stochastic) function of the input that may vary arbitrarily
in time with no a-priori model? Following the spirit of the finite-state
compressibility of a sequence, defined by Lempel and Ziv, a &quot;capacity&quot; is
defined for such a channel as the highest rate achievable by a designer knowing
the particular relation that indeed exists between the input and output for all
times, yet is constrained to use a fixed finite-length block communication
scheme without feedback, i.e. use the same encoder and decoder over each block.
In the case of the modulo additive channel, where the output sequence is
obtained by modulo addition of an unknown individual sequence to the input
sequence, this capacity is upper bounded by a function of the finite state
compressibility of the noise sequence. A universal communication scheme with
feedback that attains this capacity universally, without prior knowledge of the
noise sequence, is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2771</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2771</id><created>2010-12-13</created><authors><author><keyname>Margenstern</keyname><forenames>Maurice</forenames></author></authors><title>Bacteria inspired patterns grown with hyperbolic cellular automata</title><categories>cs.FL</categories><comments>16 pages, 13 figures</comments><msc-class>68R05, 68R99</msc-class><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we give three examples of expending patterns defined by
hyperbolic cellular automata whose growth seems to be very similar to the
growth of colonies of bacteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2774</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2774</id><created>2010-12-13</created><authors><author><keyname>Liu</keyname><forenames>D.</forenames></author><author><keyname>Blenn</keyname><forenames>N.</forenames></author><author><keyname>Van Mieghem</keyname><forenames>P.</forenames></author></authors><title>Modeling Social Networks with Overlapping Communities Using Hypergraphs
  and Their Line Graphs</title><categories>cs.SI physics.soc-ph</categories><comments>11 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose that hypergraphs can be used to model social networks with
overlapping communities. The nodes of the hypergraphs represent the
communities. The hyperlinks of the hypergraphs denote the individuals who may
participate in multiple communities. The hypergraphs are not easy to analyze,
however, the line graphs of hypergraphs are simple graphs or weighted graphs,
so that the network theory can be applied. We define the overlapping depth $k$
of an individual by the number of communities that overlap in that individual,
and we prove that the minimum adjacency eigenvalue of the corresponding line
graph is not smaller than $-k_{max}$, which is the maximum overlapping depth of
the whole network. Based on hypergraphs with preferential attachment, we
establish a network model which incorporates overlapping communities with
tunable overlapping parameters $k$ and $w$. By comparing with the Hyves social
network, we show that our social network model possesses high clustering,
assortative mixing, power-law degree distribution and short average path
length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2782</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2782</id><created>2010-12-13</created><authors><author><keyname>Shoval</keyname><forenames>Oren</forenames></author><author><keyname>Alon</keyname><forenames>Uri</forenames></author><author><keyname>Sontag</keyname><forenames>Eduardo</forenames></author></authors><title>Symmetry invariance for adapting biological systems</title><categories>cs.SY math.OC physics.bio-ph q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study in this paper certain properties of the responses of dynamical
systems to external inputs. The motivation arises from molecular systems
biology. and, in particular, the recent discovery of an important transient
property, related to Weber's law in psychophysics: &quot;fold-change detection&quot; in
adapting systems, the property that scale uncertainty does not affect
responses. FCD appears to play an important role in key signaling transduction
mechanisms in eukaryotes, including the ERK and Wnt pathways, as well as in
E.coli and possibly other prokaryotic chemotaxis pathways. In this paper, we
provide further theoretical results regarding this property. Far more
generally, we develop a necessary and sufficient characterization of adapting
systems whose transient behaviors are invariant under the action of a set
(often, a group) of symmetries in their sensory field. A particular instance is
FCD, which amounts to invariance under the action of the multiplicative group
of positive real numbers. Our main result is framed in terms of a notion which
extends equivariant actions of compact Lie groups. Its proof relies upon
control theoretic tools, and in particular the uniqueness theorem for minimal
realizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2787</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2787</id><created>2010-12-13</created><authors><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Caro</keyname><forenames>St&#xe9;phane</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Ur-Rehman</keyname><forenames>Raza</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Comparison of Planar Parallel Manipulator Architectures based on a
  Multi-objective Design Optimization Approach</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>34th Annual Mechanisms and Robotics Conference (MR), Montr\'eal :
  Canada (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the comparison of planar parallel manipulator
architectures based on a multi-objective design optimization approach. The
manipulator architectures are compared with regard to their mass in motion and
their regular workspace size, i.e., the objective functions. The optimization
problem is subject to constraints on the manipulator dexterity and stiffness.
For a given external wrench, the displacements of the moving platform have to
be smaller than given values throughout the obtained maximum regular dexterous
workspace. The contributions of the paper are highlighted with the study of
3-RPR, 3-RPR and 3-RPR planar parallel manipulator architectures, which are
compared by means of their Pareto frontiers obtained with a genetic algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2789</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2789</id><created>2010-12-09</created><authors><author><keyname>Wang</keyname><forenames>Xiaoyue</forenames></author><author><keyname>Ding</keyname><forenames>Hui</forenames></author><author><keyname>Trajcevski</keyname><forenames>Goce</forenames></author><author><keyname>Scheuermann</keyname><forenames>Peter</forenames></author><author><keyname>Keogh</keyname><forenames>Eamonn</forenames></author></authors><title>Experimental Comparison of Representation Methods and Distance Measures
  for Time Series Data</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The previous decade has brought a remarkable increase of the interest in
applications that deal with querying and mining of time series data. Many of
the research efforts in this context have focused on introducing new
representation methods for dimensionality reduction or novel similarity
measures for the underlying data. In the vast majority of cases, each
individual work introducing a particular method has made specific claims and,
aside from the occasional theoretical justifications, provided quantitative
experimental observations. However, for the most part, the comparative aspects
of these experiments were too narrowly focused on demonstrating the benefits of
the proposed methods over some of the previously introduced ones. In order to
provide a comprehensive validation, we conducted an extensive experimental
study re-implementing eight different time series representations and nine
similarity measures and their variants, and testing their effectiveness on
thirty-eight time series data sets from a wide variety of application domains.
In this paper, we give an overview of these different techniques and present
our comparative experimental findings regarding their effectiveness. In
addition to providing a unified validation of some of the existing
achievements, our experiments also indicate that, in some cases, certain claims
in the literature may be unduly optimistic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2797</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2797</id><created>2010-12-13</created><authors><author><keyname>Kochanski</keyname><forenames>Greg P.</forenames></author><author><keyname>Shih</keyname><forenames>Chilin</forenames></author><author><keyname>Shosted</keyname><forenames>Ryan</forenames></author></authors><title>Should Corpora be Big, Rich, or Dense?</title><categories>cs.SD</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we ask what properties makes a large corpus more or less
useful. We suggest that size, by itself, should not be the ultimate goal of
building a corpus. Large-scale corpora are considered desirable because they
offer statistical stability and rich variation. But this rich variation means
more factors to control and evaluate, which can limit the advantages of size.
We discuss the use of multi-channel data to complement large-scale speech
corpora. Even though multi-channel data may limit the scale of a corpus (due to
the complex and labor-intensive nature of data collection) they can offer
information that allows us to tease apart various factors related to speech
production.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2825</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2825</id><created>2010-12-13</created><updated>2011-02-22</updated><authors><author><keyname>Nussbaum</keyname><forenames>Yahav</forenames></author></authors><title>Improved distance queries in planar graphs</title><categories>cs.DS cs.DM</categories><acm-class>G.2.2; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are several known data structures that answer distance queries between
two arbitrary vertices in a planar graph. The tradeoff is among preprocessing
time, storage space and query time. In this paper we present three data
structures that answer such queries, each with its own advantage over previous
data structures. The first one improves the query time of data structures of
linear space. The second improves the preprocessing time of data structures
with a space bound of O(n^(4/3)) or higher while matching the best known query
time. The third data structure improves the query time for a similar range of
space bounds, at the expense of a longer preprocessing time. The techniques
that we use include modifying the parameters of planar graph decompositions,
combining the different advantages of existing data structures, and using the
Monge property for finding minimum elements of matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2830</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2830</id><created>2010-12-13</created><authors><author><keyname>Yu</keyname><forenames>Hang</forenames></author><author><keyname>Zhong</keyname><forenames>Lin</forenames></author><author><keyname>Sabharwal</keyname><forenames>Ashutosh</forenames></author></authors><title>Beamsteering on Mobile Devices: Network Capacity and Client Efficiency</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current and emerging mobile devices are omni directional in wireless
communication. Such omni directionality not only limits device energy
efficiency but also poses a significant challenge toward the capacity of
wireless networks through inter-link interference. In this work, we seek to
make mobile clients directional with beamsteering. We first demonstrate that
beamsteering is already feasible to mobile devices such as Netbooks and eBook
readers in terms of form factor, power efficiency, and device mobility. We
further reveal that beamsteering mobile clients face a unique challenge to
balance client efficiency and network capacity. There is an optimal operating
point for a beamsteering mobile client in terms of the number of antennas and
transmit power that achieve the required capacity with lowest power. Finally,
we provide a distributed algorithm called BeamAdapt that allows each client to
closely approach its optimal point iteratively without central coordination. We
also offer a cellular system realization of BeamAdapt. Using Qualnet-based
simulation, we show that BeamAdapt with four antennas can reduce client power
consumption by 55% while maintaining a required network throughput for a
large-scale network, compared to the same network with omni directional mobile
clients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2831</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2831</id><created>2010-12-13</created><updated>2010-12-20</updated><authors><author><keyname>Dong</keyname><forenames>Mian</forenames></author><author><keyname>Zhong</keyname><forenames>Lin</forenames></author></authors><title>Sesame: Self-Constructive System Energy Modeling for Battery-Powered
  Mobile Systems</title><categories>cs.OS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  System energy models are important for energy optimization and management in
mobile systems. However, existing system energy models are built in lab with
the help from a second computer. Not only are they labor-intensive; but also
they will not adequately account for the great diversity in the hardware and
usage of mobile systems. Moreover, existing system energy models are intended
for energy estimation for time intervals of one second or longer; they do not
provide the required rate for fine-grain use such as per-application energy
accounting.
  In this work, we study a self-modeling paradigm in which a mobile system
automatically generates its energy model without any external assistance. Our
solution, Se-same, leverages the possibility of self power measurement through
the smart battery interface and employs a suite of novel techniques to achieve
accuracy and rate much higher than that of the smart battery interface.
  We report the implementation and evaluation of Se-same on a laptop and a
smartphone. The experiment results show that Sesame generates system energy
models of 95% accuracy at one estimation per second and 88% accuracy at one
estimation per 10ms, without any external assistance. A five-day field studies
with four laptop and four smartphones users further demonstrate the
effectiveness, efficiency, and noninvasiveness of Sesame.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2832</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2832</id><created>2010-12-13</created><authors><author><keyname>Rahmati</keyname><forenames>Ahmad</forenames></author><author><keyname>Zhong</keyname><forenames>Lin</forenames></author></authors><title>A Longitudinal Study of Non-Voice Mobile Phone Usage by Teens from an
  Underserved Urban Community</title><categories>cs.HC cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report a user study of over four months on the non-voice usage of mobile
phones by teens from an underserved urban community in the USA where a
community-wide, open-access Wi-Fi network exists. We instrumented the phones to
record quantitative information regarding their usage and location in a
privacy-respecting manner. We conducted focus group meetings and interviewed
participants regularly for qualitative data. We present our findings on what
applications our participants used and how their usage changed over time. The
findings highlight the challenges to evaluating the usability of mobile systems
and the value of long-term methodologies. Based on our findings, we analyze the
unique values of mobile phones, as a platform technology. Our study shows that
the usage is highly mobile, location-dependent, and serves multiple social
purposes for the participants. Furthermore, we present concrete findings on how
to perform and analyze similar user studies on mobile phones, including four
contributing factors to usage evolution, and provide guidelines for their
design and evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2835</identifier>
 <datestamp>2011-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2835</id><created>2010-12-13</created><updated>2011-12-01</updated><authors><author><keyname>Hirani</keyname><forenames>Anil N.</forenames></author><author><keyname>Kalyanaraman</keyname><forenames>Kaushik</forenames></author><author><keyname>Wang</keyname><forenames>Han</forenames></author><author><keyname>Watts</keyname><forenames>Seth</forenames></author></authors><title>Cohomologous Harmonic Cochains</title><categories>cs.CG math.GT math.NA</categories><comments>Language improvements to version 7. Content is otherwise the same as
  version 7</comments><msc-class>65F10, 68U05, 65N30, 55-04</msc-class><acm-class>F.2.2; G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe algorithms for finding harmonic cochains, an essential ingredient
for solving elliptic partial differential equations in exterior calculus.
Harmonic cochains are also useful in computational topology and computer
graphics. We focus on finding harmonic cochains cohomologous to a given
cocycle. Amongst other things, this allows localization near topological
features of interest. We derive a weighted least squares method by proving a
discrete Hodge-deRham theorem on the isomorphism between the space of harmonic
cochains and cohomology. The solution obtained either satisfies the Whitney
form finite element exterior calculus equations or the discrete exterior
calculus equations for harmonic cochains, depending on the discrete Hodge star
used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2858</identifier>
 <datestamp>2011-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2858</id><created>2010-12-13</created><authors><author><keyname>Ameloot</keyname><forenames>Tom</forenames></author><author><keyname>Neven</keyname><forenames>Frank</forenames></author><author><keyname>Bussche</keyname><forenames>Jan Van den</forenames></author></authors><title>Relational transducers for declarative networking</title><categories>cs.DB</categories><journal-ref>30th ACM Symposium on Principles of Database Systems, 2011</journal-ref><doi>10.1145/1989284.1989321</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by a recent conjecture concerning the expressiveness of declarative
networking, we propose a formal computation model for &quot;eventually consistent&quot;
distributed querying, based on relational transducers. A tight link has been
conjectured between coordination-freeness of computations, and monotonicity of
the queries expressed by such computations. Indeed, we propose a formal
definition of coordination-freeness and confirm that the class of monotone
queries is captured by coordination-free transducer networks.
Coordination-freeness is a semantic property, but the syntactic class that we
define of &quot;oblivious&quot; transducers also captures the same class of monotone
queries. Transducer networks that are not coordination-free are much more
powerful.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2860</identifier>
 <datestamp>2013-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2860</id><created>2010-12-13</created><updated>2011-05-03</updated><authors><author><keyname>Ji</keyname><forenames>Yi</forenames></author><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>Paquet</keyname><forenames>Joey</forenames></author></authors><title>Towards Refactoring the DMF to Support Jini and JMS DMS in GIPSY</title><categories>cs.DC</categories><comments>16 pages; 9 figures; an index. v4 includes significant updates and a
  version was submitted to PPPJ'11</comments><acm-class>D.2.11; D.2.12; H.3.4</acm-class><doi>10.1145/2347583.2347588</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we report on our re-engineering effort to refactor and unify
two somewhat disjoint Java distributed middleware technologies -- Jini and JMS
-- used in the implementation of the Demand Migration System (DMS). In doing
so, we refactor their parent Demand Migration Framework (DMF), within the
General Intensional Programming System (GIPSY). The complex Java-based GIPSY
project is used to investigate on the intensional and hybrid programming
paradigms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2889</identifier>
 <datestamp>2011-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2889</id><created>2010-12-13</created><updated>2011-11-30</updated><authors><author><keyname>Gecow</keyname><forenames>Andrzej</forenames></author></authors><title>The differences between natural and artificial life. Towards a
  definition of life</title><categories>nlin.AO cs.OH q-bio.OT</categories><msc-class>92Bxx, 92B05</msc-class><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is high time to openly and without finalism define the dangerous but
needed term 'purposeful information', whose quantity is an Eigen information
value. Using the term 'biological information' in its stead forces one into an
uncomfortable detour. I propose such a definition based on the generalized
notions of 'information' and 'encoding'. Next, the properties of the
spontaneous process of collecting purposeful information are investigated. In
effect, the properties of this process: the goal 'continuation of existence',
reproduction and Darwinian mechanism are derived which suggest, that it is the
natural life process. A 'natural identity criterion' appears in this process
for an evolving object, that is connected to a 'small change tendency'.
Likewise, 'hereditary information' is defined. Artificial life is constructed
by living objects, is a part of natural life process and its properties are not
an effect of its internal restrictions but of external assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2910</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2910</id><created>2010-12-13</created><updated>2011-01-18</updated><authors><author><keyname>Bu&#x161;i&#x107;</keyname><forenames>Ana</forenames></author><author><keyname>Gaujal</keyname><forenames>Bruno</forenames></author><author><keyname>Pin</keyname><forenames>Furcy</forenames></author></authors><title>Perfect Sampling of Markov Chains with Piecewise Homogeneous Events</title><categories>cs.DM math.PR</categories><msc-class>Primary: 60J10, 65C05. Secondary: 68M20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Perfect sampling is a technique that uses coupling arguments to provide a
sample from the stationary distribution of a Markov chain in a finite time
without ever computing the distribution. This technique is very efficient if
all the events in the system have monotonicity property. However, in the
general (non-monotone) case, this technique needs to consider the whole state
space, which limits its application only to chains with a state space of small
cardinality. We propose here a new approach for the general case that only
needs to consider two trajectories. Instead of the original chain, we use two
bounding processes (envelopes) and we show that, whenever they couple, one
obtains a sample under the stationary distribution of the original chain. We
show that this new approach is particularly effective when the state space can
be partitioned into pieces where envelopes can be easily computed. We further
show that most Markovian queueing networks have this property and we propose
efficient algorithms for some of them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2965</identifier>
 <datestamp>2010-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2965</id><created>2010-12-14</created><authors><author><keyname>Agarwal</keyname><forenames>Rashmi</forenames></author><author><keyname>Krishnan</keyname><forenames>R.</forenames></author><author><keyname>Santhanam</keyname><forenames>M. S.</forenames></author><author><keyname>Srinivas</keyname><forenames>K.</forenames></author><author><keyname>Venugopalan</keyname><forenames>K.</forenames></author></authors><title>Digital watermarking : An approach based on Hilbert transform</title><categories>cs.MM</categories><comments>17 Pages, 52 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of the well known algorithms for watermarking of digital images involve
transformation of the image data to Fourier or singular vector space. In this
paper, we introduce watermarking in Hilbert transform domain for digital media.
Generally, if the image is a matrix of order $m$ by $n$, then the transformed
space is also an image of the same order. However, with Hilbert transforms, the
transformed space is of order $2m$ by $2n$. This allows for more latitude in
storing the watermark in the host image. Based on this idea, we propose an
algorithm for embedding and extracting watermark in a host image and
analytically obtain a parameter related to this procedure. Using extensive
simulations, we show that the algorithm performs well even if the host image is
corrupted by various attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2979</identifier>
 <datestamp>2010-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2979</id><created>2010-12-14</created><authors><author><keyname>Mukhopadhyay</keyname><forenames>Debajyoti</forenames></author><author><keyname>Oh</keyname><forenames>Byung-Jun</forenames></author><author><keyname>Shim</keyname><forenames>Sang-Heon</forenames></author><author><keyname>Kim</keyname><forenames>Young-Chon</forenames></author></authors><title>A Study on Recent Approaches in Handling DDoS Attacks</title><categories>cs.CR</categories><comments>7 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a study on the recent approaches in handling
Distributed Denial of Service (DDoS) attacks. DDoS attack is a fairly new type
of attack to cripple the availability of Internet services and resources. A
DDos attack can originate from anywhere in the network and typically overwhelms
the victim server by sending a huge number of packets. Several remedial
measures have been proposed by various researchers. This paper attempts to
discuss the recent offerings to handle the DDoS attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2995</identifier>
 <datestamp>2010-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2995</id><created>2010-12-14</created><authors><author><keyname>Dam</keyname><forenames>Mads</forenames></author><author><keyname>Lundblad</keyname><forenames>Andreas</forenames></author></authors><title>A Proof Carrying Code Framework for Inlined Reference Monitors in Java
  Bytecode</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a light-weight approach for certification of monitor inlining for
sequential Java bytecode using proof-carrying code. The goal is to enable the
use of monitoring for quality assurance at development time, while minimizing
the need for post-shipping code rewrites as well as changes to the end-host
TCB. Standard automaton-based security policies express constraints on allowed
API call/return sequences. Proofs are represented as JML-style program
annotations. This is adequate in our case as all proofs generated in our
framework are recognized in time polynomial in the size of the program. Policy
adherence is proved by comparing the transitions of an inlined monitor with
those of a trusted &quot;ghost&quot; monitor represented using JML-style annotations. At
time of receiving a program with proof annotations, it is sufficient for the
receiver to plug in its own trusted ghost monitor and check the resulting
verification conditions, to verify that inlining has been performed correctly,
of the correct policy. We have proved correctness of the approach at the Java
bytecode level and formalized the proof of soundness in Coq. An implementation,
including an application loader running on a mobile device, is available, and
we conclude by giving benchmarks for two sample applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.2998</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.2998</id><created>2010-12-14</created><authors><author><keyname>Kiefer</keyname><forenames>Stefan</forenames></author><author><keyname>Wojtczak</keyname><forenames>Dominik</forenames></author></authors><title>On Probabilistic Parallel Programs with Process Creation and
  Synchronisation</title><categories>cs.LO cs.FL</categories><comments>This is a technical report accompanying a TACAS'11 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We initiate the study of probabilistic parallel programs with dynamic process
creation and synchronisation. To this end, we introduce probabilistic
split-join systems (pSJSs), a model for parallel programs, generalising both
probabilistic pushdown systems (a model for sequential probabilistic procedural
programs which is equivalent to recursive Markov chains) and stochastic
branching processes (a classical mathematical model with applications in
various areas such as biology, physics, and language processing). Our pSJS
model allows for a possibly recursive spawning of parallel processes; the
spawned processes can synchronise and return values. We study the basic
performance measures of pSJSs, especially the distribution and expectation of
space, work and time. Our results extend and improve previously known results
on the subsumed models. We also show how to do performance analysis in
practice, and present two case studies illustrating the modelling power of
pSJSs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3000</identifier>
 <datestamp>2010-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3000</id><created>2010-12-14</created><authors><author><keyname>Santini</keyname><forenames>Massimo</forenames></author></authors><title>Random Generation and Approximate Counting of Combinatorial Structures</title><categories>cs.CC</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The aim of this thesis is to determine classes of NP relations for which
random generation and approximate counting problems admit an efficient
solution. Since efficient rank implies efficient random generation, we first
investigate some classes of NP relations admitting efficient ranking. On the
other hand, there are situations in which efficient random generation is
possible even when ranking is computationally infeasible. We introduce the
notion of ambiguous description as a tool for random generation and approximate
counting in such cases and show, in particular, some applications to the case
of formal languages. Finally, we discuss a limit of an heuristic for
combinatorial optimization problems based on the random initialization of local
search algorithms showing that derandomizing such heuristic can be, in some
cases, #P-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3005</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3005</id><created>2010-12-14</created><updated>2011-03-19</updated><authors><author><keyname>Gai</keyname><forenames>Yi</forenames></author><author><keyname>Krishnamachari</keyname><forenames>Bhaskar</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author></authors><title>On the Combinatorial Multi-Armed Bandit Problem with Markovian Rewards</title><categories>math.OC cs.LG cs.NI cs.SY math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a combinatorial generalization of the classical multi-armed
bandit problem that is defined as follows. There is a given bipartite graph of
$M$ users and $N \geq M$ resources. For each user-resource pair $(i,j)$, there
is an associated state that evolves as an aperiodic irreducible finite-state
Markov chain with unknown parameters, with transitions occurring each time the
particular user $i$ is allocated resource $j$. The user $i$ receives a reward
that depends on the corresponding state each time it is allocated the resource
$j$. The system objective is to learn the best matching of users to resources
so that the long-term sum of the rewards received by all users is maximized.
This corresponds to minimizing regret, defined here as the gap between the
expected total reward that can be obtained by the best-possible static matching
and the expected total reward that can be achieved by a given algorithm. We
present a polynomial-storage and polynomial-complexity-per-step
matching-learning algorithm for this problem. We show that this algorithm can
achieve a regret that is uniformly arbitrarily close to logarithmic in time and
polynomial in the number of users and resources. This formulation is broadly
applicable to scheduling and switching problems in networks and significantly
extends prior results in the area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3011</identifier>
 <datestamp>2010-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3011</id><created>2010-12-14</created><authors><author><keyname>Ailon</keyname><forenames>Nir</forenames></author><author><keyname>Avigdor-Elgrabli</keyname><forenames>Noa</forenames></author><author><keyname>Liberty</keyname><forenames>Edo</forenames></author></authors><title>An Improved Algorithm for Bipartite Correlation Clustering</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bipartite Correlation clustering is the problem of generating a set of
disjoint bi-cliques on a set of nodes while minimizing the symmetric difference
to a bipartite input graph. The number or size of the output clusters is not
constrained in any way. The best known approximation algorithm for this problem
gives a factor of 11. This result and all previous ones involve solving large
linear or semi-definite programs which become prohibitive even for modestly
sized tasks. In this paper we present an improved factor 4 approximation
algorithm to this problem using a simple combinatorial algorithm which does not
require solving large convex programs. The analysis extends a method developed
by Ailon, Charikar and Alantha in 2008, where a randomized pivoting algorithm
was analyzed for obtaining a 3-approximation algorithm for Correlation
Clustering, which is the same problem on graphs (not bipartite). The analysis
for Correlation Clustering there required defining events for structures
containing 3 vertices and using the probability of these events to produce a
feasible solution to a dual of a certain natural LP bounding the optimal cost.
It is tempting here to use sets of 4 vertices, which are the smallest
structures for which contradictions arise for Bipartite Correlation Clustering.
This simple idea, however, appears to be evasive. We show that, by modifying
the LP, we can analyze algorithms which take into consideration subgraph
structures of unbounded size. We believe our techniques are interesting in
their own right, and may be used for other problems as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3013</identifier>
 <datestamp>2010-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3013</id><created>2010-12-14</created><authors><author><keyname>Helling</keyname><forenames>Ch.</forenames><affiliation>SUPA, St Andrews, UK</affiliation></author><author><keyname>Pedretti</keyname><forenames>E.</forenames><affiliation>SUPA, St Andrews, UK</affiliation></author><author><keyname>Berdyugina</keyname><forenames>S.</forenames><affiliation>Kiepenheuer Institut, Freiburg, D</affiliation></author><author><keyname>Vidotto</keyname><forenames>A. A.</forenames><affiliation>SUPA, St Andrews, UK</affiliation></author><author><keyname>Beeck</keyname><forenames>B.</forenames><affiliation>University Goettingen, D</affiliation></author><author><keyname>Baron</keyname><forenames>E.</forenames><affiliation>University of Oklahoma, Norman, US</affiliation></author><author><keyname>Showman</keyname><forenames>A. P.</forenames><affiliation>University of Arizona, Tucson, US</affiliation></author><author><keyname>Agol</keyname><forenames>E.</forenames><affiliation>University of Washington, Seattle, UK</affiliation></author><author><keyname>Homeier</keyname><forenames>D.</forenames><affiliation>University Goettingen, D</affiliation></author></authors><title>Aspects of Multi-Dimensional Modelling of Substellar Atmospheres</title><categories>astro-ph.SR astro-ph.EP cs.CE physics.ao-ph physics.flu-dyn</categories><comments>12 pages, 5 figures, summery of Cool Stars 16 Splinter
  'Multi-Dimensional Modelling of Substellar Atmospheres'</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Theoretical arguments and observations suggest that the atmospheres of Brown
Dwarfs and planets are very dynamic on chemical and on physical time scales.
The modelling of such substellar atmospheres has, hence, been much more
demanding than initially anticipated. This Splinter
(http://star-www.st-and.ac.uk/~ch80/CS16/MultiDSplinter_CS16.html) has combined
new developments in atmosphere modelling, with novel observational techniques,
and new challenges arising from planetary and space weather observations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3018</identifier>
 <datestamp>2010-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3018</id><created>2010-12-14</created><authors><author><keyname>Liberatore</keyname><forenames>Paolo</forenames></author><author><keyname>Schaerf</keyname><forenames>Marco</forenames></author></authors><title>On the size of data structures used in symbolic model checking</title><categories>cs.AI cs.CC cs.DS cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Temporal Logic Model Checking is a verification method in which we describe a
system, the model, and then we verify whether some properties, expressed in a
temporal logic formula, hold in the system. It has many industrial
applications. In order to improve performance, some tools allow preprocessing
of the model, verifying on-line a set of properties reusing the same compiled
model; we prove that the complexity of the Model Checking problem, without any
preprocessing or preprocessing the model or the formula in a polynomial data
structure, is the same. As a result preprocessing does not always exponentially
improve performance.
  Symbolic Model Checking algorithms work by manipulating sets of states, and
these sets are often represented by BDDs. It has been observed that the size of
BDDs may grow exponentially as the model and formula increase in size. As a
side result, we formally prove that a superpolynomial increase of the size of
these BDDs is unavoidable in the worst case. While this exponential growth has
been empirically observed, to the best of our knowledge it has never been
proved so far in general terms. This result not only holds for all types of
BDDs regardless of the variable ordering, but also for more powerful data
structures, such as BEDs, RBCs, MTBDDs, and ADDs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3023</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3023</id><created>2010-12-14</created><updated>2012-02-03</updated><authors><author><keyname>Tabourier</keyname><forenames>Lionel</forenames></author><author><keyname>Roth</keyname><forenames>Camille</forenames></author><author><keyname>Cointet</keyname><forenames>Jean-Philippe</forenames></author></authors><title>Generating constrained random graphs using multiple edge switches</title><categories>cs.SI physics.soc-ph</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The generation of random graphs using edge swaps provides a reliable method
to draw uniformly random samples of sets of graphs respecting some simple
constraints, e.g. degree distributions. However, in general, it is not
necessarily possible to access all graphs obeying some given con- straints
through a classical switching procedure calling on pairs of edges. We therefore
propose to get round this issue by generalizing this classical approach through
the use of higher-order edge switches. This method, which we denote by &quot;k-edge
switching&quot;, makes it possible to progres- sively improve the covered portion of
a set of constrained graphs, thereby providing an increasing, asymptotically
certain confidence on the statistical representativeness of the obtained
sample.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3024</identifier>
 <datestamp>2010-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3024</id><created>2010-12-14</created><authors><author><keyname>Boldi</keyname><forenames>Paolo</forenames></author><author><keyname>Vigna</keyname><forenames>Sebastiano</forenames></author></authors><title>E = I + T: The internal extent formula for compacted tries</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that in a binary tree the external path length minus the
internal path length is exactly 2n-2, where n is the number of external nodes.
We show that a generalization of the formula holds for compacted tries,
replacing the role of paths with the notion of extent, and the value 2n-2 with
the trie measure, an estimation of the number of bits that are necessary to
describe the trie.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3030</identifier>
 <datestamp>2011-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3030</id><created>2010-12-13</created><updated>2011-03-23</updated><authors><author><keyname>Dunfield</keyname><forenames>Nathan M.</forenames></author><author><keyname>Hirani</keyname><forenames>Anil N.</forenames></author></authors><title>The Least Spanning Area of a Knot and the Optimal Bounding Chain Problem</title><categories>cs.CG cs.DS math.DG math.GT</categories><comments>9 pages, 5 figures. V2: Added Remark 5.7. V3: Many minor
  improvements. To appear in SoCG 2011</comments><msc-class>57M35, 57M25, 49Q05, 68U05</msc-class><acm-class>F.2.2; G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two fundamental objects in knot theory are the minimal genus surface and the
least area surface bounded by a knot in a 3-dimensional manifold. When the knot
is embedded in a general 3-manifold, the problems of finding these surfaces
were shown to be NP-complete and NP-hard respectively. However, there is
evidence that the special case when the ambient manifold is R^3, or more
generally when the second homology is trivial, should be considerably more
tractable. Indeed, we show here that a natural discrete version of the least
area surface can be found in polynomial time. The precise setting is that the
knot is a 1-dimensional subcomplex of a triangulation of the ambient
3-manifold. The main tool we use is a linear programming formulation of the
Optimal Bounding Chain Problem (OBCP), where one is required to find the
smallest norm chain with a given boundary. While the decision variant of OBCP
is NP-complete in general, we give conditions under which it can be solved in
polynomial time. We then show that the least area surface can be constructed
from the optimal bounding chain using a standard desingularization argument
from 3-dimensional topology. We also prove that the related Optimal Homologous
Chain Problem is NP-complete for homology with integer coefficients,
complementing the corresponding result of Chen and Freedman for mod 2 homology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3040</identifier>
 <datestamp>2010-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3040</id><created>2010-12-13</created><authors><author><keyname>Ding</keyname><forenames>Jie</forenames></author><author><keyname>Hillston</keyname><forenames>Jane</forenames></author></authors><title>Numerically Representing A Stochastic Process Algebra</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The syntactic nature and compositionality characteristic of stochastic
process algebras make models to be easily understood by human beings, but not
convenient for machines as well as people to directly carry out mathematical
analysis and stochastic simulation. This paper presents a numerical
representation schema for the stochastic process algebra PEPA, which can
provide a platform to directly and conveniently employ a variety of
computational approaches to both qualitatively and quantitatively analyse the
models. Moreover, these approaches developed on the basis of the schema are
demonstrated and discussed. In particular, algorithms for automatically
deriving the schema from a general PEPA model and simulating the model based on
the derived schema to derive performance measures are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3057</identifier>
 <datestamp>2011-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3057</id><created>2010-12-14</created><updated>2011-07-05</updated><authors><author><keyname>Schlei</keyname><forenames>B. R.</forenames></author></authors><title>Speeding Up the 3D Surface Generator VESTA</title><categories>cs.CG cs.GR</categories><comments>This paper has been withdrawn, since it will become a part of a new
  version of &quot;Volume-Enclosing Surface Extraction&quot;, by B. R. Schlei,
  arXiv:1011.1787</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The very recent volume-enclosing surface extraction algorithm, VESTA, is
revisited. VESTA is used to determine implicit surfaces that are potentially
contained in 3D data sets, such as 3D image data and/or 3D simulation data.
VESTA surfaces are non-degenerate, i.e., they always enclose a volume that is
larger than zero and they never self-intersect, prior to a further processing,
e.g., towards isosurfaces. In addition to its ability to deal with local cell
ambiguities consistently - and thereby avoiding the accidental generation of
holes in the final surfaces - the information of the interior and/or exterior
of enclosed 3D volumes is propagated correctly to each of the final surface
tiles. Particular emphasis is put here on the speed up of the original
formulation of VESTA, while applying the algorithm to 2x2x2 voxel
neighborhoods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3059</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3059</id><created>2010-12-14</created><updated>2012-07-09</updated><authors><author><keyname>Ryabko</keyname><forenames>Boris</forenames></author><author><keyname>Ryabko</keyname><forenames>Daniil</forenames></author></authors><title>Confidence Sets in Time-Series Filtering</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>some of the results were reported at ISIT2011, St. Petersburg,
  Russia, pp. 2436-2438</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of filtering of finite-alphabet stationary ergodic time series is
considered. A method for constructing a confidence set for the (unknown) signal
is proposed, such that the resulting set has the following properties: First,
it includes the unknown signal with probability $\gamma$, where $\gamma$ is a
parameter supplied to the filter. Second, the size of the confidence sets grows
exponentially with the rate that is asymptotically equal to the conditional
entropy of the signal given the data. Moreover, it is shown that this rate is
optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3071</identifier>
 <datestamp>2010-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3071</id><created>2010-12-14</created><authors><author><keyname>Rahmati</keyname><forenames>Ahmad</forenames></author><author><keyname>Shepard</keyname><forenames>Clay</forenames></author><author><keyname>Tossell</keyname><forenames>Chad</forenames></author><author><keyname>Nicoara</keyname><forenames>Angela</forenames></author><author><keyname>Zhong</keyname><forenames>Lin</forenames></author><author><keyname>Kortum</keyname><forenames>Phil</forenames></author><author><keyname>Singh</keyname><forenames>Jatinder</forenames></author></authors><title>Seamless Flow Migration on Smartphones without Network Support</title><categories>cs.NI cs.OS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the following question: Is it possible to migrate TCP/IP
flows between different networks on modern mobile devices, without
infrastructure support or protocol changes? To answer this question, we make
three research contributions. (i) We report a comprehensive characterization of
IP traffic on smartphones using traces collected from 27 iPhone 3GS users for
three months. (ii) Driven by the findings from the characterization, we devise
two novel system mechanisms for mobile devices to sup-port seamless flow
migration without network support, and extensively evaluate their effectiveness
using our field collected traces of real-life usage. Wait-n-Migrate leverages
the fact that most flows are short lived. It establishes new flows on newly
available networks but allows pre-existing flows on the old network to
terminate naturally, effectively decreasing, or even eliminating, connectivity
gaps during network switches. Resumption Agent takes advantage of the
functionality integrated into many modern protocols to securely resume flows
without application intervention. When combined, Wait-n-Migrate and Resumption
Agent provide an unprecedented opportunity to immediately deploy performance
and efficiency-enhancing policies that leverage multiple networks to improve
the performance, efficiency, and connectivity of mobile devices. (iii) Finally,
we report an iPhone 3GS based implementation of these two system mechanisms and
show that their overhead is negligible. Furthermore, we employ an example
network switching policy, called AutoSwitch, to demonstrate their performance.
AutoSwitch improves the Wi-Fi user experience by intelligently migrating TCP
flows between Wi-Fi and cellular networks. Through traces and field
measurements, we show that AutoSwitch reduces the number of user disruptions by
an order of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3098</identifier>
 <datestamp>2010-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3098</id><created>2010-12-14</created><authors><author><keyname>Lehre</keyname><forenames>Per Kristian</forenames></author><author><keyname>Yao</keyname><forenames>Xin</forenames></author></authors><title>On the Impact of Mutation-Selection Balance on the Runtime of
  Evolutionary Algorithms</title><categories>cs.NE nlin.AO q-bio.PE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The interplay between mutation and selection plays a fundamental role in the
behaviour of evolutionary algorithms (EAs). However, this interplay is still
not completely understood. This paper presents a rigorous runtime analysis of a
non-elitist population-based EA that uses the linear ranking selection
mechanism. The analysis focuses on how the balance between parameter $\eta$,
controlling the selection pressure in linear ranking, and parameter $\chi$
controlling the bit-wise mutation rate, impacts the runtime of the algorithm.
The results point out situations where a correct balance between selection
pressure and mutation rate is essential for finding the optimal solution in
polynomial time. In particular, it is shown that there exist fitness functions
which can only be solved in polynomial time if the ratio between parameters
$\eta$ and $\chi$ is within a narrow critical interval, and where a small
change in this ratio can increase the runtime exponentially. Furthermore, it is
shown quantitatively how the appropriate parameter choice depends on the
characteristics of the fitness function. In addition to the original results on
the runtime of EAs, this paper also introduces a very useful analytical tool,
i.e., multi-type branching processes, to the runtime analysis of non-elitist
population-based EAs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3100</identifier>
 <datestamp>2010-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3100</id><created>2010-12-14</created><authors><author><keyname>Sun</keyname><forenames>Cong</forenames></author><author><keyname>Tang</keyname><forenames>Liyong</forenames></author><author><keyname>Chen</keyname><forenames>Zhong</forenames></author></authors><title>Secure Information Flow by Model Checking Pushdown System</title><categories>cs.CR</categories><comments>20 pages, this is an extended version of the paper published in
  UIC-ATC'09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an approach on model checking information flow for imperative
language with procedures. We characterize our model with pushdown system, which
has a stack of unbounded length that naturally models the execution of
procedural programs. Because the type-based static analysis is sometimes too
conservative and rejects safe program as ill-typed, we take a semantic-based
approach by self-composing symbolic pushdown system and specifying
noninterference with LTL formula. Then we verify this LTL-expressed property
via model checker Moped. Except for overcoming the conservative characteristic
of type-based approach, our motivation also includes the insufficient state of
arts on precise information flow analysis under inter-procedural setting. To
remedy the inefficiency of model checking compared with type system, we propose
both compact form and contracted form of self-composition. According to our
experimental results, they can greatly increase the efficiency of realistic
verification. Our method provides flexibility on separating program abstraction
from noninterference verification, thus could be expected to use on different
programming languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3117</identifier>
 <datestamp>2015-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3117</id><created>2010-12-14</created><updated>2015-09-01</updated><authors><author><keyname>Maor</keyname><forenames>Cy</forenames></author></authors><title>Cooperation under Incomplete Information on the Discount Factors</title><categories>cs.GT math.PR</categories><comments>Thesis submitted in partial fulfillment of requirements for the M.
  Sc. degree in the School of Mathematical Sciences, Tel-Aviv University. The
  research work for this thesis has been carried out at Tel-Aviv University
  under the supervision of Prof. Eilon Solan</comments><msc-class>91Axx</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the repeated Prisoner's Dilemma, when every player has a different
discount factor, the grim-trigger strategy is an equilibrium if and only if the
discount factor of each player is higher than some threshold. What happens if
the players have incomplete information regarding the discount factors? In this
work we look at repeated games in which each player has incomplete information
regarding the other player's discount factor, and ask when a pair of
grim-trigger strategies is an equilibrium. We provide necessary and sufficient
conditions for such strategies to be an equilibrium. We characterize the states
of the world in which the strategies are not triggered, i.e., the players
cooperate, in such equilibria (or $\epsilon$-equilibria), and ask whether these
&quot;cooperation events&quot; are close to those in the complete information case, when
the information is &quot;almost&quot; complete, in several senses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3127</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3127</id><created>2010-12-14</created><updated>2011-03-16</updated><authors><author><keyname>Fox</keyname><forenames>Jacob</forenames></author><author><keyname>Lee</keyname><forenames>Choongbum</forenames></author><author><keyname>Sudakov</keyname><forenames>Benny</forenames></author></authors><title>Maximum union-free subfamilies</title><categories>math.CO cs.DM</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An old problem of Moser asks: how large of a union-free subfamily does every
family of m sets have? A family of sets is called union-free if there are no
three distinct sets in the family such that the union of two of the sets is
equal to the third set. We show that every family of m sets contains a
union-free subfamily of size at least \lfloor \sqrt{4m+1}\rfloor - 1 and that
this bound is tight. This solves Moser's problem and proves a conjecture of
Erd\H{o}s and Shelah from 1972. More generally, a family of sets is
a-union-free if there are no a+1 distinct sets in the family such that one of
them is equal to the union of a others. We determine up to an absolute
multiplicative constant factor the size of the largest guaranteed a-union-free
subfamily of a family of m sets. Our result verifies in a strong form a
conjecture of Barat, F\&quot;{u}redi, Kantor, Kim and Patkos.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3130</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3130</id><created>2010-12-14</created><updated>2013-04-16</updated><authors><author><keyname>Braverman</keyname><forenames>Vladimir</forenames></author><author><keyname>Gelles</keyname><forenames>Ran</forenames></author><author><keyname>Ostrovsky</keyname><forenames>Rafail</forenames></author></authors><title>How to Catch L_2-Heavy-Hitters on Sliding Windows</title><categories>cs.DS</categories><comments>v3: updated acknowledgment v2: minor changes; extended abstract to
  appear in COCOON 2013</comments><doi>10.1016/j.tcs.2014.06.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding heavy-elements (heavy-hitters) in streaming data is one of the
central, and well-understood tasks. Despite the importance of this problem,
when considering the sliding windows model of streaming (where elements
eventually expire) the problem of finding L_2-heavy elements has remained
completely open despite multiple papers and considerable success in finding
L_1-heavy elements.
  In this paper, we develop the first poly-logarithmic-memory algorithm for
finding L_2-heavy elements in sliding window model. Since L_2 heavy elements
play a central role for many fundamental streaming problems (such as frequency
moments), we believe our method would be extremely useful for many
sliding-windows algorithms and applications. For example, our technique allows
us not only to find L_2-heavy elements, but also heavy elements with respect to
any L_p for 0&lt;p&lt;2 on sliding windows. Thus, our paper completely resolves the
question of finding L_p-heavy elements for sliding windows with
poly-logarithmic memory for all values of p since it is well known that for p&gt;2
this task is impossible.
  Our method may have other applications as well. We demonstrate a broader
applicability of our novel yet simple method on two additional examples: we
show how to obtain a sliding window approximation of other properties such as
the similarity of two streams, or the fraction of elements that appear exactly
a specified number of times within the window (the rarity problem). In these
two illustrative examples of our method, we replace the current expected memory
bounds with worst case bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3148</identifier>
 <datestamp>2010-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3148</id><created>2010-12-14</created><authors><author><keyname>Agrawal</keyname><forenames>Kush</forenames></author></authors><title>To study the phenomenon of the Moravec's Paradox</title><categories>cs.AI cs.RO</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  &quot;Encoded in the large, highly evolved sensory and motor portions of the human
brain is a billion years of experience about the nature of the world and how to
survive in it. The deliberate process we call reasoning is, I believe, the
thinnest veneer of human thought, effective only because it is supported by
this much older and much powerful, though usually unconscious, sensor motor
knowledge. We are all prodigious Olympians in perceptual and motor areas, so
good that we make the difficult look easy. Abstract thought, though, is a new
trick, perhaps less than 100 thousand years old. We have not yet mastered it.
It is not all that intrinsically difficult; it just seems so when we do it.&quot;-
Hans Moravec Moravec's paradox is involved with the fact that it is the
seemingly easier day to day problems that are harder to implement in a machine,
than the seemingly complicated logic based problems of today. The results prove
that most artificially intelligent machines are as adept if not more than us at
under-taking long calculations or even play chess, but their logic brings them
nowhere when it comes to carrying out everyday tasks like walking, facial
gesture recognition or speech recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3156</identifier>
 <datestamp>2010-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3156</id><created>2010-12-14</created><authors><author><keyname>Wang</keyname><forenames>Pu</forenames></author><author><keyname>Gonz&#xe1;lez</keyname><forenames>Marta C.</forenames></author><author><keyname>Menezes</keyname><forenames>Ronaldo</forenames></author><author><keyname>Barab&#xe1;si</keyname><forenames>Albert-L&#xe1;szl&#xf3;</forenames></author></authors><title>New generation of mobile phone viruses and corresponding countermeasures</title><categories>cs.NI cs.CR physics.soc-ph</categories><comments>19 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fast growing market for smart phones coupled with their almost continuous
online presence makes these devices the new targets of virus writers. It has
been recently found that the topological spread of MMS (Multimedia Message
Services) viruses is highly restricted by the underlying fragmentation of the
call graph. In this paper, we study MMS viruses under another type of spreading
behavior: scanning. We find that hybrid MMS viruses including some level of
scanning are more dangerous to the mobile community than their standard
topological counterparts. However, the effectiveness of both scanning and
topological behaviors in MMS viruses can generally be limited by two
controlling methods: (i) decreasing susceptible handsets' market share (OS it
runs) and (ii) improving monitoring capacity to limit the frequency in which
MMS messages can be sent by the mobile viruses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3174</identifier>
 <datestamp>2011-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3174</id><created>2010-12-14</created><updated>2011-06-20</updated><authors><author><keyname>Ambainis</keyname><forenames>Andris</forenames></author><author><keyname>Childs</keyname><forenames>Andrew M.</forenames></author><author><keyname>Liu</keyname><forenames>Yi-Kai</forenames></author></authors><title>Quantum property testing for bounded-degree graphs</title><categories>quant-ph cs.CC</categories><comments>21 pages; v3: more detailed proof of the lower bound; v2: minor
  corrections to Lemma 6</comments><report-no>NSF-KITP-10-147</report-no><journal-ref>Proceedings of RANDOM 2011, Lecture Notes in Computer Science
  6845, pp. 365-376</journal-ref><doi>10.1007/978-3-642-22935-0_31</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study quantum algorithms for testing bipartiteness and expansion of
bounded-degree graphs. We give quantum algorithms that solve these problems in
time O(N^(1/3)), beating the Omega(sqrt(N)) classical lower bound. For testing
expansion, we also prove an Omega(N^(1/4)) quantum query lower bound, thus
ruling out the possibility of an exponential quantum speedup. Our quantum
algorithms follow from a combination of classical property testing techniques
due to Goldreich and Ron, derandomization, and the quantum algorithm for
element distinctness. The quantum lower bound is obtained by the polynomial
method, using novel algebraic techniques and combinatorial analysis to
accommodate the graph structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3189</identifier>
 <datestamp>2015-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3189</id><created>2010-12-14</created><updated>2015-12-19</updated><authors><author><keyname>Li</keyname><forenames>Jian</forenames></author><author><keyname>Deshpande</keyname><forenames>Amol</forenames></author></authors><title>Maximizing Expected Utility for Stochastic Combinatorial Optimization
  Problems</title><categories>cs.DS cs.DB</categories><comments>30 pages, Preliminary version appears in the Proceeding of the 52nd
  Annual IEEE Symposium on Foundations of Computer Science (FOCS 2011), This
  version contains several new results ( results (2) and (3) in the abstract)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the stochastic versions of a broad class of combinatorial problems
where the weights of the elements in the input dataset are uncertain. The class
of problems that we study includes shortest paths, minimum weight spanning
trees, and minimum weight matchings, and other combinatorial problems like
knapsack. We observe that the expected value is inadequate in capturing
different types of {\em risk-averse} or {\em risk-prone} behaviors, and instead
we consider a more general objective which is to maximize the {\em expected
utility} of the solution for some given utility function, rather than the
expected weight (expected weight becomes a special case). Under the assumption
that there is a pseudopolynomial time algorithm for the {\em exact} version of
the problem (This is true for the problems mentioned above), we can obtain the
following approximation results for several important classes of utility
functions: (1) If the utility function $\uti$ is continuous, upper-bounded by a
constant and $\lim_{x\rightarrow+\infty}\uti(x)=0$, we show that we can obtain
a polynomial time approximation algorithm with an {\em additive error}
$\epsilon$ for any constant $\epsilon&gt;0$. (2) If the utility function $\uti$ is
a concave increasing function, we can obtain a polynomial time approximation
scheme (PTAS). (3) If the utility function $\uti$ is increasing and has a
bounded derivative, we can obtain a polynomial time approximation scheme. Our
results recover or generalize several prior results on stochastic shortest
path, stochastic spanning tree, and stochastic knapsack. Our algorithm for
utility maximization makes use of the separability of exponential utility and a
technique to decompose a general utility function into exponential utility
functions, which may be useful in other stochastic optimization problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3198</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3198</id><created>2010-12-14</created><updated>2011-09-11</updated><authors><author><keyname>Huh</keyname><forenames>Hoon</forenames></author><author><keyname>Tulino</keyname><forenames>Antonia M.</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>Network MIMO with Linear Zero-Forcing Beamforming: Large System
  Analysis, Impact of Channel Estimation and Reduced-Complexity Scheduling</title><categories>cs.IT math.IT</categories><comments>52 pages, 7 figures, revised and submitted to IEEE Trans. on Inform.
  Theory (under the 2nd review)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the downlink of a multi-cell system with multi-antenna base
stations and single-antenna user terminals, arbitrary base station cooperation
clusters, distance-dependent propagation pathloss, and general &quot;fairness&quot;
requirements. Base stations in the same cooperation cluster employ joint
transmission with linear zero-forcing beamforming, subject to sum or per-base
station power constraints. Inter-cluster interference is treated as noise at
the user terminals. Analytic expressions for the system spectral efficiency are
found in the large-system limit where both the numbers of users and antennas
per base station tend to infinity with a given ratio. In particular, for the
per-base station power constraint, we find new results in random matrix theory,
yielding the squared Frobenius norm of submatrices of the Moore-Penrose
pseudo-inverse for the structured non-i.i.d. channel matrix resulting from the
cooperation cluster, user distribution, and path-loss coefficients. The
analysis is extended to the case of non-ideal Channel State Information at the
Transmitters (CSIT) obtained through explicit downlink channel training and
uplink feedback. Specifically, our results illuminate the trade-off between the
benefit of a larger number of cooperating antennas and the cost of estimating
higher-dimensional channel vectors. Furthermore, our analysis leads to a new
simplified downlink scheduling scheme that pre-selects the users according to
probabilities obtained from the large-system results, depending on the desired
fairness criterion. The proposed scheme performs close to the optimal
(finite-dimensional) opportunistic user selection while requiring significantly
less channel state feedback, since only a small fraction of pre-selected users
must feed back their channel state information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3201</identifier>
 <datestamp>2010-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3201</id><created>2010-12-14</created><authors><author><keyname>Huang</keyname><forenames>Qin</forenames></author><author><keyname>Diao</keyname><forenames>Qiuju</forenames></author><author><keyname>Lin</keyname><forenames>Shu</forenames></author><author><keyname>Abdel-Ghaffar</keyname><forenames>Khaled</forenames></author></authors><title>Cyclic and Quasi-Cyclic LDPC Codes on Row and Column Constrained
  Parity-Check Matrices and Their Trapping Sets</title><categories>cs.IT math.IT</categories><comments>70 pages, submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with construction and structural analysis of both
cyclic and quasi-cyclic codes, particularly LDPC codes. It consists of three
parts. The first part shows that a cyclic code given by a parity-check matrix
in circulant form can be decomposed into descendant cyclic and quasi-cyclic
codes of various lengths and rates. Some fundamental structural properties of
these descendant codes are developed, including the characterizations of the
roots of the generator polynomial of a cyclic descendant code. The second part
of the paper shows that cyclic and quasi-cyclic descendant LDPC codes can be
derived from cyclic finite geometry LDPC codes using the results developed in
first part of the paper. This enlarges the repertoire of cyclic LDPC codes. The
third part of the paper analyzes the trapping sets of regular LDPC codes whose
parity-check matrices satisfy a certain constraint on their rows and columns.
Several classes of finite geometry and finite field cyclic and quasi-cyclic
LDPC codes with large minimum weights are shown to have no harmful trapping
sets with size smaller than their minimum weights. Consequently, their
performance error-floors are dominated by their minimum weights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3216</identifier>
 <datestamp>2010-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3216</id><created>2010-12-14</created><authors><author><keyname>Zhang</keyname><forenames>Zhengdong</forenames></author><author><keyname>Ganesh</keyname><forenames>Arvind</forenames></author><author><keyname>Liang</keyname><forenames>Xiao</forenames></author><author><keyname>Ma</keyname><forenames>Yi</forenames></author></authors><title>TILT: Transform Invariant Low-rank Textures</title><categories>cs.CV</categories><comments>Submitted to IJCV. Conference version presented at ACCV 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show how to efficiently and effectively extract a class of
&quot;low-rank textures&quot; in a 3D scene from 2D images despite significant
corruptions and warping. The low-rank textures capture geometrically meaningful
structures in an image, which encompass conventional local features such as
edges and corners as well as all kinds of regular, symmetric patterns
ubiquitous in urban environments and man-made objects. Our approach to finding
these low-rank textures leverages the recent breakthroughs in convex
optimization that enable robust recovery of a high-dimensional low-rank matrix
despite gross sparse errors. In the case of planar regions with significant
affine or projective deformation, our method can accurately recover both the
intrinsic low-rank texture and the precise domain transformation, and hence the
3D geometry and appearance of the planar regions. Extensive experimental
results demonstrate that this new technique works effectively for many regular
and near-regular patterns or objects that are approximately low-rank, such as
symmetrical patterns, building facades, printed texts, and human faces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3252</identifier>
 <datestamp>2010-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3252</id><created>2010-12-15</created><authors><author><keyname>Criado</keyname><forenames>Regino</forenames></author><author><keyname>Flores</keyname><forenames>Julio</forenames></author><author><keyname>del Amo</keyname><forenames>Alejandro Garc&#xed;a</forenames></author><author><keyname>G&#xf3;mez-Garde&#xf1;es</keyname><forenames>Jes&#xfa;s</forenames></author><author><keyname>Romance</keyname><forenames>Miguel</forenames></author></authors><title>A mathematical model for networks with structures in the mesoscale</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI math.CO</categories><comments>21 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The new concept of multilevel network is introduced in order to embody some
topological properties of complex systems with structures in the mesoscale
which are not completely captured by the classical models. This new model,
which generalizes the hyper-network and hyper-structure models, fits perfectly
with several real-life complex systems, including social and public
transportation networks. We present an analysis of the structural properties of
the multilevel network, including the clustering and the metric structures.
Some analytical relationships amongst the efficiency and clustering coefficient
of this new model and the corresponding parameters of the underlying network
are obtained. Finally some random models for multilevel networks are given to
illustrate how different multilevel structures can produce similar underlying
networks and therefore that the mesoscale structure should be taken into
account in many applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3273</identifier>
 <datestamp>2010-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3273</id><created>2010-12-15</created><authors><author><keyname>Blum</keyname><forenames>Christian</forenames></author></authors><title>Iterative Beam Search for Simple Assembly Line Balancing with a Fixed
  Number of Work Stations</title><categories>cs.DM</categories><acm-class>G.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The simple assembly line balancing problem (SALBP) concerns the assignment of
tasks with pre-defined processing times to work stations that are arranged in a
line. Hereby, precedence constraints between the tasks must be respected. The
optimization goal of the SALBP-2 version of the problem concerns the
minimization of the so-called cycle time, that is, the time in which the tasks
of each work station must be completed.
  In this work we propose to tackle this problem with an iterative search
method based on beam search. The proposed algorithm is able to obtain optimal,
respectively best-known, solutions in 283 out of 302 test cases. Moreover, for
9 further test cases the algorithm is able to produce new best-known solutions.
These numbers indicate that the proposed iterative beam search algorithm is
currently a state-of-the-art method for the SALBP-2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3278</identifier>
 <datestamp>2010-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3278</id><created>2010-12-15</created><authors><author><keyname>Odumuyiwa</keyname><forenames>Victor</forenames><affiliation>LORIA</affiliation></author><author><keyname>Amos</keyname><forenames>David</forenames><affiliation>LORIA</affiliation></author></authors><title>Collaborative Knowledge Creation and Management in Information Retrieval</title><categories>cs.IR</categories><comments>KMO 2010 Knowledge management in organizations, veszpr\'em : Hongrie
  (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The final goal of Information Retrieval (IR) is knowledge production.
However, it has been argued that knowledge production is not an individual
effort but a collaborative effort. Collaboration in information retrieval is
geared towards knowledge sharing and creation of new knowledge by users. This
paper discusses Collaborative Information Retrieval (CIR) and how it culminates
to knowledge creation. It explains how created knowledge is organized and
structured. It describes a functional architecture for the development of a CIR
prototype called MECOCIR. Some of the features of the prototype are presented
as well as how they facilitate collaborative knowledge exploitation. Knowledge
creation is explained through the knowledge conversion/transformation processes
proposed by Nonaka and CIR activities that facilitate these processes are
high-lighted and discussed
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3280</identifier>
 <datestamp>2010-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3280</id><created>2010-12-15</created><authors><author><keyname>Nowakowski</keyname><forenames>Samuel</forenames><affiliation>LORIA</affiliation></author><author><keyname>Bernier</keyname><forenames>C&#xe9;dric</forenames><affiliation>LORIA</affiliation></author><author><keyname>Boyer</keyname><forenames>Anne</forenames><affiliation>LORIA</affiliation></author></authors><title>A new Recommender system based on target tracking: a Kalman Filter
  approach</title><categories>cs.AI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new approach for recommender systems based on
target tracking by Kalman filtering. We assume that users and their seen
resources are vectors in the multidimensional space of the categories of the
resources. Knowing this space, we propose an algorithm based on a Kalman filter
to track users and to predict the best prediction of their future position in
the recommendation space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3282</identifier>
 <datestamp>2010-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3282</id><created>2010-12-15</created><authors><author><keyname>Alpcan</keyname><forenames>Tansu</forenames></author></authors><title>Incentive Games and Mechanisms for Risk Management</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Incentives play an important role in (security and IT) risk management of a
large-scale organization with multiple autonomous divisions. This paper
presents an incentive mechanism design framework for risk management based on a
game-theoretic approach. The risk manager acts as a mechanism designer
providing rules and incentive factors such as assistance or subsidies to
divisions or units, which are modeled as selfish players of a strategic
(noncooperative) game. Based on this model, incentive mechanisms with various
objectives are developed that satisfy efficiency, preference-compatibility, and
strategy-proofness criteria. In addition, iterative and distributed algorithms
are presented, which can be implemented under information limitations such as
the risk manager not knowing the individual units' preferences. An example
scenario illustrates the framework and results numerically. The incentive
mechanism design approach presented is useful for not only deriving guidelines
but also developing computer-assistance systems for large-scale risk
management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3295</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3295</id><created>2010-12-15</created><authors><author><keyname>Eisenbrand</keyname><forenames>Friedrich</forenames></author><author><keyname>Kakimura</keyname><forenames>Naonori</forenames></author><author><keyname>Rothvo&#xdf;</keyname><forenames>Thomas</forenames></author><author><keyname>Sanit&#xe0;</keyname><forenames>Laura</forenames></author></authors><title>Set Covering with Ordered Replacement -- Additive and Multiplicative
  Gaps</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider set covering problems where the underlying set system satisfies a
particular replacement property w.r.t. a given partial order on the elements:
Whenever a set is in the set system then a set stemming from it via the
replacement of an element by a smaller element is also in the set system. Many
variants of BIN PACKING that have appeared in the literature are such set
covering problems with ordered replacement. We provide a rigorous account on
the additive and multiplicative integrality gap and approximability of set
covering with replacement. In particular we provide a polylogarithmic upper
bound on the additive integrality gap that also yields a polynomial time
additive approximation algorithm if the linear programming relaxation can be
efficiently solved. We furthermore present an extensive list of covering
problems that fall into our framework and consequently have polylogarithmic
additive gaps as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3310</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3310</id><created>2010-12-15</created><authors><author><keyname>Frasca</keyname><forenames>Paolo</forenames></author><author><keyname>Fagnani</keyname><forenames>Fabio</forenames></author></authors><title>The asymptotical error of broadcast gossip averaging algorithms</title><categories>math.OC cs.SY math.PR</categories><comments>10 pages, 3 figures. Based on a draft submitted to IFACWC2011</comments><msc-class>60G42, 93A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In problems of estimation and control which involve a network, efficient
distributed computation of averages is a key issue. This paper presents
theoretical and simulation results about the accumulation of errors during the
computation of averages by means of iterative &quot;broadcast gossip&quot; algorithms.
Using martingale theory, we prove that the expectation of the accumulated error
can be bounded from above by a quantity which only depends on the mixing
parameter of the algorithm and on few properties of the network: its size, its
maximum degree and its spectral gap. Both analytical results and computer
simulations show that in several network topologies of applicative interest the
accumulated error goes to zero as the size of the network grows large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3311</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3311</id><created>2010-12-15</created><updated>2011-08-18</updated><authors><author><keyname>Konrad</keyname><forenames>Christian</forenames></author><author><keyname>Magniez</keyname><forenames>Frederic</forenames></author></authors><title>Validating XML Documents in the Streaming Model with External Memory</title><categories>cs.DS cs.DB</categories><comments>Change title. Remove a statement on a lower bound (now Conjecture 2
  in Annexe B) since the proof was incomplete</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of validating XML documents of size $N$ against general
DTDs in the context of streaming algorithms. The starting point of this work is
a well-known space lower bound. There are XML documents and DTDs for which
$p$-pass streaming algorithms require $\Omega(N/p)$ space.
  We show that when allowing access to external memory, there is a
deterministic streaming algorithm that solves this problem with memory space
$O(\log^2 N)$, a constant number of auxiliary read/write streams, and $O(\log
N)$ total number of passes on the XML document and auxiliary streams.
  An important intermediate step of this algorithm is the computation of the
First-Child-Next-Sibling (FCNS) encoding of the initial XML document in a
streaming fashion. We study this problem independently, and we also provide
memory efficient streaming algorithms for decoding an XML document given in its
FCNS encoding.
  Furthermore, validating XML documents encoding binary trees in the usual
streaming model without external memory can be done with sublinear memory.
There is a one-pass algorithm using $O(\sqrt{N \log N})$ space, and a
bidirectional two-pass algorithm using $O(\log^2 N)$ space performing this
task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3312</identifier>
 <datestamp>2010-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3312</id><created>2010-12-15</created><authors><author><keyname>Oladejo</keyname><forenames>Bolanle</forenames><affiliation>LORIA</affiliation></author><author><keyname>Odumuyiwa</keyname><forenames>Victor</forenames><affiliation>LORIA</affiliation></author><author><keyname>David</keyname><forenames>Amos</forenames><affiliation>LORIA</affiliation></author></authors><title>Dynamic Capitalization and Visualization Strategy in Collaborative
  Knowledge Management System for EI Process</title><categories>cs.AI</categories><proxy>ccsd</proxy><journal-ref>International Conference in Knowledge Management and Knowledge
  Economy ICKMKE 2010, paris : France (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowledge is attributed to human whose problem-solving behavior is subjective
and complex. In today's knowledge economy, the need to manage knowledge
produced by a community of actors cannot be overemphasized. This is due to the
fact that actors possess some level of tacit knowledge which is generally
difficult to articulate. Problem-solving requires searching and sharing of
knowledge among a group of actors in a particular context. Knowledge expressed
within the context of a problem resolution must be capitalized for future
reuse. In this paper, an approach that permits dynamic capitalization of
relevant and reliable actors' knowledge in solving decision problem following
Economic Intelligence process is proposed. Knowledge annotation method and
temporal attributes are used for handling the complexity in the communication
among actors and in contextualizing expressed knowledge. A prototype is built
to demonstrate the functionalities of a collaborative Knowledge Management
system based on this approach. It is tested with sample cases and the result
showed that dynamic capitalization leads to knowledge validation hence
increasing reliability of captured knowledge for reuse. The system can be
adapted to various domains
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3319</identifier>
 <datestamp>2012-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3319</id><created>2010-12-15</created><updated>2011-02-04</updated><authors><author><keyname>Arad</keyname><forenames>Itai</forenames></author></authors><title>A note about a partial no-go theorem for quantum PCP</title><categories>cs.CC quant-ph</categories><comments>7 pages, comments are welcome! revised version with very minor
  corrections</comments><journal-ref>Quantum Information &amp; Computation, Vol.11, (2011), pp 1019</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is not a disproof of the quantum PCP conjecture!
  In this note we use perturbation on the commuting Hamiltonian problem on a
graph, based on results by Bravyi and Vyalyi, to provide a partial no-go
theorem for quantum PCP. Specifically, we derive an upper bound on how large
the promise gap can be for the quantum PCP still to hold, as a function of the
non-commuteness of the system. As the system becomes more and more commuting,
the maximal promise gap shrinks.
  We view these results as possibly a preliminary step towards disproving the
quantum PCP conjecture. A different way to view these results is actually as
indications that a critical point exists, beyond which quantum PCP indeed
holds; in any case, we hope that these results will lead to progress on this
important open problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3320</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3320</id><created>2010-12-15</created><authors><author><keyname>Gatterbauer</keyname><forenames>Wolfgang</forenames></author><author><keyname>Suciu</keyname><forenames>Dan</forenames></author></authors><title>Data Conflict Resolution Using Trust Mappings</title><categories>cs.DB cs.AI</categories><comments>20 pages, 19 figures</comments><report-no>University of Washington CSE Technical Report 09-11-01</report-no><journal-ref>Full version of SIGMOD 2010 conference paper, pp. 219-230</journal-ref><doi>10.1145/1807167.1807193</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In massively collaborative projects such as scientific or community
databases, users often need to agree or disagree on the content of individual
data items. On the other hand, trust relationships often exist between users,
allowing them to accept or reject other users' beliefs by default. As those
trust relationships become complex, however, it becomes difficult to define and
compute a consistent snapshot of the conflicting information. Previous
solutions to a related problem, the update reconciliation problem, are
dependent on the order in which the updates are processed and, therefore, do
not guarantee a globally consistent snapshot. This paper proposes the first
principled solution to the automatic conflict resolution problem in a community
database. Our semantics is based on the certain tuples of all stable models of
a logic program. While evaluating stable models in general is well known to be
hard, even for very simple logic programs, we show that the conflict resolution
problem admits a PTIME solution. To the best of our knowledge, ours is the
first PTIME algorithm that allows conflict resolution in a principled way. We
further discuss extensions to negative beliefs and prove that some of these
extensions are hard. This work is done in the context of the BeliefDB project
at the University of Washington, which focuses on the efficient management of
conflicts in community databases.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="17000" completeListSize="102538">1122234|18001</resumptionToken>
</ListRecords>
</OAI-PMH>
