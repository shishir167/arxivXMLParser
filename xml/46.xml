<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T01:12:20Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|45001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6734</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6734</id><created>2013-04-24</created><authors><author><keyname>Place</keyname><forenames>Thomas</forenames></author><author><keyname>van Rooijen</keyname><forenames>Lorijn</forenames></author><author><keyname>Zeitoun</keyname><forenames>Marc</forenames></author></authors><title>Separating regular languages by piecewise testable and unambiguous
  languages</title><categories>cs.FL</categories><comments>arXiv admin note: text overlap with arXiv:1303.2143</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Separation is a classical problem asking whether, given two sets belonging to
some class, it is possible to separate them by a set from a smaller class. We
discuss the separation problem for regular languages. We give a Ptime algorithm
to check whether two given regular languages are separable by a piecewise
testable language, that is, whether a $B{\Sigma}1(&lt;)$ sentence can witness that
the languages are disjoint. The proof refines an algebraic argument from
Almeida and the third author. When separation is possible, we also express a
separator by saturating one of the original languages by a suitable congruence.
Following the same line, we show that one can as well decide whether two
regular languages can be separated by an unambiguous language, albeit with a
higher complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6736</identifier>
 <datestamp>2014-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6736</id><created>2013-04-24</created><updated>2013-07-05</updated><authors><author><keyname>Baronchelli</keyname><forenames>Andrea</forenames></author><author><keyname>Ferrer-i-Cancho</keyname><forenames>Ramon</forenames></author><author><keyname>Pastor-Satorras</keyname><forenames>Romualdo</forenames></author><author><keyname>Chater</keyname><forenames>Nick</forenames></author><author><keyname>Christiansen</keyname><forenames>Morten H.</forenames></author></authors><title>Networks in Cognitive Science</title><categories>physics.soc-ph cs.SI q-bio.NC</categories><journal-ref>Trends in Cognitive Sciences 17, 348-360 (2013)</journal-ref><doi>10.1016/j.tics.2013.04.010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Networks of interconnected nodes have long played a key role in Cognitive
Science, from artificial neural net- works to spreading activation models of
semantic mem- ory. Recently, however, a new Network Science has been developed,
providing insights into the emergence of global, system-scale properties in
contexts as diverse as the Internet, metabolic reactions, and collaborations
among scientists. Today, the inclusion of network theory into Cognitive
Sciences, and the expansion of complex- systems science, promises to
significantly change the way in which the organization and dynamics of
cognitive and behavioral processes are understood. In this paper, we review
recent contributions of network theory at different levels and domains within
the Cognitive Sciences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6740</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6740</id><created>2013-04-24</created><authors><author><keyname>Gabow</keyname><forenames>Harold N.</forenames></author><author><keyname>Sankowski</keyname><forenames>Piotr</forenames></author></authors><title>Algebraic Algorithms for b-Matching, Shortest Undirected Paths, and
  f-Factors</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let G=(V,E) be a graph with f:V\to Z_+ a function assigning degree bounds to
vertices. We present the first efficient algebraic algorithm to find an
f-factor. The time is \tilde{O}(f(V)^{\omega}). More generally for graphs with
integral edge weights of maximum absolute value W we find a maximum weight
f-factor in time \tilde{O}(Wf(V)^{\omega}). (The algorithms are randomized,
correct with high probability and Las Vegas; the time bound is worst-case.) We
also present three specializations of these algorithms: For maximum weight
perfect f-matching the algorithm is considerably simpler (and almost identical
to its special case of ordinary weighted matching). For the single-source
shortest-path problem in undirected graphs with conservative edge weights, we
present a generalization of the shortest-path tree, and we compute it in
\tilde{O(Wn^{\omega}) time. For bipartite graphs, we improve the known
complexity bounds for vertex capacitated max-flow and min-cost max-flow on a
subclass of graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6742</identifier>
 <datestamp>2014-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6742</id><created>2013-04-24</created><updated>2014-03-11</updated><authors><author><keyname>Chavarro</keyname><forenames>Diego</forenames></author><author><keyname>Tang</keyname><forenames>Puay</forenames></author><author><keyname>Rafols</keyname><forenames>Ismael</forenames></author></authors><title>Interdisciplinarity and research on local issues: evidence from a
  developing country</title><categories>physics.soc-ph cs.DL</categories><comments>24 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores the relationship between interdisciplinarity and research
pertaining to local issues. Using Colombian publications from 1991 until 2011
in the Web of Science, we investigate the relationship between the degree of
interdisciplinarity and the local orientation of the articles. We find that a
higher degree of interdisciplinarity in a publication is associated with a
greater emphasis on Colombian issues. In particular, our results suggest that
research that combines cognitively disparate disciplines, what we refer to as
distal interdisciplinarity, tends to be associated with more local focus of
research. We discuss the implications of these results in the context of
policies aiming to foster the local socio-economic impact of research in
developing countries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6743</identifier>
 <datestamp>2014-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6743</id><created>2013-04-24</created><authors><author><keyname>Luna</keyname><forenames>German</forenames></author><author><keyname>Reid</keyname><forenames>Samuel</forenames></author><author><keyname>De Sanctis</keyname><forenames>Bianca</forenames></author><author><keyname>Gheorghiu</keyname><forenames>Vlad</forenames></author></authors><title>A Combinatorial Approach to Quantum Error Correcting Codes</title><categories>math.CO cs.IT math.IT</categories><comments>8 pages and 3 figures</comments><msc-class>94C15</msc-class><journal-ref>Discrete Mathematics, Algorithms and Applications, vol. 6, 1450054
  (2014)</journal-ref><doi>10.1142/S1793830914500542</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated from the theory of quantum error correcting codes, we investigate a
combinatorial problem that involves a symmetric $n$-vertices colourable graph
and a group of operations (colouring rules) on the graph: find the minimum
sequence of operations that maps between two given graph colourings. We provide
an explicit algorithm for computing the solution of our problem, which in turn
is directly related to computing the distance (performance) of an underlying
quantum error correcting code. Computing the distance of a quantum code is a
highly non-trivial problem and our method may be of use in the construction of
better codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6753</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6753</id><created>2013-04-24</created><updated>2013-05-02</updated><authors><author><keyname>Alizadeh</keyname><forenames>Mahnoosh</forenames></author><author><keyname>Kesidis</keyname><forenames>George</forenames></author><author><keyname>Scaglione</keyname><forenames>Anna</forenames></author></authors><title>Clustering Consumption in Queues: A Scalable Model for Electric Vehicle
  Scheduling</title><categories>cs.SY</categories><comments>Asilomar 2013, invited paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a scalable model for the aggregate electricity
demand of a fleet of electric vehicles, which can provide the right balance
between model simplicity and accuracy. The model is based on classification of
tasks with similar energy consumption characteristics into a finite number of
clusters. The aggregator responsible for scheduling the charge of the vehicles
has two goals: 1) to provide a hard QoS guarantee to the vehicles at the lowest
possible cost; 2) to offer load or generation following services to the
wholesale market. In order to achieve these goals, we combine the scalable
demand model we propose with two scheduling mechanisms, a near-optimal and a
heuristic technique. The performance of the two mechanisms is compared under a
realistic setting in our numerical experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6759</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6759</id><created>2013-04-24</created><authors><author><keyname>Jassim</keyname><forenames>Firas A.</forenames></author></authors><title>k-Modulus Method for Image Transformation</title><categories>cs.CV</categories><comments>5 pages, 2 tables, 6 figures</comments><journal-ref>International Journal of Advanced Computer Science and
  Applications, Vol. 4, No. 3, 2013</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we propose a new algorithm to make a novel spatial image
transformation. The proposed approach aims to reduce the bit depth used for
image storage. The basic technique for the proposed transformation is based of
the modulus operator. The goal is to transform the whole image into multiples
of predefined integer. The division of the whole image by that integer will
guarantee that the new image surely less in size from the original image. The
k-Modulus Method could not be used as a stand alone transform for image
compression because of its high compression ratio. It could be used as a scheme
embedded in other image processing fields especially compression. According to
its high PSNR value, it could be amalgamated with other methods to facilitate
the redundancy criterion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6761</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6761</id><created>2013-04-24</created><authors><author><keyname>Halappanavar</keyname><forenames>Mahantesh</forenames></author><author><keyname>Choudhury</keyname><forenames>Sutanay</forenames></author><author><keyname>Hogan</keyname><forenames>Emilie</forenames></author><author><keyname>Hui</keyname><forenames>Peter</forenames></author><author><keyname>Johnson</keyname><forenames>John R.</forenames></author><author><keyname>Ray</keyname><forenames>Indrajit</forenames></author><author><keyname>Holder</keyname><forenames>Lawrence</forenames></author></authors><title>Towards a Networks-of-Networks Framework for Cyber Security</title><categories>cs.CR cs.NI cs.SI</categories><comments>A shorter (3-page) version of this paper will appear in the
  Proceedings of the IEEE Intelligence and Security Informatics 2013, Seattle
  Washington, USA, June 4-7, 2013</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Networks-of-networks (NoN) is a graph-theoretic model of interdependent
networks that have distinct dynamics at each network (layer). By adding special
edges to represent relationships between nodes in different layers, NoN
provides a unified mechanism to study interdependent systems intertwined in a
complex relationship. While NoN based models have been proposed for
cyber-physical systems, in this position paper we build towards a three-layered
NoN model for an enterprise cyber system. Each layer captures a different facet
of a cyber system. We present in-depth discussion for four major graph-
theoretic applications to demonstrate how the three-layered NoN model can be
leveraged for continuous system monitoring and mission assurance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6762</identifier>
 <datestamp>2014-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6762</id><created>2013-04-24</created><updated>2014-08-26</updated><authors><author><keyname>de Carvalho</keyname><forenames>Daniel</forenames></author><author><keyname>de Falco</keyname><forenames>Lorenzo Tortora</forenames></author></authors><title>A semantic account of strong normalization in Linear Logic</title><categories>cs.LO math.LO</categories><comments>41 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that given two cut free nets of linear logic, by means of their
relational interpretations one can: 1) first determine whether or not the net
obtained by cutting the two nets is strongly normalizable 2) then (in case it
is strongly normalizable) compute the maximal length of the reduction sequences
starting from that net.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6763</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6763</id><created>2013-04-24</created><updated>2014-01-10</updated><authors><author><keyname>And&#xe9;n</keyname><forenames>Joakim</forenames></author><author><keyname>Mallat</keyname><forenames>St&#xe9;phane</forenames></author></authors><title>Deep Scattering Spectrum</title><categories>cs.SD cs.IT math.IT</categories><doi>10.1109/TSP.2014.2326991</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A scattering transform defines a locally translation invariant representation
which is stable to time-warping deformations. It extends MFCC representations
by computing modulation spectrum coefficients of multiple orders, through
cascades of wavelet convolutions and modulus operators. Second-order scattering
coefficients characterize transient phenomena such as attacks and amplitude
modulation. A frequency transposition invariant representation is obtained by
applying a scattering transform along log-frequency. State-the-of-art
classification results are obtained for musical genre and phone classification
on GTZAN and TIMIT databases, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6777</identifier>
 <datestamp>2014-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6777</id><created>2013-04-24</created><updated>2014-11-24</updated><authors><author><keyname>Zaman</keyname><forenames>Tauhid</forenames></author><author><keyname>Fox</keyname><forenames>Emily B.</forenames></author><author><keyname>Bradlow</keyname><forenames>Eric T.</forenames></author></authors><title>A Bayesian approach for predicting the popularity of tweets</title><categories>cs.SI physics.soc-ph stat.AP</categories><comments>Published in at http://dx.doi.org/10.1214/14-AOAS741 the Annals of
  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><report-no>IMS-AOAS-AOAS741</report-no><journal-ref>Annals of Applied Statistics 2014, Vol. 8, No. 3, 1583-1611</journal-ref><doi>10.1214/14-AOAS741</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We predict the popularity of short messages called tweets created in the
micro-blogging site known as Twitter. We measure the popularity of a tweet by
the time-series path of its retweets, which is when people forward the tweet to
others. We develop a probabilistic model for the evolution of the retweets
using a Bayesian approach, and form predictions using only observations on the
retweet times and the local network or &quot;graph&quot; structure of the retweeters. We
obtain good step ahead forecasts and predictions of the final total number of
retweets even when only a small fraction (i.e., less than one tenth) of the
retweet path is observed. This translates to good predictions within a few
minutes of a tweet being posted, and has potential implications for
understanding the spread of broader ideas, memes, or trends in social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6780</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6780</id><created>2013-04-24</created><authors><author><keyname>Shamir</keyname><forenames>Lior</forenames><affiliation>Lawrence Technological University</affiliation></author><author><keyname>Wallin</keyname><forenames>John F.</forenames><affiliation>Middle Tennessee State University</affiliation></author><author><keyname>Allen</keyname><forenames>Alice</forenames><affiliation>Astrophysics Source Code Library</affiliation></author><author><keyname>Berriman</keyname><forenames>Bruce</forenames><affiliation>Infrared Processing and Analysis Center, California Institute of Technology</affiliation></author><author><keyname>Teuben</keyname><forenames>Peter</forenames><affiliation>University of Maryland</affiliation></author><author><keyname>Nemiroff</keyname><forenames>Robert J.</forenames><affiliation>Michigan Technological University</affiliation></author><author><keyname>Mink</keyname><forenames>Jessica</forenames><affiliation>Harvard-Smithsonian Center for Astrophysics</affiliation></author><author><keyname>Hanisch</keyname><forenames>Robert J.</forenames><affiliation>Space Telescope Science Institute</affiliation></author><author><keyname>DuPrie</keyname><forenames>Kimberly</forenames><affiliation>Astrophysics Source Code Library</affiliation></author></authors><title>Practices in source code sharing in astrophysics</title><categories>astro-ph.IM cs.DL</categories><comments>Accepted by Astronomy and Computing. 10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While software and algorithms have become increasingly important in
astronomy, the majority of authors who publish computational astronomy research
do not share the source code they develop, making it difficult to replicate and
reuse the work. In this paper we discuss the importance of sharing scientific
source code with the entire astrophysics community, and propose that journals
require authors to make their code publicly available when a paper is
published. That is, we suggest that a paper that involves a computer program
not be accepted for publication unless the source code becomes publicly
available. The adoption of such a policy by editors, editorial boards, and
reviewers will improve the ability to replicate scientific results, and will
also make the computational astronomy methods more available to other
researchers who wish to apply them to their data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6782</identifier>
 <datestamp>2014-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6782</id><created>2013-04-24</created><updated>2014-01-13</updated><authors><author><keyname>Sou-Cheng</keyname><affiliation>Terrya</affiliation></author><author><keyname>Choi</keyname></author></authors><title>Minimal Residual Methods for Complex Symmetric, Skew Symmetric, and Skew
  Hermitian Systems</title><categories>cs.MS math.NA</categories><comments>arXiv admin note: substantial text overlap with arXiv:1003.4042</comments><report-no>Argonne National Laboratory Technical Report ANL/MCS-P3028-0812</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While there is no lack of efficient Krylov subspace solvers for Hermitian
systems, there are few for complex symmetric, skew symmetric, or skew Hermitian
systems, which are increasingly important in modern applications including
quantum dynamics, electromagnetics, and power systems. For a large consistent
complex symmetric system, one may apply a non-Hermitian Krylov subspace method
disregarding the symmetry of $A$, or a Hermitian Krylov solver on the
equivalent normal equation or an augmented system twice the original dimension.
These have the disadvantages of increasing either memory, conditioning, or
computational costs. An exception is a special version of QMR by Freund (1992),
but that may be affected by non-benign breakdowns unless look-ahead is
implemented; furthermore, it is designed for only consistent and nonsingular
problems. For skew symmetric systems, Greif and Varah (2009) adapted CG for
nonsingular skew symmetric linear systems that are necessarily and
restrictively of even order.
  We extend the symmetric and Hermitian algorithms MINRES and MINRES-QLP by
Choi, Paige and Saunders (2011) to complex symmetric, skew symmetric, and skew
Hermitian systems. In particular, MINRES-QLP uses a rank-revealing QLP
decomposition of the tridiagonal matrix from a three-term recurrent
complex-symmetric Lanczos process. Whether the systems are real or complex,
singular or invertible, compatible or inconsistent, MINRES-QLP computes the
unique minimum-length, i.e., pseudoinverse, solutions. It is a significant
extension of MINRES by Paige and Saunders (1975) with enhanced stability and
capability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6792</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6792</id><created>2013-04-24</created><authors><author><keyname>Werner</keyname><forenames>Elisabeth M.</forenames></author><author><keyname>Ye</keyname><forenames>Deping</forenames></author></authors><title>On the mixed $f$-divergence for multiple pairs of measures</title><categories>cs.IT math.IT math.MG</categories><msc-class>94A15, 94A17</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the concept of the classical $f$-divergence (for a pair of
measures) is extended to the mixed $f$-divergence (for multiple pairs of
measures). The mixed $f$-divergence provides a way to measure the difference
between multiple pairs of (probability) measures. Properties for the mixed
$f$-divergence are established, such as permutation invariance and symmetry in
distributions. An Alexandrov-Fenchel type inequality and an isoperimetric type
inequality for the mixed $f$-divergence will be proved and applications in the
theory of convex bodies are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6800</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6800</id><created>2013-04-25</created><updated>2013-05-14</updated><authors><author><keyname>Karpinski</keyname><forenames>Marek</forenames></author><author><keyname>Schmied</keyname><forenames>Richard</forenames></author></authors><title>Approximation Hardness of Graphic TSP on Cubic Graphs</title><categories>cs.CC cs.DM cs.DS math.CO math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove explicit approximation hardness results for the Graphic TSP on cubic
and subcubic graphs as well as the new inapproximability bounds for the
corresponding instances of the (1,2)-TSP. The proof technique uses new modular
constructions of simulating gadgets for the restricted cubic and subcubic
instances. The modular constructions used in the paper could be also of
independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6806</identifier>
 <datestamp>2013-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6806</id><created>2013-04-25</created><updated>2013-11-11</updated><authors><author><keyname>Babaioff</keyname><forenames>Moshe</forenames></author><author><keyname>Lucier</keyname><forenames>Brendan</forenames></author><author><keyname>Nisan</keyname><forenames>Noam</forenames></author></authors><title>Bertrand Networks</title><categories>cs.GT</categories><acm-class>J.4; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study scenarios where multiple sellers of a homogeneous good compete on
prices, where each seller can only sell to some subset of the buyers.
Crucially, sellers cannot price-discriminate between buyers. We model the
structure of the competition by a graph (or hyper-graph), with nodes
representing the sellers and edges representing populations of buyers. We study
equilibria in the game between the sellers, prove that they always exist, and
present various structural, quantitative, and computational results about them.
We also analyze the equilibria completely for a few cases. Many questions are
left open.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6809</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6809</id><created>2013-04-25</created><authors><author><keyname>Nafi</keyname><forenames>Kawser Wazed</forenames></author><author><keyname>Kar</keyname><forenames>Tonny Shekha</forenames></author><author><keyname>Hossain</keyname><forenames>Amjad</forenames></author><author><keyname>Hashem</keyname><forenames>M. M. A</forenames></author></authors><title>A New Trusted and E-Commerce Architecture for Cloud Computing</title><categories>cs.DC cs.CR</categories><comments>Accepted for publication in the Procs. of the IEEE 2013 International
  Conference on Informatics, Electronics and Vision (ICIEV 2013), pp.XX-XX,
  Dhaka, Bangladesh, May 17-18, (2013). arXiv admin note: substantial text
  overlap with arXiv:1304.4028</comments><journal-ref>Procs. of the IEEE 2013 International Conference on Informatics,
  Electronics and Vision (ICIEV 2013), pp.XX-XX, Dhaka, Bangladesh, May 17-18,
  (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing platform gives people the opportunity for sharing resources,
services and information among the people of the whole world. In private cloud
system, information is shared among the persons who are in that cloud.
Presently, different types of internet based systems are running in Cloud
Computing environment. E-commerce is one of them. Present models are not
secured enough for executing e-transactions easily, especially in cloud
platform. Again, most of the time, clients fail to distinguish between the good
online business companies and the bad one, which discourages clients and
companies to migrate in cloud. In this paper, we have proposed a newer
e-commerce architecture depends on encryption based secured and fuzzy logic
based certain trust model which will be helpful to solve present e-commerce
problems. We had discussed about the whole working procedure of the model in
this paper. Finally, at the end of this paper, we have discussed some
experimental results about our proposed model which will help to show the
validity of our model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6810</identifier>
 <datestamp>2015-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6810</id><created>2013-04-25</created><authors><author><keyname>Fierens</keyname><forenames>Daan</forenames></author><author><keyname>Broeck</keyname><forenames>Guy Van den</forenames></author><author><keyname>Renkens</keyname><forenames>Joris</forenames></author><author><keyname>Shterionov</keyname><forenames>Dimitar</forenames></author><author><keyname>Gutmann</keyname><forenames>Bernd</forenames></author><author><keyname>Thon</keyname><forenames>Ingo</forenames></author><author><keyname>Janssens</keyname><forenames>Gerda</forenames></author><author><keyname>De Raedt</keyname><forenames>Luc</forenames></author></authors><title>Inference and learning in probabilistic logic programs using weighted
  Boolean formulas</title><categories>cs.AI cs.LG cs.LO</categories><comments>To appear in Theory and Practice of Logic Programming (TPLP)</comments><journal-ref>Theory and Practice of Logic Programming, 15 (3): 358-401, 2015</journal-ref><doi>10.1017/S1471068414000076</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic logic programs are logic programs in which some of the facts
are annotated with probabilities. This paper investigates how classical
inference and learning tasks known from the graphical model community can be
tackled for probabilistic logic programs. Several such tasks such as computing
the marginals given evidence and learning from (partial) interpretations have
not really been addressed for probabilistic logic programs before.
  The first contribution of this paper is a suite of efficient algorithms for
various inference tasks. It is based on a conversion of the program and the
queries and evidence to a weighted Boolean formula. This allows us to reduce
the inference tasks to well-studied tasks such as weighted model counting,
which can be solved using state-of-the-art methods known from the graphical
model and knowledge compilation literature. The second contribution is an
algorithm for parameter estimation in the learning from interpretations
setting. The algorithm employs Expectation Maximization, and is built on top of
the developed inference algorithms.
  The proposed approach is experimentally evaluated. The results show that the
inference algorithms improve upon the state-of-the-art in probabilistic logic
programming and that it is indeed possible to learn the parameters of a
probabilistic logic program from interpretations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6813</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6813</id><created>2013-04-25</created><authors><author><keyname>Boissonnat</keyname><forenames>Jean-Daniel</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Dey</keyname><forenames>Tamal K.</forenames><affiliation>CSE</affiliation></author><author><keyname>Maria</keyname><forenames>Cl&#xe9;ment</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>The Compressed Annotation Matrix: an Efficient Data Structure for
  Computing Persistent Cohomology</title><categories>cs.CG</categories><proxy>ccsd</proxy><report-no>RR-8195</report-no><journal-ref>N&amp;deg; RR-8195 (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The persistent homology with coefficients in a field F coincides with the
same for cohomology because of duality. We propose an implementation of a
recently introduced algorithm for persistent cohomology that attaches
annotation vectors with the simplices. We separate the representation of the
simplicial complex from the representation of the cohomology groups, and
introduce a new data structure for maintaining the annotation matrix, which is
more compact and reduces substancially the amount of matrix operations. In
addition, we propose heuristics to simplify further the representation of the
cohomology groups and improve both time and space complexities. The paper
provides a theoretical analysis, as well as a detailed experimental study of
our implementation and comparison with state-of-the-art software for persistent
homology and cohomology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6822</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6822</id><created>2013-04-25</created><authors><author><keyname>Che</keyname><forenames>Yue Ling</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Gong</keyname><forenames>Yi</forenames></author></authors><title>On Design of Opportunistic Spectrum Access in the Presence of Reactive
  Primary Users</title><categories>cs.IT math.IT</categories><comments>The longer version of a paper to appear in IEEE Transactions on
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Opportunistic spectrum access (OSA) is a key technique enabling the secondary
users (SUs) in a cognitive radio (CR) network to transmit over the &quot;spectrum
holes&quot; unoccupied by the primary users (PUs). In this paper, we focus on the
OSA design in the presence of reactive PUs, where PU's access probability in a
given channel is related to SU's past access decisions. We model the channel
occupancy of the reactive PU as a 4-state discrete-time Markov chain. We
formulate the optimal OSA design for SU throughput maximization as a
constrained finite-horizon partially observable Markov decision process (POMDP)
problem. We solve this problem by first considering the conventional short-term
conditional collision probability (SCCP) constraint. We then adopt a long-term
PU throughput (LPUT) constraint to effectively protect the reactive PU
transmission. We derive the structure of the optimal OSA policy under the LPUT
constraint and propose a suboptimal policy with lower complexity. Numerical
results are provided to validate the proposed studies, which reveal some
interesting new tradeoffs between SU throughput maximization and PU
transmission protection in a practical interaction scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6832</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6832</id><created>2013-04-25</created><authors><author><keyname>Dau</keyname><forenames>Son Hoang</forenames></author><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author></authors><title>Polynomial Time Algorithm for Min-Ranks of Graphs with Simple Tree
  Structures</title><categories>math.CO cs.DM cs.DS</categories><comments>Accepted by Algorithmica, 30 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The min-rank of a graph was introduced by Haemers (1978) to bound the Shannon
capacity of a graph. This parameter of a graph has recently gained much more
attention from the research community after the work of Bar-Yossef et al.
(2006). In their paper, it was shown that the min-rank of a graph G
characterizes the optimal scalar linear solution of an instance of the Index
Coding with Side Information (ICSI) problem described by the graph G. It was
shown by Peeters (1996) that computing the min-rank of a general graph is an
NP-hard problem. There are very few known families of graphs whose min-ranks
can be found in polynomial time. In this work, we introduce a new family of
graphs with e?fficiently computed min-ranks. Specifically, we establish a
polynomial time dynamic programming algorithm to compute the min-ranks of
graphs having simple tree structures. Intuitively, such graphs are obtained by
gluing together, in a tree-like structure, any set of graphs for which the
min-ranks can be determined in polynomial time. A polynomial time algorithm to
recognize such graphs is also proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6858</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6858</id><created>2013-04-25</created><authors><author><keyname>Tadaki</keyname><forenames>Kohtaro</forenames></author></authors><title>Phase Transition and Strong Predictability</title><categories>cs.IT math.IT</categories><comments>5 pages, LaTeX2e, no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The statistical mechanical interpretation of algorithmic information theory
(AIT, for short) was introduced and developed in our former work [K. Tadaki,
Local Proceedings of CiE 2008, pp.425-434, 2008], where we introduced the
notion of thermodynamic quantities into AIT. These quantities are real
functions of temperature T&gt;0. The values of all the thermodynamic quantities
diverge when T exceeds 1. This phenomenon corresponds to phase transition in
statistical mechanics. In this paper we introduce the notion of strong
predictability for an infinite binary sequence and then apply it to the
partition function Z(T), which is one of the thermodynamic quantities in AIT.
We then reveal a new computational aspect of the phase transition in AIT by
showing the critical difference of the behavior of Z(T) between T=1 and T&lt;1 in
terms of the strong predictability for the base-two expansion of Z(T).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6870</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6870</id><created>2013-04-25</created><authors><author><keyname>Anderson</keyname><forenames>Matthew</forenames></author><author><keyname>Dawar</keyname><forenames>Anuj</forenames></author><author><keyname>Holm</keyname><forenames>Bjarki</forenames></author></authors><title>Maximum Matching and Linear Programming in Fixed-Point Logic with
  Counting</title><categories>cs.LO cs.CC cs.DM</categories><comments>Full version of paper to appear in LICS 2013</comments><msc-class>68Q19, 90C60</msc-class><acm-class>F.1.3; F.2.2; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish the expressibility in fixed-point logic with counting (FPC) of a
number of natural polynomial-time problems. In particular, we show that the
size of a maximum matching in a graph is definable in FPC. This settles an open
problem first posed by Blass, Gurevich and Shelah, who asked whether the
existence of perfect matchings in general graphs could be determined in the
more powerful formalism of choiceless polynomial time with counting. Our result
is established by showing that the ellipsoid method for solving linear programs
can be implemented in FPC. This allows us to prove that linear programs can be
optimised in FPC if the corresponding separation oracle problem can be defined
in FPC. On the way to defining a suitable separation oracle for the maximum
matching problem, we provide FPC formulas defining maximum flows and canonical
minimum cuts in capacitated graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6872</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6872</id><created>2013-04-25</created><authors><author><keyname>Patel</keyname><forenames>Rupa</forenames></author><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author></authors><title>Security Issues In Speech Watermarking for Information Transmission</title><categories>cs.MM cs.CR</categories><comments>Pages: 10 Figures: 5, Conference Procedings, AMOC 2011, Advances in
  Modeling, Optimization and Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The secure transmission of speech information is a significant issue faced by
many security professionals and individuals. By applying voice-encryption
technique any kind of encrypted sensitive speech data such as password can be
transmitted. But this has the serious disadvantage that by means of
cryptanalysis attack encrypted data can be compromised. Increasing the strength
of encryption/decryption results in an associated increased in the cost.
Additional techniques like stenography and digital watermarking can be used to
conceal information in an undetectable way in audio data. However this
watermarked audio data has to be send through unreliable media and an
eavesdropper might get hold of secret message and can also determine the
identity of a speaker who is sending the information since human voice contains
information based on its characteristics such as frequency, pitch, and energy.
This paper proposes Normalized Speech Watermarking technique. Speech signal is
normalized to hide the identity of the speaker who is sending the information
and then speech watermarking technique is applied on this normalized signal
that contains the message (password) so that what information is transmitted
should not be unauthorizedly revealed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6889</identifier>
 <datestamp>2014-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6889</id><created>2013-04-25</created><updated>2014-01-07</updated><authors><author><keyname>Francis</keyname><forenames>Maria</forenames></author><author><keyname>Dukkipati</keyname><forenames>Ambedkar</forenames></author></authors><title>Reduced Gr\&quot;obner Bases and Macaulay-Buchberger Basis Theorem over
  Noetherian Rings</title><categories>cs.SC math.AC</categories><journal-ref>Journal of Symbolic Computation, 65: 1-14, 2014</journal-ref><doi>10.1016/j.jsc.2014.01.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we extend the characterization of $\mathbb{Z}[x]/\ &lt; f \ &gt;$,
where $f \in \mathbb{Z}[x]$ to be a free $\mathbb{Z}$-module to multivariate
polynomial rings over any commutative Noetherian ring, $A$. The
characterization allows us to extend the Gr\&quot;obner basis method of computing a
$\Bbbk$-vector space basis of residue class polynomial rings over a field
$\Bbbk$ (Macaulay-Buchberger Basis Theorem) to rings, i.e.
$A[x_1,\ldots,x_n]/\mathfrak{a}$, where $\mathfrak{a} \subseteq
A[x_1,\ldots,x_n]$ is an ideal. We give some insights into the characterization
for two special cases, when $A = \mathbb{Z}$ and $A =
\Bbbk[\theta_1,\ldots,\theta_m]$. As an application of this characterization,
we show that the concept of Border bases can be extended to rings when the
corresponding residue class ring is a finitely generated, free $A$-module.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6896</identifier>
 <datestamp>2015-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6896</id><created>2013-04-25</created><updated>2015-08-25</updated><authors><author><keyname>Wang</keyname><forenames>Tao</forenames></author></authors><title>Strongly light subgraphs in the 1-planar graphs with minimum degree 7</title><categories>math.CO cs.DM</categories><comments>6 pages, 6 figures,
  http://amc-journal.eu/index.php/amc/article/view/564. in Ars Mathematica
  Contemporanea, 2015</comments><msc-class>05C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph is {\em $1$-planar} if it can be drawn in the plane such that every
edge crosses at most one other edge. A connected graph $H$ is {\em strongly
light} in a family of graphs $\mathfrak{G}$, if there exists a constant
$\lambda$, such that every graph $G$ in $\mathfrak{G}$ contains a subgraph $K$
isomorphic to $H$ with $\deg_{G}(v) \leq \lambda$ for all $v \in V(K)$. In this
paper, we present some strongly light subgraphs in the family of $1$-planar
graphs with minimum degree~$7$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6897</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6897</id><created>2013-04-25</created><authors><author><keyname>Bose</keyname><forenames>Prosenjit</forenames></author><author><keyname>Dou&#xef;eb</keyname><forenames>Karim</forenames></author><author><keyname>Iacono</keyname><forenames>John</forenames></author><author><keyname>Langerman</keyname><forenames>Stefan</forenames></author></authors><title>The Power and Limitations of Static Binary Search Trees with Lazy Finger</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A static binary search tree where every search starts from where the previous
one ends (lazy finger) is considered. Such a search method is more powerful
than that of the classic optimal static trees, where every search starts from
the root (root finger), and less powerful than when rotations are
allowed---where finding the best rotation based tree is the topic of the
dynamic optimality conjecture of Sleator and Tarjan. The runtime of the classic
root-finger tree can be expressed in terms of the entropy of the distribution
of the searches, but we show that this is not the case for the optimal lazy
finger tree. A non-entropy based asymptotically-tight expression for the
runtime of the optimal lazy finger trees is derived, and a dynamic
programming-based method is presented to compute the optimal tree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6898</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6898</id><created>2013-04-25</created><authors><author><keyname>Wiltsche</keyname><forenames>Clemens</forenames></author></authors><title>Automated Synthesis of Controllers for Search and Rescue from Temporal
  Logic Specifications</title><categories>cs.SY</categories><comments>Master Thesis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this thesis, the synthesis of correct-by-construction controllers for
robots assisting in Search and Rescue (SAR) is considered. In recent years, the
development of robots assisting in disaster mitigation in urban environments
has been actively encouraged, since robots can be deployed in dangerous and
hazardous areas where human SAR operations would not be possible.
  In order to meet the reliability requirements in SAR, the specifications of
the robots are stated in Linear Temporal Logic and synthesized into finite
state machines that can be executed as controllers. The resulting controllers
are purely discrete and maintain an ongoing interaction with their environment
by changing their internal state according to the inputs they receive from
sensors or other robots.
  Since SAR robots have to cooperate in order to complete the required tasks,
the synthesis of controllers that together achieve a common goal is considered.
This distributed synthesis problem is provably undecidable, hence it cannot be
solved in full generality, but a set of design principles is introduced in
order to develop specialized synthesizable specifications. In particular,
communication and cooperation are resolved by introducing a verified
standardized communication protocol and preempting negotiations between robots.
  The robots move on a graph on which we consider the search for stationary and
moving targets. Searching for moving targets is cast into a game of cops and
robbers, and specifications implementing a winning strategy are developed so
that the number of robots required is minimized.
  The viability of the methods is demonstrated by synthesizing controllers for
robots performing search and rescue for stationary targets and searching for
moving targets. It is shown that the controllers are guaranteed to achieve the
common goal of finding and rescuing the targets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6899</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6899</id><created>2013-04-25</created><authors><author><keyname>Szalkai</keyname><forenames>Bal&#xe1;zs</forenames></author></authors><title>An implementation of the relational k-means algorithm</title><categories>cs.LG cs.CV cs.MS</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A C# implementation of a generalized k-means variant called relational
k-means is described here. Relational k-means is a generalization of the
well-known k-means clustering method which works for non-Euclidean scenarios as
well. The input is an arbitrary distance matrix, as opposed to the traditional
k-means method, where the clustered objects need to be identified with vectors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6906</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6906</id><created>2013-04-25</created><authors><author><keyname>Konrad</keyname><forenames>Christian</forenames></author><author><keyname>Ros&#xe9;n</keyname><forenames>Adi</forenames></author></authors><title>Approximating Semi-Matchings in Streaming and in Two-Party Communication</title><categories>cs.DS</categories><comments>This is the long version including all proves of the ICALP 2013 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the communication complexity and streaming complexity of
approximating unweighted semi-matchings. A semi-matching in a bipartite graph G
= (A, B, E), with n = |A|, is a subset of edges S that matches all A vertices
to B vertices with the goal usually being to do this as fairly as possible.
While the term 'semi-matching' was coined in 2003 by Harvey et al. [WADS 2003],
the problem had already previously been studied in the scheduling literature
under different names.
  We present a deterministic one-pass streaming algorithm that for any 0 &lt;=
\epsilon &lt;= 1 uses space O(n^{1+\epsilon}) and computes an
O(n^{(1-\epsilon)/2})-approximation to the semi-matching problem. Furthermore,
with O(log n) passes it is possible to compute an O(log n)-approximation with
space O(n).
  In the one-way two-party communication setting, we show that for every
\epsilon &gt; 0, deterministic communication protocols for computing an
O(n^{1/((1+\epsilon)c + 1)})-approximation require a message of size more than
cn bits. We present two deterministic protocols communicating n and 2n edges
that compute an O(sqrt(n)) and an O(n^{1/3})-approximation respectively.
  Finally, we improve on results of Harvey et al. [Journal of Algorithms 2006]
and prove new links between semi-matchings and matchings. While it was known
that an optimal semi-matching contains a maximum matching, we show that there
is a hierarchical decomposition of an optimal semi-matching into maximum
matchings. A similar result holds for semi-matchings that do not admit
length-two degree-minimizing paths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6920</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6920</id><created>2013-04-25</created><updated>2013-09-30</updated><authors><author><keyname>Barros</keyname><forenames>Joao</forenames></author><author><keyname>Toffano</keyname><forenames>Zeno</forenames></author><author><keyname>Meguebli</keyname><forenames>Youssef</forenames></author><author><keyname>Doan</keyname><forenames>Bich-Li&#xea;n</forenames></author></authors><title>Contextual Query Using Bell Tests</title><categories>cs.IR quant-ph</categories><comments>12 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tests are essential in Information Retrieval and Data Mining in order to
evaluate the effectiveness of a query. An automatic measure tool intended to
exhibit the meaning of words in context has been developed and linked with
Quantum Theory, particularly entanglement. &quot;Quantum like&quot; experiments were
undertaken on semantic space based on the Hyperspace Analogue Language (HAL)
method. A quantum HAL model was implemented using state vectors issued from the
HAL matrix and query observables, testing a wide range of windows sizes. The
Bell parameter S, associating measures on two words in a document, was derived
showing peaks for specific window sizes. The peaks show maximum quantum
violation of the Bell inequalities and are document dependent. This new
correlation measure inspired by Quantum Theory could be promising for measuring
query relevance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6925</identifier>
 <datestamp>2013-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6925</id><created>2013-04-25</created><updated>2013-05-30</updated><authors><author><keyname>Benaim</keyname><forenames>Saguy</forenames></author><author><keyname>Benedikt</keyname><forenames>Michael</forenames></author><author><keyname>Lenhardt</keyname><forenames>Rastislav</forenames></author><author><keyname>Worrell</keyname><forenames>James</forenames></author></authors><title>Controlling the Depth, Size, and Number of Subtrees for Two-variable
  Logic on Trees</title><categories>cs.LO</categories><comments>28 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Verification of properties of first order logic with two variables FO2 has
been investigated in a number of contexts. Over arbitrary structures it is
known to be decidable with NEXPTIME complexity, with finitely satisfiable
formulas having exponential-sized models. Over word structures, where FO2 is
known to have the same expressiveness as unary temporal logic, the same
properties hold. Over finite labelled ordered trees FO2 is also of interest: it
is known to have the same expressiveness as navigational XPath, a common query
language for XML documents. Prior work on XPath and FO2 gives a 2EXPTIME bound
for satisfiability of FO2. In this work we give the first in-depth look at the
complexity of FO2 on trees, and on the size and depth of models. We show that
the doubly-exponential bound is not tight, and neither do the
NEXPTIME-completeness results from the word case carry over: the exact
complexity varies depending on the vocabulary used, the presence or absence of
a schema, and the encoding used for labels. Our results depend on an analysis
of subformula types in models of FO2 formulas, including techniques for
controlling the number of distinct subtrees, the depth, and the size of a
witness to finite satisfiability for FO2 sentences over trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6933</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6933</id><created>2013-04-25</created><updated>2013-04-26</updated><authors><author><keyname>Keglevic</keyname><forenames>Manuel</forenames></author><author><keyname>Sablatnig</keyname><forenames>Robert</forenames></author></authors><title>Digit Recognition in Handwritten Weather Records</title><categories>cs.CV</categories><comments>Part of the OAGM/AAPR 2013 proceedings (arXiv:1304.1876), 8 pages</comments><report-no>OAGM-AAPR/2013/07</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the automatic recognition of handwritten temperature
values in weather records. The localization of table cells is based on line
detection using projection profiles. Further, a stroke-preserving line removal
method which is based on gradient images is proposed. The presented digit
recognition utilizes features which are extracted using a set of filters and a
Support Vector Machine classifier. It was evaluated on the MNIST and the USPS
dataset and our own database with about 17,000 RGB digit images. An accuracy of
99.36% per digit is achieved for the entire system using a set of 84 weather
records.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6937</identifier>
 <datestamp>2015-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6937</id><created>2013-04-25</created><updated>2015-01-05</updated><authors><author><keyname>Booker</keyname><forenames>Andrew R.</forenames></author><author><keyname>Hiary</keyname><forenames>Ghaith A.</forenames></author><author><keyname>Keating</keyname><forenames>Jon P.</forenames></author></authors><title>Detecting squarefree numbers</title><categories>math.NT cs.DS math-ph math.MP</categories><comments>31 pages, 3 figures, latest version</comments><journal-ref>Duke Math. J. 164, no. 2 (2015), 235-275</journal-ref><doi>10.1215/00127094-2856619</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm, based on the explicit formula for $L$-functions and
conditional on GRH, for proving that a given integer is squarefree with little
or no knowledge of its factorization. We analyze the algorithm both
theoretically and practically, and use it to prove that several RSA challenge
numbers are not squarefull.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6945</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6945</id><created>2013-04-25</created><authors><author><keyname>Levene</keyname><forenames>Mark</forenames></author><author><keyname>Fenner</keyname><forenames>Trevor</forenames></author><author><keyname>Bar-Ilan</keyname><forenames>Judit</forenames></author></authors><title>A bibliometric index based on the complete list of cited publications</title><categories>cs.DL</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new index, the $j$-index, which is defined for an author as the
sum of the square roots of the numbers of citations to each of the author's
publications. The idea behind the $j$-index it to remedy a drawback of the
$h$-index $-$ that the $h$-index does not take into account the full citation
record of a researcher. The square root function is motivated by our desire to
avoid the possible bias that may occur with a simple sum when an author has
several very highly cited papers. We compare the $j$-index to the $h$-index,
the $g$-index and the total citation count for three subject areas using
several association measures.
  Our results indicate that that the association between the $j$-index and the
other indices varies according to the subject area. One explanation of this
variation may be due to the proportion of citations to publications of the
researcher that are in the $h$-core. The $j$-index is {\em not} an $h$-index
variant, and as such is intended to complement rather than necessarily replace
the $h$-index and other bibliometric indicators, thus providing a more complete
picture of a researcher's achievements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6962</identifier>
 <datestamp>2015-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6962</id><created>2013-04-25</created><updated>2015-11-04</updated><authors><author><keyname>Usevich</keyname><forenames>Konstantin</forenames></author><author><keyname>Markovsky</keyname><forenames>Ivan</forenames></author></authors><title>Variable projection methods for approximate (greatest) common divisor
  computations</title><categories>math.OC cs.NA math.NA</categories><comments>32 pages, 4 figures</comments><msc-class>15B05, 15B99, 41A29, 65K05, 65Y20, 68W25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding for a given $N$-tuple of polynomials (real
or complex) the closest $N$-tuple that has a common divisor of degree at least
$d$. Extended weighted Euclidean seminorm of the coefficients is used as a
measure of closeness. Two equivalent representations of the problem are
considered: (i) direct parameterization over the common divisors and quotients
(image representation), and (ii) Sylvester low-rank approximation (kernel
representation). We use the duality between least-squares and least-norm
problems to show that (i) and (ii) are closely related to mosaic Hankel
low-rank approximation. This allows us to apply to the approximate common
divisor problem recent results on complexity and accuracy of computations for
mosaic Hankel low-rank approximation. We develop optimization methods based on
the variable projection principle both for image and kernel representation.
These methods have linear complexity in the degrees of the polynomials for
small and large $d$. We provide a software implementation of the developed
methods, which is based on a software package for structured low-rank
approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6969</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6969</id><created>2013-04-25</created><authors><author><keyname>Mehmetoglu</keyname><forenames>Mustafa S.</forenames></author><author><keyname>Akyol</keyname><forenames>Emrah</forenames></author><author><keyname>Rose</keyname><forenames>Kenneth</forenames></author></authors><title>A Deterministic Annealing Approach to Optimization of Zero-delay
  Source-Channel Codes</title><categories>cs.IT math.IT</categories><comments>Submitted to ITW 2013, in review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies optimization of zero-delay source-channel codes, and
specifically the problem of obtaining globally optimal transformations that map
between the source space and the channel space, under a given transmission
power constraint and for the mean square error distortion. Particularly, we
focus on the setting where the decoder has access to side information, whose
cost surface is known to be riddled with local minima. Prior work derived the
necessary conditions for optimality of the encoder and decoder mappings, along
with a greedy optimization algorithm that imposes these conditions iteratively,
in conjunction with the heuristic &quot;noisy channel relaxation&quot; method to mitigate
poor local minima. While noisy channel relaxation is arguably effective in
simple settings, it fails to provide accurate global optimization results in
more complicated settings including the decoder with side information as
considered in this paper. We propose a global optimization algorithm based on
the ideas of &quot;deterministic annealing&quot;- a non-convex optimization method,
derived from information theoretic principles with analogies to statistical
physics, and successfully employed in several problems including clustering,
vector quantization and regression. We present comparative numerical results
that show strict superiority of the proposed algorithm over greedy optimization
methods as well as over the noisy channel relaxation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6983</identifier>
 <datestamp>2014-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6983</id><created>2013-04-25</created><updated>2014-09-06</updated><authors><author><keyname>Lewitzka</keyname><forenames>Steffen</forenames></author></authors><title>Algebraic semantics for a modal logic close to S1</title><categories>cs.LO</categories><comments>14 pages, thoroughly revised and extended version, title has changed</comments><msc-class>03B45</msc-class><doi>10.1093/logcom/exu067</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The modal systems S1--S3 were introduced by C. I. Lewis as logics for strict
implication. While there are Kripke semantics for S2 and S3, there is no known
natural semantics for S1. We extend S1 by a Substitution Principle SP which
generalizes a reference rule of S1. In system S1+SP, the relation of strict
equivalence $\varphi\equiv\psi$ satisfies the identity axioms of R. Suszko's
non-Fregean logic adapted to the language of modal logic (we call these axioms
the axioms of propositional identity). This enables us to develop a framework
of algebraic semantics which captures S1+SP as well as the Lewis systems
S3--S5. So from the viewpoint of algebraic semantics, S1+SP turns out to be an
interesting modal logic. We show that S1+SP is strictly contained between S1
and S3 and differs from S2. It is the weakest modal logic containing S1 such
that strict equivalence is axiomatized by propositional identity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6990</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6990</id><created>2013-04-25</created><authors><author><keyname>Schilling</keyname><forenames>Tanja</forenames></author><author><keyname>Pajdla</keyname><forenames>Tomas</forenames></author></authors><title>Euclidean Upgrade from a Minimal Number of Segments</title><categories>cs.CV</categories><comments>Part of the OAGM/AAPR 2013 proceedings (arXiv:1304.1876)</comments><report-no>OAGM-AAPR/2013/03</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an algebraic approach to upgrade a projective
reconstruction to a Euclidean one, and aim at computing the rectifying
homography from a minimal number of 9 segments of known length. Constraints are
derived from these segments which yield a set of polynomial equations that we
solve by means of Gr\&quot;obner bases. We explain how a solver for such a system of
equations can be constructed from simplified template data. Moreover, we
present experiments that demonstrate that the given problem can be solved in
this way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6994</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6994</id><created>2013-04-25</created><authors><author><keyname>Dubois</keyname><forenames>Swan</forenames><affiliation>LPD, EPFL</affiliation></author><author><keyname>Guerraoui</keyname><forenames>Rachid</forenames><affiliation>LPD, EPFL</affiliation></author></authors><title>Sp\'eculation et auto-stabilisation</title><categories>cs.DC</categories><comments>in French</comments><proxy>ccsd</proxy><journal-ref>15\`emes Rencontres Francophones sur les Aspects Algorithmiques
  des T\'el\'ecommunications (AlgoTel), Pornic : France (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-stabilization ensures that, after any transient fault, the system
recovers in a finite time and eventually exhibits a correct behaviour.
Speculation consists in guaranteeing that the system satisfies its requirements
for any execution but exhibits significantly better performances for a subset
of executions that are more probable. A speculative protocol is in this sense
supposed to be both robust and efficient in practice. We introduce the notion
of speculative stabilization which we illustrate through the mutual exclusion
problem. We then present a novel speculatively stabilizing mutual exclusion
protocol. Our protocol is self-stabilizing for any asynchronous execution. We
prove that its stabilization time for synchronous executions is diam(g)/2 steps
(where diam(g) denotes the diameter of the system). This complexity result is
of independent interest. The celebrated mutual exclusion protocol of Dijkstra
stabilizes in n steps (where n is the number of processes) in synchronous
executions and the question whether the stabilization time could be strictly
smaller than the diameter has been open since then (almost 40 years). We show
that this is indeed possible for any underlying topology. We also provide a
lower bound proof that shows that our new stabilization time of diam(g)/2 steps
is optimal for synchronous executions, even if asynchronous stabilization is
not required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.6996</identifier>
 <datestamp>2013-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.6996</id><created>2013-04-25</created><authors><author><keyname>Allix</keyname><forenames>Olivier</forenames><affiliation>LMT</affiliation></author><author><keyname>Gosselet</keyname><forenames>Pierre</forenames><affiliation>LMT</affiliation></author><author><keyname>Kerfriden</keyname><forenames>Pierre</forenames><affiliation>LMT</affiliation></author><author><keyname>Saavedra</keyname><forenames>Karin</forenames><affiliation>LMT</affiliation></author></authors><title>Virtual Delamination Testing through Non-Linear Multi-Scale
  Computational Methods: Some Recent Progress</title><categories>math.NA cs.NA</categories><proxy>ccsd</proxy><journal-ref>CMC: Computers, Materials, \&amp; Continua 32, 2 (2012) 107-132</journal-ref><doi>10.3970/cmc.2012.032.107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the parallel simulation of delamination problems at the
meso-scale by means of multi-scale methods, the aim being the Virtual
Delamination Testing of Composite parts. In the non-linear context, Domain
Decomposition Methods are mainly used as a solver for the tangent problem to be
solved at each iteration of a Newton-Raphson algorithm. In case of strongly
nonlinear and heterogeneous problems, this procedure may lead to severe
difficulties. The paper focuses on methods to circumvent these problems, which
can now be expressed using a relatively general framework, even though the
different ingredients of the strategy have emerged separately. We rely here on
the micro-macro framework proposed in (Ladev\`eze, Loiseau, and Dureisseix,
2001). The method proposed in this paper introduces three additional features:
(i) the adaptation of the macro-basis to situations where classical
homogenization does not provide a good preconditioner, (ii) the use of
non-linear relocalization to decrease the number of global problems to be
solved in the case of unevenly distributed non-linearities, (iii) the
adaptation of the approximation of the local Schur complement which governs the
convergence of the proposed iterative technique. Computations of delamination
and delamination-buckling interaction with contact on potentially large
delaminated areas are used to illustrate those aspects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7001</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7001</id><created>2013-04-25</created><authors><author><keyname>Bhatia</keyname><forenames>Deepika</forenames></author><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author></authors><title>Network Control Systems RTAI framework A Review</title><categories>cs.OS</categories><comments>Pages: 4 Figures : 1</comments><journal-ref>International Journal of Computer Science and Information
  Technologies (IJCSIT),Vol. 2(5) , 2011, 2380-2383</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the advancement in the automation industry, to perform complex remote
operations is required. Advancements in the networking technology has led to
the development of different architectures to implement control from a large
distance. In various control applications of the modern industry, the agents,
such as sensors, actuators, and controllers are basically geographically
distributed. For efficient working of a control application, all of the agents
have to exchange information through a communication media. At present, an
increasing number of distributed control systems are based on platforms made up
of conventional PCs running open-source real-time operating systems. Often,
these systems needed to have networked devices supporting synchronized
operations with respect to each node. A framework is studied that relies on
standard software and protocol as RTAI, EtherCAT, RTnet and IEEE 1588. RTAI and
its various protocols are studied in network control systems environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7018</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7018</id><created>2013-04-25</created><authors><author><keyname>Kreeft</keyname><forenames>Jasper</forenames></author><author><keyname>Gerritsma</keyname><forenames>Marc</forenames></author></authors><title>Higher-order compatible discretization on hexahedrals</title><categories>math-ph cs.CE cs.CG cs.NA math.MP</categories><comments>to appear in Lecture Notes in Computational Science and Engineering</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive a compatible discretization method that relies heavily on the
underlying geometric structure, and obeys the topological sequences and
commuting properties that are constructed. As a sample problem we consider the
vorticity-velocity-pressure formulation of the Stokes problem. We motivate the
choice for a mixed variational formulation based on both geometric as well as
physical arguments. Numerical tests confirm the theoretical results that we
obtain a pointwise divergence-free solution for the Stokes problem and that the
method obtains optimal convergence rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7025</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7025</id><created>2013-04-25</created><authors><author><keyname>Ramesh</keyname><forenames>Gayatri</forenames></author><author><keyname>Atallah</keyname><forenames>Elie</forenames></author><author><keyname>Sun</keyname><forenames>Qiyu</forenames></author></authors><title>Recovery of bilevel causal signals with finite rate of innovation using
  positive sampling kernels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bilevel signal $x$ with maximal local rate of innovation $R$ is a
continuous-time signal that takes only two values 0 and 1 and that there is at
most one transition position in any time period of 1/R.In this note, we
introduce a recovery method for bilevel causal signals $x$ with maximal local
rate of innovation $R$ from their uniform samples $x*h(nT), n\ge 1$, where the
sampling kernel $h$ is causal and positive on $(0, T)$, and the sampling rate
$\tau:=1/T$ is at (or above) the maximal local rate of innovation $R$. We also
discuss stability of the bilevel signal recovery procedure in the presence of
bounded noises.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7029</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7029</id><created>2013-04-25</created><authors><author><keyname>Alur</keyname><forenames>Rajeev</forenames></author><author><keyname>Raghothaman</keyname><forenames>Mukund</forenames></author></authors><title>Decision Problems for Additive Regular Functions</title><categories>cs.FL</categories><comments>Conference version to appear in ICALP 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Additive Cost Register Automata (ACRA) map strings to integers using a finite
set of registers that are updated using assignments of the form &quot;x := y + c&quot; at
every step. The corresponding class of additive regular functions has multiple
equivalent characterizations, appealing closure properties, and a decidable
equivalence problem. In this paper, we solve two decision problems for this
model. First, we define the register complexity of an additive regular function
to be the minimum number of registers that an ACRA needs to compute it. We
characterize the register complexity by a necessary and sufficient condition
regarding the largest subset of registers whose values can be made far apart
from one another. We then use this condition to design a PSPACE algorithm to
compute the register complexity of a given ACRA, and establish a matching lower
bound. Our results also lead to a machine-independent characterization of the
register complexity of additive regular functions. Second, we consider
two-player games over ACRAs, where the objective of one of the players is to
reach a target set while minimizing the cost. We show the corresponding
decision problem to be EXPTIME-complete when costs are non-negative integers,
but undecidable when costs are integers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7034</identifier>
 <datestamp>2013-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7034</id><created>2013-04-25</created><updated>2013-06-26</updated><authors><author><keyname>Singh</keyname><forenames>P.</forenames></author><author><keyname>Sreenivasan</keyname><forenames>S.</forenames></author><author><keyname>Szymanski</keyname><forenames>B. K.</forenames></author><author><keyname>Korniss</keyname><forenames>G.</forenames></author></authors><title>Threshold-limited spreading in social networks with multiple initiators</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><journal-ref>Scientific Reports 3, 2330 (2013)</journal-ref><doi>10.1038/srep02330</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A classical model for social-influence-driven opinion change is the threshold
model. Here we study cascades of opinion change driven by threshold model
dynamics in the case where multiple {\it initiators} trigger the cascade, and
where all nodes possess the same adoption threshold $\phi$. Specifically, using
empirical and stylized models of social networks, we study cascade size as a
function of the initiator fraction $p$. We find that even for arbitrarily high
value of $\phi$, there exists a critical initiator fraction $p_c(\phi)$ beyond
which the cascade becomes global. Network structure, in particular clustering,
plays a significant role in this scenario. Similarly to the case of single-node
or single-clique initiators studied previously, we observe that community
structure within the network facilitates opinion spread to a larger extent than
a homogeneous random network. Finally, we study the efficacy of different
initiator selection strategies on the size of the cascade and the cascade
window.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7038</identifier>
 <datestamp>2013-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7038</id><created>2013-04-25</created><updated>2013-06-29</updated><authors><author><keyname>Winslow</keyname><forenames>Andrew</forenames></author></authors><title>Staged Self-Assembly and Polyomino Context-Free Grammars</title><categories>cs.CC cs.CG</categories><comments>34 pages, 23 figures. An abstract version has been accepted to DNA 19</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous work by Demaine et al. (2012) developed a strong connection between
smallest context-free grammars and staged self-assembly systems for
one-dimensional strings and assemblies. We extend this work to two-dimensional
polyominoes and assemblies, comparing staged self-assembly systems to a natural
generalization of context-free grammars we call polyomino context-free grammars
(PCFGs). We achieve nearly optimal bounds on the largest ratios of the smallest
PCFG and staged self-assembly system for a given polyomino with n cells. For
the ratio of PCFGs over assembly systems, we show the smallest PCFG can be an
Omega(n/(log(n))^3)-factor larger than the smallest staged assembly system,
even when restricted to square polyominoes. For the ratio of assembly systems
over PCFGs, we show that the smallest staged assembly system is never more than
a O(log(n))-factor larger than the smallest PCFG and is sometimes an
Omega(log(n)/loglog(n))-factor larger.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7045</identifier>
 <datestamp>2014-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7045</id><created>2013-04-25</created><updated>2014-02-20</updated><authors><author><keyname>Livni</keyname><forenames>Roi</forenames></author><author><keyname>Shalev-Shwartz</keyname><forenames>Shai</forenames></author><author><keyname>Shamir</keyname><forenames>Ohad</forenames></author></authors><title>An Algorithm for Training Polynomial Networks</title><categories>cs.LG cs.AI stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider deep neural networks, in which the output of each node is a
quadratic function of its inputs. Similar to other deep architectures, these
networks can compactly represent any function on a finite training set. The
main goal of this paper is the derivation of an efficient layer-by-layer
algorithm for training such networks, which we denote as the \emph{Basis
Learner}. The algorithm is a universal learner in the sense that the training
error is guaranteed to decrease at every iteration, and can eventually reach
zero under mild conditions. We present practical implementations of this
algorithm, as well as preliminary experimental results. We also compare our
deep architecture to other shallow architectures for learning polynomials, in
particular kernel learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7047</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7047</id><created>2013-04-25</created><authors><author><keyname>Deshpande</keyname><forenames>Yash</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Finding Hidden Cliques of Size \sqrt{N/e} in Nearly Linear Time</title><categories>math.PR cs.IT math.IT math.ST stat.TH</categories><comments>48 pages, 1 table, no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider an Erd\&quot;os-Renyi random graph in which each edge is present
independently with probability 1/2, except for a subset $\sC_N$ of the vertices
that form a clique (a completely connected subgraph). We consider the problem
of identifying the clique, given a realization of such a random graph.
  The best known algorithm provably finds the clique in linear time with high
probability, provided $|\sC_N|\ge 1.261\sqrt{N}$ \cite{dekel2011finding}.
Spectral methods can be shown to fail on cliques smaller than $\sqrt{N}$. In
this paper we describe a nearly linear time algorithm that succeeds with high
probability for $|\sC_N|\ge (1+\eps)\sqrt{N/e}$ for any $\eps&gt;0$. This is the
first algorithm that provably improves over spectral methods.
  We further generalize the hidden clique problem to other background graphs
(the standard case corresponding to the complete graph on $N$ vertices). For
large girth regular graphs of degree $(\Delta+1)$ we prove that `local'
algorithms succeed if $|\sC_N|\ge (1+\eps)N/\sqrt{e\Delta}$ and fail if
$|\sC_N|\le(1-\eps)N/\sqrt{e\Delta}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7048</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7048</id><created>2013-04-25</created><authors><author><keyname>Dobzinski</keyname><forenames>Shahar</forenames></author><author><keyname>Leme</keyname><forenames>Renato Paes</forenames></author></authors><title>Efficiency Guarantees in Auctions with Budgets</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In settings where players have a limited access to liquidity, represented in
the form of budget constraints, efficiency maximization has proven to be a
challenging goal. In particular, the social welfare cannot be approximated by a
better factor then the number of players. Therefore, the literature has mainly
resorted to Pareto-efficiency as a way to achieve efficiency in such settings.
While successful in some important scenarios, in many settings it is known that
either exactly one incentive-compatible auction that always outputs a
Pareto-efficient solution, or that no truthful mechanism can always guarantee a
Pareto-efficient outcome. Traditionally, impossibility results can be avoided
by considering approximations. However, Pareto-efficiency is a binary property
(is either satisfied or not), which does not allow for approximations.
  In this paper we propose a new notion of efficiency, called \emph{liquid
welfare}. This is the maximum amount of revenue an omniscient seller would be
able to extract from a certain instance. We explain the intuition behind this
objective function and show that it can be 2-approximated by two different
auctions. Moreover, we show that no truthful algorithm can guarantee an
approximation factor better than 4/3 with respect to the liquid welfare, and
provide a truthful auction that attains this bound in a special case.
  Importantly, the liquid welfare benchmark also overcomes impossibilities for
some settings. While it is impossible to design Pareto-efficient auctions for
multi-unit auctions where players have decreasing marginal values, we give a
deterministic $O(\log n)$-approximation for the liquid welfare in this setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7049</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7049</id><created>2013-04-25</created><authors><author><keyname>Jhurani</keyname><forenames>Chetan</forenames></author></authors><title>Subspace-preserving sparsification of matrices with minimal perturbation
  to the near null-space. Part I: Basics</title><categories>math.NA cs.MS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is the first of two papers to describe a matrix sparsification algorithm
that takes a general real or complex matrix as input and produces a sparse
output matrix of the same size. The non-zero entries in the output are chosen
to minimize changes to the singular values and singular vectors corresponding
to the near null-space of the input. The output matrix is constrained to
preserve left and right null-spaces exactly. The sparsity pattern of the output
matrix is automatically determined or can be given as input.
  If the input matrix belongs to a common matrix subspace, we prove that the
computed sparse matrix belongs to the same subspace. This works without
imposing explicit constraints pertaining to the subspace. This property holds
for the subspaces of Hermitian, complex-symmetric, Hamiltonian, circulant,
centrosymmetric, and persymmetric matrices, and for each of the skew
counterparts.
  Applications of our method include computation of reusable sparse
preconditioning matrices for reliable and efficient solution of high-order
finite element systems. The second paper in this series describes our
open-source implementation, and presents further technical details.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7050</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7050</id><created>2013-04-25</created><authors><author><keyname>Jhurani</keyname><forenames>Chetan</forenames></author></authors><title>Subspace-preserving sparsification of matrices with minimal perturbation
  to the near null-space. Part II: Approximation and Implementation</title><categories>math.NA cs.MS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is the second of two papers to describe a matrix sparsification
algorithm that takes a general real or complex matrix as input and produces a
sparse output matrix of the same size. The first paper presented the original
algorithm, its features, and theoretical results.
  Since the output of this sparsification algorithm is a matrix rather than a
vector, it can be costly in memory and run-time if an implementation does not
exploit the structural properties of the algorithm and the matrix. Here we show
how to modify the original algorithm to increase its efficiency. This is
possible by computing an approximation to the exact result. We introduce extra
constraints that are automatically determined based on the input matrix. This
addition reduces the number of unknown degrees of freedom but still preserves
many matrix subspaces. We also describe our open-source library that implements
this sparsification algorithm and has interfaces in C++, C, and MATLAB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7053</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7053</id><created>2013-04-25</created><authors><author><keyname>Jhurani</keyname><forenames>Chetan</forenames></author><author><keyname>Mullowney</keyname><forenames>Paul</forenames></author></authors><title>A GEMM interface and implementation on NVIDIA GPUs for multiple small
  matrices</title><categories>cs.MS cs.DC math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an interface and an implementation of the General Matrix Multiply
(GEMM) routine for multiple small matrices processed simultaneously on NVIDIA
graphics processing units (GPUs). We focus on matrix sizes under 16. The
implementation can be easily extended to larger sizes. For single precision
matrices, our implementation is 30% to 600% faster than the batched cuBLAS
implementation distributed in the CUDA Toolkit 5.0 on NVIDIA Tesla K20c. For
example, we obtain 104 GFlop/s and 216 GFlop/s when multiplying 100,000
independent matrix pairs of size 10 and 16, respectively. Similar improvement
in performance is obtained for other sizes, in single and double precision for
real and complex types, and when the number of matrices is smaller. Apart from
our implementation, our different function interface also plays an important
role in the improved performance. Applications of this software include Finite
Element computation on GPUs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7054</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7054</id><created>2013-04-25</created><authors><author><keyname>Jhurani</keyname><forenames>Chetan</forenames></author></authors><title>Batched Kronecker product for 2-D matrices and 3-D arrays on NVIDIA GPUs</title><categories>cs.MS cs.DC math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an interface and an implementation for performing Kronecker
product actions on NVIDIA GPUs for multiple small 2-D matrices and 3-D arrays
processed in parallel as a batch. This method is suited to cases where the
Kronecker product component matrices are identical but the operands in a
matrix-free application vary in the batch. Any batched GEMM (General Matrix
Multiply) implementation, for example ours [1] or the one in cuBLAS, can also
be used for performing batched Kronecker products on GPUs. However, the
specialized implementation presented here is faster and uses less memory.
Partly this is because a simple GEMM based approach would require extra copies
to and from main memory. We focus on matrix sizes less than or equal to 16,
since these are the typical polynomial degrees in Finite Elements, but the
implementation can be easily extended for other sizes. We obtain 143 and 285
GFlop/s for single precision real when processing matrices of size 10 and 16,
respectively on NVIDIA Tesla K20c using CUDA 5.0. The corresponding speeds for
3-D array Kronecker products are 126 and 268 GFlop/s, respectively. Double
precision is easily supported using the C++ template mechanism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7055</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7055</id><created>2013-04-25</created><authors><author><keyname>Gao</keyname><forenames>Zhihan</forenames></author></authors><title>An LP-based 3/2-approximation algorithm for the graphic s-t path TSP</title><categories>cs.DS</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We design a new LP-based algorithm for the graphic $s$-$t$ path Traveling
Salesman Problem (TSP), which achieves the best approximation factor of 1.5.
The algorithm is based on the idea of narrow cuts due to An, Kleinberg, and
Shmoys. It partly answers an open question of Seb\H{o}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7061</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7061</id><created>2013-04-26</created><authors><author><keyname>I</keyname><forenames>Tomohiro</forenames></author><author><keyname>Nakashima</keyname><forenames>Yuto</forenames></author><author><keyname>Inenaga</keyname><forenames>Shunsuke</forenames></author><author><keyname>Bannai</keyname><forenames>Hideo</forenames></author><author><keyname>Takeda</keyname><forenames>Masayuki</forenames></author></authors><title>Efficient Lyndon factorization of grammar compressed text</title><categories>cs.DS</categories><comments>CPM 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm for computing the Lyndon factorization of a string
that is given in grammar compressed form, namely, a Straight Line Program
(SLP). The algorithm runs in $O(n^4 + mn^3h)$ time and $O(n^2)$ space, where
$m$ is the size of the Lyndon factorization, $n$ is the size of the SLP, and
$h$ is the height of the derivation tree of the SLP. Since the length of the
decompressed string can be exponentially large w.r.t. $n, m$ and $h$, our
result is the first polynomial time solution when the string is given as SLP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7067</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7067</id><created>2013-04-26</created><authors><author><keyname>I</keyname><forenames>Tomohiro</forenames></author><author><keyname>Matsubara</keyname><forenames>Wataru</forenames></author><author><keyname>Shimohira</keyname><forenames>Kouji</forenames></author><author><keyname>Inenaga</keyname><forenames>Shunsuke</forenames></author><author><keyname>Bannai</keyname><forenames>Hideo</forenames></author><author><keyname>Takeda</keyname><forenames>Masayuki</forenames></author><author><keyname>Narisawa</keyname><forenames>Kazuyuki</forenames></author><author><keyname>Shinohara</keyname><forenames>Ayumi</forenames></author></authors><title>Detecting regularities on grammar-compressed strings</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We solve the problems of detecting and counting various forms of regularities
in a string represented as a Straight Line Program (SLP). Given an SLP of size
$n$ that represents a string $s$ of length $N$, our algorithm compute all runs
and squares in $s$ in $O(n^3h)$ time and $O(n^2)$ space, where $h$ is the
height of the derivation tree of the SLP. We also show an algorithm to compute
all gapped-palindromes in $O(n^3h + gnh\log N)$ time and $O(n^2)$ space, where
$g$ is the length of the gap. The key technique of the above solution also
allows us to compute the periods and covers of the string in $O(n^2 h)$ time
and $O(nh(n+\log^2 N))$ time, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7071</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7071</id><created>2013-04-26</created><authors><author><keyname>Ablinger</keyname><forenames>Jakob</forenames></author><author><keyname>Bl&#xfc;mlein</keyname><forenames>Johannes</forenames></author></authors><title>Harmonic Sums, Polylogarithms, Special Numbers, and their
  Generalizations</title><categories>math-ph cs.SC hep-ph hep-th math.AG math.MP</categories><comments>30 pages Latex, 3 Figures, 1 style file, Cintribution to:
  &quot;Integration, Summation and Special Functions in Quantum Field Theory&quot;, to
  appear at Springer Verlag, Vienna</comments><report-no>DESY 13-073, DO-TH 13/10, SFB/CPP-13-26, LPN13-025</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In these introductory lectures we discuss classes of presently known nested
sums, associated iterated integrals, and special constants which hierarchically
appear in the evaluation of massless and massive Feynman diagrams at higher
loops. These quantities are elements of stuffle and shuffle algebras implying
algebraic relations being widely independent of the special quantities
considered. They are supplemented by structural relations. The generalizations
are given in terms of generalized harmonic sums, (generalized) cyclotomic sums,
and sums containing in addition binomial and inverse-binomial weights. To all
these quantities iterated integrals and special numbers are associated. We also
discuss the analytic continuation of nested sums of different kind to complex
values of the external summation bound N.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7072</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7072</id><created>2013-04-26</created><authors><author><keyname>Wan</keyname><forenames>Chang Jin</forenames></author><author><keyname>Zhu</keyname><forenames>Li Qiang</forenames></author><author><keyname>Shi</keyname><forenames>Yi</forenames></author><author><keyname>Wan</keyname><forenames>Qing</forenames></author></authors><title>Learning and Spatiotemporally Correlated Functions Mimicked in
  Oxide-Based Artificial Synaptic Transistors</title><categories>cond-mat.mtrl-sci cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning and logic are fundamental brain functions that make the individual
to adapt to the environment, and such functions are established in human brain
by modulating ionic fluxes in synapses. Nanoscale ionic/electronic devices with
inherent synaptic functions are considered to be essential building blocks for
artificial neural networks. Here, Multi-terminal IZO-based artificial synaptic
transistors gated by fast proton-conducting phosphosilicate electrolytes are
fabricated on glass substrates. Proton in the SiO2 electrolyte and IZO channel
conductance are regarded as the neurotransmitter and synaptic weight,
respectively. Spike-timing dependent plasticity, short-term memory and
long-term memory were successfully mimicked in such protonic/electronic hybrid
artificial synapses. And most importantly, spatiotemporally correlated logic
functions are also mimicked in a simple artificial neural network without any
intentional hard-wire connections due to the naturally proton-related coupling
effect. The oxide-based protonic/electronic hybrid artificial synaptic
transistors reported here are potential building blocks for artificial neural
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7073</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7073</id><created>2013-04-26</created><authors><author><keyname>Negi</keyname><forenames>Priyanka</forenames></author><author><keyname>Mishra</keyname><forenames>Anupama</forenames></author><author><keyname>Gupta</keyname><forenames>B. B.</forenames></author></authors><title>Enhanced CBF Packet Filtering Method to Detect DDoS Attack in Cloud
  Computing Environment</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tremendous and extraordinary growths in the field of internet, intranet,
extranet and its users have developed an innovative era of great global
competition and contention. Denial of service attack by multiple nodes is
accomplished of disturbing the services of rival servers. The attack can be for
multiple reasons. So it is a major threat for cloud environment. Due to low
effectiveness and large storage conventional defending approaches cannot be
easily applied in cloud security. The effects of various attacks can decrease
the influence of a cloud. So, in view of this challenge task, this paper aims
at enhancing a proposed method for cloud security. We propose a modification to
the confidence Based Filtering method (CBF) which is investigated for cloud
computing environment based on correlation pattern to mitigate DDoS attacks on
Cloud. The modification introduces nominal additional bandwidth and tries to
increase the processing speed of the victim initiated server.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7075</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7075</id><created>2013-04-26</created><authors><author><keyname>Brand</keyname><forenames>Michael</forenames></author></authors><title>Lower bounds on the M\&quot;{u}nchhausen problem</title><categories>cs.IT math.CO math.IT</categories><comments>7 pages</comments><msc-class>05B20, 11B30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  &quot;The Baron's omni-sequence&quot;, B(n), first defined by Khovanova and Lewis
(2011), is a sequence that gives for each n the minimum number of weighings on
balance scales that can verify the correct labeling of n identically-looking
coins with distinct integer weights between 1 gram and n grams. A trivial lower
bound on B(n) is log_3(n), and it has been shown that B(n) is log_3(n) + O(log
log n). In this paper we give a first nontrivial lower bound to the
M\&quot;{u}nchhausen problem, showing that there is an infinite number of n values
for which B(n) does not equal ceil(log_3 n). Furthermore, we show that if N(k)
is the number of n values for which k = ceil(log_3 n) and B(n) does not equal
k, then N(k) is an unbounded function of k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7094</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7094</id><created>2013-04-26</created><authors><author><keyname>Pinn</keyname><forenames>Jun Ziang</forenames></author><author><keyname>Zung</keyname><forenames>A. Fr.</forenames></author></authors><title>A new Watermarking Technique for Secure Database</title><categories>cs.DB cs.CR cs.MM</categories><comments>Database</comments><journal-ref>International Journal of Computer Engineering &amp; Applications, Vol.
  I, No. I, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital multimedia watermarking technology was suggested in the last decade
to embed copyright information in digital objects such images, audio and video.
However, the increasing use of relational database systems in many real-life
applications created an ever increasing need for watermarking database systems.
As a result, watermarking relational database systems is now merging as a
research area that deals with the legal issue of copyright protection of
database systems. Approach: In this study, we proposed an efficient database
watermarking algorithm based on inserting binary image watermarks in
non-numeric mutli-word attributes of selected database tuples. Results: The
algorithm is robust as it resists attempts to remove or degrade the embedded
watermark and it is blind as it does not require the original database in order
to extract the embedded watermark. Conclusion: Experimental results
demonstrated blindness and the robustness of the algorithm against common
database attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7095</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7095</id><created>2013-04-26</created><authors><author><keyname>Liu</keyname><forenames>Shuiyin</forenames></author><author><keyname>Ling</keyname><forenames>Cong</forenames></author><author><keyname>Wu</keyname><forenames>Xiaofu</forenames></author></authors><title>Proximity Factors of Lattice Reduction-Aided Precoding for Multiantenna
  Broadcast</title><categories>cs.IT math.IT</categories><comments>ISIT 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lattice precoding is an effective strategy for multiantenna broadcast. In
this paper, we show that approximate lattice precoding in multiantenna
broadcast is a variant of the closest vector problem (CVP) known as $\eta$-CVP.
The proximity factors of lattice reduction-aided precoding are defined, and
their bounds are derived, which measure the worst-case loss in power efficiency
compared to sphere precoding. Unlike decoding applications, this analysis does
not suffer from the boundary effect of a finite constellation, since the
underlying lattice in multiantenna broadcast is indeed infinite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7096</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7096</id><created>2013-04-26</created><authors><author><keyname>Tiwari</keyname><forenames>Rajesh Kumar</forenames></author></authors><title>A Novel approach for Hybrid Database</title><categories>cs.DB cs.CR cs.MM</categories><journal-ref>International Journal of Computer Engineering &amp; Applications, Vol
  1, Iss 1, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the current world of economic crises, the cost control is one of the chief
concerns for all types of industries, especially for the small venders. The
small vendors are suppose to minimize their budget on Information Technology by
reducing the initial investment in hardware and costly database servers like
ORACLE, SQL Server, SYBASE, etc. for the purpose of data processing and
storing. In other divisions, the electronic devices manufacturing companies
want to increase the demand and reduce the manufacturing cost by introducing
the low cost technologies. The new small devices like ipods, iphones, palm top
etc. are now-a-days used as data computation and storing tools. For both the
cases mentioned above, instead of going for the costly database servers which
additionally requires extra hardware as well as the extra expenses in training
and handling, the flat file may be considered as a candidate due to its easy
handling nature, fast accessing, and of course free of cost. But the main
hurdle is the security aspects which are not up to the optimum level. In this
paper, we propose a methodology that combines all the merit of the flat file
and with the help of a novel steganographic technique we can maintain the
utmost security fence. The new proposed methodology will undoubtedly be highly
beneficial for small vendors as well as for the above said electronic devices
manufacturer
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7118</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7118</id><created>2013-04-26</created><authors><author><keyname>Tapson</keyname><forenames>J.</forenames></author><author><keyname>Cohen</keyname><forenames>G.</forenames></author><author><keyname>Afshar</keyname><forenames>S.</forenames></author><author><keyname>Stiefel</keyname><forenames>K.</forenames></author><author><keyname>Buskila</keyname><forenames>Y.</forenames></author><author><keyname>Wang</keyname><forenames>R.</forenames></author><author><keyname>Hamilton</keyname><forenames>T. J.</forenames></author><author><keyname>van Schaik</keyname><forenames>A.</forenames></author></authors><title>Synthesis of neural networks for spatio-temporal spike pattern
  recognition and processing</title><categories>cs.NE q-bio.NC</categories><comments>In submission to Frontiers in Neuromorphic Engineering</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The advent of large scale neural computational platforms has highlighted the
lack of algorithms for synthesis of neural structures to perform predefined
cognitive tasks. The Neural Engineering Framework offers one such synthesis,
but it is most effective for a spike rate representation of neural information,
and it requires a large number of neurons to implement simple functions. We
describe a neural network synthesis method that generates synaptic connectivity
for neurons which process time-encoded neural signals, and which makes very
sparse use of neurons. The method allows the user to specify, arbitrarily,
neuronal characteristics such as axonal and dendritic delays, and synaptic
transfer functions, and then solves for the optimal input-output relationship
using computed dendritic weights. The method may be used for batch or online
learning and has an extremely fast optimization process. We demonstrate its use
in generating a network to recognize speech which is sparsely encoded as spike
times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7121</identifier>
 <datestamp>2014-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7121</id><created>2013-04-26</created><updated>2014-06-10</updated><authors><author><keyname>Aroca</keyname><forenames>Jordi Arjona</forenames></author><author><keyname>Anta</keyname><forenames>Antonio Fernandez</forenames></author><author><keyname>Mosteiro</keyname><forenames>Miguel A.</forenames></author><author><keyname>Thraves</keyname><forenames>Christopher</forenames></author><author><keyname>Wang</keyname><forenames>Lin</forenames></author></authors><title>Power-efficient Assignment of Virtual Machines to Physical Machines</title><categories>cs.DS cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by current trends in cloud computing, we study a version of the
generalized assignment problem where a set of virtual processors has to be
implemented by a set of identical processors. For literature consistency, we
say that a set of virtual machines (VMs) is assigned to a set of physical
machines (PMs). The optimization criteria is to minimize the power consumed by
all the PMs. We term the problem Virtual Machine Assignment (VMA). Crucial
differences with previous work include a variable number of PMs, that each VM
must be assigned to exactly one PM (i.e., VMs cannot be implemented
fractionally), and a minimum power consumption for each active PM. Such
infrastructure may be strictly constrained in the number of PMs or in the PMs'
capacity, depending on how costly (in terms of power consumption) is to add a
new PM to the system or to heavily load some of the existing PMs. Low usage or
ample budget yields models where PM capacity and/or the number of PMs may be
assumed unbounded for all practical purposes. We study 4 VMA problems depending
on whether the capacity or the number of PMs is bounded or not. Specifically,
we study hardness and online competitiveness for a variety of cases. To the
best of our knowledge, this is the first comprehensive study of the VMA problem
for this cost function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7123</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7123</id><created>2013-04-26</created><authors><author><keyname>Gamboa</keyname><forenames>Ruben</forenames><affiliation>University of Wyoming, USA</affiliation></author><author><keyname>Davis</keyname><forenames>Jared</forenames><affiliation>Centaur Technology, USA</affiliation></author></authors><title>Proceedings International Workshop on the ACL2 Theorem Prover and its
  Applications</title><categories>cs.LO cs.MS</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 114, 2013</journal-ref><doi>10.4204/EPTCS.114</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the Eleventh International Workshop
on the ACL2 Theorem Prover and its Applications, held on May 30 and 31, 2013,
in Laramie, Wyoming, USA.
  ACL2 is an industrial-strength automated reasoning system, the latest in the
Boyer-Moore family of theorem provers. The ACL2 workshop is the major technical
forum for users of the ACL2 theorem proving system to present research on the
prover and its applications.
  This year's workshop received 15 submissions covering a wide range of
applications, libraries, prover enhancements, interfaces, and experience
reports. 11 papers were selected by the program committee for presentation at
the workshop.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7124</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7124</id><created>2013-04-26</created><authors><author><keyname>Begum</keyname><forenames>Arshiya</forenames></author><author><keyname>Ali</keyname><forenames>Mohammed Tanveer</forenames></author></authors><title>Security threats in Prepaid Mobile</title><categories>cs.CY</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Recent communications environment significantly expand the mobile
environment. Prepaid mobile services for 3G networks enables telecommunication
to sign up new users by utilizing the latest in converged billing technologies.
The worldwide mobile communication market is exploding, and 50 percent of
subscribers are expected to use prepaid billing . Prepaid services are driving
mobile communication into emerging markets such as South America, Eastern
Europe, Asia, Africa and Gulf Countries. Prepaid phone service requires a user
to make payment before calling. It is quite common to get prepaid SIM cards on
every major Network. This paper discuss about various prepaid techniques,
challenges and countermeasures in prepaid mobile communication system .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7132</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7132</id><created>2013-04-26</created><authors><author><keyname>Riegler</keyname><forenames>Gernot</forenames></author><author><keyname>Pock</keyname><forenames>Thomas</forenames></author><author><keyname>P&#xf6;tzi</keyname><forenames>Werner</forenames></author><author><keyname>Veronig</keyname><forenames>Astrid</forenames></author></authors><title>Filament and Flare Detection in H{\alpha} image sequences</title><categories>cs.CV astro-ph.IM</categories><comments>Part of the OAGM/AAPR 2013 proceedings (arXiv:1304.1876)</comments><report-no>OAGM-AAPR/2013/16</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solar storms can have a major impact on the infrastructure of the earth. Some
of the causing events are observable from ground in the H{\alpha} spectral
line. In this paper we propose a new method for the simultaneous detection of
flares and filaments in H{\alpha} image sequences. Therefore we perform several
preprocessing steps to enhance and normalize the images. Based on the intensity
values we segment the image by a variational approach. In a final
postprecessing step we derive essential properties to classify the events and
further demonstrate the performance by comparing our obtained results to the
data annotated by an expert. The information produced by our method can be used
for near real-time alerts and the statistical analysis of existing data by
solar physicists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7140</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7140</id><created>2013-04-26</created><authors><author><keyname>Helmberger</keyname><forenames>M.</forenames></author><author><keyname>Urschler</keyname><forenames>M.</forenames></author><author><keyname>Pienn</keyname><forenames>M.</forenames></author><author><keyname>Balint</keyname><forenames>Z.</forenames></author><author><keyname>Olschewski</keyname><forenames>A.</forenames></author><author><keyname>Bischof</keyname><forenames>H.</forenames></author></authors><title>Pulmonary Vascular Tree Segmentation from Contrast-Enhanced CT Images</title><categories>cs.CV physics.med-ph</categories><comments>Part of the OAGM/AAPR 2013 proceedings (1304.1876)</comments><report-no>OAGM-AAPR/2013/09</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a pulmonary vessel segmentation algorithm, which is fast, fully
automatic and robust. It uses a coarse segmentation of the airway tree and a
left and right lung labeled volume to restrict a vessel enhancement filter,
based on an offset medialness function, to the lungs. We show the application
of our algorithm on contrast-enhanced CT images, where we derive a clinical
parameter to detect pulmonary hypertension (PH) in patients. Results on a
dataset of 24 patients show that quantitative indices derived from the
segmentation are applicable to distinguish patients with and without PH.
Further work-in-progress results are shown on the VESSEL12 challenge dataset,
which is composed of non-contrast-enhanced scans, where we range in the
midfield of participating contestants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7151</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7151</id><created>2013-04-26</created><authors><author><keyname>Lord</keyname><forenames>Phillip</forenames></author><author><keyname>Marshall</keyname><forenames>Lindsay</forenames></author></authors><title>Twenty-Five Shades of Greycite: Semantics for referencing and
  preservation</title><categories>cs.DL</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Semantic publishing can enable richer documents with clearer, computationally
interpretable properties. For this vision to become reality, however, authors
must benefit from this process, so that they are incentivised to add these
semantics. Moreover, the publication process that generates final content must
allow and enable this semantic content. Here we focus on author-led or &quot;grey&quot;
literature, which uses a convenient and simple publication pipeline. We
describe how we have used metadata in articles to enable richer referencing of
these articles and how we have customised the addition of these semantics to
articles. Finally, we describe how we use the same semantics to aid in digital
preservation and non-repudiability of research articles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7153</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7153</id><created>2013-04-26</created><authors><author><keyname>Innerhofer</keyname><forenames>Peter</forenames></author><author><keyname>Pock</keyname><forenames>Thomas</forenames></author></authors><title>A Convex Approach for Image Hallucination</title><categories>cs.CV</categories><comments>submitted to \&quot;OAGM-AAPR 2013, 8 pages, 3 figures</comments><report-no>OAGM-AAPR/2013/18</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a global convex approach for image hallucination.
Altering the idea of classical multi image super resolution (SU) systems to
single image SU, we incorporate aligned images to hallucinate the output. Our
work is based on the paper of Tappen et al. where they use a non-convex model
for image hallucination. In comparison we formulate a convex primal
optimization problem and derive a fast converging primal-dual algorithm with a
global optimal solution. We use a database with face images to incorporate
high-frequency details to the high-resolution output. We show that we can
achieve state-of-the-art results by using a convex approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7157</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7157</id><created>2013-04-26</created><authors><author><keyname>Derczynski</keyname><forenames>Leon</forenames></author><author><keyname>Shaw</keyname><forenames>Richard</forenames></author><author><keyname>Solway</keyname><forenames>Ben</forenames></author><author><keyname>Wang</keyname><forenames>Jun</forenames></author></authors><title>Question Answering Against Very-Large Text Collections</title><categories>cs.CL cs.IR</categories><journal-ref>Master's theses, 2008, University of Sheffield</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Question answering involves developing methods to extract useful information
from large collections of documents. This is done with specialised search
engines such as Answer Finder. The aim of Answer Finder is to provide an answer
to a question rather than a page listing related documents that may contain the
correct answer. So, a question such as &quot;How tall is the Eiffel Tower&quot; would
simply return &quot;325m&quot; or &quot;1,063ft&quot;. Our task was to build on the current version
of Answer Finder by improving information retrieval, and also improving the
pre-processing involved in question series analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7158</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7158</id><created>2013-04-26</created><authors><author><keyname>Bordes</keyname><forenames>Antoine</forenames></author><author><keyname>Usunier</keyname><forenames>Nicolas</forenames></author><author><keyname>Garcia-Duran</keyname><forenames>Alberto</forenames></author><author><keyname>Weston</keyname><forenames>Jason</forenames></author><author><keyname>Yakhnenko</keyname><forenames>Oksana</forenames></author></authors><title>Irreflexive and Hierarchical Relations as Translations</title><categories>cs.LG</categories><comments>Submitted at the ICML 2013 workshop &quot;Structured Learning: Inferring
  Graphs from Structured and Unstructured Inputs&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of embedding entities and relations of knowledge
bases in low-dimensional vector spaces. Unlike most existing approaches, which
are primarily efficient for modeling equivalence relations, our approach is
designed to explicitly model irreflexive relations, such as hierarchies, by
interpreting them as translations operating on the low-dimensional embeddings
of the entities. Preliminary experiments show that, despite its simplicity and
a smaller number of parameters than previous approaches, our approach achieves
state-of-the-art performance according to standard evaluation protocols on data
from WordNet and Freebase.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7162</identifier>
 <datestamp>2013-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7162</id><created>2013-04-26</created><updated>2013-07-30</updated><authors><author><keyname>Borello</keyname><forenames>Martino</forenames></author></authors><title>The automorphism group of a self-dual [72,36,16] code is not an
  elementary abelian group of order 8</title><categories>cs.IT math.CO math.IT</categories><comments>9 pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The existence of an extremal self-dual binary linear code C of length 72 is a
long-standing open problem. We continue the investigation of its automorphism
group: looking at the combination of the subcodes fixed by different
involutions and doing a computer calculation with Magma, we prove that Aut(C)
is not isomorphic to the elementary abelian group of order 8. Combining this
with the known results in the literature one obtains that Aut(C) has order at
most 5.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7168</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7168</id><created>2013-04-26</created><authors><author><keyname>Saad</keyname><forenames>Emad</forenames></author></authors><title>Non Deterministic Logic Programs</title><categories>cs.AI</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Non deterministic applications arise in many domains, including, stochastic
optimization, multi-objectives optimization, stochastic planning, contingent
stochastic planning, reinforcement learning, reinforcement learning in
partially observable Markov decision processes, and conditional planning. We
present a logic programming framework called non deterministic logic programs,
along with a declarative semantics and fixpoint semantics, to allow
representing and reasoning about inherently non deterministic real-world
applications. The language of non deterministic logic programs framework is
extended with non-monotonic negation, and two alternative semantics are
defined: the stable non deterministic model semantics and the well-founded non
deterministic model semantics as well as their relationship is studied. These
semantics subsume the deterministic stable model semantics and the
deterministic well-founded semantics of deterministic normal logic programs,
and they reduce to the semantics of deterministic definite logic programs
without negation. We show the application of the non deterministic logic
programs framework to a conditional planning problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7184</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7184</id><created>2013-04-26</created><authors><author><keyname>Kavelar</keyname><forenames>Albert</forenames></author><author><keyname>Zambanini</keyname><forenames>Sebastian</forenames></author><author><keyname>Kampel</keyname><forenames>Martin</forenames></author></authors><title>Reading Ancient Coin Legends: Object Recognition vs. OCR</title><categories>cs.CV</categories><comments>Part of the OAGM/AAPR 2013 proceedings (arXiv:1304.1876)</comments><report-no>OAGM-AAPR/2013/08</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Standard OCR is a well-researched topic of computer vision and can be
considered solved for machine-printed text. However, when applied to
unconstrained images, the recognition rates drop drastically. Therefore, the
employment of object recognition-based techniques has become state of the art
in scene text recognition applications. This paper presents a scene text
recognition method tailored to ancient coin legends and compares the results
achieved in character and word recognition experiments to a standard OCR
engine. The conducted experiments show that the proposed method outperforms the
standard OCR engine on a set of 180 cropped coin legend words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7185</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7185</id><created>2013-04-26</created><updated>2013-05-17</updated><authors><author><keyname>Arrighi</keyname><forenames>Pablo</forenames><affiliation>LIG</affiliation></author><author><keyname>Schabanel</keyname><forenames>Nicolas</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Theyssier</keyname><forenames>Guillaume</forenames><affiliation>LAMA</affiliation></author></authors><title>Stochastic Cellular Automata: Correlations, Decidability and Simulations</title><categories>cs.DM cs.FL</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a simple formalism for dealing with deterministic, non-
deterministic and stochastic cellular automata in an unified and composable
manner. This formalism allows for local probabilistic correlations, a feature
which is not present in usual definitions. We show that this feature allows for
strictly more behaviors (for instance, number conserving stochastic cellular
automata require these local probabilistic correlations). We also show that
several problems which are deceptively simple in the usual definitions, become
undecidable when we allow for local probabilistic correlations, even in
dimension one. Armed with this formalism, we extend the notion of intrinsic
simulation between deterministic cellular automata, to the non-deterministic
and stochas- tic settings. Although the intrinsic simulation relation is shown
to become undecidable in dimension two and higher, we provide explicit tools to
prove or disprove the existence of such a simulation between any two given
stochastic cellular automata. Those tools rely upon a characterization of
equality of stochastic global maps, shown to be equivalent to the existence of
a stochastic coupling between the random sources. We apply them to prove that
there is no universal stochastic cellular automaton. Yet we provide stochastic
cellular automata achieving optimal partial universality, as well as a
universal non-deterministic cellular automaton.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7204</identifier>
 <datestamp>2014-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7204</id><created>2013-04-26</created><updated>2014-10-21</updated><authors><author><keyname>Charatonik</keyname><forenames>Witold</forenames></author><author><keyname>Kiero&#x144;ski</keyname><forenames>Emanuel</forenames></author><author><keyname>Mazowiecki</keyname><forenames>Filip</forenames></author></authors><title>Satisfiability of the Two-Variable Fragment of First-Order Logic over
  Trees</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the satisfiability problem for the two-variable fragment of
first-order logic over finite unranked trees. We work with signatures
consisting of some unary predicates and the binary navigational predicates
child, right sibling, and their respective transitive closures. We prove that
the satisfiability problem for the logic containing all these predicates is
EXPSPACE-complete. Further, we consider the restriction of the class of
structures to singular trees, i.e., we assume that at every node precisely one
unary predicate holds. We observe that the full logic and even for unordered
trees remain EXPSPACE-complete over finite singular trees, but the complexity
decreases for some weaker logics. Namely, the logic with one binary predicate,
descendant is NEXPTIME-complete, and its guarded version is PSPACE-complete
over finite singular trees, even though both these logics are EXPSPACE-complete
over arbitrary finite trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7209</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7209</id><created>2013-04-26</created><authors><author><keyname>Kindermann</keyname><forenames>Roland</forenames></author><author><keyname>Junttila</keyname><forenames>Tommi</forenames></author><author><keyname>Niemel&#xe4;</keyname><forenames>Ilkka</forenames></author></authors><title>Bounded Model Checking of an MITL Fragment for Timed Automata</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Timed automata (TAs) are a common formalism for modeling timed systems.
Bounded model checking (BMC) is a verification method that searches for runs
violating a property using a SAT or SMT solver. MITL is a real-time extension
of the linear time logic LTL. Originally, MITL was defined for traces of
non-overlapping time intervals rather than the &quot;super-dense&quot; time traces
allowing for intervals overlapping in single points that are employed by the
nowadays common semantics of timed automata. In this paper we extend the
semantics of a fragment of MITL to super-dense time traces and devise a bounded
model checking encoding for the fragment. We prove correctness and completeness
in the sense that using a sufficiently large bound a counter-example to any
given non-holding property can be found. We have implemented the proposed
bounded model checking approach and experimentally studied the efficiency and
scalability of the implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7211</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7211</id><created>2013-04-26</created><authors><author><keyname>Welk</keyname><forenames>Martin</forenames></author><author><keyname>Erler</keyname><forenames>Martin</forenames></author></authors><title>Algorithmic Optimisations for Iterative Deconvolution Methods</title><categories>cs.CV</categories><comments>Part of the OAGM/AAPR 2013 proceedings (arXiv:1304.1876)</comments><report-no>OAGM-AAPR/2013/06</report-no><acm-class>I.4.4; F.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate possibilities to speed up iterative algorithms for non-blind
image deconvolution. We focus on algorithms in which convolution with the
point-spread function to be deconvolved is used in each iteration, and aim at
accelerating these convolution operations as they are typically the most
expensive part of the computation. We follow two approaches: First, for some
practically important specific point-spread functions, algorithmically
efficient sliding window or list processing techniques can be used. In some
constellations this allows faster computation than via the Fourier domain.
Second, as iterations progress, computation of convolutions can be restricted
to subsets of pixels. For moderate thinning rates this can be done with almost
no impact on the reconstruction quality. Both approaches are demonstrated in
the context of Richardson-Lucy deconvolution but are not restricted to this
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7217</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7217</id><created>2013-03-27</created><authors><author><keyname>Kupervasser</keyname><forenames>Oleg</forenames></author><author><keyname>Rubinstein</keyname><forenames>Alexander</forenames></author></authors><title>Correction of inertial navigation system's errors by the help of
  video-based navigator based on Digital Terrarium Map</title><categories>cs.SY</categories><comments>32 pages, 18 figures, Positioning Vol.4 No.1, February 2013. arXiv
  admin note: substantial text overlap with arXiv:1107.0399, arXiv:1107.1470,
  arXiv:1106.6341</comments><doi>10.4236/pos.2013.41010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the error analysis of a novel navigation algorithm that
uses as input the sequence of images acquired from a moving camera and a
Digital Terrain (or Elevation) Map (DTM/DEM). More specifically, it has been
shown that the optical flow derived from two consecutive camera frames can be
used in combination with a DTM to estimate the position, orientation and
ego-motion parameters of the moving camera. As opposed to previous works, the
proposed approach does not require an intermediate explicit reconstruction of
the 3D world. In the present work the sensitivity of the algorithm outlined
above is studied. The main sources for errors are identified to be the
optical-flow evaluation and computation, the quality of the information about
the terrain, the structure of the observed terrain and the trajectory of the
camera. By assuming appropriate characterization of these error sources, a
closed form expression for the uncertainty of the pose and motion of the camera
is first developed and then the influence of these factors is confirmed using
extensive numerical simulations. The main conclusion of this paper is to
establish that the proposed navigation algorithm generates accurate estimates
for reasonable scenarios and error sources, and thus can be effectively used as
part of a navigation system of autonomous vehicles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7222</identifier>
 <datestamp>2013-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7222</id><created>2013-04-26</created><updated>2013-05-24</updated><authors><author><keyname>Bradford</keyname><forenames>Russell</forenames></author><author><keyname>Davenport</keyname><forenames>James H.</forenames></author><author><keyname>England</keyname><forenames>Matthew</forenames></author><author><keyname>Wilson</keyname><forenames>David</forenames></author></authors><title>Optimising Problem Formulation for Cylindrical Algebraic Decomposition</title><categories>cs.SC</categories><comments>To appear in: Proceedings of Conferences on Intelligent Computer
  Mathematics (CICM '13) - Calculemus strand</comments><msc-class>68W30, O3C10</msc-class><acm-class>I.1.2</acm-class><journal-ref>Intelligent Computer Mathematics. Berlin: Springer, pp. 19-34.
  (Lecture Notes in Computer Science; 7961), 2013</journal-ref><doi>10.1007/978-3-642-39320-4_2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cylindrical algebraic decomposition (CAD) is an important tool for the study
of real algebraic geometry with many applications both within mathematics and
elsewhere. It is known to have doubly exponential complexity in the number of
variables in the worst case, but the actual computation time can vary greatly.
It is possible to offer different formulations for a given problem leading to
great differences in tractability. In this paper we suggest a new measure for
CAD complexity which takes into account the real geometry of the problem. This
leads to new heuristics for choosing: the variable ordering for a CAD problem,
a designated equational constraint, and formulations for truth-table invariant
CADs (TTICADs). We then consider the possibility of using Groebner bases to
precondition TTICAD and when such formulations constitute the creation of a new
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7223</identifier>
 <datestamp>2013-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7223</id><created>2013-04-26</created><updated>2013-05-24</updated><authors><author><keyname>England</keyname><forenames>Matthew</forenames></author><author><keyname>Bradford</keyname><forenames>Russell</forenames></author><author><keyname>Davenport</keyname><forenames>James H.</forenames></author><author><keyname>Wilson</keyname><forenames>David</forenames></author></authors><title>Understanding Branch Cuts of Expressions</title><categories>cs.MS cs.SC</categories><comments>To appear in: Proceedings of Conferences on Intelligent Computer
  Mathematics (CICM '13) - Mathematical Knowledge Management (MKM) strand</comments><msc-class>68W30, 33F10</msc-class><acm-class>I.1.1; G.4</acm-class><journal-ref>Intelligent Computer Mathematics. Berlin: Springer, pp. 136-151.
  (Lecture Notes in Computer Science; 7961), 2013</journal-ref><doi>10.1007/978-3-642-39320-4_9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We assume some standard choices for the branch cuts of a group of functions
and consider the problem of then calculating the branch cuts of expressions
involving those functions. Typical examples include the addition formulae for
inverse trigonometric functions. Understanding these cuts is essential for
working with the single-valued counterparts, the common approach to encoding
multi-valued functions in computer algebra systems. While the defining choices
are usually simple (typically portions of either the real or imaginary axes)
the cuts induced by the expression may be surprisingly complicated. We have
made explicit and implemented techniques for calculating the cuts in the
computer algebra programme Maple. We discuss the issues raised, classifying the
different cuts produced. The techniques have been gathered in the BranchCuts
package, along with tools for visualising the cuts. The package is included in
Maple 17 as part of the FunctionAdvisor tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7224</identifier>
 <datestamp>2013-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7224</id><created>2013-04-26</created><updated>2013-12-06</updated><authors><author><keyname>Ciccarese</keyname><forenames>Paolo</forenames></author><author><keyname>Soiland-Reyes</keyname><forenames>Stian</forenames></author><author><keyname>Belhajjame</keyname><forenames>Khalid</forenames></author><author><keyname>Gray</keyname><forenames>Alasdair J G</forenames></author><author><keyname>Goble</keyname><forenames>Carole</forenames></author><author><keyname>Clark</keyname><forenames>Tim</forenames></author></authors><title>PAV ontology: Provenance, Authoring and Versioning</title><categories>cs.DL cs.IR</categories><comments>22 pages (incl 5 tables and 19 figures). Submitted to Journal of
  Biomedical Semantics 2013-04-26 (#1858276535979415). Revised article
  submitted 2013-08-30. Second revised article submitted 2013-10-06. Accepted
  2013-10-07. Author proofs sent 2013-10-09 and 2013-10-16. Published
  2013-11-22. Final version 2013-12-06.
  http://www.jbiomedsem.com/content/4/1/37</comments><report-no>University of Manchester eScholar: uk-ac-man-scw:193385</report-no><acm-class>I.2.4; H.2.1; H.3.7; I.7.4</acm-class><journal-ref>Journal of Biomedical Semantics 2013, 4:37</journal-ref><doi>10.1186/2041-1480-4-37</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Provenance is a critical ingredient for establishing trust of published
scientific content. This is true whether we are considering a data set, a
computational workflow, a peer-reviewed publication or a simple scientific
claim with supportive evidence. Existing vocabularies such as DC Terms and the
W3C PROV-O are domain-independent and general-purpose and they allow and
encourage for extensions to cover more specific needs. We identify the specific
need for identifying or distinguishing between the various roles assumed by
agents manipulating digital artifacts, such as author, contributor and curator.
  We present the Provenance, Authoring and Versioning ontology (PAV): a
lightweight ontology for capturing just enough descriptions essential for
tracking the provenance, authoring and versioning of web resources. We argue
that such descriptions are essential for digital scientific content. PAV
distinguishes between contributors, authors and curators of content and
creators of representations in addition to the provenance of originating
resources that have been accessed, transformed and consumed. We explore five
projects (and communities) that have adopted PAV illustrating their usage
through concrete examples. Moreover, we present mappings that show how PAV
extends the PROV-O ontology to support broader interoperability.
  The authors strived to keep PAV lightweight and compact by including only
those terms that have demonstrated to be pragmatically useful in existing
applications, and by recommending terms from existing ontologies when
plausible.
  We analyze and compare PAV with related approaches, namely Provenance
Vocabulary, DC Terms and BIBFRAME. We identify similarities and analyze their
differences with PAV, outlining strengths and weaknesses of our proposed model.
We specify SKOS mappings that align PAV with DC Terms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7226</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7226</id><created>2013-04-26</created><authors><author><keyname>Gubarev</keyname><forenames>F.</forenames></author><author><keyname>Kunin</keyname><forenames>V.</forenames></author><author><keyname>Pospelov</keyname><forenames>A.</forenames></author></authors><title>Lay-up Optimization of Laminated Composites: Mixed Approach with Exact
  Feasibility Bounds on Lamination Parameters</title><categories>cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We suggest modified bi-level approach for finding the best stacking sequence
of laminated composite structures subject to mechanical, blending and
manufacturing constraints. We propose to use both the number of plies laid up
at predefined angles and lamination parameters as independent variables at
outer (global) stage of bi-level scheme aimed to satisfy buckling, strain and
percentage constraints. Our formulation allows precise definition of the
feasible region of lamination parameters and greatly facilitates the solution
of inner level problem of finding the optimal stacking sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7230</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7230</id><created>2013-04-26</created><updated>2013-04-29</updated><authors><author><keyname>Kessler</keyname><forenames>David C.</forenames></author><author><keyname>Taylor</keyname><forenames>Jack</forenames></author><author><keyname>Dunson</keyname><forenames>David B.</forenames></author></authors><title>Learning Densities Conditional on Many Interacting Features</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning a distribution conditional on a set of discrete-valued features is a
commonly encountered task. This becomes more challenging with a
high-dimensional feature set when there is the possibility of interaction
between the features. In addition, many frequently applied techniques consider
only prediction of the mean, but the complete conditional density is needed to
answer more complex questions. We demonstrate a novel nonparametric Bayes
method based upon a tensor factorization of feature-dependent weights for
Gaussian kernels. The method makes use of multistage feature selection for
dimension reduction. The resulting conditional density morphs flexibly with the
selected features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7235</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7235</id><created>2013-04-26</created><authors><author><keyname>Brunsch</keyname><forenames>Tobias</forenames></author><author><keyname>R&#xf6;glin</keyname><forenames>Heiko</forenames></author></authors><title>Finding Short Paths on Polytopes by the Shadow Vertex Algorithm</title><categories>cs.DS math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the shadow vertex algorithm can be used to compute a short path
between a given pair of vertices of a polytope P = {x : Ax \leq b} along the
edges of P, where A \in R^{m \times n} is a real-valued matrix. Both, the
length of the path and the running time of the algorithm, are polynomial in m,
n, and a parameter 1/delta that is a measure for the flatness of the vertices
of P. For integer matrices A \in Z^{m \times n} we show a connection between
delta and the largest absolute value Delta of any sub-determinant of A,
yielding a bound of O(Delta^4 m n^4) for the length of the computed path. This
bound is expressed in the same parameter Delta as the recent non-constructive
bound of O(Delta^2 n^4 \log (n Delta)) by Bonifas et al.
  For the special case of totally unimodular matrices, the length of the
computed path simplifies to O(m n^4), which significantly improves the
previously best known constructive bound of O(m^{16} n^3 \log^3(mn)) by Dyer
and Frieze.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7236</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7236</id><created>2013-04-26</created><authors><author><keyname>Perina</keyname><forenames>Alessandro</forenames></author><author><keyname>Jojic</keyname><forenames>Nebojsa</forenames></author></authors><title>In the sight of my wearable camera: Classifying my visual experience</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce and we analyze a new dataset which resembles the input to
biological vision systems much more than most previously published ones. Our
analysis leaded to several important conclusions. First, it is possible to
disambiguate over dozens of visual scenes (locations) encountered over the
course of several weeks of a human life with accuracy of over 80%, and this
opens up possibility for numerous novel vision applications, from early
detection of dementia to everyday use of wearable camera streams for automatic
reminders, and visual stream exchange. Second, our experimental results
indicate that, generative models such as Latent Dirichlet Allocation or
Counting Grids, are more suitable to such types of data, as they are more
robust to overtraining and comfortable with images at low resolution, blurred
and characterized by relatively random clutter and a mix of objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7238</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7238</id><created>2013-04-26</created><authors><author><keyname>Chaudhuri</keyname><forenames>Arindam</forenames></author><author><keyname>De</keyname><forenames>Kajal</forenames></author><author><keyname>Chatterjee</keyname><forenames>Dipak</forenames></author></authors><title>Solution of the Decision Making Problems using Fuzzy Soft Relations</title><categories>cs.AI</categories><comments>29 Pages Journal Paper, International Journal of Information
  Technology, Volume 15, Number 1, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Fuzzy Modeling has been applied in a wide variety of fields such as
Engineering and Management Sciences and Social Sciences to solve a number
Decision Making Problems which involve impreciseness, uncertainty and vagueness
in data. In particular, applications of this Modeling technique in Decision
Making Problems have remarkable significance. These problems have been tackled
using various theories such as Probability theory, Fuzzy Set Theory, Rough Set
Theory, Vague Set Theory, Approximate Reasoning Theory etc. which lack in
parameterization of the tools due to which they could not be applied
successfully to such problems. The concept of Soft Set has a promising
potential for giving an optimal solution for these problems. With the
motivation of this new concept, in this paper we define the concepts of Soft
Relation and Fuzzy Soft Relation and then apply them to solve a number of
Decision Making Problems. The advantages of Fuzzy Soft Relation compared to
other paradigms are discussed. To the best of our knowledge this is the first
work on the application of Fuzzy Soft Relation to the Decision Making Problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7239</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7239</id><created>2013-04-26</created><authors><author><keyname>Chaudhuri</keyname><forenames>Arindam</forenames></author><author><keyname>De</keyname><forenames>Kajal</forenames></author><author><keyname>Chatterjee</keyname><forenames>Dipak</forenames></author></authors><title>Solution of System of Linear Equations - A Neuro-Fuzzy Approach</title><categories>cs.AI</categories><comments>11 Pages, Journal Article, East West Journal of Mathematics, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neuro-Fuzzy Modeling has been applied in a wide variety of fields such as
Decision Making, Engineering and Management Sciences etc. In particular,
applications of this Modeling technique in Decision Making by involving complex
Systems of Linear Algebraic Equations have remarkable significance. In this
Paper, we present Polak-Ribiere Conjugate Gradient based Neural Network with
Fuzzy rules to solve System of Simultaneous Linear Algebraic Equations. This is
achieved using Fuzzy Backpropagation Learning Rule. The implementation results
show that the proposed Neuro-Fuzzy Network yields effective solutions for
exactly determined, underdetermined and over-determined Systems of Linear
Equations. This fact is demonstrated by the Computational Complexity analysis
of the Neuro-Fuzzy Algorithm. The proposed Algorithm is simulated effectively
using MATLAB software. To the best of our knowledge this is the first work of
the Systems of Linear Algebraic Equations using Neuro-Fuzzy Modeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7244</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7244</id><created>2013-03-28</created><authors><author><keyname>Berghammer</keyname><forenames>Rudolf</forenames></author><author><keyname>Schnoor</keyname><forenames>Henning</forenames></author></authors><title>Relation-algebraic and Tool-supported Control of Condorcet Voting</title><categories>cs.GT cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a relation-algebraic model of Condorcet voting and, based on it,
relation-algebraic solutions of the constructive control problem via the
removal of voters.
  We consider two winning conditions, viz. to be a Condorcet winner and to be
in the (Gilles resp. upward) uncovered set. For the first condition the control
problem is known to be NP-hard; for the second condition the NP-hardness of the
control problem is shown in the paper. All relation-algebraic specifications we
will develop in the paper immediately can be translated into the programming
language of the BDD-based computer system RelView. Our approach is very
flexible and especially appropriate for prototyping and experimentation, and as
such very instructive for educational purposes. It can easily be applied to
other voting rules and control problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7256</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7256</id><created>2013-04-26</created><updated>2013-09-15</updated><authors><author><keyname>Bopardikar</keyname><forenames>Shaunak D.</forenames></author><author><keyname>Englot</keyname><forenames>Brendan J.</forenames></author><author><keyname>Speranzon</keyname><forenames>Alberto</forenames></author></authors><title>Robust Belief Roadmap: Planning Under Intermittent Sensing</title><categories>cs.RO</categories><comments>10 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we extend the recent body of work on planning under
uncertainty to include the fact that sensors may not provide any measurement
owing to misdetection. This is caused either by adverse environmental
conditions that prevent the sensors from making measurements or by the
fundamental limitations of the sensors. Examples include RF-based ranging
devices that intermittently do not receive the signal from beacons because of
obstacles; the misdetection of features by a camera system in detrimental
lighting conditions; a LIDAR sensor that is pointed at a glass-based material
such as a window, etc.
  The main contribution of this paper is twofold. We first show that it is
possible to obtain an analytical bound on the performance of a state estimator
under sensor misdetection occurring stochastically over time in the
environment. We then show how this bound can be used in a sample-based path
planning algorithm to produce a path that trades off accuracy and robustness.
Computational results demonstrate the benefit of the approach and comparisons
are made with the state of the art in path planning under state uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7278</identifier>
 <datestamp>2013-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7278</id><created>2013-04-26</created><updated>2013-08-08</updated><authors><author><keyname>Gibson</keyname><forenames>Travis E.</forenames></author><author><keyname>Annaswamy</keyname><forenames>Anuradha M.</forenames></author><author><keyname>Lavretsky</keyname><forenames>Eugene</forenames></author></authors><title>On Adaptive Control with Closed-loop Reference Models: Transients,
  Oscillations, and Peaking</title><categories>cs.SY math.OC nlin.AO</categories><doi>10.1109/ACCESS.2013.2284005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the main features of adaptive systems is an oscillatory convergence
that exacerbates with the speed of adaptation. Recently it has been shown that
Closed-loop Reference Models (CRMs) can result in improved transient
performance over their open-loop counterparts in model reference adaptive
control. In this paper, we quantify both the transient performance in the
classical adaptive systems and their improvement with CRMs. In addition to
deriving bounds on L-2 norms of the derivatives of the adaptive parameters
which are shown to be smaller, an optimal design of CRMs is proposed which
minimizes an underlying peaking phenomenon. The analytical tools proposed are
shown to be applicable for a range of adaptive control problems including
direct control and composite control with observer feedback. The presence of
CRMs in adaptive backstepping and adaptive robot control are also discussed.
Simulation results are presented throughout the paper to support the
theoretical derivations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7282</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7282</id><created>2013-04-25</created><authors><author><keyname>Saktel</keyname><forenames>Priti</forenames></author><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author></authors><title>An Improved Approach for Word Ambiguity Removal</title><categories>cs.CL</categories><comments>Pages:12 Tables: 07 Figures: 14, International Journal of Human
  Computer Interaction (IJHCI), Volume (3): Issue (3): 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Word ambiguity removal is a task of removing ambiguity from a word, i.e.
correct sense of word is identified from ambiguous sentences. This paper
describes a model that uses Part of Speech tagger and three categories for word
sense disambiguation (WSD). Human Computer Interaction is very needful to
improve interactions between users and computers. For this, the Supervised and
Unsupervised methods are combined. The WSD algorithm is used to find the
efficient and accurate sense of a word based on domain information. The
accuracy of this work is evaluated with the aim of finding best suitable domain
of word.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7284</identifier>
 <datestamp>2013-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7284</id><created>2013-04-26</created><updated>2013-10-16</updated><authors><author><keyname>Zhe</keyname><forenames>Shandian</forenames></author><author><keyname>Xu</keyname><forenames>Zenglin</forenames></author><author><keyname>Qi</keyname><forenames>Yuan</forenames></author></authors><title>Supervised Heterogeneous Multiview Learning for Joint Association Study
  and Disease Diagnosis</title><categories>cs.LG cs.CE stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given genetic variations and various phenotypical traits, such as Magnetic
Resonance Imaging (MRI) features, we consider two important and related tasks
in biomedical research: i)to select genetic and phenotypical markers for
disease diagnosis and ii) to identify associations between genetic and
phenotypical data. These two tasks are tightly coupled because underlying
associations between genetic variations and phenotypical features contain the
biological basis for a disease. While a variety of sparse models have been
applied for disease diagnosis and canonical correlation analysis and its
extensions have bee widely used in association studies (e.g., eQTL analysis),
these two tasks have been treated separately. To unify these two tasks, we
present a new sparse Bayesian approach for joint association study and disease
diagnosis. In this approach, common latent features are extracted from
different data sources based on sparse projection matrices and used to predict
multiple disease severity levels based on Gaussian process ordinal regression;
in return, the disease status is used to guide the discovery of relationships
between the data sources. The sparse projection matrices not only reveal
interactions between data sources but also select groups of biomarkers related
to the disease. To learn the model from data, we develop an efficient
variational expectation maximization algorithm. Simulation results demonstrate
that our approach achieves higher accuracy in both predicting ordinal labels
and discovering associations between data sources than alternative methods. We
apply our approach to an imaging genetics dataset for the study of Alzheimer's
Disease (AD). Our method identifies biologically meaningful relationships
between genetic variations, MRI features, and AD status, and achieves
significantly higher accuracy for predicting ordinal AD stages than the
competing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7285</identifier>
 <datestamp>2013-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7285</id><created>2013-04-25</created><authors><author><keyname>Sassi-Hidri</keyname><forenames>Minyar</forenames></author><author><keyname>Bdira</keyname><forenames>Soukaina Ben</forenames></author></authors><title>Traitement approximatif des requ\^etes flexibles avec groupement
  d'attributs et jointure</title><categories>cs.DB</categories><comments>in French. The 13\`eme Conf\'erence Francophone sur l'Extraction et
  la Gestion des Connaissances (EGC), pp. 29-30, 2013</comments><journal-ref>The 3rd International Conference on Advances in Databases,
  Knowledge, and Data Applications (DBKDA), pp. 128-135, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of approximate processing for flexible
queries in the form SELECT-FROM-WHERE-GROUP BY with join condition. It offers a
flexible framework for online aggregation while promoting response time at the
expense of result accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7289</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7289</id><created>2013-04-26</created><authors><author><keyname>Derczynski</keyname><forenames>Leon</forenames></author><author><keyname>Llorens</keyname><forenames>Hector</forenames></author><author><keyname>UzZaman</keyname><forenames>Naushad</forenames></author></authors><title>TimeML-strict: clarifying temporal annotation</title><categories>cs.CL</categories><acm-class>I.2.7</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  TimeML is an XML-based schema for annotating temporal information over
discourse. The standard has been used to annotate a variety of resources and is
followed by a number of tools, the creation of which constitute hundreds of
thousands of man-hours of research work. However, the current state of
resources is such that many are not valid, or do not produce valid output, or
contain ambiguous or custom additions and removals. Difficulties arising from
these variances were highlighted in the TempEval-3 exercise, which included its
own extra stipulations over conventional TimeML as a response.
  To unify the state of current resources, and to make progress toward easy
adoption of its current incarnation ISO-TimeML, this paper introduces
TimeML-strict: a valid, unambiguous, and easy-to-process subset of TimeML. We
also introduce three resources -- a schema for TimeML-strict; a validator tool
for TimeML-strict, so that one may ensure documents are in the correct form;
and a repair tool that corrects common invalidating errors and adds
disambiguating markup in order to convert documents from the laxer TimeML
standard to TimeML-strict.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7294</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7294</id><created>2013-04-26</created><authors><author><keyname>Shreshtha</keyname><forenames>Rushikesh B.</forenames></author><author><keyname>Goudar</keyname><forenames>Rajeswari</forenames></author></authors><title>Self Configurable Re-link Establishment using Continuous Neighbor
  Discovery in Asynchronous Sensor Networks</title><categories>cs.NI</categories><journal-ref>http://ijcsn.org/IJCSN-2012/1-6/IJCSN-2012-1-6-28.pdf</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Sensor network generally has a large number of sensor nodes that are
deployed at some audited site. In most sensor networks the nodes are static.
Nevertheless, node connectivity is subject to changes because of disruptions in
wireless communication, transmission power changes, or loss of synchronization
between neighbouring nodes, so there is a need to maintain synchronization
between the neighbouring nodes in order to have efficient communication. Hence
even after a sensor is aware of its immediate neighbours, it must continuously
maintain its view a process we call continuous neighbour discovery. In this
proposed work we are maintaining synchronization between neighbouring nodes so
that the sensor network will be always active.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7300</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7300</id><created>2013-04-26</created><authors><author><keyname>Haustein</keyname><forenames>Stefanie</forenames><affiliation>&#xc9;cole de biblioth&#xe9;conomie et des sciences de l'information, Universit&#xe9; de Montr&#xe9;al, Montr&#xe9;al</affiliation></author><author><keyname>Peters</keyname><forenames>Isabella</forenames><affiliation>Department of Information Science, Heinrich-Heine-University</affiliation></author><author><keyname>Bar-Ilan</keyname><forenames>Judit</forenames><affiliation>Department of Information Science, Bar-Ilan University</affiliation></author><author><keyname>Priem</keyname><forenames>Jason</forenames><affiliation>School of Information and Library Science, University of North Carolina at Chapel Hill</affiliation></author><author><keyname>Shema</keyname><forenames>Hadas</forenames><affiliation>Department of Information Science, Bar-Ilan University</affiliation></author><author><keyname>Terliesner</keyname><forenames>Jens</forenames><affiliation>Department of Information Science, Heinrich-Heine-University</affiliation></author></authors><title>Coverage and adoption of altmetrics sources in the bibliometric
  community</title><categories>cs.DL</categories><comments>12 pages, 6 figures. Accepted to 14th International Society of
  Scientometrics and Informatics Conference, Vienna Austria 15-19th July 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Altmetrics, indices based on social media platforms and tools, have recently
emerged as alternative means of measuring scholarly impact. Such indices assume
that scholars in fact populate online social environments, and interact with
scholarly products there. We tested this assumption by examining the use and
coverage of social media environments amongst a sample of bibliometricians. As
expected, coverage varied: 82% of articles published by sampled
bibliometricians were included in Mendeley libraries, while only 28% were
included in CiteULike. Mendeley bookmarking was moderately correlated (.45)
with Scopus citation. Over half of respondents asserted that social media tools
were affecting their professional lives, although uptake of online tools varied
widely. 68% of those surveyed had LinkedIn accounts, while Academia.edu,
Mendeley, and ResearchGate each claimed a fifth of respondents. Nearly half of
those responding had Twitter accounts, which they used both personally and
professionally. Surveyed bibliometricians had mixed opinions on altmetrics'
potential; 72% valued download counts, while a third saw potential in tracking
articles' influence in blogs, Wikipedia, reference managers, and social media.
Altogether, these findings suggest that some online tools are seeing
substantial use by bibliometricians, and that they present a potentially
valuable source of impact data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7308</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7308</id><created>2013-04-26</created><authors><author><keyname>Kolte</keyname><forenames>Ritesh</forenames></author><author><keyname>&#xd6;zg&#xfc;r</keyname><forenames>Ayfer</forenames></author></authors><title>Improved Capacity Approximations for Gaussian Relay Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to ITW 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a Gaussian relay network where a number of sources communicate to a
destination with the help of several layers of relays. Recent work has shown
that a compress-and-forward based strategy at the relays can achieve the
capacity of this network within an additive gap. In this strategy, the relays
quantize their observations at the noise level and map it to a random Gaussian
codebook. The resultant capacity gap is independent of the SNR's of the
channels in the network but linear in the total number of nodes.
  In this paper, we show that if the relays quantize their signals at a
resolution decreasing with the number of nodes in the network, the additive gap
to capacity can be made logarithmic in the number of nodes for a class of
layered, time-varying wireless relay networks. This suggests that the
rule-of-thumb to quantize the received signals at the noise level used for
compress-and-forward in the current literature can be highly suboptimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7318</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7318</id><created>2013-04-26</created><authors><author><keyname>Ene</keyname><forenames>Alina</forenames></author><author><keyname>Har-Peled</keyname><forenames>Sariel</forenames></author><author><keyname>Raichel</keyname><forenames>Benjamin</forenames></author></authors><title>Fast Clustering with Lower Bounds: No Customer too Far, No Shop too
  Small</title><categories>cs.CG</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the \LowerBoundedCenter (\lbc) problem, which is a clustering
problem that can be viewed as a variant of the \kCenter problem. In the \lbc
problem, we are given a set of points P in a metric space and a lower bound
\lambda, and the goal is to select a set C \subseteq P of centers and an
assignment that maps each point in P to a center of C such that each center of
C is assigned at least \lambda points. The price of an assignment is the
maximum distance between a point and the center it is assigned to, and the goal
is to find a set of centers and an assignment of minimum price. We give a
constant factor approximation algorithm for the \lbc problem that runs in O(n
\log n) time when the input points lie in the d-dimensional Euclidean space
R^d, where d is a constant. We also prove that this problem cannot be
approximated within a factor of 1.8-\epsilon unless P = \NP even if the input
points are points in the Euclidean plane R^2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7324</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7324</id><created>2013-04-27</created><authors><author><keyname>Robillard</keyname><forenames>David E.</forenames></author></authors><title>Adaptive Software Radio Steganography</title><categories>cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an adaptable steganography (information hiding) method
for digital radio communication. Many radio steganography methods exist, but
most are defined at higher levels of the protocol stack and are thus protocol
dependent. In contrast, this method is defined at the physical layer, which
makes it widely applicable regardless of the protocols used at higher layers.
This approach is also adaptive; the covertness of the hidden channel is simple
to control via a single continuous parameter either manually or automatically.
Several variations are introduced, each with performance evaluated by
simulation. Results show this to be a feasible method with a reasonable
trade-off between performance and covertness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7344</identifier>
 <datestamp>2014-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7344</id><created>2013-04-27</created><updated>2014-07-15</updated><authors><author><keyname>Chern</keyname><forenames>Bobbie</forenames></author><author><keyname>Farnia</keyname><forenames>Farzan</forenames></author><author><keyname>&#xd6;zg&#xfc;r</keyname><forenames>Ayfer</forenames></author></authors><title>On feedback in Gaussian multi-hop networks</title><categories>cs.IT math.IT</categories><comments>16 pages; Submitted to Transactions on Information Theory in July
  2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study of feedback has been mostly limited to single-hop communication
settings. In this paper, we consider Gaussian networks where sources and
destinations can communicate with the help of intermediate relays over multiple
hops. We assume that links in the network can be bidirected providing
opportunities for feedback. We ask the following question: can the information
transfer in both directions of a link be critical to maximizing the end-to-end
communication rates in the network? Equivalently, could one of the directions
in each bidirected link (and more generally at least one of the links forming a
cycle) be shut down and the capacity of the network still be approximately
maintained? We show that in any arbitrary Gaussian network with bidirected
edges and cycles and unicast traffic, we can always identify a directed acyclic
subnetwork that approximately maintains the capacity of the original network.
For Gaussian networks with multiple-access and broadcast traffic, an acyclic
subnetwork is sufficient to achieve every rate point in the capacity region of
the original network, however, there may not be a single acyclic subnetwork
that maintains the whole capacity region. For networks with multicast and
multiple unicast traffic, on the other hand, bidirected information flow across
certain links can be critically needed to maximize the end-to-end capacity
region. These results can be regarded as generalizations of the conclusions
regarding the usefulness of feedback in various single-hop Gaussian settings
and can provide opportunities for simplifying operation in Gaussian multi-hop
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7345</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7345</id><created>2013-04-27</created><authors><author><keyname>Bajwa</keyname><forenames>Imran Sarwar</forenames></author></authors><title>SOA Embedded in BPM: A High Level View of Object Oriented Paradigm</title><categories>cs.SE</categories><comments>WASET 2011 Spring International Conference, May 2011, pp.209-312,
  Tokyo, Japan</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The trends of design and development of information systems have undergone a
variety of ongoing phases and stages. These variations have been evolved due to
brisk changes in user requirements and business needs. To meet these
requirements and needs, a flexible and agile business solution was required to
come up with the latest business trends and styles. Another obstacle in agility
of information systems was typically different treatment of same diseases of
two patients: business processes and information services. After the emergence
of information technology, the business processes and information systems have
become counterparts. But these two business halves have been treated under
totally different standards. There is need to streamline the boundaries of
these both pillars that are equally sharing information system's burdens and
liabilities. In last decade, the object orientation has evolved into one of the
major solutions for modern business needs and now, SOA is the solution to shift
business on ranks of electronic platform. BPM is another modern business
solution that assists to regularize optimization of business processes. This
paper discusses how object orientation can be conformed to incorporate or embed
SOA in BPM for improved information systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7346</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7346</id><created>2013-04-27</created><authors><author><keyname>Bajwa</keyname><forenames>Imran Sarwar</forenames></author><author><keyname>Bordbar</keyname><forenames>Behzad</forenames></author><author><keyname>Lee</keyname><forenames>Mark</forenames></author></authors><title>SBVR vs OCL: A Comparative Analysis of Standards</title><categories>cs.SE</categories><comments>14th IEEE International Multitopic Conference (INMIC 2011),
  pp.261-266, Karachi, Pakistan</comments><doi>10.1109/INMIC.2011.6151485</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In software modelling, the designers have to produce UML visual models with
software constraints. Similarly, in business modelling, designers have to model
business processes using business constraints (business rules). Constraints are
the key components in the skeleton of business or software models. A designer
has to write constraints to semantically compliment business models or UML
models and finally implementing the constraints into business processes or
source code. Business constraints/rules can be written using SBVR (Semantics of
Business Vocabulary and Rules) while OCL (Object Constraint Language) is the
well-known medium for writing software constraints. SBVR and OCL are two
significant standards from OMG. Both standards are principally different as
SBVR is typically used in business domains and OCL is employed to compliment
software models. However, we have identified a few similarities in both
standards that are interesting to study. In this paper, we have performed a
comparative analysis of both standards as we are looking for a mechanism for
automatic transformation of SBVR to OCL. The major emphasis of the study is to
highlight principal features of SBVR and OCL such as similarities, differences
and key parameters on which these both standards can work together.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7355</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7355</id><created>2013-04-27</created><updated>2013-05-01</updated><authors><author><keyname>Proborszcz</keyname><forenames>Filip</forenames></author></authors><title>Web graph compression with fast access</title><categories>cs.DS cs.IR cs.SI</categories><comments>MSc thesis, May 2012, advisors: Szymon Grabowski, Wojciech Bieniecki;
  65 pages, 16 figures, 6 tables, 5 code snippets, source code available at:
  http://sourceforge.net/projects/webgraphcompres/files/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years studying the content of the World Wide Web became a very
important yet rather difficult task. There is a need for a compression
technique that would allow a web graph representation to be put into the memory
while maintaining random access time competitive to the time needed to access
uncompressed web graph on a hard drive.
  There are already available techniques that accomplish this task, but there
is still room for improvements and this thesis attempts to prove it. It
includes a comparison of two methods contained in state of art of this field
(BV and k2partitioned) to two already implemented algorithms (rewritten,
however, in C++ programming language to maximize speed and resource management
efficiency), which are LM and 2D, and introduces the new variant of the latter
one, called 2D stripes.
  This thesis serves as well as a proof of concept. The final considerations
show positive and negative aspects of all presented methods, expose the
feasibility of the new variant as well as indicate future direction for
development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7359</identifier>
 <datestamp>2014-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7359</id><created>2013-04-27</created><updated>2013-05-23</updated><authors><author><keyname>Ferrer-i-Cancho</keyname><forenames>Ramon</forenames></author><author><keyname>D&#x119;bowski</keyname><forenames>&#x141;ukasz</forenames></author><author><keyname>Mart&#xed;n</keyname><forenames>Ferm&#xed;n Moscoso del Prado</forenames></author></authors><title>Constant conditional entropy and related hypotheses</title><categories>cond-mat.stat-mech cs.CL cs.IT math.IT physics.data-an</categories><comments>introduction improved; typos corrected</comments><journal-ref>Journal of Statistical Mechanics, L07001 (2013)</journal-ref><doi>10.1088/1742-5468/2013/07/L07001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constant entropy rate (conditional entropies must remain constant as the
sequence length increases) and uniform information density (conditional
probabilities must remain constant as the sequence length increases) are two
information theoretic principles that are argued to underlie a wide range of
linguistic phenomena. Here we revise the predictions of these principles to the
light of Hilberg's law on the scaling of conditional entropy in language and
related laws. We show that constant entropy rate (CER) and two interpretations
for uniform information density (UID), full UID and strong UID, are
inconsistent with these laws. Strong UID implies CER but the reverse is not
true. Full UID, a particular case of UID, leads to costly uncorrelated
sequences that are totally unrealistic. We conclude that CER and its particular
cases are incomplete hypotheses about the scaling of conditional entropies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7373</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7373</id><created>2013-04-27</created><authors><author><keyname>Kumar</keyname><forenames>Gunjan</forenames></author><author><keyname>Shannigrahi</keyname><forenames>Saswata</forenames></author></authors><title>NP-Hardness of Speed Scaling with a Sleep State</title><categories>cs.DS</categories><comments>12 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A modern processor can dynamically set it's speed while it's active, and can
make a transition to sleep state when required. When the processor is operating
at a speed $s$, the energy consumed per unit time is given by a convex power
function $P(s)$ having the property that $P(0) &gt; 0$ and $P&quot;(s) &gt; 0$ for all
values of $s$. Moreover, $C &gt; 0$ units of energy is required to make a
transition from the sleep state to the active state. The jobs are specified by
their arrival time, deadline and the processing volume.
  We consider a scheduling problem, called speed scaling with sleep state,
where each job has to be scheduled within their arrival time and deadline, and
the goal is to minimize the total energy consumption required to process these
jobs. Albers et. al. proved the NP-hardness of this problem by reducing an
instance of an NP-hard partition problem to an instance of this scheduling
problem. The instance of this scheduling problem consists of the arrival time,
the deadline and the processing volume for each of the jobs, in addition to $P$
and $C$. Since $P$ and $C$ depend on the instance of the partition problem,
this proof of the NP-hardness of the speed scaling with sleep state problem
doesn't remain valid when $P$ and $C$ are fixed. In this paper, we prove that
the speed scaling with sleep state problem remains NP-hard for any fixed
positive number $C$ and convex $P$ satisfying $P(0) &gt; 0$ and $P&quot;(s) &gt; 0$ for
all values of $s$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7375</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7375</id><created>2013-04-27</created><authors><author><keyname>Yeo</keyname><forenames>Jeongho</forenames></author><author><keyname>Cho</keyname><forenames>Joon Ho</forenames></author></authors><title>Asymptotic FRESH Properizer for Block Processing of Improper-Complex
  Second-Order Cyclostationary Random Processes</title><categories>cs.IT math.IT</categories><comments>42 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the block processing of a discrete-time (DT) improper-complex
second-order cyclostationary (SOCS) random process is considered. In
particular, it is of interest to find a pre-processing operation that enables
computationally efficient near-optimal post-processing. An invertible
linear-conjugate linear (LCL) operator named the DT FREquency Shift (FRESH)
properizer is first proposed. It is shown that the DT FRESH properizer converts
a DT improper-complex SOCS random process input to an equivalent DT
proper-complex SOCS random process output by utilizing the information only
about the cycle period of the input. An invertible LCL block processing
operator named the asymptotic FRESH properizer is then proposed that mimics the
operation of the DT FRESH properizer but processes a finite number of
consecutive samples of a DT improper-complex SOCS random process. It is shown
that the output of the asymptotic FRESH properizer is not proper but
asymptotically proper and that its frequency-domain covariance matrix converges
to a highly-structured block matrix with diagonal blocks as the block size
tends to infinity. Two representative estimation and detection problems are
presented to demonstrate that asymptotically optimal low-complexity
post-processors can be easily designed by exploiting these asymptotic
second-order properties of the output of the asymptotic FRESH properizer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7380</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7380</id><created>2013-04-27</created><authors><author><keyname>Rosenkranz</keyname><forenames>Markus</forenames></author><author><keyname>Phisanbut</keyname><forenames>Nalina</forenames></author></authors><title>A Symbolic Approach to Boundary Problems for Linear Partial Differential
  Equations: Applications to the Completely Reducible Case of the Cauchy
  Problem with Constant Coefficients</title><categories>cs.SC</categories><comments>14 pages</comments><msc-class>68W30, 35-04, 47A05, 47F05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a general algebraic setting for describing linear boundary
problems in a symbolic computation context, with emphasis on the case of
partial differential equations. The general setting is then applied to the
Cauchy problem for completely reducible partial differential equations with
constant coefficients. While we concentrate on the theoretical features in this
paper, the underlying operator ring is implemented and provides a sufficient
basis for all methods presented here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7386</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7386</id><created>2013-04-27</created><authors><author><keyname>Tams</keyname><forenames>Benjamin</forenames></author></authors><title>Attacks and Countermeasures in Fingerprint Based Biometric Cryptosystems</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate implementations of biometric cryptosystems protecting
fingerprint templates (which are mostly based on the fuzzy vault scheme by
Juels and Sudan in 2002) with respect to the security they provide. We show
that attacks taking advantage of the system's false acceptance rate, i.e.
false-accept attacks, pose a very serious risk --- even if brute-force attacks
are impractical to perform. Our observations lead to the clear conclusion that
currently a single fingerprint is not sufficient to provide a secure biometric
cryptosystem. But there remain other problems that can not be resolved by
merely switching to multi-finger: Kholmatov and Yanikoglu in 2007 demonstrated
that it is possible to break two matching vault records at quite a high rate
via the correlation attack.
  We propose an implementation of a minutiae fuzzy vault that is inherently
resistant against cross-matching and the correlation attack. Surprisingly,
achieving cross-matching resistance is not at the cost of authentication
performance. In particular, we propose to use a randomized decoding procedure
and find that it is possible to achieve a GAR=91% at which no false accepts are
observed on a database generally used. Our ideas can be adopted into an
implementation of a multibiometric cryptosystem. All experiments described in
this paper can fully be reproduced using software available for download.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7392</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7392</id><created>2013-04-27</created><authors><author><keyname>Zhang</keyname><forenames>Jie</forenames></author><author><keyname>Yang</keyname><forenames>En-hui</forenames></author><author><keyname>Kieffer</keyname><forenames>John C.</forenames></author></authors><title>A Universal Grammar-Based Code For Lossless Compression of Binary Trees</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of lossless compression of binary trees, with the aim
of reducing the number of code bits needed to store or transmit such trees. A
lossless grammar-based code is presented which encodes each binary tree into a
binary codeword in two steps. In the first step, the tree is transformed into a
context-free grammar from which the tree can be reconstructed. In the second
step, the context-free grammar is encoded into a binary codeword. The decoder
of the grammar-based code decodes the original tree from its codeword by
reversing the two encoding steps. It is shown that the resulting grammar-based
binary tree compression code is a universal code on a family of probabilistic
binary tree source models satisfying certain weak restrictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7394</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7394</id><created>2013-04-27</created><updated>2013-09-27</updated><authors><author><keyname>Ouaknine</keyname><forenames>Joel</forenames><affiliation>Department of Computer Science, Oxford University, UK</affiliation></author><author><keyname>Palikareva</keyname><forenames>Hristina</forenames><affiliation>Department of Computing, Imperial College London, UK</affiliation></author><author><keyname>Roscoe</keyname><forenames>A. W.</forenames><affiliation>Department of Computer Science, Oxford University, UK</affiliation></author><author><keyname>Worrell</keyname><forenames>James</forenames><affiliation>Department of Computer Science, Oxford University, UK</affiliation></author></authors><title>A Static Analysis Framework for Livelock Freedom in CSP</title><categories>cs.LO</categories><comments>53 pages, 20 figures</comments><proxy>Logical Methods In Computer Science</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 3 (September
  23, 2013) lmcs:884</journal-ref><doi>10.2168/LMCS-9(3:24)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a process algebra with hiding and recursion it is possible to create
processes which compute internally without ever communicating with their
environment. Such processes are said to diverge or livelock. In this paper we
show how it is possible to conservatively classify processes as livelock-free
through a static analysis of their syntax. In particular, we present a
collection of rules, based on the inductive structure of terms, which guarantee
livelock-freedom of the denoted process. This gives rise to an algorithm which
conservatively flags processes that can potentially livelock. We illustrate our
approach by applying both BDD-based and SAT-based implementations of our
algorithm to a range of benchmarks, and show that our technique in general
substantially outperforms the model checker FDR whilst exhibiting a low rate of
inconclusive results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7397</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7397</id><created>2013-04-27</created><authors><author><keyname>Huang</keyname><forenames>Fenix W. D.</forenames></author><author><keyname>Nebel</keyname><forenames>Markus E.</forenames></author><author><keyname>Reidys</keyname><forenames>Christian M.</forenames></author></authors><title>Uniform generation of RNA pseudoknot structures with genus filtration</title><categories>cs.CE math.CO q-bio.BM</categories><comments>11 figures, 25 pages</comments><msc-class>05C85</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a sampling framework for RNA structures of fixed
topological genus. We introduce a novel, linear time, uniform sampling
algorithm for RNA structures of fixed topological genus $g$, for arbitrary
$g&gt;0$. Furthermore we develop a linear time sampling algorithm for RNA
structures of fixed topological genus $g$ that are weighted by a simplified,
loop-based energy functional. For this process the partition function of the
energy functional has to be computed once, which has $O(n^2)$ time complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7399</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7399</id><created>2013-04-27</created><authors><author><keyname>Glover</keyname><forenames>Jared</forenames></author><author><keyname>Popovic</keyname><forenames>Sanja</forenames></author></authors><title>Bingham Procrustean Alignment for Object Detection in Clutter</title><categories>cs.CV cs.RO stat.AP</categories><comments>Submitted to IROS 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new system for object detection in cluttered RGB-D images is presented. Our
main contribution is a new method called Bingham Procrustean Alignment (BPA) to
align models with the scene. BPA uses point correspondences between oriented
features to derive a probability distribution over possible model poses. The
orientation component of this distribution, conditioned on the position, is
shown to be a Bingham distribution. This result also applies to the classic
problem of least-squares alignment of point sets, when point features are
orientation-less, and gives a principled, probabilistic way to measure pose
uncertainty in the rigid alignment problem. Our detection system leverages BPA
to achieve more reliable object detections in clutter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7401</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7401</id><created>2013-04-27</created><authors><author><keyname>Zhang</keyname><forenames>Weituo</forenames></author><author><keyname>Lim</keyname><forenames>Chjan</forenames></author><author><keyname>Szymanski</keyname><forenames>Boleslaw K.</forenames></author></authors><title>Analytic Treatment of Tipping Points for Social Consensus in Large
  Random Networks</title><categories>cs.SI physics.soc-ph</categories><comments>7 pages, 5 figures</comments><journal-ref>Physical Review E, 86(6) 061134 (2012)</journal-ref><doi>10.1103/PhysRevE.86.061134</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a homogeneous pair approximation to the Naming Game (NG) model
by deriving a six-dimensional ODE for the two-word Naming Game. Our ODE reveals
the change in dynamical behavior of the Naming Game as a function of the
average degree &lt; k &gt; of an uncorrelated network. This result is in good
agreement with the numerical results. We also analyze the extended NG model
that allows for presence of committed nodes and show that there is a shift of
the tipping point for social consensus in sparse networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7402</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7402</id><created>2013-04-27</created><authors><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Fu</keyname><forenames>Fang-Wei</forenames></author><author><keyname>Wan</keyname><forenames>Daqing</forenames></author></authors><title>Stopping Sets of Algebraic Geometry Codes</title><categories>cs.IT math.IT</categories><comments>17 pages</comments><msc-class>11T71</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stopping sets and stopping set distribution of a linear code play an
important role in the performance analysis of iterative decoding for this
linear code. Let $C$ be an $[n,k]$ linear code over $\f$ with parity-check
matrix $H$, where the rows of $H$ may be dependent. Let $[n]=\{1,2,...,n\}$
denote the set of column indices of $H$. A \emph{stopping set} $S$ of $C$ with
parity-check matrix $H$ is a subset of $[n]$ such that the restriction of $H$
to $S$ does not contain a row of weight 1. The \emph{stopping set distribution}
$\{T_{i}(H)\}_{i=0}^{n}$ enumerates the number of stopping sets with size $i$
of $C$ with parity-check matrix $H$. Denote $H^{*}$ the parity-check matrix
consisting of all the non-zero codewords in the dual code $C^{\bot}$. In this
paper, we study stopping sets and stopping set distributions of some residue
algebraic geometry (AG) codes with parity-check matrix $H^*$. First, we give
two descriptions of stopping sets of residue AG codes. For the simplest AG
codes, i.e., the generalized Reed-Solomon codes, it is easy to determine all
the stopping sets. Then we consider AG codes from elliptic curves. We use the
group structure of rational points of elliptic curves to present a complete
characterization of stopping sets. Then the stopping sets, the stopping set
distribution and the stopping distance of the AG code from an elliptic curve
are reduced to the search, counting and decision versions of the subset sum
problem in the group of rational points of the elliptic curve, respectively.
Finally, for some special cases, we determine the stopping set distributions of
AG codes from elliptic curves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7403</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7403</id><created>2013-04-27</created><authors><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author></authors><title>Improved Approximation Algorithms for the Min-Max Selecting Items
  Problem</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a simple deterministic $O(\log K / \log\log K)$ approximation
algorithm for the Min-Max Selecting Items problem, where $K$ is the number of
scenarios. While our main goal is simplicity, this result also improves over
the previous best approximation ratio of $O(\log K)$ due to Kasperski, Kurpisz,
and Zieli\'nski (Information Processing Letters (2013)). Despite using the
method of pessimistic estimators, the algorithm has a polynomial runtime also
in the RAM model of computation. We also show that the LP formulation for this
problem by Kasperski and Zieli\'nski (Annals of Operations Research (2009)),
which is the basis for the previous work and ours, has an integrality gap of at
least $\Omega(\log K / \log\log K)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7413</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7413</id><created>2013-04-27</created><updated>2013-04-30</updated><authors><author><keyname>Aksoy</keyname><forenames>Sinan</forenames></author><author><keyname>Azzam</keyname><forenames>Alexander Adam</forenames></author><author><keyname>Coppersmith</keyname><forenames>Chaya</forenames></author><author><keyname>Glass</keyname><forenames>Julie</forenames></author><author><keyname>Karaali</keyname><forenames>Gizem</forenames></author><author><keyname>Zhao</keyname><forenames>Xueying</forenames></author><author><keyname>Zhu</keyname><forenames>Xinjing</forenames></author></authors><title>School Choice as a One-Sided Matching Problem: Cardinal Utilities and
  Optimization</title><categories>math.OC cs.GT</categories><comments>This work evolved from an earlier version of arXiv:1010.2312 (v1) and
  has textual overlaps with that version in the introduction / background. We
  cite the final version of that paper (v2, published as part of the ISAIM 2012
  Proceedings) and use some of its results here. Different titles and separate
  submissions indicate the substantially different theoretical emphases of the
  two papers. (4/30/13)</comments><msc-class>90B80, 90C27, 91B14, 91B68</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The school choice problem concerns the design and implementation of matching
mechanisms that produce school assignments for students within a given public
school district. Previously considered criteria for evaluating proposed
mechanisms such as stability, strategyproofness and Pareto efficiency do not
always translate into desirable student assignments. In this note, we explore a
class of one-sided, cardinal utility maximizing matching mechanisms focused
exclusively on student preferences. We adapt a well-known combinatorial
optimization technique (the Hungarian algorithm) as the kernel of this class of
matching mechanisms. We find that, while such mechanisms can be adapted to meet
desirable criteria not met by any previously employed mechanism in the school
choice literature, they are not strategyproof. We discuss the practical
implications and limitations of our approach at the end of the article.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7423</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7423</id><created>2013-04-27</created><authors><author><keyname>Chowdhury</keyname><forenames>Nafisa Afrin</forenames></author><author><keyname>Khatun</keyname><forenames>Murshida</forenames></author><author><keyname>Hashem</keyname><forenames>M. M. A.</forenames></author></authors><title>On Integrating Fuzzy Knowledge Using a Novel Evolutionary Algorithm</title><categories>cs.NE cs.AI</categories><journal-ref>Procs. of the IEEE 10th International Conference on Computer &amp;
  Information Technology (ICCIT 2007), pp. 38-43, Dhaka, Bangladesh, December
  27-29, (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fuzzy systems may be considered as knowledge-based systems that incorporates
human knowledge into their knowledge base through fuzzy rules and fuzzy
membership functions. The intent of this study is to present a fuzzy knowledge
integration framework using a Novel Evolutionary Strategy (NES), which can
simultaneously integrate multiple fuzzy rule sets and their membership function
sets. The proposed approach consists of two phases: fuzzy knowledge encoding
and fuzzy knowledge integration. Four application domains, the hepatitis
diagnosis, the sugarcane breeding prediction, Iris plants classification, and
Tic-tac-toe endgame were used to show the performance ofthe proposed knowledge
approach. Results show that the fuzzy knowledge base derived using our approach
performs better than Genetic Algorithm based approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7429</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7429</id><created>2013-04-28</created><authors><author><keyname>Golrezaei</keyname><forenames>Negin</forenames></author><author><keyname>Mansourifard</keyname><forenames>Parisa</forenames></author><author><keyname>Molisch</keyname><forenames>Andreas F.</forenames></author><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author></authors><title>Base-Station Assisted Device-to-Device Communications for
  High-Throughput Wireless Video Networks</title><categories>cs.NI</categories><comments>28 pages, 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new scheme for increasing the throughput of video files in
cellular communications systems. This scheme exploits (i) the redundancy of
user requests as well as (ii) the considerable storage capacity of smartphones
and tablets. Users cache popular video files and - after receiving requests
from other users - serve these requests via device-to-device localized
transmissions. The file placement is optimal when a central control knows a
priori the locations of wireless devices when file requests occur. However,
even a purely random caching scheme shows only a minor performance loss
compared to such a genie-aided scheme. We then analyze the optimal
collaboration distance, trading off frequency reuse with the probability of
finding a requested file within the collaboration distance. We show that an
improvement of spectral efficiency of one to two orders of magnitude is
possible, even if there is not very high redundancy in video requests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7432</identifier>
 <datestamp>2013-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7432</id><created>2013-04-28</created><updated>2013-07-31</updated><authors><author><keyname>Chen</keyname><forenames>Wei</forenames></author><author><keyname>Wang</keyname><forenames>Yajun</forenames></author><author><keyname>Yu</keyname><forenames>Dongxiao</forenames></author><author><keyname>Zhang</keyname><forenames>Li</forenames></author></authors><title>Sybil-proof Mechanisms in Query Incentive Networks</title><categories>cs.GT cs.SI</categories><comments>ACM EC 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study incentive mechanisms for retrieving information from
networked agents. Following the model in [Kleinberg and Raghavan 2005], the
agents are represented as nodes in an infinite tree, which is generated by a
random branching process. A query is issued by the root, and each node
possesses an answer with an independent probability $p=1/n$. Further, each node
in the tree acts strategically to maximize its own payoff. In order to
encourage the agents to participate in the information acquisition process, an
incentive mechanism is needed to reward agents who provide the information as
well as agents who help to facilitate such acquisition.
  We focus on designing efficient sybil-proof incentive mechanisms, i.e., which
are robust to fake identity attacks. %We consider incentive mechanisms which
are sybil-proof, i.e., robust to fake identity attacks. We propose a family of
mechanisms, called the direct referral (DR) mechanisms, which allocate most
reward to the information holder as well as its direct parent (or direct
referral). We show that, when designed properly, the direct referral mechanism
is sybil-proof and efficient. In particular, we show that we may achieve an
expected cost of $O(h^2)$ for propagating the query down $h$ levels for any
branching factor $b&gt;1$. This result exponentially improves on previous work
when requiring to find an answer with high probability. When the underlying
network is a deterministic chain, our mechanism is optimal under some mild
assumptions. In addition, due to its simple reward structure, the DR mechanism
might have good chance to be adopted in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7434</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7434</id><created>2013-04-28</created><authors><author><keyname>Jose</keyname><forenames>Renu</forenames></author><author><keyname>Ambat</keyname><forenames>Sooraj K.</forenames></author><author><keyname>Hari</keyname><forenames>K. V. S.</forenames></author></authors><title>Low Complexity Joint Estimation of Synchronization Impairments in Sparse
  Channel for MIMO-OFDM System</title><categories>cs.IT math.IT</categories><comments>7 pages, 4 figures, under review in AEU - International Journal of
  Electronics and Communications (Elsevier) (paper id-AEUE-D-12-00625)</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Low complexity joint estimation of synchronization impairments and channel in
a single-user MIMO-OFDM system is presented in this letter. Based on a system
model that takes into account the effects of synchronization impairments such
as carrier frequency offset, sampling frequency offset, and symbol timing
error, and channel, a Maximum Likelihood (ML) algorithm for the joint
estimation is proposed. To reduce the complexity of ML grid search, the number
of received signal samples used for estimation need to be reduced. The
conventional channel estimation methods using Least-Squares (LS) fail for the
reduced sample under-determined system, which results in poor performance of
the joint estimator. The proposed ML algorithm uses Compressed Sensing (CS)
based channel estimation method in a sparse fading scenario, where the received
samples used for estimation are less than that required for an LS based
estimation. The performance of the estimation method is studied through
numerical simulations, and it is observed that CS based joint estimator
performs better than LS based joint estimator
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7435</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7435</id><created>2013-04-28</created><authors><author><keyname>Paris</keyname><forenames>J. F.</forenames></author></authors><title>Statistical characterization of kappa-mu shadowed fading</title><categories>cs.IT math.IT stat.AP</categories><comments>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates a natural generalization of the kappa-mu fading
channel in which the line-of-sight (LOS) component is subject to shadowing.
This fading distribution has a clear physical interpretation, good analytical
properties and unifies the one-side Gaussian, Rayleigh, Nakagami-m, Ricean,
kappa-mu and Ricean shadowed fading distributions. The three basic statistical
characterizations, i.e. probability density function (PDF), cumulative
distribution function (CDF) and moment generating function (MGF), of the
kappa-mu shadowed distribution are obtained in closed-form. Then, it is also
shown that the sum and maximum distributions of independent but arbitrarily
distributed kappa-mu shadowed variates can be expressed in closed-form. This
set of new statistical results is finally applied to the performance analysis
of several wireless communication systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7451</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7451</id><created>2013-04-28</created><authors><author><keyname>Bhavani</keyname><forenames>A B</forenames></author></authors><title>Cross-site Scripting Attacks on Android WebView</title><categories>cs.CR</categories><journal-ref>Bhavani A B, Cross-site Scripting Attacks on Android WebView,IJCSN
  International Journal of Computer Science and Network, Vol 2, Issue 2, April
  2013, ISSN:2277-5420</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  WebView is an essential component in Android and iOS. It enables applications
to display content from on-line resources. It simplifies task of performing a
network request, parsing the data and rendering it. WebView uses a number of
APIs which can interact with the web contents inside WebView. In the current
paper, Cross-site scripting attacks or XSS attacks specific to Android WebView
are discussed. Cross site scripting (XSS) is a type of vulnerability commonly
found in web applications. This vulnerability makes it possible for attackers
to run malicious code into victim's WebView,through HttpClient APIs. Using this
malicious code, the attackers can steal the victim's credentials, such as
cookies. The access control policies (that is,the same origin policy) employed
by the browser to protect those credentials can be bypassed by exploiting the
XSS vulnerability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7456</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7456</id><created>2013-04-28</created><authors><author><keyname>Sun</keyname><forenames>He</forenames></author></authors><title>Counting Hypergraphs in Data Streams</title><categories>cs.DS math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the first streaming algorithm for counting an arbitrary hypergraph
$H$ of constant size in a massive hypergraph $G$. Our algorithm can handle both
edge-insertions and edge-deletions, and is applicable for the distributed
setting. Moreover, our approach provides the first family of graph polynomials
for the hypergraph counting problem. Because of the close relationship between
hypergraphs and set systems, our approach may have applications in studying
similar problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7457</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7457</id><created>2013-04-28</created><authors><author><keyname>Ahmed</keyname><forenames>Mohammed F. A.</forenames></author><author><keyname>Al-Naffouri</keyname><forenames>Tareq Y.</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>On the Effect of Correlated Measurements on the Performance of
  Distributed Estimation</title><categories>cs.IT math.IT</categories><comments>5 pages</comments><doi>10.1109/TSP.2013.2283841</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the distributed estimation of an unknown scalar parameter in
Wireless Sensor Networks (WSNs). Sensor nodes transmit their noisy observations
over multiple access channel to a Fusion Center (FC) that reconstructs the
source parameter. The received signal is corrupted by noise and channel fading,
so that the FC objective is to minimize the Mean-Square Error (MSE) of the
estimate. In this paper, we assume sensor node observations to be correlated
with the source signal and correlated with each other as well. The correlation
coefficient between two observations is exponentially decaying with the
distance separation. The effect of the distance-based correlation on the
estimation quality is demonstrated and compared with the case of unity
correlated observations. Moreover, a closed-form expression for the outage
probability is derived and its dependency on the correlation coefficients is
investigated. Numerical simulations are provided to verify our analytic
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7461</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7461</id><created>2013-04-28</created><authors><author><keyname>Krivulin</keyname><forenames>Nikolai</forenames></author></authors><title>A maximization problem in tropical mathematics: a complete solution and
  application examples</title><categories>math.OC cs.SY</categories><comments>19 pages</comments><msc-class>65K10 (Primary) 15A80, 90C48, 90B35 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A multidimensional optimization problem is formulated in the tropical
mathematics setting as to maximize a nonlinear objective function, which is
defined through a multiplicative conjugate transposition operator on vectors in
a finite-dimensional semimodule over a general idempotent semifield. The study
is motivated by problems drawn from project scheduling, where the deviation
between initiation or completion times of activities in a project is to be
maximized subject to various precedence constraints among the activities. To
solve the unconstrained problem, we first establish an upper bound for the
objective function, and then solve a system of vector equations to find all
vectors that yield the bound. As a corollary, an extension of the solution to
handle constrained problems is discussed. The results obtained are applied to
give complete direct solutions to the motivating problems from project
scheduling. Numerical examples of the development of optimal schedules are also
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7465</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7465</id><created>2013-04-28</created><authors><author><keyname>Celebi</keyname><forenames>M. Emre</forenames></author><author><keyname>Kingravi</keyname><forenames>Hassan A.</forenames></author></authors><title>Deterministic Initialization of the K-Means Algorithm Using Hierarchical
  Clustering</title><categories>cs.LG cs.CV</categories><comments>23 pages, 3 figures, 10 tables. arXiv admin note: substantial text
  overlap with arXiv:1209.1960</comments><acm-class>I.5.3; H.2.8</acm-class><journal-ref>International Journal of Pattern Recognition and Artificial
  Intelligence 26 (2012) 1250018</journal-ref><doi>10.1142/S0218001412500188</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  K-means is undoubtedly the most widely used partitional clustering algorithm.
Unfortunately, due to its gradient descent nature, this algorithm is highly
sensitive to the initial placement of the cluster centers. Numerous
initialization methods have been proposed to address this problem. Many of
these methods, however, have superlinear complexity in the number of data
points, making them impractical for large data sets. On the other hand, linear
methods are often random and/or order-sensitive, which renders their results
unrepeatable. Recently, Su and Dy proposed two highly successful hierarchical
initialization methods named Var-Part and PCA-Part that are not only linear,
but also deterministic (non-random) and order-invariant. In this paper, we
propose a discriminant analysis based approach that addresses a common
deficiency of these two methods. Experiments on a large and diverse collection
of data sets from the UCI Machine Learning Repository demonstrate that Var-Part
and PCA-Part are highly competitive with one of the best random initialization
methods to date, i.e., k-means++, and that the proposed approach significantly
improves the performance of both hierarchical methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7468</identifier>
 <datestamp>2015-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7468</id><created>2013-04-28</created><updated>2015-10-27</updated><authors><author><keyname>Kempe</keyname><forenames>David</forenames></author><author><keyname>Kleinberg</keyname><forenames>Jon</forenames></author><author><keyname>Oren</keyname><forenames>Sigal</forenames></author><author><keyname>Slivkins</keyname><forenames>Aleksandrs</forenames></author></authors><title>Selection and Influence in Cultural Dynamics</title><categories>cs.GT cs.SI physics.soc-ph</categories><comments>A one-page abstract of this work has appeared in ACM EC 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the fundamental principles driving diversity or homogeneity in domains
such as cultural differentiation, political affiliation, and product adoption
is the tension between two forces: influence (the tendency of people to become
similar to others they interact with) and selection (the tendency to be
affected most by the behavior of others who are already similar). Influence
tends to promote homogeneity within a society, while selection frequently
causes fragmentation. When both forces act simultaneously, it becomes an
interesting question to analyze which societal outcomes should be expected.
  To study this issue more formally, we analyze a natural stylized model built
upon active lines of work in political opinion formation, cultural diversity,
and language evolution. We assume that the population is partitioned into
&quot;types&quot; according to some traits (such as language spoken or political
affiliation). While all types of people interact with one another, only people
with sufficiently similar types can possibly influence one another. The
&quot;similarity&quot; is captured by a graph on types in which individuals of the same
or adjacent types can influence one another. We achieve an essentially complete
characterization of (stable) equilibrium outcomes and prove convergence from
all starting states. We also consider generalizations of this model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7479</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7479</id><created>2013-04-28</created><updated>2015-05-25</updated><authors><author><keyname>Shankar</keyname><forenames>Varun</forenames></author><author><keyname>Wright</keyname><forenames>Grady B.</forenames></author><author><keyname>Kirby</keyname><forenames>Robert M.</forenames></author><author><keyname>Fogelson</keyname><forenames>Aaron L.</forenames></author></authors><title>Augmenting the Immersed Boundary Method with Radial Basis Functions
  (RBFs) for the Modeling of Platelets in Hemodynamic Flows</title><categories>math.NA cs.NA</categories><comments>25 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new computational method by extending the Immersed Boundary (IB)
method with a spectrally-accurate geometric model based on Radial Basis
Function (RBF) interpolation of the Lagrangian structures. Our specific
motivation is the modeling of platelets in hemodynamic flows, though we
anticipate that our method will be useful in other applications as well. The
efficacy of our new RBF-IB method is shown through a series of numerical
experiments. Specifically, we compare our method with the traditional IB method
in terms of convergence and accuracy, computational cost, maximum stable
time-step size and volume loss. We conclude that the RBF-IB method has
advantages over the traditional Immersed Boundary method, and is well-suited
for modeling of platelets in hemodynamic flows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7480</identifier>
 <datestamp>2014-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7480</id><created>2013-04-28</created><updated>2014-01-06</updated><authors><author><keyname>Kampeas</keyname><forenames>Joseph</forenames></author><author><keyname>Cohen</keyname><forenames>Asaf</forenames></author><author><keyname>Gurewitz</keyname><forenames>Omer</forenames></author></authors><title>The Capacity of the Multiple Access Channel Under Distributed Scheduling
  - Order Optimality of Linear Receivers</title><categories>cs.IT math.IT</categories><comments>41 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the problem of a Multiple-Input Multiple-Output (MIMO)
Multiple-Access Channel (MAC) at the limit of large number of users. Clearly,
in practical scenarios, only a small subset of the users can be scheduled to
utilize the channel simultaneously. Thus, a problem of user selection arises.
However, since solutions which collect Channel State Information (CSI) from all
users and decide on the best subset to transmit in each slot do not scale when
the number of users is large, distributed algorithms for user selection are
advantageous.
  In this paper, we suggest a distributed user selection algorithm, which
selects a group of users to transmit without coordinating between all users and
without all users sending CSI to the base station. This threshold-based
algorithm is analyzed for both Zero-Forcing (ZF) and Minimal Mean Square Error
(MMSE) receivers, and its expected capacity in the limit of large number of
users is investigated. It is shown that for large number of users it achieves
the same scaling laws as the optimal centralized scheme. Multi-stage
distributed schemes are also considered and shown to be advantageous in
practical scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7487</identifier>
 <datestamp>2013-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7487</id><created>2013-04-28</created><updated>2013-07-25</updated><authors><author><keyname>Bazarsky</keyname><forenames>Alex</forenames></author><author><keyname>Presman</keyname><forenames>Noam</forenames></author><author><keyname>Litsyn</keyname><forenames>Simon</forenames></author></authors><title>Design of Non-Binary Quasi-Cyclic LDPC Codes by ACE Optimization</title><categories>cs.IT math.IT</categories><comments>Accepted to 2013 IEEE Information Theory Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algorithm for constructing Tanner graphs of non-binary irregular
quasi-cyclic LDPC codes is introduced. It employs a new method for selection of
edge labels allowing control over the code's non-binary ACE spectrum and
resulting in low error-floor. The efficiency of the algorithm is demonstrated
by generating good codes of short to moderate length over small fields,
outperforming codes generated by the known methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7505</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7505</id><created>2013-04-28</created><authors><author><keyname>Ramanujan</keyname><forenames>M. S.</forenames></author><author><keyname>Saurabh</keyname><forenames>Saket</forenames></author></authors><title>Linear Time Parameterized Algorithms via Skew-Symmetric Multicuts</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A skew-symmetric graph $(D=(V,A),\sigma)$ is a directed graph $D$ with an
involution $\sigma$ on the set of vertices and arcs. In this paper, we
introduce a separation problem, $d$-Skew-Symmetric Multicut, where we are given
a skew-symmetric graph $D$, a family of $\cal T$ of $d$-sized subsets of
vertices and an integer $k$. The objective is to decide if there is a set
$X\subseteq A$ of $k$ arcs such that every set $J$ in the family has a vertex
$v$ such that $v$ and $\sigma(v)$ are in different connected components of
$D'=(V,A\setminus (X\cup \sigma(X))$. In this paper, we give an algorithm for
this problem which runs in time $O((4d)^{k}(m+n+\ell))$, where $m$ is the
number of arcs in the graph, $n$ the number of vertices and $\ell$ the length
of the family given in the input.
  Using our algorithm, we show that Almost 2-SAT has an algorithm with running
time $O(4^kk^4\ell)$ and we obtain algorithms for {\sc Odd Cycle Transversal}
and {\sc Edge Bipartization} which run in time $O(4^kk^4(m+n))$ and
$O(4^kk^5(m+n))$ respectively. This resolves an open problem posed by Reed,
Smith and Vetta [Operations Research Letters, 2003] and improves upon the
earlier almost linear time algorithm of Kawarabayashi and Reed [SODA, 2010].
  We also show that Deletion q-Horn Backdoor Set Detection is a special case of
3-Skew-Symmetric Multicut, giving us an algorithm for Deletion q-Horn Backdoor
Set Detection which runs in time $O(12^kk^5\ell)$. This gives the first
fixed-parameter tractable algorithm for this problem answering a question posed
in a paper by a superset of the authors [STACS, 2013]. Using this result, we
get an algorithm for Satisfiability which runs in time $O(12^kk^5\ell)$ where
$k$ is the size of the smallest q-Horn deletion backdoor set, with $\ell$ being
the length of the input formula.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7507</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7507</id><created>2013-04-28</created><authors><author><keyname>Bann</keyname><forenames>Eugene Yuta</forenames></author><author><keyname>Bryson</keyname><forenames>Joanna J.</forenames></author></authors><title>Measuring Cultural Relativity of Emotional Valence and Arousal using
  Semantic Clustering and Twitter</title><categories>cs.CL cs.AI</categories><comments>To be presented at the 35th Annual Meeting of the Cognitive Science
  Society (CogSci 2013), Berlin, Germany, Wednesday, July 31 - Saturday, August
  3, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Researchers since at least Darwin have debated whether and to what extent
emotions are universal or culture-dependent. However, previous studies have
primarily focused on facial expressions and on a limited set of emotions. Given
that emotions have a substantial impact on human lives, evidence for cultural
emotional relativity might be derived by applying distributional semantics
techniques to a text corpus of self-reported behaviour. Here, we explore this
idea by measuring the valence and arousal of the twelve most popular emotion
keywords expressed on the micro-blogging site Twitter. We do this in three
geographical regions: Europe, Asia and North America. We demonstrate that in
our sample, the valence and arousal levels of the same emotion keywords differ
significantly with respect to these geographical regions --- Europeans are, or
at least present themselves as more positive and aroused, North Americans are
more negative and Asians appear to be more positive but less aroused when
compared to global valence and arousal levels of the same emotion keywords. Our
work is the first in kind to programatically map large text corpora to a
dimensional model of affect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7509</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7509</id><created>2013-04-28</created><updated>2014-08-17</updated><authors><author><keyname>Zhou</keyname><forenames>Yuhan</forenames></author><author><keyname>Yu</keyname><forenames>Wei</forenames></author></authors><title>Optimized Backhaul Compression for Uplink Cloud Radio Access Network</title><categories>cs.IT math.IT</categories><comments>13 pages, 8 figures; published in IEEE Journal on Selected Areas in
  Communications, Special Issue on 5G Communication Systems, June 2014</comments><journal-ref>IEEE Journal on Selected Areas in Communications, vol.32, no.6,
  pp.1295--1307, June 2014</journal-ref><doi>10.1109/JSAC.2014.2328133</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the uplink of a cloud radio access network (C-RAN) where
the cell sites are connected to a cloud-computing-based central processor (CP)
with noiseless backhaul links with finite capacities. We employ a simple
compress-and-forward scheme in which the base-stations(BSs) quantize the
received signals and send the quantized signals to the CP using either
distributed Wyner-Ziv coding or single-user compression. The CP decodes the
quantization codewords first, then decodes the user messages as if the remote
users and the cloud center form a virtual multiple-access channel (VMAC). This
paper formulates the problem of optimizing the quantization noise levels for
weighted sum rate maximization under a sum backhaul capacity constraint. We
propose an alternating convex optimization approach to find a local optimum
solution to the problem efficiently, and more importantly, establish that
setting the quantization noise levels to be proportional to the background
noise levels is near optimal for sum-rate maximization when the
signal-to-quantization-noise ratio (SQNR) is high. In addition, with Wyner-Ziv
coding, the approximate quantization noise level is shown to achieve the
sum-capacity of the uplink C-RAN model to within a constant gap. With
single-user compression, a similar constant-gap result is obtained under a
diagonal dominant channel condition. These results lead to an efficient
algorithm for allocating the backhaul capacities in C-RAN. The performance of
the proposed scheme is evaluated for practical multicell and heterogeneous
networks. It is shown that multicell processing with optimized quantization
noise levels across the BSs can significantly improve the performance of
wireless cellular networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7512</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7512</id><created>2013-04-28</created><authors><author><keyname>Sidiropoulos</keyname><forenames>Anastasios</forenames></author></authors><title>Non-positive curvature, and the planar embedding conjecture</title><categories>cs.CG cs.DS math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The planar embedding conjecture asserts that any planar metric admits an
embedding into L_1 with constant distortion. This is a well-known open problem
with important algorithmic implications, and has received a lot of attention
over the past two decades. Despite significant efforts, it has been verified
only for some very restricted cases, while the general problem remains elusive.
  In this paper we make progress towards resolving this conjecture. We show
that every planar metric of non-positive curvature admits a constant-distortion
embedding into L_1. This confirms the planar embedding conjecture for the case
of non-positively curved metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7516</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7516</id><created>2013-04-28</created><authors><author><keyname>Saeedi</keyname><forenames>Mehdi</forenames></author><author><keyname>Markov</keyname><forenames>Igor L.</forenames></author></authors><title>Quantum Circuits for GCD Computation with $O(n \log n)$ Depth and O(n)
  Ancillae</title><categories>cs.ET quant-ph</categories><comments>5 pages, 6 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  GCD computations and variants of the Euclidean algorithm enjoy broad uses in
both classical and quantum algorithms. In this paper, we propose quantum
circuits for GCD computation with $O(n \log n)$ depth with O(n) ancillae. Prior
circuit construction needs $O(n^2)$ running time with O(n) ancillae. The
proposed construction is based on the binary GCD algorithm and it benefits from
log-depth circuits for 1-bit shift, comparison/subtraction, and managing
ancillae. The worst-case gate count remains $O(n^2)$, as in traditional
circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7517</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7517</id><created>2013-04-28</created><authors><author><keyname>Torrieri</keyname><forenames>Don</forenames></author><author><keyname>Valenti</keyname><forenames>Matthew C.</forenames></author><author><keyname>Talarico</keyname><forenames>Salvatore</forenames></author></authors><title>A New Analysis of the DS-CDMA Cellular Uplink Under Spatial Constraints</title><categories>cs.IT math.IT</categories><comments>6 pages, 6 figures, to appear at International Conference on
  Communications (ICC) 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new analysis is presented for the direct-sequence code-division multiple
access (DS-CDMA) cellular uplink. For a given network topology, closed-form
expressions are found for the outage probability and rate of each uplink in the
presence of path-dependent Nakagami fading and log-normal shadowing. The
topology may be arbitrary or modeled by a random spatial distribution for a
fixed number of base stations and mobiles placed over a finite area with the
separations among them constrained to exceed a minimum distance. The analysis
is more detailed and accurate than existing ones and facilitates the resolution
of network design issues, including the influence of the minimum base-station
separation, the role of the spreading factor, and the impact of various
power-control and rate-control policies. It is shown that once power control is
established, the rate can be allocated according to a fixed-rate or
variable-rate policy with the objective of either meeting an outage constraint
or maximizing throughput. An advantage of the variable-rate policy is that it
allows an outage constraint to be enforced on every uplink, whereas the
fixed-rate policy can only meet an average outage constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7528</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7528</id><created>2013-04-28</created><authors><author><keyname>Hansen</keyname><forenames>Toke J.</forenames></author><author><keyname>Mahoney</keyname><forenames>Michael W.</forenames></author></authors><title>Semi-supervised Eigenvectors for Large-scale Locally-biased Learning</title><categories>cs.LG math.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many applications, one has side information, e.g., labels that are
provided in a semi-supervised manner, about a specific target region of a large
data set, and one wants to perform machine learning and data analysis tasks
&quot;nearby&quot; that prespecified target region. For example, one might be interested
in the clustering structure of a data graph near a prespecified &quot;seed set&quot; of
nodes, or one might be interested in finding partitions in an image that are
near a prespecified &quot;ground truth&quot; set of pixels. Locally-biased problems of
this sort are particularly challenging for popular eigenvector-based machine
learning and data analysis tools. At root, the reason is that eigenvectors are
inherently global quantities, thus limiting the applicability of
eigenvector-based methods in situations where one is interested in very local
properties of the data.
  In this paper, we address this issue by providing a methodology to construct
semi-supervised eigenvectors of a graph Laplacian, and we illustrate how these
locally-biased eigenvectors can be used to perform locally-biased machine
learning. These semi-supervised eigenvectors capture
successively-orthogonalized directions of maximum variance, conditioned on
being well-correlated with an input seed set of nodes that is assumed to be
provided in a semi-supervised manner. We show that these semi-supervised
eigenvectors can be computed quickly as the solution to a system of linear
equations; and we also describe several variants of our basic method that have
improved scaling properties. We provide several empirical examples
demonstrating how these semi-supervised eigenvectors can be used to perform
locally-biased learning; and we discuss the relationship between our results
and recent machine learning algorithms that use global eigenvectors of the
graph Laplacian.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7530</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7530</id><created>2013-04-28</created><authors><author><keyname>Bateni</keyname><forenames>MohammadHossein</forenames></author><author><keyname>Hajiaghayi</keyname><forenames>MohammadTaghi</forenames></author><author><keyname>Liaghat</keyname><forenames>Vahid</forenames></author></authors><title>Improved Approximation Algorithms for (Budgeted) Node-weighted Steiner
  Problems</title><categories>cs.DS cs.DM</categories><comments>To appear in ICALP 2013</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Moss and Rabani[12] study constrained node-weighted Steiner tree problems
with two independent weight values associated with each node, namely, cost and
prize (or penalty). They give an O(log n)-approximation algorithm for the
prize-collecting node-weighted Steiner tree problem (PCST). They use the
algorithm for PCST to obtain a bicriteria (2, O(log n))-approximation algorithm
for the Budgeted node-weighted Steiner tree problem. Their solution may cost up
to twice the budget, but collects a factor Omega(1/log n) of the optimal prize.
We improve these results from at least two aspects.
  Our first main result is a primal-dual O(log h)-approximation algorithm for a
more general problem, prize-collecting node-weighted Steiner forest, where we
have (h) demands each requesting the connectivity of a pair of vertices. Our
algorithm can be seen as a greedy algorithm which reduces the number of demands
by choosing a structure with minimum cost-to-reduction ratio. This natural
style of argument (also used by Klein and Ravi[10] and Guha et al.[8]) leads to
a much simpler algorithm than that of Moss and Rabani[12] for PCST.
  Our second main contribution is for the Budgeted node-weighted Steiner tree
problem, which is also an improvement to [12] and [8]. In the unrooted case, we
improve upon an O(log^2(n))-approximation of [8], and present an O(log
n)-approximation algorithm without any budget violation. For the rooted case,
where a specified vertex has to appear in the solution tree, we improve the
bicriteria result of [12] to a bicriteria approximation ratio of (1+eps, O(log
n)/(eps^2)) for any positive (possibly subconstant) (eps). That is, for any
permissible budget violation (1+eps), we present an algorithm achieving a
tradeoff in the guarantee for prize. Indeed, we show that this is almost tight
for the natural linear-programming relaxation used by us as well as in [12].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7539</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7539</id><created>2013-04-28</created><updated>2014-01-25</updated><authors><author><keyname>Ramasamy</keyname><forenames>Dinesh</forenames></author><author><keyname>Venkateswaran</keyname><forenames>Sriram</forenames></author><author><keyname>Madhow</keyname><forenames>Upamanyu</forenames></author></authors><title>Compressive parameter estimation in AWGN</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2014.2306180</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing is by now well-established as an effective tool for
extracting sparsely distributed information, where sparsity is a discrete
concept, referring to the number of dominant nonzero signal components in some
basis for the signal space. In this paper, we establish a framework for
estimation of continuous-valued parameters based on compressive measurements on
a signal corrupted by additive white Gaussian noise (AWGN). While standard
compressed sensing based on naive discretization has been shown to suffer from
performance loss due to basis mismatch, we demonstrate that this is not an
inherent property of compressive measurements. Our contributions are summarized
as follows: (a) We identify the isometries required to preserve fundamental
estimation-theoretic quantities such as the Ziv-Zakai bound (ZZB) and the
Cramer-Rao bound (CRB). Under such isometries, compressive projections can be
interpreted simply as a reduction in &quot;effective SNR.&quot; (b) We show that the
threshold behavior of the ZZB provides a criterion for determining the minimum
number of measurements for &quot;accurate&quot; parameter estimation. (c) We provide
detailed computations of the number of measurements needed for the isometries
in (a) to hold for the problem of frequency estimation in a mixture of
sinusoids. We show via simulations that the design criterion in (b) is accurate
for estimating the frequency of a single sinusoid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7544</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7544</id><created>2013-04-28</created><authors><author><keyname>Lin</keyname><forenames>Jimmy</forenames></author></authors><title>Monoidify! Monoids as a Design Principle for Efficient MapReduce
  Algorithms</title><categories>cs.DC cs.DB cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that since the sort/shuffle stage in MapReduce is costly,
local aggregation is one important principle to designing efficient algorithms.
This short paper represents an attempt to more clearly articulate this design
principle in terms of monoids, which generalizes the use of combiners and the
in-mapper combining pattern.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7547</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7547</id><created>2013-04-28</created><authors><author><keyname>Khare</keyname><forenames>Ritu</forenames></author><author><keyname>Sahai</keyname><forenames>Esha</forenames></author><author><keyname>Pramanick</keyname><forenames>Ira</forenames></author></authors><title>Remote Mentoring Young Females in STEM through MAGIC</title><categories>cs.CY physics.ed-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The limited representation of women in STEM workforce is a concerning
national issue. It has been found that the gender stratification is not due to
the lack of talent amongst young females, but due to the lack of access to
female role models. To this end, &quot;remote mentoring&quot; is an effective way to
offer nation-wide personalized STEM mentoring to young females from all
segments of the society. In this paper, we introduce MAGIC, an organization
dedicated to mentoring young females in STEM through remote methods. We conduct
a retrospective study of MAGIC's formative years and present our experience in
remotely establishing 23 highly tailored mentor-mentee pairs. We provide
several key findings on STEM remote mentoring, such as popular communication
tools, frequently sought STEM skills among girls, and projects that could be
accomplished through remote mentoring. Furthermore, we present key challenges
faced by mentors and mentees, notable outcomes, and lessons learnt about remote
mentoring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7548</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7548</id><created>2013-04-28</created><authors><author><keyname>de Lamare</keyname><forenames>Rodrigo C.</forenames></author><author><keyname>Sampaio-Neto</keyname><forenames>Raimundo</forenames></author></authors><title>Adaptive Reduced-Rank RLS Algorithms based on Joint Iterative
  Optimization of Filters for Space-Time Interference Suppression</title><categories>cs.IT math.IT</categories><comments>3 figures. arXiv admin note: substantial text overlap with
  arXiv:1205.4390, arXiv:1301.2696</comments><journal-ref>ICASSP 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents novel adaptive reduced-rank filtering algorithms based on
joint iterative optimization of adaptive filters. The novel scheme consists of
a joint iterative optimization of a bank of full-rank adaptive filters that
constitute the projection matrix and an adaptive reduced-rank filter that
operates at the output of the bank of filters. We describe least squares (LS)
expressions for the design of the projection matrix and the reduced-rank filter
and recursive least squares (RLS) adaptive algorithms for its computationally
efficient implementation. Simulations for a space-time interference suppression
in a CDMA system application show that the proposed scheme outperforms in
convergence and tracking the state-of-the-art reduced-rank schemes at about the
same complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7552</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7552</id><created>2013-04-28</created><authors><author><keyname>de Lamare</keyname><forenames>Rodrigo C.</forenames></author><author><keyname>Hjorungnes</keyname><forenames>Are</forenames></author><author><keyname>Sampaio-Neto</keyname><forenames>Raimundo</forenames></author></authors><title>Adaptive Decision Feedback Reduced-Rank Equalization Based on Joint
  Iterative Optimization of Adaptive Estimation Algorithms for Multi-Antenna
  Systems</title><categories>cs.IT math.IT</categories><comments>6 figures. arXiv admin note: substantial text overlap with
  arXiv:1301.2697</comments><journal-ref>JWCNC 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel adaptive reduced-rank multi-input-multi-output
(MIMO) decision feedback equalization structure based on joint iterative
optimization of adaptive estimators. The novel reduced-rank equalization
structure consists of a joint iterative optimization of two equalization
stages, namely, a projection matrix that performs dimensionality reduction and
a reduced-rank estimator that retrieves the desired transmitted symbol. The
proposed reduced-rank structure is followed by a decision feedback scheme that
is responsible for cancelling the inter-antenna interference caused by the
associated data streams. We describe least squares (LS) expressions for the
design of the projection matrix and the reduced-rank estimator along with
computationally efficient recursive least squares (RLS) adaptive estimation
algorithms. Simulations for a MIMO equalization application show that the
proposed scheme outperforms the state-of-the-art reduced-rank and the
conventional estimation algorithms at about the same complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7558</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7558</id><created>2013-04-28</created><authors><author><keyname>Abboud</keyname><forenames>Amir</forenames></author><author><keyname>Lewi</keyname><forenames>Kevin</forenames></author></authors><title>Exact Weight Subgraphs and the k-Sum Conjecture</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the Exact-Weight-H problem of finding a (not necessarily induced)
subgraph H of weight 0 in an edge-weighted graph G. We show that for every H,
the complexity of this problem is strongly related to that of the infamous
k-Sum problem. In particular, we show that under the k-Sum Conjecture, we can
achieve tight upper and lower bounds for the Exact-Weight-H problem for various
subgraphs H such as matching, star, path, and cycle. One interesting
consequence is that improving on the O(n^3) upper bound for Exact-Weight-4-Path
or Exact-Weight-5-Path will imply improved algorithms for 3-Sum, 5-Sum,
All-Pairs Shortest Paths and other fundamental problems. This is in sharp
contrast to the minimum-weight and (unweighted) detection versions, which can
be solved easily in time O(n^2). We also show that a faster algorithm for any
of the following three problems would yield faster algorithms for the others:
3-Sum, Exact-Weight-3-Matching, and Exact-Weight-3-Star.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7571</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7571</id><created>2013-04-29</created><authors><author><keyname>Cohen</keyname><forenames>Nachshon</forenames></author><author><keyname>Nutov</keyname><forenames>Zeev</forenames></author></authors><title>Approximating {0,1,2}-Survivable Networks with Minimum Number of Steiner
  Points</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider low connectivity variants of the Survivable Network with Minimum
Number of Steiner Points (SN-MSP) problem: given a finite set $R$ of terminals
in a metric space (M,d), a subset $B \subseteq R$ of &quot;unstable&quot; terminals, and
connectivity requirements {r_{uv}: u,v \in R}, find a minimum size set $S
\subseteq M$ of additional points such that the unit-disc graph of $R \cup S$
contains $r_{uv}$ pairwise internally edge-disjoint and $(B \cup S)$-disjoint
$uv$-paths for all $u,v \in R$. The case when $r_{uv}=1$ for all $u,v \in R$ is
the {\sf Steiner Tree with Minimum Number of Steiner Points} (ST-MSP) problem,
and the case $r_{uv} \in \{0,1\}$ is the {\sf Steiner Forest with Minimum
Number of Steiner Points} (SF-MSP) problem. Let $\Delta$ be the maximum number
of points in a unit ball such that the distance between any two of them is
larger than 1. It is known that $\Delta=5$ in $\mathbb{R}^2$ The previous known
approximation ratio for {\sf ST-MSP} was $\lfloor (\Delta+1)/2
\rfloor+1+\epsilon$ in an arbitrary normed space \cite{NY}, and $2.5+\epsilon$
in the Euclidean space $\mathbb{R}^2$ \cite{cheng2008relay}. Our approximation
ratio for ST-MSP is $1+\ln(\Delta-1)+\epsilon$ in an arbitrary normed space,
which in $\mathbb{R}^2$ reduces to $1+\ln 4+\epsilon &lt; 2.3863 +\epsilon$. For
SN-MSP with $r_{uv} \in \{0,1,2\}$, we give a simple $\Delta$-approximation
algorithm. In particular, for SF-MSP, this improves the previous ratio
$2\Delta$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7576</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7576</id><created>2013-04-29</created><authors><author><keyname>Panigrahy</keyname><forenames>Rina</forenames></author><author><keyname>Popat</keyname><forenames>Preyas</forenames></author></authors><title>Fractal structures in Adversarial Prediction</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fractals are self-similar recursive structures that have been used in
modeling several real world processes. In this work we study how &quot;fractal-like&quot;
processes arise in a prediction game where an adversary is generating a
sequence of bits and an algorithm is trying to predict them. We will see that
under a certain formalization of the predictive payoff for the algorithm it is
most optimal for the adversary to produce a fractal-like sequence to minimize
the algorithm's ability to predict. Indeed it has been suggested before that
financial markets exhibit a fractal-like behavior. We prove that a fractal-like
distribution arises naturally out of an optimization from the adversary's
perspective.
  In addition, we give optimal trade-offs between predictability and expected
deviation (i.e. sum of bits) for our formalization of predictive payoff. This
result is motivated by the observation that several time series data exhibit
higher deviations than expected for a completely random walk.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7577</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7577</id><created>2013-04-29</created><authors><author><keyname>Panigrahy</keyname><forenames>Rina</forenames></author><author><keyname>Popat</keyname><forenames>Preyas</forenames></author></authors><title>Optimal amortized regret in every interval</title><categories>cs.LG cs.DS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the classical problem of predicting the next bit in a sequence of
bits. A standard performance measure is {\em regret} (loss in payoff) with
respect to a set of experts. For example if we measure performance with respect
to two constant experts one that always predicts 0's and another that always
predicts 1's it is well known that one can get regret $O(\sqrt T)$ with respect
to the best expert by using, say, the weighted majority algorithm. But this
algorithm does not provide performance guarantee in any interval. There are
other algorithms that ensure regret $O(\sqrt {x \log T})$ in any interval of
length $x$. In this paper we show a randomized algorithm that in an amortized
sense gets a regret of $O(\sqrt x)$ for any interval when the sequence is
partitioned into intervals arbitrarily. We empirically estimated the constant
in the $O()$ for $T$ upto 2000 and found it to be small -- around 2.1. We also
experimentally evaluate the efficacy of this algorithm in predicting high
frequency stock data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7578</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7578</id><created>2013-04-29</created><authors><author><keyname>Hamza</keyname><forenames>Fatima Amir</forenames></author><author><keyname>Romdhani</keyname><forenames>Lamia</forenames></author><author><keyname>Mohamed</keyname><forenames>Amr</forenames></author></authors><title>Novel Network Coding-based Techniques for Multi-layer Video Delivery
  over Multi-hop Wireless testbed</title><categories>cs.NI</categories><comments>accepted in PEMWN 2012, Tunisia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The actual performance of video delivery over wireless networks is best
captured through experimental studies over real testbed, which is crucial to
uncover the technical problems and practical challenges of realizing the
proposed video delivery techniques. Network coding (NC) provides a paradigm
shift to optimize the network resources for enhancing the video quality as a
result of delivery over multi-hop wireless networks. In this paper, we propose
a novel framework for evaluating the performance of NC-based video delivery
over multi-hop wireless networks. Based on an experimental testbed
implementation of inter-layer video coding and delivery, we propose a new
generalized technique for multi-hop interlayer NC in enhancing video delivery
quality. We evaluate the trade-off between complexity of multi-hop NC, and
video quality gain. We provide clear recommendations for best design choices of
NC-based inter-layer video coding and delivery over multi-hop wireless mesh
network considering link conditions and Packet Delivery Ratio (PDR). The
results show that using NC improves the layered video performance in single and
multi-hop network. The average number of decoded layers when using NC in single
hop outperforms that when using NC in multi-hop.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7590</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7590</id><created>2013-04-29</created><authors><author><keyname>Chilton</keyname><forenames>Chris</forenames></author><author><keyname>Kwiatkowska</keyname><forenames>Marta</forenames></author><author><keyname>Wang</keyname><forenames>Xu</forenames></author></authors><title>Revisiting Timed Specification Theory II : Realisability</title><categories>cs.LO cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present an assume-guarantee specification theory (aka
interface theory from [14]) for modular synthesis and verification of real-time
systems with critical timing constraints. It is a further step of our earlier
work [10] which achieved an elegant algebraic specification theory for
real-time systems endowed with the capability to freeze time. In this paper we
relinquish such (unrealisable) capability and target more realistic systems
without the ability to stop time.
  Our theory, in a combined process-algebraic and reactive-synthesis style,
provides the operations of parallel composition for system integration, logical
conjunction/disjunction for viewpoint fusion and independent development, and
quotient for incremental synthesis.
  We show that a substitutive refinement preorder, which is a coarsening of the
pre-congruence in [10], constitutes the weakest pre-congruence preserving
freedom of incompatibility errors. The coarsening requires a shift in the focus
of our theory to a more game-theoretical treatment, where the coarsening
constitutes a reactive synthesis game named normalisation and is efficiently
implementable by a novel local bot-backpropagation algorithm.
  Previously, timed concurrent games have been studied in [1,14,13], where one
of the key concern is the removal of time-blocking strategies by applying blame
assignment [13]. Our timed games also have the issue of time-blocking
strategies, which may arise through the composition of specifications. However,
due to our distinctively different formulation of timed games, we have
discovered another elegant solution to the problem without blame assignment.
Our solution utilises a second reactive synthesis game called realisation,
which is dual to normalisation and implementable by the dual local
top-backpropagation algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7600</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7600</id><created>2013-04-29</created><authors><author><keyname>Beling</keyname><forenames>Piotr</forenames></author></authors><title>C++11 - okre\'slanie typ\'ow</title><categories>cs.PL</categories><comments>6 pages, in Polish</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a review of some new futures introduced to C++ language
by ISO/IEC 14882:2011 standard (known as C++11). It describes new language
elements which allow to easier expressed of types of variables: auto and
decltype keywords, new function declaration syntax, and tools which are
included in type_traits header.
  -----
  Niniejszy artyku{\l} jest jednym z serii artyku{\l}\'ow w kt\'orych zawarto
przegl{\ka}d nowych element\'ow j{\ke}zyka C++ wprowadzonych przez standard
ISO/IEC 14882:2011, znany pod nazw{\ka} C++11. W artykule przedstawiono nowe
mo\.zliwo\'sci zwi{\ka}zane ze wskazywaniem typ\'ow zmiennych. Opisano s{\l}owa
kluczowe auto i decltype, now{\ka} sk{\l}adnie deklarowania funkcji/metod oraz
narz{\ke}dzia zawarte w pliku nag{\l}\'owkowym &lt;type_traits&gt;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7603</identifier>
 <datestamp>2013-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7603</id><created>2013-04-29</created><authors><author><keyname>Bradford</keyname><forenames>Russell</forenames></author><author><keyname>Davenport</keyname><forenames>James H.</forenames></author><author><keyname>England</keyname><forenames>Matthew</forenames></author><author><keyname>McCallum</keyname><forenames>Scott</forenames></author><author><keyname>Wilson</keyname><forenames>David</forenames></author></authors><title>Cylindrical Algebraic Decompositions for Boolean Combinations</title><categories>cs.SC</categories><comments>To appear in the proceedings of the 38th International Symposium on
  Symbolic and Algebraic Computation (ISSAC '13)</comments><msc-class>68W30, 03C10</msc-class><acm-class>I.1.2</acm-class><journal-ref>In: Proceedings of the 38th International Symposium on Symbolic
  and Algebraic Computation, (ISSAC '13), pp 125-132, 2013</journal-ref><doi>10.1145/2465506.2465516</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article makes the key observation that when using cylindrical algebraic
decomposition (CAD) to solve a problem with respect to a set of polynomials, it
is not always the signs of those polynomials that are of paramount importance
but rather the truth values of certain quantifier free formulae involving them.
This motivates our definition of a Truth Table Invariant CAD (TTICAD). We
generalise the theory of equational constraints to design an algorithm which
will efficiently construct a TTICAD for a wide class of problems, producing
stronger results than when using equational constraints alone. The algorithm is
implemented fully in Maple and we present promising results from
experimentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7604</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7604</id><created>2013-04-29</created><authors><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Iacono</keyname><forenames>John</forenames></author><author><keyname>Langerman</keyname><forenames>Stefan</forenames></author><author><keyname>&#xd6;zkan</keyname><forenames>&#xd6;zg&#xfc;r</forenames></author></authors><title>Combining Binary Search Trees</title><categories>cs.DS</categories><comments>12 pages, 2 figures, ICALP 2013</comments><acm-class>E.1; F.1.1; F.2.2; G.2.1; I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a general transformation for combining a constant number of binary
search tree data structures (BSTs) into a single BST whose running time is
within a constant factor of the minimum of any &quot;well-behaved&quot; bound on the
running time of the given BSTs, for any online access sequence.
  (A BST has a well behaved bound with $f(n)$ overhead if it spends at most
\bigoh{f(n)} time per access and its bound satisfies a weak sense of closure
under subsequences.) In particular, we obtain a BST data structure that is
\bigoh{\log\log n} competitive, satisfies the working set bound (and thus
satisfies the static finger bound and the static optimality bound), satisfies
the dynamic finger bound, satisfies the unified bound with an additive
\bigoh{\log\log n} factor, and performs each access in worst-case \bigoh{\log
n} time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7605</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7605</id><created>2013-04-29</created><authors><author><keyname>Sweeney</keyname><forenames>Latanya</forenames></author><author><keyname>Abu</keyname><forenames>Akua</forenames></author><author><keyname>Winn</keyname><forenames>Julia</forenames></author></authors><title>Identifying Participants in the Personal Genome Project by Name (A
  Re-identification Experiment)</title><categories>cs.CY</categories><comments>4 pages</comments><report-no>Harvard University, Data Privacy Lab 1021-1</report-no><acm-class>K.4.1; K.6.5; J.3; H.1.2; H.2.0; H.2.7; H.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We linked names and contact information to publicly available profiles in the
Personal Genome Project. These profiles contain medical and genomic
information, including details about medications, procedures and diseases, and
demographic information, such as date of birth, gender, and postal code. By
linking demographics to public records such as voter lists, and mining for
names hidden in attached documents, we correctly identified 84 to 97 percent of
the profiles for which we provided names. Our ability to learn their names is
based on their demographics, not their DNA, thereby revisiting an old
vulnerability that could be easily thwarted with minimal loss of research
value. So, we propose technical remedies for people to learn about their
demographics to make better decisions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7607</identifier>
 <datestamp>2015-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7607</id><created>2013-04-29</created><authors><author><keyname>Tang</keyname><forenames>Xiaolin</forenames></author><author><keyname>Yang</keyname><forenames>Chunhua</forenames></author><author><keyname>Zhou</keyname><forenames>Xiaojun</forenames></author><author><keyname>Gui</keyname><forenames>Weihua</forenames></author></authors><title>A Discrete State Transition Algorithm for Generalized Traveling Salesman
  Problem</title><categories>math.OC cs.AI cs.NE</categories><comments>8 pages, 1 figure</comments><journal-ref>Advances in Global Optimization, 2015, 95:137-145</journal-ref><doi>10.1007/978-3-319-08377-3__15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generalized traveling salesman problem (GTSP) is an extension of classical
traveling salesman problem (TSP), which is a combinatorial optimization problem
and an NP-hard problem. In this paper, an efficient discrete state transition
algorithm (DSTA) for GTSP is proposed, where a new local search operator named
\textit{K-circle}, directed by neighborhood information in space, has been
introduced to DSTA to shrink search space and strengthen search ability. A
novel robust update mechanism, restore in probability and risk in probability
(Double R-Probability), is used in our work to escape from local minima. The
proposed algorithm is tested on a set of GTSP instances. Compared with other
heuristics, experimental results have demonstrated the effectiveness and strong
adaptability of DSTA and also show that DSTA has better search ability than its
competitors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7614</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7614</id><created>2013-04-29</created><updated>2013-08-27</updated><authors><author><keyname>Su</keyname><forenames>Guoxin</forenames></author><author><keyname>Rosenblum</keyname><forenames>David S.</forenames></author></authors><title>Asymptotic Bounds for Quantitative Verification of Perturbed
  Probabilistic Systems</title><categories>cs.SE cs.LO</categories><comments>This paper is a long version of the paper Asymptotic Bounds for
  Quantitative Verification of Perturbed Probabilistic Systems in the
  proceedings of 15th International Conference on Formal Engineering Methods</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The majority of existing probabilistic model checking case studies are based
on well understood theoretical models and distributions. However, real-life
probabilistic systems usually involve distribution parameters whose values are
obtained by empirical measurements and thus are subject to small perturbations.
In this paper, we consider perturbation analysis of reachability in the
parametric models of these systems (i.e., parametric Markov chains) equipped
with the norm of absolute distance. Our main contribution is a method to
compute the asymptotic bounds in the form of condition numbers for constrained
reachability probabilities against perturbations of the distribution parameters
of the system. The adequacy of the method is demonstrated through experiments
with the Zeroconf protocol and the hopping frog problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7615</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7615</id><created>2013-04-29</created><authors><author><keyname>Jackson</keyname><forenames>Adrian</forenames></author><author><keyname>Strand</keyname><forenames>Par</forenames></author></authors><title>MDMP: Managed Data Message Passing</title><categories>cs.DC cs.PL</categories><comments>Submitted to SC13, 10 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MDMP is a new parallel programming approach that aims to provide users with
an easy way to add parallelism to programs, optimise the message passing costs
of traditional scientific simulation algorithms, and enable existing MPI-based
parallel programs to be optimised and extended without requiring the whole code
to be re-written from scratch. MDMP utilises a directives based approach to
enable users to specify what communications should take place in the code, and
then implements those communications for the user in an optimal manner using
both the information provided by the user and data collected from instrumenting
the code and gathering information on the data to be communicated. This work
will present the basic concepts and functionality of MDMP and discuss the
performance that can be achieved using our prototype implementation of MDMP on
some model scientific simulation applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7622</identifier>
 <datestamp>2015-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7622</id><created>2013-04-29</created><updated>2013-10-18</updated><authors><author><keyname>Zhou</keyname><forenames>Xiaojun</forenames></author></authors><title>Optimal Design of Water Distribution Networks by Discrete State
  Transition Algorithm</title><categories>math.OC cs.IT math.CO math.IT math.PR</categories><comments>14 pages, 13 figures</comments><doi>10.1080/0305215X.2015.1025775</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal design of water distribution networks, which are governed by a series
of linear and nonlinear equations, has been extensively studied in the past
decades. Due to their NP-hardness, methods to solve the optimization problem
have changed from traditional mathematical programming to modern intelligent
optimization techniques. In this study, with respect to the model formulation,
we have demonstrated that the network system can be reduced to the
dimensionality of the number of closed simple loops or required independent
paths, and the reduced nonlinear system can be solved efficiently by the
Newton-Raphson method. Regarding the optimization technique, a discrete state
transition algorithm (STA) is introduced to solve several cases of water
distribution networks. In discrete STA, there exist four basic intelligent
operators, namely, swap, shift, symmetry and substitute as well as the &quot;risk
and restore in probability&quot; strategy. Firstly, we focus on a parametric study
of the restore probability $p_1$ and risk probability $p_2$. To effectively
deal with the head pressure constraints, we then investigate the effect of
penalty coefficient and search enforcement on the performance of the algorithm.
Based on the experience gained from the training of the Two-Loop network
problem, the discrete STA has successfully achieved the best known solutions
for the Hanoi and New York problems. A detailed comparison of our results with
those gained by other algorithms is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7632</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7632</id><created>2013-04-29</created><authors><author><keyname>Geissmann</keyname><forenames>Barbara</forenames></author><author><keyname>&#x160;r&#xe1;mek</keyname><forenames>Rastislav</forenames></author></authors><title>Counting small cuts in a graph</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the minimum cut problem in the presence of uncertainty and show how
to apply a novel robust optimization approach, which aims to exploit the
similarity in subsequent graph measurements or similar graph instances, without
posing any assumptions on the way they have been obtained. With experiments we
show that the approach works well when compared to other approaches that are
also oblivious towards the relationship between the input datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7638</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7638</id><created>2013-04-29</created><updated>2013-06-26</updated><authors><author><keyname>Campiteli</keyname><forenames>Monica G.</forenames></author><author><keyname>Holanda</keyname><forenames>Adriano J.</forenames></author><author><keyname>Soares</keyname><forenames>Leonardo D. H.</forenames></author><author><keyname>Soles</keyname><forenames>Paulo R. C.</forenames></author><author><keyname>Kinouchi</keyname><forenames>Osame</forenames></author></authors><title>Lobby index as a network centrality measure</title><categories>cs.SI cs.DL physics.soc-ph</categories><comments>11 pages, 4 figures. arXiv admin note: substantial text overlap with
  arXiv:1005.4803</comments><doi>10.1016/j.physa.2013.06.065</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the lobby index (l-index for short) as a local node centrality
measure for complex networks. The l-inde is compared with degree (a local
measure), betweenness and Eigenvector centralities (two global measures) in the
case of biological network (Yeast interaction protein-protein network) and a
linguistic network (Moby Thesaurus II). In both networks, the l-index has poor
correlation with betweenness but correlates with degree and Eigenvector. Being
a local measure, one can take advantage by using the l-index because it carries
more information about its neighbors when compared with degree centrality,
indeed it requires less time to compute when compared with Eigenvector
centrality. Results suggests that l-index produces better results than degree
and Eigenvector measures for ranking purposes, becoming suitable as a tool to
perform this task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7642</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7642</id><created>2013-04-29</created><authors><author><keyname>Roberts</keyname><forenames>Ben</forenames></author><author><keyname>Gunawardena</keyname><forenames>Dinan</forenames></author><author><keyname>Kash</keyname><forenames>Ian A.</forenames></author><author><keyname>Key</keyname><forenames>Peter</forenames></author></authors><title>Ranking and Tradeoffs in Sponsored Search Auctions</title><categories>cs.GT</categories><comments>To appear in Proceedings of the 14th ACM Conference on Electronic
  Commerce (EC '13)</comments><acm-class>J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a sponsored search auction, decisions about how to rank ads impose
tradeoffs between objectives such as revenue and welfare. In this paper, we
examine how these tradeoffs should be made. We begin by arguing that the most
natural solution concept to evaluate these tradeoffs is the lowest symmetric
Nash equilibrium (SNE). As part of this argument, we generalise the well known
connection between the lowest SNE and the VCG outcome. We then propose a new
ranking algorithm, loosely based on the revenue-optimal auction, that uses a
reserve price to order the ads (not just to filter them) and give conditions
under which it raises more revenue than simply applying that reserve price.
Finally, we conduct extensive simulations examining the tradeoffs enabled by
different ranking algorithms and show that our proposed algorithm enables
superior operating points by a variety of metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7653</identifier>
 <datestamp>2014-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7653</id><created>2013-04-29</created><updated>2014-06-23</updated><authors><author><keyname>Wang</keyname><forenames>Xianwen</forenames></author><author><keyname>Mao</keyname><forenames>Wenli</forenames></author><author><keyname>Xu</keyname><forenames>Shenmeng</forenames></author><author><keyname>Zhang</keyname><forenames>Chunbo</forenames></author></authors><title>Usage History of Scientific Literature: Nature Metrics and Metrics of
  Nature Publications</title><categories>cs.DL</categories><comments>11 pages, 5 figures and 4 tables</comments><journal-ref>Scientometrics, 2014, 98(3), 1923-1933</journal-ref><doi>10.1007/s11192-013-1167-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, we analyze the dynamic usage history of Nature publications
over time using Nature metrics data. We conduct analysis from two perspectives.
On the one hand, we examine how long it takes before the articles' downloads
reach 50%/80% of the total; on the other hand, we compare the percentage of
total downloads in 7 days, 30 days, and 100 days after publication. In general,
papers are downloaded most frequently within a short time period right after
their publication. And we find that compared with Non-Open Access papers,
readers' attention on Open Access publications are more enduring. Based on the
usage data of a newly published paper, regression analysis could predict the
future expected total usage counts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7654</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7654</id><created>2013-04-29</created><authors><author><keyname>Jackson</keyname><forenames>Adrian</forenames></author><author><keyname>Campobasso</keyname><forenames>M. Sergio</forenames></author></authors><title>Optimised hybrid parallelisation of a CFD code on Many Core
  architectures</title><categories>cs.DC</categories><comments>Submitted to the SC13 conference, 10 pages with 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  COSA is a novel CFD system based on the compressible Navier-Stokes model for
unsteady aerodynamics and aeroelasticity of fixed structures, rotary wings and
turbomachinery blades. It includes a steady, time domain, and harmonic balance
flow solver.
  COSA has primarily been parallelised using MPI, but there is also a hybrid
parallelisation that adds OpenMP functionality to the MPI parallelisation to
enable larger number of cores to be utilised for a given simulation as the MPI
parallelisation is limited to the number of geometric partitions (or blocks) in
the simulation, or to exploit multi-threaded hardware where appropriate. This
paper outlines the work undertaken to optimise these two parallelisation
strategies, improving the efficiency of both and therefore reducing the
computational time required to compute simulations. We also analyse the power
consumption of the code on a range of leading HPC systems to further understand
the performance of the code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7664</identifier>
 <datestamp>2015-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7664</id><created>2013-04-29</created><updated>2015-05-22</updated><authors><author><keyname>Wittmann</keyname><forenames>Markus</forenames></author><author><keyname>Hager</keyname><forenames>Georg</forenames></author><author><keyname>Zeiser</keyname><forenames>Thomas</forenames></author><author><keyname>Treibig</keyname><forenames>Jan</forenames></author><author><keyname>Wellein</keyname><forenames>Gerhard</forenames></author></authors><title>Chip-level and multi-node analysis of energy-optimized lattice-Boltzmann
  CFD simulations</title><categories>cs.PF cs.DC</categories><comments>23 pages, 13 figures; post-peer-review version</comments><doi>10.1002/cpe.3489</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Memory-bound algorithms show complex performance and energy consumption
behavior on multicore processors. We choose the lattice-Boltzmann method (LBM)
on an Intel Sandy Bridge cluster as a prototype scenario to investigate if and
how single-chip performance and power characteristics can be generalized to the
highly parallel case. First we perform an analysis of a sparse-lattice LBM
implementation for complex geometries. Using a single-core performance model,
we predict the intra-chip saturation characteristics and the optimal operating
point in terms of energy to solution as a function of implementation details,
clock frequency, vectorization, and number of active cores per chip. We show
that high single-core performance and a correct choice of the number of active
cores per chip are the essential optimizations for lowest energy to solution at
minimal performance degradation. Then we extrapolate to the MPI-parallel level
and quantify the energy-saving potential of various optimizations and execution
modes, where we find these guidelines to be even more important, especially
when communication overhead is non-negligible. In our setup we could achieve
energy savings of 35% in this case, compared to a naive approach. We also
demonstrate that a simple non-reflective reduction of the clock speed leaves
most of the energy saving potential unused.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7687</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7687</id><created>2013-04-29</created><updated>2013-06-09</updated><authors><author><keyname>Even</keyname><forenames>Guy</forenames></author><author><keyname>Medina</keyname><forenames>Moti</forenames></author></authors><title>A Nonmonotone Analysis with the Primal-Dual Approach: online routing of
  virtual circuits with unknown durations</title><categories>cs.DS</categories><comments>To appear in SIROCCO 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the question of whether the primal-dual approach for the design
and analysis of online algorithms can be applied to nonmonotone problems. We
provide a positive answer by presenting a primal-dual analysis to the online
algorithm of Awerbuch et al.[AAPW01] for routing virtual circuits with unknown
durations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7693</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7693</id><created>2013-04-29</created><authors><author><keyname>Czyzowicz</keyname><forenames>Jurek</forenames></author><author><keyname>Gasieniec</keyname><forenames>Leszek</forenames></author><author><keyname>Georgiou</keyname><forenames>Konstantinos</forenames></author><author><keyname>Kranakis</keyname><forenames>Evangelos</forenames></author><author><keyname>MacQuarrie</keyname><forenames>Fraser</forenames></author></authors><title>The Beachcombers' Problem: Walking and Searching with Mobile Robots</title><categories>cs.DS</categories><comments>19 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce and study a new problem concerning the exploration of a
geometric domain by mobile robots. Consider a line segment $[0,I]$ and a set of
$n$ mobile robots $r_1,r_2,..., r_n$ placed at one of its endpoints. Each robot
has a {\em searching speed} $s_i$ and a {\em walking speed} $w_i$, where $s_i
&lt;w_i$. We assume that each robot is aware of the number of robots of the
collection and their corresponding speeds. At each time moment a robot $r_i$
either walks along a portion of the segment not exceeding its walking speed
$w_i$ or searches a portion of the segment with the speed not exceeding $s_i$.
A search of segment $[0,I]$ is completed at the time when each of its points
have been searched by at least one of the $n$ robots. We want to develop {\em
mobility schedules} (algorithms) for the robots which complete the search of
the segment as fast as possible. More exactly we want to maximize the {\em
speed} of the mobility schedule (equal to the ratio of the segment length
versus the time of the completion of the schedule).
  We analyze first the offline scenario when the robots know the length of the
segment that is to be searched. We give an algorithm producing a mobility
schedule for arbitrary walking and searching speeds and prove its optimality.
Then we propose an online algorithm, when the robots do not know in advance the
actual length of the segment to be searched. The speed $S$ of such algorithm is
defined as $S = \inf_{I_L} S(I_L)$ where $S(I_L)$ denotes the speed of
searching of segment $I_L=[0,L]$. We prove that the proposed online algorithm
is 2-competitive. The competitive ratio is shown to be better in the case when
the robots' walking speeds are all the same.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7700</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7700</id><created>2013-04-29</created><updated>2013-07-30</updated><authors><author><keyname>Katsoulakis</keyname><forenames>Markos A.</forenames></author><author><keyname>Plechac</keyname><forenames>Petr</forenames></author></authors><title>Information-theoretic tools for parametrized coarse-graining of
  non-equilibrium extended systems</title><categories>physics.comp-ph cs.IT math.IT physics.data-an</categories><comments>14 pages, 6 figures, expanded version v2 with additional benchmark</comments><msc-class>82-08, 82-C20, 82-C22, 82-C80</msc-class><doi>10.1063/1.4818534</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we focus on the development of new methods suitable for
efficient and reliable coarse-graining of {\it non-equilibrium} molecular
systems. In this context, we propose error estimation and controlled-fidelity
model reduction methods based on Path-Space Information Theory, and combine it
with statistical parametric estimation of rates for non-equilibrium stationary
processes. The approach we propose extends the applicability of existing
information-based methods for deriving parametrized coarse-grained models to
Non-Equilibrium systems with Stationary States (NESS). In the context of
coarse-graining it allows for constructing optimal parametrized Markovian
coarse-grained dynamics, by minimizing information loss (due to
coarse-graining) on the path space. Furthermore, the associated path-space
Fisher Information Matrix can provide confidence intervals for the
corresponding parameter estimators. We demonstrate the proposed coarse-graining
method in a non-equilibrium system with diffusing interacting particles, driven
by out-of-equilibrium boundary conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7705</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7705</id><created>2013-04-29</created><authors><author><keyname>Matousek</keyname><forenames>Jiri</forenames></author></authors><title>Computing higher homotopy groups is W[1]-hard</title><categories>cs.CC cs.CG</categories><msc-class>68U05, 68W99, 55Q05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently it was shown that, for every fixed k&gt;1, given a finite simply
connected simplicial complex X, the kth homotopy group \pi_k(X) can be computed
in time polynomial in the number n of simplices of X. We prove that this
problem is W[1]-hard w.r.t. the parameter k even for X of dimension 4, and thus
very unlikely to admit an algorithm with running time bound f(k)n^C for an
absolute constant C. We also simplify, by about 20 pages, a 1989 proof by Anick
that, with k part of input, the computation of the rank of \pi_k(X) is #P-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7710</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7710</id><created>2013-04-29</created><authors><author><keyname>Wei</keyname><forenames>Yun</forenames></author><author><keyname>Ji</keyname><forenames>Chuanyi</forenames></author><author><keyname>Galvan</keyname><forenames>Floyd</forenames></author><author><keyname>Couvillon</keyname><forenames>Stephen</forenames></author><author><keyname>Orellana</keyname><forenames>George</forenames></author><author><keyname>Momoh</keyname><forenames>James</forenames></author></authors><title>Learning Geo-Temporal Non-Stationary Failure and Recovery of Power
  Distribution</title><categories>cs.SY cs.LG physics.soc-ph</categories><comments>12 pages, 12 figures, Accepted with minor revisions by TNNLS, Special
  Issue on Learning in Nonstationary and Evolving Environments. arXiv admin
  note: text overlap with arXiv:1202.4720</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smart energy grid is an emerging area for new applications of machine
learning in a non-stationary environment. Such a non-stationary environment
emerges when large-scale failures occur at power distribution networks due to
external disturbances such as hurricanes and severe storms. Power distribution
networks lie at the edge of the grid, and are especially vulnerable to external
disruptions. Quantifiable approaches are lacking and needed to learn
non-stationary behaviors of large-scale failure and recovery of power
distribution. This work studies such non-stationary behaviors in three aspects.
First, a novel formulation is derived for an entire life cycle of large-scale
failure and recovery of power distribution. Second, spatial-temporal models of
failure and recovery of power distribution are developed as geo-location based
multivariate non-stationary GI(t)/G(t)/Infinity queues. Third, the
non-stationary spatial-temporal models identify a small number of parameters to
be learned. Learning is applied to two real-life examples of large-scale
disruptions. One is from Hurricane Ike, where data from an operational network
is exact on failures and recoveries. The other is from Hurricane Sandy, where
aggregated data is used for inferring failure and recovery processes at one of
the impacted areas. Model parameters are learned using real data. Two findings
emerge as results of learning: (a) Failure rates behave similarly at the two
different provider networks for two different hurricanes but differently at the
geographical regions. (b) Both rapid- and slow-recovery are present for
Hurricane Ike but only slow recovery is shown for a regional distribution
network from Hurricane Sandy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7713</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7713</id><created>2013-04-29</created><authors><author><keyname>Flesia</keyname><forenames>Ana Georgina</forenames></author><author><keyname>Gimenez</keyname><forenames>Javier</forenames></author><author><keyname>Fiori</keyname><forenames>Elena Rufeil</forenames></author></authors><title>Markovian models for one dimensional structure estimation on heavily
  noisy imagery</title><categories>cs.CV stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radar (SAR) images often exhibit profound appearance variations due to a
variety of factors including clutter noise produced by the coherent nature of
the illumination. Ultrasound images and infrared images have similar cluttered
appearance, that make 1 dimensional structures, as edges and object boundaries
difficult to locate. Structure information is usually extracted in two steps:
first, building and edge strength mask classifying pixels as edge points by
hypothesis testing, and secondly estimating from that mask, pixel wide
connected edges. With constant false alarm rate (CFAR) edge strength detectors
for speckle clutter, the image needs to be scanned by a sliding window composed
of several differently oriented splitting sub-windows. The accuracy of edge
location for these ratio detectors depends strongly on the orientation of the
sub-windows. In this work we propose to transform the edge strength detection
problem into a binary segmentation problem in the undecimated wavelet domain,
solvable using parallel 1d Hidden Markov Models. For general dependency models,
exact estimation of the state map becomes computationally complex, but in our
model, exact MAP is feasible. The effectiveness of our approach is demonstrated
on simulated noisy real-life natural images with available ground truth, while
the strength of our output edge map is measured with Pratt's, Baddeley an Kappa
proficiency measures. Finally, analysis and experiments on three different
types of SAR images, with different polarizations, resolutions and textures,
illustrate that the proposed method can detect structure on SAR images
effectively, providing a very good start point for active contour methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7718</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7718</id><created>2013-04-29</created><authors><author><keyname>Hoy</keyname><forenames>Darrell</forenames></author><author><keyname>Jain</keyname><forenames>Kamal</forenames></author><author><keyname>Wilkens</keyname><forenames>Christopher A.</forenames></author></authors><title>A Dynamic Axiomatic Approach to First-Price Auctions</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first-price auction is popular in practice for its simplicity and
transparency. Moreover, its potential virtues grow in complex settings where
incentive compatible auctions may generate little or no revenue. Unfortunately,
the first-price auction is poorly understood in theory because equilibrium is
not {\em a priori} a credible predictor of bidder behavior.
  We take a dynamic approach to studying first-price auctions: rather than
basing performance guarantees solely on static equilibria, we study the
repeated setting and show that robust performance guarantees may be derived
from simple axioms of bidder behavior. For example, as long as a loser raises
her bid quickly, a standard first-price auction will generate at least as much
revenue as a second-price auction. We generalize this dynamic technique to
complex pay-your-bid auction settings and show that progressively stronger
assumptions about bidder behavior imply progressively stronger guarantees about
the auction's performance.
  Along the way, we find that the auctioneer's choice of bidding language is
critical when generalizing beyond the single-item setting, and we propose a
specific construction called the {\em utility-target auction} that performs
well. The utility-target auction includes a bidder's final utility as an
additional parameter, identifying the single dimension along which she wishes
to compete. This auction is closely related to profit-target bidding in
first-price and ascending proxy package auctions and gives strong revenue
guarantees for a variety of complex auction environments. Of particular
interest, the guaranteed existence of a pure-strategy equilibrium in the
utility-target auction shows how Overture might have eliminated the cyclic
behavior in their generalized first-price sponsored search auction if bidders
could have placed more sophisticated bids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7727</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7727</id><created>2013-04-29</created><updated>2013-05-09</updated><authors><author><keyname>Neely</keyname><forenames>Michael J.</forenames></author></authors><title>Distributed stochastic optimization via correlated scheduling</title><categories>math.OC cs.MA</categories><comments>16 pages, 5 figures, this version adds an appendix to explain the 2BD
  derivation at the end of Theorem 3</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a problem where multiple users make repeated decisions
based on their own observed events. The events and decisions at each time step
determine the values of a utility function and a collection of penalty
functions. The goal is to make distributed decisions over time to maximize time
average utility subject to time average constraints on the penalties. An
example is a collection of power constrained sensor nodes that repeatedly
report their own observations to a fusion center. Maximum time average utility
is fundamentally reduced because users do not know the events observed by
others. Optimality is characterized for this distributed context. It is shown
that optimality is achieved by correlating user decisions through a commonly
known pseudorandom sequence. An optimal algorithm is developed that chooses
pure strategies at each time step based on a set of time-varying weights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7728</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7728</id><created>2013-04-29</created><authors><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author><author><keyname>Borgohain</keyname><forenames>Rajdeep</forenames></author></authors><title>Machine Translation Systems in India</title><categories>cs.CL cs.CY</categories><comments>5 pages, 5 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine Translation is the translation of one natural language into another
using automated and computerized means. For a multilingual country like India,
with the huge amount of information exchanged between various regions and in
different languages in digitized format, it has become necessary to find an
automated process from one language to another. In this paper, we take a look
at the various Machine Translation System in India which is specifically built
for the purpose of translation between the Indian languages. We discuss the
various approaches taken for building the machine translation system and then
discuss some of the Machine Translation Systems in India along with their
features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7745</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7745</id><created>2013-04-29</created><authors><author><keyname>Krishnamurthy</keyname><forenames>Sundar R.</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>On the Capacity of the Finite Field Counterparts of Wireless
  Interference Networks</title><categories>cs.IT math.IT</categories><comments>Full version of paper accepted for presentation at ISIT 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work explores how degrees of freedom (DoF) results from wireless
networks can be translated into capacity results for their finite field
counterparts that arise in network coding applications. The main insight is
that scalar (SISO) finite field channels over $\mathbb{F}_{p^n}$ are analogous
to n x n vector (MIMO) channels in the wireless setting, but with an important
distinction -- there is additional structure due to finite field arithmetic
which enforces commutativity of matrix multiplication and limits the channel
diversity to n, making these channels similar to diagonal channels in the
wireless setting. Within the limits imposed by the channel structure, the DoF
optimal precoding solutions for wireless networks can be translated into
capacity optimal solutions for their finite field counterparts. This is shown
through the study of the 2-user X channel and the 3-user interference channel.
Besides bringing the insights from wireless networks into network coding
applications, the study of finite field networks over $\mathbb{F}_{p^n}$ also
touches upon important open problems in wireless networks (finite SNR, finite
diversity scenarios) through interesting parallels between p and SNR, and n and
diversity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7750</identifier>
 <datestamp>2014-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7750</id><created>2013-04-29</created><authors><author><keyname>Dai</keyname><forenames>Xin-Rong</forenames></author><author><keyname>Sun</keyname><forenames>Qiyu</forenames></author></authors><title>The $abc$-problem for Gabor systems</title><categories>cs.IT math.DS math.FA math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Gabor system generated by a window function $\phi$ and a rectangular
lattice $a \Z\times \Z/b$ is given by $${\mathcal G}(\phi, a \Z\times
\Z/b):=\{e^{-2\pi i n t/b} \phi(t- m a):\ (m, n)\in \Z\times \Z\}.$$ One of
fundamental problems in Gabor analysis is to identify window functions $\phi$
and time-frequency shift lattices $a \Z\times \Z/b$ such that the corresponding
Gabor system ${\mathcal G}(\phi, a \Z\times \Z/b)$ is a Gabor frame for
$L^2(\R)$, the space of all square-integrable functions on the real line $\R$.
In this paper, we provide a full classification of triples $(a,b,c)$ for which
the Gabor system ${\mathcal G}(\chi_I, a \Z\times \Z/b)$ generated by the ideal
window function $\chi_I$ on an interval $I$ of length $c$ is a Gabor frame for
$L^2(\R)$. For the classification of such triples $(a, b, c)$ (i.e., the
$abc$-problem for Gabor systems), we introduce maximal invariant sets of some
piecewise linear transformations and establish the equivalence between Gabor
frame property and triviality of maximal invariant sets. We then study dynamic
system associated with the piecewise linear transformations and explore various
properties of their maximal invariant sets. By performing holes-removal surgery
for maximal invariant sets to shrink and augmentation operation for a line with
marks to expand, we finally parameterize those triples $(a, b, c)$ for which
maximal invariant sets are trivial. The novel techniques involving
non-ergodicity of dynamical systems associated with some novel non-contractive
and non-measure-preserving transformations lead to our arduous answer to the
$abc$-problem for Gabor systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7751</identifier>
 <datestamp>2015-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7751</id><created>2013-04-29</created><updated>2015-04-22</updated><authors><author><keyname>Chen</keyname><forenames>Yuxin</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Minimax Capacity Loss under Sub-Nyquist Universal Sampling</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory. It has been
  presented in part at the IEEE International Symposium on Information Theory
  (ISIT) 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the information rate loss in analog channels when the
sampler is designed to operate independent of the instantaneous channel
occupancy. Specifically, a multiband linear time-invariant Gaussian channel
under universal sub-Nyquist sampling is considered. The entire channel
bandwidth is divided into $n$ subbands of equal bandwidth. At each time only
$k$ constant-gain subbands are active, where the instantaneous subband
occupancy is not known at the receiver and the sampler. We study the
information loss through a capacity loss metric, that is, the capacity gap
caused by the lack of instantaneous subband occupancy information. We
characterize the minimax capacity loss for the entire sub-Nyquist rate regime,
provided that the number $n$ of subbands and the SNR are both large. The
minimax limits depend almost solely on the band sparsity factor and the
undersampling factor, modulo some residual terms that vanish as $n$ and SNR
grow. Our results highlight the power of randomized sampling methods (i.e. the
samplers that consist of random periodic modulation and low-pass filters),
which are able to approach the minimax capacity loss with exponentially high
probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7755</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7755</id><created>2013-04-29</created><updated>2013-11-18</updated><authors><author><keyname>Pucha&#x142;a</keyname><forenames>Zbigniew</forenames></author><author><keyname>Rudnicki</keyname><forenames>&#x141;ukasz</forenames></author><author><keyname>&#x17b;yczkowski</keyname><forenames>Karol</forenames></author></authors><title>Majorization entropic uncertainty relations</title><categories>quant-ph cs.IT math.IT</categories><comments>Published version</comments><journal-ref>J. Phys. A: Math. Theor. 46 272002 (2013)</journal-ref><doi>10.1088/1751-8113/46/27/272002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Entropic uncertainty relations in a finite dimensional Hilbert space are
investigated. Making use of the majorization technique we derive explicit lower
bounds for the sum of R\'enyi entropies describing probability distributions
associated with a given pure state expanded in eigenbases of two observables.
Obtained bounds are expressed in terms of the largest singular values of
submatrices of the unitary rotation matrix. Numerical simulations show that for
a generic unitary matrix of size N = 5 our bound is stronger than the well
known result of Maassen and Uffink (MU) with a probability larger than 98%. We
also show that the bounds investigated are invariant under the dephasing and
permutation operations. Finally, we derive a classical analogue of the MU
uncertainty relation, which is formulated for stochastic transition matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7788</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7788</id><created>2013-04-29</created><authors><author><keyname>Sahai</keyname><forenames>Esha</forenames></author><author><keyname>Watts</keyname><forenames>Ken</forenames></author><author><keyname>Adrion</keyname><forenames>Rick</forenames></author></authors><title>Extending Record and Playback Technologies to Support Cooperative
  Learning</title><categories>cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have long-term experience with developing and employing multimedia
materials for on-campus and distance education. We also are assessing the
efficacy of cooperative learning where groups of learners explore, with
guidance from an instructor, the learning environment and construct models of
meaning based on their shared learning experiences. Our core technologies
capture and store classroom events, but are record-and-playback technologies
focused on delivering content to individual learners. We describe an extension
of our technology, Cooperative Learning in MANIC (CLIMANIC), which allows
groups of learners and teachers to collaborate and communicate. We describe our
current assessment of CLIMANIC and future plans for more extensive evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7793</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7793</id><created>2013-04-29</created><authors><author><keyname>Aupy</keyname><forenames>Guillaume</forenames></author><author><keyname>Shantharam</keyname><forenames>Manu</forenames></author><author><keyname>Benoit</keyname><forenames>Anne</forenames></author><author><keyname>Robert</keyname><forenames>Yves</forenames></author><author><keyname>Raghavan</keyname><forenames>Padma</forenames></author></authors><title>Co-Scheduling Algorithms for High-Throughput Workload Execution</title><categories>cs.DS cs.DC</categories><report-no>INRIA RR-8293</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates co-scheduling algorithms for processing a set of
parallel applications. Instead of executing each application one by one, using
a maximum degree of parallelism for each of them, we aim at scheduling several
applications concurrently. We partition the original application set into a
series of packs, which are executed one by one. A pack comprises several
applications, each of them with an assigned number of processors, with the
constraint that the total number of processors assigned within a pack does not
exceed the maximum number of available processors. The objective is to
determine a partition into packs, and an assignment of processors to
applications, that minimize the sum of the execution times of the packs. We
thoroughly study the complexity of this optimization problem, and propose
several heuristics that exhibit very good performance on a variety of
workloads, whose application execution times model profiles of parallel
scientific codes. We show that co-scheduling leads to to faster workload
completion time and to faster response times on average (hence increasing
system throughput and saving energy), for significant benefits over traditional
scheduling from both the user and system perspectives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7799</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7799</id><created>2013-04-29</created><updated>2015-04-01</updated><authors><author><keyname>Atre</keyname><forenames>Medha</forenames></author></authors><title>Left Bit Right: For SPARQL Join Queries with OPTIONAL Patterns
  (Left-outer-joins)</title><categories>cs.DB</categories><comments>SIGMOD 2015</comments><acm-class>H.2.4</acm-class><doi>10.1145/2723372.2746483</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  SPARQL basic graph pattern (BGP) (a.k.a. SQL inner-join) query optimization
is a well researched area. However, optimization of OPTIONAL pattern queries
(a.k.a. SQL left-outer-joins) poses additional challenges, due to the
restrictions on the \textit{reordering} of left-outer-joins. The occurrence of
such queries tends to be as high as 50% of the total queries (e.g., DBPedia
query logs).
  In this paper, we present \textit{Left Bit Right} (LBR), a technique for
\textit{well-designed} nested BGP and OPTIONAL pattern queries. Through LBR, we
propose a novel method to represent such queries using a graph of
\textit{supernodes}, which is used to aggressively prune the RDF triples, with
the help of compressed indexes. We also propose novel optimization strategies
-- first of a kind, to the best of our knowledge -- that combine together the
characteristics of \textit{acyclicity} of queries, \textit{minimality}, and
\textit{nullification}, \textit{best-match} operators. In this paper, we focus
on OPTIONAL patterns without UNIONs or FILTERs, but we also show how UNIONs and
FILTERs can be handled with our technique using a \textit{query rewrite}. Our
evaluation on RDF graphs of up to and over one billion triples, on a commodity
laptop with 8 GB memory, shows that LBR can process \textit{well-designed}
low-selectivity complex queries up to 11 times faster compared to the
state-of-the-art RDF column-stores as Virtuoso and MonetDB, and for highly
selective queries, LBR is at par with them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7804</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7804</id><created>2013-04-29</created><updated>2013-05-01</updated><authors><author><keyname>Doty</keyname><forenames>David</forenames></author></authors><title>Producibility in hierarchical self-assembly</title><categories>cs.DS cs.CC cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Three results are shown on producibility in the hierarchical model of tile
self-assembly. It is shown that a simple greedy polynomial-time strategy
decides whether an assembly A is producible. The algorithm can be optimized to
use O(|A| log^2 |A|) time. Cannon, Demaine, Demaine, Eisenstat, Patitz,
Schweller, Summers, and Winslow showed that the problem of deciding if an
assembly A is the unique producible terminal assembly of a tile system T can be
solved in O(|A|^2 |T| + |A| |T|^2) time for the special case of noncooperative
&quot;temperature 1&quot; systems. It is shown that this can be improved to O(|A| |T| log
|T|) time. Finally, it is shown that if two assemblies are producible, and if
they can be overlapped consistently -- i.e., if the positions that they share
have the same tile type in each assembly -- then their union is also
producible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7819</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7819</id><created>2013-04-29</created><authors><author><keyname>Scott</keyname><forenames>Michael 'Adrir'</forenames></author></authors><title>Vocalnayno: Designing a Game-Based Intervention to Support Reading
  Development in Primary Schools</title><categories>cs.CY cs.HC</categories><comments>Presented at the 6th European Conference on Games-Based Learning, Oct
  4-5, 2012, Cork, Ireland</comments><acm-class>K.3.1</acm-class><journal-ref>Proceedings of the 6th European Conference on Games-Based
  Learning. ACPI: Reading, UK. 654--657</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Encouraging children to read frequently and helping them to develop their
reading skills as effectively as possible can be a challenge for some primary
schools. This research questions whether the use of a game-based intervention
can integrate into the existing teaching culture to aid volunteer teaching
assistants in achieving a more significant impact on pupil reading development.
A prototype based on the initial process of requirements gathering is presented
using Multimedia Fusion Developer 2. The design incorporates a game-like
exercise where a foam volcano character releases bubbles containing letters and
words. Pupils must read these aloud in order to burst them open, which is
recorded as a metric of reading ability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7820</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7820</id><created>2013-04-29</created><updated>2013-05-04</updated><authors><author><keyname>Ding</keyname><forenames>Jianguo</forenames></author><author><keyname>Bouvry</keyname><forenames>Pascal</forenames></author></authors><title>Challenges on Probabilistic Modeling for Evolving Networks</title><categories>cs.SI cs.AI physics.soc-ph</categories><comments>18 pages. Book chapter. arXiv admin note: text overlap with
  arXiv:1012.0009 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the emerging of new networks, such as wireless sensor networks, vehicle
networks, P2P networks, cloud computing, mobile Internet, or social networks,
the network dynamics and complexity expands from system design, hardware,
software, protocols, structures, integration, evolution, application, even to
business goals. Thus the dynamics and uncertainty are unavoidable
characteristics, which come from the regular network evolution and unexpected
hardware defects, unavoidable software errors, incomplete management
information and dependency relationship between the entities among the emerging
complex networks. Due to the complexity of emerging networks, it is not always
possible to build precise models in modeling and optimization (local and
global) for networks. This paper presents a survey on probabilistic modeling
for evolving networks and identifies the new challenges which emerge on the
probabilistic models and optimization strategies in the potential application
areas of network performance, network management and network security for
evolving networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7833</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7833</id><created>2013-04-29</created><authors><author><keyname>Dai</keyname><forenames>Bang-Sin</forenames></author><author><keyname>Kao</keyname><forenames>Mong-Jen</forenames></author><author><keyname>Lee</keyname><forenames>D. T.</forenames></author></authors><title>Optimal Time-Convex Hull under the Lp Metrics</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of computing the time-convex hull of a point set
under the general $L_p$ metric in the presence of a straight-line highway in
the plane. The traveling speed along the highway is assumed to be faster than
that off the highway, and the shortest time-path between a distant pair may
involve traveling along the highway. The time-convex hull ${TCH}(P)$ of a point
set $P$ is the smallest set containing both $P$ and \emph{all} shortest
time-paths between any two points in ${TCH}(P)$. In this paper we give an
algorithm that computes the time-convex hull under the $L_p$ metric in optimal
$O(n\log n)$ time for a given set of $n$ points and a real number $p$ with
$1\le p \le \infty$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7842</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7842</id><created>2013-04-29</created><authors><author><keyname>Gobithaasan</keyname><forenames>R. U.</forenames></author><author><keyname>Ali</keyname><forenames>J. M.</forenames></author><author><keyname>Miura</keyname><forenames>Kenjiro T.</forenames></author></authors><title>The Logarithmic Curvature Graphs of Generalised Cornu Spirals</title><categories>cs.GR</categories><journal-ref>2012 Punjab University Journal of Mathematics, 44, Pg.1-8</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Generalized Cornu Spiral (GCS) was first proposed by Ali et al. in 1995
[9]. Due to the monotonocity of its curvature function, the surface generated
with GCS segments has been considered as a high quality surface and it has
potential applications in surface design [2]. In this paper, the analysis of
GCS segment is carried out by determining its aesthetic value using the log
curvature Graph (LCG) as proposed by Kanaya et al.[10]. The analysis of LCG
supports the claim that GCS is indeed a generalized aesthetic curve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7843</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7843</id><created>2013-04-29</created><authors><author><keyname>Ahmad</keyname><forenames>Azruddin</forenames></author><author><keyname>Rudrusamy</keyname><forenames>Gobithasan</forenames></author><author><keyname>Budiarto</keyname><forenames>Rahmat</forenames></author><author><keyname>Samsudin</keyname><forenames>Azman</forenames></author><author><keyname>Ramadass</keyname><forenames>Sureswaran</forenames></author></authors><title>A Hybrid Rule Based Fuzzy-Neural Expert System For Passive Network
  Monitoring</title><categories>cs.AI cs.NI</categories><journal-ref>2002 Proceedings of the Arab Conference on Information Technology
  ACIT 2002, Dhaka, Pg.746-752</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An enhanced approach for network monitoring is to create a network monitoring
tool that has artificial intelligence characteristics. There are a number of
approaches available. One such approach is by the use of a combination of rule
based, fuzzy logic and neural networks to create a hybrid ANFIS system. Such
system will have a dual knowledge database approach. One containing membership
function values to compare to and do deductive reasoning and another database
with rules deductively formulated by an expert (a network administrator). The
knowledge database will be updated continuously with newly acquired patterns.
In short, the system will be composed of 2 parts, learning from data sets and
fine-tuning the knowledge-base using neural network and the use of fuzzy logic
in making decision based on the rules and membership functions inside the
knowledge base. This paper will discuss the idea, steps and issues involved in
creating such a system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7845</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7845</id><created>2013-04-29</created><authors><author><keyname>Ahmad</keyname><forenames>Azhar</forenames></author><author><keyname>Gobithasan</keyname><forenames>R.</forenames></author><author><keyname>Ali</keyname><forenames>Jamaluddin Md.</forenames></author></authors><title>G2 Transition curve using Quartic Bezier Curve</title><categories>cs.GR</categories><journal-ref>2007 Computer Graphics, Imaging and Visualization CGIV 2007, Pg.
  223-228</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method to construct transition curves using a family of the quartic Bezier
spiral is described. The transition curves discussed are S-shape and C-shape of
contact, between two separated circles. A spiral is a curve of monotone
increasing or monotone decreasing curvature of one sign. Thus, a spiral cannot
have an inflection point or curvature extreme. The family of quartic Bezier
spiral form which is introduced has more degrees of freedom and will give a
better approximation. It is proved that the methods of constructing transition
curves can be simplified by the transformation process and the ratio of two
radii has no restriction, which extends the application area, and it gives a
family of transition curves that allow more flexible curve designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7846</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7846</id><created>2013-04-29</created><updated>2013-09-10</updated><authors><author><keyname>Robins</keyname><forenames>Vanessa</forenames></author></authors><title>Algebraic Topology</title><categories>math-ph cs.CG math.AT math.MP</categories><comments>This manuscript will be published as Chapter 5 in Wiley's textbook
  \emph{Mathematical Tools for Physicists}, 2nd edition, edited by Michael
  Grinfeld from the University of Strathclyde</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The chapter provides an introduction to the basic concepts of Algebraic
Topology with an emphasis on motivation from applications in the physical
sciences. It finishes with a brief review of computational work in algebraic
topology, including persistent homology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7848</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7848</id><created>2013-04-29</created><authors><author><keyname>Ahmad</keyname><forenames>Azhar</forenames></author><author><keyname>Gobithasan</keyname><forenames>R.</forenames></author><author><keyname>Ali</keyname><forenames>Jamaluddin Md.</forenames></author></authors><title>Characterization of Planar Cubic Alternative curve</title><categories>cs.GR</categories><journal-ref>2009 Journal of Mathematika, Vol. 25, Nu.2, Pg. 125-134</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the planar cubic Alternative curve to determine the
conditions for convex, loops, cusps and inflection points. Thus cubic curve is
represented by linear combination of three control points and basis function
that consist of two shape parameters. By using algebraic manipulation, we can
determine the constraint of shape parameters and sufficient conditions are
derived which ensure that the curve is a strictly convex, loops, cusps and
inflection point. We conclude the result in a shape diagram of parameters. The
simplicity of this form makes characterization more intuitive and efficient to
compute.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7851</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7851</id><created>2013-04-29</created><updated>2013-06-06</updated><authors><author><keyname>Abousleiman</keyname><forenames>Rami</forenames></author><author><keyname>Qu</keyname><forenames>Guangzhi</forenames></author><author><keyname>Rawashdeh</keyname><forenames>Osamah</forenames></author></authors><title>North Atlantic Right Whale Contact Call Detection</title><categories>cs.LG cs.SD</categories><comments>6 pages, ICML 2013 Workshop on Machine Learning for Bioacoustics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The North Atlantic right whale (Eubalaena glacialis) is an endangered
species. These whales continuously suffer from deadly vessel impacts alongside
the eastern coast of North America. There have been countless efforts to save
the remaining 350 - 400 of them. One of the most prominent works is done by
Marinexplore and Cornell University. A system of hydrophones linked to
satellite connected-buoys has been deployed in the whales habitat. These
hydrophones record and transmit live sounds to a base station. These recording
might contain the right whale contact call as well as many other noises. The
noise rate increases rapidly in vessel-busy areas such as by the Boston harbor.
This paper presents and studies the problem of detecting the North Atlantic
right whale contact call with the presence of noise and other marine life
sounds. A novel algorithm was developed to preprocess the sound waves before a
tree based hierarchical classifier is used to classify the data and provide a
score. The developed model was trained with 30,000 data points made available
through the Cornell University Whale Detection Challenge program. Results
showed that the developed algorithm had close to 85% success rate in detecting
the presence of the North Atlantic right whale.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7852</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7852</id><created>2013-04-29</created><authors><author><keyname>Miura</keyname><forenames>K. T.</forenames></author><author><keyname>Shirahata</keyname><forenames>R.</forenames></author><author><keyname>Agari</keyname><forenames>S.</forenames></author><author><keyname>Usuki</keyname><forenames>S.</forenames></author><author><keyname>Gobithaasan</keyname><forenames>R. U.</forenames></author></authors><title>Variational Formulation of the Log-Aesthetic Surface and Development of
  Discrete Surface Filters</title><categories>cs.GR</categories><journal-ref>2012 Computer Aided Design &amp; Application, Vol.9 (6), Pg.901-914</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The log-aesthetic curves include the logarithmic (equiangular) spiral,
clothoid, and involute curves. Although most of them are expressed only by an
integral form of the tangent vector, it is possible to interactively generate
and deform them and they are expected to be utilized for practical use of
industrial and graphical design. The discrete log-aesthetic filter based on the
formulation of the log-aesthetic curve has successfully been introduced not to
impose strong constraints on the designer's activity, to let him/her design
freely and to embed the properties of the log-aesthetic curves for complicated
ones with both increasing and decreasing curvature. In this paper, in order to
define the log-aesthetic surface and develop surface filters based on its
formulation, at first we reformulate the log-aesthetic curve with variational
principle. Then we propose several new functionals to be minimized for
free-form surfaces and define the log-aesthetic surface. Furthermore we propose
new discrete surface filters based on the log-aesthetic surface formulation
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7854</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7854</id><created>2013-04-30</created><updated>2013-05-26</updated><authors><author><keyname>Bertossi</keyname><forenames>Leopoldo</forenames></author><author><keyname>Gardezi</keyname><forenames>Jaffer</forenames></author></authors><title>On the Complexity of Query Answering under Matching Dependencies for
  Entity Resolution</title><categories>cs.DB</categories><comments>To appear in Proc. of the Alberto Mendelzon International Workshop on
  Foundations of Data Management (AMW 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matching Dependencies (MDs) are a relatively recent proposal for declarative
entity resolution. They are rules that specify, given the similarities
satisfied by values in a database, what values should be considered duplicates,
and have to be matched. On the basis of a chase-like procedure for MD
enforcement, we can obtain clean (duplicate-free) instances; actually possibly
several of them. The resolved answers to queries are those that are invariant
under the resulting class of resolved instances. In previous work we identified
some tractable cases (i.e. for certain classes of queries and MDs) of resolved
query answering. In this paper we further investigate the complexity of this
problem, identifying some intractable cases. For a special case we obtain a
dichotomy complexity result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7855</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7855</id><created>2013-04-30</created><authors><author><keyname>Kaufmann</keyname><forenames>Matt</forenames><affiliation>University of Texas at Austin</affiliation></author><author><keyname>Moore</keyname><forenames>J Strother</forenames><affiliation>University of Texas at Austin</affiliation></author></authors><title>Enhancements to ACL2 in Versions 5.0, 6.0, and 6.1</title><categories>cs.MS cs.AI cs.LO</categories><comments>In Proceedings ACL2 2013, arXiv:1304.7123</comments><proxy>EPTCS</proxy><acm-class>F.4.1; I.2.3; G.4</acm-class><journal-ref>EPTCS 114, 2013, pp. 5-12</journal-ref><doi>10.4204/EPTCS.114.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report on highlights of the ACL2 enhancements introduced in ACL2 releases
since the 2011 ACL2 Workshop. Although many enhancements are critical for
soundness or robustness, we focus in this paper on those improvements that
could benefit users who are aware of them, but that might not be discovered in
everyday practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7856</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7856</id><created>2013-04-30</created><authors><author><keyname>Eggensperger</keyname><forenames>Caleb</forenames></author></authors><title>Proof Pad: A New Development Environment for ACL2</title><categories>cs.SE cs.HC cs.PL</categories><comments>In Proceedings ACL2 2013, arXiv:1304.7123</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 114, 2013, pp. 13-28</journal-ref><doi>10.4204/EPTCS.114.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most software development projects rely on Integrated Development
Environments (IDEs) based on the desktop paradigm, with an interactive,
mouse-driven user interface. The standard installation of ACL2, on the other
hand, is designed to work closely with Emacs. ACL2 experts, on the whole, like
this mode of operation, but students and other new programmers who have learned
to program with desktop IDEs often react negatively to the process of adapting
to an unfamiliar form of interaction.
  This paper discusses Proof Pad, a new IDE for ACL2. Proof Pad is not the only
attempt to provide ACL2 IDEs catering to students and beginning programmers.
The ACL2 Sedan and DrACuLa systems arose from similar motivations. Proof Pad
builds on the work of those systems, while also taking into account the unique
workflow of the ACL2 theorem proving system.
  The design of Proof Pad incorporated user feedback from the outset, and that
process continued through all stages of development. Feedback took the form of
direct observation of users interacting with the IDE as well as questionnaires
completed by users of Proof Pad and other ACL2 IDEs. The result is a
streamlined interface and fast, responsive system that supports using ACL2 as a
programming language and a theorem proving system. Proof Pad also provides a
property-based testing environment with random data generation and automated
interpretation of properties as ACL2 theorem definitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7857</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7857</id><created>2013-04-30</created><authors><author><keyname>Greve</keyname><forenames>David</forenames><affiliation>Rockwell Collins</affiliation></author><author><keyname>Slind</keyname><forenames>Konrad</forenames><affiliation>Rockwell Collins</affiliation></author></authors><title>A Step-Indexing Approach to Partial Functions</title><categories>cs.LO</categories><comments>In Proceedings ACL2 2013, arXiv:1304.7123</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 114, 2013, pp. 42-53</journal-ref><doi>10.4204/EPTCS.114.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an ACL2 package for defining partial recursive functions that
also supports efficient execution. While packages for defining partial
recursive functions already exist for other theorem provers, they often require
inductive definitions or recursion operators which are not available in ACL2
and they provide little, if any, support for executing the resulting
definitions. We use step-indexing as the underlying implementation technology,
enabling the definitions to be carried out in first order logic. We also show
how recent enhancements to ACL2's guard feature can be used to enable the
efficient execution of partial recursive functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7858</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7858</id><created>2013-04-30</created><authors><author><keyname>Goel</keyname><forenames>Shilpi</forenames><affiliation>Department of Computer Science, University of Texas at Austin</affiliation></author><author><keyname>Hunt,</keyname><forenames>Warren A</forenames><suffix>Jr.</suffix><affiliation>Department of Computer Science, University of Texas at Austin</affiliation></author><author><keyname>Kaufmann</keyname><forenames>Matt</forenames><affiliation>Department of Computer Science, University of Texas at Austin</affiliation></author></authors><title>Abstract Stobjs and Their Application to ISA Modeling</title><categories>cs.LO cs.AR cs.SC</categories><comments>In Proceedings ACL2 2013, arXiv:1304.7123</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 114, 2013, pp. 54-69</journal-ref><doi>10.4204/EPTCS.114.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new ACL2 feature, the abstract stobj, and show how to apply it
to modeling the instruction set architecture of a microprocessor. Benefits of
abstract stobjs over traditional (&quot;concrete&quot;) stobjs can include faster
execution, support for symbolic simulation, more efficient reasoning, and
resilience of proof developments under modeling optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7859</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7859</id><created>2013-04-30</created><authors><author><keyname>Verbeek</keyname><forenames>Freek</forenames><affiliation>Open University of The Netherlands</affiliation></author><author><keyname>Schmaltz</keyname><forenames>Julien</forenames><affiliation>Open University of The Netherlands</affiliation></author></authors><title>Verification of Building Blocks for Asynchronous Circuits</title><categories>cs.LO</categories><comments>In Proceedings ACL2 2013, arXiv:1304.7123</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 114, 2013, pp. 70-84</journal-ref><doi>10.4204/EPTCS.114.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scalable formal verification constitutes an important challenge for the
design of asynchronous circuits. Deadlock freedom is a property that is desired
but hard to verify. It is an emergent property that has to be verified
monolithically. We present our approach to using ACL2 to verify necessary and
sufficient conditions over asynchronous delay-insensitive primitives. These
conditions are used to derive SAT/SMT instances from circuits built out of
these primitives. These SAT/SMT instances help in establishing absence of
deadlocks. Our verification effort consists of building an executable checker
in the ACL2 logic tailored for our purpose. We prove that this checker is
correct. This approach enables us to prove ACL2 theorems involving defun-sk
constructs and free variables fully automatically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7860</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7860</id><created>2013-04-30</created><authors><author><keyname>Helms</keyname><forenames>Lucas</forenames><affiliation>University of Wyoming</affiliation></author><author><keyname>Gamboa</keyname><forenames>Ruben</forenames><affiliation>University of Wyoming</affiliation></author></authors><title>An Interpreter for Quantum Circuits</title><categories>cs.LO quant-ph</categories><comments>In Proceedings ACL2 2013, arXiv:1304.7123</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 114, 2013, pp. 85-94</journal-ref><doi>10.4204/EPTCS.114.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes an ACL2 interpreter for &quot;netlists&quot; describing quantum
circuits. Several quantum gates are implemented, including the Hadamard gate H,
which rotates vectors by 45 degrees, necessitating the use of irrational
numbers, at least at the logical level. Quantum measurement presents an
especially difficult challenge, because it requires precise comparisons of
irrational numbers and the use of random numbers. This paper does not address
computation with irrational numbers or the generation of random numbers,
although future work includes the development of pseudo-random generators for
ACL2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7861</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7861</id><created>2013-04-30</created><authors><author><keyname>Davis</keyname><forenames>Jared</forenames><affiliation>Centaur Technology</affiliation></author><author><keyname>Swords</keyname><forenames>Sol</forenames><affiliation>Centaur Technology</affiliation></author></authors><title>Verified AIG Algorithms in ACL2</title><categories>cs.LO cs.MS</categories><comments>In Proceedings ACL2 2013, arXiv:1304.7123</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 114, 2013, pp. 95-110</journal-ref><doi>10.4204/EPTCS.114.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  And-Inverter Graphs (AIGs) are a popular way to represent Boolean functions
(like circuits). AIG simplification algorithms can dramatically reduce an AIG,
and play an important role in modern hardware verification tools like
equivalence checkers. In practice, these tricky algorithms are implemented with
optimized C or C++ routines with no guarantee of correctness. Meanwhile, many
interactive theorem provers can now employ SAT or SMT solvers to automatically
solve finite goals, but no theorem prover makes use of these advanced,
AIG-based approaches.
  We have developed two ways to represent AIGs within the ACL2 theorem prover.
One representation, Hons-AIGs, is especially convenient to use and reason
about. The other, Aignet, is the opposite; it is styled after modern AIG
packages and allows for efficient algorithms. We have implemented functions for
converting between these representations, random vector simulation, conversion
to CNF, etc., and developed reasoning strategies for verifying these
algorithms.
  Aside from these contributions towards verifying AIG algorithms, this work
has an immediate, practical benefit for ACL2 users who are using GL to
bit-blast finite ACL2 theorems: they can now optionally trust an off-the-shelf
SAT solver to carry out the proof, instead of using the built-in BDD package.
Looking to the future, it is a first step toward implementing verified AIG
simplification algorithms that might further improve GL performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7862</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7862</id><created>2013-04-30</created><authors><author><keyname>van Gastel</keyname><forenames>Bernard</forenames><affiliation>Open University of the Netherlands</affiliation></author><author><keyname>Schmaltz</keyname><forenames>Julien</forenames><affiliation>Open University of the Netherlands</affiliation></author></authors><title>A formalisation of XMAS</title><categories>cs.AR cs.LO</categories><comments>In Proceedings ACL2 2013, arXiv:1304.7123</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 114, 2013, pp. 111-126</journal-ref><doi>10.4204/EPTCS.114.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communication fabrics play a key role in the correctness and performance of
modern multi-core processors and systems-on-chip. To enable formal
verification, a recent trend is to use high-level micro-architectural models to
capture designers' intent about the communication and processing of messages.
Intel proposed the xMAS language to support the formal definition of executable
specifications of micro-architectures. We formalise the semantics of xMAS in
ACL2. Our formalisation represents the computation of the values of all wires
of a design. Our main function computes a set of possible routing targets for
each message and whether a message can make progress according to the current
network state. We prove several properties on the semantics, including
termination, non-emptiness of routing, and correctness of progress conditions.
Our current effort focuses on a basic subset of the entire xMAS language, which
includes queues, functions, and switches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7863</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7863</id><created>2013-04-30</created><authors><author><keyname>Hardin</keyname><forenames>David S.</forenames><affiliation>Rockwell Collins</affiliation></author><author><keyname>Hardin</keyname><forenames>Samuel S.</forenames><affiliation>Iowa State University</affiliation></author></authors><title>ACL2 Meets the GPU: Formalizing a CUDA-based Parallelizable All-Pairs
  Shortest Path Algorithm in ACL2</title><categories>cs.LO cs.DS</categories><comments>In Proceedings ACL2 2013, arXiv:1304.7123</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 114, 2013, pp. 127-142</journal-ref><doi>10.4204/EPTCS.114.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As Graphics Processing Units (GPUs) have gained in capability and GPU
development environments have matured, developers are increasingly turning to
the GPU to off-load the main host CPU of numerically-intensive, parallelizable
computations. Modern GPUs feature hundreds of cores, and offer programming
niceties such as double-precision floating point, and even limited recursion.
This shift from CPU to GPU, however, raises the question: how do we know that
these new GPU-based algorithms are correct?
  In order to explore this new verification frontier, we formalized a
parallelizable all-pairs shortest path (APSP) algorithm for weighted graphs,
originally coded in NVIDIA's CUDA language, in ACL2. The ACL2 specification is
written using a single-threaded object (stobj) and tail recursion, as the
stobj/tail recursion combination yields the most straightforward translation
from imperative programming languages, as well as efficient, scalable
executable specifications within ACL2 itself. The ACL2 version of the APSP
algorithm can process millions of vertices and edges with little to no garbage
generation, and executes at one-sixth the speed of a host-based version of APSP
coded in C- a very respectable result for a theorem prover.
  In addition to formalizing the APSP algorithm (which uses Dijkstra's shortest
path algorithm at its core), we have also provided capability that the original
APSP code lacked, namely shortest path recovery. Path recovery is accomplished
using a secondary ACL2 stobj implementing a LIFO stack, which is proven
correct. To conclude the experiment, we ported the ACL2 version of the APSP
kernels back to C, resulting in a less than 5% slowdown, and also performed a
partial back-port to CUDA, which, surprisingly, yielded a slight performance
increase.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7864</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7864</id><created>2013-04-30</created><authors><author><keyname>Rudrusamy</keyname><forenames>Gobithasan</forenames></author><author><keyname>Ahmad</keyname><forenames>Azrudin</forenames></author><author><keyname>Budiarto</keyname><forenames>Rahmat</forenames></author><author><keyname>Samsudin</keyname><forenames>Azman</forenames></author><author><keyname>Ramadass</keyname><forenames>Sureswaran</forenames></author></authors><title>Fuzzy Based Diagnostics System for Identifying Network Traffic Flow
  Anomalies</title><categories>cs.NI</categories><journal-ref>2003 Proceedings of the International Conference of Robotics,
  Vision, Information and Signal Processing ROVISP, Penang, IEEE, Pg.190-195</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses the usage of network traffic properties in passive
network monitoring which are used in recognizing and identifying anomaly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7868</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7868</id><created>2013-04-30</created><authors><author><keyname>Zakaria</keyname><forenames>Rozaimi</forenames></author><author><keyname>Wahab</keyname><forenames>Abd. Fatah</forenames></author><author><keyname>Gobithaasan</keyname><forenames>R. U.</forenames></author></authors><title>Normal type-2 Fuzzy Rational B-Spline Curve</title><categories>cs.GR</categories><journal-ref>2013 Int. Journal of Math. Analysis, 7(16), Pg.789-806</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we proposed a new form of type-2 fuzzy data points(T2FDPs)
that is normal type-2 data points(NT2FDPs). These brand-new forms of data were
defined by using the definition of normal type-2 triangular fuzzy
number(NT2TFN). Then, we applied fuzzification(alpha-cut) and type-reduction
processes towards NT2FDPs after they had been redefined based on the situation
of NT2FDPs. Furthermore, we redefine the defuzzification definition along with
the new definitions of fuzzification process and type-reduction method to
obtain crisp type-2 fuzzy solution data points. For all these processes from
the defining the NT2FDPs to defuzzification of NT2FDPs, we demonstrate through
curve representation by using the rational B-spline curve function as the
example form modeling these NT2FDPs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7875</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7875</id><created>2013-04-30</created><authors><author><keyname>Joosten</keyname><forenames>Sebastiaan J. C.</forenames></author><author><keyname>van Gastel</keyname><forenames>Bernard</forenames></author><author><keyname>Schmaltz</keyname><forenames>Julien</forenames></author></authors><title>A Macro for Reusing Abstract Functions and Theorems</title><categories>cs.LO cs.PL</categories><comments>In Proceedings ACL2 2013, arXiv:1304.7123</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 114, 2013, pp. 29-41</journal-ref><doi>10.4204/EPTCS.114.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Even though the ACL2 logic is first order, the ACL2 system offers several
mechanisms providing users with some operations akin to higher order logic
ones. In this paper, we propose a macro, named instance-of-defspec, to ease the
reuse of abstract functions and facts proven about them. Defspec is an ACL2
book allowing users to define constrained functions and their associated
properties. It contains macros facilitating the definition of such abstract
specifications and instances thereof. Currently, lemmas and theorems derived
from these abstract functions are not automatically instantiated. This is
exactly the purpose of our new macro. instance-of-defspec will not only
instantiate functions and theorems within a specification but also many more
functions and theorems built on top of the specification. As a working example,
we describe various fold functions over monoids, which we gradually built from
arbitrary functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7881</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7881</id><created>2013-04-30</created><authors><author><keyname>Gobithaasan</keyname><forenames>R. U.</forenames></author></authors><title>Various Types of Aesthetic Curves</title><categories>cs.GR</categories><journal-ref>2011 The Proceedings of Seminar Bidang Kepakaran Jabatan Matematik
  2010, Cherating, Pahang. Disember 27th- 30th 2010, Pg.9-22</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The research on developing planar curves to produce visually pleasing
products (ranges from electric appliances to car body design) and
indentifying/modifying planar curves for special purposes namely for railway
design, highway design and robot trajectories have been progressing since
1970s. The pattern of research in this field of study has branched to five
major groups namely curve synthesis, fairing process, improvement in control of
natural spiral, construction of new type of planar curves and, natural spiral
fitting &amp; approximation techniques. The purpose of is this paper is to briefly
review recent progresses in Computer Aided Geometric Design (CAGD) focusing on
the topics states above.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7883</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7883</id><created>2013-04-30</created><authors><author><keyname>Gobithaasan</keyname><forenames>R. U.</forenames></author><author><keyname>Ali</keyname><forenames>Jamaludin Md.</forenames></author><author><keyname>Miura</keyname><forenames>Kenjiro T.</forenames></author></authors><title>An Improvised Algorithm to Identify The Beauty of A Planar Curve</title><categories>cs.GR</categories><journal-ref>2008 The Proceedings of Simposium Kebangsaan Sains Matematik ke-16
  (SKSM16), Kota Bharu, Kelantan. June 3rd-5th 2008, Pg.223-228</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An improvised algorithm is proposed based on the work of Yoshimoto and
Harada. The improvised algorithm results a graph which is called LDGC or
Logarithmic Distribution Graph of Curvature. This graph has the capability to
identify the beauty of monotonic planar curves with less effort as compared to
LDDC by Yoshimoto and Harada.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7886</identifier>
 <datestamp>2014-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7886</id><created>2013-04-30</created><updated>2014-07-21</updated><authors><author><keyname>Ju</keyname><forenames>Hyunsgsik</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Throughput Maximization in Wireless Powered Communication Networks</title><categories>cs.IT math.IT</categories><comments>26 pages, 12 figures</comments><journal-ref>IEEE Transactions on Wireless Communications, vol. 13, no. 1, pp.
  418-428, Jan. 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the newly emerging wireless powered communication network
(WPCN) in which one hybrid access point (H-AP) with constant power supply
coordinates the wireless energy/information transmissions to/from distributed
users that do not have energy sources. A &quot;harvest-then-transmit&quot; protocol is
proposed where all users first harvest the wireless energy broadcast by the
H-AP in the downlink (DL) and then send their independent information to the
H-AP in the uplink (UL) by time-division-multiple-access (TDMA). First, we
study the sum-throughput maximization of all users by jointly optimizing the
time allocation for the DL wireless power transfer versus the users' UL
information transmissions given a total time constraint based on the users' DL
and UL channels as well as their average harvested energy values. By applying
convex optimization techniques, we obtain the closed-form expressions for the
optimal time allocations to maximize the sum-throughput. Our solution reveals
&quot;doubly near-far&quot; phenomenon due to both the DL and UL distance-dependent
signal attenuation, where a far user from the H-AP, which receives less
wireless energy than a nearer user in the DL, has to transmit with more power
in the UL for reliable information transmission. Consequently, the maximum
sum-throughput is achieved by allocating substantially more time to the near
users than the far users, thus resulting in unfair rate allocation among
different users. To overcome this problem, we furthermore propose a new
performance metric so-called common-throughput with the additional constraint
that all users should be allocated with an equal rate regardless of their
distances to the H-AP. We present an efficient algorithm to solve the
common-throughput maximization problem. Simulation results demonstrate the
effectiveness of the common-throughput approach for solving the new doubly
near-far problem in WPCNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7889</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7889</id><created>2013-04-30</created><authors><author><keyname>Kayande</keyname><forenames>Deepali</forenames></author><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author></authors><title>Priority Based Pre-emptive Task Scheduling for Android Operating System</title><categories>cs.OH</categories><comments>Pages: 5 Figures : 10</comments><journal-ref>International Journal of Computer Science and Telecommunications
  (IJCST), Volume 2,Issue 7,October 2011,pg 17-21</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Android mobile operating system which is based on Linux Kernel 2.6, has open
source license and adaptability to user driven applications. As all other
operating systems it has all the basic features like process scheduling, memory
management, process management etc associated with it. Any mobile platform
works smoothly when the process scheduling is performed in a proper way. Ideal
platform is that in which no resource conflict occurs. Thus scheduling in every
manner is essential for the operating system to adapt itself with the
requirement of a particular application. In this paper, priority based
pre-emptive task scheduling is proposed for the SMS application. The idea is to
define High priority to required contacts, for ex. Contact numbers of parents
or teachers will be given High priority. If in case, any SMS from these High
priority contacts is received, the application would flash the SMS on the
active screen and redirect this High priority SMS to the Priority Inbox.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7920</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7920</id><created>2013-04-30</created><authors><author><keyname>Mooij</keyname><forenames>Joris M.</forenames></author><author><keyname>Janzing</keyname><forenames>Dominik</forenames></author><author><keyname>Sch&#xf6;lkopf</keyname><forenames>Bernhard</forenames></author></authors><title>From Ordinary Differential Equations to Structural Causal Models: the
  deterministic case</title><categories>stat.OT cs.AI</categories><comments>Submitted to UAI 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how, and under which conditions, the equilibrium states of a
first-order Ordinary Differential Equation (ODE) system can be described with a
deterministic Structural Causal Model (SCM). Our exposition sheds more light on
the concept of causality as expressed within the framework of Structural Causal
Models, especially for cyclic models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7928</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7928</id><created>2013-04-30</created><authors><author><keyname>Meissner</keyname><forenames>Paul</forenames></author><author><keyname>Leitinger</keyname><forenames>Erik</forenames></author><author><keyname>Fr&#xf6;hle</keyname><forenames>Markus</forenames></author><author><keyname>Witrisal</keyname><forenames>Klaus</forenames></author></authors><title>Accurate and Robust Indoor Localization Systems using Ultra-wideband
  Signals</title><categories>cs.ET cs.IT math.IT</categories><comments>Published at the European Navigation Conference (ENC) 2013, Vienna,
  Austria</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Indoor localization systems that are accurate and robust with respect to
propagation channel conditions are still a technical challenge today. In
particular, for systems based on range measurements from radio signals,
non-line-of-sight (NLOS) situations can result in large position errors. In
this paper, we address these issues using measurements in a representative
indoor environment. Results show that conventional tracking schemes using high-
and a low-complexity ranging algorithms are strongly impaired by NLOS
conditions unless a very large signal bandwidth is used. Furthermore, we
discuss and evaluate the performance of multipath-assisted indoor navigation
and tracking (MINT), that can overcome these impairments by making use of
multipath propagation. Across a wide range of bandwidths, MINT shows superior
performance compared to conventional schemes, and virtually no degradation in
its robustness due to NLOS conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7942</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7942</id><created>2013-04-30</created><authors><author><keyname>Filannino</keyname><forenames>Michele</forenames></author><author><keyname>Brown</keyname><forenames>Gavin</forenames></author><author><keyname>Nenadic</keyname><forenames>Goran</forenames></author></authors><title>ManTIME: Temporal expression identification and normalization in the
  TempEval-3 challenge</title><categories>cs.CL</categories><comments>5 pages, 1 figure, 2 tables Second Joint Conference on Lexical and
  Computational Semantics (*SEM), Volume 2: Seventh International Workshop on
  Semantic Evaluation (SemEval 2013)</comments><acm-class>I.2.7; I.2.4; I.2.6</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper describes a temporal expression identification and normalization
system, ManTIME, developed for the TempEval-3 challenge. The identification
phase combines the use of conditional random fields along with a
post-processing identification pipeline, whereas the normalization phase is
carried out using NorMA, an open-source rule-based temporal normalizer. We
investigate the performance variation with respect to different feature types.
Specifically, we show that the use of WordNet-based features in the
identification task negatively affects the overall performance, and that there
is no statistically significant difference in using gazetteers, shallow parsing
and propositional noun phrases labels on top of the morphological features. On
the test data, the best run achieved 0.95 (P), 0.85 (R) and 0.90 (F1) in the
identification phase. Normalization accuracies are 0.84 (type attribute) and
0.77 (value attribute). Surprisingly, the use of the silver data (alone or in
addition to the gold annotated ones) does not improve the performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7948</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7948</id><created>2013-04-30</created><updated>2013-06-02</updated><authors><author><keyname>Osendorfer</keyname><forenames>Christian</forenames></author><author><keyname>Bayer</keyname><forenames>Justin</forenames></author><author><keyname>van der Smagt</keyname><forenames>Patrick</forenames></author></authors><title>Convolutional Neural Networks learn compact local image descriptors</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A standard deep convolutional neural network paired with a suitable loss
function learns compact local image descriptors that perform comparably to
state-of-the art approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7959</identifier>
 <datestamp>2014-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7959</id><created>2013-04-30</created><updated>2014-04-24</updated><authors><author><keyname>Brodal</keyname><forenames>Gerth St&#xf8;lting</forenames></author><author><keyname>Larsen</keyname><forenames>Kasper Green</forenames></author></authors><title>Optimal Planar Orthogonal Skyline Counting Queries</title><categories>cs.DS</categories><comments>Full version of paper appearing in the proceedings of the 14th
  Scandinavian Symposium and Workshops on Algorithm Theory, 2014</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The skyline of a set of points in the plane is the subset of maximal points,
where a point $(x,y)$ is maximal if no other point $(x',y')$ satisfies $x'\ge
x$ and $y'\ge Y$. We consider the problem of preprocessing a set $P$ of $n$
points into a space efficient static data structure supporting orthogonal
skyline counting queries, i.e. given a query rectangle $R$ to report the size
of the skyline of $P$ intersected with $R$. We present a data structure for
storing n points with integer coordinates having query time $O(\lg n/\lg\lg n)$
and space usage $O(n)$. The model of computation is a unit cost RAM with
logarithmic word size. We prove that these bounds are the best possible by
presenting a lower bound in the cell probe model with logarithmic word size:
Space usage $n\lg^{O(1)} n$ implies worst case query time $\Omega(\lg n/\lg\lg
n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7966</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7966</id><created>2013-04-30</created><authors><author><keyname>Fang</keyname><forenames>Yi</forenames></author><author><keyname>Wang</keyname><forenames>Lin</forenames></author><author><keyname>Chen</keyname><forenames>Guanrong</forenames></author></authors><title>Performance of a Multiple-Access DCSK-CC System over Nakagami-$m$ Fading
  Channels</title><categories>cs.IT cs.PF math.IT</categories><comments>4 pages, 5 figures, accepted, IEEE ISCAS, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel cooperative scheme to enhance the
performance of multiple-access (MA) differential-chaos-shift-keying (DCSK)
systems. We provide the bit-error-rate (BER) performance and throughput
analyses for the new system with a decode-and-forward (DF) protocol over
Nakagami-$m$ fading channels. Our simulated results not only show that this
system significantly improves the BER performance as compared to the existing
DCSK non-cooperative (DCSK-NC) system and the multiple-input multiple-output
DCSK (MIMO-DCSK) system, but also verify the theoretical analyses. Furthermore,
we show that the throughput of this system approximately equals that of the
DCSK-NC system, both of which have prominent improvements over the MIMO-DCSK
system. We thus believe that the proposed system can be a good framework for
chaos-modulation-based wireless communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7971</identifier>
 <datestamp>2013-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7971</id><created>2013-04-30</created><updated>2013-06-11</updated><authors><author><keyname>Jamali</keyname><forenames>Vahid</forenames></author><author><keyname>Zlatanov</keyname><forenames>Nikola</forenames></author><author><keyname>Ikhlef</keyname><forenames>Aissa</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author></authors><title>Adaptive Mode Selection and Power Allocation in Bidirectional
  Buffer-aided Relay Networks</title><categories>cs.IT math.IT</categories><comments>arXiv admin note: substantial text overlap with arXiv:1303.3732</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of sum rate maximization in a
bidirectional relay network with fading. Hereby, user 1 and user 2 communicate
with each other only through a relay, i.e., a direct link between user 1 and
user 2 is not present. In this network, there exist six possible transmission
modes: four point-to-point modes (user 1-to-relay, user 2-to-relay,
relay-to-user 1, relay-to-user 2), a multiple access mode (both users to the
relay), and a broadcast mode (the relay to both users). Most existing protocols
assume a fixed schedule of using a subset of the aforementioned transmission
modes, as a result, the sum rate is limited by the capacity of the weakest link
associated with the relay in each time slot. Motivated by this limitation, we
develop a protocol which is not restricted to adhere to a predefined schedule
for using the transmission modes. Therefore, all transmission modes of the
bidirectional relay network can be used adaptively based on the instantaneous
channel state information (CSI) of the involved links. To this end, the relay
has to be equipped with two buffers for the storage of the information received
from users 1 and 2, respectively. For the considered network, given a total
average power budget for all nodes, we jointly optimize the transmission mode
selection and power allocation based on the instantaneous CSI in each time slot
for sum rate maximization. Simulation results show that the proposed protocol
outperforms existing protocols for all signal-to-noise ratios (SNRs).
Specifically, we obtain a considerable gain at low SNRs due to the adaptive
power allocation and at high SNRs due to the adaptive mode selection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7984</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7984</id><created>2013-04-30</created><authors><author><keyname>Hadiji</keyname><forenames>Fabian</forenames></author><author><keyname>Kersting</keyname><forenames>Kristian</forenames></author><author><keyname>Bauckhage</keyname><forenames>Christian</forenames></author><author><keyname>Ahmadi</keyname><forenames>Babak</forenames></author></authors><title>GeoDBLP: Geo-Tagging DBLP for Mining the Sociology of Computer Science</title><categories>cs.SI cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many collective human activities have been shown to exhibit universal
patterns. However, the possibility of universal patterns across timing events
of researcher migration has barely been explored at global scale. Here, we show
that timing events of migration within different countries exhibit remarkable
similarities. Specifically, we look at the distribution governing the data of
researcher migration inferred from the web. Compiling the data in itself
represents a significant advance in the field of quantitative analysis of
migration patterns. Official and commercial records are often access
restricted, incompatible between countries, and especially not registered
across researchers. Instead, we introduce GeoDBLP where we propagate
geographical seed locations retrieved from the web across the DBLP database of
1,080,958 authors and 1,894,758 papers. But perhaps more important is that we
are able to find statistical patterns and create models that explain the
migration of researchers. For instance, we show that the science job market can
be treated as a Poisson process with individual propensities to migrate
following a log-normal distribution over the researcher's career stage. That
is, although jobs enter the market constantly, researchers are generally not
&quot;memoryless&quot; but have to care greatly about their next move. The propensity to
make k&gt;1 migrations, however, follows a gamma distribution suggesting that
migration at later career stages is &quot;memoryless&quot;. This aligns well but actually
goes beyond scientometric models typically postulated based on small case
studies. On a very large, transnational scale, we establish the first general
regularities that should have major implications on strategies for education
and research worldwide.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7992</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7992</id><created>2013-04-30</created><updated>2013-11-23</updated><authors><author><keyname>Vlassis</keyname><forenames>Nikos</forenames></author><author><keyname>Pacheco</keyname><forenames>Maria Pires</forenames></author><author><keyname>Sauter</keyname><forenames>Thomas</forenames></author></authors><title>Fast Reconstruction of Compact Context-Specific Metabolic Network Models</title><categories>q-bio.MN cs.CE math.OC</categories><comments>fixed an error in the functional analysis of the liver model</comments><doi>10.1371/journal.pcbi.1003424</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Systemic approaches to the study of a biological cell or tissue rely
increasingly on the use of context-specific metabolic network models. The
reconstruction of such a model from high-throughput data can routinely involve
large numbers of tests under different conditions and extensive parameter
tuning, which calls for fast algorithms. We present FASTCORE, a generic
algorithm for reconstructing context-specific metabolic network models from
global genome-wide metabolic network models such as Recon X. FASTCORE takes as
input a core set of reactions that are known to be active in the context of
interest (e.g., cell or tissue), and it searches for a flux consistent
subnetwork of the global network that contains all reactions from the core set
and a minimal set of additional reactions. Our key observation is that a
minimal consistent reconstruction can be defined via a set of sparse modes of
the global network, and FASTCORE iteratively computes such a set via a series
of linear programs. Experiments on liver data demonstrate speedups of several
orders of magnitude, and significantly more compact reconstructions, over a
chief rival method. Given its simplicity and its excellent performance,
FASTCORE can form the backbone of many future metabolic network reconstruction
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7993</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7993</id><created>2013-04-30</created><authors><author><keyname>Absil</keyname><forenames>Romain</forenames></author><author><keyname>M&#xe9;lot</keyname><forenames>Hadrien</forenames></author></authors><title>Digenes: genetic algorithms to discover conjectures about directed and
  undirected graphs</title><categories>cs.DM cs.NE</categories><comments>17 Pages, 2 Figures, 2 Tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present Digenes, a new discovery system that aims to help researchers in
graph theory. While its main task is to find extremal graphs for a given
(function of) invariants, it also provides some basic support in proof
conception. This has already been proved to be very useful to find new
conjectures since the AutoGraphiX system of Caporossi and Hansen (Discrete
Math. 212-2000). However, unlike existing systems, Digenes can be used both
with directed or undirected graphs. In this paper, we present the principles
and functionality of Digenes, describe the genetic algorithms that have been
designed to achieve them, and give some computational results and open
questions. This do arise some interesting questions regarding genetic
algorithms design particular to this field, such as crossover definition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.7998</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.7998</id><created>2013-03-07</created><authors><author><keyname>Thirumurugan</keyname><forenames>S.</forenames></author><author><keyname>Raj</keyname><forenames>E. George Dharma Prakash</forenames></author></authors><title>A Novel Cluster Validation Approach on Pso-Pac Mechanism in Ad Hoc
  Network</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ad hoc network places a vital role in contemporary days communication
scenario. This network performance gets up while the clustering phenomenon has
been incorporated. The cluster formation using the vital parameters is
incredible on deciding the efficiency level of the clustered ad hoc networks.
The PSO-PAC mechanism forms clusters based on swarm intelligence by considering
energy as crucial parameter. This optimized cluster helps to suits the
applications where the energy parameter plays a key role. The clusters formed
by this mechanism may not ascertain the compactness of the clusters. Thus, this
paper proposes D-PAC as an index based validation mechanism to be handled on
clusters formed using PSO-PAC. The cluster formation and validation mechanism
have been implemented using OMNET++ simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8006</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8006</id><created>2013-03-23</created><authors><author><keyname>Anjum</keyname><forenames>Sheraz</forenames></author><author><keyname>Munir</keyname><forenames>Ehsan Ullah</forenames></author><author><keyname>Anwar</keyname><forenames>Waqas</forenames></author><author><keyname>Javaid</keyname><forenames>Nadeem</forenames></author></authors><title>Object Oriented Model for Evaluation of On-Chip Networks</title><categories>cs.OH</categories><journal-ref>Research Journal of Applied Sciences, Engineering and Technology
  5(2): 353-356, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Network on Chip (NoC) paradigm is rapidly replacing bus based System on
Chip (SoC) designs due to their inherent disadvantages such as non-scalability,
saturation and congestion. Currently very few tools are available for the
simulation and evaluation of on-chip architectures. This study proposes a
generic object oriented model for performance evaluation of on-chip
interconnect architectures and algorithms. The generic nature of the proposed
model can help the researchers in evaluation of any kind of on-chip switching
networks. The model was applied on 2D-Mesh and 2D-Diagonal-Mesh on-chip
switching networks for verification and selection of best out of both the
analyzed architectures. The results show the superiority of 2D-Diagonal-Mesh
over 2D-Mesh in terms of average packet delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8013</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8013</id><created>2013-03-29</created><authors><author><keyname>Sharma</keyname><forenames>Kamlesh</forenames></author><author><keyname>Suryakanthi</keyname><forenames>T.</forenames></author><author><keyname>Prasad</keyname><forenames>T. V.</forenames></author></authors><title>Exploration of Speech enabled System for English</title><categories>cs.HC cs.SD</categories><comments>9 pages, Proc. of the International Conference on System Modeling and
  Advancement in Research Trends (SMART), Teerthankar Mahaveer University,
  Moradabad, UP, India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents exploration of speech enable operating systems, software,
and applications. It begins with a description of how such systems work, and
the level of accuracy that can be expected. It explains the applications of
speech recognition technology in different areas education, medical, mobile
computing, railway reservation, dictation, and web browsing. A brief comparison
of the operating systems supported for voice, speech recognition software or
tool. It gives the brief introduction about the potential of voice/speech
recognition software. It explains the feature of different speech enable
Operating system and speech recognition software. Windows speech recognition
have many innovative features for Windows operating system and efficiently
assist the computer to control, dictate, navigate, selecting the words, sending
emails and correcting the words or sentences. It also explains the benefits and
issue related to speech technology. In last era speech recognition technology
grew tremendously. There are large number of companies who are working in these
area and developing software for the people who are not able to control the
system through keyboard or mouse such as physically impaired and senior
citizens. This paper gives a brief introduction of speech enabled OS and speech
recognition software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8016</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8016</id><created>2013-04-23</created><authors><author><keyname>Barth</keyname><forenames>Lukas</forenames></author><author><keyname>Kobourov</keyname><forenames>Stephen</forenames></author><author><keyname>Pupyrev</keyname><forenames>Sergey</forenames></author><author><keyname>Ueckerdt</keyname><forenames>Torsten</forenames></author></authors><title>On Semantic Word Cloud Representation</title><categories>cs.DS cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of computing semantic-preserving word clouds in which
semantically related words are close to each other. While several heuristic
approaches have been described in the literature, we formalize the underlying
geometric algorithm problem: Word Rectangle Adjacency Contact (WRAC). In this
model each word is associated with rectangle with fixed dimensions, and the
goal is to represent semantically related words by ensuring that the two
corresponding rectangles touch. We design and analyze efficient polynomial-time
algorithms for some variants of the WRAC problem, show that several general
variants are NP-hard, and describe a number of approximation algorithms.
Finally, we experimentally demonstrate that our theoretically-sound algorithms
outperform the early heuristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8019</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8019</id><created>2013-04-30</created><authors><author><keyname>Kurz</keyname><forenames>Gerhard</forenames></author><author><keyname>Gilitschenski</keyname><forenames>Igor</forenames></author><author><keyname>Julier</keyname><forenames>Simon</forenames></author><author><keyname>Hanebeck</keyname><forenames>Uwe D.</forenames></author></authors><title>Recursive Estimation of Orientation Based on the Bingham Distribution</title><categories>cs.SY cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Directional estimation is a common problem in many tracking applications.
Traditional filters such as the Kalman filter perform poorly because they fail
to take the periodic nature of the problem into account. We present a recursive
filter for directional data based on the Bingham distribution in two
dimensions. The proposed filter can be applied to circular filtering problems
with 180 degree symmetry, i.e., rotations by 180 degrees cannot be
distinguished. It is easily implemented using standard numerical techniques and
suitable for real-time applications. The presented approach is extensible to
quaternions, which allow tracking arbitrary three-dimensional orientations. We
evaluate our filter in a challenging scenario and compare it to a traditional
Kalman filtering approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8020</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8020</id><created>2013-04-30</created><updated>2013-05-01</updated><authors><author><keyname>Calandriello</keyname><forenames>Daniele</forenames></author><author><keyname>Niu</keyname><forenames>Gang</forenames></author><author><keyname>Sugiyama</keyname><forenames>Masashi</forenames></author></authors><title>Semi-Supervised Information-Maximization Clustering</title><categories>cs.LG stat.ML</categories><comments>Slightly change metadata. arXiv admin note: text overlap with
  arXiv:1112.0611</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semi-supervised clustering aims to introduce prior knowledge in the decision
process of a clustering algorithm. In this paper, we propose a novel
semi-supervised clustering algorithm based on the information-maximization
principle. The proposed method is an extension of a previous unsupervised
information-maximization clustering algorithm based on squared-loss mutual
information to effectively incorporate must-links and cannot-links. The
proposed method is computationally efficient because the clustering solution
can be obtained analytically via eigendecomposition. Furthermore, the proposed
method allows systematic optimization of tuning parameters such as the kernel
width, given the degree of belief in the must-links and cannot-links. The
usefulness of the proposed method is demonstrated through experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8026</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8026</id><created>2013-04-30</created><authors><author><keyname>Parandehgheibi</keyname><forenames>Marzieh</forenames></author><author><keyname>Lee</keyname><forenames>Hyang-Won</forenames></author><author><keyname>Modiano</keyname><forenames>Eytan</forenames></author></authors><title>Survivable Paths in Multilayer Networks</title><categories>math.OC cs.DS</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider protection problems in multilayer networks. In single-layer
networks, a pair of disjoint paths can be used to provide protection for a
source-destination pair. However, this approach cannot be directly applied to
layered networks where disjoint paths may not always exist. In this paper, we
take a new approach which is based on finding a set of paths that may not be
disjoint but together will survive any single physical link failure. First, we
consider the problem of finding the minimum number of survivable paths. In
particular, we focus on two versions of this problem: one where the length of a
path is restricted, and the other where the number of paths sharing a fiber is
restricted. We prove that in general, finding the minimum survivable path set
is NP-hard, whereas both of the restricted versions of the problem can be
solved in polynomial time. We formulate the problem as Integer Linear Programs
(ILPs), and use these formulations to develop heuristics and approximation
algorithms. Next, we consider the problem of finding a set of survivable paths
that uses the minimum number of fibers. We show that this problem is NP-hard in
general, and develop heuristics and approximation algorithms with provable
approximation bounds. Finally, we present simulation results comparing the
different algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8028</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8028</id><created>2013-04-30</created><authors><author><keyname>Zitouni</keyname><forenames>Rafik</forenames></author><author><keyname>Ataman</keyname><forenames>Stefan</forenames></author><author><keyname>Mathian</keyname><forenames>Marie</forenames></author><author><keyname>George</keyname><forenames>Laurent</forenames></author></authors><title>IEEE 802.15.4 transceiver for the 868/915 MHz band using Software
  Defined Radio</title><categories>cs.NI</categories><comments>6 pages</comments><journal-ref>Proceedings of SDR'12-WInnComm-Europe, 27-29 June 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reports an implementation of the PHY specifications of the IEEE
802.15.4 standard for the frequency band 868 915 MHz on a Software Defined
Radio (SDR) platform. This standard is defined for low power, low data rate and
low cost wireless networks. These specifications are used by the Zigbee
technology for various applications such as home automation, industry
monitoring or medical surveillance. Several hardware PHY 868/915 MHz band IEEE
802.15.4 transceiver implementations have been already reported on ASIC and FPG
[1] [2]. SDR offers one possibility to realize a transceiver with high
flexibility and reconfigurability [3]. The whole transmitter and receiver chain
has been defined in software using the GNU Radio software project [4] and the
USRP (Universal Software Radio Peripheral) platform from Ettus Research [5].
Two new blocks have been added to the GNU Radio project, one for the Direct
Sequence Spread Spectrum and the second for the reconstruction of the packets.
The experimentations have been performed in a noisy environment and the PER,
BER and SNR have been computed. The obtained results are coherent with what can
be expected from the theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8029</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8029</id><created>2013-04-30</created><updated>2013-08-19</updated><authors><author><keyname>Etzlinger</keyname><forenames>Bernhard</forenames></author><author><keyname>Wymeersch</keyname><forenames>Henk</forenames></author><author><keyname>Springer</keyname><forenames>Andreas</forenames></author></authors><title>Cooperative Synchronization in Wireless Networks</title><categories>cs.DC cs.IT math.IT</categories><msc-class>68W15</msc-class><acm-class>C.2.1</acm-class><doi>10.1109/TSP.2014.2313531</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Synchronization is a key functionality in wireless network, enabling a wide
variety of services. We consider a Bayesian inference framework whereby network
nodes can achieve phase and skew synchronization in a fully distributed way. In
particular, under the assumption of Gaussian measurement noise, we derive two
message passing methods (belief propagation and mean field), analyze their
convergence behavior, and perform a qualitative and quantitative comparison
with a number of competing algorithms. We also show that both methods can be
applied in networks with and without master nodes. Our performance results are
complemented by, and compared with, the relevant Bayesian Cram\'er-Rao bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8034</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8034</id><created>2013-04-30</created><updated>2013-05-01</updated><authors><author><keyname>Bianculli</keyname><forenames>Domenico</forenames></author><author><keyname>Filieri</keyname><forenames>Antonio</forenames></author><author><keyname>Ghezzi</keyname><forenames>Carlo</forenames></author><author><keyname>Mandrioli</keyname><forenames>Dino</forenames></author></authors><title>A Syntactic-Semantic Approach to Incremental Verification</title><categories>cs.SE</categories><comments>22 pages, 8 figures. Corrected typos</comments><acm-class>D.2.4; D.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software verification of evolving systems is challenging mainstream
methodologies and tools. Formal verification techniques often conflict with the
time constraints imposed by change management practices for evolving systems.
Since changes in these systems are often local to restricted parts, an
incremental verification approach could be beneficial.
  This paper introduces SiDECAR, a general framework for the definition of
verification procedures, which are made incremental by the framework itself.
Verification procedures are driven by the syntactic structure (defined by a
grammar) of the system and encoded as semantic attributes associated with the
grammar. Incrementality is achieved by coupling the evaluation of semantic
attributes with an incremental parsing technique.
  We show the application of SiDECAR to the definition of two verification
procedures: probabilistic verification of reliability requirements and
verification of safety properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8046</identifier>
 <datestamp>2013-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8046</id><created>2013-04-30</created><updated>2013-07-31</updated><authors><author><keyname>Antunes</keyname><forenames>Lu\is</forenames></author><author><keyname>Bauwens</keyname><forenames>Bruno</forenames></author><author><keyname>Souto</keyname><forenames>Andre</forenames></author><author><keyname>Teixeira</keyname><forenames>Andreia</forenames></author></authors><title>Sophistication vs Logical Depth</title><categories>cs.IT cs.CC math.IT</categories><comments>9 pages</comments><msc-class>94A17</msc-class><acm-class>H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sophistication and logical depth are two measures that express how
complicated the structure in a string is. Sophistication is defined as the
minimal complexity of a computable function that defines a two-part description
for the string that is shortest within some precision; the second can be
defined as the minimal computation time of a program that is shortest within
some precision. We show that the Busy Beaver function of the sophistication of
a string exceeds its logical depth with logarithmically bigger precision, and
that logical depth exceeds the Busy Beaver function of sophistication with
logarithmically bigger precision. We also show that this is not true if the
precision is only increased by a constant (when the notions are defined with
plain Kolmogorov complexity). Finally we show that sophistication is unstable
in its precision: constant variations can change its value by a linear term in
the length of the string.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8052</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8052</id><created>2013-03-29</created><authors><author><keyname>Qin</keyname><forenames>Binjie</forenames></author><author><keyname>Gu</keyname><forenames>Zhijun</forenames></author><author><keyname>Sun</keyname><forenames>Xianjun</forenames></author><author><keyname>Lv</keyname><forenames>Yisong</forenames></author></authors><title>Registration of Images with Outliers Using Joint Saliency Map</title><categories>cs.CV</categories><comments>Preprint version for publication in IEEE Signal Processing Letters,
  17(1):91-94, 2010</comments><doi>10.1109/LSP.2009.2033728</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Mutual information (MI) is a popular similarity measure for image
registration, whereby good registration can be achieved by maximizing the
compactness of the clusters in the joint histogram. However, MI is sensitive to
the &quot;outlier&quot; objects that appear in one image but not the other, and also
suffers from local and biased maxima. We propose a novel joint saliency map
(JSM) to highlight the corresponding salient structures in the two images, and
emphatically group those salient structures into the smoothed compact clusters
in the weighted joint histogram. This strategy could solve both the outlier and
the local maxima problems. Experimental results show that the JSM-MI based
algorithm is not only accurate but also robust for registration of challenging
image pairs with outliers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8069</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8069</id><created>2013-04-30</created><authors><author><keyname>Kobel</keyname><forenames>Alexander</forenames></author><author><keyname>Sagraloff</keyname><forenames>Michael</forenames></author></authors><title>Fast Approximate Polynomial Multipoint Evaluation and Applications</title><categories>cs.NA cs.SC math.NA</categories><msc-class>65Y20</msc-class><acm-class>F.2.1; G.1.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that, using fast algorithms for polynomial multiplication
and division, evaluation of a polynomial $F\in\CC[x]$ of degree $n$ at $n$
complex-valued points can be done with $\softOh(n)$ exact field operations in
$\CC,$ where $\softOh(\cdot)$ means that we omit polylogarithmic factors. We
complement this result by an analysis of \emph{approximate multipoint
evaluation} of $F$ to a precision of $L$ bits after the binary point and prove
a bit complexity of $\softOh (n(L + \tau + n\Gamma)),$ where $2^\tau$ and
$\cramped{2^{\Gamma}},$ with $\tau,\Gamma\in\NN_{\ge 1},$ are bounds on the
magnitude of the coefficients of $F$ and the evaluation points, respectively.
In particular, in the important case where the precision demand dominates the
other input parameters, the complexity is soft-linear in $n$ and $L.$ Our
result on approximate multipoint evaluation has some interesting consequences
on the bit complexity of three further approximation algorithms which all use
polynomial evaluation as a key subroutine. This comprises an algorithm to
approximate the real roots of a polynomial, an algorithm for polynomial
interpolation, and a method for computing a Taylor shift of a polynomial. For
all of the latter algorithms, we derive near optimal running times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8080</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8080</id><created>2013-04-25</created><authors><author><keyname>Patel</keyname><forenames>Rupa</forenames></author><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author><author><keyname>Thakare</keyname><forenames>V. M</forenames></author></authors><title>Secure Transmission of Password Using Speech Watermarking</title><categories>cs.MM cs.CR</categories><comments>Pages: 4 Figures: 7, International Journal of Computer Science and
  Technology (IJCST) Vol.2, Issue 3, September 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet is one of the most valuable resources for information communication
and retrievals. Most multimedia signals today are in digital formats. The
digital data can be duplicated and edited with great ease which has led to a
need for data integrity and protection of digital data. The security
requirements such as integrity or data authentication can be met by
implementing security measures using digital watermarking techniques. In this
paper a blind speech watermarking algorithm that embeds the watermark signal
data in the musical (sequence) host signal by using frequency masking is used.
A different logarithmic approach is proposed. In this regard a logarithmic
function is first applied to watermark data. Then the transformed signal is
embedded to the converted version of host signal which is obtained by applying
Fast Fourier transform method. Finally using inverse Fast Fourier Transform and
antilogarithmic function watermark signal is retrieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8083</identifier>
 <datestamp>2015-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8083</id><created>2013-04-30</created><updated>2015-02-08</updated><authors><author><keyname>Bethanabhotla</keyname><forenames>Dilip</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author><author><keyname>Neely</keyname><forenames>Michael J.</forenames></author></authors><title>Adaptive Video Streaming for Wireless Networks with Multiple Users and
  Helpers</title><categories>cs.NI cs.IT math.IT math.OC</categories><comments>final version to appear in IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the optimal design of a scheduling policy for adaptive video
streaming in a wireless network formed by several users and helpers. A feature
of such networks is that any user is typically in the range of multiple
helpers. Hence, in order to cope with user-helper association, load balancing
and inter-cell interference, an efficient streaming policy should allow the
users to dynamically select the helper node to download from, and determine
adaptively the video quality level of the download. In order to obtain a
tractable formulation, we follow a &quot;divide and conquer&quot; approach: i) Assuming
that each video packet (chunk) is delivered within its playback delay (&quot;smooth
streaming regime&quot;), the problem is formulated as a network utility maximization
(NUM), subject to queue stability, where the network utility function is a
concave and componentwise non-decreasing function of the users' video quality
measure. ii) We solve the NUM problem by using a Lyapunov Drift Plus Penalty
approach, obtaining a scheme that naturally decomposes into two sub-policies
referred to as &quot;congestion control&quot; (adaptive video quality and helper station
selection) and &quot;transmission scheduling&quot; (dynamic allocation of the helper-user
physical layer transmission rates).Our solution is provably optimal with
respect to the proposed NUM problem, in a strong per-sample path sense. iii)
Finally, we propose a method to adaptively estimate the maximum queuing delays,
such that each user can calculate its pre-buffering and re-buffering time in
order to cope with the fluctuations of the queuing delays. Through simulations,
we evaluate the performance of the proposed algorithm under realistic
assumptions of a network with densely deployed helper nodes, and demonstrate
the per-sample path optimality of the proposed solution by considering a
non-stationary non-ergodic scenario with user mobility, VBR video coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8087</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8087</id><created>2013-04-30</created><authors><author><keyname>Bhaskara</keyname><forenames>Aditya</forenames></author><author><keyname>Charikar</keyname><forenames>Moses</forenames></author><author><keyname>Vijayaraghavan</keyname><forenames>Aravindan</forenames></author></authors><title>Uniqueness of Tensor Decompositions with Applications to Polynomial
  Identifiability</title><categories>cs.DS cs.LG math.ST stat.TH</categories><comments>51 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a robust version of the celebrated result of Kruskal on the
uniqueness of tensor decompositions: we prove that given a tensor whose
decomposition satisfies a robust form of Kruskal's rank condition, it is
possible to approximately recover the decomposition if the tensor is known up
to a sufficiently small (inverse polynomial) error.
  Kruskal's theorem has found many applications in proving the identifiability
of parameters for various latent variable models and mixture models such as
Hidden Markov models, topic models etc. Our robust version immediately implies
identifiability using only polynomially many samples in many of these settings.
This polynomial identifiability is an essential first step towards efficient
learning algorithms for these models.
  Recently, algorithms based on tensor decompositions have been used to
estimate the parameters of various hidden variable models efficiently in
special cases as long as they satisfy certain &quot;non-degeneracy&quot; properties. Our
methods give a way to go beyond this non-degeneracy barrier, and establish
polynomial identifiability of the parameters under much milder conditions.
Given the importance of Kruskal's theorem in the tensor literature, we expect
that this robust version will have several applications beyond the settings we
explore in this work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8092</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8092</id><created>2013-04-30</created><authors><author><keyname>Shanmugavadivu</keyname><forenames>P.</forenames></author><author><keyname>Sivakumar</keyname><forenames>V.</forenames></author></authors><title>Fractal-Based Detection of Microcalcification Clusters in Digital
  Mammograms</title><categories>cs.CV</categories><comments>Appeared in ICECIT-2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel method for edge detection of microcalcification
clusters in mammogram images is presented using the concept of Fractal
Dimension and Hurst co-efficient that enables to locate the microcalcifications
in the mammograms. This technique detects the edges accurately than the ones
obtained by the conventional Sobel method. Generally, Sobel method detects the
edges of the regions/objects in an image using the Fudge factor that assumes
its value as 0.5, by default. In this proposed technique, the Fudge factor is
suitably replaced with Hurst Co-efficient, which is computed as the difference
of Fractal dimension and the topological dimension of a given input image.
These two dimensions are image-dependent, and hence the respective Hurst
co-efficient too varies with respect to images. Hence, the image-dependent
Hurst co-efficient based Sobel method is proved to produce better results than
the Fudge factor based Sobel method. The results of the proposed method
substantiate the merit of the proposed technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8102</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8102</id><created>2013-04-30</created><authors><author><keyname>Loyka</keyname><forenames>Sergey</forenames></author><author><keyname>Kostina</keyname><forenames>Victoria</forenames></author><author><keyname>Gagnon</keyname><forenames>Francois</forenames></author></authors><title>On Convexity of Error Rates in Digital Communications</title><categories>cs.IT math.IT</categories><comments>Accepted by IEEE Information Theory Transactions, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convexity properties of error rates of a class of decoders, including the
ML/min-distance one as a special case, are studied for arbitrary
constellations, bit mapping and coding. Earlier results obtained for the AWGN
channel are extended to a wide class of noise densities, including unimodal and
spherically-invariant noise. Under these broad conditions, symbol and bit error
rates are shown to be convex functions of the SNR in the high-SNR regime with
an explicitly-determined threshold, which depends only on the constellation
dimensionality and minimum distance, thus enabling an application of the
powerful tools of convex optimization to such digital communication systems in
a rigorous way. It is the decreasing nature of the noise power density around
the decision region boundaries that insures the convexity of symbol error rates
in the general case. The known high/low SNR bounds of the convexity/concavity
regions are tightened and no further improvement is shown to be possible in
general. The high SNR bound fits closely into the channel coding theorem: all
codes, including capacity-achieving ones, whose decision regions include the
hardened noise spheres (from the noise sphere hardening argument in the channel
coding theorem) satisfies this high SNR requirement and thus has convex error
rates in both SNR and noise power. We conjecture that all capacity-achieving
codes have convex error rates. Convexity properties in signal amplitude and
noise power are also investigated. Some applications of the results are
discussed. In particular, it is shown that fading is convexity-preserving and
is never good in low dimensions under spherically-invariant noise, which may
also include any linear diversity combining.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8108</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8108</id><created>2013-04-30</created><authors><author><keyname>Singh</keyname><forenames>Mohit</forenames></author><author><keyname>Vishnoi</keyname><forenames>Nisheeth K.</forenames></author></authors><title>Entropy, Optimization and Counting</title><categories>cs.DS cs.CC cs.DM math.CO stat.CO</categories><acm-class>F.2.2; G.1.6; G.2.1; G.2.2; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the problem of computing max-entropy distributions
over a discrete set of objects subject to observed marginals. Interest in such
distributions arises due to their applicability in areas such as statistical
physics, economics, biology, information theory, machine learning,
combinatorics and, more recently, approximation algorithms. A key difficulty in
computing max-entropy distributions has been to show that they have
polynomially-sized descriptions. We show that such descriptions exist under
general conditions. Subsequently, we show how algorithms for (approximately)
counting the underlying discrete set can be translated into efficient
algorithms to (approximately) compute max-entropy distributions. In the reverse
direction, we show how access to algorithms that compute max-entropy
distributions can be used to count, which establishes an equivalence between
counting and computing max-entropy distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8109</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8109</id><created>2013-04-30</created><authors><author><keyname>Petrlic</keyname><forenames>Ronald</forenames></author><author><keyname>Sekula</keyname><forenames>Stephan</forenames></author></authors><title>Unlinkable content playbacks in a multiparty DRM system</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a solution to the problem of privacy invasion in a multiparty
digital rights management scheme. (Roaming) users buy content licenses from a
content provider and execute it at any nearby content distributor. Our
approach, which does not need any trusted third party--in contrast to most
related work on privacy-preserving DRM--is based on a re-encryption scheme that
runs on any mobile Android device. Only a minor security-critical part needs to
be performed on the device's smartcard which could, for instance, be a SIM
card.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8125</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8125</id><created>2013-04-30</created><authors><author><keyname>Chierichetti</keyname><forenames>Flavio</forenames></author><author><keyname>Kleinberg</keyname><forenames>Jon</forenames></author><author><keyname>Oren</keyname><forenames>Sigal</forenames></author></authors><title>On Discrete Preferences and Coordination</title><categories>cs.GT cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An active line of research has considered games played on networks in which
payoffs depend on both a player's individual decision and also the decisions of
her neighbors. Such games have been used to model issues including the
formation of opinions and the adoption of technology. A basic question that has
remained largely open in this area is to consider games where the strategies
available to the players come from a fixed, discrete set, and where players may
have different intrinsic preferences among the possible strategies. It is
natural to model the tension among these different preferences by positing a
distance function on the strategy set that determines a notion of &quot;similarity&quot;
among strategies; a player's payoff is determined by the distance from her
chosen strategy to her preferred strategy and to the strategies chosen by her
network neighbors. Even when there are only two strategies available, this
framework already leads to natural open questions about a version of the
classical Battle of the Sexes problem played on a graph.
  We develop a set of techniques for analyzing this class of games, which we
refer to as discrete preference games. We parametrize the games by the relative
extent to which a player takes into account the effect of her preferred
strategy and the effect of her neighbors' strategies, allowing us to
interpolate between network coordination games and unilateral decision-making.
When these two effects are balanced, we show that the price of stability is
equal to 1 for any discrete preference game in which the distance function on
the strategies is a tree metric; as a special case, this includes the Battle of
the Sexes on a graph. We also show that trees form the maximal family of
metrics for which the price of stability is 1, and produce a collection of
metrics on which the price of stability converges to a tight bound of 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8126</identifier>
 <datestamp>2015-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8126</id><created>2013-04-30</created><updated>2014-07-20</updated><authors><author><keyname>Chen</keyname><forenames>Yuxin</forenames></author><author><keyname>Chi</keyname><forenames>Yuejie</forenames></author></authors><title>Robust Spectral Compressed Sensing via Structured Matrix Completion</title><categories>cs.IT cs.SY math.IT math.NA stat.ML</categories><comments>accepted to IEEE Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, Vol. 60, No. 10, pp. 6576
  - 6601, October 2014</journal-ref><doi>10.1109/TIT.2014.2343623</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper explores the problem of \emph{spectral compressed sensing}, which
aims to recover a spectrally sparse signal from a small random subset of its
$n$ time domain samples. The signal of interest is assumed to be a
superposition of $r$ multi-dimensional complex sinusoids, while the underlying
frequencies can assume any \emph{continuous} values in the normalized frequency
domain. Conventional compressed sensing paradigms suffer from the basis
mismatch issue when imposing a discrete dictionary on the Fourier
representation. To address this issue, we develop a novel algorithm, called
\emph{Enhanced Matrix Completion (EMaC)}, based on structured matrix completion
that does not require prior knowledge of the model order. The algorithm starts
by arranging the data into a low-rank enhanced form exhibiting multi-fold
Hankel structure, and then attempts recovery via nuclear norm minimization.
Under mild incoherence conditions, EMaC allows perfect recovery as soon as the
number of samples exceeds the order of $r\log^{4}n$, and is stable against
bounded noise. Even if a constant portion of samples are corrupted with
arbitrary magnitude, EMaC still allows exact recovery, provided that the sample
complexity exceeds the order of $r^{2}\log^{3}n$. Along the way, our results
demonstrate the power of convex relaxation in completing a low-rank multi-fold
Hankel or Toeplitz matrix from minimal observed entries. The performance of our
algorithm and its applicability to super resolution are further validated by
numerical experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8129</identifier>
 <datestamp>2015-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8129</id><created>2013-04-30</created><updated>2015-01-07</updated><authors><author><keyname>Hemenway</keyname><forenames>Brett</forenames></author><author><keyname>Ostrovsky</keyname><forenames>Rafail</forenames></author><author><keyname>Wootters</keyname><forenames>Mary</forenames></author></authors><title>Local Correctability of Expander Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we present the first local-decoding algorithm for expander
codes. This yields a new family of constant-rate codes that can recover from a
constant fraction of errors in the codeword symbols, and where any symbol of
the codeword can be recovered with high probability by reading $N^\epsilon$
symbols from the corrupted codeword, where $N$ is the block-length of the code.
  Expander codes, introduced by Sipser and Spielman, are formed from an
expander graph $G = (V,E)$ of degree $d$, and an inner code of block-length $d$
over an alphabet $\Sigma$. Each edge of the expander graph is associated with a
symbol in $\Sigma$. A string in $\Sigma^{E}$ will be a codeword if for each
vertex in $V$, the symbols on the adjacent edges form a codeword in the inner
code.
  We show that if the inner code has a smooth reconstruction algorithm in the
noiseless setting, then the corresponding expander code has an efficient
local-correction algorithm in the noisy setting. Instantiating our construction
with inner codes based on finite geometries, we obtain novel locally decodable
codes with rate approaching one. This provides an alternative to the
multiplicity codes of Kopparty, Saraf and Yekhanin (STOC '11) and the lifted
codes of Guo, Kopparty and Sudan (ITCS '13).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8132</identifier>
 <datestamp>2013-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8132</id><created>2013-04-30</created><updated>2013-11-07</updated><authors><author><keyname>Zhu</keyname><forenames>Zeyuan Allen</forenames></author><author><keyname>Lattanzi</keyname><forenames>Silvio</forenames></author><author><keyname>Mirrokni</keyname><forenames>Vahab</forenames></author></authors><title>Local Graph Clustering Beyond Cheeger's Inequality</title><categories>cs.DS cs.LG stat.ML</categories><comments>An extended abstract of this paper has appeared in the proceedings of
  the 30th International Conference on Machine Learning (ICML 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by applications of large-scale graph clustering, we study
random-walk-based LOCAL algorithms whose running times depend only on the size
of the output cluster, rather than the entire graph. All previously known such
algorithms guarantee an output conductance of $\tilde{O}(\sqrt{\phi(A)})$ when
the target set $A$ has conductance $\phi(A)\in[0,1]$. In this paper, we improve
it to $$\tilde{O}\bigg( \min\Big\{\sqrt{\phi(A)},
\frac{\phi(A)}{\sqrt{\mathsf{Conn}(A)}} \Big\} \bigg)\enspace, $$ where the
internal connectivity parameter $\mathsf{Conn}(A) \in [0,1]$ is defined as the
reciprocal of the mixing time of the random walk over the induced subgraph on
$A$.
  For instance, using $\mathsf{Conn}(A) = \Omega(\lambda(A) / \log n)$ where
$\lambda$ is the second eigenvalue of the Laplacian of the induced subgraph on
$A$, our conductance guarantee can be as good as
$\tilde{O}(\phi(A)/\sqrt{\lambda(A)})$. This builds an interesting connection
to the recent advance of the so-called improved Cheeger's Inequality [KKL+13],
which says that global spectral algorithms can provide a conductance guarantee
of $O(\phi_{\mathsf{opt}}/\sqrt{\lambda_3})$ instead of
$O(\sqrt{\phi_{\mathsf{opt}}})$.
  In addition, we provide theoretical guarantee on the clustering accuracy (in
terms of precision and recall) of the output set. We also prove that our
analysis is tight, and perform empirical evaluation to support our theory on
both synthetic and real data.
  It is worth noting that, our analysis outperforms prior work when the cluster
is well-connected. In fact, the better it is well-connected inside, the more
significant improvement (both in terms of conductance and accuracy) we can
obtain. Our results shed light on why in practice some random-walk-based
algorithms perform better than its previous theory, and help guide future
research about local clustering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1304.8135</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1304.8135</id><created>2013-04-30</created><updated>2013-05-08</updated><authors><author><keyname>Solomon</keyname><forenames>Shay</forenames></author></authors><title>From Hierarchical Partitions to Hierarchical Covers: Optimal
  Fault-Tolerant Spanners for Doubling Metrics</title><categories>cs.DS cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we devise an optimal construction of fault-tolerant spanners
for doubling metrics. Specifically, for any $n$-point doubling metric, any
$\eps &gt; 0$, and any integer $0 \le k \le n-2$, our construction provides a
$k$-fault-tolerant $(1+\eps)$-spanner with optimal degree $O(k)$ within optimal
time $O(n \log n + k n)$.
  We then strengthen this result to provide near-optimal (up to a factor of
$\log k$) guarantees on the diameter and weight of our spanners, namely,
diameter $O(\log n)$ and weight $O(k^2 + k \log n) \cdot \omega(MST)$, while
preserving the optimal guarantees on the degree $O(k)$ and the running time
$O(n \log n + k n)$.
  Our result settles several fundamental open questions in this area,
culminating a long line of research that started with the STOC'95 paper of Arya
et al.\ and the STOC'98 paper of Levcopoulos et al.
  On the way to this result we develop a new technique for constructing
spanners in doubling metrics. Our spanner construction is based on a novel
\emph{hierarchical cover} of the metric, whereas most previous constructions of
spanners for doubling and Euclidean metrics (such as the net-tree spanner) are
based on \emph{hierarchical partitions} of the metric. We demonstrate the power
of hierarchical covers in the context of geometric spanners by improving the
state-of-the-art results in this area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0001</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0001</id><created>2013-04-30</created><authors><author><keyname>Zakaria</keyname><forenames>Rozaimi</forenames></author><author><keyname>Wahab</keyname><forenames>Abd. Fatah</forenames></author><author><keyname>Gobithaasan</keyname><forenames>R. U.</forenames></author></authors><title>Perfectly normal type-2 fuzzy interpolation B-spline curve</title><categories>cs.GR</categories><comments>arXiv admin note: substantial text overlap with arXiv:1304.7868</comments><journal-ref>2013 Applied Mathematical Sciences 7 (21-24), Pg.1043-1055</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we proposed another new form of type-2 fuzzy data
points(T2FDPs) that is perfectly normal type-2 data points(PNT2FDPs). These
kinds of brand-new data were defined by using the existing type-2 fuzzy set
theory(T2FST) and type-2 fuzzy number(T2FN) concept since we dealt with the
problem of defining complex uncertainty data. Along with this restructuring, we
included the fuzzification(alpha-cut operation), type-reduction and
defuzzification processes against PNT2FDPs. In addition, we used interpolation
B-soline curve function to demonstrate the PNT2FDPs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0015</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0015</id><created>2013-04-30</created><authors><author><keyname>Lakshminarayanan</keyname><forenames>Balaji</forenames></author><author><keyname>Teh</keyname><forenames>Yee Whye</forenames></author></authors><title>Inferring ground truth from multi-annotator ordinal data: a
  probabilistic approach</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A popular approach for large scale data annotation tasks is crowdsourcing,
wherein each data point is labeled by multiple noisy annotators. We consider
the problem of inferring ground truth from noisy ordinal labels obtained from
multiple annotators of varying and unknown expertise levels. Annotation models
for ordinal data have been proposed mostly as extensions of their
binary/categorical counterparts and have received little attention in the
crowdsourcing literature. We propose a new model for crowdsourced ordinal data
that accounts for instance difficulty as well as annotator expertise, and
derive a variational Bayesian inference algorithm for parameter estimation. We
analyze the ordinal extensions of several state-of-the-art annotator models for
binary/categorical labels and evaluate the performance of all the models on two
real world datasets containing ordinal query-URL relevance scores, collected
through Amazon's Mechanical Turk. Our results indicate that the proposed model
performs better or as well as existing state-of-the-art methods and is more
resistant to `spammy' annotators (i.e., annotators who assign labels randomly
without actually looking at the instance) than popular baselines such as mean,
median, and majority vote which do not account for annotator expertise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0020</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0020</id><created>2013-04-30</created><authors><author><keyname>Jassim</keyname><forenames>Firas A.</forenames></author></authors><title>Image Compression By Embedding Five Modulus Method Into JPEG</title><categories>cs.CV cs.MM</categories><comments>9 pages, 6 tables, 6 figures</comments><journal-ref>Signal &amp; Image Processing : An International Journal (SIPIJ)
  Vol.4, No.2, April 2013</journal-ref><doi>10.5121/sipij.2013.4203</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The standard JPEG format is almost the optimum format in image compression.
The compression ratio in JPEG sometimes reaches 30:1. The compression ratio of
JPEG could be increased by embedding the Five Modulus Method (FMM) into the
JPEG algorithm. The novel algorithm gives twice the time as the standard JPEG
algorithm or more. The novel algorithm was called FJPEG (Five-JPEG). The
quality of the reconstructed image after compression is approximately
approaches the JPEG. Standard test images have been used to support and
implement the suggested idea in this paper and the error metrics have been
computed and compared with JPEG.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0032</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0032</id><created>2013-04-30</created><authors><author><keyname>Blaum</keyname><forenames>Mario</forenames></author></authors><title>Construction of PMDS and SD Codes extending RAID 5</title><categories>cs.IT math.IT</categories><comments>7 pages</comments><report-no>IBM Research Report, IBM Research Report, RJ10504, March 2013</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A construction of Partial Maximum Distance Separable (PMDS) and Sector-Disk
(SD) codes extending RAID 5 with two extra parities is given, solving an open
problem. Previous constructions relied on computer searches, while our
constructions provide a theoretical solution to the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0034</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0034</id><created>2013-04-30</created><authors><author><keyname>Gibson</keyname><forenames>Richard</forenames></author></authors><title>Regret Minimization in Non-Zero-Sum Games with Applications to Building
  Champion Multiplayer Computer Poker Agents</title><categories>cs.GT cs.MA</categories><msc-class>68T37, 68T42, 91A06, 91A18</msc-class><acm-class>I.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In two-player zero-sum games, if both players minimize their average external
regret, then the average of the strategy profiles converges to a Nash
equilibrium. For n-player general-sum games, however, theoretical guarantees
for regret minimization are less understood. Nonetheless, Counterfactual Regret
Minimization (CFR), a popular regret minimization algorithm for extensive-form
games, has generated winning three-player Texas Hold'em agents in the Annual
Computer Poker Competition (ACPC). In this paper, we provide the first set of
theoretical properties for regret minimization algorithms in non-zero-sum games
by proving that solutions eliminate iterative strict domination. We formally
define \emph{dominated actions} in extensive-form games, show that CFR avoids
iteratively strictly dominated actions and strategies, and demonstrate that
removing iteratively dominated actions is enough to win a mock tournament in a
small poker game. In addition, for two-player non-zero-sum games, we bound the
worst case performance and show that in practice, regret minimization can yield
strategies very close to equilibrium. Our theoretical advancements lead us to a
new modification of CFR for games with more than two players that is more
efficient and may be used to generate stronger strategies than previously
possible. Furthermore, we present a new three-player Texas Hold'em poker agent
that was built using CFR and a novel game decomposition method. Our new agent
wins the three-player events of the 2012 ACPC and defeats the winning
three-player programs from previous competitions while requiring less resources
to generate than the 2011 winner. Finally, we show that our CFR modification
computes a strategy of equal quality to our new agent in a quarter of the time
of standard CFR using half the memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0051</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0051</id><created>2013-04-30</created><authors><author><keyname>Xu</keyname><forenames>Kevin S.</forenames></author><author><keyname>Kliger</keyname><forenames>Mark</forenames></author><author><keyname>Chen</keyname><forenames>Yilun</forenames></author><author><keyname>Woolf</keyname><forenames>Peter J.</forenames></author><author><keyname>Hero</keyname><forenames>Alfred O.</forenames><suffix>III</suffix></author></authors><title>Revealing social networks of spammers through spectral clustering</title><categories>cs.SI cs.LG physics.soc-ph stat.ML</categories><comments>Source code and data available at
  http://tbayes.eecs.umich.edu/xukevin/spam_icc09 Proceedings of the IEEE
  International Conference on Communications (2009)</comments><doi>10.1109/ICC.2009.5199418</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To date, most studies on spam have focused only on the spamming phase of the
spam cycle and have ignored the harvesting phase, which consists of the mass
acquisition of email addresses. It has been observed that spammers conceal
their identity to a lesser degree in the harvesting phase, so it may be
possible to gain new insights into spammers' behavior by studying the behavior
of harvesters, which are individuals or bots that collect email addresses. In
this paper, we reveal social networks of spammers by identifying communities of
harvesters with high behavioral similarity using spectral clustering. The data
analyzed was collected through Project Honey Pot, a distributed system for
monitoring harvesting and spamming. Our main findings are (1) that most
spammers either send only phishing emails or no phishing emails at all, (2)
that most communities of spammers also send only phishing emails or no phishing
emails at all, and (3) that several groups of spammers within communities
exhibit coherent temporal behavior and have similar IP addresses. Our findings
reveal some previously unknown behavior of spammers and suggest that there is
indeed social structure between spammers to be discovered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0060</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0060</id><created>2013-04-30</created><updated>2013-05-09</updated><authors><author><keyname>Ely</keyname><forenames>Gregory</forenames></author><author><keyname>Aeron</keyname><forenames>Shuchin</forenames></author></authors><title>Complexity penalized hydraulic fracture localization and moment tensor
  estimation under limited model information</title><categories>physics.geo-ph cs.IT math.IT stat.AP</categories><doi>10.1121/1.4806001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a novel technique for micro-seismic localization
using a group sparse penalization that is robust to the focal mechanism of the
source and requires only a velocity model of the stratigraphy rather than a
full Green's function model of the earth's response. In this technique we
construct a set of perfect delta detector responses, one for each detector in
the array, to a seismic event at a given location and impose a group sparsity
across the array. This scheme is independent of the moment tensor and exploits
the time compactness of the incident seismic signal. Furthermore we present a
method for improving the inversion of the moment tensor and Green's function
when the geometry of seismic array is limited. In particular we demonstrate
that both Tikhonov regularization and truncated SVD can improve the recovery of
the moment tensor and be robust to noise. We evaluate our algorithm on
synthetic data and present error bounds for both estimation of the moment
tensor as well as localization. Furthermore we discuss the estimated moment
tensor accuracy as a function of both array geometry and fault orientation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0061</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0061</id><created>2013-04-30</created><authors><author><keyname>Ding</keyname><forenames>Cunsheng</forenames></author><author><keyname>Helleseth</keyname><forenames>Tor</forenames></author></authors><title>Optimal Ternary Cyclic Codes from Monomials</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cyclic codes are a subclass of linear codes and have applications in consumer
electronics, data storage systems, and communication systems as they have
efficient encoding and decoding algorithms. Perfect nonlinear monomials were
employed to construct optimal ternary cyclic codes with parameters $[3^m-1,
3^m-1-2m, 4]$ by Carlet, Ding and Yuan in 2005. In this paper, almost perfect
nonlinear monomials, and a number of other monomials over $\gf(3^m)$ are used
to construct optimal ternary cyclic codes with the same parameters. Nine open
problems on such codes are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0062</identifier>
 <datestamp>2014-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0062</id><created>2013-04-30</created><updated>2013-05-22</updated><authors><author><keyname>Taghavi</keyname><forenames>Zeinab</forenames></author><author><keyname>Movahedi</keyname><forenames>Narjes S.</forenames></author><author><keyname>Draghici</keyname><forenames>Sorin</forenames></author><author><keyname>Chitsaz</keyname><forenames>Hamidreza</forenames></author></authors><title>Distilled Single Cell Genome Sequencing and De Novo Assembly for Sparse
  Microbial Communities</title><categories>q-bio.GN cs.CE</categories><doi>10.1093/bioinformatics/btt420</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identification of every single genome present in a microbial sample is an
important and challenging task with crucial applications. It is challenging
because there are typically millions of cells in a microbial sample, the vast
majority of which elude cultivation. The most accurate method to date is
exhaustive single cell sequencing using multiple displacement amplification,
which is simply intractable for a large number of cells. However, there is hope
for breaking this barrier as the number of different cell types with distinct
genome sequences is usually much smaller than the number of cells.
  Here, we present a novel divide and conquer method to sequence and de novo
assemble all distinct genomes present in a microbial sample with a sequencing
cost and computational complexity proportional to the number of genome types,
rather than the number of cells. The method is implemented in a tool called
Squeezambler. We evaluated Squeezambler on simulated data. The proposed divide
and conquer method successfully reduces the cost of sequencing in comparison
with the naive exhaustive approach.
  Availability: Squeezambler and datasets are available under
http://compbio.cs.wayne.edu/software/squeezambler/.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0064</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0064</id><created>2013-04-30</created><authors><author><keyname>Reid</keyname><forenames>Samuel</forenames></author></authors><title>On Generalizing a Temporal Formalism for Game Theory to the Asymptotic
  Combinatorics of S5 Modal Frames</title><categories>math.LO cs.LO math.CO</categories><comments>8 pages and 3 figures</comments><msc-class>03B44, 05A16</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A temporal-theoretic formalism for understanding game theory is described
where a strict ordering relation on a set of time points $T$ defines a game on
$T$. Using this formalism, a proof of Zermelo's Theorem, which states that
every finite 2-player zero-sum game is determined, is given and an exhaustive
analysis of the game of Nim is presented. Furthermore, a combinatorial analysis
of games on a set of arbitrary time points is given; in particular, it is
proved that the number of distinct games on a set $T$ with cardinality $n$ is
the number of partial orders on a set of $n$ elements. By generalizing this
theorem from temporal modal frames to S5 modal frames, it is proved that the
number of isomorphism classes of S5 modal frames $\mathcal{F} = \ &lt; W, R \ &gt;$
with $|W|=n$ is equal to the partition function $p(n)$. As a corollary of the
fact that the partition function is asymptotic to the Hardy-Ramanujan number
$$\frac{1}{4\sqrt{3}n}e^{\pi \sqrt{2n/3}}$$ the number of isomorphism classes
of S5 modal frames $\mathcal{F} = \ &lt; W, R \ &gt;$ with $|W|=n$ is asymptotically
the Hardy-Ramanujan number. Lastly, we use these results to prove that an
arbitrary modal frame is an S5 modal frame with probability zero.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0069</identifier>
 <datestamp>2013-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0069</id><created>2013-04-30</created><updated>2013-06-22</updated><authors><author><keyname>Fink</keyname><forenames>Martin</forenames></author><author><keyname>Pupyrev</keyname><forenames>Sergey</forenames></author></authors><title>Ordering Metro Lines by Block Crossings</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A problem that arises in drawings of transportation networks is to minimize
the number of crossings between different transportation lines. While this can
be done efficiently under specific constraints, not all solutions are visually
equivalent. We suggest merging crossings into block crossings, that is,
crossings of two neighboring groups of consecutive lines. Unfortunately,
minimizing the total number of block crossings is NP-hard even for very simple
graphs. We give approximation algorithms for special classes of graphs and an
asymptotically worst-case optimal algorithm for block crossings on general
graphs. That is, we bound the number of block crossings that our algorithm
needs and construct worst-case instances on which the number of block crossings
that is necessary in any solution is asymptotically the same as our bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0085</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0085</id><created>2013-05-01</created><authors><author><keyname>Feldman</keyname><forenames>Michal</forenames></author><author><keyname>Kempe</keyname><forenames>David</forenames></author><author><keyname>Lucier</keyname><forenames>Brendan</forenames></author><author><keyname>Leme</keyname><forenames>Renato Paes</forenames></author></authors><title>Pricing Public Goods for Private Sale</title><categories>cs.GT</categories><comments>accepted to EC'13</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the pricing problem faced by a seller who assigns a price to a
good that confers its benefits not only to its buyers, but also to other
individuals around them. For example, a snow-blower is potentially useful not
only to the household that buys it, but also to others on the same street.
Given that the seller is constrained to selling such a (locally) public good
via individual private sales, how should he set his prices given the
distribution of values held by the agents?
  We study this problem as a two-stage game. In the first stage, the seller
chooses and announces a price for the product. In the second stage, the agents
(each having a private value for the good) decide simultaneously whether or not
they will buy the product. In the resulting game, which can exhibit a
multiplicity of equilibria, agents must strategize about whether they will
themselves purchase the good to receive its benefits.
  In the case of a fully public good (where all agents benefit whenever any
agent purchases), we describe a pricing mechanism that is approximately
revenue-optimal (up to a constant factor) when values are drawn from a regular
distribution. We then study settings in which the good is only &quot;locally&quot;
public: agents are arranged in a network and share benefits only with their
neighbors. We describe a pricing method that approximately maximizes revenue,
in the worst case over equilibria of agent behavior, for any $d$-regular
network. Finally, we show that approximately optimal prices can be found for
general networks in the special case that private values are drawn from a
uniform distribution. We also discuss some barriers to extending these results
to general networks and regular distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0087</identifier>
 <datestamp>2014-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0087</id><created>2013-05-01</created><updated>2014-01-06</updated><authors><author><keyname>Yang</keyname><forenames>Jiyan</forenames></author><author><keyname>Meng</keyname><forenames>Xiangrui</forenames></author><author><keyname>Mahoney</keyname><forenames>Michael W.</forenames></author></authors><title>Quantile Regression for Large-scale Applications</title><categories>cs.DS cs.DC cs.NA stat.ML</categories><comments>35 pages; long version of a paper appearing in the 2013 ICML. Version
  to appear in the SIAM Journal on Scientific Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantile regression is a method to estimate the quantiles of the conditional
distribution of a response variable, and as such it permits a much more
accurate portrayal of the relationship between the response variable and
observed covariates than methods such as Least-squares or Least Absolute
Deviations regression. It can be expressed as a linear program, and, with
appropriate preprocessing, interior-point methods can be used to find a
solution for moderately large problems. Dealing with very large problems,
\emph(e.g.), involving data up to and beyond the terabyte regime, remains a
challenge. Here, we present a randomized algorithm that runs in nearly linear
time in the size of the input and that, with constant probability, computes a
$(1+\epsilon)$ approximate solution to an arbitrary quantile regression
problem. As a key step, our algorithm computes a low-distortion
subspace-preserving embedding with respect to the loss function of quantile
regression. Our empirical evaluation illustrates that our algorithm is
competitive with the best previous work on small to medium-sized problems, and
that in addition it can be implemented in MapReduce-like environments and
applied to terabyte-sized problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0101</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0101</id><created>2013-05-01</created><authors><author><keyname>Lescanne</keyname><forenames>Pierre</forenames><affiliation>LIP</affiliation></author></authors><title>Bubbles are rational</title><categories>cs.GT cs.LO q-fin.GN</categories><comments>Translation of http://hal-ens-lyon.archives-ouvertes.fr/ensl-00646546</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As we show using the notion of equilibrium in the theory of infinite
sequential games, bubbles and escalations are rational for economic and
environmental agents, who believe in an infinite world. This goes against a
vision of a self regulating, wise and pacific economy in equilibrium. In other
words, in this context, equilibrium is not a synonymous of stability. We
attempt to draw from this statement methodological consequences and a new
approach to economics. To the mindware of economic agents (a concept due to
cognitive psychology) we propose to add coinduction to properly reason on
infinite games. This way we refine the notion of rationality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0103</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0103</id><created>2013-05-01</created><authors><author><keyname>Plessis</keyname><forenames>Marthinus Christoffel du</forenames></author><author><keyname>Sugiyama</keyname><forenames>Masashi</forenames></author></authors><title>Clustering Unclustered Data: Unsupervised Binary Labeling of Two
  Datasets Having Different Class Balances</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the unsupervised learning problem of assigning labels to
unlabeled data. A naive approach is to use clustering methods, but this works
well only when data is properly clustered and each cluster corresponds to an
underlying class. In this paper, we first show that this unsupervised labeling
problem in balanced binary cases can be solved if two unlabeled datasets having
different class balances are available. More specifically, estimation of the
sign of the difference between probability densities of two unlabeled datasets
gives the solution. We then introduce a new method to directly estimate the
sign of the density difference without density estimation. Finally, we
demonstrate the usefulness of the proposed method against several clustering
methods on various toy problems and real-world datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0110</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0110</id><created>2013-05-01</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Hirschberg</keyname><forenames>Daniel S.</forenames></author></authors><title>Combinatorial Pair Testing: Distinguishing Workers from Slackers</title><categories>cs.DS</categories><comments>12 pages. Extended version of a paper to appear at the Algorithms and
  Data Structures Symposium (WADS 2013)</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We formalize a problem we call combinatorial pair testing (CPT), which has
applications to the identification of uncooperative or unproductive
participants in pair programming, massively distributed computing, and
crowdsourcing environments. We give efficient adaptive and nonadaptive CPT
algorithms and we show that our methods use an optimal number of testing rounds
to within constant factors. We also provide an empirical evaluation of some of
our methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0120</identifier>
 <datestamp>2015-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0120</id><created>2013-05-01</created><updated>2015-02-24</updated><authors><author><keyname>Dolce</keyname><forenames>Francesco</forenames></author><author><keyname>Perrin</keyname><forenames>Dominique</forenames></author></authors><title>Interval exchanges, admissibility and branching Rauzy induction</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a definition of admissibility for subintervals in interval
exchange transformations. Using this notion, we prove a property of the natural
codings of interval exchange transformations, namely that any derived set of a
regular interval exchange set is a regular interval exchange set with the same
number of intervals. Derivation is taken here with respect to return words. We
characterize the admissible intervals using a branching version of the Rauzy
induction. We also study the case of regular interval exchange transformations
defined over a quadratic field and show that the set of factors of such a
transformation is primitive morphic. The proof uses an extension of a result of
Boshernitzan and Carroll.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0124</identifier>
 <datestamp>2014-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0124</id><created>2013-05-01</created><updated>2014-04-22</updated><authors><author><keyname>Boban</keyname><forenames>Mate</forenames></author><author><keyname>Barros</keyname><forenames>Joao</forenames></author><author><keyname>Tonguz</keyname><forenames>Ozan K.</forenames></author></authors><title>Geometry-Based Vehicle-to-Vehicle Channel Modeling for Large-Scale
  Simulation</title><categories>cs.NI</categories><comments>Preprint of an article that will be published in IEEE Transactions on
  Vehicular Technology</comments><doi>10.1109/TVT.2014.2317803</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the dynamic nature of vehicular traffic and the road surroundings,
vehicle-to-vehicle (V2V) propagation characteristics vary greatly on both
small- and large-scale. Recent measurements have shown that both large static
objects (e.g., buildings and foliage) as well as mobile objects (surrounding
vehicles) have a profound impact on V2V communication. At the same time,
system-level Vehicular Ad Hoc Network (VANET) simulators by and large employ
simple statistical propagation models, which do not account for surrounding
objects explicitly. We designed GEMV$^2$ (Geometry-based Efficient propagation
Model for V2V communication), which uses outlines of vehicles, buildings, and
foliage to distinguish the following three types of links: line of sight (LOS),
non-LOS due to vehicles, and non- LOS due to static objects. For each link,
GEMV$^2$ calculates the large-scale signal variations deterministically,
whereas the small- scale signal variations are calculated stochastically based
on the number and size of surrounding objects. We implement GEMV$^2$ in MATLAB
and show that it scales well by using it to simulate radio propagation for
city-wide networks with tens of thousands of vehicles on commodity hardware. We
make the source code of GEMV$^2$ freely available. Finally, we validate
GEMV$^2$ against extensive measurements performed in urban, suburban, highway,
and open space environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0127</identifier>
 <datestamp>2015-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0127</id><created>2013-05-01</created><updated>2015-02-20</updated><authors><author><keyname>Berth&#xe9;</keyname><forenames>Val&#xe9;rie</forenames></author><author><keyname>De Felice</keyname><forenames>Clelia</forenames></author><author><keyname>Dolce</keyname><forenames>Francesco</forenames></author><author><keyname>Leroy</keyname><forenames>Julien</forenames></author><author><keyname>Perrin</keyname><forenames>Dominique</forenames></author><author><keyname>Reutenauer</keyname><forenames>Christophe</forenames></author><author><keyname>Rindone</keyname><forenames>Giuseppina</forenames></author></authors><title>The finite index basis property</title><categories>cs.DM math.CO</categories><comments>arXiv admin note: text overlap with arXiv:1011.5369, arXiv:1305.0120</comments><journal-ref>J. Pure Appl. Algebra, 219 (2015) 2521-2537</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe in this paper a connection between bifix codes, symbolic
dynamical systems and free groups. This is in the spirit of the connection
established previously for the symbolic systems corresponding to Sturmian
words. We introduce a class of sets of factors of an infinite word with linear
factor complexity containing Sturmian sets and regular interval exchange sets,
namemly the class of tree sets. We prove as a main result that for a uniformly
recurrent tree set $F$, a finite bifix code $X$ on the alphabet $A$ is
$F$-maximal of $F$-degree $d$ if and only if it is the basis of a subgroup of
index $d$ of the free group on $A$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0135</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0135</id><created>2013-05-01</created><updated>2013-05-07</updated><authors><author><keyname>Lanci</keyname><forenames>Gloria</forenames></author></authors><title>Translating cities: the use of digital technologies in urban
  environments</title><categories>cs.CY</categories><comments>Working Paper, 9 pages, author name and contact details added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer models and information systems have been used for urban planning and
design since the 1950s. Their capacity for analysis and problem-solving has
increased substantially since then with hardware and software being able to
manage large amounts of data. The beginning of the 2000s brought better
technologies for data visualisation and intuitive software products and
nowadays they are being used to design and manipulate highly complex urban
systems. However, ontological and epistemological questions remain about the
nature of urban environments. What do we know about cities - and what is a city
exactly? What theoretical models can be applied to the study of cities? How do
we translate a city into data? What type of information really matters and what
do we want to communicate with them? What are the implications of computer
modelling for urban planning and design? This paper reviews how digital
technologies have been used to shape our understanding of cities and how they
impact the design and planning of cities. The point of depart is a scrutiny of
the emergence of modern planning in the nineteenth century when cities became a
scientific subject. A range of theories and concepts of the urban form and
urban growth developed during the twentieth century will be presented and then
linked to the first investigations involving the use of the computer for
modelling and planning. The paper concludes with some discussions around the
interaction of computing and urban theories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0141</identifier>
 <datestamp>2014-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0141</id><created>2013-05-01</created><updated>2013-05-02</updated><authors><author><keyname>Naish</keyname><forenames>Lee</forenames></author><author><keyname>S&#xf8;ndergaard</keyname><forenames>Harald</forenames></author></authors><title>Truth versus information in logic programming</title><categories>cs.LO</categories><comments>39 pages, 10 figures, 1 table. See also
  http://ww2.cs.mu.oz.au/~lee/papers/sem4lp/ (previous version had 2 comments
  in code accidentally deleted and checkmarks/ticks in Table 1 were displayed
  as &quot;4&quot;)</comments><acm-class>F.3.1; F.3.2; F.4.1; D.2.1; D.2.4</acm-class><doi>10.1017/S1471068413000069</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The semantics of logic programs was originally described in terms of
two-valued logic. Soon, however, it was realised that three-valued logic had
some natural advantages, as it provides distinct values not only for truth and
falsehood, but also for &quot;undefined&quot;. The three-valued semantics proposed by
Fitting and by Kunen are closely related to what is computed by a logic
program, the third truth value being associated with non-termination. A
different three-valued semantics, proposed by Naish, shared much with those of
Fitting and Kunen but incorporated allowances for programmer intent, the third
truth value being associated with underspecification. Naish used an
(apparently) novel &quot;arrow&quot; operator to relate the intended meaning of left and
right sides of predicate definitions. In this paper we suggest that the
additional truth values of Fitting/Kunen and Naish are best viewed as duals. We
use Belnap's four-valued logic, also used elsewhere by Fitting, to unify the
two three-valued approaches. The truth values are arranged in a bilattice which
supports the classical ordering on truth values as well as the &quot;information
ordering&quot;. We note that the &quot;arrow&quot; operator of Naish (and our four-valued
extension) is essentially the information ordering, whereas the classical arrow
denotes the truth ordering. This allows us to shed new light on many aspects of
logic programming, including program analysis, type and mode systems,
declarative debugging and the relationships between specifications and
programs, and successive executions states of a program. This paper is to
appear in Theory and Practice of Logic Programming (TPLP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0152</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0152</id><created>2013-05-01</created><authors><author><keyname>Sacerdoti</keyname><forenames>Federico D.</forenames></author></authors><title>The Software Garden</title><categories>cs.SE</categories><comments>9 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a practical method of developing custom HPC software
products using a store of libraries and tools independent from the OS called a
&quot;garden&quot;. All dependencies from the product to libraries of the underlying OS
distribution are carefully severed, isolating the package from instability due
to system upgrades and ensuring repeatable deterministic builds on different
flavors of Linux. The method also guarantees multiple versions of a software
product may exist together and function correctly, greatly facilitating upgrade
and rollback. The method is the first known system to expose all past software
versions to the designer, and support deterministic single-package rollback
without affecting other installed software. An application of this method for
building a high performance trading system in C++ is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0153</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0153</id><created>2013-05-01</created><authors><author><keyname>Chen</keyname><forenames>Junting</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>Convergence Analysis of Mixed Timescale Cross-Layer Stochastic
  Optimization</title><categories>cs.SY cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a cross-layer optimization problem driven by
multi-timescale stochastic exogenous processes in wireless communication
networks. Due to the hierarchical information structure in a wireless network,
a mixed timescale stochastic iterative algorithm is proposed to track the
time-varying optimal solution of the cross-layer optimization problem, where
the variables are partitioned into short-term controls updated in a faster
timescale, and long-term controls updated in a slower timescale. We focus on
establishing a convergence analysis framework for such multi-timescale
algorithms, which is difficult due to the timescale separation of the algorithm
and the time-varying nature of the exogenous processes. To cope with this
challenge, we model the algorithm dynamics using stochastic differential
equations (SDEs) and show that the study of the algorithm convergence is
equivalent to the study of the stochastic stability of a virtual stochastic
dynamic system (VSDS). Leveraging the techniques of Lyapunov stability, we
derive a sufficient condition for the algorithm stability and a tracking error
bound in terms of the parameters of the multi-timescale exogenous processes.
Based on these results, an adaptive compensation algorithm is proposed to
enhance the tracking performance. Finally, we illustrate the framework by an
application example in wireless heterogeneous network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0159</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0159</id><created>2013-05-01</created><authors><author><keyname>Janin</keyname><forenames>Lilian</forenames></author><author><keyname>Rosone</keyname><forenames>Giovanna</forenames></author><author><keyname>Cox</keyname><forenames>Anthony J.</forenames></author></authors><title>Adaptive reference-free compression of sequence quality scores</title><categories>q-bio.GN cs.DS</categories><comments>Accepted paper for HiTSeq 2013, to appear in Bioinformatics.
  Bioinformatics should be considered the original place of publication of this
  work, please cite accordingly</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivation:
  Rapid technological progress in DNA sequencing has stimulated interest in
compressing the vast datasets that are now routinely produced. Relatively
little attention has been paid to compressing the quality scores that are
assigned to each sequence, even though these scores may be harder to compress
than the sequences themselves. By aggregating a set of reads into a compressed
index, we find that the majority of bases can be predicted from the sequence of
bases that are adjacent to them and hence are likely to be less informative for
variant calling or other applications. The quality scores for such bases are
aggressively compressed, leaving a relatively small number at full resolution.
Since our approach relies directly on redundancy present in the reads, it does
not need a reference sequence and is therefore applicable to data from
metagenomics and de novo experiments as well as to resequencing data.
  Results:
  We show that a conservative smoothing strategy affecting 75% of the quality
scores above Q2 leads to an overall quality score compression of 1 bit per
value with a negligible effect on variant calling. A compression of 0.68 bit
per quality value is achieved using a more aggressive smoothing strategy, again
with a very small effect on variant calling.
  Availability:
  Code to construct the BWT and LCP-array on large genomic data sets is part of
the BEETL library, available as a github respository at
http://git@github.com:BEETL/BEETL.git .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0160</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0160</id><created>2013-05-01</created><authors><author><keyname>Bauer</keyname><forenames>Markus J.</forenames></author><author><keyname>Cox</keyname><forenames>Anthony J.</forenames></author><author><keyname>Rosone</keyname><forenames>Giovanna</forenames></author><author><keyname>Sciortino</keyname><forenames>Marinella</forenames></author></authors><title>Lightweight LCP Construction for Next-Generation Sequencing Datasets</title><categories>cs.DS q-bio.GN</categories><comments>Springer LNCS (Lecture Notes in Computer Science) should be
  considered as the original place of publication, please cite accordingly. The
  final version of this manuscript is available at
  http://link.springer.com/chapter/10.1007/978-3-642-33122-0_26</comments><journal-ref>Lecture Notes in Computer Science Volume 7534, 2012, pp 326-337</journal-ref><doi>10.1007/978-3-642-33122-0_26</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The advent of &quot;next-generation&quot; DNA sequencing (NGS) technologies has meant
that collections of hundreds of millions of DNA sequences are now commonplace
in bioinformatics. Knowing the longest common prefix array (LCP) of such a
collection would facilitate the rapid computation of maximal exact matches,
shortest unique substrings and shortest absent words. CPU-efficient algorithms
for computing the LCP of a string have been described in the literature, but
require the presence in RAM of large data structures. This prevents such
methods from being feasible for NGS datasets.
  In this paper we propose the first lightweight method that simultaneously
computes, via sequential scans, the LCP and BWT of very large collections of
sequences. Computational results on collections as large as 800 million
100-mers demonstrate that our algorithm scales to the vast sequence collections
encountered in human whole genome sequencing experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0172</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0172</id><created>2013-05-01</created><authors><author><keyname>Biniaz</keyname><forenames>Ahmad</forenames></author><author><keyname>Maheshwari</keyname><forenames>Anil</forenames></author><author><keyname>Smid</keyname><forenames>Michiel</forenames></author></authors><title>An Optimal Algorithm for the Euclidean Bottleneck Full Steiner Tree
  Problem</title><categories>cs.CG</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $P$ and $S$ be two disjoint sets of $n$ and $m$ points in the plane,
respectively. We consider the problem of computing a Steiner tree whose Steiner
vertices belong to $S$, in which each point of $P$ is a leaf, and whose longest
edge length is minimum. We present an algorithm that computes such a tree in
$O((n+m)\log m)$ time, improving the previously best result by a logarithmic
factor. We also prove a matching lower bound in the algebraic computation tree
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0177</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0177</id><created>2013-05-01</created><updated>2013-05-19</updated><authors><author><keyname>Coja-Oghlan</keyname><forenames>Amin</forenames></author></authors><title>Upper-bounding the k-colorability threshold by counting covers</title><categories>math.CO cs.DM</categories><msc-class>06E10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $G(n,m)$ be the random graph on $n$ vertices with $m$ edges. Let $d=2m/n$
be its average degree. We prove that $G(n,m)$ fails to be $k$-colorable with
high probability if $d&gt;2k\ln k-\ln k-1+o_k(1)$. This matches a conjecture put
forward on the basis of sophisticated but non-rigorous statistical physics
ideas (Krzakala, Pagnani, Weigt 2004). The proof is based on applying the first
moment method to the number of &quot;covers&quot;, a physics-inspired concept. By
comparison, a standard first moment over the number of $k$-colorings shows that
$\gnm$ is not $k$-colorable with high probability if $d&gt;2k\ln k-\ln k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0185</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0185</id><created>2013-05-01</created><authors><author><keyname>Sham</keyname><forenames>Chiu-Wing</forenames></author><author><keyname>Chen</keyname><forenames>Xu</forenames></author><author><keyname>Lau</keyname><forenames>Francis C. M.</forenames></author><author><keyname>Zhao</keyname><forenames>Yue</forenames></author><author><keyname>Tam</keyname><forenames>Wai M.</forenames></author></authors><title>A 2.0 Gb/s Throughput Decoder for QC-LDPC Convolutional Codes</title><categories>cs.IT cs.AR math.IT</categories><comments>accepted to IEEE Transactions on Circuits and Systems I</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper propose a decoder architecture for low-density parity-check
convolutional code (LDPCCC). Specifically, the LDPCCC is derived from a
quasi-cyclic (QC) LDPC block code. By making use of the quasi-cyclic structure,
the proposed LDPCCC decoder adopts a dynamic message storage in the memory and
uses a simple address controller. The decoder efficiently combines the memories
in the pipelining processors into a large memory block so as to take advantage
of the data-width of the embedded memory in a modern field-programmable gate
array (FPGA). A rate-5/6 QC-LDPCCC has been implemented on an Altera Stratix
FPGA. It achieves up to 2.0 Gb/s throughput with a clock frequency of 100 MHz.
Moreover, the decoder displays an excellent error performance of lower than
$10^{-13}$ at a bit-energy-to-noise-power-spectral-density ratio ($E_b/N_0$) of
3.55 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0187</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0187</id><created>2013-05-01</created><authors><author><keyname>Cherifi</keyname><forenames>Chantal</forenames></author><author><keyname>Rivierre</keyname><forenames>Yvan</forenames></author><author><keyname>Santucci</keyname><forenames>Jean-Francois</forenames></author></authors><title>A Community Based Algorithm for Large Scale Web Service Composition</title><categories>cs.AI cs.SE</categories><journal-ref>Cherifi, C., Y. Rivierre, Santucci, J.F.: A Community Based
  Algorithm for Large Scale Web Service Composition. In Journal of Convergence
  Information Technology (JCIT), Vol.8 N4 pp. 148-157, (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web service composition is the process of synthesizing a new composite
service using a set of available Web services in order to satisfy a client
request that cannot be treated by any available Web services. The Web services
space is a dynamic environment characterized by a huge number of elements.
Furthermore, many Web services are offering similar functionalities. In this
paper we propose a model for Web service composition designed to address the
scale effect and the redundancy issue. The Web services space is represented by
a two-layered network architecture. A concrete similarity network layer
organizes the Web services operations into communities of functionally similar
operations. An abstract interaction network layer represents the composition
relationships between the sets of communities. Composition synthesis is
performed by a two-phased graph search algorithm. First, the interaction
network is mined in order to discover abstract solutions to the request goal.
Then, the abstract compositions are instantiated with concrete operations
selected from the similarity network. This strategy allows an efficient
exploration of the Web services space. Furthermore, operations grouped in a
community can be easily substituted if necessary during the composition's
synthesis's process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0189</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0189</id><created>2013-05-01</created><authors><author><keyname>Cherifi</keyname><forenames>Chantal</forenames></author><author><keyname>Santucci</keyname><forenames>Jean-Francois</forenames></author></authors><title>A Comparative Study of Web Services Composition Networks</title><categories>cs.SE</categories><journal-ref>Cherifi, C., Santucci, J.-F.: A Comparative Study of Web Services
  Composition Networks. In: Complex Networks 2012 Workshop, International
  Conference on Signal Image Technology &amp; Internet Based Systems (SITIS),
  Napoli, Italy (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web services growth makes the composition process a hard task to solve. This
numerous interacting elements can be adequately represented by a network.
Discovery and composition can benefit from the knowledge of the network
structure. In this paper, we investigate the topological properties of two
models of syntactic and semantic Web services composition networks: dependency
and interaction. Results show that they share a similar organization
characterized by the small-world property, a heavy-tailed degree distribution
and a low transitivity value. Furthermore, the networks are disassortative.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0190</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0190</id><created>2013-05-01</created><authors><author><keyname>Cherifi</keyname><forenames>Chantal</forenames></author><author><keyname>Santucci</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author></authors><title>Analyzing Web Services Networks: a WS-NEXT Application</title><categories>cs.SE</categories><journal-ref>Cherifi, C., Santucci, J.F.: Analyzing Web services Networks : A
  WS-NEXT Application. In Advances in Information Technology from AI to Virtual
  Reality, Ubiquitous Computing and Communication Journal (UBICC), pp. 60-77,
  (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web services represent a system with a huge number of units and many various
and complex interactions. Complex networks as a tool for modelling and
analyzing natural environments seem to be well adapted to such a complex
system. To describe a set of Web services we propose three Web services network
models based on the notions of dependency, interaction and similarity. Using
the WS-NEXT extractor we instantiate the models with a collection of Web
services descriptions. We take advantage of complex network properties to
provide an analyzis of the Web services networks. Those networks and the
knowledge of their toplogical properties can be exploited for the discovery and
composition processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0191</identifier>
 <datestamp>2015-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0191</id><created>2013-05-01</created><authors><author><keyname>Cherifi</keyname><forenames>Chantal</forenames></author><author><keyname>Labatut</keyname><forenames>Vincent</forenames></author><author><keyname>Santucci</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author></authors><title>Benefits of Semantics on Web Service Composition from a Complex Network
  Perspective</title><categories>cs.SI cs.AI cs.SE</categories><journal-ref>In International Conference on Networked Digital Technologies, pp
  80-90, Springer CCIS, Czech Republic (2010)</journal-ref><doi>10.1007/978-3-642-14306-9_9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The number of publicly available Web services (WS) is continuously growing,
and in parallel, we are witnessing a rapid development in semantic-related web
technologies. The intersection of the semantic web and WS allows the
development of semantic WS. In this work, we adopt a complex network
perspective to perform a comparative analysis of the syntactic and semantic
approaches used to describe WS. From a collection of publicly available WS
descriptions, we extract syntactic and semantic WS interaction networks. We
take advantage of tools from the complex network field to analyze them and
determine their properties. We show that WS interaction networks exhibit some
of the typical characteristics observed in real-world networks, such as short
average distance between nodes and community structure. By comparing syntactic
and semantic networks through their properties, we show the introduction of
semantics in WS descriptions should improve the composition process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0194</identifier>
 <datestamp>2015-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0194</id><created>2013-05-01</created><authors><author><keyname>Aksoy</keyname><forenames>Cihan</forenames></author><author><keyname>Labatut</keyname><forenames>Vincent</forenames></author><author><keyname>Cherifi</keyname><forenames>Chantal</forenames></author><author><keyname>Santucci</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author></authors><title>MATAWS: A Multimodal Approach for Automatic WS Semantic Annotation</title><categories>cs.SE cs.CL cs.IR</categories><journal-ref>In International Conference on Networked Digital Technologies,
  Springer CCIS 136),China (2011)</journal-ref><doi>10.1007/978-3-642-22185-9_27</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many recent works aim at developing methods and tools for the processing of
semantic Web services. In order to be properly tested, these tools must be
applied to an appropriate benchmark, taking the form of a collection of
semantic WS descriptions. However, all of the existing publicly available
collections are limited by their size or their realism (use of randomly
generated or resampled descriptions). Larger and realistic syntactic (WSDL)
collections exist, but their semantic annotation requires a certain level of
automation, due to the number of operations to be processed. In this article,
we propose a fully automatic method to semantically annotate such large WS
collections. Our approach is multimodal, in the sense it takes advantage of the
latent semantics present not only in the parameter names, but also in the type
names and structures. Concept-to-word association is performed by using Sigma,
a mapping of WordNet to the SUMO ontology. After having described in details
our annotation method, we apply it to the larger collection of real-world
syntactic WS descriptions we could find, and assess its efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0195</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0195</id><created>2013-05-01</created><authors><author><keyname>Cherifi</keyname><forenames>Chantal</forenames></author></authors><title>Similartity Network For Semantic Web Services Substitution</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web services substitution is one of the most challenging tasks for automating
the composition process of multiple Web services. It aims to improve
performances and to deal efficiently with Web services failures. Many existing
solutions have approached the problem through classification of substitutable
Web services. To go a step further, we propose in this paper a network based
approach where nodes are Web services operations and links join similar
operations. Four similarity measures based on the comparison of input and
output parameters values of Web services operations are presented. A
comparative evaluation of the topological structure of the corresponding
networks is performed on a benchmark of semantically annotated Web services.
Results show that this approach allows a more detailed analysis of
substitutable Web services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0196</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0196</id><created>2013-05-01</created><authors><author><keyname>Cherifi</keyname><forenames>Chantal</forenames></author><author><keyname>Labatut</keyname><forenames>Vincent</forenames></author><author><keyname>Santucci</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author></authors><title>Topological Properties of Web Services Similarity Networks</title><categories>cs.IR cs.SI</categories><journal-ref>In Strategic Advantage of Computing Information Systems in
  Enterprise Management, ATINER, pp. 105-117, (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The number of publicly available Web services (WS) is continuously growing.
To perform efficient WS discovery, it is desirable to organize the WS space.
Works in this direction propose to group WS according to certain shared
properties. Such groups commonly called communities are based either on
similarity or on interaction between WS. In this paper we focus on the former,
and propose a new network-based approach to extract communities from a WS
collection. This process is three-stepped: first we define several similarity
functions able to compare WS operations, second we use them to build so-called
similarity networks, and third we identify communities under the form of
specific structures in these networks. We apply our method on a collection of
real-world WS and comment the resulting communities. Finally, we additionally
provide an analysis and an interpretation of our similarity networks with a
complex networks perspective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0203</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0203</id><created>2013-05-01</created><authors><author><keyname>Nemtsov</keyname><forenames>Arik</forenames></author><author><keyname>Averbuch</keyname><forenames>Amir</forenames></author><author><keyname>Schclar</keyname><forenames>Alon</forenames></author></authors><title>Matrix Compression using the Nystro\&quot;om Method</title><categories>cs.NA</categories><comments>31 pages, 3 figures, submitted to Linear Algebra and its Applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Nystr\&quot;{o}m method is routinely used for out-of-sample extension of
kernel matrices. We describe how this method can be applied to find the
singular value decomposition (SVD) of general matrices and the eigenvalue
decomposition (EVD) of square matrices. We take as an input a matrix $M\in
\mathbb{R}^{m\times n}$, a user defined integer $s\leq min(m,n)$ and $A_M \in
\mathbb{R}^{s\times s}$, a matrix sampled from the columns and rows of $M$.
These are used to construct an approximate rank-$s$ SVD of $M$ in
$O\left(s^2\left(m+n\right)\right)$ operations. If $M$ is square, the rank-$s$
EVD can be similarly constructed in $O\left(s^2 n\right)$ operations. Thus, the
matrix $A_M$ is a compressed version of $M$. We discuss the choice of $A_M$ and
propose an algorithm that selects a good initial sample for a pivoted version
of $M$. The proposed algorithm performs well for general matrices and kernel
matrices whose spectra exhibit fast decay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0205</identifier>
 <datestamp>2013-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0205</id><created>2013-05-01</created><authors><author><keyname>Berset</keyname><forenames>Yves</forenames></author><author><keyname>Medo</keyname><forenames>Matus</forenames></author></authors><title>The effect of the initial network configuration on preferential
  attachment</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI physics.data-an</categories><comments>7 pages, 6 figures</comments><journal-ref>European Physical Journal B 86, 260, 2013</journal-ref><doi>10.1140/epjb/e2013-30998-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical preferential attachment model is sensitive to the choice of the
initial configuration of the network. As the number of initial nodes and their
degree grow, so does the time needed for an equilibrium degree distribution to
be established. We study this phenomenon, provide estimates of the
equilibration time, and characterize the degree distribution cutoff observed at
finite times. When the initial network is dense and exceeds a certain small
size, there is no equilibration and a suitable statistical test can always
discern the produced degree distribution from the equilibrium one. As a
by-product, the weighted Kolmogorov-Smirnov statistic is demonstrated to be
more suitable for statistical analysis of power-law distributions with cutoff
when the data is ample.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0208</identifier>
 <datestamp>2013-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0208</id><created>2013-05-01</created><updated>2013-07-22</updated><authors><author><keyname>Mohri</keyname><forenames>Mehryar</forenames></author><author><keyname>Rostamizadeh</keyname><forenames>Afshin</forenames></author></authors><title>Perceptron Mistake Bounds</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a brief survey of existing mistake bounds and introduce novel
bounds for the Perceptron or the kernel Perceptron algorithm. Our novel bounds
generalize beyond standard margin-loss type bounds, allow for any convex and
Lipschitz loss function, and admit a very simple proof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0209</identifier>
 <datestamp>2014-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0209</id><created>2013-05-01</created><updated>2014-03-11</updated><authors><author><keyname>Gember</keyname><forenames>Aaron</forenames></author><author><keyname>Krishnamurthy</keyname><forenames>Anand</forenames></author><author><keyname>John</keyname><forenames>Saul St.</forenames></author><author><keyname>Grandl</keyname><forenames>Robert</forenames></author><author><keyname>Gao</keyname><forenames>Xiaoyang</forenames></author><author><keyname>Anand</keyname><forenames>Ashok</forenames></author><author><keyname>Benson</keyname><forenames>Theophilus</forenames></author><author><keyname>Sekar</keyname><forenames>Vyas</forenames></author><author><keyname>Akella</keyname><forenames>Aditya</forenames></author></authors><title>Stratos: A Network-Aware Orchestration Layer for Virtual Middleboxes in
  Clouds</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Enterprises want their in-cloud services to leverage the performance and
security benefits that middleboxes offer in traditional deployments. Such
virtualized deployments create new opportunities (e.g., flexible scaling) as
well as new challenges (e.g., dynamics, multiplexing) for middlebox management
tasks such as service composition and provisioning. Unfortunately, enterprises
lack systematic tools to efficiently compose and provision in-the-cloud
middleboxes and thus fall short of achieving the benefits that cloud-based
deployments can offer. To this end, we present the design and implementation of
Stratos, an orchestration layer for virtual middleboxes. Stratos provides
efficient and correct composition in the presence of dynamic scaling via
software-defined networking mechanisms. It ensures efficient and scalable
provisioning by combining middlebox-specific traffic engineering, placement,
and horizontal scaling strategies. We demonstrate the effectiveness of Stratos
using an experimental prototype testbed and large-scale simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0213</identifier>
 <datestamp>2014-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0213</id><created>2013-05-01</created><updated>2014-02-13</updated><authors><author><keyname>Krishnamurthy</keyname><forenames>Akshay</forenames></author><author><keyname>Sharpnack</keyname><forenames>James</forenames></author><author><keyname>Singh</keyname><forenames>Aarti</forenames></author></authors><title>Recovering Graph-Structured Activations using Adaptive Compressive
  Measurements</title><categories>stat.ML cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the localization of a cluster of activated vertices in a graph, from
adaptively designed compressive measurements. We propose a hierarchical
partitioning of the graph that groups the activated vertices into few
partitions, so that a top-down sensing procedure can identify these partitions,
and hence the activations, using few measurements. By exploiting the cluster
structure, we are able to provide localization guarantees at weaker signal to
noise ratios than in the unstructured setting. We complement this performance
guarantee with an information theoretic lower bound, providing a necessary
signal-to-noise ratio for any algorithm to successfully localize the cluster.
We verify our analysis with some simulations, demonstrating the practicality of
our algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0218</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0218</id><created>2013-05-01</created><authors><author><keyname>Dushnik</keyname><forenames>Dina</forenames></author><author><keyname>Schclar</keyname><forenames>Alon</forenames></author><author><keyname>Averbuch</keyname><forenames>Amir</forenames></author></authors><title>Video Segmentation via Diffusion Bases</title><categories>cs.CV cs.MM</categories><comments>29 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identifying moving objects in a video sequence, which is produced by a static
camera, is a fundamental and critical task in many computer-vision
applications. A common approach performs background subtraction, which
identifies moving objects as the portion of a video frame that differs
significantly from a background model. A good background subtraction algorithm
has to be robust to changes in the illumination and it should avoid detecting
non-stationary background objects such as moving leaves, rain, snow, and
shadows. In addition, the internal background model should quickly respond to
changes in background such as objects that start to move or stop. We present a
new algorithm for video segmentation that processes the input video sequence as
a 3D matrix where the third axis is the time domain. Our approach identifies
the background by reducing the input dimension using the \emph{diffusion bases}
methodology. Furthermore, we describe an iterative method for extracting and
deleting the background. The algorithm has two versions and thus covers the
complete range of backgrounds: one for scenes with static backgrounds and the
other for scenes with dynamic (moving) backgrounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0219</identifier>
 <datestamp>2014-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0219</id><created>2013-05-01</created><updated>2014-01-09</updated><authors><author><keyname>Das</keyname><forenames>Tamal</forenames></author><author><keyname>Drogon</keyname><forenames>Marek</forenames></author><author><keyname>Jukan</keyname><forenames>Admela</forenames></author><author><keyname>Hoffmann</keyname><forenames>Marco</forenames></author></authors><title>Study of Network Migration to New Technologies using Agent-based
  Modeling Techniques</title><categories>cs.NI</categories><comments>Submitted to Springer Journal of Network and Systems Management</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conventionally, network migration models study competition between emerging
and incumbent technologies by considering the resulting increase in revenue and
associated cost of migration. We propose to advance the science in the existing
network migration models by considering additional critical factors, including
(i) synergistic relationships across multiple technologies, (ii) reduction in
operational expenditures (OpEx) as a reason to migrate, and, (iii) implications
of local network effects on migration decisions. To this end, we propose a
novel agent-based migration model considering these factors. Based on the
model, we analyze the case study of network migration to two emerging
networking paradigms, i.e., IETF Path Computation Element (PCE) and
Software-Defined Networking (SDN). We validate our model using extensive
simulations. Our results demonstrate the synergistic effects of migration to
multiple complementary technologies, and show that a technology migration may
be eased by the joint migration to multiple technologies. In particular, we
find that migration to SDN can be eased by joint migration to PCE, and that the
benefits derived from SDN are best exploited in combination with PCE, than by
itself.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0245</identifier>
 <datestamp>2013-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0245</id><created>2013-05-01</created><authors><author><keyname>Book</keyname><forenames>Theodore</forenames></author><author><keyname>Witick</keyname><forenames>Martha</forenames></author><author><keyname>Wallach</keyname><forenames>Dan S.</forenames></author></authors><title>Automated generation of web server fingerprints</title><categories>cs.CR cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we demonstrate that it is possible to automatically generate
fingerprints for various web server types using multifactor Bayesian inference
on randomly selected servers on the Internet, without building an a priori
catalog of server features or behaviors. This makes it possible to conclusively
study web server distribution without relying on reported (and variable)
version strings. We gather data by sending a collection of specialized requests
to 110,000 live web servers. Using only the server response codes, we then
train an algorithm to successfully predict server types independently of the
server version string. In the process, we note several distinguishing features
of current web infrastructure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0258</identifier>
 <datestamp>2013-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0258</id><created>2013-05-01</created><updated>2013-11-05</updated><authors><author><keyname>Monnig</keyname><forenames>Nathan D.</forenames></author><author><keyname>Fornberg</keyname><forenames>Bengt</forenames></author><author><keyname>Meyer</keyname><forenames>Francois G.</forenames></author></authors><title>Inverting Nonlinear Dimensionality Reduction with Scale-Free Radial
  Basis Function Interpolation</title><categories>math.NA cs.NA physics.data-an stat.ML</categories><comments>Accepted for publication in Applied and Computational Harmonic
  Analysis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nonlinear dimensionality reduction embeddings computed from datasets do not
provide a mechanism to compute the inverse map. In this paper, we address the
problem of computing a stable inverse map to such a general bi-Lipschitz map.
Our approach relies on radial basis functions (RBFs) to interpolate the inverse
map everywhere on the low-dimensional image of the forward map. We demonstrate
that the scale-free cubic RBF kernel performs better than the Gaussian kernel:
it does not suffer from ill-conditioning, and does not require the choice of a
scale. The proposed construction is shown to be similar to the Nystr\&quot;om
extension of the eigenvectors of the symmetric normalized graph Laplacian
matrix. Based on this observation, we provide a new interpretation of the
Nystr\&quot;om extension with suggestions for improvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0261</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0261</id><created>2013-05-01</created><authors><author><keyname>Cherifi1</keyname><forenames>Chantal</forenames></author><author><keyname>Labatut</keyname><forenames>Vincent</forenames></author><author><keyname>Santucci</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author></authors><title>Web Services Dependency Networks Analysis</title><categories>cs.IR cs.SI physics.soc-ph</categories><comments>arXiv admin note: substantial text overlap with arXiv:1305.0191</comments><journal-ref>International Conference of New Media and Interactivity (NMI), pp.
  115-120 (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Along with a continuously growing number of publicly available Web services
(WS), we are witnessing a rapid development in semantic-related web
technologies, which lead to the apparition of semantically described WS. In
this work, we perform a comparative analysis of the syntactic and semantic
approaches used to describe WS, from a complex network perspective. First, we
extract syntactic and semantic WS dependency networks from a collection of
publicly available WS descriptions. Then, we take advantage of tools from the
complex network field to analyze them and determine their topological
properties. We show WS dependency networks exhibit some of the typical
characteristics observed in real-world networks, such as small world and scale
free properties, as well as community structure. By comparing syntactic and
semantic networks through their topological properties, we show the
introduction of semantics in WS description allows modeling more accurately the
dependencies between parameters, which in turn could lead to improved
composition mining methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0297</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0297</id><created>2013-05-01</created><authors><author><keyname>Spivak</keyname><forenames>David I.</forenames></author></authors><title>The operad of wiring diagrams: formalizing a graphical language for
  databases, recursion, and plug-and-play circuits</title><categories>cs.DB math.CT math.LO</categories><comments>28 pages</comments><msc-class>18D50, 18A15, 18B10, 03B10, 03B70, 03D20, 68P15, 94C99</msc-class><acm-class>H.2.3; H.5; B.6; D.1.6; D.3.3; E.1; F.4.1; G.2.2; G.4; H.2.1</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Wiring diagrams, as seen in digital circuits, can be nested hierarchically
and thus have an aspect of self-similarity. We show that wiring diagrams form
the morphisms of an operad $\mcT$, capturing this self-similarity. We discuss
the algebra $\Rel$ of mathematical relations on $\mcT$, and in so doing use
wiring diagrams as a graphical language with which to structure queries on
relational databases. We give the example of circuit diagrams as a special
case. We move on to show how plug-and-play devices and also recursion can be
formulated in the operadic framework as well. Throughout we include many
examples and figures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0300</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0300</id><created>2013-05-01</created><authors><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author><author><keyname>Martinez</keyname><forenames>Genaro J.</forenames></author></authors><title>Bio-imitaiton of Mexican migration routes to the USA with slime mould on
  3D terrains</title><categories>cs.ET nlin.AO</categories><journal-ref>Adamatzky A. and Martinez G. J. Bio-Imitation of Mexican Migration
  Routes to the USA with Slime Mould on 3D Terrains. J Bionic Engineering 10
  (2013) 242--250</journal-ref><doi>10.1016/S1672-6529(13)60220-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Plasmodium of Physarum polycephalum is a large single cell visible by unaided
eye. It shows sophisticated behavioural traits in foraging for nutrients and
developing an optimal transport network of protoplasmic tubes spanning sources
of nutrients. When placed in an environment with distributed sources of
nutrients the cell 'computes' an optimal graph spanning the nutrients by
growing a network of protoplasmic tubes. P. polycephalum imitates development
of man-made transport networks of a country when configuration of nutrients
represents major urban areas. We employ this feature of the slime mould to
imitate mexican migration to USA. The Mexican migration to USA is the World's
largest migration system. We bio-physically imitate the migration using slime
mould P. polycephalum. In laboratory experiments with 3D Nylon terrains of USA
we imitated development of migratory routes from Mexico-USA border to ten urban
areas with high concentration of Mexican migrants. From results of laboratory
experiments we extracted topologies of migratory routes, and highlighted a role
of elevations in shaping the human movement networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0305</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0305</id><created>2013-05-01</created><authors><author><keyname>Hughes</keyname><forenames>Richard J.</forenames></author><author><keyname>Nordholt</keyname><forenames>Jane E.</forenames></author><author><keyname>McCabe</keyname><forenames>Kevin P.</forenames></author><author><keyname>Newell</keyname><forenames>Raymond T.</forenames></author><author><keyname>Peterson</keyname><forenames>Charles G.</forenames></author><author><keyname>Somma</keyname><forenames>Rolando D.</forenames></author></authors><title>Network-Centric Quantum Communications with Application to Critical
  Infrastructure Protection</title><categories>quant-ph cs.CR</categories><comments>7 pages, 3 figures</comments><report-no>LA-UR-13-22718 (version 2)</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network-centric quantum communications (NQC) - a new, scalable instantiation
of quantum cryptography providing key management with forward security for
lightweight encryption, authentication and digital signatures in optical
networks - is briefly described. Results from a multi-node experimental
test-bed utilizing integrated photonics quantum communications components,
known as QKarDs, include: quantum identification; verifiable quantum secret
sharing; multi-party authenticated key establishment, including group keying;
and single-fiber quantum-secured communications that can be applied as a
security retrofit/upgrade to existing optical fiber installations. A
demonstration that NQC meets the challenging simultaneous latency and security
requirements of electric grid control communications, which cannot be met
without compromises using conventional cryptography, is described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0311</identifier>
 <datestamp>2014-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0311</id><created>2013-05-01</created><authors><author><keyname>Guo</keyname><forenames>Zhenyu</forenames></author><author><keyname>Wang</keyname><forenames>Z. Jane</forenames></author></authors><title>An Adaptive Descriptor Design for Object Recognition in the Wild</title><categories>cs.CV</categories><comments>8 pages</comments><doi>10.1109/ICCV.2013.319</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital images nowadays have various styles of appearance, in the aspects of
color tones, contrast, vignetting, and etc. These 'picture styles' are directly
related to the scene radiance, image pipeline of the camera, and post
processing functions. Due to the complexity and nonlinearity of these causes,
popular gradient-based image descriptors won't be invariant to different
picture styles, which will decline the performance of object recognition. Given
that images shared online or created by individual users are taken with a wide
range of devices and may be processed by various post processing functions, to
find a robust object recognition system is useful and challenging. In this
paper, we present the first study on the influence of picture styles for object
recognition, and propose an adaptive approach based on the kernel view of
gradient descriptors and multiple kernel learning, without estimating or
specifying the styles of images used in training and testing. We conduct
experiments on Domain Adaptation data set and Oxford Flower data set. The
experiments also include several variants of the flower data set by processing
the images with popular photo effects. The results demonstrate that our
proposed method improve from standard descriptors in all cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0321</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0321</id><created>2013-05-01</created><authors><author><keyname>Tune</keyname><forenames>Paul</forenames></author><author><keyname>Nguyen</keyname><forenames>Hung X.</forenames></author><author><keyname>Roughan</keyname><forenames>Matthew</forenames></author></authors><title>Hidden Markov Model Identifiability via Tensors</title><categories>cs.IT math.IT</categories><comments>Accepted to ISIT 2013. 5 pages, no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The prevalence of hidden Markov models (HMMs) in various applications of
statistical signal processing and communications is a testament to the power
and flexibility of the model. In this paper, we link the identifiability
problem with tensor decomposition, in particular, the Canonical Polyadic
decomposition. Using recent results in deriving uniqueness conditions for
tensor decomposition, we are able to provide a necessary and sufficient
condition for the identification of the parameters of discrete time finite
alphabet HMMs. This result resolves a long standing open problem regarding the
derivation of a necessary and sufficient condition for uniquely identifying an
HMM. We then further extend recent preliminary work on the identification of
HMMs with multiple observers by deriving necessary and sufficient conditions
for identifiability in this setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0336</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0336</id><created>2013-05-01</created><authors><author><keyname>Gusev</keyname><forenames>Vladimir V.</forenames></author><author><keyname>Maslennikova</keyname><forenames>Marina I.</forenames></author><author><keyname>Pribavkina</keyname><forenames>Elena V.</forenames></author></authors><title>Finitely generated ideal languages and synchronizing automata</title><categories>cs.FL</categories><comments>Submitted to WORDS 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study representations of ideal languages by means of strongly connected
synchronizing automata. For every finitely generated ideal language L we
construct such an automaton with at most 2^n states, where n is the maximal
length of words in L. Our constructions are based on the De Bruijn graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0355</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0355</id><created>2013-05-02</created><authors><author><keyname>Javanmard</keyname><forenames>Adel</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Model Selection for High-Dimensional Regression under the Generalized
  Irrepresentability Condition</title><categories>math.ST cs.IT cs.LG math.IT stat.ME stat.ML stat.TH</categories><comments>32 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the high-dimensional regression model a response variable is linearly
related to $p$ covariates, but the sample size $n$ is smaller than $p$. We
assume that only a small subset of covariates is `active' (i.e., the
corresponding coefficients are non-zero), and consider the model-selection
problem of identifying the active covariates. A popular approach is to estimate
the regression coefficients through the Lasso ($\ell_1$-regularized least
squares). This is known to correctly identify the active set only if the
irrelevant covariates are roughly orthogonal to the relevant ones, as
quantified through the so called `irrepresentability' condition. In this paper
we study the `Gauss-Lasso' selector, a simple two-stage method that first
solves the Lasso, and then performs ordinary least squares restricted to the
Lasso active set. We formulate `generalized irrepresentability condition'
(GIC), an assumption that is substantially weaker than irrepresentability. We
prove that, under GIC, the Gauss-Lasso correctly recovers the active set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0356</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0356</id><created>2013-05-02</created><authors><author><keyname>Femminella</keyname><forenames>Mauro</forenames></author><author><keyname>Reali</keyname><forenames>Gianluca</forenames></author><author><keyname>Colitti</keyname><forenames>Walter</forenames></author><author><keyname>Steenhaut</keyname><forenames>Kris</forenames></author></authors><title>A Markovian Model for Assessing the Consistency of Vehicular Storage
  Systems</title><categories>cs.NI</categories><comments>Accepted for publication in IEEE LANMAN 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we evaluate the suitability of the vehicular devices for
supporting data storage and distribution applications. Vehicular storage
systems have recently emerged as means for making the information related to
the vehicular environment available to vehicular users. Information could
either be collected by sensors mounted onboard vehicles or coming from the
surrounding environment. Modeling a vehicular data storage and distribution
system requires the introduction of a number of parameters, such as the vehicle
concentration and transmission range, the value of which may determine the
suitability or unsuitability of the vehicular environment for establishing a
communication infrastructure with the desired quality. In this paper we show
how to solve this problem by resorting to a Markovian model and some results
achieved through its application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0357</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0357</id><created>2013-05-02</created><authors><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author></authors><title>Relevance distributions across Bradford Zones: Can Bradfordizing improve
  search?</title><categories>cs.IR cs.DL</categories><comments>11 pages, 2 figures, Preprint of a full paper @ 14th International
  Society of Scientometrics and Informetrics Conference (ISSI 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this paper is to describe the evaluation of the effectiveness
of the bibliometric technique Bradfordizing in an information retrieval (IR)
scenario. Bradfordizing is used to re-rank topical document sets from
conventional abstracting &amp; indexing (A&amp;I) databases into core and more
peripheral document zones. Bradfordized lists of journal articles and
monographs will be tested in a controlled scenario consisting of different A&amp;I
databases from social and political sciences, economics, psychology and medical
science, 164 standardized IR topics and intellectual assessments of the listed
documents. Does Bradfordizing improve the ratio of relevant documents in the
first third (core) compared to the second and last third (zone 2 and zone 3,
respectively)? The IR tests show that relevance distributions after re-ranking
improve at a significant level if documents in the core are compared with
documents in the succeeding zones. After Bradfordizing of document pools, the
core has a significant better average precision than zone 2, zone 3 and
baseline. This paper should be seen as an argument in favour of alternative
non-textual (bibliometric) re-ranking methods which can be simply applied in
text-based retrieval systems and in particular in A&amp;I databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0359</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0359</id><created>2013-05-02</created><authors><author><keyname>Femminella</keyname><forenames>M.</forenames></author><author><keyname>Reali</keyname><forenames>G.</forenames></author><author><keyname>Valocchi</keyname><forenames>D.</forenames></author><author><keyname>Francescangeli</keyname><forenames>R.</forenames></author><author><keyname>Schulzrinne</keyname><forenames>H.</forenames></author></authors><title>Advanced Caching for Distributing Sensor Data through Programmable Nodes</title><categories>cs.NI</categories><comments>Accepted for publication in IEEE LANMAN 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper shows an innovative solution for distributing dynamic sensor data
by using distributed caches. Our proposal is based on the concepts of service
modularization and virtualization of network nodes made available by the
NetServ hosting environment, which has been defined and implemented with the
aim of extending the functions of the network nodes. Through a lab experiment
involving tens of nodes, we have demonstrated a significant performance
improvements in term of traffic saving and download time in comparison with a
legacy, Internet-based, approach. Beyond this performance improvements, the
proposed solution holds also functional improvements, in terms of dynamic
deployment and easy integration with services making use of sensor data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0361</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0361</id><created>2013-05-02</created><authors><author><keyname>Zhang</keyname><forenames>Hai-Feng</forenames></author><author><keyname>Yang</keyname><forenames>Zimo</forenames></author><author><keyname>Wu</keyname><forenames>Zhi-Xi</forenames></author><author><keyname>Wang</keyname><forenames>Bing-Hong</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Braess's Paradox in Epidemic Game: Better Condition Results in Less
  Payoff</title><categories>physics.soc-ph cs.SI q-bio.PE</categories><comments>17 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Facing the threats of infectious diseases, we take various actions to protect
ourselves, but few studies considered an evolving system with competing
strategies. In view of that, we propose an evolutionary epidemic model coupled
with human behaviors, where individuals have three strategies: vaccination,
self-protection and laissez faire, and could adjust their strategies according
to their neighbors' strategies and payoffs at the beginning of each new season
of epidemic spreading. We found a counter-intuitive phenomenon analogous to the
well-known \emph{Braess's Paradox}, namely a better condition may lead to worse
performance. Specifically speaking, increasing the successful rate of
self-protection does not necessarily reduce the epidemic size or improve the
system payoff. This phenomenon is insensitive to the network topologies, and
can be well explained by a mean-field approximation. Our study demonstrates an
important fact that a better condition for individuals may yield a worse
outcome for the society.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0377</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0377</id><created>2013-05-02</created><authors><author><keyname>Chadegani</keyname><forenames>Arezoo Aghaei</forenames></author><author><keyname>Salehi</keyname><forenames>Hadi</forenames></author><author><keyname>Yunus</keyname><forenames>Melor Md</forenames></author><author><keyname>Farhadi</keyname><forenames>Hadi</forenames></author><author><keyname>Fooladi</keyname><forenames>Masood</forenames></author><author><keyname>Farhadi</keyname><forenames>Maryam</forenames></author><author><keyname>Ebrahim</keyname><forenames>Nader Ale</forenames></author></authors><title>A Comparison between Two Main Academic Literature Collections: Web of
  Science and Scopus Databases</title><categories>cs.DL cs.CY</categories><comments>9 pages, 4 figures</comments><msc-class>K.3.2</msc-class><journal-ref>Asian Social Science vol. 9, no. 5, pp. 18-26, April 27, 2013</journal-ref><doi>10.5539/ass.v9n5p18</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Nowadays, the worlds scientific community has been publishing an enormous
number of papers in different scientific fields. In such environment, it is
essential to know which databases are equally efficient and objective for
literature searches. It seems that two most extensive databases are Web of
Science and Scopus. Besides searching the literature, these two databases used
to rank journals in terms of their productivity and the total citations
received to indicate the journals impact, prestige or influence. This article
attempts to provide a comprehensive comparison of these databases to answer
frequent questions which researchers ask, such as: How Web of Science and
Scopus are different? In which aspects these two databases are similar? Or, if
the researchers are forced to choose one of them, which one should they prefer?
For answering these questions, these two databases will be compared based on
their qualitative and quantitative characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0379</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0379</id><created>2013-05-02</created><authors><author><keyname>Fooladi</keyname><forenames>Masood</forenames></author><author><keyname>Salehi</keyname><forenames>Hadi</forenames></author><author><keyname>Yunus</keyname><forenames>Melor Md</forenames></author><author><keyname>Farhadi</keyname><forenames>Maryam</forenames></author><author><keyname>Chadegani</keyname><forenames>Arezoo Aghaei</forenames></author><author><keyname>Farhadi</keyname><forenames>Hadi</forenames></author><author><keyname>Ebrahim</keyname><forenames>Nader Ale</forenames></author></authors><title>Does Criticisms Overcome the Praises of Journal Impact Factor?</title><categories>cs.DL</categories><comments>7 pages, No figure</comments><msc-class>K.3.2</msc-class><journal-ref>Asian Social Science vol. 9, no. 5, pp. 176-182, April 27, 2013</journal-ref><doi>10.5539/ass.v9n5p176</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Journal impact factor (IF) as a gauge of influence and impact of a particular
journal comparing with other journals in the same area of research, reports the
mean number of citations to the published articles in particular journal.
Although, IF attracts more attention and being used more frequently than other
measures, it has been subjected to criticisms, which overcome the advantages of
IF. Critically, extensive use of IF may result in destroying editorial and
researchers behaviour, which could compromise the quality of scientific
articles. Therefore, it is the time of the timeliness and importance of a new
invention of journal ranking techniques beyond the journal impact factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0384</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0384</id><created>2013-05-02</created><authors><author><keyname>Chaporkar</keyname><forenames>Prasanna</forenames></author><author><keyname>Proutiere</keyname><forenames>Alexandre</forenames></author></authors><title>Optimal Distributed Scheduling in Wireless Networks under the SINR
  interference model</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radio resource sharing mechanisms are key to ensuring good performance in
wireless networks. In their seminal paper \cite{tassiulas1}, Tassiulas and
Ephremides introduced the Maximum Weighted Scheduling algorithm, and proved its
throughput-optimality. Since then, there have been extensive research efforts
to devise distributed implementations of this algorithm. Recently, distributed
adaptive CSMA scheduling schemes \cite{jiang08} have been proposed and shown to
be optimal, without the need of message passing among transmitters. However
their analysis relies on the assumption that interference can be accurately
modelled by a simple interference graph. In this paper, we consider the more
realistic and challenging SINR interference model. We present {\it the first
distributed scheduling algorithms that (i) are optimal under the SINR
interference model, and (ii) that do not require any message passing}. They are
based on a combination of a simple and efficient power allocation strategy
referred to as {\it Power Packing} and randomization techniques. We first
devise algorithms that are rate-optimal in the sense that they perform as well
as the best centralized scheduling schemes in scenarios where each transmitter
is aware of the rate at which it should send packets to the corresponding
receiver. We then extend these algorithms so that they reach
throughput-optimality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0395</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0395</id><created>2013-05-02</created><authors><author><keyname>Cichocki</keyname><forenames>Andrzej</forenames></author></authors><title>Tensor Decompositions: A New Concept in Brain Data Analysis?</title><categories>cs.NA cs.LG q-bio.NC stat.ML</categories><journal-ref>Control Measurement, and System Integration (SICE), special issue;
  Measurement of Brain Functions and Bio-Signals, 7, 507-517, (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matrix factorizations and their extensions to tensor factorizations and
decompositions have become prominent techniques for linear and multilinear
blind source separation (BSS), especially multiway Independent Component
Analysis (ICA), NonnegativeMatrix and Tensor Factorization (NMF/NTF), Smooth
Component Analysis (SmoCA) and Sparse Component Analysis (SCA). Moreover,
tensor decompositions have many other potential applications beyond multilinear
BSS, especially feature extraction, classification, dimensionality reduction
and multiway clustering. In this paper, we briefly overview new and emerging
models and approaches for tensor decompositions in applications to group and
linked multiway BSS/ICA, feature extraction, classification andMultiway Partial
Least Squares (MPLS) regression problems. Keywords: Multilinear BSS, linked
multiway BSS/ICA, tensor factorizations and decompositions, constrained Tucker
and CP models, Penalized Tensor Decompositions (PTD), feature extraction,
classification, multiway PLS and CCA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0412</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0412</id><created>2013-05-02</created><authors><author><keyname>Reboredo</keyname><forenames>Hugo</forenames></author><author><keyname>Xavier</keyname><forenames>Jo&#xe3;o</forenames></author><author><keyname>Rodrigues</keyname><forenames>Miguel R. D.</forenames></author></authors><title>Filter Design with Secrecy Constraints: The MIMO Gaussian Wiretap
  Channel</title><categories>cs.IT math.IT</categories><comments>38 pages, 11 figures. Accepted for publication in IEEE Transactions
  on Signal Processing</comments><doi>10.1109/TSP.2013.2262275</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of filter design with secrecy constraints,
where two legitimate parties (Alice and Bob) communicate in the presence of an
eavesdropper (Eve), over a Gaussian multiple-input-multiple-output (MIMO)
wiretap channel. This problem involves designing, subject to a power
constraint, the transmit and the receive filters which minimize the
mean-squared error (MSE) between the legitimate parties whilst assuring that
the eavesdropper MSE remains above a certain threshold. We consider a general
MIMO Gaussian wiretap scenario, where the legitimate receiver uses a linear
Zero-Forcing (ZF) filter and the eavesdropper receiver uses either a ZF or an
optimal linear Wiener filter. We provide a characterization of the optimal
filter designs by demonstrating the convexity of the optimization problems. We
also provide generalizations of the filter designs from the scenario where the
channel state is known to all the parties to the scenario where there is
uncertainty in the channel state. A set of numerical results illustrates the
performance of the novel filter designs, including the robustness to channel
modeling errors. In particular, we assess the efficacy of the designs in
guaranteeing not only a certain MSE level at the eavesdropper, but also in
limiting the error probability at the eavesdropper. We also assess the impact
of the filter designs on the achievable secrecy rates. The penalty induced by
the fact that the eavesdropper may use the optimal non-linear receive filter
rather than the optimal linear one is also explored in the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0423</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0423</id><created>2013-05-02</created><authors><author><keyname>Danafar</keyname><forenames>Somayeh</forenames></author><author><keyname>Rancoita</keyname><forenames>Paola M. V.</forenames></author><author><keyname>Glasmachers</keyname><forenames>Tobias</forenames></author><author><keyname>Whittingstall</keyname><forenames>Kevin</forenames></author><author><keyname>Schmidhuber</keyname><forenames>Juergen</forenames></author></authors><title>Testing Hypotheses by Regularized Maximum Mean Discrepancy</title><categories>cs.LG cs.AI stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Do two data samples come from different distributions? Recent studies of this
fundamental problem focused on embedding probability distributions into
sufficiently rich characteristic Reproducing Kernel Hilbert Spaces (RKHSs), to
compare distributions by the distance between their embeddings. We show that
Regularized Maximum Mean Discrepancy (RMMD), our novel measure for kernel-based
hypothesis testing, yields substantial improvements even when sample sizes are
small, and excels at hypothesis tests involving multiple comparisons with power
control. We derive asymptotic distributions under the null and alternative
hypotheses, and assess power control. Outstanding results are obtained on:
challenging EEG data, MNIST, the Berkley Covertype, and the Flare-Solar
dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0433</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0433</id><created>2013-05-02</created><authors><author><keyname>Chapelle</keyname><forenames>Mathieu</forenames><affiliation>University Paris Est, France</affiliation></author><author><keyname>Liedloff</keyname><forenames>Mathieu</forenames><affiliation>University of Orleans, France</affiliation></author><author><keyname>Todinca</keyname><forenames>Ioan</forenames><affiliation>University of Orleans, France</affiliation></author><author><keyname>Villanger</keyname><forenames>Yngve</forenames><affiliation>University of Bergen, Norway</affiliation></author></authors><title>TREEWIDTH and PATHWIDTH parameterized by vertex cover</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  After the number of vertices, Vertex Cover is the largest of the classical
graph parameters and has more and more frequently been used as a separate
parameter in parameterized problems, including problems that are not directly
related to the Vertex Cover. Here we consider the TREEWIDTH and PATHWIDTH
problems parameterized by k, the size of a minimum vertex cover of the input
graph. We show that the PATHWIDTH and TREEWIDTH can be computed in O*(3^k)
time. This complements recent polynomial kernel results for TREEWIDTH and
PATHWIDTH parameterized by the Vertex Cover.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0434</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0434</id><created>2013-05-02</created><authors><author><keyname>Leroy</keyname><forenames>Julien</forenames></author></authors><title>An $S$-adic characterization of minimal subshifts with first difference
  of complexity $1 \leq p(n+1) - p(n) \leq 2$</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In [Ergodic Theory Dynam. System, 16 (1996) 663--682], S. Ferenczi proved
that any minimal subshift with first difference of complexity bounded by 2 is
$S$-adic with $\card S \leq 3^{27}$. In this paper, we improve this result by
giving an $S$-adic charaterization of these subshifts with a set $S$ of 5
morphisms, solving by this way the $S$-adic conjecture for this particular
case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0435</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0435</id><created>2013-05-02</created><authors><author><keyname>Darling1</keyname><forenames>Emily S.</forenames></author><author><keyname>Shiffman</keyname><forenames>David</forenames></author><author><keyname>C&#xf4;t&#xe9;</keyname><forenames>Isabelle M.</forenames></author><author><keyname>Drew</keyname><forenames>Joshua A.</forenames></author></authors><title>The role of twitter in the life cycle of a scientific publication</title><categories>cs.DL cs.CY physics.soc-ph q-bio.PE</categories><comments>31 pages, 5 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Twitter is a micro-blogging social media platform for short messages that can
have a long-term impact on how scientists create and publish ideas. We
investigate the usefulness of twitter in the development and distribution of
scientific knowledge. At the start of the life cycle of a scientific
publication, twitter provides a large virtual department of colleagues that can
help to rapidly generate, share and refine new ideas. As ideas become
manuscripts, twitter can be used as an informal arena for the pre-review of
works in progress. Finally, tweeting published findings can communicate
research to a broad audience of other researchers, decision makers, journalists
and the general public that can amplify the scientific and social impact of
publications. However, there are limitations, largely surrounding issues of
intellectual property and ownership, inclusiveness and misrepresentations of
science sound bites. Nevertheless, we believe twitter is a useful social media
tool that can provide a valuable contribution to scientific publishing in the
21st century.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0438</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0438</id><created>2013-05-02</created><authors><author><keyname>Zhou</keyname><forenames>Jie</forenames></author><author><keyname>Yan</keyname><forenames>Gang</forenames></author><author><keyname>Lai</keyname><forenames>Choy-Heng</forenames></author></authors><title>Efficient routing on multilayered communication networks</title><categories>cs.NI physics.soc-ph</categories><comments>6 pages, 4 figures</comments><journal-ref>Europhysics Letters, 102 (2013) 28002</journal-ref><doi>10.1209/0295-5075/102/28002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the optimal routing on multilayered communication networks, which
are composed of two layers of subnetworks. One is a wireless network, and the
other is a wired network. We develop a simple recurrent algorithm to find an
optimal routing on this kind of multilayered network, where the single-channel
transmission mode and the multichannel transmission mode used on the wireless
subnetwork are considered, respectively. Compared with the performance of the
shortest path algorithm, our algorithm can significantly enhance the transport
capacity. We show that our methods proposed in this letter could take advantage
of the coupling of the two layers to the most extent, so that the wireless
subnetwork could sufficiently utilize the wired subnetwork for transportation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0445</identifier>
 <datestamp>2013-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0445</id><created>2013-05-02</created><updated>2013-06-06</updated><authors><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Deep Learning of Representations: Looking Forward</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning research aims at discovering learning algorithms that discover
multiple levels of distributed representations, with higher levels representing
more abstract concepts. Although the study of deep learning has already led to
impressive theoretical results, learning algorithms and breakthrough
experiments, several challenges lie ahead. This paper proposes to examine some
of these challenges, centering on the questions of scaling deep learning
algorithms to much larger models and datasets, reducing optimization
difficulties due to ill-conditioning or local minima, designing more efficient
and powerful inference and sampling procedures, and learning to disentangle the
factors of variation underlying the observed data. It also proposes a few
forward-looking research directions aimed at overcoming these challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0453</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0453</id><created>2013-05-02</created><authors><author><keyname>Kawamura</keyname><forenames>Akitoshi</forenames></author><author><keyname>Cook</keyname><forenames>Stephen</forenames></author></authors><title>Complexity Theory for Operators in Analysis</title><categories>cs.CC math.NA</categories><comments>22 pages, 9 figures; a few typos fixed after journal publication</comments><msc-class>03D15, 65Y20, 68Q05, 68Q15</msc-class><acm-class>F.1.1; F.1.3</acm-class><journal-ref>ACM Transactions on Computation Theory 4(2), Article 5, 2012</journal-ref><doi>10.1145/2189778.2189780</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an extension of the framework for discussing the computational
complexity of problems involving uncountably many objects, such as real
numbers, sets and functions, that can be represented only through
approximation. The key idea is to use (a certain class of) string functions as
names representing these objects. These are more expressive than infinite
sequences, which served as names in prior work that formulated complexity in
more restricted settings. An advantage of using string functions is that we can
define their &quot;size&quot; in the way inspired by higher-type complexity theory. This
enables us to talk about computation on string functions whose time or space is
bounded polynomially in the input size, giving rise to more general analogues
of the classes P, NP, and PSPACE. We also define NP- and PSPACE-completeness
under suitable many-one reductions.
  Because our framework separates machine computation and semantics, it can be
applied to problems on sets of interest in analysis once we specify a suitable
representation (encoding). As prototype applications, we consider the
complexity of functions (operators) on real numbers, real sets, and real
functions. For example, the task of numerical algorithms for solving a certain
class of differential equations is naturally viewed as an operator taking real
functions to real functions. As there was no complexity theory for operators,
previous results only stated how complex the solution can be. We now
reformulate them and show that the operator itself is polynomial-space
complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0458</identifier>
 <datestamp>2013-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0458</id><created>2013-05-02</created><updated>2013-12-03</updated><authors><author><keyname>Pagani</keyname><forenames>Giuliano Andrea</forenames></author><author><keyname>Aiello</keyname><forenames>Marco</forenames></author></authors><title>From the Grid to the Smart Grid, Topologically</title><categories>physics.soc-ph cs.CE cs.CY cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Smart Grid is not just about the digitalization of the Power Grid. In its
more visionary acceptation, it is a model of energy management in which the
users are engaged in producing energy as well as consuming it, while having
information systems fully aware of the energy demand-response of the network
and of dynamically varying prices. A natural question is then: to make the
Smart Grid a reality will the Distribution Grid have to be updated? We assume a
positive answer to the question and we consider the lower layers of Medium and
Low Voltage to be the most affected by the change. In our previous work, we
have analyzed samples of the Dutch Distribution Grid in our previous work and
we have considered possible evolutions of these using synthetic topologies
modeled after studies of complex systems in other technological domains in
another previous work. In this paper, we take an extra important further step
by defining a methodology for evolving any existing physical Power Grid to a
good Smart Grid model thus laying the foundations for a decision support system
for utilities and governmental organizations. In doing so, we consider several
possible evolution strategies and apply then to the Dutch Distribution Grid. We
show how more connectivity is beneficial in realizing more efficient and
reliable networks. Our proposal is topological in nature, and enhanced with
economic considerations of the costs of such evolutions in terms of cabling
expenses and economic benefits of evolving the Grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0467</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0467</id><created>2013-05-02</created><authors><author><keyname>Cherifi</keyname><forenames>Chantal</forenames></author><author><keyname>Santucci</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author></authors><title>On Topological Structure of Web Services Networks for Composition</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to deal efficiently with the exponential growth of the Web services
landscape in composition life cycle activities, it is necessary to have a clear
view of its main features. As for many situations where there is a lot of
interacting entities, the complex networks paradigm is an appropriate approach
to analyze the interactions between the multitudes of Web services. In this
paper, we present and investigate the main interactions between semantic Web
services models from the complex network perspective. Results show that both
parameter and operation networks exhibit the main characteristics of typical
real-world complex networks such as the small-world property and an
inhomogeneous degree distribution. These results yield valuable insight in
order to develop composition search algorithms, to deal with security threat in
the composition process and on the phenomena which characterize its evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0471</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0471</id><created>2013-05-02</created><authors><author><keyname>Cherifi</keyname><forenames>Chantal</forenames></author><author><keyname>Santucci</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author></authors><title>Community Structure in Interaction Web Service Networks</title><categories>cs.SI cs.NI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real-world complex systems such as social, biological, information as
well as technological systems results of a decentralized and unplanned
evolution which leads to a common structuration. Irrespective of their origin,
these so-called complex networks typically exhibit small-world and scale-free
properties. Another common feature is their organisation into communities. In
this paper, we introduce models of interaction networks based on the
composition process of syntactic and semantic Web services. An extensive
experimental study conducted on a benchmark of real Web services shows that
these networks possess the typical properties of complex networks (small-world,
scale-free). Unlike most social networks, they are not transitive. Using a
representative sample of community detection algorithms, a community
structuration is revealed. The comparative evaluation of the discovered
community structures shows that they are very similar in terms of content.
Furthermore, the analysis performed on the community structures and on the
communities themselves, leads us to conclude that their topological properties
are consistent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0483</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0483</id><created>2013-05-02</created><authors><author><keyname>Choudhari</keyname><forenames>A V</forenames></author><author><keyname>Pande</keyname><forenames>N A</forenames></author><author><keyname>Gupta</keyname><forenames>M R</forenames></author></authors><title>Feasibility Analysis of Low Cost Graphical Processing Units for
  Electromagnetic Field Simulations by Finite Difference Time Domain Method</title><categories>cs.DC physics.comp-ph</categories><doi>10.5120/11739-7396</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Among several techniques available for solving Computational Electromagnetics
(CEM) problems, the Finite Difference Time Domain (FDTD) method is one of the
best suited approaches when a parallelized hardware platform is used. In this
paper we investigate the feasibility of implementing the FDTD method using the
NVIDIA GT 520, a low cost Graphical Processing Unit (GPU), for solving the
differential form of Maxwell's equation in time domain. Initially a generalized
benchmarking problem of bandwidth test and another benchmarking problem of
'matrix left division is discussed for understanding the correlation between
the problem size and the performance on the CPU and the GPU respectively. This
is further followed by the discussion of the FDTD method, again implemented on
both, the CPU and the GT520 GPU. For both of the above comparisons, the CPU
used is Intel E5300, a low cost dual core CPU.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0502</identifier>
 <datestamp>2013-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0502</id><created>2013-05-02</created><updated>2013-07-01</updated><authors><author><keyname>Jin</keyname><forenames>Ruoming</forenames></author><author><keyname>Wang</keyname><forenames>Guan</forenames></author></authors><title>Simple, Fast, and Scalable Reachability Oracle</title><categories>cs.DB</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A reachability oracle (or hop labeling) assigns each vertex v two sets of
vertices: Lout(v) and Lin(v), such that u reaches v iff Lout(u) \cap Lin(v)
\neq \emptyset. Despite their simplicity and elegance, reachability oracles
have failed to achieve efficiency in more than ten years since their
introduction: the main problem is high construction cost, which stems from a
set-cover framework and the need to materialize transitive closure. In this
paper, we present two simple and efficient labeling algorithms,
Hierarchical-Labeling and Distribution-Labeling, which can work onmassive
real-world graphs: their construction time is an order of magnitude faster than
the setcover based labeling approach, and transitive closure materialization is
not needed. On large graphs, their index sizes and their query performance can
now beat the state-of-the-art transitive closure compression and online search
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0503</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0503</id><created>2013-05-02</created><authors><author><keyname>Han</keyname><forenames>Jaemin</forenames></author><author><keyname>Wang</keyname><forenames>Chih-Chun</forenames></author><author><keyname>Shroff</keyname><forenames>Ness B.</forenames></author></authors><title>Graph-Theoretic Characterization of The Feasibility of The
  Precoding-Based 3-Unicast Interference Alignment Scheme</title><categories>cs.IT math.IT</categories><comments>35 pages, 4 figures, and 2 tables. This manuscript was submitted to
  IEEE Trans IT in May 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new precoding-based intersession network coding (NC) scheme has recently
been proposed, which applies the interference alignment technique, originally
devised for wireless interference channels, to the 3-unicast problem of
directed acyclic networks. The main result of this work is a graph-theoretic
characterization of the feasibility of the 3-unicast interference alignment
scheme. To that end, we first investigate several key relationships between the
point-to-point network channel gains and the underlying graph structure. Such
relationships turn out to be critical when characterizing graph-theoretically
the feasibility of precoding-based solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0505</identifier>
 <datestamp>2014-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0505</id><created>2013-05-02</created><updated>2014-11-12</updated><authors><author><keyname>Babbitt</keyname><forenames>Matthew</forenames></author><author><keyname>Geneson</keyname><forenames>J. T.</forenames></author><author><keyname>Khovanova</keyname><forenames>Tanya</forenames></author></authors><title>On k-visibility graphs</title><categories>math.CO cs.DM</categories><comments>17 pages, 6 figures</comments><msc-class>05C35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine several types of visibility graphs in which sightlines can pass
through $k$ objects. For $k \geq 1$ we bound the maximum thickness of semi-bar
$k$-visibility graphs between $\lceil \frac{2}{3} (k + 1) \rceil$ and $2k$. In
addition we show that the maximum number of edges in arc and circle
$k$-visibility graphs on $n$ vertices is at most $(k+1)(3n-k-2)$ for $n &gt; 4k+4$
and ${n \choose 2}$ for $n \leq 4k+4$, while the maximum chromatic number is at
most $6k+6$. In semi-arc $k$-visibility graphs on $n$ vertices, we show that
the maximum number of edges is ${n \choose 2}$ for $n \leq 3k+3$ and at most
$(k+1)(2n-\frac{k+2}{2})$ for $n &gt; 3k+3$, while the maximum chromatic number is
at most $4k+4$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0507</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0507</id><created>2013-05-02</created><authors><author><keyname>Jin</keyname><forenames>Ruoming</forenames></author><author><keyname>Ruan</keyname><forenames>Ning</forenames></author><author><keyname>You</keyname><forenames>Bo</forenames></author><author><keyname>Wang</keyname><forenames>Haixun</forenames></author></authors><title>Hub-Accelerator: Fast and Exact Shortest Path Computation in Large
  Social Networks</title><categories>cs.SI cs.DB physics.soc-ph</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shortest path computation is one of the most fundamental operations for
managing and analyzing large social networks. Though existing techniques are
quite effective for finding the shortest path on large but sparse road
networks, social graphs have quite different characteristics: they are
generally non-spatial, non-weighted, scale-free, and they exhibit small-world
properties in addition to their massive size. In particular, the existence of
hubs, those vertices with a large number of connections, explodes the search
space, making the shortest path computation surprisingly challenging. In this
paper, we introduce a set of novel techniques centered around hubs,
collectively referred to as the Hub-Accelerator framework, to compute the
k-degree shortest path (finding the shortest path between two vertices if their
distance is within k). These techniques enable us to significantly reduce the
search space by either greatly limiting the expansion scope of hubs (using the
novel distance- preserving Hub-Network concept) or completely pruning away the
hubs in the online search (using the Hub2-Labeling approach). The
Hub-Accelerator approaches are more than two orders of magnitude faster than
BFS and the state-of-the-art approximate shortest path method Sketch for the
shortest path computation. The Hub- Network approach does not introduce
additional index cost with light pre-computation cost; the index size and index
construction cost of Hub2-Labeling are also moderate and better than or
comparable to the approximation indexing Sketch method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0510</identifier>
 <datestamp>2013-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0510</id><created>2013-05-01</created><updated>2013-07-07</updated><authors><author><keyname>Li</keyname><forenames>Zhi</forenames></author><author><keyname>Zhu</keyname><forenames>Xiaoqing</forenames></author><author><keyname>Gahm</keyname><forenames>Josh</forenames></author><author><keyname>Pan</keyname><forenames>Rong</forenames></author><author><keyname>Hu</keyname><forenames>Hao</forenames></author><author><keyname>Begen</keyname><forenames>Ali C.</forenames></author><author><keyname>Oran</keyname><forenames>Dave</forenames></author></authors><title>Probe and Adapt: Rate Adaptation for HTTP Video Streaming At Scale</title><categories>cs.NI</categories><comments>Bridged version submitted to IEEE Journal on Selected Areas in
  Communications, Special Issue on Adaptive Media Streaming</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today, the technology for video streaming over the Internet is converging
towards a paradigm named HTTP-based adaptive streaming (HAS). HAS comes with
two unique flavors. First, by riding on top of HTTP/TCP, it leverages the
network-friendly TCP to achieve firewall/NATS traversal and bandwidth sharing.
Second, by pre-encoding and storing the video in a number of discrete bitrate
levels, it introduces video bitrate adaptivity in a scalable way that the video
encoding is excluded from the closed-loop adaptation. A conventional wisdom is
that the TCP throughput observed by a HAS client indicates the available
network bandwidth, thus can be used as a reliable reference for the video
bitrate selection.
  We argue that this no longer holds true when HAS becomes a substantial
fraction of the Internet traffic. We show that when multiple HAS clients
compete at a network bottleneck, the presence of competing clients and the
discrete nature of the video bitrates would together create confusion for a
client to correctly perceive its fair-share bandwidth. Through analysis and
real experiments, we demonstrate that this fundamental limitation would lead
to, for example, video rate oscillation that negatively impacts the video
watching experiences. We therefore argue that it is necessary to implement at
the application layer a &quot;probe-and-adapt&quot; mechanism for HAS video rate
adaptation, which is akin but orthogonal to the transport-layer network rate
adaptation achieved by TCP. We present PANDA -- a client-side rate adaptation
algorithm for HAS -- as an embodiment of this idea. Our testbed results show
that compared to conventional algorithms, PANDA is able to reduce the
instability of video rate by 60%, at a given risk of buffer underrun.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0512</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0512</id><created>2013-05-02</created><authors><author><keyname>Whidden</keyname><forenames>Chris</forenames></author><author><keyname>Beiko</keyname><forenames>Robert G.</forenames></author><author><keyname>Zeh</keyname><forenames>Norbert</forenames></author></authors><title>Fixed-Parameter and Approximation Algorithms for Maximum Agreement
  Forests of Multifurcating Trees</title><categories>cs.DS q-bio.PE</categories><comments>28 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present efficient algorithms for computing a maximum agreement forest
(MAF) of a pair of multifurcating (nonbinary) rooted trees. Our algorithms
match the running times of the currently best algorithms for the binary case.
The size of an MAF corresponds to the subtree prune-and-regraft (SPR) distance
of the two trees and is intimately connected to their hybridization number.
These distance measures are essential tools for understanding reticulate
evolution, such as lateral gene transfer, recombination, and hybridization.
Multifurcating trees arise naturally as a result of statistical uncertainty in
current tree construction methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0513</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0513</id><created>2013-05-02</created><authors><author><keyname>Jin</keyname><forenames>Ruoming</forenames></author><author><keyname>Shen</keyname><forenames>Yelong</forenames></author><author><keyname>Liu</keyname><forenames>Lin</forenames></author><author><keyname>Chen</keyname><forenames>Xue-wen</forenames></author></authors><title>Limiting the Neighborhood: De-Small-World Network for Outbreak
  Prevention</title><categories>cs.SI physics.soc-ph</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we study a basic and practically important strategy to help
prevent and/or delay an outbreak in the context of network: limiting the
contact between individuals. In this paper, we introduce the average
neighborhood size as a new measure for the degree of being small-world and
utilize it to formally define the desmall- world network problem. We also prove
the NP-hardness of the general reachable pair cut problem and propose a greedy
edge betweenness based approach as the benchmark in selecting the candidate
edges for solving our problem. Furthermore, we transform the de-small-world
network problem as an OR-AND Boolean function maximization problem, which is
also an NP-hardness problem. In addition, we develop a numerical relaxation
approach to solve the Boolean function maximization and the de-small-world
problem. Also, we introduce the short-betweenness, which measures the edge
importance in terms of all short paths with distance no greater than a certain
threshold, and utilize it to speed up our numerical relaxation approach. The
experimental evaluation demonstrates the effectiveness and efficiency of our
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0516</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0516</id><created>2013-05-02</created><authors><author><keyname>Jancar</keyname><forenames>Petr</forenames></author></authors><title>Finiteness up to bisimilarity is decidable for pushdown processes</title><categories>cs.LO cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that it is decidable if a given configuration of a pushdown
automaton (pda) with no epsilon-transitions is bisimulation equivalent with
some unspecified finite-state process. While the semidecidability of the
positive case has been long clear, it is the existence of a finite effectively
verifiable witness of the negative case which is the crucial point here. The
presented algorithm also uses a procedure for deciding bisimilarity between pda
configurations, which is known due to Senizergues (1998, 2005). The complexity
of the procedure is non-elementary, as shown by Benedikt, Goeller, Kiefer, and
Murawski (2012), but the EXPTIME-hardness (Kucera and Mayr 2002, and Srba 2002)
remains the only known complexity bound for the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0526</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0526</id><created>2013-05-02</created><authors><author><keyname>Sachdeva</keyname><forenames>Sushant</forenames></author><author><keyname>Vishnoi</keyname><forenames>Nisheeth K.</forenames></author></authors><title>Matrix Inversion Is As Easy As Exponentiation</title><categories>cs.DS cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the inverse of a positive-definite matrix can be approximated
by a weighted-sum of a small number of matrix exponentials. Combining this with
a previous result [OSV12], we establish an equivalence between matrix inversion
and exponentiation up to polylogarithmic factors. In particular, this
connection justifies the use of Laplacian solvers for designing fast
semi-definite programming based algorithms for certain graph problems. The
proof relies on the Euler-Maclaurin formula and certain bounds derived from the
Riemann zeta function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0534</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0534</id><created>2013-05-02</created><authors><author><keyname>Kleinberg</keyname><forenames>Robert</forenames></author><author><keyname>Yuan</keyname><forenames>Yang</forenames></author></authors><title>On the Ratio of Revenue to Welfare in Single-Parameter Mechanism Design</title><categories>cs.GT</categories><comments>15 pages</comments><acm-class>J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  What fraction of the potential social surplus in an environment can be
extracted by a revenue-maximizing monopolist? We investigate this problem in
Bayesian single-parameter environments with independent private values. The
precise answer to the question obviously depends on the particulars of the
environment: the feasibility constraint and the distributions from which the
bidders' private values are sampled. Rather than solving the problem in
particular special cases, our work aims to provide universal lower bounds on
the revenue-to-welfare ratio that hold under the most general hypotheses that
allow for non-trivial such bounds.
  Our results can be summarized as follows. For general feasibility
constraints, the revenue-to-welfare ratio is at least a constant times the
inverse-square-root of the number of agents, and this is tight up to constant
factors. For downward-closed feasibility constraints, the revenue-to-welfare
ratio is bounded below by a constant. Both results require the bidders'
distributions to satisfy hypotheses somewhat stronger than regularity; we show
that the latter result cannot avoid this requirement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0538</identifier>
 <datestamp>2013-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0538</id><created>2013-05-02</created><updated>2013-12-12</updated><authors><author><keyname>Bernardo</keyname><forenames>Marco</forenames></author><author><keyname>De Nicola</keyname><forenames>Rocco</forenames></author><author><keyname>Loreti</keyname><forenames>Michele</forenames></author></authors><title>A Companion of &quot;Relating Strong Behavioral Equivalences for Processes
  with Nondeterminism and Probabilities&quot;</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the paper &quot;Relating Strong Behavioral Equivalences for Processes with
Nondeterminism and Probabilities&quot; to appear in TCS, we present a comparison of
behavioral equivalences for nondeterministic and probabilistic processes. In
particular, we consider strong trace, failure, testing, and bisimulation
equivalences. For each of these groups of equivalences, we examine the
discriminating power of three variants stemming from three approaches that
differ for the way probabilities of events are compared when nondeterministic
choices are resolved via deterministic schedulers. The established
relationships are summarized in a so-called spectrum. However, the equivalences
we consider in that paper are only a small subset of those considered in the
original spectrum of equivalences for nondeterministic systems introduced by
Rob van Glabbeek. In this companion paper we we enlarge the spectrum by
considering variants of trace equivalences (completed-trace equivalences),
additional decorated-trace equivalences (failure-trace, readiness, and
ready-trace equivalences), and variants of bisimulation equivalences (kernels
of simulation, completed-simulation, failure-simulation, and ready-simulation
preorders). Moreover, we study how the spectrum changes when randomized
schedulers are used instead of deterministic ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0540</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0540</id><created>2013-05-02</created><updated>2013-05-13</updated><authors><author><keyname>Shang</keyname><forenames>Shang</forenames></author><author><keyname>Hui</keyname><forenames>Yuk</forenames></author><author><keyname>Hui</keyname><forenames>Pan</forenames></author><author><keyname>Cuff</keyname><forenames>Paul</forenames></author><author><keyname>Kulkarni</keyname><forenames>Sanjeev</forenames></author></authors><title>Privacy Preserving Recommendation System Based on Groups</title><categories>cs.IR</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Recommendation systems have received considerable attention in the recent
decades. Yet with the development of information technology and social media,
the risk in revealing private data to service providers has been a growing
concern to more and more users. Trade-offs between quality and privacy in
recommendation systems naturally arise. In this paper, we present a privacy
preserving recommendation framework based on groups. The main idea is to use
groups as a natural middleware to preserve users' privacy. A distributed
preference exchange algorithm is proposed to ensure the anonymity of data,
wherein the effective size of the anonymity set asymptotically approaches the
group size with time. We construct a hybrid collaborative filtering model based
on Markov random walks to provide recommendations and predictions to group
members. Experimental results on the MovieLens and Epinions datasets show that
our proposed methods outperform the baseline methods, L+ and ItemRank, two
state-of-the-art personalized recommendation algorithms, for both
recommendation precision and hit rate despite the absence of personal
preference information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0543</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0543</id><created>2013-05-02</created><authors><author><keyname>Lambiotte</keyname><forenames>Renaud</forenames></author><author><keyname>Tabourier</keyname><forenames>Lionel</forenames></author><author><keyname>Delvenne</keyname><forenames>Jean-Charles</forenames></author></authors><title>Burstiness and spreading on temporal networks</title><categories>physics.soc-ph cs.SI q-bio.PE</categories><comments>5 pages</comments><doi>10.1140/epjb/e2013-40456-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss how spreading processes on temporal networks are impacted by the
shape of their inter-event time distributions. Through simple mathematical
arguments and toy examples, we find that the key factor is the ordering in
which events take place, a property that tends to be affected by the bulk of
the distributions and not only by their tail, as usually considered in the
literature. We show that a detailed modeling of the temporal patterns observed
in complex networks can change dramatically the properties of a spreading
process, such as the ergodicity of a random walk process or the persistence of
an epidemic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0547</identifier>
 <datestamp>2013-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0547</id><created>2013-05-02</created><authors><author><keyname>Somekh-Baruch</keyname><forenames>Anelia</forenames></author></authors><title>On Achievable Rates for Channels with Mismatched Decoding</title><categories>cs.IT math.IT</categories><comments>A shorter version of this paper was accepted to the International
  Symposium on Information Theory 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of mismatched decoding for discrete memoryless channels is
addressed. A mismatched cognitive multiple-access channel is introduced, and an
inner bound on its capacity region is derived using two alternative encoding
methods: superposition coding and random binning. The inner bounds are derived
by analyzing the average error probability of the code ensemble for both
methods and by a tight characterization of the resulting error exponents.
Random coding converse theorems are also derived. A comparison of the
achievable regions shows that in the matched case, random binning performs as
well as superposition coding, i.e., the region achievable by random binning is
equal to the capacity region. The achievability results are further specialized
to obtain a lower bound on the mismatch capacity of the single-user channel by
investigating a cognitive multiple access channel whose achievable sum-rate
serves as a lower bound on the single-user channel's capacity. In certain
cases, for given auxiliary random variables this bound strictly improves on the
achievable rate derived by Lapidoth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0548</identifier>
 <datestamp>2014-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0548</id><created>2013-05-02</created><updated>2014-11-22</updated><authors><author><keyname>Garber</keyname><forenames>David</forenames></author><author><keyname>Kahrobaei</keyname><forenames>Delaram</forenames></author><author><keyname>Lam</keyname><forenames>Ha T.</forenames></author></authors><title>Length-based attacks in polycyclic groups</title><categories>math.GR cs.CR</categories><comments>J. Math. Crypt. 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  After the Anshel-Anshel-Goldfeld (AAG) key-exchange protocol was introduced
in 1999, it was implemented and studied with braid groups and with the Thompson
group as its underlying platforms. The length-based attack, introduced by
Hughes and Tannenbaum, has been used to extensively study AAG with the braid
group as the underlying platform. Meanwhile, a new platform, using polycyclic
groups, was proposed by Eick and Kahrobaei.
  In this paper, we show that with a high enough Hirsch length, the polycyclic
group as an underlying platform for AAG is resistant to the length-based
attack. In particular, polycyclic groups could provide a secure platform for
any cryptosystem based on conjugacy search problem such as non-commutative
Diffie-Hellman, ElGamal and Cramer-Shoup key exchange protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0552</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0552</id><created>2013-05-02</created><authors><author><keyname>Perc</keyname><forenames>Matjaz</forenames></author></authors><title>Self-organization of progress across the century of physics</title><categories>physics.soc-ph cs.DL cs.SI physics.data-an</categories><comments>5 two-column pages, 5 figures; accepted for publication in Scientific
  Reports [the n-gram viewer for publications of the American Physical Society
  is available at http://www.matjazperc.com/aps]</comments><journal-ref>Sci. Rep. 3 (2013) 1720</journal-ref><doi>10.1038/srep01720</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We make use of information provided in the titles and abstracts of over half
a million publications that were published by the American Physical Society
during the past 119 years. By identifying all unique words and phrases and
determining their monthly usage patterns, we obtain quantifiable insights into
the trends of physics discovery from the end of the 19th century to today. We
show that the magnitudes of upward and downward trends yield heavy-tailed
distributions, and that their emergence is due to the Matthew effect. This
indicates that both the rise and fall of scientific paradigms is driven by
robust principles of self-organization. Data also confirm that periods of war
decelerate scientific progress, and that the later is very much subject to
globalization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0556</identifier>
 <datestamp>2013-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0556</id><created>2013-05-02</created><updated>2013-10-11</updated><authors><author><keyname>Clark</keyname><forenames>Stephen</forenames></author><author><keyname>Coecke</keyname><forenames>Bob</forenames></author><author><keyname>Grefenstette</keyname><forenames>Edward</forenames></author><author><keyname>Pulman</keyname><forenames>Stephen</forenames></author><author><keyname>Sadrzadeh</keyname><forenames>Mehrnoosh</forenames></author></authors><title>A quantum teleportation inspired algorithm produces sentence meaning
  from word meaning and grammatical structure</title><categories>cs.CL quant-ph</categories><comments>10 pages, many pictures</comments><msc-class>68T50</msc-class><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss an algorithm which produces the meaning of a sentence given
meanings of its words, and its resemblance to quantum teleportation. In fact,
this protocol was the main source of inspiration for this algorithm which has
many applications in the area of Natural Language Processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0574</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0574</id><created>2013-05-02</created><updated>2013-05-06</updated><authors><author><keyname>Jabbour</keyname><forenames>Said</forenames></author><author><keyname>Sais</keyname><forenames>Lakhdar</forenames></author><author><keyname>Salhi</keyname><forenames>Yakoub</forenames></author></authors><title>Extending Modern SAT Solvers for Enumerating All Models</title><categories>cs.AI</categories><comments>This paper is withdrawn by the authors due to a missing reference.
  The authors work further on this issue and conduct exhaustive experimental
  comparison with other related works</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the problem of enumerating all models of a Boolean
formula in conjunctive normal form (CNF). We propose an extension of CDCL-based
SAT solvers to deal with this fundamental problem. Then, we provide an
experimental evaluation of our proposed SAT model enumeration algorithms on
both satisfiable SAT instances taken from the last SAT challenge and on
instances from the SAT-based encoding of sequence mining problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0576</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0576</id><created>2013-05-02</created><updated>2013-08-13</updated><authors><author><keyname>Ad&#xe1;mek</keyname><forenames>Ji&#x159;&#xed;</forenames><affiliation>Institut f&#xfc;r Theoretische Informatik, Technische Universit&#xe4;t Braunschweig, Germany</affiliation></author><author><keyname>Milius</keyname><forenames>Stefan</forenames><affiliation>Institut f&#xfc;r Theoretische Informatik, Technische Universit&#xfc;t Braunschweig, Germany</affiliation></author><author><keyname>Moss</keyname><forenames>Lawrence S</forenames><affiliation>Department of Mathematics, Indiana University, Bloomington, IN, USA</affiliation></author><author><keyname>Sousa</keyname><forenames>Lurdes</forenames><affiliation>Polytechnic Institute of Viseu and Centre for Mathematics of the University of Coimbra, Portugal</affiliation></author></authors><title>Well-Pointed Coalgebras</title><categories>cs.LO math.CT</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 3 (August 9,
  2013) lmcs:704</journal-ref><doi>10.2168/LMCS-9(3:2)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For endofunctors of varieties preserving intersections, a new description of
the final coalgebra and the initial algebra is presented: the former consists
of all well-pointed coalgebras. These are the pointed coalgebras having no
proper subobject and no proper quotient. The initial algebra consists of all
well-pointed coalgebras that are well-founded in the sense of Osius and Taylor.
And initial algebras are precisely the final well-founded coalgebras. Finally,
the initial iterative algebra consists of all finite well-pointed coalgebras.
Numerous examples are discussed e.g. automata, graphs, and labeled transition
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0585</identifier>
 <datestamp>2013-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0585</id><created>2013-05-02</created><updated>2013-12-04</updated><authors><author><keyname>Zhao</keyname><forenames>Changhong</forenames></author><author><keyname>Topcu</keyname><forenames>Ufuk</forenames></author><author><keyname>Li</keyname><forenames>Na</forenames></author><author><keyname>Low</keyname><forenames>Steven</forenames></author></authors><title>Design and Stability of Load-Side Primary Frequency Control in Power
  Systems</title><categories>cs.SY math.OC</categories><comments>14 pages, 13 figures. To appear in IEEE Transactions on Automatic
  Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a systematic method to design ubiquitous continuous fast-acting
distributed load control for primary frequency regulation in power networks, by
formulating an optimal load control (OLC) problem where the objective is to
minimize the aggregate cost of tracking an operating point subject to power
balance over the network. We prove that the swing dynamics and the branch power
flows, coupled with frequency-based load control, serve as a distributed
primal-dual algorithm to solve OLC. We establish the global asymptotic
stability of a multimachine network under such type of load-side primary
frequency control. These results imply that the local frequency deviations at
each bus convey exactly the right information about the global power imbalance
for the loads to make individual decisions that turn out to be globally
optimal. Simulations confirm that the proposed algorithm can rebalance power
and resynchronize bus frequencies after a disturbance with significantly
improved transient performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0596</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0596</id><created>2013-05-02</created><authors><author><keyname>Hassan</keyname><forenames>Taha</forenames></author><author><keyname>Javed</keyname><forenames>Fahad</forenames></author><author><keyname>Arshad</keyname><forenames>Naveed</forenames></author></authors><title>An Empirical Investigation of V-I Trajectory based Load Signatures for
  Non-Intrusive Load Monitoring</title><categories>cs.CE</categories><comments>11 pages, 11 figures. Under review for IEEE Transactions on Smart
  Grid</comments><doi>10.1109/TSG.2013.2271282</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Choice of load signature or feature space is one of the most fundamental
design choices for non-intrusive load monitoring or energy disaggregation
problem. Electrical power quantities, harmonic load characteristics, canonical
transient and steady-state waveforms are some of the typical choices of load
signature or load signature basis for current research addressing appliance
classification and prediction. This paper expands and evaluates appliance load
signatures based on V-I trajectory - the mutual locus of instantaneous voltage
and current waveforms - for precision and robustness of prediction in
classification algorithms used to disaggregate residential overall energy use
and predict constituent appliance profiles. We also demonstrate the use of
variants of differential evolution as a novel strategy for selection of optimal
load models in context of energy disaggregation. A publicly available benchmark
dataset REDD is employed for evaluation purposes. Our experimental evaluations
indicate that these load signatures, in conjunction with a number of popular
classification algorithms, offer better or generally comparable overall
precision of prediction, robustness and reliability against dynamic, noisy and
highly similar load signatures with reference to electrical power quantities
and harmonic content. Herein, wave-shape features are found to be an effective
new basis of classification and prediction for semi-automated energy
disaggregation and monitoring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0597</identifier>
 <datestamp>2013-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0597</id><created>2013-05-02</created><authors><author><keyname>Chawla</keyname><forenames>Shuchi</forenames></author><author><keyname>Hartline</keyname><forenames>Jason D.</forenames></author><author><keyname>Malec</keyname><forenames>David</forenames></author><author><keyname>Sivan</keyname><forenames>Balasubramanian</forenames></author></authors><title>Prior-Independent Mechanisms for Scheduling</title><categories>cs.GT cs.DS</categories><comments>This paper will appear in Proceedings of the ACM Symposium on Theory
  of Computing 2013 (STOC'13)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the makespan minimization problem with unrelated selfish machines
under the assumption that job sizes are stochastic. We design simple truthful
mechanisms that under various distributional assumptions provide constant and
sublogarithmic approximations to expected makespan. Our mechanisms are
prior-independent in that they do not rely on knowledge of the job size
distributions. Prior-independent approximation mechanisms have been previously
studied for the objective of revenue maximization [Dhangwatnotai, Roughgarden
and Yan'10, Devanur, Hartline, Karlin and Nguyen'11, Roughgarden, Talgam-Cohen
and Yan'12]. In contrast to our results, in prior-free settings no truthful
anonymous deterministic mechanism for the makespan objective can provide a
sublinear approximation [Ashlagi, Dobzinski and Lavi'09].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0598</identifier>
 <datestamp>2013-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0598</id><created>2013-05-02</created><authors><author><keyname>Fu</keyname><forenames>Hu</forenames></author><author><keyname>Lucier</keyname><forenames>Brendan</forenames></author><author><keyname>Sivan</keyname><forenames>Balasubramanian</forenames></author><author><keyname>Syrgkanis</keyname><forenames>Vasilis</forenames></author></authors><title>Cost-Recovering Bayesian Algorithmic Mechanism Design</title><categories>cs.GT</categories><comments>This paper will appear in Proceedings of the ACM Conference on
  Electronic Commerce 2013 (EC'13)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the design of Bayesian incentive compatible mechanisms in single
parameter domains, for the objective of optimizing social efficiency as
measured by social cost. In the problems we consider, a group of participants
compete to receive service from a mechanism that can provide such services at a
cost. The mechanism wishes to choose which agents to serve in order to maximize
social efficiency, but is not willing to suffer an expected loss: the agents'
payments should cover the cost of service in expectation.
  We develop a general method for converting arbitrary approximation algorithms
for the underlying optimization problem into Bayesian incentive compatible
mechanisms that are cost-recovering in expectation. In particular, we give
polynomial time black-box reductions from the mechanism design problem to the
problem of designing a social cost minimization algorithm without incentive
constraints. Our reduction increases the expected social cost of the given
algorithm by a factor of O(log(min{n, h})), where n is the number of agents and
h is the ratio between the highest and lowest nonzero valuations in the
support. We also provide a lower bound illustrating that this inflation of the
social cost is essential: no BIC cost-recovering mechanism can achieve an
approximation factor better than \Omega(log(n)) or \Omega(log(h)) in general.
  Our techniques extend to show that a certain class of truthful algorithms can
be made cost-recovering in the non-Bayesian setting, in such a way that the
approximation factor degrades by at most O(log(min{n, h})). This is an
improvement over previously-known constructions with inflation factor O(log n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0606</identifier>
 <datestamp>2013-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0606</id><created>2013-05-02</created><authors><author><keyname>Mahdian</keyname><forenames>Alireza</forenames></author><author><keyname>Han</keyname><forenames>Richard</forenames></author><author><keyname>Lv</keyname><forenames>Qin</forenames></author><author><keyname>Mishra</keyname><forenames>Shivakant</forenames></author></authors><title>Results from a Practical Deployment of the MyZone Decentralized P2P
  Social Network</title><categories>cs.CR cs.DC cs.SI</categories><comments>24 pages, 13 Figures, 1 Table. arXiv admin note: text overlap with
  arXiv:1110.5371</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents MyZone, a private online social network for relatively
small, closely-knit communities. MyZone has three important distinguishing
features. First, users keep the ownership of their data and have complete
control over maintaining their privacy. Second, MyZone is free from any
possibility of content censorship and is highly resilient to any single point
of disconnection. Finally, MyZone minimizes deployment cost by minimizing its
computation, storage and network bandwidth requirements. It incorporates both a
P2P architecture and a centralized architecture in its design ensuring high
availability, security and privacy. A prototype of MyZone was deployed over a
period of 40 days with a membership of more than one hundred users. The paper
provides a detailed evaluation of the results obtained from this deployment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0619</identifier>
 <datestamp>2013-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0619</id><created>2013-05-03</created><authors><author><keyname>Sassioui</keyname><forenames>Redouane</forenames></author><author><keyname>Hamss</keyname><forenames>Aata El</forenames></author><author><keyname>Szczecinski</keyname><forenames>Leszek</forenames></author><author><keyname>Benjillali</keyname><forenames>Mustapha</forenames></author></authors><title>Resource Allocation for Downlink Channel Transmission Based on
  Superposition Coding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the problem of transmitting information to multiple users over a
shared wireless channel. The problem of resource allocation (RA) for the users
with the knowledge of their channel state information has been treated
extensively in the literature where various approaches trading off the users'
throughput and fairness were proposed. The emphasis was mostly on the
time-sharing (TS) approach, where the resource allocated to the user is
equivalent to its time share of the channel access. In this work, we propose to
take advantage of the broadcast nature of the channel and we adopt
superposition coding (SC)-known to outperform TS in multiple users broadcasting
scenarios. In SC, users' messages are simultaneously transmitted by superposing
their codewords with different power fractions under a total power constraint.
The main challenge is to find a simple way to allocate these power fractions to
all users taking into account the fairness/throughput tradeoff. We present an
algorithm with this purpose and we apply it in the case of popular proportional
fairness (PF). The obtained results using SC are illustrated with various
numerical examples where, comparing to TS, a rate increase between 20% and 300%
is observed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0625</identifier>
 <datestamp>2013-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0625</id><created>2013-05-03</created><authors><author><keyname>Sharma</keyname><forenames>Kamlesh</forenames></author><author><keyname>Prasad</keyname><forenames>Dr. T. V.</forenames></author></authors><title>CONATION: English Command Input/Output System for Computers</title><categories>cs.HC cs.CL</categories><comments>6 pages, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this information technology age, a convenient and user friendly interface
is required to operate the computer system on very fast rate. In the human
being, speech being a natural mode of communication has potential to being a
fast and convenient mode of interaction with computer. Speech recognition will
play an important role in taking technology to them. It is the need of this era
to access the information within seconds. This paper describes the design and
development of speaker independent and English command interpreted system for
computers. HMM model is used to represent the phoneme like speech commands.
Experiments have been done on real world data and system has been trained in
normal condition for real world subject.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0626</identifier>
 <datestamp>2013-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0626</id><created>2013-05-03</created><authors><author><keyname>Chen</keyname><forenames>Fuqiang</forenames></author></authors><title>An Improved EM algorithm</title><categories>cs.LG cs.AI stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we firstly give a brief introduction of expectation
maximization (EM) algorithm, and then discuss the initial value sensitivity of
expectation maximization algorithm. Subsequently, we give a short proof of EM's
convergence. Then, we implement experiments with the expectation maximization
algorithm (We implement all the experiments on Gaussion mixture model (GMM)).
Our experiment with expectation maximization is performed in the following
three cases: initialize randomly; initialize with result of K-means; initialize
with result of K-medoids. The experiment result shows that expectation
maximization algorithm depend on its initial state or parameters. And we found
that EM initialized with K-medoids performed better than both the one
initialized with K-means and the one initialized randomly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0638</identifier>
 <datestamp>2013-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0638</id><created>2013-05-03</created><authors><author><keyname>Wang</keyname><forenames>Deqing</forenames></author><author><keyname>Zhang</keyname><forenames>Hui</forenames></author><author><keyname>Liu</keyname><forenames>Rui</forenames></author><author><keyname>Lv</keyname><forenames>Weifeng</forenames></author></authors><title>Feature Selection Based on Term Frequency and T-Test for Text
  Categorization</title><categories>cs.LG cs.IR stat.ML</categories><comments>5pages 9 figures CIKM2012 paper</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Much work has been done on feature selection. Existing methods are based on
document frequency, such as Chi-Square Statistic, Information Gain etc.
However, these methods have two shortcomings: one is that they are not reliable
for low-frequency terms, and the other is that they only count whether one term
occurs in a document and ignore the term frequency. Actually, high-frequency
terms within a specific category are often regards as discriminators.
  This paper focuses on how to construct the feature selection function based
on term frequency, and proposes a new approach based on $t$-test, which is used
to measure the diversity of the distributions of a term between the specific
category and the entire corpus. Extensive comparative experiments on two text
corpora using three classifiers show that our new approach is comparable to or
or slightly better than the state-of-the-art feature selection methods (i.e.,
$\chi^2$, and IG) in terms of macro-$F_1$ and micro-$F_1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0648</identifier>
 <datestamp>2013-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0648</id><created>2013-05-03</created><updated>2013-12-20</updated><authors><author><keyname>Bruse</keyname><forenames>Florian</forenames></author><author><keyname>Friedmann</keyname><forenames>Oliver</forenames></author><author><keyname>Lange</keyname><forenames>Martin</forenames></author></authors><title>On Guarded Transformation In The Modal Mu-Calculus</title><categories>cs.LO</categories><comments>Expanded version, submitted to: Logic Journal of the IGPL</comments><msc-class>03B44, 68Q60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Guarded normal form requires occurrences of fixpoint variables in a
{\mu}-calculus-formula to occur under the scope of a modal operator. The
literature contains guarded transformations that effectively bring a
{\mu}-calculus-formula into guarded normal form. We show that the known guarded
transformations can cause an exponential blowup in formula size, contrary to
existing claims of polynomial behaviour. We also show that any polynomial
guarded transformation for {\mu}-calculus-formulas in the more relaxed
vectorial form gives rise to a polynomial solution algorithm for parity games,
the existence of which is an open problem. We also investigate transformations
between the {\mu}-calculus, vectorial form and hierarchical equation systems,
which are an alternative syntax for alternating parity tree automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0649</identifier>
 <datestamp>2013-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0649</id><created>2013-05-03</created><updated>2013-10-28</updated><authors><author><keyname>Bulteau</keyname><forenames>Laurent</forenames></author><author><keyname>Komusiewicz</keyname><forenames>Christian</forenames></author></authors><title>Minimum Common String Partition Parameterized by Partition Size is
  Fixed-Parameter Tractable</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The NP-hard Minimum Common String Partition problem asks whether two strings
$x$ and $y$ can each be partitioned into at most $k$ substrings, called blocks,
such that both partitions use exactly the same blocks in a different order. We
present the first fixed-parameter algorithm for Minimum Common String Partition
using only parameter $k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0664</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0664</id><created>2013-05-03</created><updated>2013-06-03</updated><authors><author><keyname>Serafimovski</keyname><forenames>N.</forenames></author><author><keyname>Younis</keyname><forenames>A.</forenames></author><author><keyname>Mesleh</keyname><forenames>R.</forenames></author><author><keyname>Chambers</keyname><forenames>P.</forenames></author><author><keyname>Di Renzo</keyname><forenames>M.</forenames></author><author><keyname>Wang</keyname><forenames>C. X.</forenames></author><author><keyname>Grant</keyname><forenames>P. M.</forenames></author><author><keyname>Beach</keyname><forenames>M. A.</forenames></author><author><keyname>Haas</keyname><forenames>H.</forenames></author></authors><title>Practical Implementation of Spatial Modulation</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Vehicular Technology, accepted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we seek to characterise the performance of spatial modulation
(SM) and spatial multiplexing (SMX) with an experimental test bed. Two National
Instruments (NI)-PXIe devices are used for the system testing, one for the
transmitter and one for the receiver. The digital signal processing that
formats the information data in preparation of transmission is described along
with the digital signal processing that recovers the information data. In
addition, the hardware limitations of the system are also analysed. The average
bit error ratio (ABER) of the system is validated through both theoretical
analysis and simulation results for SM and SMX under line of sight (LoS)
channel conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0665</identifier>
 <datestamp>2013-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0665</id><created>2013-05-03</created><updated>2013-10-12</updated><authors><author><keyname>Chen</keyname><forenames>Fuqiang</forenames></author><author><keyname>Wu</keyname><forenames>Yan</forenames></author><author><keyname>Bu</keyname><forenames>Yude</forenames></author><author><keyname>Zhao</keyname><forenames>Guodong</forenames></author></authors><title>Spectral Classification Using Restricted Boltzmann Machine</title><categories>cs.LG</categories><comments>8 pages, 2 figures, Accepted in PASA for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, a novel machine learning algorithm, restricted Boltzmann
machine (RBM), is introduced. The algorithm is applied for the spectral
classification in astronomy. RBM is a bipartite generative graphical model with
two separate layers (one visible layer and one hidden layer), which can extract
higher level features to represent the original data. Despite generative, RBM
can be used for classification when modified with a free energy and a soft-max
function. Before spectral classification, the original data is binarized
according to some rule. Then we resort to the binary RBM to classify
cataclysmic variables (CVs) and non-CVs (one half of all the given data for
training and the other half for testing). The experiment result shows
state-of-the-art accuracy of 100%, which indicates the efficiency of the binary
RBM algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0668</identifier>
 <datestamp>2013-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0668</id><created>2013-05-03</created><authors><author><keyname>Ismaeel</keyname><forenames>Ayad Ghany</forenames></author><author><keyname>Yousif</keyname><forenames>Raghad Zuhair</forenames></author><author><keyname>Abdallh</keyname><forenames>Essa F.</forenames></author></authors><title>GUI Based Automatic Remote Control of Gas Reduction System using PIC
  Microcontroller</title><categories>cs.OH</categories><comments>11 pages, 25 figures, Tables 4, and this research obtained
  certificate from Erbil Power Station, which is the beneficiary company of it.
  Available at http://www.estij.org/papers/vol3no22013/1vol3no2.pdf, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The GRS is a one of the important units in Erbil Power Station EPS, which is
responsible on controlling gas pressure and gas temperature this unit
previously works manually. The local control panel for GRS system contains two
types of digital signals the first one indicated by Light Emitting Diodes LED
to point normal operations, fault and alarm, and event of operations while the
second indicated by ON-OFF switches, which consists of two types the push
buttons switch and mode selector switch. To overcome human in manual control
faults in controlling GRS systems, automation system becomes the best solution.
The purpose of this research is to design and implement embedded automation
system that can be used to control a GRS automatically through a GUI and from
remote location by using programmable interface controller (PIC16F877A). In
this research the (PIC) software which is based on (C language), developed by
Microchip (MPLAB) is used in programming a PIC microcontroller, then Visual
Basic is used in the construction of GUI, the RS-232 serial cable is used as a
connector between PIC and PC. Implement the proposed design and test it as a
first system shows all operations of GRS successful were converted into full
computerize controlling (with the ability of full automatic control) from
remote location through proposed GUI. Keywords-Peripheral Interface Controller
(PIC); Microcontroller; Graphical User Interface (GUI); Remote; Control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0669</identifier>
 <datestamp>2013-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0669</id><created>2013-05-03</created><authors><author><keyname>Boyar</keyname><forenames>Joan</forenames></author><author><keyname>Gupta</keyname><forenames>Sushmita</forenames></author><author><keyname>Larsen</keyname><forenames>Kim S.</forenames></author></authors><title>Relative Interval Analysis of Paging Algorithms on Access Graphs</title><categories>cs.DS</categories><comments>IMADA-preprint-cs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Access graphs, which have been used previously in connection with competitive
analysis and relative worst order analysis to model locality of reference in
paging, are considered in connection with relative interval analysis. The
algorithms LRU, FIFO, FWF, and FAR are compared using the path, star, and cycle
access graphs. In this model, some of the expected results are obtained.
However, although LRU is found to be strictly better than FIFO on paths, it has
worse performance on stars, cycles, and complete graphs, in this model. We
solve an open question from [Dorrigiv, Lopez-Ortiz, Munro, 2009], obtaining
tight bounds on the relationship between LRU and FIFO with relative interval
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0673</identifier>
 <datestamp>2013-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0673</id><created>2013-05-03</created><authors><author><keyname>Ismaeel</keyname><forenames>Ayad Ghany</forenames></author><author><keyname>Rizqo</keyname><forenames>Sanaa Enwaya</forenames></author></authors><title>Optimal Productivity of Succoring Patients System using Mobile GIS Based
  on WCF Technology</title><categories>cs.CY</categories><comments>10 pages, 5 figures, 2 tables. Available at
  http://www.ijcnwc.org/papers/vol3no22013/4vol3no2.pdf, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Depending on references of the World Health Organization there is large
numbers of sick persons with different diseases worldwide, and without succor
at a suitable time this could lead to fatality of the patients. This paper
offers a succoring system controlled by the patient based on the location of
patients. The proposed system is the first tracking system using mobile GIS
based on WCF technology to offer online succoring (24 hour a day), but really
works only when the patient sends request for succoring. The patients will send
a request (SMS by click one button) contains his ID, Longitude and Latitude via
GPRS network to a web server containing a database, which the patient was
registered previously on it. Then the server will locate the patient on Google
map and retrieve the patient's information from the database. This information
will be used by the server to send succoring facility and notify the nearest
and most suitable ESC; moreover, the server will send SMS over IP to inform the
patient emergency contacts and emergency hospital. The optimal productivity for
proposed succoring system appears in handling a large number of requests within
short period at rate of one request/need succoring per sec as result of using
mobile GIS based on WCF technology. Furthermore, the process of request and
reply for emergency cases of the patients achieved in costeffective way due to
this technology, which allow sending data (SMS over IP) via Internet using GPRS
network. The proposed system can be implemented in a minimum configuration
(hardware and software) to minimize the overall cost of operation and
manufacturing. Keywords- WCF; WPF; Build-in GPS; GPRS; Mobile GIS; SoIP;
Tracking System; Google Maps API.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0674</identifier>
 <datestamp>2013-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0674</id><created>2013-05-03</created><authors><author><keyname>Arz</keyname><forenames>Julian</forenames></author><author><keyname>Fischer</keyname><forenames>Johannes</forenames></author></authors><title>LZ-Compressed String Dictionaries</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to compress string dictionaries using the Lempel-Ziv (LZ78) data
compression algorithm. Our approach is validated experimentally on dictionaries
of up to 1.5 GB of uncompressed text. We achieve compression ratios often
outperforming the existing alternatives, especially on dictionaries containing
many repeated substrings. Our query times remain competitive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0688</identifier>
 <datestamp>2015-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0688</id><created>2013-05-03</created><authors><author><keyname>Cherifi</keyname><forenames>Chantal</forenames></author><author><keyname>Labatut</keyname><forenames>Vincent</forenames></author><author><keyname>Santucci</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author></authors><title>On Flexible Web Services Composition Networks</title><categories>cs.SE cs.IR</categories><journal-ref>In: International Conference on Digital Information and
  Communication Technology and its Applications (DICTAP), Springer CCIS, Dijon,
  France (2011)</journal-ref><doi>10.1007/978-3-642-21984-9_5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The semantic Web service community develops efforts to bring semantics to Web
service descriptions and allow automatic discovery and composition. However,
there is no widespread adoption of such descriptions yet, because semantically
defining Web services is highly complicated and costly. As a result, production
Web services still rely on syntactic descriptions, key-word based discovery and
predefined compositions. Hence, more advanced research on syntactic Web
services is still ongoing. In this work we build syntactic composition Web
services networks with three well known similarity metrics, namely Levenshtein,
Jaro and Jaro-Winkler. We perform a comparative study on the metrics
performance by studying the topological properties of networks built from a
test collection of real-world descriptions. It appears Jaro-Winkler finds more
appropriate similarities and can be used at higher thresholds. For lower
thresholds, the Jaro metric would be preferable because it detect less
irrelevant relationships.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0698</identifier>
 <datestamp>2013-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0698</id><created>2013-05-03</created><authors><author><keyname>H&#xfc;llermeier</keyname><forenames>Eyke</forenames></author></authors><title>Learning from Imprecise and Fuzzy Observations: Data Disambiguation
  through Generalized Loss Minimization</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Methods for analyzing or learning from &quot;fuzzy data&quot; have attracted increasing
attention in recent years. In many cases, however, existing methods (for
precise, non-fuzzy data) are extended to the fuzzy case in an ad-hoc manner,
and without carefully considering the interpretation of a fuzzy set when being
used for modeling data. Distinguishing between an ontic and an epistemic
interpretation of fuzzy set-valued data, and focusing on the latter, we argue
that a &quot;fuzzification&quot; of learning algorithms based on an application of the
generic extension principle is not appropriate. In fact, the extension
principle fails to properly exploit the inductive bias underlying statistical
and machine learning methods, although this bias, at least in principle, offers
a means for &quot;disambiguating&quot; the fuzzy data. Alternatively, we therefore
propose a method which is based on the generalization of loss functions in
empirical risk minimization, and which performs model identification and data
disambiguation simultaneously. Elaborating on the fuzzification of specific
types of losses, we establish connections to well-known loss functions in
regression and classification. We compare our approach with related methods and
illustrate its use in logistic regression for binary classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0699</identifier>
 <datestamp>2013-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0699</id><created>2013-05-03</created><authors><author><keyname>Asadi</keyname><forenames>Nima</forenames></author><author><keyname>Lin</keyname><forenames>Jimmy</forenames></author></authors><title>Fast, Incremental Inverted Indexing in Main Memory for Web-Scale
  Collections</title><categories>cs.IR cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For text retrieval systems, the assumption that all data structures reside in
main memory is increasingly common. In this context, we present a novel
incremental inverted indexing algorithm for web-scale collections that directly
constructs compressed postings lists in memory. Designing efficient in-memory
algorithms requires understanding modern processor architectures and memory
hierarchies: in this paper, we explore the issue of postings lists contiguity.
Naturally, postings lists that occupy contiguous memory regions are preferred
for retrieval, but maintaining contiguity increases complexity and slows
indexing. On the other hand, allowing discontiguous index segments simplifies
index construction but decreases retrieval performance. Understanding this
tradeoff is our main contribution: We find that co-locating small groups of
inverted list segments yields query evaluation performance that is
statistically indistinguishable from fully-contiguous postings lists. In other
words, it is not necessary to lay out in-memory data structures such that all
postings for a term are contiguous; we can achieve ideal performance with a
relatively small amount of effort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0711</identifier>
 <datestamp>2013-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0711</id><created>2013-05-03</created><authors><author><keyname>Evseenko</keyname><forenames>Nina</forenames></author></authors><title>New hybrid distributed voting algorithm</title><categories>cs.DC cs.CR</categories><comments>3 pages, 2 figures, ICCAT 2013 conference</comments><msc-class>68M14</msc-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Increasing data volumes requires additional rating techniques. Reputation
systems are the subject of much research. There are various techniques to rate
content that facilitate the search of quality content. Page rank, citation
index and votes from users are some rating examples. In the article I focus on
decentralized vote systems. The article reviews several distributed vote
designs. I list the distributed vote requirements. A new hybrid algorithm is
proposed which operates in the structured overlay P2P DHT Kademlia network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0735</identifier>
 <datestamp>2013-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0735</id><created>2013-05-03</created><authors><author><keyname>Tan</keyname><forenames>Onur</forenames></author><author><keyname>Gunduz</keyname><forenames>Deniz</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Increasing Smart Meter Privacy Through Energy Harvesting and Storage
  Devices</title><categories>cs.IT math.IT</categories><comments>11 pages, 8 figures, to appear in the IEEE JSAC Smart Grid Series</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smart meters are key elements for the operation of smart grids. By providing
near realtime information on the energy consumption of individual users, smart
meters increase the efficiency in generation, distribution and storage of
energy in a smart grid. The ability of the utility provider to track users
energy consumption inevitably leads to important threats to privacy. In this
paper, privacy in a smart metering system is studied from an information
theoretic perspective in the presence of energy harvesting and storage units.
It is shown that energy harvesting provides increased privacy by diversifying
the energy source, while a storage device can be used to increase both the
energy efficiency and the privacy of the user. For given input load and energy
harvesting rates, it is shown that there exists a trade-off between the
information leakage rate, which is used to measure the privacy of the user, and
the wasted energy rate, which is a measure of the energy-efficiency. The impact
of the energy harvesting rate and the size of the storage device on this
trade-off is also studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0750</identifier>
 <datestamp>2015-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0750</id><created>2013-05-03</created><updated>2015-07-28</updated><authors><author><keyname>Kindermann</keyname><forenames>Philipp</forenames></author><author><keyname>Niedermann</keyname><forenames>Benjamin</forenames></author><author><keyname>Rutter</keyname><forenames>Ignaz</forenames></author><author><keyname>Schaefer</keyname><forenames>Marcus</forenames></author><author><keyname>Schulz</keyname><forenames>Andr&#xe9;</forenames></author><author><keyname>Wolff</keyname><forenames>Alexander</forenames></author></authors><title>Multi-Sided Boundary Labeling</title><categories>cs.CG</categories><doi>10.1007/s00453-015-0028-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Boundary Labeling problem, we are given a set of $n$ points, referred
to as sites, inside an axis-parallel rectangle $R$, and a set of $n$ pairwise
disjoint rectangular labels that are attached to $R$ from the outside. The task
is to connect the sites to the labels by non-intersecting rectilinear paths,
so-called leaders, with at most one bend.
  In this paper, we study the Multi-Sided Boundary Labeling problem, with
labels lying on at least two sides of the enclosing rectangle. We present a
polynomial-time algorithm that computes a crossing-free leader layout if one
exists. So far, such an algorithm has only been known for the cases in which
labels lie on one side or on two opposite sides of $R$ (here a crossing-free
solution always exists). The case where labels may lie on adjacent sides is
more difficult. We present efficient algorithms for testing the existence of a
crossing-free leader layout that labels all sites and also for maximizing the
number of labeled sites in a crossing-free leader layout. For two-sided
boundary labeling with adjacent sides, we further show how to minimize the
total leader length in a crossing-free layout.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0751</identifier>
 <datestamp>2014-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0751</id><created>2013-05-03</created><updated>2014-11-07</updated><authors><author><keyname>Pe&#xf1;a</keyname><forenames>Jose M.</forenames></author></authors><title>Marginal AMP Chain Graphs</title><categories>stat.ML cs.AI</categories><comments>Changes from v1 to v2: Discussion section got extended. Changes from
  v2 to v3: New Sections 3 and 5. Changes from v3 to v4: Example 4 added to
  discussion section. Changes from v4 to v5: None. Changes from v5 to v6: Some
  minor and major errors have been corrected. The latter include the
  definitions of descending route and pairwise separation base, and the proofs
  of Theorems 5 and 6</comments><journal-ref>International Journal of Approximate Reasoning, 55 (5), 1185-1206,
  2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new family of models that is based on graphs that may have
undirected, directed and bidirected edges. We name these new models marginal
AMP (MAMP) chain graphs because each of them is Markov equivalent to some AMP
chain graph under marginalization of some of its nodes. However, MAMP chain
graphs do not only subsume AMP chain graphs but also multivariate regression
chain graphs. We describe global and pairwise Markov properties for MAMP chain
graphs and prove their equivalence for compositional graphoids. We also
characterize when two MAMP chain graphs are Markov equivalent.
  For Gaussian probability distributions, we also show that every MAMP chain
graph is Markov equivalent to some directed and acyclic graph with
deterministic nodes under marginalization and conditioning on some of its
nodes. This is important because it implies that the independence model
represented by a MAMP chain graph can be accounted for by some data generating
process that is partially observed and has selection bias. Finally, we modify
MAMP chain graphs so that they are closed under marginalization for Gaussian
probability distributions. This is a desirable feature because it guarantees
parsimonious models under marginalization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0757</identifier>
 <datestamp>2013-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0757</id><created>2013-05-03</created><authors><author><keyname>Hamann</keyname><forenames>Michael</forenames></author><author><keyname>Hartmann</keyname><forenames>Tanja</forenames></author><author><keyname>Wagner</keyname><forenames>Dorothea</forenames></author></authors><title>Hierarchies of Predominantly Connected Communities</title><categories>cs.DS cs.SI physics.soc-ph</categories><comments>to appear (WADS 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider communities whose vertices are predominantly connected, i.e., the
vertices in each community are stronger connected to other community members of
the same community than to vertices outside the community. Flake et al.
introduced a hierarchical clustering algorithm that finds such predominantly
connected communities of different coarseness depending on an input parameter.
We present a simple and efficient method for constructing a clustering
hierarchy according to Flake et al. that supersedes the necessity of choosing
feasible parameter values and guarantees the completeness of the resulting
hierarchy, i.e., the hierarchy contains all clusterings that can be constructed
by the original algorithm for any parameter value. However, predominantly
connected communities are not organized in a single hierarchy. Thus, we develop
a framework that, after precomputing at most $2(n-1)$ maximum flows, admits a
linear time construction of a clustering $\C(S)$ of predominantly connected
communities that contains a given community $S$ and is maximum in the sense
that any further clustering of predominantly connected communities that also
contains $S$ is hierarchically nested in $\C(S)$. We further generalize this
construction yielding a clustering with similar properties for $k$ given
communities in $O(kn)$ time. This admits the analysis of a network's structure
with respect to various communities in different hierarchies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0763</identifier>
 <datestamp>2014-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0763</id><created>2013-05-03</created><updated>2013-07-01</updated><authors><author><keyname>Crossley</keyname><forenames>Matthew</forenames></author><author><keyname>Nisbet</keyname><forenames>Andy</forenames></author><author><keyname>Amos</keyname><forenames>Martyn</forenames></author></authors><title>Quantifying the Impact of Parameter Tuning on Nature-Inspired Algorithms</title><categories>cs.NE</categories><comments>8 pages, 7 figures. Accepted at the European Conference on Artificial
  Life (ECAL) 2013, Taormina, Italy</comments><doi>10.7551/978-0-262-31709-2-ch138</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of parameterization is often central to the effective deployment
of nature-inspired algorithms. However, finding the optimal set of parameter
values for a combination of problem instance and solution method is highly
challenging, and few concrete guidelines exist on how and when such tuning may
be performed. Previous work tends to either focus on a specific algorithm or
use benchmark problems, and both of these restrictions limit the applicability
of any findings. Here, we examine a number of different algorithms, and study
them in a &quot;problem agnostic&quot; fashion (i.e., one that is not tied to specific
instances) by considering their performance on fitness landscapes with varying
characteristics. Using this approach, we make a number of observations on which
algorithms may (or may not) benefit from tuning, and in which specific
circumstances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0776</identifier>
 <datestamp>2014-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0776</id><created>2013-05-03</created><updated>2014-06-04</updated><authors><author><keyname>Bordewich</keyname><forenames>Magnus</forenames></author><author><keyname>Greenhill</keyname><forenames>Catherine</forenames></author><author><keyname>Patel</keyname><forenames>Viresh</forenames></author></authors><title>Mixing of the Glauber dynamics for the ferromagnetic Potts model</title><categories>cs.DM math-ph math.CO math.MP</categories><comments>35 pages. Revision addressing referees' comments</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present several results on the mixing time of the Glauber dynamics for
sampling from the Gibbs distribution in the ferromagnetic Potts model. At a
fixed temperature and interaction strength, we study the interplay between the
maximum degree ($\Delta$) of the underlying graph and the number of colours or
spins ($q$) in determining whether the dynamics mixes rapidly or not. We find a
lower bound $L$ on the number of colours such that Glauber dynamics is rapidly
mixing if at least $L$ colours are used. We give a closely-matching upper bound
$U$ on the number of colours such that with probability that tends to 1, the
Glauber dynamics mixes slowly on random $\Delta$-regular graphs when at most
$U$ colours are used. We show that our bounds can be improved if we restrict
attention to certain types of graphs of maximum degree $\Delta$, e.g. toroidal
grids for $\Delta = 4$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0779</identifier>
 <datestamp>2013-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0779</id><created>2013-05-03</created><updated>2013-07-09</updated><authors><author><keyname>Hauenstein</keyname><forenames>Jonathan D.</forenames></author><author><keyname>Ikenmeyer</keyname><forenames>Christian</forenames></author><author><keyname>Landsberg</keyname><forenames>J. M.</forenames></author></authors><title>Equations for lower bounds on border rank</title><categories>cs.CC math.AG</categories><comments>13 pages</comments><msc-class>68Q17</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present new methods for determining polynomials in the ideal of the
variety of bilinear maps of border rank at most r. We apply these methods to
several cases including the case r = 6 in the space of bilinear maps C^4 x C^4
-&gt; C^4. This space of bilinear maps includes the matrix multiplication operator
M_2 for two by two matrices. We show these newly obtained polynomials do not
vanish on the matrix multiplication operator M_2, which gives a new proof that
the border rank of the multiplication of 2 x 2 matrices is seven. Other
examples are considered along with an explanation of how to implement the
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0787</identifier>
 <datestamp>2013-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0787</id><created>2013-05-03</created><updated>2013-06-10</updated><authors><author><keyname>Dietsch</keyname><forenames>Daniel</forenames></author><author><keyname>Podelski</keyname><forenames>Andreas</forenames></author><author><keyname>Nam</keyname><forenames>Jaechang</forenames></author><author><keyname>Papadopoulos</keyname><forenames>Pantelis M.</forenames></author><author><keyname>Sch&#xe4;f</keyname><forenames>Martin</forenames></author></authors><title>Monitoring Student Activity in Collaborative Software Development</title><categories>cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents data analysis from a course on Software Engineering in an
effort to identify metrics and techniques that would allow instructor to act
proactively and identify patterns of low engagement and inefficient peer
collaboration. Over the last two terms, 106 students in their second year of
studies formed 20 groups and worked collaboratively to develop video games.
Throughout the lab, students have to use a variety of tools for managing and
developing their projects, such as software version control, static analysis
tools, wikis, mailing lists, etc. The students are also supported by weekly
meetings with teaching assistants and instructors regarding group progress,
code quality, and management issues. Through these meetings and their
interactions with the software tools, students leave a detailed trace of data
related to their individual engagement and their collaboration behavior in
their groups. The paper provides discussion on the different source of data
that can be monitored, and present preliminary results on how these data can be
used to analyze students' activity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0807</identifier>
 <datestamp>2013-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0807</id><created>2013-05-03</created><authors><author><keyname>Paul</keyname><forenames>Manas</forenames></author><author><keyname>Mandal</keyname><forenames>Jyotsna Kumar</forenames></author></authors><title>A Novel Symmetric Key Cryptographic Technique at Bit Level Based on
  Spiral Matrix Concept</title><categories>cs.CR</categories><comments>International Conference on Information Technology, Electronics and
  Communications (ICITEC 2013), Bangalore, India, March, 2013, 6 page</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a session based bit level symmetric key
cryptographic technique and it is termed as Spiral Matrix Based Bit Orientation
Technique (SMBBOT). SMBBOT consider the input plain text as binary bit stream.
During encryption this stream is chopped into manageable sized blocks with
variable lengths. Bits of these blocks are taken from MSB to LSB to fit into a
square matrix of suitable order following the concept of Spiral matrix. This
square matrix splits into 2x2 sub-matrices. Bits are taken column-wise from all
2x2 sub-matrices to form the encrypted binary string. Cipher text is generated
from this encrypted binary string. Combination of values of block length and
no. of blocks of a session generates the session key for SMBBOT. For decryption
the cipher text is considered as binary bit string. Processing the session key
information, this binary string is broken down into predefined blocks. Bits of
these blocks are taken from MSB to LSB to fit column-wise into 2x2 square
matrices. Using these sub-matrices a single square matrix with suitable order
is formed. The decrypted binary string is formed after taking the bits from the
square matrix following the reverse concept of Spiral Matrix. The plain text is
regenerated from decrypted binary string. A comparison of SMBBOT with existing
and industrially accepted TDES and AES has been done.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0810</identifier>
 <datestamp>2013-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0810</id><created>2013-05-03</created><updated>2013-11-10</updated><authors><author><keyname>Kliuchnikov</keyname><forenames>Vadym</forenames></author><author><keyname>Maslov</keyname><forenames>Dmitri</forenames></author></authors><title>Optimization of Clifford Circuits</title><categories>quant-ph cs.ET</categories><comments>7 pages, 5 figures</comments><journal-ref>Phys. Rev. A 88, 052307 (2013)</journal-ref><doi>10.1103/PhysRevA.88.052307</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study optimal synthesis of Clifford circuits, and apply the results to
peep-hole optimization of quantum circuits. We report optimal circuits for all
Clifford operations with up to four inputs. We perform peep-hole optimization
of Clifford circuits with up to 40 inputs found in the literature, and
demonstrate the reduction in the number of gates by about 50%. We extend our
methods to the optimal synthesis of linear reversible circuits, partially
specified Clifford functions, and optimal Clifford circuits with five inputs up
to input/output permutation. The results find their application in randomized
benchmarking protocols, quantum error correction, and quantum circuit
optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0817</identifier>
 <datestamp>2013-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0817</id><created>2013-05-03</created><authors><author><keyname>Zou</keyname><forenames>Yulong</forenames></author><author><keyname>Wang</keyname><forenames>Xianbin</forenames></author><author><keyname>Shen</keyname><forenames>Weiming</forenames></author></authors><title>Optimal Relay Selection for Physical-Layer Security in Cooperative
  Wireless Networks</title><categories>cs.IT math.IT</categories><comments>13 pages</comments><journal-ref>IEEE Journal on Selected Areas in Communications, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we explore the physical-layer security in cooperative wireless
networks with multiple relays where both amplify-and-forward (AF) and
decode-and-forward (DF) protocols are considered. We propose the AF and DF
based optimal relay selection (i.e., AFbORS and DFbORS) schemes to improve the
wireless security against eavesdropping attack. For the purpose of comparison,
we examine the traditional AFbORS and DFbORS schemes, denoted by T-AFbORS and
TDFbORS, respectively. We also investigate a so-called multiple relay combining
(MRC) framework and present the traditional AF and DF based MRC schemes, called
T-AFbMRC and TDFbMRC, where multiple relays participate in forwarding the
source signal to destination which then combines its received signals from the
multiple relays. We derive closed-form intercept probability expressions of the
proposed AFbORS and DFbORS (i.e., P-AFbORS and P-DFbORS) as well as the
T-AFbORS, TDFbORS, T-AFbMRC and T-DFbMRC schemes in the presence of
eavesdropping attack. We further conduct an asymptotic intercept probability
analysis to evaluate the diversity order performance of relay selection schemes
and show that no matter which relaying protocol is considered (i.e., AF and
DF), the traditional and proposed optimal relay selection approaches both
achieve the diversity order M where M represents the number of relays. In
addition, numerical results show that for both AF and DF protocols, the
intercept probability performance of proposed optimal relay selection is
strictly better than that of the traditional relay selection and multiple relay
combining methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0842</identifier>
 <datestamp>2015-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0842</id><created>2013-05-03</created><updated>2015-01-08</updated><authors><author><keyname>Zhan</keyname><forenames>Jinchun</forenames></author><author><keyname>Vaswani</keyname><forenames>Namrata</forenames></author></authors><title>Time Invariant Error Bounds for Modified-CS based Sparse Signal Sequence
  Recovery</title><categories>cs.IT math.IT</categories><comments>Accepted to IEEE Transaction on Information Theory. arXiv admin note:
  substantial text overlap with arXiv:1104.2108</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we obtain performance guarantees for modified-CS and for its
improved version, modified-CS-Add-LS-Del, for recursive reconstruction of a
time sequence of sparse signals from a reduced set of noisy measurements
available at each time. Under mild assumptions, we show that the support
recovery error of both algorithms is bounded by a time-invariant and small
value at all times. The same is also true for the reconstruction error. Under a
slow support change assumption, (i) the support recovery error bound is small
compared to the support size; and (ii) our results hold under weaker
assumptions on the number of measurements than what $\ell_1$ minimization for
noisy data needs. We first give a general result that only assumes a bound on
support size, number of support changes and number of small magnitude nonzero
entries at each time. Later, we specialize the main idea of these results for
two sets of signal change assumptions that model the class of problems in which
a new element that is added to the support either gets added at a large initial
magnitude or its magnitude slowly increases to a large enough value within a
finite delay. Simulation experiments are shown to back up our claims.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0848</identifier>
 <datestamp>2014-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0848</id><created>2013-05-03</created><updated>2014-04-14</updated><authors><author><keyname>Ozols</keyname><forenames>Maris</forenames></author><author><keyname>Smith</keyname><forenames>Graeme</forenames></author><author><keyname>Smolin</keyname><forenames>John A.</forenames></author></authors><title>Bound entangled states with a private key and their classical
  counterpart</title><categories>quant-ph cs.IT math.IT</categories><comments>This version matches with the published version and includes changes
  suggested by referees. We added a new appendix on distillation with remanent
  devices and also discuss the 4x5 example in more detail. A Mathematica
  notebook with source code is included</comments><journal-ref>Phys. Rev. Lett. 112, 110502 (2014)</journal-ref><doi>10.1103/PhysRevLett.112.110502</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Entanglement is a fundamental resource for quantum information processing. In
its pure form, it allows quantum teleportation and sharing classical secrets.
Realistic quantum states are noisy and their usefulness is only partially
understood. Bound-entangled states are central to this question---they have no
distillable entanglement, yet sometimes still have a private classical key. We
present a construction of bound-entangled states with private key based on
classical probability distributions. From this emerge states possessing a new
classical analogue of bound entanglement, distinct from the long-sought bound
information. We also find states of smaller dimensions and higher key rates
than previously known. Our construction has implications for classical
cryptography: we show that existing protocols are insufficient for extracting
private key from our distributions due to their &quot;bound-entangled&quot; nature. We
propose a simple extension of existing protocols that can extract key from
them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0854</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0854</id><created>2013-05-03</created><authors><author><keyname>Gilad</keyname><forenames>Yossi</forenames></author><author><keyname>Herzberg</keyname><forenames>Amir</forenames></author><author><keyname>Shulman</keyname><forenames>Haya</forenames></author></authors><title>Off-Path Hacking: The Illusion of Challenge-Response Authentication</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Everyone is concerned about the Internet security, yet most traffic is not
cryptographically protected. The usual justification is that most attackers are
only off-path and cannot intercept traffic; hence, challenge-response
mechanisms suffice to ensure authenticity. Usually, the challenges re-use
existing `unpredictable' header fields to protect widely-deployed protocols
such as TCP and DNS. We argue that this practice may often only give an
illusion of security. We present recent off-path TCP injection and DNS
poisoning attacks, enabling attackers to circumvent existing challenge-response
defenses. Both TCP and DNS attacks are non-trivial, yet very efficient and
practical. The attacks foil widely deployed security mechanisms, such as the
Same Origin Policy, and allow a wide range of exploits, e.g., long-term caching
of malicious objects and scripts. We hope that this article will motivate
adoption of cryptographic mechanisms such as SSL/TLS, IPsec and DNSSEC, and of
correct, secure challenge-response mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0860</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0860</id><created>2013-05-03</created><authors><author><keyname>&#xc7;al&#x131;k</keyname><forenames>&#xc7;a&#x11f;da&#x15f;</forenames></author></authors><title>Nonlinearity Computation for Sparse Boolean Functions</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algorithm for computing the nonlinearity of a Boolean function from its
algebraic normal form (ANF) is proposed. By generalizing the expression of the
weight of a Boolean function in terms of its ANF coefficients, a formulation of
the distances to linear functions is obtained. The special structure of these
distances can be exploited to reduce the task of nonlinearity computation to
solving an associated binary integer programming problem. The proposed
algorithm can be used in cases where applying the Fast Walsh transform is
infeasible, typically when the number of input variables exceeds 40.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0866</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0866</id><created>2013-05-03</created><updated>2013-11-03</updated><authors><author><keyname>V</keyname><forenames>Sarasvathi</forenames></author><author><keyname>Iyengar</keyname><forenames>N. CH. S. N.</forenames></author><author><keyname>Saha</keyname><forenames>Snehanshu</forenames></author></authors><title>Interference Aware Channel Assignmnet Using Edge Coloring in
  Multi-Channel Multi-Radio Wireless Mesh Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently multi-channel multi-radio wireless mesh networks are considered a
reliable and cost effective way for internet access in wide area. A major
research challenge in this network is selecting least interference channel from
available channel and then assigning it to radio efficiently. Many algorithms
and methods have been developed for channel assignment to maximize network
throughput using orthogonal channels. Recent research and testbed experiments
proved that POC based channel assignment allows more flexibility in wireless
spectrum sharing. In this paper, we represent the channel assignment as a graph
edge coloring problem using POC. The signal-to-noise interference ratio is
measured to avoid interference from neighbouring transmission, when we assign
channel to link. Simulation result shows that our proposed method improves
network throughput and performance. Keywords:
  Wireless Mesh Networks, Multi-Radio, Multi-Channel, Partially Overlapping
Channels, Signal-to-noise interference
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0868</identifier>
 <datestamp>2014-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0868</id><created>2013-05-03</created><updated>2014-05-21</updated><authors><author><keyname>Meng</keyname><forenames>Chun</forenames></author><author><keyname>Das</keyname><forenames>Abhik Kumar</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>Abinesh</forenames></author><author><keyname>Jafar</keyname><forenames>Syed Ali</forenames></author><author><keyname>Markopoulou</keyname><forenames>Athina</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Precoding-Based Network Alignment For Three Unicast Sessions</title><categories>cs.IT math.IT</categories><comments>arXiv admin note: text overlap with arXiv:1202.3405</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of network coding across three unicast sessions over
a directed acyclic graph, where each sender and the receiver is connected to
the network via a single edge of unit capacity. We consider a network model in
which the middle of the network only performs random linear network coding, and
restrict our approaches to precoding-based linear schemes, where the senders
use precoding matrices to encode source symbols. We adapt a precoding-based
interference alignment technique, originally developed for the wireless
interference channel, to construct a precoding-based linear scheme, which we
refer to as as a {\em precoding-based network alignment scheme (PBNA)}. A
primary difference between this setting and the wireless interference channel
is that the network topology can introduce dependencies between elements of the
transfer matrix, which we refer to as coupling relations, and can potentially
affect the achievable rate of PBNA. We identify all possible such coupling
relations, and interpret these coupling relations in terms of network topology
and present polynomial-time algorithms to check the presence of these coupling
relations. Finally, we show that, depending on the coupling relations present
in the network, the optimal symmetric rate achieved by precoding-based linear
scheme can take only three possible values, all of which can be achieved by
PBNA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0870</identifier>
 <datestamp>2015-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0870</id><created>2013-05-03</created><updated>2015-01-26</updated><authors><author><keyname>Pawar</keyname><forenames>Sameer</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>Computing a k-sparse n-length Discrete Fourier Transform using at most
  4k samples and O(k log k) complexity</title><categories>cs.DS cs.IT cs.MM math.IT</categories><comments>36 pages, 15 figures. To be presented at ISIT-2013, Istanbul Turkey</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given an $n$-length input signal $\mbf{x}$, it is well known that its
Discrete Fourier Transform (DFT), $\mbf{X}$, can be computed in $O(n \log n)$
complexity using a Fast Fourier Transform (FFT). If the spectrum $\mbf{X}$ is
exactly $k$-sparse (where $k&lt;&lt;n$), can we do better? We show that
asymptotically in $k$ and $n$, when $k$ is sub-linear in $n$ (precisely, $k
\propto n^{\delta}$ where $0 &lt; \delta &lt;1$), and the support of the non-zero DFT
coefficients is uniformly random, we can exploit this sparsity in two
fundamental ways (i) {\bf {sample complexity}}: we need only $M=rk$
deterministically chosen samples of the input signal $\mbf{x}$ (where $r &lt; 4$
when $0 &lt; \delta &lt; 0.99$); and (ii) {\bf {computational complexity}}: we can
reliably compute the DFT $\mbf{X}$ using $O(k \log k)$ operations, where the
constants in the big Oh are small and are related to the constants involved in
computing a small number of DFTs of length approximately equal to the sparsity
parameter $k$. Our algorithm succeeds with high probability, with the
probability of failure vanishing to zero asymptotically in the number of
samples acquired, $M$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0871</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0871</id><created>2013-05-03</created><authors><author><keyname>Liu</keyname><forenames>Weifeng</forenames></author><author><keyname>Wang</keyname><forenames>Xiaomeng</forenames></author><author><keyname>Wang</keyname><forenames>Yanjiang</forenames></author></authors><title>Dictionary learning based image enhancement for rarity detection</title><categories>cs.CV</categories><comments>2 pages, 2figures, submitted to Electronics Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image enhancement is an important image processing technique that processes
images suitably for a specific application e.g. image editing. The conventional
solutions of image enhancement are grouped into two categories which are
spatial domain processing method and transform domain processing method such as
contrast manipulation, histogram equalization, homomorphic filtering. This
letter proposes a new image enhance method based on dictionary learning.
Particularly, the proposed method adjusts the image by manipulating the rarity
of dictionary atoms. Firstly, learn the dictionary through sparse coding
algorithms on divided sub-image blocks. Secondly, compute the rarity of
dictionary atoms on statistics of the corresponding sparse coefficients.
Thirdly, adjust the rarity according to specific application and form a new
dictionary. Finally, reconstruct the image using the updated dictionary and
sparse coefficients. Compared with the traditional techniques, the proposed
method enhances image based on the image content not on distribution of pixel
grey value or frequency. The advantages of the proposed method lie in that it
is in better correspondence with the response of the human visual system and
more suitable for salient objects extraction. The experimental results
demonstrate the effectiveness of the proposed image enhance method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0876</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0876</id><created>2013-05-04</created><authors><author><keyname>Pucella</keyname><forenames>Riccardo</forenames></author></authors><title>Knowledge and Security</title><categories>cs.CR cs.LO</categories><comments>51 pages; preliminary version of a chapter for an upcoming Handbook
  of Logics for Knowledge and Belief</comments><acm-class>F.4.1; D.4.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Epistemic concepts, and in some cases epistemic logic, have been used in
security research to formalize security properties of systems. This survey
illustrates some of these uses by focusing on confidentiality in the context of
cryptographic protocols, and in the context of multi-level security systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0896</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0896</id><created>2013-05-04</created><authors><author><keyname>Shah</keyname><forenames>Hemal</forenames></author><author><keyname>Kosta</keyname><forenames>Yogeshwar</forenames></author><author><keyname>Patel</keyname><forenames>Vikrant</forenames></author></authors><title>Characterizing and Evaluation :Temporal properties of real and synthetic
  datasets for DTN</title><categories>cs.NI</categories><comments>10 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Nodes movements play a significant role in disseminating messages in the
sparse mobile ad-hoc network. In the network scenarios, where traditional
end-to-end paths do not exist, mobility creates opportunities for nodes to
connect and communicate when they are encountered. A series of encountering
opportunities spread a message among many nodes and eventually deliver to the
destination. Further improvements to the performance of message delivery can
come from exploiting temporal mobility properties. It is modeled as time
varying graph, where, moving nodes are considered as vertices and contact
opportunity to other nodes as an edge. The paper discusses about
characterization and design of the temporal algorithm. Then, evaluating
temporal distance, diameter and centrality of real and synthetic mobility data
sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0900</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0900</id><created>2013-05-04</created><authors><author><keyname>Martin</keyname><forenames>Ursula</forenames></author><author><keyname>Pease</keyname><forenames>Alison</forenames></author></authors><title>Mathematical practice, crowdsourcing, and social machines</title><categories>cs.SI cs.DL math.HO physics.soc-ph</categories><comments>To appear, Springer LNCS, Proceedings of Conferences on Intelligent
  Computer Mathematics, CICM 2013, July 2013 Bath, UK</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The highest level of mathematics has traditionally been seen as a solitary
endeavour, to produce a proof for review and acceptance by research peers.
Mathematics is now at a remarkable inflexion point, with new technology
radically extending the power and limits of individuals. Crowdsourcing pulls
together diverse experts to solve problems; symbolic computation tackles huge
routine calculations; and computers check proofs too long and complicated for
humans to comprehend.
  Mathematical practice is an emerging interdisciplinary field which draws on
philosophy and social science to understand how mathematics is produced. Online
mathematical activity provides a novel and rich source of data for empirical
investigation of mathematical practice - for example the community question
answering system {\it mathoverflow} contains around 40,000 mathematical
conversations, and {\it polymath} collaborations provide transcripts of the
process of discovering proofs. Our preliminary investigations have demonstrated
the importance of &quot;soft&quot; aspects such as analogy and creativity, alongside
deduction and proof, in the production of mathematics, and have given us new
ways to think about the roles of people and machines in creating new
mathematical knowledge. We discuss further investigation of these resources and
what it might reveal.
  Crowdsourced mathematical activity is an example of a &quot;social machine&quot;, a new
paradigm, identified by Berners-Lee, for viewing a combination of people and
computers as a single problem-solving entity, and the subject of major
international research endeavours. We outline a future research agenda for
mathematics social machines, a combination of people, computers, and
mathematical archives to create and apply mathematics, with the potential to
change the way people do mathematics, and to transform the reach, pace, and
impact of mathematics research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0904</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0904</id><created>2013-05-04</created><authors><author><keyname>Martin</keyname><forenames>Ursula</forenames></author><author><keyname>Pease</keyname><forenames>Alison</forenames></author></authors><title>What does mathoverflow tell us about the production of mathematics?</title><categories>cs.SI cs.DL math.HO physics.soc-ph</categories><comments>Appeared in SOHUMAN, 2nd International Workshop on Social Media for
  Crowdsourcing and Human Computation, at ACM Web Science 2013, May 1, 2013,
  Paris http://eipcm.org/sohuman2013/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The highest level of mathematics research is traditionally seen as a solitary
activity. Yet new innovations by mathematicians themselves are starting to
harness the power of social computation to create new modes of mathematical
production. We study the effectiveness of one such system, and make proposals
for enhancement, drawing on AI and computer based mathematics. We analyse the
content of a sample of questions and responses in the community question
answering system for research mathematicians, math-overflow. We find that
mathoverflow is very effective, with 90% of our sample of questions answered
completely or in part. A typical response is an informal dialogue, allowing
error and speculation, rather than rigorous mathematical argument: 37% of our
sample discussions acknowledged error. Responses typically present information
known to the respondent, and readily checked by other users: thus the
effectiveness of mathoverflow comes from information sharing. We conclude that
extending and the power and reach of mathoverflow through a combination of
people and machines raises new challenges for artificial intelligence and
computational mathematics, in particular how to handle error, analogy and
informal reasoning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0907</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0907</id><created>2013-05-04</created><authors><author><keyname>Dahshan</keyname><forenames>Mostafa H.</forenames></author></authors><title>Maximum-Bandwidth Node-Disjoint Paths</title><categories>cs.NI math.CO</categories><msc-class>05C21</msc-class><acm-class>F.2; F.2.0; F.2.2; G.2; G.2.1; G.2.2</acm-class><journal-ref>International Journal of Advanced Computer Science and
  Applications - IJACSA, Volume 3, Issue 3, March 2012, pp 48-56</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new method for finding the node-disjoint paths with
maximum combined bandwidth in communication networks. This problem is an
NP-complete problem which can be optimally solved in exponential time using
integer linear programming (ILP). The presented method uses a maximum-cost
variant of Dijkstra algorithm and a virtual-node representation to obtain the
maximum-bandwidth node-disjoint path. Through several simulations, we compare
the performance of our method to a modern heuristic technique and to the ILP
solution. We show that, in a polynomial execution time, our proposed method
produces results that are almost identical to ILP in a significantly lower
execution time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0909</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0909</id><created>2013-05-04</created><authors><author><keyname>Barletta</keyname><forenames>Luca</forenames></author><author><keyname>Borgonovo</keyname><forenames>Flaminio</forenames></author><author><keyname>Cesana</keyname><forenames>Matteo</forenames></author></authors><title>An Asymptotically Efficient Backlog Estimate for Dynamic Frame Aloha</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate backlog estimation procedures for Dynamic Frame
Aloha (DFA) in Radio Frequency Identification (RFID) environment. In
particular, we address the tag identification efficiency with any tag number
$N$, including $N\rightarrow\infty$. Although in the latter case efficiency
$e^{-1}$ is possible, none of the solution proposed in the literature has been
shown to reach such value. We analyze Schoute's backlog estimate, which is very
attractive for its simplicity, and formally show that its asymptotic efficiency
is 0.311. Leveraging the analysis, we propose the Asymptotic Efficient backlog
Estimate (AE$^2$) an improvement of the Schoute's backlog estimate, whose
efficiency reaches $e^{-1}$ asymptotically. We further show that AE$^2$ can be
optimized in order to present an efficiency very close to $e^{-1}$ for
practically any value of the population size. We also evaluate the loss of
efficiency when the frame size is constrained to be a power of two, as required
by RFID standards for DFA, and theoretically show that the asymptotic
efficiency becomes 0.356.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0911</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0911</id><created>2013-05-04</created><updated>2013-09-20</updated><authors><author><keyname>Ben-Amram</keyname><forenames>Amir M.</forenames></author></authors><title>A Comment on Budach's Mouse-in-an-Octant Problem</title><categories>cs.FL</categories><comments>3 pages, 2 bibliographic references</comments><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Budach's Mouse-in-an-Octant Problem (attributed to Lothar Budach in a 1980
article by van Emde Boas and Karpinski) concerns the behaviour of a very simple
finite-state machine (&quot;the mouse&quot;) moving on the integer two-dimensional grid.
Its decidability is apparently still open. This note sketches a proof that an
extended version of the problem (a super-mouse) is undecidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0918</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0918</id><created>2013-05-04</created><authors><author><keyname>Qureshi</keyname><forenames>Jalaluddin</forenames></author><author><keyname>Fohy</keyname><forenames>Chuan Heng</forenames></author><author><keyname>Cai</keyname><forenames>Jianfei</forenames></author></authors><title>Primer and Recent Developments on Fountain Codes</title><categories>cs.IT cs.NI math.IT</categories><comments>This paper appears in BSP Recent Patents on Telecommunications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we survey the various erasure codes which had been proposed and
patented recently, and along the survey we provide introductory tutorial on
many of the essential concepts and readings in erasure and Fountain codes.
Packet erasure is a fundamental characteristic inherent in data storage and
data transmission system. Traditionally replication/ retransmission based
techniques had been employed to deal with packet erasures in such systems.
While the Reed-Solomon (RS) erasure codes had been known for quite some time to
improve system reliability and reduce data redundancy, the high decoding
computation cost of RS codes has offset wider implementation of RS codes.
However recent exponential growth in data traffic and demand for larger data
storage capacity has simmered interest in erasure codes. Recent results have
shown promising results to address the decoding computation complexity and
redundancy tradeoff inherent in erasure codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0922</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0922</id><created>2013-05-04</created><authors><author><keyname>Azad</keyname><forenames>M. A. Khayer</forenames></author><author><keyname>Islam</keyname><forenames>Md. Shafiqul</forenames></author><author><keyname>Hashem</keyname><forenames>M. M. A.</forenames></author></authors><title>On Comparison between Evolutionary Programming Network-based Learning
  and Novel Evolution Strategy Algorithm-based Learning</title><categories>cs.NE cs.LG</categories><journal-ref>Procs. of the 3rd International Conference on Electrical,
  Electronics and Computer Engineering (ICEECE 2003), pp. 213-218, Dhaka,
  Bangladesh, December 22-24, (2003)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents two different evolutionary systems - Evolutionary
Programming Network (EPNet) and Novel Evolutions Strategy (NES) Algorithm.
EPNet does both training and architecture evolution simultaneously, whereas NES
does a fixed network and only trains the network. Five mutation operators
proposed in EPNet to reflect the emphasis on evolving ANNs behaviors. Close
behavioral links between parents and their offspring are maintained by various
mutations, such as partial training and node splitting. On the other hand, NES
uses two new genetic operators - subpopulation-based max-mean arithmetical
crossover and time-variant mutation. The above-mentioned two algorithms have
been tested on a number of benchmark problems, such as the medical diagnosis
problems (breast cancer, diabetes, and heart disease). The results and the
comparison between them are also presented in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0935</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0935</id><created>2013-05-04</created><updated>2013-12-19</updated><authors><author><keyname>Gomberoff</keyname><forenames>Andr&#xe9;s</forenames></author><author><keyname>Mu&#xf1;oz</keyname><forenames>V&#xed;ctor</forenames></author><author><keyname>Romagnoli</keyname><forenames>Pierre Paul</forenames></author></authors><title>The physics of custody</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>7 pages, 6 figures</comments><doi>10.1140/epjb/e2014-40666-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Divorced individuals face complex situations when they have children with
different ex-partners, or even more, when their new partners have children of
their own. In such cases, and when kids spend every other weekend with each
parent, a practical problem emerges: Is it possible to have such a custody
arrangement that every couple has either all of the kids together or no kids at
all? We show that in general, it is not possible, but that the number of
couples that do can be maximized. The problem turns out to be equivalent to
finding the ground state of a spin glass system, which is known to be
equivalent to what is called a weighted max-cut problem in graph theory, and
hence it is NP-Complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0936</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0936</id><created>2013-05-04</created><authors><author><keyname>Fatima</keyname><forenames>Boumahdi</forenames></author></authors><title>Endow a service-oriented architecture by a decisional aspect</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Service oriented architecture is more and more used in the companies, The
importance of the service orientation and its advantages with the information
system of the company, confront us to a new challenge. It is primarily to
ensure the decision aspect of the information system of company by adopting
Services Orientated Architecture like support architecture. This engineering
must ensure on the one hand the flexibility of the information system and on
the oth-er hand, avoids the redevelopment of the system by the decisions
request. In the actual position, several obstacles force the installation of
the SOA within the company. It is basically a question of the lack of method to
be implemented to define the services architecture within the information
system of the company which takes account the decisional aspect. Moreover,
there's no existing works which treat this challenge. On the basis of these
notes, we are interested, in this paper, on the develop-ment of a
three-dimensional new architecture for the integration of the deci-sional
aspect in SOA architectures, so that they are used perfectly. The proposal
takes support, mainly, on the use of a coupling MAS-SOA. To demonstrate the
application of our proposition, we use two study cases: project management and
Evapo-transpiration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0939</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0939</id><created>2013-05-04</created><authors><author><keyname>Mukhopadhyay</keyname><forenames>Debajyoti</forenames></author><author><keyname>Sharma</keyname><forenames>Manoj</forenames></author><author><keyname>Joshi</keyname><forenames>Gajanan</forenames></author><author><keyname>Pagare</keyname><forenames>Trupti</forenames></author><author><keyname>Palwe</keyname><forenames>Adarsha</forenames></author></authors><title>Intelligent Agent Based Semantic Web in Cloud Computing Environment</title><categories>cs.IR</categories><comments>10 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Considering today's web scenario, there is a need of effective and meaningful
search over the web which is provided by Semantic Web. Existing search engines
are keyword based. They are vulnerable in answering intelligent queries from
the user due to the dependence of their results on information available in web
pages. While semantic search engines provides efficient and relevant results as
the semantic web is an extension of the current web in which information is
given well defined meaning. MetaCrawler is a search tool that uses several
existing search engines and provides combined results by using their own page
ranking algorithm. This paper proposes development of a meta-semantic-search
engine called SemanTelli which works within cloud. SemanTelli fetches results
from different semantic search engines such as Hakia, DuckDuckGo, SenseBot with
the help of intelligent agents that eliminate the limitations of existing
search engines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0943</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0943</id><created>2013-05-04</created><authors><author><keyname>Faliszewski</keyname><forenames>Piotr</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author></authors><title>Weighted Electoral Control</title><categories>cs.GT cs.CC cs.MA</categories><comments>Preliminary version appears in AAMAS 2013</comments><acm-class>I.2.11; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although manipulation and bribery have been extensively studied under
weighted voting, there has been almost no work done on election control under
weighted voting. This is unfortunate, since weighted voting appears in many
important natural settings. In this paper, we study the complexity of
controlling the outcome of weighted elections through adding and deleting
voters. We obtain polynomial-time algorithms, NP-completeness results, and for
many NP-complete cases, approximation algorithms. In particular, for scoring
rules we completely characterize the complexity of weighted voter control. Our
work shows that for quite a few important cases, either polynomial-time exact
algorithms or polynomial-time approximation algorithms exist.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0947</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0947</id><created>2013-05-04</created><updated>2013-05-07</updated><authors><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author></authors><title>A Versatile Dependent Model for Heterogeneous Cellular Networks</title><categories>cs.NI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new model for heterogeneous cellular networks that incorporates
dependencies between the layers. In particular, it places lower-tier base
stations at locations that are poorly covered by the macrocells, and it
includes a small-cell model for the case where the goal is to enhance network
capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0948</identifier>
 <datestamp>2014-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0948</id><created>2013-05-04</created><updated>2014-05-17</updated><authors><author><keyname>Tzameret</keyname><forenames>Iddo</forenames></author></authors><title>Sparser Random 3SAT Refutation Algorithms and the Interpolation Problem</title><categories>cs.CC</categories><comments>Minor improvements. ICALP 2014</comments><msc-class>03F20, 68Q17, 68Q15, 03F30</msc-class><acm-class>F.2.2; F.4.1; I.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We formalize a combinatorial principle, called the 3XOR principle, due to
Feige, Kim and Ofek (2006), as a family of unsatisfiable propositional formulas
for which refutations of small size in any propositional proof system that
possesses the feasible interpolation property imply an efficient deterministic
refutation algorithm for random 3SAT with n variables and \Omega(n^{1.4})
clauses. Such small size refutations would improve the state-of-the-art (with
respect to the clause density) efficient refutation algorithm, which works only
for \Omega(n^{1.5}) many clauses (Feige and Ofek (2007)).
  We demonstrate polynomial-size refutations of the 3XOR principle in
resolution operating with disjunctions of quadratic equations with small
integer coefficients, denoted R(quad); this is a weak extension of cutting
planes with small coefficients. We show that R(quad) is weakly automatizable
iff R(lin) is weakly automatizable, where R(lin) is similar to R(quad) but with
linear instead of quadratic equations (introduced in Raz and Tzameret (2008)).
This reduces the problem of refuting random 3CNF with n variables and
\Omega(n^{1.4}) clauses to the interpolation problem of R(quad) and to the weak
automatizability of R(lin).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0954</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0954</id><created>2013-05-04</created><updated>2013-09-15</updated><authors><author><keyname>Croll</keyname><forenames>Grenville J.</forenames></author></authors><title>BiEntropy - The Approximate Entropy of a Finite Binary String</title><categories>cs.OH</categories><comments>16 Pages, 7 Tables, 6 Colour Figures. Presented at ANPA 34, Rowland's
  Castle, Hampshire, England, August 2013</comments><proxy>Grenville Croll</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design, implement and test a simple algorithm which computes the
approximate entropy of a finite binary string of arbitrary length. The
algorithm uses a weighted average of the Shannon Entropies of the string and
all but the last binary derivative of the string. We successfully test the
algorithm in the fields of Prime Number Theory (where we prove explicitly that
the sequence of prime numbers is not periodic), Human Vision, Cryptography,
Random Number Generation and Quantitative Finance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0958</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0958</id><created>2013-05-04</created><authors><author><keyname>Ford</keyname><forenames>Russell</forenames></author><author><keyname>Kim</keyname><forenames>Changkyu</forenames></author><author><keyname>Rangan</keyname><forenames>Sundeep</forenames></author></authors><title>Opportunistic Third-Party Backhaul for Cellular Wireless Networks</title><categories>cs.NI</categories><comments>9 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With high capacity air interfaces and large numbers of small cells, backhaul
-- the wired connectivity to base stations -- is increasingly becoming the cost
driver in cellular wireless networks. One reason for the high cost of backhaul
is that capacity is often purchased on leased lines with guaranteed rates
provisioned to peak loads. In this paper, we present an alternate
\emph{opportunistic backhaul} model where third parties provide base stations
and backhaul connections and lease out excess capacity in their networks to the
cellular provider when available, presumably at significantly lower costs than
guaranteed connections. We describe a scalable architecture for such
deployments using open access femtocells, which are small plug-and-play base
stations that operate in the carrier's spectrum but can connect directly into
the third party provider's wired network. Within the proposed architecture, we
present a general user association optimization algorithm that enables the
cellular provider to dynamically determine which mobiles should be assigned to
the third-party femtocells based on the traffic demands, interference and
channel conditions and third-party access pricing. Although the optimization is
non-convex, the algorithm uses a computationally efficient method for finding
approximate solutions via dual decomposition. Simulations of the deployment
model based on actual base station locations are presented that show that large
capacity gains are achievable if adoption of third-party, open access
femtocells can reach even a small fraction of the current market penetration of
WiFi access points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0961</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0961</id><created>2013-05-04</created><updated>2013-05-18</updated><authors><author><keyname>Hoover</keyname><forenames>Wm. G.</forenames></author><author><keyname>Hoover</keyname><forenames>Carol G.</forenames></author></authors><title>Time-Reversible Random Number Generators : Solution of Our Challenge by
  Federico Ricci-Tersenghi</title><categories>cs.DM cond-mat.stat-mech physics.comp-ph</categories><comments>Seven pages with a single Figure, dedicated to the memories of our
  late colleague Ian Snook</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nearly all the evolution equations of physics are time-reversible, in the
sense that a movie of the solution, played backwards, would obey exactly the
same differential equations as the original forward solution. By way of
contrast, stochastic approaches are typically not time-reversible, though they
could be made so by the simple expedient of storing their underlying
pseudorandom numbers in an array. Here we illustrate the notion of
time-reversible random number generators. In Version 1 we offered a suitable
reward for the first arXiv response furnishing a reversed version of an only
slightly-more-complicated pseudorandom number generator. Here we include
Professor Ricci-Tersenghi's prize-winning reversed version as described in his
arXiv:1305.1805 contribution: &quot;The Solution to the Challenge in
`Time-Reversible Random Number Generators' by Wm. G. Hoover and Carol G.
Hoover&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0967</identifier>
 <datestamp>2015-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0967</id><created>2013-05-04</created><updated>2015-03-02</updated><authors><author><keyname>Laraki</keyname><forenames>Rida</forenames></author><author><keyname>Mertikopoulos</keyname><forenames>Panayotis</forenames></author></authors><title>Inertial game dynamics and applications to constrained optimization</title><categories>math.OC cs.GT math.DS</categories><comments>30 pages, 4 figures; significantly revised paper structure and added
  new material on Euclidean embeddings and evolutionarily stable strategies</comments><msc-class>Primary 90C51, 91A26, secondary 34A12, 34A26, 34D05, 70F40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aiming to provide a new class of game dynamics with good long-term
rationality properties, we derive a second-order inertial system that builds on
the widely studied &quot;heavy ball with friction&quot; optimization method. By
exploiting a well-known link between the replicator dynamics and the
Shahshahani geometry on the space of mixed strategies, the dynamics are stated
in a Riemannian geometric framework where trajectories are accelerated by the
players' unilateral payoff gradients and they slow down near Nash equilibria.
Surprisingly (and in stark contrast to another second-order variant of the
replicator dynamics), the inertial replicator dynamics are not well-posed; on
the other hand, it is possible to obtain a well-posed system by endowing the
mixed strategy space with a different Hessian-Riemannian (HR) metric structure,
and we characterize those HR geometries that do so. In the single-agent version
of the dynamics (corresponding to constrained optimization over simplex-like
objects), we show that regular maximum points of smooth functions attract all
nearby solution orbits with low initial speed. More generally, we establish an
inertial variant of the so-called &quot;folk theorem&quot; of evolutionary game theory
and we show that strict equilibria are attracting in asymmetric
(multi-population) games - provided of course that the dynamics are well-posed.
A similar asymptotic stability result is obtained for evolutionarily stable
strategies in symmetric (single- population) games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0978</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0978</id><created>2013-05-04</created><updated>2013-06-01</updated><authors><author><keyname>Zhang</keyname><forenames>Yuan</forenames></author></authors><title>Optimization Approach to Parametric Tuning of Power System Stabilizer
  Based on Trajectory Sensitivity Analysis</title><categories>cs.SY</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposed an transient-based optimal parametric tuning method for
power system stabilizer (PSS) based on trajectory sensitivity (TS) analysis of
hybrid system, such as hybrid power system (HPS). The main objective is to
explore a systematic optimization approach of PSS under large disturbance of
HPS, where its nonlinear features cannot be ignored, which, however, the
traditional eigenvalue-based small signal optimizations do neglect the higher
order terms of Taylor series of the system state equations. In contrast to
previous work, the proposed TS optimal method focuses on the gradient
information of objective function with respect to decision variables by means
of the trajectory sensitivity of HPS to the PSS parameters, and optimizes the
PSS parameters in terms of the conjugate gradient method. Firstly, the
traditional parametric tuning methods of PSS are introduced. Then, the
systematic mathematical models and transient trajectory simulation are
presented by introducing switching/reset events in terms of triggering
hypersurfaces so as to formulate the optimization problem using TS analysis.
Finally, a case study of IEEE three-machine-nine-bus standard test system is
discussed in detail to exemplify the practicality and effectiveness of the
proposed optimal method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0982</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0982</id><created>2013-05-04</created><authors><author><keyname>Perera</keyname><forenames>Charith</forenames></author><author><keyname>Zaslavsky</keyname><forenames>Arkady</forenames></author><author><keyname>Christen</keyname><forenames>Peter</forenames></author><author><keyname>Georgakopoulos</keyname><forenames>Dimitrios</forenames></author></authors><title>Context Aware Computing for The Internet of Things: A Survey</title><categories>cs.SE cs.HC</categories><comments>IEEE Communications Surveys &amp; Tutorials Journal, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As we are moving towards the Internet of Things (IoT), the number of sensors
deployed around the world is growing at a rapid pace. Market research has shown
a significant growth of sensor deployments over the past decade and has
predicted a significant increment of the growth rate in the future. These
sensors continuously generate enormous amounts of data. However, in order to
add value to raw sensor data we need to understand it. Collection, modelling,
reasoning, and distribution of context in relation to sensor data plays
critical role in this challenge. Context-aware computing has proven to be
successful in understanding sensor data. In this paper, we survey context
awareness from an IoT perspective. We present the necessary background by
introducing the IoT paradigm and context-aware fundamentals at the beginning.
Then we provide an in-depth analysis of context life cycle. We evaluate a
subset of projects (50) which represent the majority of research and commercial
solutions proposed in the field of context-aware computing conducted over the
last decade (2001-2011) based on our own taxonomy. Finally, based on our
evaluation, we highlight the lessons to be learnt from the past and some
possible directions for future research. The survey addresses a broad range of
techniques, methods, models, functionalities, systems, applications, and
middleware solutions related to context awareness and IoT. Our goal is not only
to analyse, compare and consolidate past research work but also to appreciate
their findings and discuss their applicability towards the IoT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.0983</identifier>
 <datestamp>2014-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.0983</id><created>2013-05-04</created><updated>2014-01-13</updated><authors><author><keyname>Sun</keyname><forenames>Sun</forenames></author><author><keyname>Dong</keyname><forenames>Min</forenames></author><author><keyname>Liang</keyname><forenames>Ben</forenames></author></authors><title>Real-Time Welfare-Maximizing Regulation Allocation in Dynamic
  Aggregator-EVs System</title><categories>cs.SY cs.PF math.OC</categories><comments>13 pages</comments><journal-ref>IEEE Transactions on Smart Grid, vol. 5, pp. 1397-1409, May 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of vehicle-to-grid (V2G) has gained recent interest as more and
more electric vehicles (EVs) are put to use. In this paper, we consider a
dynamic aggregator-EVs system, where an aggregator centrally coordinates a
large number of dynamic EVs to perform regulation service. We propose a
Welfare-Maximizing Regulation Allocation (WMRA) algorithm for the aggregator to
fairly allocate the regulation amount among its EVs. Compared to previous
works, WMRA accommodates a wide spectrum of vital system characteristics,
including dynamics of EV, limited EV battery size, EV battery degradation cost,
and the cost of using external energy sources for the aggregator. The algorithm
operates in real time and does not require any prior knowledge of the
statistical information of the system. Theoretically, we demonstrate that WMRA
is away from the optimum by O(1/V), where V is a controlling parameter
depending on EV's battery size. In addition, our simulation results indicate
that WMRA can substantially outperform a suboptimal greedy algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1002</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1002</id><created>2013-05-05</created><authors><author><keyname>Yoon</keyname><forenames>Ji Won</forenames></author><author><keyname>Friel</keyname><forenames>Nial</forenames></author></authors><title>Efficient Estimation of the number of neighbours in Probabilistic K
  Nearest Neighbour Classification</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic k-nearest neighbour (PKNN) classification has been introduced
to improve the performance of original k-nearest neighbour (KNN) classification
algorithm by explicitly modelling uncertainty in the classification of each
feature vector. However, an issue common to both KNN and PKNN is to select the
optimal number of neighbours, $k$. The contribution of this paper is to
incorporate the uncertainty in $k$ into the decision making, and in so doing
use Bayesian model averaging to provide improved classification. Indeed the
problem of assessing the uncertainty in $k$ can be viewed as one of statistical
model selection which is one of the most important technical issues in the
statistics and machine learning domain. In this paper, a new functional
approximation algorithm is proposed to reconstruct the density of the model
(order) without relying on time consuming Monte Carlo simulations. In addition,
this algorithm avoids cross validation by adopting Bayesian framework. The
performance of this algorithm yielded very good performance on several real
experimental datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1010</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1010</id><created>2013-05-05</created><authors><author><keyname>Ville</keyname><forenames>Geoffroy</forenames></author></authors><title>An Optimal Mastermind (4,7) Strategy and More Results in the Expected
  Case</title><categories>cs.GT</categories><comments>20 pages, 9 tables, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an optimal strategy for solving the 4 peg-7 color
Mastermind MM(4,7) in the expected case (4.676) along with optimal strategies
or upper bounds for other values. The program developed is using a depth-first
branch and bound algorithm relying on tight upper bound, dynamic lower bound
evaluation and guess equivalence to prune symmetric tree branches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1012</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1012</id><created>2013-05-05</created><updated>2013-05-12</updated><authors><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author><author><keyname>Zhang</keyname><forenames>Fan</forenames></author><author><keyname>Cui</keyname><forenames>Ying</forenames></author></authors><title>Low Complexity Delay-Constrained Beamforming for Multi-User MIMO Systems
  with Imperfect CSIT</title><categories>cs.IT math.IT</categories><comments>14 pages, 7 figures, 1 table. This paper has been accepted by the
  IEEE Transactions on Signal Processing</comments><doi>10.1109/TSP.2013.2264058</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the delay-constrained beamforming control for
downlink multi-user MIMO (MU- MIMO) systems with imperfect channel state
information at the transmitter (CSIT). The delay-constrained control problem is
formulated as an infinite horizon average cost partially observed Markov
decision process. To deal with the curse of dimensionality, we introduce a
virtual continuous time system and derive a closed-form approximate value
function using perturbation analysis w.r.t. the CSIT errors. To deal with the
challenge of the conditional packet error rate (PER), we build a tractable
closed- form approximation using a Bernstein-type inequality. Based on the
closed-form approximations of the relative value function and the conditional
PER, we propose a conservative formulation of the original beamforming control
problem. The conservative problem is non-convex and we transform it into a
convex problem using the semidefinite relaxation (SDR) technique. We then
propose an alternating iterative algorithm to solve the SDR problem. Finally,
the proposed scheme is compared with various baselines through simulations and
it is shown that significant performance gain can be achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1019</identifier>
 <datestamp>2014-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1019</id><created>2013-05-05</created><updated>2014-01-02</updated><authors><author><keyname>Zhang</keyname><forenames>Xiao-Lei</forenames></author><author><keyname>Wu</keyname><forenames>Ji</forenames></author></authors><title>Simple Deep Random Model Ensemble</title><categories>cs.LG</categories><comments>This paper has been withdrawn by the author due to a lack of full
  empirical evaluation. More advanced method has been developed. This method
  has been fully out of date</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Representation learning and unsupervised learning are two central topics of
machine learning and signal processing. Deep learning is one of the most
effective unsupervised representation learning approach. The main contributions
of this paper to the topics are as follows. (i) We propose to view the
representative deep learning approaches as special cases of the knowledge reuse
framework of clustering ensemble. (ii) We propose to view sparse coding when
used as a feature encoder as the consensus function of clustering ensemble, and
view dictionary learning as the training process of the base clusterings of
clustering ensemble. (ii) Based on the above two views, we propose a very
simple deep learning algorithm, named deep random model ensemble (DRME). It is
a stack of random model ensembles. Each random model ensemble is a special
k-means ensemble that discards the expectation-maximization optimization of
each base k-means but only preserves the default initialization method of the
base k-means. (iv) We propose to select the most powerful representation among
the layers by applying DRME to clustering where the single-linkage is used as
the clustering algorithm. Moreover, the DRME based clustering can also detect
the number of the natural clusters accurately. Extensive experimental
comparisons with 5 representation learning methods on 19 benchmark data sets
demonstrate the effectiveness of DRME.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1021</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1021</id><created>2013-05-05</created><authors><author><keyname>Ambainis</keyname><forenames>Andris</forenames></author><author><keyname>Balodis</keyname><forenames>Kaspars</forenames></author><author><keyname>Iraids</keyname><forenames>J&#x101;nis</forenames></author><author><keyname>Ozols</keyname><forenames>Raitis</forenames></author><author><keyname>Smotrovs</keyname><forenames>Juris</forenames></author></authors><title>Parameterized Quantum Query Complexity of Graph Collision</title><categories>quant-ph cs.CC cs.DS</categories><comments>12 pages, 5 figures, submitted to ICALP workshop &quot;Workshop on Quantum
  and Classical Complexity&quot; in 5/5/2013</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We present three new quantum algorithms in the quantum query model for
\textsc{graph-collision} problem: \begin{itemize} \item an algorithm based on
tree decomposition that uses $O\left(\sqrt{n}t^{\sfrac{1}{6}}\right)$ queries
where $t$ is the treewidth of the graph; \item an algorithm constructed on a
span program that improves a result by Gavinsky and Ito. The algorithm uses
$O(\sqrt{n}+\sqrt{\alpha^{**}})$ queries, where $\alpha^{**}(G)$ is a graph
parameter defined by \[\alpha^{**}(G):=\min_{VC\text{-- vertex cover
of}G}{\max_{\substack{I\subseteq VC\\I\text{-- independent set}}}{\sum_{v\in
I}{\deg{v}}}};\] \item an algorithm for a subclass of circulant graphs that
uses $O(\sqrt{n})$ queries. \end{itemize} We also present an example of a
possibly difficult graph $G$ for which all the known graphs fail to solve graph
collision in $O(\sqrt{n} \log^c n)$ queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1022</identifier>
 <datestamp>2014-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1022</id><created>2013-05-05</created><updated>2014-03-08</updated><authors><author><keyname>Drissi</keyname><forenames>Ahmed</forenames></author><author><keyname>Asimi</keyname><forenames>Ahmed</forenames></author></authors><title>A New Approach to Decoding of Rational Irreducible Goppa code</title><categories>cs.CR</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The interesting properties of classical Goppa code and its effective decoding
algorithm (algorithm of patterson) make the most appropriate candidate for use
in the MC Eliece cryptosystem. Information leakage which results from the
relationship between the error vector weight and the number of iterations in
the decoding algorithm, presented a weakness of the cryptosystem. In this
paper, we introduce a new approach to decoding, the use of binary Goppa code in
system design MC Eliece which solve the problem of the leak of information, on
the contrary in case of patterson algorithm. We treat this decoding method
using the Newton identities and results of linear algebra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1027</identifier>
 <datestamp>2013-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1027</id><created>2013-05-05</created><updated>2013-07-17</updated><authors><author><keyname>Azar</keyname><forenames>Mohammad Gheshlaghi</forenames></author><author><keyname>Lazaric</keyname><forenames>Alessandro</forenames></author><author><keyname>Brunskill</keyname><forenames>Emma</forenames></author></authors><title>Regret Bounds for Reinforcement Learning with Policy Advice</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In some reinforcement learning problems an agent may be provided with a set
of input policies, perhaps learned from prior experience or provided by
advisors. We present a reinforcement learning with policy advice (RLPA)
algorithm which leverages this input set and learns to use the best policy in
the set for the reinforcement learning task at hand. We prove that RLPA has a
sub-linear regret of \tilde O(\sqrt{T}) relative to the best input policy, and
that both this regret and its computational complexity are independent of the
size of the state and action space. Our empirical simulations support our
theoretical analysis. This suggests RLPA may offer significant advantages in
large domains where some prior good policies are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1040</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1040</id><created>2013-05-05</created><authors><author><keyname>Chen</keyname><forenames>Ting-Li</forenames></author></authors><title>On the Convergence and Consistency of the Blurring Mean-Shift Process</title><categories>stat.ML cs.LG</categories><comments>arXiv admin note: text overlap with arXiv:1201.1979</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The mean-shift algorithm is a popular algorithm in computer vision and image
processing. It can also be cast as a minimum gamma-divergence estimation. In
this paper we focus on the &quot;blurring&quot; mean shift algorithm, which is one
version of the mean-shift process that successively blurs the dataset. The
analysis of the blurring mean-shift is relatively more complicated compared to
the nonblurring version, yet the algorithm convergence and the estimation
consistency have not been well studied in the literature. In this paper we
prove both the convergence and the consistency of the blurring mean-shift. We
also perform simulation studies to compare the efficiency of the blurring and
the nonblurring versions of the mean-shift algorithms. Our results show that
the blurring mean-shift has more efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1044</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1044</id><created>2013-05-05</created><authors><author><keyname>Mercurio</keyname><forenames>Andrea</forenames></author><author><keyname>Di Giorgio</keyname><forenames>Alessandro</forenames></author><author><keyname>Purificato</keyname><forenames>Fabio</forenames></author></authors><title>Optimal Fully Electric Vehicle load balancing with an ADMM algorithm in
  Smartgrids</title><categories>cs.SY cs.DC</categories><comments>This paper has been accepted for the 21st Mediterranean Conference on
  Control and Automation, therefore it is subjected to IEEE Copyrights. See
  IEEE copyright notice at http://www.ieee.org/documents/ieeecopyrightform.pdf</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a system architecture and a suitable control
methodology for the load balancing of Fully Electric Vehicles at Charging
Station (CS). Within the proposed architecture, control methodologies allow to
adapt Distributed Energy Resources (DER) generation profiles and active loads
to ensure economic benefits to each actor. The key aspect is the organization
in two levels of control: at local level a Load Area Controller (LAC) optimally
calculates the FEVs charging sessions, while at higher level a Macro Load Area
Aggregator (MLAA) provides DER with energy production profiles, and LACs with
energy withdrawal profiles. Proposed control methodologies involve the solution
of a Walrasian market equilibrium and the design of a distributed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1052</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1052</id><created>2013-05-05</created><authors><author><keyname>Jassim</keyname><forenames>Firas Ajil</forenames></author><author><keyname>Altaani</keyname><forenames>Fawzi H.</forenames></author></authors><title>Hybridization of Otsu Method and Median Filter for Color Image
  Segmentation</title><categories>cs.CV</categories><comments>6 pages, 7 figures</comments><journal-ref>International Journal of Soft Computing and Engineering, Volume-3,
  Issue-2, May 2013</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this article a novel algorithm for color image segmentation has been
developed. The proposed algorithm based on combining two existing methods in
such a novel way to obtain a significant method to partition the color image
into significant regions. On the first phase, the traditional Otsu method for
gray channel image segmentation were applied for each of the R,G, and B
channels separately to determine the suitable automatic threshold for each
channel. After that, the new modified channels are integrated again to
formulate a new color image. The resulted image suffers from some kind of
distortion. To get rid of this distortion, the second phase is arise which is
the median filter to smooth the image and increase the segmented regions. This
process looks very significant by the ocular eye. Experimental results were
presented on a variety of test images to support the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1059</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1059</id><created>2013-05-05</created><authors><author><keyname>Hor&#xe1;&#x10d;ek</keyname><forenames>Jaroslav</forenames></author><author><keyname>Hlad&#xed;k</keyname><forenames>Milan</forenames></author></authors><title>Subsquares Approach - Simple Scheme for Solving Overdetermined Interval
  Linear Systems</title><categories>cs.NA</categories><comments>submitted to PPAM 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we present a new simple but efficient scheme - Subsquares
approach - for development of algorithms for enclosing the solution set of
overdetermined interval linear systems. We are going to show two algorithms
based on this scheme and discuss their features. We start with a simple
algorithm as a motivation, then we continue with a sequential algorithm. Both
algorithms can be easily parallelized. The features of both algorithms will be
discussed and numerically tested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1060</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1060</id><created>2013-05-05</created><authors><author><keyname>Giordano</keyname><forenames>Laura</forenames></author><author><keyname>Gliozzi</keyname><forenames>Valentina</forenames></author><author><keyname>Olivetti</keyname><forenames>Nicola</forenames></author><author><keyname>Pozzato</keyname><forenames>Gian Luca</forenames></author></authors><title>On Rational Closure in Description Logics of Typicality</title><categories>cs.AI</categories><msc-class>68T30, 68T27</msc-class><acm-class>I.2.4; I.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define the notion of rational closure in the context of Description Logics
extended with a tipicality operator. We start from ALC+T, an extension of ALC
with a typicality operator T: intuitively allowing to express concepts of the
form T(C), meant to select the &quot;most normal&quot; instances of a concept C. The
semantics we consider is based on rational model. But we further restrict the
semantics to minimal models, that is to say, to models that minimise the rank
of domain elements. We show that this semantics captures exactly a notion of
rational closure which is a natural extension to Description Logics of Lehmann
and Magidor's original one. We also extend the notion of rational closure to
the Abox component. We provide an ExpTime algorithm for computing the rational
closure of an Abox and we show that it is sound and complete with respect to
the minimal model semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1082</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1082</id><created>2013-05-06</created><authors><author><keyname>Tajbakhsh</keyname><forenames>Shahriar Etemadi</forenames></author><author><keyname>Sadeghi</keyname><forenames>Parastoo</forenames></author></authors><title>Random Linear Network Codes for Secrecy over Wireless Broadcast Channels</title><categories>cs.IT cs.CR math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a set of $n$ messages and a group of $k$ clients. Each client is
privileged for receiving an arbitrary subset of the messages over a broadcast
erasure channel, which generalizes scenario of a previous work. We propose a
method for secretly delivering each message to its privileged recipients in a
way that each receiver can decode its own messages but not the others'. Our
method is based on combining the messages using linear network coding and
hiding the decoding coefficients from the unprivileged clients. We provide an
information theoretic proof for the secrecy of the proposed method. In
particular we show that an unprivileged client cannot obtain any meaningful
information even if it holds the entire set of coded data packets transmitted
over the channel. Moreover, in our method, the decoding complexity is desirably
low at the receiver side.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1091</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1091</id><created>2013-05-06</created><authors><author><keyname>Geil</keyname><forenames>Olav</forenames></author><author><keyname>Martin</keyname><forenames>Stefano</forenames></author></authors><title>Further improvements on the Feng-Rao bound for dual codes</title><categories>cs.IT math.AC math.AG math.IT</categories><comments>16 pages, 3 figures</comments><msc-class>94B65, 94B27, 94B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Salazar, Dunn and Graham in [Salazar et. al., 2006] presented an improved
Feng-Rao bound for the minimum distance of dual codes. In this work we take the
improvement a step further. Both the original bound by Salazar et. al., as well
as our improvement are lifted so that they deal with generalized Hamming
weights. We also demonstrate the advantage of working with one-way
well-behaving pairs rather than weakly well-behaving or well-behaving pairs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1102</identifier>
 <datestamp>2013-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1102</id><created>2013-05-06</created><updated>2013-11-05</updated><authors><author><keyname>Castro</keyname><forenames>Luis I. Reyes</forenames></author><author><keyname>Chaudhari</keyname><forenames>Pratik</forenames></author><author><keyname>Tumova</keyname><forenames>Jana</forenames></author><author><keyname>Karaman</keyname><forenames>Sertac</forenames></author><author><keyname>Frazzoli</keyname><forenames>Emilio</forenames></author><author><keyname>Rus</keyname><forenames>Daniela</forenames></author></authors><title>Incremental Sampling-based Algorithm for Minimum-violation Motion
  Planning</title><categories>cs.RO</categories><comments>8 pages, final version submitted to CDC '13</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of control strategy synthesis for dynamical
systems with differential constraints to fulfill a given reachability goal
while satisfying a set of safety rules. Particular attention is devoted to
goals that become feasible only if a subset of the safety rules are violated.
The proposed algorithm computes a control law, that minimizes the level of
unsafety while the desired goal is guaranteed to be reached. This problem is
motivated by an autonomous car navigating an urban environment while following
rules of the road such as &quot;always travel in right lane'' and &quot;do not change
lanes frequently''. Ideas behind sampling based motion-planning algorithms,
such as Probabilistic Road Maps (PRMs) and Rapidly-exploring Random Trees
(RRTs), are employed to incrementally construct a finite concretization of the
dynamics as a durational Kripke structure. In conjunction with this, a weighted
finite automaton that captures the safety rules is used in order to find an
optimal trajectory that minimizes the violation of safety rules. We prove that
the proposed algorithm guarantees asymptotic optimality, i.e., almost-sure
convergence to optimal solutions. We present results of simulation experiments
and an implementation on an autonomous urban mobility-on-demand system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1112</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1112</id><created>2013-05-06</created><authors><author><keyname>Urli</keyname><forenames>Tommaso</forenames></author></authors><title>json2run: a tool for experiment design &amp; analysis</title><categories>cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  json2run is a tool to automate the running, storage and analysis of
experiments. The main advantage of json2run is that it allows to describe a set
of experiments concisely as a JSON-formatted parameter tree. It also supports
parallel execution of experiments, automatic parameter tuning through the
F-Race framework and storage and analysis of experiments with MongoDB and R.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1114</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1114</id><created>2013-05-06</created><authors><author><keyname>Bouneffouf</keyname><forenames>Djallel</forenames></author></authors><title>Towards User Profile Modelling in Recommender System</title><categories>cs.IR</categories><acm-class>I.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of profile appeared in the 1970s decade, which was mainly due to
the need to create custom applications that could be adapted to the user. In
this paper, we treat the different aspects of the user's profile, defining it,
profile, its features and its indicators of interest, and then we describe the
different approaches of modelling and acquiring the user's interests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1120</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1120</id><created>2013-05-06</created><authors><author><keyname>Krumme</keyname><forenames>Coco</forenames><affiliation>&quot;Sandy&quot;</affiliation></author><author><keyname>Llorente</keyname><forenames>Alejandro</forenames><affiliation>&quot;Sandy&quot;</affiliation></author><author><keyname>Cebri&#xe1;n</keyname><forenames>Manuel</forenames><affiliation>&quot;Sandy&quot;</affiliation></author><author><keyname>Alex</keyname><affiliation>&quot;Sandy&quot;</affiliation></author><author><keyname>Pentland</keyname></author><author><keyname>Moro</keyname><forenames>Esteban</forenames></author></authors><title>The predictability of consumer visitation patterns</title><categories>physics.soc-ph cs.SI</categories><journal-ref>Coco Krumme, Alejandro Llorente, Manuel Cebrian, Alex Pentland,
  and Esteban Moro. The predictability of consumer visitation patterns.
  Scientific Reports, 3, April 2013</journal-ref><doi>10.1038/srep01645</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider hundreds of thousands of individual economic transactions to ask:
how predictable are consumers in their merchant visitation patterns? Our
results suggest that, in the long-run, much of our seemingly elective activity
is actually highly predictable. Notwithstanding a wide range of individual
preferences, shoppers share regularities in how they visit merchant locations
over time. Yet while aggregate behavior is largely predictable, the
interleaving of shopping events introduces important stochastic elements at
short time scales. These short- and long-scale patterns suggest a theoretical
upper bound on predictability, and describe the accuracy of a Markov model in
predicting a person's next location. We incorporate population-level transition
probabilities in the predictive models, and find that in many cases these
improve accuracy. While our results point to the elusiveness of precise
predictions about where a person will go next, they suggest the existence, at
large time-scales, of regularities across the population.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1121</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1121</id><created>2013-05-06</created><authors><author><keyname>Augustine</keyname><forenames>John</forenames></author><author><keyname>Molla</keyname><forenames>Anisur Rahaman</forenames></author><author><keyname>Morsy</keyname><forenames>Ehab</forenames></author><author><keyname>Pandurangan</keyname><forenames>Gopal</forenames></author><author><keyname>Robinson</keyname><forenames>Peter</forenames></author><author><keyname>Upfal</keyname><forenames>Eli</forenames></author></authors><title>Storage and Search in Dynamic Peer-to-Peer Networks</title><categories>cs.DC</categories><comments>to appear at SPAA 2013</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study robust and efficient distributed algorithms for searching, storing,
and maintaining data in dynamic Peer-to-Peer (P2P) networks. P2P networks are
highly dynamic networks that experience heavy node churn (i.e., nodes join and
leave the network continuously over time). Our goal is to guarantee, despite
high node churn rate, that a large number of nodes in the network can store,
retrieve, and maintain a large number of data items. Our main contributions are
fast randomized distributed algorithms that guarantee the above with high
probability (whp) even under high adversarial churn:
  1. A randomized distributed search algorithm that (whp) guarantees that
searches from as many as $n - o(n)$ nodes ($n$ is the stable network size)
succeed in ${O}(\log n)$-rounds despite ${O}(n/\log^{1+\delta} n)$ churn, for
any small constant $\delta &gt; 0$, per round. We assume that the churn is
controlled by an oblivious adversary (that has complete knowledge and control
of what nodes join and leave and at what time, but is oblivious to the random
choices made by the algorithm).
  2. A storage and maintenance algorithm that guarantees (whp) data items can
be efficiently stored (with only $\Theta(\log{n})$ copies of each data item)
and maintained in a dynamic P2P network with churn rate up to
${O}(n/\log^{1+\delta} n)$ per round. Our search algorithm together with our
storage and maintenance algorithm guarantees that as many as $n - o(n)$ nodes
can efficiently store, maintain, and search even under ${O}(n/\log^{1+\delta}
n)$ churn per round. Our algorithms require only polylogarithmic in $n$ bits to
be processed and sent (per round) by each node.
  To the best of our knowledge, our algorithms are the first-known,
fully-distributed storage and search algorithms that provably work under highly
dynamic settings (i.e., high churn rates per step).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1141</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1141</id><created>2013-05-06</created><authors><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author><author><keyname>Thakare</keyname><forenames>V M</forenames></author></authors><title>Acoustic Echo Cancellation Postfilter Design Issues For Speech
  Recognition System</title><categories>cs.SD</categories><comments>Pages: 6</comments><journal-ref>International Journal of Science and Advanced Technology (IJSAT),
  ISSN 2221-8386, Vol 1 No 5, July 2011, pp 38-43</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a generalized postfilter algorithm design issues are presented.
This postfilter is used to jointly suppress late reverberation, residual echo,
and background noise. When residual echo and noise are suppressed, the best
result obtains by suppressing both interferences together after the Acoustic
echo cancellation (AEC). The main advantage of this approach is that the
residual echo and noise suppression does not suffer from the existence of a
strong acoustic echo component. Furthermore, the Acoustic echo cancellation
(AEC) does not suffer from the time-varying noise suppression. A disadvantage
is that the input signal of the Acoustic echo cancellation (AEC) has a low
signal-to-noise ratio (SNR). To overcome this problem, algorithms have been
proposed where, apart from the joint suppression, a noise-reduced signal is
used to adapt the echo canceller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1145</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1145</id><created>2013-05-06</created><authors><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author><author><keyname>Thakare</keyname><forenames>V M</forenames></author></authors><title>Techniques for Feature Extraction In Speech Recognition System : A
  Comparative Study</title><categories>cs.SD cs.CL</categories><comments>Pages: 9 Figures : 3</comments><journal-ref>International Journal Of Computer Applications In Engineering,
  Technology and Sciences (IJCAETS),ISSN 0974-3596,2010,pp 412-418</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The time domain waveform of a speech signal carries all of the auditory
information. From the phonological point of view, it little can be said on the
basis of the waveform itself. However, past research in mathematics, acoustics,
and speech technology have provided many methods for converting data that can
be considered as information if interpreted correctly. In order to find some
statistically relevant information from incoming data, it is important to have
mechanisms for reducing the information of each segment in the audio signal
into a relatively small number of parameters, or features. These features
should describe each segment in such a characteristic way that other similar
segments can be grouped together by comparing their features. There are
enormous interesting and exceptional ways to describe the speech signal in
terms of parameters. Though, they all have their strengths and weaknesses, we
have presented some of the most used methods with their importance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1146</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1146</id><created>2013-05-06</created><authors><author><keyname>Wang</keyname><forenames>Daoshun</forenames></author><author><keyname>Ye</keyname><forenames>Ziwei</forenames></author><author><keyname>Li</keyname><forenames>Xiaobo</forenames></author></authors><title>How to Collaborate between Threshold Schemes</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Threshold schemes have been used to protect secrets by distributing shares to
participants. To protect two secrets, we can use two separate traditional
schemes, say, a (t1, n1) scheme and a (t2, n2) scheme. If there are u
(&lt;=min(t1, t2)) participants involved in both schemes, each of these u
participants must keep two different shares. This paper proposes a method that
allows each common participant to keep only one share. Our method constructs
two polynomials with u common crossover points. We give theoretical details and
two demonstrative examples. This algorithm can also handle the collaboration
between more than two schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1155</identifier>
 <datestamp>2013-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1155</id><created>2013-05-06</created><updated>2013-10-04</updated><authors><author><keyname>Dimitrov</keyname><forenames>Darko</forenames></author></authors><title>Efficient computation of trees with minimal atom-bond connectivity index</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The {\em atom-bond connectivity (ABC) index} is one of the recently most
investigated degree-based molecular structure descriptors, that have
applications in chemistry. For a graph $G$, the ABC index is defined as
$\sum_{uv\in E(G)}\sqrt{\frac{(d(u) +d(v)-2)}{d(u)d(v)}}$, where $d(u)$ is the
degree of vertex $u$ in $G$ and $E(G)$ is the set of edges of $G$. Despite many
attempts in the last few years, it is still an open problem to characterize
trees with minimal $ABC$ index. In this paper, we present an efficient approach
of computing trees with minimal ABC index, by considering the degree sequences
of trees and some known properties of the graphs with minimal $ABC$ index. The
obtained results disprove some existing conjectures end suggest new ones to be
set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1157</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1157</id><created>2013-05-06</created><authors><author><keyname>Bingmann</keyname><forenames>Timo</forenames></author><author><keyname>Sanders</keyname><forenames>Peter</forenames></author></authors><title>Parallel String Sample Sort</title><categories>cs.DS cs.DC</categories><comments>34 pages, 7 figures and 12 tables</comments><acm-class>F.2.2; E.5; D.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss how string sorting algorithms can be parallelized on modern
multi-core shared memory machines. As a synthesis of the best sequential string
sorting algorithms and successful parallel sorting algorithms for atomic
objects, we propose string sample sort. The algorithm makes effective use of
the memory hierarchy, uses additional word level parallelism, and largely
avoids branch mispredictions. Additionally, we parallelize variants of multikey
quicksort and radix sort that are also useful in certain situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1163</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1163</id><created>2013-05-06</created><authors><author><keyname>Paletta</keyname><forenames>Lucas</forenames></author><author><keyname>Santner</keyname><forenames>Katrin</forenames></author><author><keyname>Fritz</keyname><forenames>Gerald</forenames></author><author><keyname>Hofmann</keyname><forenames>Albert</forenames></author><author><keyname>Lodron</keyname><forenames>Gerald</forenames></author><author><keyname>Thallinger</keyname><forenames>Georg</forenames></author><author><keyname>Mayer</keyname><forenames>Heinz</forenames></author></authors><title>A Computer Vision System for Attention Mapping in SLAM based 3D Models</title><categories>cs.CV</categories><comments>Part of the OAGM/AAPR 2013 proceedings (arXiv:1304.1876)</comments><report-no>OAGM-AAPR/2013/10</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study of human factors in the frame of interaction studies has been
relevant for usability engi-neering and ergonomics for decades. Today, with the
advent of wearable eye-tracking and Google glasses, monitoring of human factors
will soon become ubiquitous. This work describes a computer vision system that
enables pervasive mapping and monitoring of human attention. The key
contribu-tion is that our methodology enables full 3D recovery of the gaze
pointer, human view frustum and associated human centred measurements directly
into an automatically computed 3D model in real-time. We apply RGB-D SLAM and
descriptor matching methodologies for the 3D modelling, locali-zation and fully
automated annotation of ROIs (regions of interest) within the acquired 3D
model. This innovative methodology will open new avenues for attention studies
in real world environments, bringing new potential into automated processing
for human factors technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1169</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1169</id><created>2013-05-06</created><authors><author><keyname>Khouadjia</keyname><forenames>Mostepha Redouane</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author><author><keyname>Vidal</keyname><forenames>Vincent</forenames><affiliation>DCSD</affiliation></author><author><keyname>Dr&#xe9;o</keyname><forenames>Johann</forenames><affiliation>TRT</affiliation></author><author><keyname>Sav&#xe9;ant</keyname><forenames>Pierre</forenames><affiliation>TRT</affiliation></author></authors><title>Multi-Objective AI Planning: Comparing Aggregation and Pareto Approaches</title><categories>cs.AI</categories><proxy>ccsd</proxy><journal-ref>EvoCOP -- 13th European Conference on Evolutionary Computation in
  Combinatorial Optimisation 7832 (2013) 202-213</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most real-world Planning problems are multi-objective, trying to minimize
both the makespan of the solution plan, and some cost of the actions involved
in the plan. But most, if not all existing approaches are based on
single-objective planners, and use an aggregation of the objectives to remain
in the single-objective context. Divide and Evolve (DaE) is an evolutionary
planner that won the temporal deterministic satisficing track at the last
International Planning Competitions (IPC). Like all Evolutionary Algorithms
(EA), it can easily be turned into a Pareto-based Multi-Objective EA. It is
however important to validate the resulting algorithm by comparing it with the
aggregation approach: this is the goal of this paper. The comparative
experiments on a recently proposed benchmark set that are reported here
demonstrate the usefulness of going Pareto-based in AI Planning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1172</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1172</id><created>2013-05-06</created><authors><author><keyname>Chazal</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Sophia Antipolis / INRIA Saclay - Ile de France</affiliation></author><author><keyname>Sun</keyname><forenames>Jian</forenames></author></authors><title>Gromov-Hausdorff Approximation of Metric Spaces with Linear Structure</title><categories>cs.CG cs.LG math.MG</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many real-world applications data come as discrete metric spaces sampled
around 1-dimensional filamentary structures that can be seen as metric graphs.
In this paper we address the metric reconstruction problem of such filamentary
structures from data sampled around them. We prove that they can be
approximated, with respect to the Gromov-Hausdorff distance by well-chosen Reeb
graphs (and some of their variants) and we provide an efficient and easy to
implement algorithm to compute such approximations in almost linear time. We
illustrate the performances of our algorithm on a few synthetic and real data
sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1175</identifier>
 <datestamp>2014-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1175</id><created>2013-05-06</created><updated>2013-05-07</updated><authors><author><keyname>Gallos</keyname><forenames>Lazaros K.</forenames></author><author><keyname>Potiguar</keyname><forenames>Fabricio Q.</forenames></author><author><keyname>Andrade</keyname><forenames>Jos&#xe9; S.</forenames><suffix>Jr.</suffix></author><author><keyname>Makse</keyname><forenames>Hernan A.</forenames></author></authors><title>IMDB network revisited: unveiling fractal and modular properties from a
  typical small-world network</title><categories>physics.soc-ph cs.SI</categories><comments>12 pages, 9 figures, accepted for publication in PLOS ONE</comments><journal-ref>PLOS One, volume 8, issue 6, e66443 (2013)</journal-ref><doi>10.1371/journal.pone.0066443</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a subset of the movie collaboration network, imdb.com, where only
adult movies are included. We show that there are many benefits in using such a
network, which can serve as a prototype for studying social interactions. We
find that the strength of links, i.e., how many times two actors have
collaborated with each other, is an important factor that can significantly
influence the network topology. We see that when we link all actors in the same
movie with each other, the network becomes small-world, lacking a proper
modular structure. On the other hand, by imposing a threshold on the minimum
number of links two actors should have to be in our studied subset, the network
topology becomes naturally fractal. This occurs due to a large number of
meaningless links, namely, links connecting actors that did not actually
interact. We focus our analysis on the fractal and modular properties of this
resulting network, and show that the renormalization group analysis can
characterize the self-similar structure of these networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1183</identifier>
 <datestamp>2013-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1183</id><created>2013-05-06</created><updated>2013-07-16</updated><authors><author><keyname>Filipovi&#x10d;</keyname><forenames>J.</forenames></author><author><keyname>Madzin</keyname><forenames>M.</forenames></author><author><keyname>Fousek</keyname><forenames>J.</forenames></author><author><keyname>Matyska</keyname><forenames>L.</forenames></author></authors><title>Optimizing CUDA Code By Kernel Fusion---Application on BLAS</title><categories>cs.DC</categories><comments>Manuscript submitted to SIAM Journal on Scientific Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern GPUs are able to perform significantly more arithmetic operations than
transfers of a single word to or from global memory. Hence, many GPU kernels
are limited by memory bandwidth and cannot exploit the arithmetic power of
GPUs. However, the memory locality can be often improved by kernel fusion when
a sequence of kernels is executed and some kernels in this sequence share data.
  In this paper, we show how kernels performing map, reduce or their nested
combinations can be fused automatically by our source-to-source compiler. To
demonstrate the usability of the compiler, we have implemented several BLAS-1
and BLAS-2 routines and show how the performance of their sequences can be
improved by fusions.
  Compared to similar sequences using CUBLAS, our compiler is able to generate
code that is up to 2.61x faster for the examples tested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1187</identifier>
 <datestamp>2013-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1187</id><created>2013-05-06</created><updated>2013-12-10</updated><authors><author><keyname>Khanzadi</keyname><forenames>M. Reza</forenames></author><author><keyname>Kuylenstierna</keyname><forenames>Dan</forenames></author><author><keyname>Panahi</keyname><forenames>Ashkan</forenames></author><author><keyname>Eriksson</keyname><forenames>Thomas</forenames></author><author><keyname>Zirath</keyname><forenames>Herbert</forenames></author></authors><title>Calculation of the Performance of Communication Systems from Measured
  Oscillator Phase Noise</title><categories>cs.IT math.IT</categories><comments>Accepted in IEEE Transactions on Circuits and Systems-I: Regular
  Papers</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Oscillator phase noise (PN) is one of the major problems that affect the
performance of communication systems. In this paper, a direct connection
between oscillator measurements, in terms of measured single-side band PN
spectrum, and the optimal communication system performance, in terms of the
resulting error vector magnitude (EVM) due to PN, is mathematically derived and
analyzed. First, a statistical model of the PN, considering the effect of white
and colored noise sources, is derived. Then, we utilize this model to derive
the modified Bayesian Cramer-Rao bound on PN estimation, and use it to find an
EVM bound for the system performance. Based on our analysis, it is found that
the influence from different noise regions strongly depends on the
communication bandwidth, i.e., the symbol rate. For high symbol rate
communication systems, cumulative PN that appears near carrier is of relatively
low importance compared to the white PN far from carrier. Our results also show
that 1/f^3 noise is more predictable compared to 1/f^2 noise and in a fair
comparison it affects the performance less.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1193</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1193</id><created>2013-05-06</created><authors><author><keyname>Feulner</keyname><forenames>Thomas</forenames></author></authors><title>Canonical Forms and Automorphisms in the Projective Space</title><categories>cs.IT cs.DM math.CO math.IT</categories><msc-class>05E18, 20B25, 20B40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\C$ be a sequence of multisets of subspaces of a vector space $\F_q^k$.
We describe a practical algorithm which computes a canonical form and the
stabilizer of $\C$ under the group action of the general semilinear group. It
allows us to solve canonical form problems in coding theory, i.e. we are able
to compute canonical forms of linear codes, $\F_{q}$-linear block codes over
the alphabet $\F_{q^s}$ and random network codes under their natural notion of
equivalence. The algorithm that we are going to develop is based on the
partition refinement method and generalizes a previous work by the author on
the computation of canonical forms of linear codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1199</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1199</id><created>2013-05-06</created><updated>2013-06-26</updated><authors><author><keyname>Smith</keyname><forenames>Leslie N.</forenames></author></authors><title>How to find real-world applications for compressive sensing</title><categories>cs.CV</categories><comments>10 pages</comments><journal-ref>Proceedings of SPIE DSS 2013, Conference 8717 Compressive Sensing
  II</journal-ref><doi>10.1117/12.2018244</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  The potential of compressive sensing (CS) has spurred great interest in the
research community and is a fast growing area of research. However, research
translating CS theory into practical hardware and demonstrating clear and
significant benefits with this hardware over current, conventional imaging
techniques has been limited. This article helps researchers to find those niche
applications where the CS approach provides substantial gain over conventional
approaches by articulating lessons learned in finding one such application; sea
skimming missile detection. As a proof of concept, it is demonstrated that a
simplified CS missile detection architecture and algorithm provides comparable
results to the conventional imaging approach but using a smaller FPA. The
primary message is that all of the excitement surrounding CS is necessary and
appropriate for encouraging our creativity but we all must also take off our
&quot;rose colored glasses&quot; and critically judge our ideas, methods and results
relative to conventional imaging approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1206</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1206</id><created>2013-05-06</created><authors><author><keyname>Cardelino</keyname><forenames>Juan</forenames></author><author><keyname>Caselles</keyname><forenames>Vicent</forenames></author><author><keyname>Bertalmio</keyname><forenames>Marcelo</forenames></author><author><keyname>Randall</keyname><forenames>Gregory</forenames></author></authors><title>A Contrario Selection of Optimal Partitions for Image Segmentation</title><categories>cs.CV</categories><comments>Siam Journal on Imaging Sciences</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel segmentation algorithm based on a hierarchical
representation of images. The main contribution of this work is to explore the
capabilities of the A Contrario reasoning when applied to the segmentation
problem, and to overcome the limitations of current algorithms within that
framework. This exploratory approach has three main goals.
  Our first goal is to extend the search space of greedy merging algorithms to
the set of all partitions spanned by a certain hierarchy, and to cast the
segmentation as a selection problem within this space. In this way we increase
the number of tested partitions and thus we potentially improve the
segmentation results. In addition, this space is considerably smaller than the
space of all possible partitions, thus we still keep the complexity controlled.
  Our second goal aims to improve the locality of region merging algorithms,
which usually merge pairs of neighboring regions. In this work, we overcome
this limitation by introducing a validation procedure for complete partitions,
rather than for pairs of regions.
  The third goal is to perform an exhaustive experimental evaluation
methodology in order to provide reproducible results.
  Finally, we embed the selection process on a statistical A Contrario
framework which allows us to have only one free parameter related to the
desired scale.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1212</identifier>
 <datestamp>2014-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1212</id><created>2013-05-06</created><updated>2014-02-07</updated><authors><author><keyname>Lecci</keyname><forenames>Fabrizio</forenames></author><author><keyname>Rinaldo</keyname><forenames>Alessandro</forenames></author><author><keyname>Wasserman</keyname><forenames>Larry</forenames></author></authors><title>Statistical Analysis of Metric Graph Reconstruction</title><categories>math.ST cs.CG stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A metric graph is a 1-dimensional stratified metric space consisting of
vertices and edges or loops glued together. Metric graphs can be naturally used
to represent and model data that take the form of noisy filamentary structures,
such as street maps, neurons, networks of rivers and galaxies. We consider the
statistical problem of reconstructing the topology of a metric graph embedded
in R^D from a random sample. We derive lower and upper bounds on the minimax
risk for the noiseless case and tubular noise case. The upper bound is based on
the reconstruction algorithm given in Aanjaneya et al. (2012).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1216</identifier>
 <datestamp>2014-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1216</id><created>2013-05-06</created><updated>2014-03-03</updated><authors><author><keyname>Robinson-Garc&#xed;a</keyname><forenames>Nicol&#xe1;s</forenames></author><author><keyname>Torres-Salinas</keyname><forenames>Daniel</forenames></author><author><keyname>L&#xf3;pez-C&#xf3;zar</keyname><forenames>Emilio Delgado</forenames></author><author><keyname>Herrera</keyname><forenames>Francisco</forenames></author></authors><title>An insight into the importance of national university rankings in an
  international context: The case of the I-UGR Rankings of Spanish universities</title><categories>cs.DL</categories><comments>V1 Paper accepted for the ISSI 2013, V2 Paper accepted for
  Scientometrics Special Issue of the ISSI 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The great importance international rankings have achieved in the research
policy arena warns against many threats consequence of the flaws and
shortcomings these tools present. One of them has to do with the inability to
accurately represent national university systems as their original purpose is
only to rank world-class universities. Another one has to do with the lack of
representativeness of universities' disciplinary profiles as they usually
provide a unique table. Although some rankings offer a great coverage and
others offer league tables by fields, no international ranking does both. In
order to surpass such limitation from a research policy viewpoint, this paper
analyzes the possibility of using national rankings in order to complement
international rankings. For this, we analyze the Spanish university system as a
study case presenting the I-UGR Rankings for Spanish universities by fields and
subfields. Then, we compare their results with those obtained by the Shanghai
Ranking, the QS Ranking, the Leiden Ranking and the NTU Ranking, as they all
have basic common grounds which allow such comparison. We conclude that it is
advisable to use national rankings in order to complement international
rankings, however we observe that this must be done with certain caution as
they differ on the methodology employed as well as on the construction of the
fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1221</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1221</id><created>2013-05-06</created><authors><author><keyname>Blaum</keyname><forenames>Mario</forenames></author><author><keyname>Plank</keyname><forenames>James S.</forenames></author></authors><title>Construction of two SD Codes</title><categories>cs.IT math.IT</categories><comments>8 pages. arXiv admin note: text overlap with arXiv:1305.0032</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  SD codes are erasure codes that address the mixed failure mode of current
RAID systems. Rather than dedicate entire disks to erasure coding, as done in
RAID-5, RAID-6 and Reed-Solomon coding, an SD code dedicates entire disks, plus
individual sectors to erasure coding. The code then tolerates combinations of
disk and sector errors, rather than solely disk errors. It is been an open
problem to construct general codes that have the SD property, and previous work
has relied on Monte Carlo searches. In this paper, we present two general
constructions that address the cases with one disk and two sectors, and two
disks and two sectors. Additionally, we make an observation about shortening SD
codes that allows us to prune Monte Carlo searches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1222</identifier>
 <datestamp>2013-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1222</id><created>2013-05-06</created><updated>2013-11-12</updated><authors><author><keyname>Tr&#xe4;ff</keyname><forenames>Jesper Larsson</forenames></author></authors><title>A Note on (Parallel) Depth- and Breadth-First Search by Arc Elimination</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note recapitulates an algorithmic observation for ordered Depth-First
Search (DFS) in directed graphs that immediately leads to a parallel algorithm
with linear speed-up for a range of processors for non-sparse graphs. The note
extends the approach to ordered Breadth-First Search (BFS). With $p$
processors, both DFS and BFS algorithms run in $O(m/p+n)$ time steps on a
shared-memory parallel machine allowing concurrent reading of locations, e.g.,
a CREW PRAM, and have linear speed-up for $p\leq m/n$. Both algorithms need $n$
synchronization steps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1230</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1230</id><created>2013-05-06</created><authors><author><keyname>Rezaei</keyname><forenames>Farzad</forenames></author><author><keyname>Charalambous</keyname><forenames>Charalambos D.</forenames></author><author><keyname>Stavrou</keyname><forenames>Photios A.</forenames></author></authors><title>Rate Distortion Function for a Class of Relative Entropy Sources</title><categories>cs.IT math.IT</categories><comments>6 pages, final version presented at Internation Symposium on
  Mathematical Theory of Networks and Systems (MTNS), Budapest, Hungary, 2010,
  pp. 1853-1858</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with rate distortion or source coding with fidelity
criterion, in measure spaces, for a class of source distributions. The class of
source distributions is described by a relative entropy constraint set between
the true and a nominal distribution. The rate distortion problem for the class
is thus formulated and solved using minimax strategies, which result in robust
source coding with fidelity criterion. It is shown that minimax and maxmin
strategies can be computed explicitly, and they are generalizations of the
classical solution. Finally, for discrete memoryless uncertain sources, the
rate distortion theorem is stated for the class omitting the derivations while
the converse is derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1256</identifier>
 <datestamp>2015-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1256</id><created>2013-05-06</created><authors><author><keyname>Mirone</keyname><forenames>Alessandro</forenames></author><author><keyname>Brun</keyname><forenames>Emmanuel</forenames></author><author><keyname>Coan</keyname><forenames>Paola</forenames></author></authors><title>A Convex Functional for Image Denoising based on Patches with
  Constrained Overlaps and its vectorial application to Low Dose Differential
  Phase Tomography</title><categories>math.NA cs.CV</categories><doi>10.1371/journal.pone.0114325</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We solve the image denoising problem with a dictionary learning technique by
writing a convex functional of a new form. This functional contains beside the
usual sparsity inducing term and fidelity term, a new term which induces
similarity between overlapping patches in the overlap regions. The functional
depends on two free regularization parameters: a coefficient multiplying the
sparsity-inducing $L_{1}$ norm of the patch basis functions coefficients, and a
coefficient multiplying the $L_{2}$ norm of the differences between patches in
the overlapping regions. The solution is found by applying the iterative
proximal gradient descent method with FISTA acceleration. In the case of
tomography reconstruction we calculate the gradient by applying projection of
the solution and its error backprojection at each iterative step. We study the
quality of the solution, as a function of the regularization parameters and
noise, on synthetic datas for which the solution is a-priori known. We apply
the method on experimental data in the case of Differential Phase Tomography.
For this case we use an original approach which consists in using vectorial
patches, each patch having two components: one per each gradient component. The
resulting algorithm, implemented in the ESRF tomography reconstruction code
PyHST, results to be robust, efficient, and well adapted to strongly reduce the
required dose and the number of projections in medical tomography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1259</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1259</id><created>2013-04-11</created><authors><author><keyname>Chobot</keyname><forenames>Edwin</forenames></author><author><keyname>Newby</keyname><forenames>Daniel</forenames></author><author><keyname>Chandler</keyname><forenames>Renee</forenames></author><author><keyname>Abu-Mulaweh</keyname><forenames>Nusaybah</forenames></author><author><keyname>Chen</keyname><forenames>Chao</forenames></author><author><keyname>Pomalaza-Raez</keyname><forenames>Carlos</forenames></author></authors><title>Design and Implementation of a Wireless Sensor and Actuator Network for
  Energy Measurement and Control at Home</title><categories>cs.NI</categories><comments>15 pages, 12 figures</comments><journal-ref>International Journal of Embedded Systems and Applications, vol.
  3, no. 1, March 2013</journal-ref><doi>10.5121/ijesa.2013.3101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the design, implementation, and testing of a wireless
sensor and actuator network for monitoring the energy use of electric
appliances in a home environment. The network includes energy measurement nodes
and a central server, where the nodes read the energy use of connected
appliance, and wirelessly report their readings to the central server for
processing. The server displays the readings from these nodes via a user visual
interface in real time. Through this system, users can easily understand their
electricity usage patterns and adapt their behavior to reduce their energy
consumption and costs. Moreover, users are able to remotely power on/off
individual devices to actively control the power use of certain appliances. The
system allows for inexpensive monitoring of home energy use and illustrates a
practical way to control the energy consumption through user interaction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1268</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1268</id><created>2013-05-06</created><authors><author><keyname>Levy</keyname><forenames>Bernard C.</forenames></author><author><keyname>Zorzi</keyname><forenames>Mattia</forenames></author></authors><title>A Contraction Analysis of the Convergence of Risk-Sensitive Filters</title><categories>math.OC cs.SY</categories><comments>22 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A contraction analysis of risk-sensitive Riccati equations is proposed. When
the state-space model is reachable and observable, a block-update
implementation of the risk-sensitive filter is used to show that the N-fold
composition of the Riccati map is strictly contractive with respect to the
Riemannian metric of positive definite matrices, when N is larger than the
number of states. The range of values of the risk-sensitivity parameter for
which the map remains contractive can be estimated a priori. It is also found
that a second condition must be imposed on the risk-sensitivity parameter and
on the initial error variance to ensure that the solution of the risk-sensitive
Riccati equation remains positive definite at all times. The two conditions
obtained can be viewed as extending to the multivariable case an earlier
analysis of Whittle for the scalar case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1270</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1270</id><created>2013-05-06</created><authors><author><keyname>Jacob</keyname><forenames>Grasha</forenames></author><author><keyname>Murugan</keyname><forenames>A.</forenames></author></authors><title>An Encryption Scheme with DNA Technology and JPEG Zigzag Coding for
  Secure Transmission of Images</title><categories>cs.CR</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Internet is a ubiquitous and affordable communications network suited for
e-commerce and medical image communications. Security has become a major issue
as data communication channels can be intruded by intruders during
transmission. Though, different methods have been proposed and used to protect
the transmission of data from illegal and unauthorized access, code breakers
have come up with various methods to crack them. DNA based Cryptography brings
forward a new hope for unbreakable algorithms. This paper outlines an
encryption scheme with DNA technology and JPEG Zigzag Coding for Secure
Transmission of Images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1288</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1288</id><created>2013-05-06</created><authors><author><keyname>Szolnoki</keyname><forenames>Attila</forenames></author><author><keyname>Perc</keyname><forenames>Matjaz</forenames></author></authors><title>Decelerated invasion and waning moon patterns in public goods games with
  delayed distribution</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI q-bio.PE</categories><comments>4 two-column pages, 5 figures; accepted for publication in Physical
  Review E</comments><journal-ref>Phys. Rev. E 87 (2013) 054801</journal-ref><doi>10.1103/PhysRevE.87.054801</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the evolution of cooperation in the spatial public goods game,
focusing on the effects that are brought about by the delayed distribution of
goods that accumulate in groups due to the continuous investments of
cooperators. We find that intermediate delays enhance network reciprocity
because of a decelerated invasion of defectors, who are unable to reap the same
high short-term benefits as they do in the absence of delayed distribution.
Long delays, however, introduce a risk because the large accumulated wealth
might fall into the wrong hands. Indeed, as soon as the curvature of a
cooperative cluster turns negative, the engulfed defectors can collect the
heritage of many generations of cooperators, and by doing so start a waning
moon pattern that nullifies the benefits of decelerated invasion. Accidental
meeting points of growing cooperative clusters may also act as triggers for the
waning moon effect, thus linking the success of cooperators with their
propensity to fail in a rather bizarre way. Our results highlight that
&quot;investing into the future&quot; is a good idea only if that future is sufficiently
near and not likely to be burdened by inflation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1293</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1293</id><created>2013-05-07</created><authors><author><keyname>Ying</keyname><forenames>Xiang</forenames></author><author><keyname>Xin</keyname><forenames>Shi-Qing</forenames></author><author><keyname>He</keyname><forenames>Ying</forenames></author></authors><title>Parallel Chen-Han (PCH) Algorithm for Discrete Geodesics</title><categories>cs.GR</categories><comments>10 pages, accepted to ACM Transactions on Graphics with major
  revision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many graphics applications, the computation of exact geodesic distance is
very important. However, the high computational cost of the existing geodesic
algorithms means that they are not practical for large-scale models or
time-critical applications. To tackle this challenge, we propose the parallel
Chen-Han (or PCH) algorithm, which extends the classic Chen-Han (CH) discrete
geodesic algorithm to the parallel setting. The original CH algorithm and its
variant both lack a parallel solution because the windows (a key data structure
that carries the shortest distance in the wavefront propagation) are maintained
in a strict order or a tightly coupled manner, which means that only one window
is processed at a time. We propose dividing the CH's sequential algorithm into
four phases, window selection, window propagation, data organization, and
events processing so that there is no data dependence or conflicts in each
phase and the operations within each phase can be carried out in parallel. The
proposed PCH algorithm is able to propagate a large number of windows
simultaneously and independently. We also adopt a simple yet effective strategy
to control the total number of windows. We implement the PCH algorithm on
modern GPUs (such as Nvidia GTX 580) and analyze the performance in detail. The
performance improvement (compared to the sequential algorithms) is highly
consistent with GPU double-precision performance (GFLOPS). Extensive
experiments on real-world models demonstrate an order of magnitude improvement
in execution time compared to the state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1295</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1295</id><created>2013-05-06</created><authors><author><keyname>Dietzfelbinger</keyname><forenames>Martin</forenames></author><author><keyname>Woelfel</keyname><forenames>Philipp</forenames></author></authors><title>Tight Lower Bounds for Greedy Routing in Higher-Dimensional Small-World
  Grids</title><categories>cs.DS cs.CC cs.NI cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider Kleinberg's celebrated small world graph model (Kleinberg, 2000),
in which a D-dimensional grid {0,...,n-1}^D is augmented with a constant number
of additional unidirectional edges leaving each node. These long range edges
are determined at random according to a probability distribution (the
augmenting distribution), which is the same for each node. Kleinberg suggested
using the inverse D-th power distribution, in which node v is the long range
contact of node u with a probability proportional to ||u-v||^(-D). He showed
that such an augmenting distribution allows to route a message efficiently in
the resulting random graph: The greedy algorithm, where in each intermediate
node the message travels over a link that brings the message closest to the
target w.r.t. the Manhattan distance, finds a path of expected length O(log^2
n) between any two nodes. In this paper we prove that greedy routing does not
perform asymptotically better for any uniform and isotropic augmenting
distribution, i.e., the probability that node u has a particular long range
contact v is independent of the labels of u and v and only a function of
||u-v||.
  In order to obtain the result, we introduce a novel proof technique: We
define a budget game, in which a token travels over a game board, while the
player manages a &quot;probability budget&quot;. In each round, the player bets part of
her remaining probability budget on step sizes. A step size is chosen at random
according to a probability distribution of the player's bet. The token then
makes progress as determined by the chosen step size, while some of the
player's bet is removed from her probability budget. We prove a tight lower
bound for such a budget game, and then obtain a lower bound for greedy routing
in the D-dimensional grid by a reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1319</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1319</id><created>2013-05-06</created><authors><author><keyname>Bamman</keyname><forenames>David</forenames></author><author><keyname>Smith</keyname><forenames>Noah A.</forenames></author></authors><title>New Alignment Methods for Discriminative Book Summarization</title><categories>cs.CL</categories><comments>This paper reflects work in progress</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the unsupervised alignment of the full text of a book with a
human-written summary. This presents challenges not seen in other text
alignment problems, including a disparity in length and, consequent to this, a
violation of the expectation that individual words and phrases should align,
since large passages and chapters can be distilled into a single summary
phrase. We present two new methods, based on hidden Markov models, specifically
targeted to this problem, and demonstrate gains on an extractive book
summarization task. While there is still much room for improvement,
unsupervised alignment holds intrinsic value in offering insight into what
features of a book are deemed worthy of summarization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1327</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1327</id><created>2013-05-06</created><authors><author><keyname>Zatloukal</keyname><forenames>Kevin C.</forenames></author></authors><title>Classical and Quantum Algorithms for Testing Equivalence of Group
  Extensions</title><categories>quant-ph cs.DS</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While efficient algorithms are known for solving many important problems
related to groups, no efficient algorithm is known for determining whether two
arbitrary groups are isomorphic. The particular case of 2-nilpotent groups, a
special type of central extension, is widely believed to contain the essential
hard cases. However, looking specifically at central extensions, the natural
formulation of being &quot;the same&quot; is not isomorphism but rather &quot;equivalence,&quot;
which requires an isomorphism to preserves the structure of the extension. In
this paper, we show that equivalence of central extensions can be computed
efficiently on a classical computer when the groups are small enough to be
given by their multiplication tables. However, in the model of black box
groups, which allows the groups to be much larger, we show that equivalence can
be computed efficiently on a quantum computer but not a classical one (under
common complexity assumptions). Our quantum algorithm demonstrates a new
application of the hidden subgroup problem for general abelian groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1330</identifier>
 <datestamp>2013-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1330</id><created>2013-05-06</created><updated>2013-12-19</updated><authors><author><keyname>Geng</keyname><forenames>Quan</forenames></author><author><keyname>Viswanath</keyname><forenames>Pramod</forenames></author></authors><title>Optimal Noise Adding Mechanisms for Approximate Differential Privacy</title><categories>cs.DS cs.CR</categories><comments>27 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the (nearly) optimal mechanisms in $(\epsilon,\delta)$-approximate
differential privacy for integer-valued query functions and vector-valued
(histogram-like) query functions under a utility-maximization/cost-minimization
framework. We characterize the tradeoff between $\epsilon$ and $\delta$ in
utility and privacy analysis for histogram-like query functions ($\ell^1$
sensitivity), and show that the $(\epsilon,\delta)$-differential privacy is a
framework not much more general than the $(\epsilon,0)$-differential privacy
and $(0,\delta)$-differential privacy in the context of $\ell^1$ and $\ell^2$
cost functions, i.e., minimum expected noise magnitude and noise power. In the
same context of $\ell^1$ and $\ell^2$ cost functions, we show the
near-optimality of uniform noise mechanism and discrete Laplacian mechanism in
the high privacy regime (as $(\epsilon,\delta) \to (0,0)$). We conclude that in
$(\epsilon,\delta)$-differential privacy, the optimal noise magnitude and noise
power are $\Theta(\min(\frac{1}{\epsilon},\frac{1}{\delta}))$ and
$\Theta(\min(\frac{1}{\epsilon^2},\frac{1}{\delta^2}))$, respectively, in the
high privacy regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1343</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1343</id><created>2013-05-06</created><authors><author><keyname>Bleier</keyname><forenames>Arnim</forenames></author><author><keyname>Strotmann</keyname><forenames>Andreas</forenames></author></authors><title>Towards an Author-Topic-Term-Model Visualization of 100 Years of German
  Sociological Society Proceedings</title><categories>cs.DL cs.CL cs.IR</categories><comments>Accepted: 14th International Society of Scientometrics and
  Informetrics Conference, Vienna Austria 15-19th July 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Author co-citation studies employ factor analysis to reduce high-dimensional
co-citation matrices to low-dimensional and possibly interpretable factors, but
these studies do not use any information from the text bodies of publications.
We hypothesise that term frequencies may yield useful information for
scientometric analysis. In our work we ask if word features in combination with
Bayesian analysis allow well-founded science mapping studies. This work goes
back to the roots of Mosteller and Wallace's (1964) statistical text analysis
using word frequency features and a Bayesian inference approach, tough with
different goals. To answer our research question we (i) introduce a new data
set on which the experiments are carried out, (ii) describe the Bayesian model
employed for inference and (iii) present first results of the analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1344</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1344</id><created>2013-05-06</created><authors><author><keyname>Benzarti</keyname><forenames>Faouzi</forenames></author><author><keyname>Amiri</keyname><forenames>Hamid</forenames></author></authors><title>Speckle Noise Reduction in Medical Ultrasound Images</title><categories>cs.CV</categories><journal-ref>International Journal of Computer Science Issues, Vol 9, Issue 2,
  No 3, March 2012 ISSN 1694-0814</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ultrasound imaging is an incontestable vital tool for diagnosis, it provides
in non-invasive manner the internal structure of the body to detect eventually
diseases or abnormalities tissues. Unfortunately, the presence of speckle noise
in these images affects edges and fine details which limit the contrast
resolution and make diagnostic more difficult. In this paper, we propose a
denoising approach which combines logarithmic transformation and a non linear
diffusion tensor. Since speckle noise is multiplicative and nonwhite process,
the logarithmic transformation is a reasonable choice to convert
signaldependent or pure multiplicative noise to an additive one. The key idea
from using diffusion tensor is to adapt the flow diffusion towards the local
orientation by applying anisotropic diffusion along the coherent structure
direction of interesting features in the image. To illustrate the effective
performance of our algorithm, we present some experimental results on
synthetically and real echographic images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1347</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1347</id><created>2013-05-06</created><authors><author><keyname>Gupta</keyname><forenames>Anupam</forenames></author><author><keyname>Talwar</keyname><forenames>Kunal</forenames></author><author><keyname>Witmer</keyname><forenames>David</forenames></author></authors><title>Sparsest Cut on Bounded Treewidth Graphs: Algorithms and Hardness
  Results</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a 2-approximation algorithm for Non-Uniform Sparsest Cut that runs in
time $n^{O(k)}$, where $k$ is the treewidth of the graph. This improves on the
previous $2^{2^k}$-approximation in time $\poly(n) 2^{O(k)}$ due to
Chlamt\'a\v{c} et al.
  To complement this algorithm, we show the following hardness results: If the
Non-Uniform Sparsest Cut problem has a $\rho$-approximation for series-parallel
graphs (where $\rho \geq 1$), then the Max Cut problem has an algorithm with
approximation factor arbitrarily close to $1/\rho$. Hence, even for such
restricted graphs (which have treewidth 2), the Sparsest Cut problem is NP-hard
to approximate better than $17/16 - \epsilon$ for $\epsilon &gt; 0$; assuming the
Unique Games Conjecture the hardness becomes $1/\alpha_{GW} - \epsilon$. For
graphs with large (but constant) treewidth, we show a hardness result of $2 -
\epsilon$ assuming the Unique Games Conjecture.
  Our algorithm rounds a linear program based on (a subset of) the
Sherali-Adams lift of the standard Sparsest Cut LP. We show that even for
treewidth-2 graphs, the LP has an integrality gap close to 2 even after
polynomially many rounds of Sherali-Adams. Hence our approach cannot be
improved even on such restricted graphs without using a stronger relaxation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1359</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1359</id><created>2013-05-06</created><authors><author><keyname>Andoni</keyname><forenames>Alexandr</forenames></author><author><keyname>Panigrahy</keyname><forenames>Rina</forenames></author></authors><title>A Differential Equations Approach to Optimizing Regret Trade-offs</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the classical question of predicting binary sequences and study
the {\em optimal} algorithms for obtaining the best possible regret and payoff
functions for this problem. The question turns out to be also equivalent to the
problem of optimal trade-offs between the regrets of two experts in an &quot;experts
problem&quot;, studied before by \cite{kearns-regret}. While, say, a regret of
$\Theta(\sqrt{T})$ is known, we argue that it important to ask what is the
provably optimal algorithm for this problem --- both because it leads to
natural algorithms, as well as because regret is in fact often comparable in
magnitude to the final payoffs and hence is a non-negligible term.
  In the basic setting, the result essentially follows from a classical result
of Cover from '65. Here instead, we focus on another standard setting, of
time-discounted payoffs, where the final &quot;stopping time&quot; is not specified. We
exhibit an explicit characterization of the optimal regret for this setting.
  To obtain our main result, we show that the optimal payoff functions have to
satisfy the Hermite differential equation, and hence are given by the solutions
to this equation. It turns out that characterization of the payoff function is
qualitatively different from the classical (non-discounted) setting, and,
namely, there's essentially a unique optimal solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1363</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1363</id><created>2013-05-06</created><updated>2013-05-16</updated><authors><author><keyname>Gao</keyname><forenames>Wei</forenames></author><author><keyname>Jin</keyname><forenames>Rong</forenames></author><author><keyname>Zhu</keyname><forenames>Shenghuo</forenames></author><author><keyname>Zhou</keyname><forenames>Zhi-Hua</forenames></author></authors><title>One-Pass AUC Optimization</title><categories>cs.LG</categories><comments>Proceeding of 30th International Conference on Machine Learning</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  AUC is an important performance measure and many algorithms have been devoted
to AUC optimization, mostly by minimizing a surrogate convex loss on a training
data set. In this work, we focus on one-pass AUC optimization that requires
only going through the training data once without storing the entire training
dataset, where conventional online learning algorithms cannot be applied
directly because AUC is measured by a sum of losses defined over pairs of
instances from different classes. We develop a regression-based algorithm which
only needs to maintain the first and second order statistics of training data
in memory, resulting a storage requirement independent from the size of
training data. To efficiently handle high dimensional data, we develop a
randomized algorithm that approximates the covariance matrices by low rank
matrices. We verify, both theoretically and empirically, the effectiveness of
the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1371</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1371</id><created>2013-05-06</created><authors><author><keyname>Min</keyname><forenames>Fan</forenames></author><author><keyname>Zhu</keyname><forenames>William</forenames></author></authors><title>Granular association rules for multi-valued data</title><categories>cs.IR cs.DB</categories><comments>Proceedings of The 2013 Canadian Conference on Electrical and
  Computer Engineering (to appear)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Granular association rule is a new approach to reveal patterns hide in
many-to-many relationships of relational databases. Different types of data
such as nominal, numeric and multi-valued ones should be dealt with in the
process of rule mining. In this paper, we study multi-valued data and develop
techniques to filter out strong however uninteresting rules. An example of such
rule might be &quot;male students rate movies released in 1990s that are NOT
thriller.&quot; This kind of rules, called negative granular association rules,
often overwhelms positive ones which are more useful. To address this issue, we
filter out negative granules such as &quot;NOT thriller&quot; in the process of granule
generation. In this way, only positive granular association rules are generated
and strong ones are mined. Experimental results on the movielens data set
indicate that most rules are negative, and our technique is effective to filter
them out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1372</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1372</id><created>2013-05-06</created><authors><author><keyname>Min</keyname><forenames>Fan</forenames></author><author><keyname>Zhu</keyname><forenames>William</forenames></author></authors><title>Cold-start recommendation through granular association rules</title><categories>cs.IR</categories><comments>Submitted to Joint Rough Sets 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recommender systems are popular in e-commerce as they suggest items of
interest to users. Researchers have addressed the cold-start problem where
either the user or the item is new. However, the situation with both new user
and new item has seldom been considered. In this paper, we propose a cold-start
recommendation approach to this situation based on granular association rules.
Specifically, we provide a means for describing users and items through
information granules, a means for generating association rules between users
and items, and a means for recommending items to users using these rules.
Experiments are undertaken on a publicly available dataset MovieLens. Results
indicate that rule sets perform similarly on the training and the testing sets,
and the appropriate setting of granule is essential to the application of
granular association rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1375</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1375</id><created>2013-05-06</created><updated>2013-05-08</updated><authors><author><keyname>Gysel</keyname><forenames>Rob</forenames></author></authors><title>Unique Perfect Phylogeny Characterizations via Uniquely Representable
  Chordal Graphs</title><categories>cs.DM cs.CE math.CO q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The perfect phylogeny problem is a classic problem in computational biology,
where we seek an unrooted phylogeny that is compatible with a set of
qualitative characters. Such a tree exists precisely when an intersection graph
associated with the character set, called the partition intersection graph, can
be triangulated using a restricted set of fill edges. Semple and Steel used the
partition intersection graph to characterize when a character set has a unique
perfect phylogeny. Bordewich, Huber, and Semple showed how to use the partition
intersection graph to find a maximum compatible set of characters. In this
paper, we build on these results, characterizing when a unique perfect
phylogeny exists for a subset of partial characters. Our characterization is
stated in terms of minimal triangulations of the partition intersection graph
that are uniquely representable, also known as ur-chordal graphs. Our
characterization is motivated by the structure of ur-chordal graphs, and the
fact that the block structure of minimal triangulations is mirrored in the
graph that has been triangulated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1396</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1396</id><created>2013-05-07</created><updated>2013-09-12</updated><authors><author><keyname>Di Martino</keyname><forenames>Mat&#xed;as</forenames></author><author><keyname>Hern&#xe1;ndez</keyname><forenames>Guzman</forenames></author><author><keyname>Fiori</keyname><forenames>Marcelo</forenames></author><author><keyname>Fern&#xe1;ndez</keyname><forenames>Alicia</forenames></author></authors><title>A new framework for optimal classifier design</title><categories>cs.CV cs.LG stat.ML</categories><journal-ref>Pattern Recognition, Volume 46, Issue 8, August 2013, Pages
  2249-2255</journal-ref><doi>10.1016/j.patcog.2013.01.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of alternative measures to evaluate classifier performance is gaining
attention, specially for imbalanced problems. However, the use of these
measures in the classifier design process is still unsolved. In this work we
propose a classifier designed specifically to optimize one of these alternative
measures, namely, the so-called F-measure. Nevertheless, the technique is
general, and it can be used to optimize other evaluation measures. An algorithm
to train the novel classifier is proposed, and the numerical scheme is tested
with several databases, showing the optimality and robustness of the presented
classifier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1397</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1397</id><created>2013-05-07</created><authors><author><keyname>Tyagi</keyname><forenames>Himanshu</forenames></author><author><keyname>Narayan</keyname><forenames>Prakash</forenames></author></authors><title>How Many Queries Will Resolve Common Randomness?</title><categories>cs.IT cs.CR math.IT</categories><comments>Accepted for publication in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A set of m terminals, observing correlated signals, communicate interactively
to generate common randomness for a given subset of them. Knowing only the
communication, how many direct queries of the value of the common randomness
will resolve it? A general upper bound, valid for arbitrary signal alphabets,
is developed for the number of such queries by using a query strategy that
applies to all common randomness and associated communication. When the
underlying signals are independent and identically distributed repetitions of m
correlated random variables, the number of queries can be exponential in signal
length. For this case, the mentioned upper bound is tight and leads to a
single-letter formula for the largest query exponent, which coincides with the
secret key capacity of a corresponding multiterminal source model. In fact, the
upper bound constitutes a strong converse for the optimum query exponent, and
implies also a new strong converse for secret key capacity. A key tool,
estimating the size of a large probability set in terms of Renyi entropy, is
interpreted separately, too, as a lossless block coding result for general
sources. As a particularization, it yields the classic result for a discrete
memoryless source.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1407</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1407</id><created>2013-05-07</created><updated>2013-10-01</updated><authors><author><keyname>Pan</keyname><forenames>Feng</forenames></author><author><keyname>Schild</keyname><forenames>Aaron</forenames></author></authors><title>Interdiction Problems on Planar Graphs</title><categories>cs.DS math.OC</categories><comments>25 pages, 9 figures. Extended abstract in APPROX-RANDOM 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interdiction problems are leader-follower games in which the leader is
allowed to delete a certain number of edges from the graph in order to
maximally impede the follower, who is trying to solve an optimization problem
on the impeded graph. We introduce approximation algorithms and strong
NP-completeness results for interdiction problems on planar graphs. We give a
multiplicative $(1 + \epsilon)$-approximation for the maximum matching
interdiction problem on weighted planar graphs. The algorithm runs in
pseudo-polynomial time for each fixed $\epsilon &gt; 0$. We also show that
weighted maximum matching interdiction, budget-constrained flow improvement,
directed shortest path interdiction, and minimum perfect matching interdiction
are strongly NP-complete on planar graphs. To our knowledge, our
budget-constrained flow improvement result is the first planar NP-completeness
proof that uses a one-vertex crossing gadget.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1409</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1409</id><created>2013-05-07</created><updated>2013-05-20</updated><authors><author><keyname>Cai</keyname><forenames>Jin-Yi</forenames></author><author><keyname>Fu</keyname><forenames>Zhiguo</forenames></author></authors><title>A Collapse Theorem for Holographic Algorithms with Matchgates on Domain
  Size at Most 4</title><categories>cs.CC</categories><comments>24 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Holographic algorithms with matchgates are a novel approach to design
polynomial time computation. It uses Kasteleyn's algorithm for perfect
matchings, and more importantly a holographic reduction . The two fundamental
parameters of a holographic reduction are the domain size $k$ of the underlying
problem, and the basis size $\ell$. A holographic reduction transforms the
computation to matchgates by a linear transformation that maps to (a tensor
product space of) a linear space of dimension $2^{\ell}$. We prove a sharp
basis collapse theorem, that shows that for domain size 3 and 4, all
non-trivial holographic reductions have basis size $\ell$ collapse to 1 and 2
respectively. The main proof techniques are Matchgates Identities, and a Group
Property of matchgates signatures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1415</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1415</id><created>2013-05-07</created><authors><author><keyname>Tajbakhsh</keyname><forenames>Shahriar Etemadi</forenames></author><author><keyname>Sadeghi</keyname><forenames>Parastoo</forenames></author><author><keyname>Kennedy</keyname><forenames>Rodney</forenames></author></authors><title>Centralized and Cooperative Transmission of Secure Multiple Unicasts
  using Network Coding</title><categories>cs.IT cs.CR math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a method for securely delivering a set of messages to a group of
clients over a broadcast erasure channel where each client is interested in a
distinct message. Each client is able to obtain its own message but not the
others'. In the proposed method the messages are combined together using a
special variant of random linear network coding. Each client is provided with a
private set of decoding coefficients to decode its own message. Our method
provides security for the transmission sessions against computational
brute-force attacks and also weakly security in information theoretic sense. As
the broadcast channel is assumed to be erroneous, the missing coded packets
should be recovered in some way. We consider two different scenarios. In the
first scenario the missing packets are retransmitted by the base station
(centralized). In the second scenario the clients cooperate with each other by
exchanging packets (decentralized). In both scenarios, network coding
techniques are exploited to increase the total throughput. For the case of
centralized retransmissions we provide an analytical approximation for the
throughput performance of instantly decodable network coded (IDNC)
retransmissions as well as numerical experiments. For the decentralized
scenario, we propose a new IDNC based retransmission method where its
performance is evaluated via simulations and analytical approximation.
Application of this method is not limited to our special problem and can be
generalized to a new class of problems introduced in this paper as the
cooperative index coding problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1422</identifier>
 <datestamp>2016-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1422</id><created>2013-05-07</created><updated>2016-01-11</updated><authors><author><keyname>Wittek</keyname><forenames>Peter</forenames></author><author><keyname>Gao</keyname><forenames>Shi Chao</forenames></author><author><keyname>Lim</keyname><forenames>Ik Soo</forenames></author><author><keyname>Zhao</keyname><forenames>Li</forenames></author></authors><title>Somoclu: An Efficient Parallel Library for Self-Organizing Maps</title><categories>cs.DC cs.MS cs.NE</categories><comments>27 pages, 9 figures. The code is available at
  https://peterwittek.github.io/somoclu/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Somoclu is a massively parallel tool for training self-organizing maps on
large data sets written in C++. It builds on OpenMP for multicore execution,
and on MPI for distributing the workload across the nodes in a cluster. It is
also able to boost training by using CUDA if graphics processing units are
available. A sparse kernel is included, which is useful for high-dimensional
but sparse data, such as the vector spaces common in text mining workflows.
Python, R and MATLAB interfaces facilitate interactive use. Apart from fast
execution, memory use is highly optimized, enabling training large emergent
maps even on a single computer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1426</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1426</id><created>2013-05-07</created><authors><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author><author><keyname>Thakare</keyname><forenames>V. M.</forenames></author></authors><title>Speech Enhancement Modeling Towards Robust Speech Recognition System</title><categories>cs.SD cs.CL</categories><comments>Pages: 04; Conference Proceedings International Conference on Advance
  Computing (ICAC-2008), India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Form about four decades human beings have been dreaming of an intelligent
machine which can master the natural speech. In its simplest form, this machine
should consist of two subsystems, namely automatic speech recognition (ASR) and
speech understanding (SU). The goal of ASR is to transcribe natural speech
while SU is to understand the meaning of the transcription. Recognizing and
understanding a spoken sentence is obviously a knowledge-intensive process,
which must take into account all variable information about the speech
communication process, from acoustics to semantics and pragmatics. While
developing an Automatic Speech Recognition System, it is observed that some
adverse conditions degrade the performance of the Speech Recognition System. In
this contribution, speech enhancement system is introduced for enhancing speech
signals corrupted by additive noise and improving the performance of Automatic
Speech Recognizers in noisy conditions. Automatic speech recognition
experiments show that replacing noisy speech signals by the corresponding
enhanced speech signals leads to an improvement in the recognition accuracies.
The amount of improvement varies with the type of the corrupting noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1427</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1427</id><created>2013-05-07</created><authors><author><keyname>Wu</keyname><forenames>Xiaoxiao</forenames></author><author><keyname>Ma</keyname><forenames>Wing-Kin</forenames></author><author><keyname>So</keyname><forenames>Anthony Man-Cho</forenames></author></authors><title>Achievable Rate Derivations and Further Simulation Results for
  &quot;Physical-Layer Multicasting by Stochastic Transmit Beamforming and Alamouti
  Space-Time Coding&quot;</title><categories>cs.IT math.IT</categories><comments>Technical Report, Department of Electronic Engineering, the Chinese
  University of Hong Kong, 13 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a companion technical report of the main manuscript &quot;Physical-Layer
Multicasting by Stochastic Transmit Beamforming and Alamouti Space-Time
Coding&quot;. The report serves to give detailed derivations of the achievable rate
functions encountered in the main manuscript, which are too long to be included
in the latter. In addition, more simulation results are presented to verify the
viability of the multicast schemes developed in the main manuscript.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1428</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1428</id><created>2013-05-07</created><authors><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author><author><keyname>Thakare</keyname><forenames>V M</forenames></author></authors><title>Speech based Password Protected Cyber Applications</title><categories>cs.CY</categories><comments>Pages: 04 Figures : 03</comments><journal-ref>Conference Proceedings International Conference On Emerging
  Technologies and Applications in Engineering, Technology and Sciences
  (ICETAETS-2008), India, pp 1563-1566</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Whenever we think of cyber applications, we visualize the model that gives
the idea that we are sitting in front of computer at home or workplace
connected to internet and performing all the work that generally we have to go
and do on a specific place for example e-shopping, e-banking, e-education etc.
In case of e-shopping, we view all the products on the computer screen with all
details by a single mouse click, select the product and do all further money
transaction through net. When we think of security, is it 100% secure? No, not
at all because though it is password protected, the password is a text base
secrete code that can be open. Therefore this paper is concentrated on
preparation of speech based password protected applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1429</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1429</id><created>2013-05-07</created><authors><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author><author><keyname>Mahajan</keyname><forenames>Anjali</forenames></author></authors><title>Speech User Interface for Information Retrieval</title><categories>cs.IR</categories><comments>Pages: 06 Figures: 01; Conference Proceedings International
  Conference on Digital Libraires (ICDL 06), 2006, TERI, India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Along with the rapid development of information technology, the amount of
information generated at a given time far exceeds human's ability to organize,
search, and manipulate without the help of automatic systems. Now a days so
many tools and techniques are available for storage and retrieval of
information. User uses interface to interact with these techniques, mostly text
user interface (TUI) or graphical user interface (GUI). Here, I am trying to
introduce a new interface i.e. speech for information retrieval. The goal of
this project is to develop a speech interface that can search and read the
required information from the database effectively, efficiently and more
friendly. This tool will be highly useful to blind people, they will able to
demand the information to the computer by giving voice command/s (keyword)
through microphone and listen the required information using speaker or
headphones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1434</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1434</id><created>2013-05-07</created><authors><author><keyname>Gharanjik</keyname><forenames>Ahmad</forenames></author><author><keyname>Rao</keyname><forenames>Bhavani Shankar Mysore Rama</forenames></author><author><keyname>Arapoglou</keyname><forenames>Pantelis-Daniel</forenames></author><author><keyname>Ottersten</keyname><forenames>Bj&#xf6;rn</forenames></author></authors><title>Gateway Switching in Q/V Band Satellite Feeder Links</title><categories>cs.IT math.IT</categories><comments>4 pages, 5 figures, accepted for publication in the IEEE
  Communications Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A main challenge towards realizing the next generation Terabit/s broadband
satellite communications (SatCom) is the limited spectrum available in the Ka
band. An attractive solution is to move the feeder link to the higher Q/V band,
where more spectrum is available. When utilizing the Q/V band, due to heavy
rain attenuation, gateway diversity is considered a necessity to ensure the
required feeder link availability. Although receive site diversity has been
studied in the past for SatCom, there is much less maturity in terms of
transmit diversity techniques. In this paper, a modified switch and stay
combining scheme is proposed for a Q/V band feeder link, but its performance is
also evaluated over an end-to-end satellite link. The proposed scheme is
pragmatic and has close to optimal performance with notably lower complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1439</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1439</id><created>2013-05-07</created><authors><author><keyname>Zhang</keyname><forenames>Renyuan</forenames></author><author><keyname>Cai</keyname><forenames>Kai</forenames></author><author><keyname>Gan</keyname><forenames>Yongmei</forenames></author><author><keyname>Wang</keyname><forenames>Zhaoan</forenames></author><author><keyname>Wonham</keyname><forenames>W. M.</forenames></author></authors><title>Supervision Localization of Timed Discrete-Event Systems</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study supervisor localization for real-time discrete-event systems (DES)
in the Brandin-Wonham framework of timed supervisory control. We view a
real-time DES as comprised of asynchronous agents which are coupled through
imposed logical and temporal specifications; the essence of supervisor
localization is the decomposition of monolithic (global) control action into
local control strategies for these individual agents. This study extends our
previous work on supervisor localization for untimed DES, in that monolithic
timed control action typically includes not only disabling action as in the
untimed case, but also ``clock preempting'' action which enforces prescribed
temporal behavior. The latter action is executed by a class of special events,
called ``forcible'' events; accordingly, we localize monolithic preemptive
action with respect to these events. We demonstrate the new features of timed
supervisor localization with a manufacturing cell case study, and discuss a
distributed control implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1443</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1443</id><created>2013-05-07</created><updated>2013-05-08</updated><authors><author><keyname>Kayaoglu</keyname><forenames>Mehmet</forenames></author><author><keyname>Topcu</keyname><forenames>Berkay</forenames></author><author><keyname>Uludag</keyname><forenames>Umut</forenames></author></authors><title>Standard Fingerprint Databases: Manual Minutiae Labeling and Matcher
  Performance Analyses</title><categories>cs.CV</categories><comments>14 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fingerprint verification and identification algorithms based on minutiae
features are used in many biometric systems today (e.g., governmental e-ID
programs, border control, AFIS, personal authentication for portable devices).
Researchers in industry/academia are now able to utilize many publicly
available fingerprint databases (e.g., Fingerprint Verification Competition
(FVC) &amp; NIST databases) to compare/evaluate their feature extraction and/or
matching algorithm performances against those of others. The results from these
evaluations are typically utilized by decision makers responsible for
implementing the cited biometric systems, in selecting/tuning specific sensors,
feature extractors and matchers. In this study, for a subset of the cited
public fingerprint databases, we report fingerprint minutiae matching results,
which are based on (i) minutiae extracted automatically from fingerprint
images, and (ii) minutiae extracted manually by human subjects. By doing so, we
are able to (i) quantitatively judge the performance differences between these
two cases, (ii) elaborate on performance upper bounds of minutiae matching,
utilizing what can be termed as &quot;ground truth&quot; minutiae features, (iii) analyze
minutiae matching performance, without coupling it with the minutiae extraction
performance beforehand. Further, as we will freely distribute the minutiae
templates, originating from this manual labeling study, in a standard minutiae
template exchange format (ISO 19794-2), we believe that other researchers in
the biometrics community will be able to utilize the associated results &amp;
templates to create their own evaluations pertaining to their fingerprint
minutiae extractors/matchers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1454</identifier>
 <datestamp>2014-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1454</id><created>2013-05-07</created><updated>2013-11-03</updated><authors><author><keyname>Krivulin</keyname><forenames>Nikolai</forenames></author></authors><title>A constrained tropical optimization problem: complete solution and
  application example</title><categories>math.OC cs.SY</categories><comments>20 pages, accepted for publication in Contemporary Mathematics</comments><msc-class>65K10 (Primary), 15A80, 90C48, 90B35 (Secondary)</msc-class><journal-ref>Tropical and Idempotent Mathematics and Applications, G. L.
  Litvinov, S. N. Sergeev, eds., vol. 616 of Contemporary Mathematics, AMS,
  2014, pp. 163-177</journal-ref><doi>10.1090/conm/616/12308</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper focuses on a multidimensional optimization problem, which is
formulated in terms of tropical mathematics and consists in minimizing a
nonlinear objective function subject to linear inequality constraints. To solve
the problem, we follow an approach based on the introduction of an additional
unknown variable to reduce the problem to solving linear inequalities, where
the variable plays the role of a parameter. A necessary and sufficient
condition for the inequalities to hold is used to evaluate the parameter,
whereas the general solution of the inequalities is taken as a solution of the
original problem. Under fairly general assumptions, a complete direct solution
to the problem is obtained in a compact vector form. The result is applied to
solve a problem in project scheduling when an optimal schedule is given by
minimizing the flow time of activities in a project under various activity
precedence constraints. As an illustration, a numerical example of optimal
scheduling is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1459</identifier>
 <datestamp>2013-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1459</id><created>2013-05-07</created><authors><author><keyname>Paolucci</keyname><forenames>Pier Stanislao</forenames></author><author><keyname>Bacivarov</keyname><forenames>Iuliana</forenames></author><author><keyname>Goossens</keyname><forenames>Gert</forenames></author><author><keyname>Leupers</keyname><forenames>Rainer</forenames></author><author><keyname>Rousseau</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Schumacher</keyname><forenames>Christoph</forenames></author><author><keyname>Thiele</keyname><forenames>Lothar</forenames></author><author><keyname>Vicini</keyname><forenames>Piero</forenames></author></authors><title>EURETILE 2010-2012 summary: first three years of activity of the
  European Reference Tiled Experiment</title><categories>cs.DC cs.AR cs.NE cs.OS cs.PL</categories><comments>56 pages</comments><acm-class>C.1.4; C.3; B.7.2; F.2.2</acm-class><doi>10.12837/2013T01</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is the summary of first three years of activity of the EURETILE FP7
project 247846. EURETILE investigates and implements brain-inspired and
fault-tolerant foundational innovations to the system architecture of massively
parallel tiled computer architectures and the corresponding programming
paradigm. The execution targets are a many-tile HW platform, and a many-tile
simulator. A set of SW process - HW tile mapping candidates is generated by the
holistic SW tool-chain using a combination of analytic and bio-inspired
methods. The Hardware dependent Software is then generated, providing OS
services with maximum efficiency/minimal overhead. The many-tile simulator
collects profiling data, closing the loop of the SW tool chain. Fine-grain
parallelism inside processes is exploited by optimized intra-tile compilation
techniques, but the project focus is above the level of the elementary tile.
The elementary HW tile is a multi-processor, which includes a fault tolerant
Distributed Network Processor (for inter-tile communication) and ASIP
accelerators. Furthermore, EURETILE investigates and implements the innovations
for equipping the elementary HW tile with high-bandwidth, low-latency
brain-like inter-tile communication emulating 3 levels of connection hierarchy,
namely neural columns, cortical areas and cortex, and develops a dedicated
cortical simulation benchmark: DPSNN-STDP (Distributed Polychronous Spiking
Neural Net with synaptic Spiking Time Dependent Plasticity). EURETILE leverages
on the multi-tile HW paradigm and SW tool-chain developed by the FET-ACA SHAPES
Integrated Project (2006-2009).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1473</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1473</id><created>2013-05-07</created><authors><author><keyname>Ziatdinov</keyname><forenames>Rushan</forenames></author><author><keyname>Miura</keyname><forenames>Kenjiro T.</forenames></author></authors><title>On the variety of planar spirals and their applications in computer
  aided design</title><categories>cs.GR</categories><journal-ref>European Researcher 27(8-2), 1227-1232, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we discuss the variety of planar spiral segments and their
applications in objects in both the real and artificial world. The discussed
curves with monotonic curvature function are well-known in geometric modelling
and computer aided geometric design as fair curves, and they are very
significant in aesthetic shape modelling. Fair curve segments are used for
two-point G1 and G2 Hermite interpolation, as well as for generating aesthetic
splines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1476</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1476</id><created>2013-05-07</created><authors><author><keyname>Haslhofer</keyname><forenames>Bernhard</forenames></author><author><keyname>Warner</keyname><forenames>Simeon</forenames></author><author><keyname>Lagoze</keyname><forenames>Carl</forenames></author><author><keyname>Klein</keyname><forenames>Martin</forenames></author><author><keyname>Sanderson</keyname><forenames>Robert</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author><author><keyname>van de Sompel</keyname><forenames>Herbert</forenames></author></authors><title>ResourceSync: Leveraging Sitemaps for Resource Synchronization</title><categories>cs.DL</categories><comments>3 pages, WWW 2013 developer track</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many applications need up-to-date copies of collections of changing Web
resources. Such synchronization is currently achieved using ad-hoc or
proprietary solutions. We propose ResourceSync, a general Web resource
synchronization protocol that leverages XML Sitemaps. It provides a set of
capabilities that can be combined in a modular manner to meet local or
community requirements. We report on work to implement this protocol for
arXiv.org and also provide an experimental prototype for the English Wikipedia
as well as a client API.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1477</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1477</id><created>2013-05-07</created><authors><author><keyname>Pandolfi</keyname><forenames>Luciano</forenames></author></authors><title>Sharp control time for viscoelastic bodys</title><categories>cs.SY math.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is now well understood that equations of viscoelasticity can be seen as
perturbation of wave type equations. This observation can be exploited in
several different ways and it turns out that it is a usefull tool when studying
controllability. Here we compare a viscoelastic system which fills a surface of
a solid region (the string case has already been studied) with its memoryless
counterpart (which is a generalized telegraph equation) in order to prove exact
controllability of the viscoelastic body at precisely the same times at which
the telegraph equation is controllable.
  The comparison is done using a moment method approach to controllability and
we prove, using the perturbations theorems of Paley-Wiener and Bari, that a new
sequence derived from the viscoelastic system is a Riesz sequence, a fact that
implies controllability of the viscoelastic system.
  The results so obtained generalize existing controllability results and
furthermore show that the ``sharp'' control time for the telegraph equation and
the viscoelastic system coincide.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1478</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1478</id><created>2013-05-07</created><updated>2013-05-30</updated><authors><author><keyname>Younis</keyname><forenames>Abdelhamid</forenames></author><author><keyname>Sinanovi&#x107;</keyname><forenames>Sinan</forenames></author><author><keyname>Di Renzo</keyname><forenames>Marco</forenames></author><author><keyname>Mesleh</keyname><forenames>Raed</forenames></author><author><keyname>Haas</keyname><forenames>Harald</forenames></author></authors><title>Generalised Sphere Decoding for Spatial Modulation</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Communications, accepted for publication</comments><doi>10.1109/TCOMM.2013.09.120547</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, Sphere Decoding (SD) algorithms for Spatial Modulation (SM)
are developed to reduce the computational complexity of Maximum-Likelihood (ML)
detectors. Two SDs specifically designed for SM are proposed and analysed in
terms of Bit Error Ratio (BER) and computational complexity.
  Using Monte Carlo simulations and mathematical analysis, it is shown that by
carefully choosing the initial radius the proposed sphere decoder algorithms
offer the same BER as ML detection, with a significant reduction in the
computational complexity.
  A tight closed form expression for the BER performance of SM-SD is derived in
the paper, along with an algorithm for choosing the initial radius which
provides near to optimum performance. Also, it is shown that none of the
proposed SDs are always superior to the others, but the best SD to use depends
on the target spectral efficiency. The computational complexity trade-off
offered by the proposed solutions is studied via analysis and simulation, and
is shown to validate our findings. Finally, the performance of SM-SDs are
compared to Spatial Multiplexing (SMX) applying ML decoder and applying SD.
  It is shown that for the same spectral efficiency, SM-SD offers up to 84%
reduction in complexity compared to SMX-SD, with up to 1 dB better BER
performance than SMX-ML decoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1481</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1481</id><created>2013-05-07</created><authors><author><keyname>Raab</keyname><forenames>C. G.</forenames></author></authors><title>Generalization of Risch's Algorithm to Special Functions</title><categories>cs.SC math-ph math.MP</categories><comments>19 pages, 1 style file, in: &quot;Integration, Summation and Special
  Functions in Quantum Field Theory&quot;, to appear at Springer Verlag, Vienna</comments><report-no>DESY 13-077, SFB/CPP-13-27, LPN 13-028</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symbolic integration deals with the evaluation of integrals in closed form.
We present an overview of Risch's algorithm including recent developments. The
algorithms discussed are suited for both indefinite and definite integration.
They can also be used to compute linear relations among integrals and to find
identities for special functions given by parameter integrals. The aim of this
presentation is twofold: to introduce the reader to some basic ideas of
differential algebra in the context of integration and to raise awareness in
the physics community of computer algebra algorithms for indefinite and
definite integration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1483</identifier>
 <datestamp>2014-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1483</id><created>2013-05-07</created><updated>2014-02-06</updated><authors><author><keyname>Torres-Salinas</keyname><forenames>Daniel</forenames></author><author><keyname>Robinson-Garc&#xed;a</keyname><forenames>Nicol&#xe1;s</forenames></author><author><keyname>Cabezas-Clavijo</keyname><forenames>&#xc1;lvaro</forenames></author><author><keyname>Jim&#xe9;nez-Contreras</keyname><forenames>Evaristo</forenames></author></authors><title>Analyzing the citation characteristics of books: edited books, book
  series and types of publishers in the Book Citation Index</title><categories>cs.DL</categories><comments>Paper accepted for the ISSI 2013. v2 of this paper published in
  Scientometrics</comments><doi>10.1007/s11192-013-1168-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a first approach to analyzing the factors that determine
the citation characteristics of books. For this we use the Thomson Reuters'
Book Citation Index, a novel multidisciplinary database launched in 2010 which
offers bibliometric data of books. We analyze three possible factors which are
considered to affect the citation impact of books: the presence of editors, the
inclusion in series and the type of publisher. Also, we focus on highly cited
books to see if these factors may affect them as well. We considered as highly
cited books, those in the top 5% of the most highly cited ones of the database.
We define these three aspects and we present the results for four major
scientific areas in order to identify field-based differences (Science,
Engineering &amp; Technology, Social Sciences and Arts &amp; Humanities). Finally we
conclude observing that differences were noted for edited books and types of
publishers. Although books included in series showed higher impact in two
areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1488</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1488</id><created>2013-05-07</created><authors><author><keyname>Cabezas-Clavijo</keyname><forenames>&#xc1;lvaro</forenames></author><author><keyname>Robinson-Garc&#xed;a</keyname><forenames>Nicol&#xe1;s</forenames></author><author><keyname>Torres-Salinas</keyname><forenames>Daniel</forenames></author><author><keyname>Jim&#xe9;nez-Contreras</keyname><forenames>Evaristo</forenames></author><author><keyname>Mikulka</keyname><forenames>Thomas</forenames></author><author><keyname>Gumpenberger</keyname><forenames>Christian</forenames></author><author><keyname>Wemisch</keyname><forenames>Ambros</forenames></author><author><keyname>Gorraiz</keyname><forenames>Juan</forenames></author></authors><title>Most borrowed is most cited? Library loan statistics as a proxy for
  monograph selection in citation indexes</title><categories>cs.DL</categories><comments>Paper accepted in ISSI 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study aims to analyse whether library loans statistics can be used as a
measure of monograph use and as a selection criteria for inclusion in citation
indexes. For this, we conducted an exploratory study based on loan data (1000
most borrowed monographs) from two non-Anglo-Saxon European university
libraries (Granada and Vienna) with strong social sciences and humanities
components. Loans to scientists only were also analysed at the University of
Vienna. Furthermore, citation counts for the 100 most borrowed scientific
monographs (SM) and textbooks or manuals (MTB) were retrieved from Web of
Science and Google Scholar. The results show considerable similarities in both
libraries: the percentage of loans for books in national languages represents
almost 96 per cent of the total share and SM accounts only for 10 to 13 per
cent. When considering loans to scientists only, the percentage of English
books increases to 30 per cent, the percentage of SM loans also increases
(approx 80 per cent). Furthermore, we found no significant correlations between
loans and citations. Since loan statistics are currently insufficient for
measuring the use of monographs, their suggested use as an applicable selection
criterion for book citation indexes is not yet feasible. Data improvement and
aggregation at different levels is a challenge for modern libraries in order to
enable the exploitation of this invaluable information source for scientometric
purposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1490</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1490</id><created>2013-05-07</created><authors><author><keyname>de Kerret</keyname><forenames>Paul</forenames></author><author><keyname>Guillaud</keyname><forenames>Maxime</forenames></author><author><keyname>Gesbert</keyname><forenames>David</forenames></author></authors><title>Degrees of Freedom of Certain Interference Alignment Schemes with
  Distributed CSIT</title><categories>cs.IT math.IT</categories><comments>This is an extended version of a conference submission which will be
  presented at the IEEE conference SPAWC, Darmstadt, June 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we consider the use of interference alignment (IA) in a MIMO
interference channel (IC) under the assumption that each transmitter (TX) has
access to channel state information (CSI) that generally differs from that
available to other TXs. This setting is referred to as distributed CSIT. In a
setting where CSI accuracy is controlled by a set of power exponents, we show
that in the static 3-user MIMO square IC, the number of degrees-of-freedom
(DoF) that can be achieved with distributed CSIT is at least equal to the DoF
achieved with the worst accuracy taken across the TXs and across the
interfering links. We conjecture further that this represents exactly the DoF
achieved. This result is in strong contrast with the centralized CSIT
configuration usually studied (where all the TXs share the same, possibly
imperfect, channel estimate) for which it was shown that the DoF achieved at
receiver (RX) i is solely limited by the quality of its own feedback. This
shows the critical impact of CSI discrepancies between the TXs, and highlights
the price paid by distributed precoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1495</identifier>
 <datestamp>2015-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1495</id><created>2013-05-07</created><updated>2015-04-17</updated><authors><author><keyname>Attanasi</keyname><forenames>Alessandro</forenames></author><author><keyname>Cavagna</keyname><forenames>Andrea</forenames></author><author><keyname>Del Castello</keyname><forenames>Lorenzo</forenames></author><author><keyname>Giardina</keyname><forenames>Irene</forenames></author><author><keyname>Jelic</keyname><forenames>Asja</forenames></author><author><keyname>Melillo</keyname><forenames>Stefania</forenames></author><author><keyname>Parisi</keyname><forenames>Leonardo</forenames></author><author><keyname>Pellacini</keyname><forenames>Fabio</forenames></author><author><keyname>Shen</keyname><forenames>Edward</forenames></author><author><keyname>Silvestri</keyname><forenames>Edmondo</forenames></author><author><keyname>Viale</keyname><forenames>Massimiliano</forenames></author></authors><title>GReTA - a novel Global and Recursive Tracking Algorithm in three
  dimensions</title><categories>q-bio.QM cs.CV</categories><comments>13 pages, 6 figures, 3 tables. Version 3 was slightly shortened, and
  new comprative results on the public datasets (thermal infrared videos of
  flying bats) by Z. Wu and coworkers (2014) were included. in A. Attanasi et
  al., &quot;GReTA - A Novel Global and Recursive Tracking Algorithm in Three
  Dimensions&quot;, IEEE Trans. Pattern Anal. Mach. Intell., vol.37 (2015)</comments><doi>10.1109/TPAMI.2015.2414427</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tracking multiple moving targets allows quantitative measure of the dynamic
behavior in systems as diverse as animal groups in biology, turbulence in fluid
dynamics and crowd and traffic control. In three dimensions, tracking several
targets becomes increasingly hard since optical occlusions are very likely,
i.e. two featureless targets frequently overlap for several frames. Occlusions
are particularly frequent in biological groups such as bird flocks, fish
schools, and insect swarms, a fact that has severely limited collective animal
behavior field studies in the past. This paper presents a 3D tracking method
that is robust in the case of severe occlusions. To ensure robustness, we adopt
a global optimization approach that works on all objects and frames at once. To
achieve practicality and scalability, we employ a divide and conquer
formulation, thanks to which the computational complexity of the problem is
reduced by orders of magnitude. We tested our algorithm with synthetic data,
with experimental data of bird flocks and insect swarms and with public
benchmark datasets, and show that our system yields high quality trajectories
for hundreds of moving targets with severe overlap. The results obtained on
very heterogeneous data show the potential applicability of our method to the
most diverse experimental situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1502</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1502</id><created>2013-05-07</created><updated>2013-09-01</updated><authors><author><keyname>Shuai</keyname><forenames>Hong-Han</forenames></author><author><keyname>Yang</keyname><forenames>De-Nian</forenames></author><author><keyname>Yu</keyname><forenames>Philip S.</forenames></author><author><keyname>Chen</keyname><forenames>Ming-Syan</forenames></author></authors><title>Willingness Optimization for Social Group Activity</title><categories>cs.SI physics.soc-ph</categories><comments>The extended version with 16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Studies show that a person is willing to join a social group activity if the
activity is interesting, and if some close friends also join the activity as
companions. The literature has demonstrated that the interests of a person and
the social tightness among friends can be effectively derived and mined from
social networking websites. However, even with the above two kinds of
information widely available, social group activities still need to be
coordinated manually, and the process is tedious and time-consuming for users,
especially for a large social group activity, due to complications of social
connectivity and the diversity of possible interests among friends. To address
the above important need, this paper proposes to automatically select and
recommend potential attendees of a social group activity, which could be very
useful for social networking websites as a value-added service. We first
formulate a new problem, named Willingness mAximization for Social grOup
(WASO). This paper points out that the solution obtained by a greedy algorithm
is likely to be trapped in a local optimal solution. Thus, we design a new
randomized algorithm to effectively and efficiently solve the problem. Given
the available computational budgets, the proposed algorithm is able to
optimally allocate the resources and find a solution with an approximation
ratio. We implement the proposed algorithm in Facebook, and the user study
demonstrates that social groups obtained by the proposed algorithm
significantly outperform the solutions manually configured by users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1520</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1520</id><created>2013-05-07</created><authors><author><keyname>Renau-Ferrer</keyname><forenames>Ney</forenames><affiliation>LAMIA</affiliation></author><author><keyname>Remi</keyname><forenames>C&#xe9;line</forenames><affiliation>LAMIA</affiliation></author></authors><title>A Method for Visuo-Spatial Classification of Freehand Shapes Freely
  Sketched</title><categories>cs.CV</categories><comments>IPCV'10 - 14th International Conference on Image Processing, Computer
  Vision, \&amp; Pattern Recognition, \'Etats-Unis (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the principle and the main steps of a new method for the
visuo-spatial analysis of geometrical sketches recorded online. Visuo-spatial
analysis is a necessary step for multi-level analysis. Multi-level analysis
simultaneously allows classification, comparison or clustering of the
constituent parts of a pattern according to their visuo-spatial properties,
their procedural strategies, their structural or temporal parameters, or any
combination of two or more of those parameters. The first results provided by
this method concern the comparison of sketches to some perfect patterns of
simple geometrical figures and the measure of dissimilarity between real
sketches. The mean rates of good decision higher than 95% obtained are
promising in both cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1525</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1525</id><created>2013-05-07</created><authors><author><keyname>Mohammed</keyname><forenames>Saif Khan</forenames></author><author><keyname>Larsson</keyname><forenames>Erik G.</forenames></author></authors><title>Constant-Envelope Multi-User Precoding for Frequency-Selective Massive
  MIMO Systems</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Wireless Communications Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider downlink precoding in a frequency-selective multi-user Massive
MIMO system with highly efficient but non-linear power amplifiers at the base
station (BS). A low-complexity precoding algorithm is proposed, which generates
constant-envelope (CE) signals at each BS antenna. To achieve a desired
per-user information rate, the extra total transmit power required under the
per-antenna CE constraint when compared to the commonly used less stringent
total average transmit power constraint, is small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1535</identifier>
 <datestamp>2013-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1535</id><created>2013-05-07</created><updated>2013-10-26</updated><authors><author><keyname>Rumyantsev</keyname><forenames>Andrei</forenames></author><author><keyname>Shen</keyname><forenames>Alexander</forenames></author></authors><title>Probabilistic Constructions of Computable Objects and a Computable
  Version of Lov\'asz Local Lemma</title><categories>cs.DM cs.DS</categories><comments>10 pages. arXiv admin note: substantial text overlap with
  arXiv:1012.0557</comments><msc-class>68Q87</msc-class><acm-class>G.2.1; F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A nonconstructive proof can be used to prove the existence of an object with
some properties without providing an explicit example of such an object. A
special case is a probabilistic proof where we show that an object with
required properties appears with some positive probability in some random
process. Can we use such arguments to prove the existence of a computable
infinite object? Sometimes yes: following [8], we show how the notion of a
layerwise computable mapping can be used to prove a computable version of
Lov\'asz local lemma. (A survey of Moser-Tardos proof is included to make the
paper self-contained.)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1537</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1537</id><created>2013-05-07</created><authors><author><keyname>Sorokina</keyname><forenames>M. A.</forenames></author><author><keyname>Turitsyn</keyname><forenames>S. K.</forenames></author></authors><title>Shannon capacity of nonlinear regenerative channels</title><categories>cs.IT math.IT physics.optics</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We compute Shannon capacity of nonlinear channels with regenerative elements.
Conditions are found under which capacity of such nonlinear channels is higher
than the Shannon capacity of the classical linear additive white Gaussian noise
channel. We develop a general scheme for designing the proposed channels and
apply it to the particular nonlinear sine-mapping. The upper bound for
regeneration efficiency is found and the asymptotic behavior of the capacity in
the saturation regime is derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1578</identifier>
 <datestamp>2015-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1578</id><created>2013-05-07</created><updated>2014-12-01</updated><authors><author><keyname>Mautner</keyname><forenames>Julian</forenames></author><author><keyname>Makmal</keyname><forenames>Adi</forenames></author><author><keyname>Manzano</keyname><forenames>Daniel</forenames></author><author><keyname>Tiersch</keyname><forenames>Markus</forenames></author><author><keyname>Briegel</keyname><forenames>Hans J.</forenames></author></authors><title>Projective simulation for classical learning agents: a comprehensive
  investigation</title><categories>nlin.AO cs.AI</categories><comments>Accepted for publication in New Generation Computing. 23 pages, 23
  figures</comments><journal-ref>New Generation Computing 33(1), 69-114 (2015)</journal-ref><doi>10.1007/s00354-015-0102-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the model of projective simulation (PS), a novel approach to
artificial intelligence based on stochastic processing of episodic memory which
was recently introduced [H.J. Briegel and G. De las Cuevas. Sci. Rep. 2, 400,
(2012)]. Here we provide a detailed analysis of the model and examine its
performance, including its achievable efficiency, its learning times and the
way both properties scale with the problems' dimension. In addition, we situate
the PS agent in different learning scenarios, and study its learning abilities.
A variety of new scenarios are being considered, thereby demonstrating the
model's flexibility. Furthermore, to put the PS scheme in context, we compare
its performance with those of Q-learning and learning classifier systems, two
popular models in the field of reinforcement learning. It is shown that PS is a
competitive artificial intelligence model of unique properties and strengths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1596</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1596</id><created>2013-05-03</created><authors><author><keyname>Andrioni</keyname><forenames>Alessandro</forenames></author></authors><title>A Clifford Algebra approach to the Discretizable Molecular Distance
  Geometry Problem</title><categories>cs.CG</categories><comments>extended abstract with four pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Discretizable Molecular Distance Geometry Problem (DMDGP) consists in a
subclass of the Molecular Distance Geometry Problem for which an embedding in
${\mathbb{R}^3}$ can be found using a Branch &amp; Prune (BP) algorithm in a
discrete search space. We propose a Clifford Algebra model of the DMDGP with an
accompanying version of the BP algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1598</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1598</id><created>2013-05-07</created><authors><author><keyname>Sahebi</keyname><forenames>Aria G.</forenames></author><author><keyname>Pradhan</keyname><forenames>S. Sandeep</forenames></author></authors><title>Abelian Group Codes for Source Coding and Channel Coding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the asymptotic performance of Abelian group codes for
the lossy source coding problem for arbitrary discrete (finite alphabet)
memoryless sources as well as the channel coding problem for arbitrary discrete
(finite alphabet) memoryless channels. For the source coding problem, we derive
an achievable rate-distortion function that is characterized in a single-letter
information-theoretic form using the ensemble of Abelian group codes. When the
underlying group is a field, it simplifies to the symmetric rate-distortion
function. Similarly, for the channel coding problem, we find an achievable rate
characterized in a single-letter information-theoretic form using group codes.
This simplifies to the symmetric capacity of the channel when the underlying
group is a field. We compute the rate-distortion function and the achievable
rate for several examples of sources and channels. Due to the non-symmetric
nature of the sources and channels considered, our analysis uses a synergy of
information theoretic and group-theoretic tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1609</identifier>
 <datestamp>2013-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1609</id><created>2013-05-07</created><authors><author><keyname>Cheng</keyname><forenames>Yu</forenames></author><author><keyname>Rusu</keyname><forenames>Florin</forenames></author></authors><title>Formal Representation of the SS-DB Benchmark and Experimental Evaluation
  in EXTASCID</title><categories>cs.DB</categories><comments>32 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Evaluating the performance of scientific data processing systems is a
difficult task considering the plethora of application-specific solutions
available in this landscape and the lack of a generally-accepted benchmark. The
dual structure of scientific data coupled with the complex nature of processing
complicate the evaluation procedure further. SS-DB is the first attempt to
define a general benchmark for complex scientific processing over raw and
derived data. It fails to draw sufficient attention though because of the
ambiguous plain language specification and the extraordinary SciDB results. In
this paper, we remedy the shortcomings of the original SS-DB specification by
providing a formal representation in terms of ArrayQL algebra operators and
ArrayQL/SciQL constructs. These are the first formal representations of the
SS-DB benchmark. Starting from the formal representation, we give a reference
implementation and present benchmark results in EXTASCID, a novel system for
scientific data processing. EXTASCID is complete in providing native support
both for array and relational data and extensible in executing any user code
inside the system by the means of a configurable metaoperator. These features
result in an order of magnitude improvement over SciDB at data loading,
extracting derived data, and operations over derived data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1621</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1621</id><created>2013-05-07</created><authors><author><keyname>Namiot</keyname><forenames>Dmitry</forenames></author></authors><title>Location sharing without the central server</title><categories>cs.NI</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a new model for sharing location info for mobile users.
This approach can operate without the need for disclosing identity info to
third party servers. It could be described as a safe location sharing model.
The proposed approach creates a special form of distributed database that
splits location info and identity information. In this distributed data store
identity info is always saved locally. It eliminates one of the main concerns
with location-based systems - privacy. This paper describes a model itself as
well as its implementation in the form of HTML5 mobile web application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1655</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1655</id><created>2013-05-07</created><authors><author><keyname>Hernandez-Orallo</keyname><forenames>Jose</forenames></author></authors><title>A short note on estimating intelligence from user profiles in the
  context of universal psychometrics: prospects and caveats</title><categories>cs.AI</categories><comments>Keywords: intelligence; user profiles; cognitive abilities; social
  networks; universal psychometrics; games; virtual worlds</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been an increasing interest in inferring some personality traits
from users and players in social networks and games, respectively. This goes
beyond classical sentiment analysis, and also much further than customer
profiling. The purpose here is to have a characterisation of users in terms of
personality traits, such as openness, conscientiousness, extraversion,
agreeableness, and neuroticism. While this is an incipient area of research, we
ask the question of whether cognitive abilities, and intelligence in
particular, are also measurable from user profiles. However, we pose the
question as broadly as possible in terms of subjects, in the context of
universal psychometrics, including humans, machines and hybrids. Namely, in
this paper we analyse the following question: is it possible to measure the
intelligence of humans and (non-human) bots in a social network or a game just
from their user profiles, i.e., by observation, without the use of interactive
tests, such as IQ tests, the Turing test or other more principled machine
intelligence tests?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1657</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1657</id><created>2013-05-07</created><authors><author><keyname>Savioli</keyname><forenames>Alberto</forenames></author><author><keyname>Goldoni</keyname><forenames>Emanuele</forenames></author><author><keyname>Savazzi</keyname><forenames>Pietro</forenames></author><author><keyname>Gamba</keyname><forenames>Paolo</forenames></author></authors><title>Low Complexity Indoor Localization in Wireless Sensor Networks by UWB
  and Inertial Data Fusion</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Precise indoor localization of moving targets is a challenging activity which
cannot be easily accomplished without combining different sources of
information. In this sense, the combination of different data sources with an
appropriate filter might improve both positioning and tracking performance.
This work proposes an algorithm for hybrid positioning in Wireless Sensor
Networks based on data fusion of UWB and inertial information. A constant-gain
Steady State Kalman Filter is used to bound the complexity of the system,
simplifying its implementation on a typical low-power WSN node. The performance
of the presented data fusion algorithm has been evaluated in a realistic
scenario using both simulations and realistic datasets. The obtained results
prove the validity of this approach, which efficiently fuses different
positioning data sources, reducing the localization error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1666</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1666</id><created>2013-05-07</created><authors><author><keyname>Boudaa</keyname><forenames>Boudjemaa</forenames></author></authors><title>Vers une Substitution des Services Web sans Inconsistance S\'emantique</title><categories>cs.SE</categories><comments>12 pages, in French</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to ensure high availability of Web services, recently, a new
approach was proposed based on the use of communities. In composition, this
approach consists in replacing the failed Web service by another web service
joining a community offering the same functionality of the service failed.
However, this substitution may cause inconsistency in the semantic composition
and alter its mediation initially taken to resolve the semantic heterogeneities
between Web services. This paper presents a context oriented solution to this
problem by forcing the community to adopt the semantic of the failed web
service before the substitution in which all inputs and outputs to/from the
latter must be converted according to this adopted semantic, avoiding any
alteration of a semantic mediation in web service composition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1679</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1679</id><created>2013-05-07</created><authors><author><keyname>Silva</keyname><forenames>Thiago Christiano</forenames></author><author><keyname>Zhao</keyname><forenames>Liang</forenames></author></authors><title>High Level Pattern Classification via Tourist Walks in Networks</title><categories>cs.AI cs.LG</categories><comments>Submitted to the IEEE Transactions on Neural Networks and Learning
  Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex networks refer to large-scale graphs with nontrivial connection
patterns. The salient and interesting features that the complex network study
offer in comparison to graph theory are the emphasis on the dynamical
properties of the networks and the ability of inherently uncovering pattern
formation of the vertices. In this paper, we present a hybrid data
classification technique combining a low level and a high level classifier. The
low level term can be equipped with any traditional classification techniques,
which realize the classification task considering only physical features (e.g.,
geometrical or statistical features) of the input data. On the other hand, the
high level term has the ability of detecting data patterns with semantic
meanings. In this way, the classification is realized by means of the
extraction of the underlying network's features constructed from the input
data. As a result, the high level classification process measures the
compliance of the test instances with the pattern formation of the training
data. Out of various high level perspectives that can be utilized to capture
semantic meaning, we utilize the dynamical features that are generated from a
tourist walker in a networked environment. Specifically, a weighted combination
of transient and cycle lengths generated by the tourist walk is employed for
that end. Interestingly, our study shows that the proposed technique is able to
further improve the already optimized performance of traditional classification
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1681</identifier>
 <datestamp>2013-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1681</id><created>2013-05-07</created><updated>2013-11-11</updated><authors><author><keyname>Makarychev</keyname><forenames>Konstantin</forenames></author><author><keyname>Makarychev</keyname><forenames>Yury</forenames></author><author><keyname>Vijayaraghavan</keyname><forenames>Aravindan</forenames></author></authors><title>Bilu-Linial Stable Instances of Max Cut and Minimum Multiway Cut</title><categories>cs.DS</categories><comments>24 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the notion of stability proposed by Bilu and Linial. We obtain
an exact polynomial-time algorithm for $\gamma$-stable Max Cut instances with
$\gamma \geq c\sqrt{\log n}\log\log n$ for some absolute constant $c &gt; 0$. Our
algorithm is robust: it never returns an incorrect answer; if the instance is
$\gamma$-stable, it finds the maximum cut, otherwise, it either finds the
maximum cut or certifies that the instance is not $\gamma$-stable. We prove
that there is no robust polynomial-time algorithm for $\gamma$-stable instances
of Max Cut when $\gamma &lt; \alpha_{SC}(n/2)$, where $\alpha_{SC}$ is the best
approximation factor for Sparsest Cut with non-uniform demands.
  Our algorithm is based on semidefinite programming. We show that the standard
SDP relaxation for Max Cut (with $\ell_2^2$ triangle inequalities) is integral
if $\gamma \geq D_{\ell_2^2\to \ell_1}(n)$, where $D_{\ell_2^2\to \ell_1}(n)$
is the least distortion with which every $n$ point metric space of negative
type embeds into $\ell_1$. On the negative side, we show that the SDP
relaxation is not integral when $\gamma &lt; D_{\ell_2^2\to \ell_1}(n/2)$.
Moreover, there is no tractable convex relaxation for $\gamma$-stable instances
of Max Cut when $\gamma &lt; \alpha_{SC}(n/2)$. That suggests that solving
$\gamma$-stable instances with $\gamma =o(\sqrt{\log n})$ might be difficult or
impossible.
  Our results significantly improve previously known results. The best
previously known algorithm for $\gamma$-stable instances of Max Cut required
that $\gamma \geq c\sqrt{n}$ (for some $c &gt; 0$) [Bilu, Daniely, Linial, and
Saks]. No hardness results were known for the problem. Additionally, we present
an algorithm for 4-stable instances of Minimum Multiway Cut. We also study a
relaxed notion of weak stability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1690</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1690</id><created>2013-05-07</created><authors><author><keyname>Downing</keyname><forenames>Nicholas</forenames></author><author><keyname>Feydy</keyname><forenames>Thibaut</forenames></author><author><keyname>Stuckey</keyname><forenames>Peter J.</forenames></author></authors><title>Unsatisfiable Cores for Constraint Programming</title><categories>cs.LO cs.AI</categories><comments>Submitted to CP2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constraint Programming (CP) solvers typically tackle optimization problems by
repeatedly finding solutions to a problem while placing tighter and tighter
bounds on the solution cost. This approach is somewhat naive, especially for
soft-constraint optimization problems in which the soft constraints are mostly
satisfied. Unsatisfiable-core approaches to solving soft constraint problems in
Boolean Satisfiability (e.g. MAXSAT) force all soft constraints to hold
initially. When solving fails they return an unsatisfiable core, as a set of
soft constraints that cannot hold simultaneously. Using this information the
problem is relaxed to allow certain soft constraint(s) to be violated and
solving continues. Since Lazy Clause Generation (LCG) solvers can also return
unsatisfiable cores we can adapt the MAXSAT unsatisfiable core approach to CP.
We implement the original MAXSAT unsatisfiable core solving algorithms WPM1,
MSU3 in a state-of-the-art LCG solver and show that there exist problems which
benefit from this hybrid approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1694</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1694</id><created>2013-05-07</created><authors><author><keyname>Wang</keyname><forenames>Yajun</forenames></author><author><keyname>Wong</keyname><forenames>Sam Chiu-wai</forenames></author></authors><title>Online Vertex Cover and Matching: Beating the Greedy Algorithm</title><categories>cs.DS</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we explicitly study the online vertex cover problem, which is
a natural generalization of the well-studied ski-rental problem. In the online
vertex cover problem, we are required to maintain a monotone vertex cover in a
graph whose vertices arrive online. When a vertex arrives, all its incident
edges to previously arrived vertices are revealed to the algorithm. For
bipartite graphs with the left vertices offline (i.e. all of the left vertices
arrive first before any right vertex), there are algorithms achieving the
optimal competitive ratio of $\frac{1}{1-1/e}\approx 1.582$.
  Our first result is a new optimal water-filling algorithm for this case. One
major ingredient of our result is a new charging-based analysis, which can be
generalized to attack the online fractional vertex cover problem in general
graphs. The main contribution of this paper is a 1.901-competitive algorithm
for this problem. When the underlying graph is bipartite, our fractional
solution can be rounded to an integral solution. In other words, we can obtain
a vertex cover with expected size at most 1.901 of the optimal vertex cover in
bipartite graphs.
  The next major result is a primal-dual analysis of our algorithm for the
online fractional vertex cover problem in general graphs, which implies the
dual result of a 0.526-competitive algorithm for online fractional matching in
general graphs. Notice that both problems admit a well-known 2-competitive
greedy algorithm. Our result in this paper is the first successful attempt to
beat the greedy algorithm for these two problems.
  On the hardness side, we show that no randomized online algorithm can achieve
a competitive ratio better than 1.753 and 0.625 for the online fractional
vertex cover problem and the online fractional matching problem respectively,
even for bipartite graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1704</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1704</id><created>2013-05-07</created><authors><author><keyname>Erol</keyname><forenames>Yusuf</forenames></author><author><keyname>Li</keyname><forenames>Lei</forenames></author><author><keyname>Ramsundar</keyname><forenames>Bharath</forenames></author><author><keyname>Russell</keyname><forenames>Stuart J.</forenames></author></authors><title>The Extended Parameter Filter</title><categories>stat.ML cs.AI</categories><report-no>UCB/EECS-2013-48</report-no><journal-ref>ICML 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The parameters of temporal models, such as dynamic Bayesian networks, may be
modelled in a Bayesian context as static or atemporal variables that influence
transition probabilities at every time step. Particle filters fail for models
that include such variables, while methods that use Gibbs sampling of parameter
variables may incur a per-sample cost that grows linearly with the length of
the observation sequence. Storvik devised a method for incremental computation
of exact sufficient statistics that, for some cases, reduces the per-sample
cost to a constant. In this paper, we demonstrate a connection between
Storvik's filter and a Kalman filter in parameter space and establish more
general conditions under which Storvik's filter works. Drawing on an analogy to
the extended Kalman filter, we develop and analyze, both theoretically and
experimentally, a Taylor approximation to the parameter posterior that allows
Storvik's method to be applied to a broader class of models. Our experiments on
both synthetic examples and real applications show improvement over existing
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1707</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1707</id><created>2013-05-07</created><authors><author><keyname>Longadge</keyname><forenames>Rushi</forenames></author><author><keyname>Dongre</keyname><forenames>Snehalata</forenames></author></authors><title>Class Imbalance Problem in Data Mining Review</title><categories>cs.LG</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In last few years there are major changes and evolution has been done on
classification of data. As the application area of technology is increases the
size of data also increases. Classification of data becomes difficult because
of unbounded size and imbalance nature of data. Class imbalance problem become
greatest issue in data mining. Imbalance problem occur where one of the two
classes having more sample than other classes. The most of algorithm are more
focusing on classification of major sample while ignoring or misclassifying
minority sample. The minority samples are those that rarely occur but very
important. There are different methods available for classification of
imbalance data set which is divided into three main categories, the algorithmic
approach, data-preprocessing approach and feature selection approach. Each of
this technique has their own advantages and disadvantages. In this paper
systematic study of each approach is define which gives the right direction for
research in class imbalance problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1713</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1713</id><created>2013-05-08</created><authors><author><keyname>Bhardwaj</keyname><forenames>Meenesh</forenames></author></authors><title>Optimization of stochastic database cracking</title><categories>cs.DB</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Variant Stochastic cracking is a significantly more resilient approach to
adaptive indexing. It showed [1]that Stochastic cracking uses each query as a
hint on how to reorganize data, but not blindly so; it gains resilience and
avoids performance bottlenecks by deliberately applying certain arbitrary
choices in its decision making. Therefore bring, adaptive indexing forward to a
mature formulation that confers the workload-robustness that previous
approaches lacked. Original cracking relies on the randomness of the workloads
to converge well. [2][3] However, where the workload is non-random, cracking
needs to introduce randomness on its own. Stochastic Cracking clearly improves
over original cracking by being robust in workload changes while maintaining
all original cracking features when it comes to adaptation. But looking at both
types of cracking, it conveyed an incomplete picture as at some point of time
it is must to know whether the workload is random or sequential. In this paper
our focus is on optimization of variant stochastic cracking, that could be
achieved in two ways either by reducing the initialization cost to make
stochastic cracking even more transparent to the user, especially for queries
that initiate a workload change and hence incur a higher cost or by combining
the strengths of the various stochastic cracking algorithms via a dynamic
component that decides which algorithm to choose for a query on the fly. The
efforts have been put in to make an algorithm that reduces the initialization
cost by using the main notion of both cracking, while considering the
requirements of adaptive indexing [2].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1727</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1727</id><created>2013-05-08</created><authors><author><keyname>Su</keyname><forenames>Ziyi</forenames></author><author><keyname>Biennier</keyname><forenames>Frederique</forenames></author></authors><title>On attribute-based usage control policy ratification for cooperative
  computing context</title><categories>cs.CR</categories><comments>30 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an open information systems paradigm, real-time context-awareness is vital
for the success of cooperation, therefore dynamic security attributes of
partners should considered in coalition for avoiding security conflicts.
Furthermore, the cross-boundary asset sharing activities and risks associated
to loss of governance call for a continuous regulation of partners' behavior,
paying attention to the resource sharing and consuming activities. This paper
describes an attribute-based usage control policy shceme compline to this
needs. A concise syntax with EBNF is used to summarize the base policy model.
The semantics of negotiation process is disambiguated with abductive constraint
logic programming (ACLP) and Event Calculus (EC). Then we propose a policy
ratification method based on a policy aggregation algebra that elaborate the
request space and policy rule relation. This method ensures that, when policies
are aggregated due to resource sharing and merging activities, the resulting
policy correctly interprets the original security goals of the providers'
policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1729</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1729</id><created>2013-05-08</created><updated>2013-05-13</updated><authors><author><keyname>Xu</keyname><forenames>Duo</forenames></author></authors><title>A Simple Technique for the Converse of Finite Blocklength Multiple
  Access Channels</title><categories>cs.IT math.IT</categories><comments>Results are refined</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A converse for the Discrete Memoryless Multiple Access Channel is given. The
result in [13] is refined, and the third order term is obtained. Moreover, our
proof is much simpler than [13]. With little modification, the region can be
further improved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1730</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1730</id><created>2013-05-08</created><authors><author><keyname>Xu</keyname><forenames>Duo</forenames></author></authors><title>The Redundancy of Slepian-Wolf Coding Revisited</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  [Draft] In this paper, the redundancy of Slepian Wolf coding is revisited.
Applying the random binning and converse technique in \cite{yang}, the same
results in \cite{he} are obtained with much simpler proofs. Moreover, our
results reflect more details about the high-order terms of the coding rate. The
redundancy is investigated for both fixed-rate and variable-rate cases. The
normal approximation (or dispersion) can also be obtained with minor
modification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1734</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1734</id><created>2013-05-08</created><authors><author><keyname>Thamm</keyname><forenames>Mark</forenames></author><author><keyname>Bleier</keyname><forenames>Arnim</forenames></author></authors><title>When Politicians Tweet: A Study on the Members of the German Federal
  Diet</title><categories>cs.SI physics.soc-ph</categories><comments>6 pages, ACM Web Science 2013</comments><acm-class>H.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this preliminary study we compare the characteristics of retweets and
replies on more than 350,000 messages collected by following members of the
German Federal Diet on Twitter. We find significant differences in the
characteristics pointing to distinct types of usages for retweets and replies.
Using time series and regression analysis we observe that the likelihood of a
politician using replies increases with typical leisure times while retweets
occur constant over time. Including formal references increases the probability
of a message being retweeted but drops its chance of being replied. This hints
to a more professional use for retweets while replies tend to have a personal
connotation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1737</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1737</id><created>2013-05-08</created><authors><author><keyname>Ziatdinov</keyname><forenames>Rushan</forenames></author><author><keyname>Nabiyev</keyname><forenames>Rifkat I.</forenames></author><author><keyname>Miura</keyname><forenames>Kenjiro T.</forenames></author></authors><title>MC-curves and aesthetic measurements for pseudospiral curve segments</title><categories>cs.GR</categories><journal-ref>Mathematical Design &amp; Technical Aesthetics 1(1), 6-17, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article studies families of curves with monotonic curvature function
(MC-curves) and their applications in geometric modelling and aesthetic design.
Aesthetic analysis and assessment of the structure and plastic qualities of
pseudospirals, which are curves with monotonic curvature function, are
conducted for the first time in the field of geometric modelling from the
position of technical aesthetics laws. The example of car body surface
modelling with the use of aesthetics splines is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1744</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1744</id><created>2013-05-08</created><authors><author><keyname>Na</keyname><forenames>Joong Chae</forenames></author><author><keyname>Park</keyname><forenames>Heejin</forenames></author><author><keyname>Crochemore</keyname><forenames>Maxime</forenames></author><author><keyname>Holub</keyname><forenames>Jan</forenames></author><author><keyname>Iliopoulos</keyname><forenames>Costas S.</forenames></author><author><keyname>Mouchard</keyname><forenames>Laurent</forenames></author><author><keyname>Park</keyname><forenames>Kunsoo</forenames></author></authors><title>Suffix Tree of Alignment: An Efficient Index for Similar Data</title><categories>cs.DS</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an index data structure for similar strings. The generalized
suffix tree can be a solution for this. The generalized suffix tree of two
strings $A$ and $B$ is a compacted trie representing all suffixes in $A$ and
$B$. It has $|A|+|B|$ leaves and can be constructed in $O(|A|+|B|)$ time.
However, if the two strings are similar, the generalized suffix tree is not
efficient because it does not exploit the similarity which is usually
represented as an alignment of $A$ and $B$.
  In this paper we propose a space/time-efficient suffix tree of alignment
which wisely exploits the similarity in an alignment. Our suffix tree for an
alignment of $A$ and $B$ has $|A| + l_d + l_1$ leaves where $l_d$ is the sum of
the lengths of all parts of $B$ different from $A$ and $l_1$ is the sum of the
lengths of some common parts of $A$ and $B$. We did not compromise the pattern
search to reduce the space. Our suffix tree can be searched for a pattern $P$
in $O(|P|+occ)$ time where $occ$ is the number of occurrences of $P$ in $A$ and
$B$. We also present an efficient algorithm to construct the suffix tree of
alignment. When the suffix tree is constructed from scratch, the algorithm
requires $O(|A| + l_d + l_1 + l_2)$ time where $l_2$ is the sum of the lengths
of other common substrings of $A$ and $B$. When the suffix tree of $A$ is
already given, it requires $O(l_d + l_1 + l_2)$ time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1745</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1745</id><created>2013-05-08</created><authors><author><keyname>Bouneffouf</keyname><forenames>Djallel</forenames></author></authors><title>Mobile Recommender Systems Methods: An Overview</title><categories>cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The information that mobiles can access becomes very wide nowadays, and the
user is faced with a dilemma: there is an unlimited pool of information
available to him but he is unable to find the exact information he is looking
for. This is why the current research aims to design Recommender Systems (RS)
able to continually send information that matches the user's interests in order
to reduce his navigation time. In this paper, we treat the different approaches
to recommend.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1746</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1746</id><created>2013-05-08</created><updated>2013-05-14</updated><authors><author><keyname>Scherer</keyname><forenames>Carsten W.</forenames></author></authors><title>Structured $H_\infty$-Optimal Control for Nested Interconnections: A
  State-Space Solution</title><categories>math.OC cs.SY</categories><comments>17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  If imposing general structural constraints on controllers, it is unknown how
to design $H_\infty$-controllers by convex optimization. Under a so-called
quadratic invariance structure of the generalized plant, the Youla
parametrization allows to translate the structured synthesis problem into an
infinite-dimensional convex program. Nested interconnections that are
characterized by a standard plant with a block-triangular structure fall into
this class. Recently it has been shown how to design optimal $H_2$-controllers
for such nested structures in the state-space by solving algebraic Riccati
equations. In the present paper we provide a state-space solution of the
corresponding output-feedback $H_\infty$ synthesis problem without any
counterpart in the literature. We argue that a solution based on Riccati
equations is - even for state-feedback problems - not feasible and we
illustrate our results by means of a simple numerical example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1762</identifier>
 <datestamp>2013-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1762</id><created>2013-05-08</created><updated>2013-10-18</updated><authors><author><keyname>Dar</keyname><forenames>Ronen</forenames></author><author><keyname>Shtaif</keyname><forenames>Mark</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author></authors><title>New Bounds on the Capacity of Fiber-Optics Communications</title><categories>physics.optics cs.IT math.IT</categories><comments>5 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By taking advantage of the temporal correlations of the nonlinear phase noise
in WDM systems we show that the capacity of a nonlinear fiber link is notably
higher than what is currently assumed. This advantage is translated into the
doubling of the link distance for a fixed transmission rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1783</identifier>
 <datestamp>2014-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1783</id><created>2013-05-08</created><authors><author><keyname>Noel</keyname><forenames>Adam</forenames></author><author><keyname>Cheung</keyname><forenames>Karen C.</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author></authors><title>Improving Diffusion-Based Molecular Communication with Unanchored
  Enzymes</title><categories>cs.IT math.IT q-bio.QM</categories><comments>15 pages, 4 figures, presented at the 7th International Conference on
  Bio-Inspired Models of Network, Information, and Computing Systems (BIONETICS
  2012) in Lugano, Switzerland</comments><doi>10.1007/978-3-319-06944-9_13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose adding enzymes to the propagation environment of a
diffusive molecular communication system as a strategy for mitigating
intersymbol interference. The enzymes form reaction intermediates with
information molecules and then degrade them so that they have a smaller chance
of interfering with future transmissions. We present the reaction-diffusion
dynamics of this proposed system and derive a lower bound expression for the
expected number of molecules observed at the receiver. We justify a
particle-based simulation framework, and present simulation results that show
both the accuracy of our expression and the potential for enzymes to improve
communication performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1786</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1786</id><created>2013-05-08</created><authors><author><keyname>Jacques</keyname><forenames>Laurent</forenames></author><author><keyname>Degraux</keyname><forenames>K&#xe9;vin</forenames></author><author><keyname>De Vleeschouwer</keyname><forenames>Christophe</forenames></author></authors><title>Quantized Iterative Hard Thresholding: Bridging 1-bit and
  High-Resolution Quantized Compressed Sensing</title><categories>cs.IT math.IT</categories><comments>8 pages, 2 figures. This preprint is an extended version of a paper
  accepted in Sampta13, Bremen, Germany. In particular, it contains a proof of
  the proximity of two sparse vectors that are almost consistent under 1-bit
  compressive measurements</comments><report-no>TR-LJ-2013-02</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we show that reconstructing a sparse signal from quantized
compressive measurement can be achieved in an unified formalism whatever the
(scalar) quantization resolution, i.e., from 1-bit to high resolution
assumption. This is achieved by generalizing the iterative hard thresholding
(IHT) algorithm and its binary variant (BIHT) introduced in previous works to
enforce the consistency of the reconstructed signal with respect to the
quantization model. The performance of this algorithm, simply called quantized
IHT (QIHT), is evaluated in comparison with other approaches (e.g., IHT, basis
pursuit denoise) for several quantization scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1787</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1787</id><created>2013-05-08</created><authors><author><keyname>Bouneffouf</keyname><forenames>Djallel</forenames></author></authors><title>Evolution of the user's content: An Overview of the state of the art</title><categories>cs.IR</categories><acm-class>I.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The evolution of the user's content still remains a problem for an accurate
recommendation.This is why the current research aims to design Recommender
Systems (RS) able to continually adapt information that matches the user's
interests. This paper aims to explain this problematic point in outlining the
proposals that have been made in research with their advantages and
disadvantages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1796</identifier>
 <datestamp>2013-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1796</id><created>2013-05-08</created><authors><author><keyname>Noel</keyname><forenames>Adam</forenames></author><author><keyname>Cheung</keyname><forenames>Karen C.</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author></authors><title>Using Dimensional Analysis to Assess Scalability and Accuracy in
  Molecular Communication</title><categories>cs.IT math.IT q-bio.QM</categories><comments>6 pages, 2 figures, will be presented at the 3rd IEEE International
  Workshop on Molecular and Nanoscale Communications (MoNaCom 2013) in
  Budapest, Hungary</comments><doi>10.1109/ICCW.2013.6649346</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we apply dimensional analysis to study a diffusive molecular
communication system that uses diffusing enzymes in the propagation environment
to mitigate intersymbol interference. The enzymes bind to information molecules
and then degrade them so that they cannot interfere with the detection of
future transmissions at the receiver. We determine when it is accurate to
assume that the concentration of information molecules throughout the receiver
is constant and equal to that expected at the center of the receiver. We show
that a lower bound on the expected number of molecules observed at the receiver
can be arbitrarily scaled over the environmental parameters, and generalize how
the accuracy of the lower bound is qualitatively impacted by those parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1805</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1805</id><created>2013-05-08</created><updated>2013-05-18</updated><authors><author><keyname>Ricci-Tersenghi</keyname><forenames>Federico</forenames></author></authors><title>The solution to the challenge in &quot;Time-Reversible Random Number
  Generators&quot; by Wm. G. Hoover and Carol G. Hoover</title><categories>cs.DM cond-mat.stat-mech physics.comp-ph</categories><comments>4 pages, no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I provide the algorithm that solves the challenge proposed by Wm. G. Hoover
and Carol G. Hoover in their recent paper &quot;Time-Reversible Random Number
Generators&quot;, arXiv:1305.0961, with an explanation on how to derive it
analytically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1809</identifier>
 <datestamp>2014-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1809</id><created>2013-05-08</created><updated>2014-05-02</updated><authors><author><keyname>Tziortziotis</keyname><forenames>Nikolaos</forenames></author><author><keyname>Dimitrakakis</keyname><forenames>Christos</forenames></author><author><keyname>Blekas</keyname><forenames>Konstantinos</forenames></author></authors><title>Cover Tree Bayesian Reinforcement Learning</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an online tree-based Bayesian approach for reinforcement
learning. For inference, we employ a generalised context tree model. This
defines a distribution on multivariate Gaussian piecewise-linear models, which
can be updated in closed form. The tree structure itself is constructed using
the cover tree method, which remains efficient in high dimensional spaces. We
combine the model with Thompson sampling and approximate dynamic programming to
obtain effective exploration policies in unknown environments. The flexibility
and computational simplicity of the model render it suitable for many
reinforcement learning problems in continuous state spaces. We demonstrate this
in an experimental comparison with least squares policy iteration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1824</identifier>
 <datestamp>2015-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1824</id><created>2013-05-08</created><authors><author><keyname>Hellmuth</keyname><forenames>Marc</forenames></author><author><keyname>Noll</keyname><forenames>Manuel</forenames></author><author><keyname>Ostermeier</keyname><forenames>Lydia</forenames></author></authors><title>Strong Products of Hypergraphs: Unique Prime Factorization Theorems and
  Algorithms</title><categories>cs.DM math.CO</categories><doi>10.1016/j.dam.2014.02.017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well-known that all finite connected graphs have a unique prime factor
decomposition (PFD) with respect to the strong graph product which can be
computed in polynomial time. Essential for the PFD computation is the
construction of the so-called Cartesian skeleton of the graphs under
investigation.
  In this contribution, we show that every connected thin hypergraph H has a
unique prime factorization with respect to the normal and strong (hypergraph)
product. Both products coincide with the usual strong graph product whenever H
is a graph. We introduce the notion of the Cartesian skeleton of hypergraphs as
a natural generalization of the Cartesian skeleton of graphs and prove that it
is uniquely defined for thin hypergraphs. Moreover, we show that the Cartesian
skeleton of hypergraphs can be determined in O(|E|^2) time and that the PFD can
be computed in O(|V|^2|E|) time, for hypergraphs H = (V,E) with bounded degree
and bounded rank.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1840</identifier>
 <datestamp>2013-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1840</id><created>2013-05-08</created><authors><author><keyname>Jaradat</keyname><forenames>Ward</forenames></author><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Barker</keyname><forenames>Adam</forenames></author></authors><title>A Dataflow Language for Decentralised Orchestration of Web Service
  Workflows</title><categories>cs.DC cs.SE</categories><comments>To appear in Proceedings of the IEEE 2013 7th International Workshop
  on Scientific Workflows, in conjunction with IEEE SERVICES 2013</comments><doi>10.1109/SERVICES.2013.30</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Orchestrating centralised service-oriented workflows presents significant
scalability challenges that include: the consumption of network bandwidth,
degradation of performance, and single points of failure. This paper presents a
high-level dataflow specification language that attempts to address these
scalability challenges. This language provides simple abstractions for
orchestrating large-scale web service workflows, and separates between the
workflow logic and its execution. It is based on a data-driven model that
permits parallelism to improve the workflow performance. We provide a
decentralised architecture that allows the computation logic to be moved
&quot;closer&quot; to services involved in the workflow. This is achieved through
partitioning the workflow specification into smaller fragments that may be sent
to remote orchestration services for execution. The orchestration services rely
on proxies that exploit connectivity to services in the workflow. These proxies
perform service invocations and compositions on behalf of the orchestration
services, and carry out data collection, retrieval, and mediation tasks. The
evaluation of our architecture implementation concludes that our decentralised
approach reduces the execution time of workflows, and scales accordingly with
the increasing size of data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1842</identifier>
 <datestamp>2013-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1842</id><created>2013-05-08</created><authors><author><keyname>Jaradat</keyname><forenames>Ward</forenames></author><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Barker</keyname><forenames>Adam</forenames></author></authors><title>An Architecture for Decentralised Orchestration of Web Service Workflows</title><categories>cs.DC</categories><comments>To appear in Proceedings of the IEEE 20th International Conference on
  Web Services (ICWS 2013)</comments><doi>10.1109/ICWS.2013.84</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Service-oriented workflows are typically executed using a centralised
orchestration approach that presents significant scalability challenges. These
challenges include the consumption of network bandwidth, degradation of
performance, and single-points of failure. We provide a decentralised
orchestration architecture that attempts to address these challenges. Our
architecture adopts a design model that permits the computation to be moved
&quot;closer&quot; to services in a workflow. This is achieved by partitioning workflows
specified using our simple dataflow language into smaller fragments, which may
be sent to remote locations for execution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1852</identifier>
 <datestamp>2014-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1852</id><created>2013-05-08</created><updated>2014-12-26</updated><authors><author><keyname>Stavros</keyname><forenames>Stavroglou</forenames></author><author><keyname>Ioannis</keyname><forenames>Antoniou</forenames></author></authors><title>Graph Theoretic Analysis of Knowledge Networks</title><categories>cs.SI physics.soc-ph</categories><comments>This paper has been withdrawn by the author due to some mistakes in
  the references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose of our work is to obtain a basic understanding and comparison of the
performance and structure of real Knowledge Networks, to identify strengths and
weaknesses and to highlight guidelines for improvements. We selected 18
Knowledge Networks from the service sector and 12 networks from the production
sector and estimated their Performance and Structure in terms of 19 indices
from graph theory. Highlights from our work include: 1) As most networks are
unilaterally structured, the direction of knowledge transfer should be taken
into account as illustrated in the analysis of clubs and entropy, 2) The
stability of most Knowledge Networks is questionable, 3) Few networks are
effective in sharing information, while most Knowledge Networks cannot benefit
from the network effect, have rather limited capability for coordination,
information propagation and synchronization and are not able to integrate Tacit
knowledge, 4) Few networks have large cliques which have to be managed with
caution as their role may be highly constructive or destructive, 5) While
agents with rich connections form clubs, as in most social networks, the poor
club effect is not negligible when we take into account the link direction, 6)
The directed link analysis of entropy reveals the low
complexity-diversification of the Knowledge Networks. In fact the only high
entropy network found, has been improved by Knowledge Management Professionals.
As most Knowledge Networks underperform, there is plenty of room for further
customized analysis in order to improve communication efficiency, coordination,
Tacit knowledge dissemination and robustness. This is the first comparative
study of real Knowledge Networks in terms of graph theoretic methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1861</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1861</id><created>2013-05-08</created><authors><author><keyname>Roy</keyname><forenames>Rajat Shuvro</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Debashish</forenames></author><author><keyname>Schliep</keyname><forenames>Alexander</forenames></author></authors><title>Turtle: Identifying frequent k-mers with cache-efficient algorithms</title><categories>q-bio.GN cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Counting the frequencies of k-mers in read libraries is often a first step in
the analysis of high-throughput sequencing experiments. Infrequent k-mers are
assumed to be a result of sequencing errors. The frequent k-mers constitute a
reduced but error-free representation of the experiment, which can inform read
error correction or serve as the input to de novo assembly methods. Ideally,
the memory requirement for counting should be linear in the number of frequent
k-mers and not in the, typically much larger, total number of k-mers in the
read library.
  We present a novel method that balances time, space and accuracy requirements
to efficiently extract frequent k-mers even for high coverage libraries and
large genomes such as human. Our method is designed to minimize cache-misses in
a cache-efficient manner by using a Pattern-blocked Bloom filter to remove
infrequent k-mers from consideration in combination with a novel
sort-and-compact scheme, instead of a Hash, for the actual counting. While this
increases theoretical complexity, the savings in cache misses reduce the
empirical running times. A variant can resort to a counting Bloom filter for
even larger savings in memory at the expense of false negatives in addition to
the false positives common to all Bloom filter based approaches. A comparison
to the state-of-the-art shows reduced memory requirements and running times.
Note that we also provide the first competitive method to count k-mers up to
size 64.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1880</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1880</id><created>2013-05-08</created><authors><author><keyname>Bertault</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Miller</keyname><forenames>Mirka</forenames></author><author><keyname>P&#xe9;rez-Ros&#xe9;s</keyname><forenames>Hebert</forenames></author><author><keyname>Feria-Puron</keyname><forenames>Ramiro</forenames></author><author><keyname>Vaezpour</keyname><forenames>Elaheh</forenames></author></authors><title>A Heuristic for Magic and Antimagic Graph Labellings</title><categories>math.CO cs.DS</categories><msc-class>05C78, 90C27, 90C59</msc-class><journal-ref>Proceedings of the VII Spanish Congress on Metaheuristics, and
  Evolutive and Bioinspired Algorithms (MAEB 2010). V.Campos, A.Duarte,
  M.Gallego, F.Cortazar, R.Marti (eds). Ibergarceta Publicaciones, S.L.,
  Madrid. pp. 677--684</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph labellings have been a very fruitful area of research in the last four
decades. However, despite the staggering number of papers published in the
field (over 1000), few general results are available, and most papers deal with
particular classes of graphs and methods. Here we approach the problem from the
computational viewpoint, and in a quite general way. We present the existence
problem of a particular labelling as a combinatorial optimization problem, then
we discuss the possible strategies to solve it, and finally we present a
heuristic for finding different classes of labellings, like vertex-, edge-, or
face-magic, and $(a, d)$-antimagic $(v, e, f)$-labellings. The algorithm has
been implemented in C++ and MATLAB, and with its aid we have been able to
derive new results for some classes of graphs, in particular, vertex-antimagic
edge labellings for small graphs of the type $P_2^r \times P_3^s$, for which no
general construction is known so far.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1885</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1885</id><created>2013-05-08</created><authors><author><keyname>Mota</keyname><forenames>Jo&#xe3;o F. C.</forenames></author><author><keyname>Xavier</keyname><forenames>Jo&#xe3;o M. F.</forenames></author><author><keyname>Aguiar</keyname><forenames>Pedro M. Q.</forenames></author><author><keyname>P&#xfc;schel</keyname><forenames>Markus</forenames></author></authors><title>Distributed Optimization With Local Domains: Applications in MPC and
  Network Flows</title><categories>math.OC cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Aut. Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider a network with $P$ nodes, where each node has
exclusive access to a local cost function. Our contribution is a
communication-efficient distributed algorithm that finds a vector $x^\star$
minimizing the sum of all the functions. We make the additional assumption that
the functions have intersecting local domains, i.e., each function depends only
on some components of the variable. Consequently, each node is interested in
knowing only some components of $x^\star$, not the entire vector. This allows
for improvement in communication-efficiency. We apply our algorithm to model
predictive control (MPC) and to network flow problems and show, through
experiments on large networks, that our proposed algorithm requires less
communications to converge than prior algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1886</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1886</id><created>2013-05-08</created><authors><author><keyname>Smith</keyname><forenames>Steven Thomas</forenames></author></authors><title>Geometric Optimization Methods for Adaptive Filtering</title><categories>math.OC cs.CG math.DG math.DS math.NA</categories><comments>PhD Dissertation, Harvard University, 1993. A thesis presented by
  Steven Thomas Smith to The Division of Applied Sciences in partial
  fulfillment for the degree of Doctor of Philosophy in the subject of Applied
  Mathematics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The techniques and analysis presented in this thesis provide new methods to
solve optimization problems posed on Riemannian manifolds. These methods are
applied to the subspace tracking problem found in adaptive signal processing
and adaptive control. A new point of view is offered for the constrained
optimization problem. Some classical optimization techniques on Euclidean space
are generalized to Riemannian manifolds. Several algorithms are presented and
their convergence properties are analyzed employing the Riemannian structure of
the manifold. Specifically, two new algorithms, which can be thought of as
Newton's method and the conjugate gradient method on Riemannian manifolds, are
presented and shown to possess quadratic and superlinear convergence,
respectively. These methods are applied to several eigenvalue and singular
value problems, which are posed as constrained optimization problems. ...
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1887</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1887</id><created>2013-05-08</created><authors><author><keyname>Pande</keyname><forenames>Gaurav</forenames></author></authors><title>Performance Evaluation of Video Communications over 4G Network</title><categories>cs.MM cs.NI</categories><comments>Accepted in ICACNI 2013. arXiv admin note: substantial text overlap
  with arXiv:1304.3758</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With exponential increase in the volumes of video traffic in cellular
net-works, there is an increasing need for optimizing the quality of video
delivery. 4G networks (Long Term Evolution Advanced or LTE A) are being
introduced in many countries worldwide, which allow a downlink speed of upto 1
Gbps and uplink of 100 Mbps over a single base station. In this paper, we
characterize the performance of LTE A physical layer in terms of transmitted
video quality when the channel condi-tions and LTE settings are varied. We test
the performance achieved as the channel quality is changed and HARQ features
are enabled in physical layer. Blocking and blurring metrics were used to model
image quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1899</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1899</id><created>2013-05-07</created><authors><author><keyname>Xie</keyname><forenames>Hong</forenames></author><author><keyname>Lui</keyname><forenames>John C. S.</forenames></author></authors><title>Mathematical Modeling of Product Rating: Sufficiency, Misbehavior and
  Aggregation Rules</title><categories>cs.IR cs.SI</categories><comments>33 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many web services like eBay, Tripadvisor, Epinions, etc, provide historical
product ratings so that users can evaluate the quality of products. Product
ratings are important since they affect how well a product will be adopted by
the market. The challenge is that we only have {\em &quot;partial information&quot;} on
these ratings: Each user provides ratings to only a &quot;{\em small subset of
products}&quot;. Under this partial information setting, we explore a number of
fundamental questions: What is the &quot;{\em minimum number of ratings}&quot; a product
needs so one can make a reliable evaluation of its quality? How users' {\em
misbehavior} (such as {\em cheating}) in product rating may affect the
evaluation result? To answer these questions, we present a formal mathematical
model of product evaluation based on partial information. We derive theoretical
bounds on the minimum number of ratings needed to produce a reliable indicator
of a product's quality. We also extend our model to accommodate users'
misbehavior in product rating. We carry out experiments using both synthetic
and real-world data (from TripAdvisor, Amazon and eBay) to validate our model,
and also show that using the &quot;majority rating rule&quot; to aggregate product
ratings, it produces more reliable and robust product evaluation results than
the &quot;average rating rule&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1900</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1900</id><created>2013-05-08</created><authors><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>Residue Classes of the PPT Sequence</title><categories>cs.CR</categories><comments>8 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Primitive Pythagorean triples (PPT) may be put into different equivalence
classes using residues with respect to primes. We show that the probability
that the smaller odd number associated with the PPT triple is divisible by
prime p is 2/(p+1). We have determined the autocorrelation function of the
Baudhayana sequences obtained from the residue classes and we show these
sequences have excellent randomness properties. We provide analytical
explanation for the peak and the average off-peak values for the
autocorrelation function. These sequences can be used specifically in a variety
of key generation and distribution problems and, more generally, as
pseudorandom sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1912</identifier>
 <datestamp>2014-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1912</id><created>2013-05-08</created><updated>2014-03-27</updated><authors><author><keyname>Mamonov</keyname><forenames>Alexander V.</forenames></author><author><keyname>Figueiredo</keyname><forenames>Isabel N.</forenames></author><author><keyname>Figueiredo</keyname><forenames>Pedro N.</forenames></author><author><keyname>Tsai</keyname><forenames>Yen-Hsi Richard</forenames></author></authors><title>Automated polyp detection in colon capsule endoscopy</title><categories>cs.CV</categories><comments>16 pages, 9 figures, 4 tables</comments><acm-class>I.4.8</acm-class><journal-ref>IEEE Transactions on Medical Imaging 33(7):1488-1502, 2014</journal-ref><doi>10.1109/TMI.2014.2314959</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Colorectal polyps are important precursors to colon cancer, a major health
problem. Colon capsule endoscopy (CCE) is a safe and minimally invasive
examination procedure, in which the images of the intestine are obtained via
digital cameras on board of a small capsule ingested by a patient. The video
sequence is then analyzed for the presence of polyps. We propose an algorithm
that relieves the labor of a human operator analyzing the frames in the video
sequence. The algorithm acts as a binary classifier, which labels the frame as
either containing polyps or not, based on the geometrical analysis and the
texture content of the frame. The geometrical analysis is based on a
segmentation of an image with the help of a mid-pass filter. The features
extracted by the segmentation procedure are classified according to an
assumption that the polyps are characterized as protrusions that are mostly
round in shape. Thus, we use a best fit ball radius as a decision parameter of
a binary classifier. We present a statistical study of the performance of our
approach on a data set containing over 18,900 frames from the endoscopic video
sequences of five adult patients. The algorithm demonstrates a solid
performance, achieving 47% sensitivity per frame and over 81% sensitivity per
polyp at a specificity level of 90%. On average, with a video sequence length
of 3747 frames, only 367 false positive frames need to be inspected by a human
operator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1922</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1922</id><created>2013-05-08</created><authors><author><keyname>Lee</keyname><forenames>Yin Tat</forenames></author><author><keyname>Sidford</keyname><forenames>Aaron</forenames></author></authors><title>Efficient Accelerated Coordinate Descent Methods and Faster Algorithms
  for Solving Linear Systems</title><categories>cs.DS math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we show how to accelerate randomized coordinate descent methods
and achieve faster convergence rates without paying per-iteration costs in
asymptotic running time. In particular, we show how to generalize and
efficiently implement a method proposed by Nesterov, giving faster asymptotic
running times for various algorithms that use standard coordinate descent as a
black box. In addition to providing a proof of convergence for this new general
method, we show that it is numerically stable, efficiently implementable, and
in certain regimes, asymptotically optimal.
  To highlight the computational power of this algorithm, we show how it can
used to create faster linear system solvers in several regimes:
  - We show how this method achieves a faster asymptotic runtime than conjugate
gradient for solving a broad class of symmetric positive definite systems of
equations.
  - We improve the best known asymptotic convergence guarantees for Kaczmarz
methods, a popular technique for image reconstruction and solving
overdetermined systems of equations, by accelerating a randomized algorithm of
Strohmer and Vershynin.
  - We achieve the best known running time for solving Symmetric Diagonally
Dominant (SDD) system of equations in the unit-cost RAM model, obtaining an O(m
log^{3/2} n (log log n)^{1/2} log (log n / eps)) asymptotic running time by
accelerating a recent solver by Kelner et al.
  Beyond the independent interest of these solvers, we believe they highlight
the versatility of the approach of this paper and we hope that they will open
the door for further algorithmic improvements in the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1925</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1925</id><created>2013-05-08</created><authors><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author><author><keyname>Mahajan</keyname><forenames>Anjali</forenames></author></authors><title>Speech: A Challenge to Digital Signal Processing Technology for
  Human-to-Computer Interaction</title><categories>cs.HC cs.CL</categories><comments>Pages: 06 Figures : 06. arXiv admin note: text overlap with
  arXiv:1305.1429, arXiv:1305.1428</comments><journal-ref>Conference Proceedings National Conference on Recent Trends in
  Electronics &amp; Information Technology (RTEIT),2006,pp 206-212</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This software project based paper is for a vision of the near future in which
computer interaction is characterized by natural face-to-face conversations
with lifelike characters that speak, emote, and gesture. The first step is
speech. The dream of a true virtual reality, a complete human-computer
interaction system will not come true unless we try to give some perception to
machine and make it perceive the outside world as humans communicate with each
other. This software project is under development for listening and replying
machine (Computer) through speech. The Speech interface is developed to convert
speech input into some parametric form (Speech-to-Text) for further processing
and the results, text output to speech synthesis (Text-to-Speech)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1926</identifier>
 <datestamp>2014-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1926</id><created>2013-05-08</created><updated>2013-12-16</updated><authors><author><keyname>Noel</keyname><forenames>Adam</forenames></author><author><keyname>Cheung</keyname><forenames>Karen C.</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author></authors><title>Improving Receiver Performance of Diffusive Molecular Communication with
  Enzymes</title><categories>cs.IT cs.ET math.IT</categories><comments>13 pages, 8 figures, 1 table. To appear in IEEE Transactions on
  Nanobioscience (submitted January 22, 2013; minor revision October 16, 2013;
  accepted December 4, 2013)</comments><doi>10.1109/TNB.2013.2295546</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the mitigation of intersymbol interference in a diffusive
molecular communication system using enzymes that freely diffuse in the
propagation environment. The enzymes form reaction intermediates with
information molecules and then degrade them so that they cannot interfere with
future transmissions. A lower bound expression on the expected number of
molecules measured at the receiver is derived. A simple binary receiver
detection scheme is proposed where the number of observed molecules is sampled
at the time when the maximum number of molecules is expected. Insight is also
provided into the selection of an appropriate bit interval. The expected bit
error probability is derived as a function of the current and all previously
transmitted bits. Simulation results show the accuracy of the bit error
probability expression and the improvement in communication performance by
having active enzymes present.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1946</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1946</id><created>2013-05-08</created><authors><author><keyname>Camossi</keyname><forenames>Elena</forenames></author><author><keyname>Villa</keyname><forenames>Paola</forenames></author><author><keyname>Mazzola</keyname><forenames>Luca</forenames></author></authors><title>Semantic-based Anomalous Pattern Discovery in Moving Object Trajectories</title><categories>cs.AI cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we investigate a novel semantic approach for pattern discovery
in trajectories that, relying on ontologies, enhances object movement
information with event semantics. The approach can be applied to the detection
of movement patterns and behaviors whenever the semantics of events occurring
along the trajectory is, explicitly or implicitly, available. In particular, we
tested it against an exacting case scenario in maritime surveillance, i.e., the
discovery of suspicious container transportations.
  The methodology we have developed entails the formalization of the
application domain through a domain ontology, extending the Moving Object
Ontology (MOO) described in this paper. Afterwards, movement patterns have to
be formalized, either as Description Logic (DL) axioms or queries, enabling the
retrieval of the trajectories that follow the patterns.
  In our experimental evaluation, we have considered a real world dataset of 18
Million of container events describing the deed undertaken in a port to
accomplish the shipping (e.g., loading on a vessel, export operation).
Leveraging events, we have reconstructed almost 300 thousand container
trajectories referring to 50 thousand containers travelling along three years.
We have formalized the anomalous itinerary patterns as DL axioms, testing
different ontology APIs and DL reasoners to retrieve the suspicious
transportations.
  Our experiments demonstrate that the approach is feasible and efficient. In
particular, the joint use of Pellet and SPARQL-DL enables to detect the
trajectories following a given pattern in a reasonable time with big size
datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1956</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1956</id><created>2013-05-08</created><updated>2013-05-09</updated><authors><author><keyname>Lan</keyname><forenames>Andrew S.</forenames></author><author><keyname>Studer</keyname><forenames>Christoph</forenames></author><author><keyname>Waters</keyname><forenames>Andrew E.</forenames></author><author><keyname>Baraniuk</keyname><forenames>Richard G.</forenames></author></authors><title>Joint Topic Modeling and Factor Analysis of Textual Information and
  Graded Response Data</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern machine learning methods are critical to the development of
large-scale personalized learning systems that cater directly to the needs of
individual learners. The recently developed SPARse Factor Analysis (SPARFA)
framework provides a new statistical model and algorithms for machine
learning-based learning analytics, which estimate a learner's knowledge of the
latent concepts underlying a domain, and content analytics, which estimate the
relationships among a collection of questions and the latent concepts. SPARFA
estimates these quantities given only the binary-valued graded responses to a
collection of questions. In order to better interpret the estimated latent
concepts, SPARFA relies on a post-processing step that utilizes user-defined
tags (e.g., topics or keywords) available for each question. In this paper, we
relax the need for user-defined tags by extending SPARFA to jointly process
both graded learner responses and the text of each question and its associated
answer(s) or other feedback. Our purely data-driven approach (i) enhances the
interpretability of the estimated latent concepts without the need of
explicitly generating a set of tags or performing a post-processing step, (ii)
improves the prediction performance of SPARFA, and (iii) scales to large
test/assessments where human annotation would prove burdensome. We demonstrate
the efficacy of the proposed approach on two real educational datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1958</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1958</id><created>2013-05-08</created><authors><author><keyname>Froese</keyname><forenames>Tom</forenames></author><author><keyname>Gershenson</keyname><forenames>Carlos</forenames></author><author><keyname>Rosenblueth</keyname><forenames>David A.</forenames></author></authors><title>The Dynamically Extended Mind -- A Minimal Modeling Case Study</title><categories>cs.AI cs.NE nlin.CD</categories><comments>8 pages, accepted in Congress on Evolutionary Computation IEEE CEC
  2013, Evolutionary Robotics track</comments><acm-class>I.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The extended mind hypothesis has stimulated much interest in cognitive
science. However, its core claim, i.e. that the process of cognition can extend
beyond the brain via the body and into the environment, has been heavily
criticized. A prominent critique of this claim holds that when some part of the
world is coupled to a cognitive system this does not necessarily entail that
the part is also constitutive of that cognitive system. This critique is known
as the &quot;coupling-constitution fallacy&quot;. In this paper we respond to this
reductionist challenge by using an evolutionary robotics approach to create a
minimal model of two acoustically coupled agents. We demonstrate how the
interaction process as a whole has properties that cannot be reduced to the
contributions of the isolated agents. We also show that the neural dynamics of
the coupled agents has formal properties that are inherently impossible for
those neural networks in isolation. By keeping the complexity of the model to
an absolute minimum, we are able to illustrate how the coupling-constitution
fallacy is in fact based on an inadequate understanding of the constitutive
role of nonlinear interactions in dynamical systems theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1961</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1961</id><created>2013-05-08</created><authors><author><keyname>Derbinsky</keyname><forenames>Nate</forenames></author><author><keyname>Bento</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Elser</keyname><forenames>Veit</forenames></author><author><keyname>Yedidia</keyname><forenames>Jonathan S.</forenames></author></authors><title>An Improved Three-Weight Message-Passing Algorithm</title><categories>cs.AI cs.DS math.OC physics.comp-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe how the powerful &quot;Divide and Concur&quot; algorithm for constraint
satisfaction can be derived as a special case of a message-passing version of
the Alternating Direction Method of Multipliers (ADMM) algorithm for convex
optimization, and introduce an improved message-passing algorithm based on
ADMM/DC by introducing three distinct weights for messages, with &quot;certain&quot; and
&quot;no opinion&quot; weights, as well as the standard weight used in ADMM/DC. The
&quot;certain&quot; messages allow our improved algorithm to implement constraint
propagation as a special case, while the &quot;no opinion&quot; messages speed
convergence for some problems by making the algorithm focus only on active
constraints. We describe how our three-weight version of ADMM/DC can give
greatly improved performance for non-convex problems such as circle packing and
solving large Sudoku puzzles, while retaining the exact performance of ADMM for
convex problems. We also describe the advantages of our algorithm compared to
other message-passing algorithms based upon belief propagation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1979</identifier>
 <datestamp>2014-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1979</id><created>2013-05-08</created><updated>2014-07-07</updated><authors><author><keyname>Dinur</keyname><forenames>Irit</forenames></author><author><keyname>Steurer</keyname><forenames>David</forenames></author></authors><title>Analytical Approach to Parallel Repetition</title><categories>cs.CC</categories><comments>Improved presentation, expanded and rewrote sections about expanding
  and general games</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an analytical framework for studying parallel repetition, a basic
product operation for one-round two-player games. In this framework, we
consider a relaxation of the value of a game, $\mathrm{val}_+$, and prove that
for projection games, it is both multiplicative (under parallel repetition) and
a good approximation for the true value.
  These two properties imply a parallel repetition bound as $$
\mathrm{val}(G^{\otimes k}) \approx \mathrm{val}_+(G^{\otimes k}) =
\mathrm{val}_+(G)^{k} \approx \mathrm{val}(G)^{k}. $$
  Using this framework, we can also give a short proof for the NP-hardness of
Label-Cover$(1,\delta)$ for all $\delta&gt;0$, starting from the basic PCP
theorem.
  We prove the following new results:
  - A parallel repetition bound for projection games with small soundness.
Previously, it was not known whether parallel repetition decreases the value of
such games. This result implies stronger inapproximability bounds for Set-Cover
and Label-Cover.
  - An improved bound for few parallel repetitions of projection games, showing
that Raz's counterexample is tight even for a small number of repetitions.
  Our techniques also allow us to bound the value of the direct product of
multiple games, namely, a bound on $\mathrm{val}(G_1\otimes ...\otimes G_k)$
for different projection games $G_1,...,G_k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1980</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1980</id><created>2013-05-08</created><authors><author><keyname>Raghavan</keyname><forenames>Vasanthan</forenames></author><author><keyname>Steeg</keyname><forenames>Greg Ver</forenames></author><author><keyname>Galstyan</keyname><forenames>Aram</forenames></author><author><keyname>Tartakovsky</keyname><forenames>Alexander G.</forenames></author></authors><title>Modeling Temporal Activity Patterns in Dynamic Social Networks</title><categories>physics.soc-ph cs.SI physics.data-an stat.AP</categories><comments>23 pages, 7 figures, 13 tables, submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The focus of this work is on developing probabilistic models for user
activity in social networks by incorporating the social network influence as
perceived by the user. For this, we propose a coupled Hidden Markov Model,
where each user's activity evolves according to a Markov chain with a hidden
state that is influenced by the collective activity of the friends of the user.
We develop generalized Baum-Welch and Viterbi algorithms for model parameter
learning and state estimation for the proposed framework. We then validate the
proposed model using a significant corpus of user activity on Twitter. Our
numerical studies show that with sufficient observations to ensure accurate
model learning, the proposed framework explains the observed data better than
either a renewal process-based model or a conventional uncoupled Hidden Markov
Model. We also demonstrate the utility of the proposed approach in predicting
the time to the next tweet. Finally, clustering in the model parameter space is
shown to result in distinct natural clusters of users characterized by the
interaction dynamic between a user and his network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1986</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1986</id><created>2013-05-08</created><updated>2014-08-14</updated><authors><author><keyname>Srivastava</keyname><forenames>Madhur</forenames></author><author><keyname>Singh</keyname><forenames>Satish K.</forenames></author><author><keyname>Panigrahi</keyname><forenames>Prasanta K.</forenames></author></authors><title>An Adaptive Statistical Non-uniform Quantizer for Detail Wavelet
  Components in Lossy JPEG2000 Image Compression</title><categories>cs.MM cs.CV</categories><comments>26 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents a non-uniform quantization method for the Detail
components in the JPEG2000 standard. Incorporating the fact that the
coefficients lying towards the ends of the histogram plot of each Detail
component represent the structural information of an image, the quantization
step sizes become smaller at they approach the ends of the histogram plot. The
variable quantization step sizes are determined by the actual statistics of the
wavelet coefficients. Mean and standard deviation are the two statistical
parameters used iteratively to obtain the variable step sizes. Moreover, the
mean of the coefficients lying within the step size is chosen as the quantized
value, contrary to the deadzone uniform quantizer which selects the midpoint of
the quantization step size as the quantized value. The experimental results of
the deadzone uniform quantizer and the proposed non-uniform quantizer are
objectively compared by using Mean-Squared Error (MSE) and Mean Structural
Similarity Index Measure (MSSIM), to evaluate the quantization error and
reconstructed image quality, respectively. Subjective analysis of the
reconstructed images is also carried out. Through the objective and subjective
assessments, it is shown that the non-uniform quantizer performs better than
the deadzone uniform quantizer in the perceptual quality of the reconstructed
image, especially at low bitrates. More importantly, unlike the deadzone
uniform quantizer, the non-uniform quantizer accomplishes better visual quality
with a few quantized values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1991</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1991</id><created>2013-05-08</created><authors><author><keyname>Dowe</keyname><forenames>David L.</forenames></author><author><keyname>Hernandez-Orallo</keyname><forenames>Jose</forenames></author></authors><title>On the universality of cognitive tests</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analysis of the adaptive behaviour of many different kinds of systems
such as humans, animals and machines, requires more general ways of assessing
their cognitive abilities. This need is strengthened by increasingly more tasks
being analysed for and completed by a wider diversity of systems, including
swarms and hybrids. The notion of universal test has recently emerged in the
context of machine intelligence evaluation as a way to define and use the same
cognitive test for a variety of systems, using some principled tasks and
adapting the interface to each particular subject. However, how far can
universal tests be taken? This paper analyses this question in terms of
subjects, environments, space-time resolution, rewards and interfaces. This
leads to a number of findings, insights and caveats, according to several
levels where universal tests may be progressively more difficult to conceive,
implement and administer. One of the most significant contributions is given by
the realisation that more universal tests are defined as maximisations of less
universal tests for a variety of configurations. This means that universal
tests must be necessarily adaptive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.1992</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.1992</id><created>2013-05-08</created><authors><author><keyname>Alam</keyname><forenames>Sawood</forenames></author><author><keyname>Cartledge</keyname><forenames>Charles L.</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author></authors><title>HTTP Mailbox - Asynchronous RESTful Communication</title><categories>cs.SE cs.DL</categories><comments>13 pages, 6 figures, 8 code blocks, 3 equations, and 3 tables</comments><acm-class>H.3.5</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We describe HTTP Mailbox, a mechanism to enable RESTful HTTP communication in
an asynchronous mode with a full range of HTTP methods otherwise unavailable to
standard clients and servers. HTTP Mailbox allows for broadcast and multicast
semantics via HTTP. We evaluate a reference implementation using ApacheBench (a
server stress testing tool) demonstrating high throughput (on 1,000 concurrent
requests) and a systemic error rate of 0.01%. Finally, we demonstrate our HTTP
Mailbox implementation in a human assisted web preservation application called
&quot;Preserve Me&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2004</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2004</id><created>2013-05-08</created><authors><author><keyname>Kwon</keyname><forenames>Keehang</forenames></author></authors><title>Expressing Algorithms As Concise As Possible via Computability Logic</title><categories>cs.LO</categories><comments>5 pages</comments><journal-ref>IEICE transactions on fundamental of CS vol E97-A, No.6. June
  2014, 1385-1387</journal-ref><doi>10.1587/transfun.E97.A.1385</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new approach to defining and expressing algorithms: the
notion of {\it task logical} algorithms. This notion allows the user to define
an algorithm for a task $T$ as a set of agents who can collectively perform
$T$. This notion considerably simplifies the algorithm development process and
can be seen as an integration of the sequential pseudocode and logical
algorithms. This observation requires some changes to algorithm development
process. We propose a two-step approach: the first step is to define an
algorithm for a task $T$ via a set of agents that can collectively perform $T$.
The second step is to translate these agents into (higher-order) computability
logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2006</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2006</id><created>2013-05-09</created><updated>2013-05-12</updated><authors><author><keyname>Xie</keyname><forenames>Jierui</forenames></author><author><keyname>Chen</keyname><forenames>Mingming</forenames></author><author><keyname>Szymanski</keyname><forenames>Boleslaw K.</forenames></author></authors><title>LabelRankT: Incremental Community Detection in Dynamic Networks via
  Label Propagation</title><categories>cs.SI physics.soc-ph</categories><comments>DyNetMM 2013, New York, USA (conjunction with SIGMOD/PODS 2013)</comments><journal-ref>Proc. DyNetMM 2013 at SIGMOD/PODS 2013, New York, NY, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An increasingly important challenge in network analysis is efficient
detection and tracking of communities in dynamic networks for which changes
arrive as a stream. There is a need for algorithms that can incrementally
update and monitor communities whose evolution generates huge realtime data
streams, such as the Internet or on-line social networks. In this paper, we
propose LabelRankT, an online distributed algorithm for detection of
communities in large-scale dynamic networks through stabilized label
propagation. Results of tests on real-world networks demonstrate that
LabelRankT has much lower computational costs than other algorithms. It also
improves the quality of the detected communities compared to dynamic detection
methods and matches the quality achieved by static detection approaches. Unlike
most of other algorithms which apply only to binary networks, LabelRankT works
on weighted and directed networks, which provides a flexible and promising
solution for real-world applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2009</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2009</id><created>2013-05-09</created><updated>2013-08-19</updated><authors><author><keyname>Basavaraju</keyname><forenames>Manu</forenames></author><author><keyname>Francis</keyname><forenames>Mathew C.</forenames></author></authors><title>Strong chromatic index of chordless graphs</title><categories>math.CO cs.DM</categories><comments>8 pages + 2 page appendix, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A strong edge colouring of a graph is an assignment of colours to the edges
of the graph such that for every colour, the set of edges that are given that
colour form an induced matching in the graph. The strong chromatic index of a
graph $G$, denoted by $\chi'_s(G)$, is the minimum number of colours needed in
any strong edge colouring of $G$. A graph is said to be \emph{chordless} if
there is no cycle in the graph that has a chord. Faudree, Gy\'arf\'as, Schelp
and Tuza~[The Strong Chromatic Index of Graphs, Ars Combin., 29B (1990),
pp.~205--211] considered a particular subclass of chordless graphs, namely the
class of graphs in which all the cycle lengths are multiples of four, and asked
whether the strong chromatic index of these graphs can be bounded by a linear
function of the maximum degree. Chang and Narayanan~[Strong Chromatic Index of
2-degenerate Graphs, J. Graph Theory, 73(2) (2013), pp.~119--126] answered this
question in the affirmative by proving that if $G$ is a chordless graph with
maximum degree $\Delta$, then $\chi'_s(G) \leq 8\Delta -6$. We improve this
result by showing that for every chordless graph $G$ with maximum degree
$\Delta$, $\chi'_s(G)\leq 3\Delta$. This bound is tight up to to an additive
constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2038</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2038</id><created>2013-05-09</created><authors><author><keyname>Meyer</keyname><forenames>Patrick E.</forenames></author></authors><title>A Rank Minrelation - Majrelation Coefficient</title><categories>stat.ML cs.AI</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Improving the detection of relevant variables using a new bivariate measure
could importantly impact variable selection and large network inference
methods. In this paper, we propose a new statistical coefficient that we call
the rank minrelation coefficient. We define a minrelation of X to Y (or
equivalently a majrelation of Y to X) as a measure that estimate p(Y &gt; X) when
X and Y are continuous random variables. The approach is similar to Lin's
concordance coefficient that rather focuses on estimating p(X = Y). In other
words, if a variable X exhibits a minrelation to Y then, as X increases, Y is
likely to increases too. However, on the contrary to concordance or
correlation, the minrelation is not symmetric. More explicitly, if X decreases,
little can be said on Y values (except that the uncertainty on Y actually
increases). In this paper, we formally define this new kind of bivariate
dependencies and propose a new statistical coefficient in order to detect those
dependencies. We show through several key examples that this new coefficient
has many interesting properties in order to select relevant variables, in
particular when compared to correlation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2039</identifier>
 <datestamp>2013-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2039</id><created>2013-05-09</created><updated>2013-08-02</updated><authors><author><keyname>Bulin</keyname><forenames>Jakub</forenames></author><author><keyname>Delic</keyname><forenames>Dejan</forenames></author><author><keyname>Jackson</keyname><forenames>Marcel</forenames></author><author><keyname>Niven</keyname><forenames>Todd</forenames></author></authors><title>On the reduction of the CSP dichotomy conjecture to digraphs</title><categories>cs.CC math.CO</categories><comments>34 pages. Article is to appear in CP2013. This version includes two
  appendices with proofs of claims omitted from the main article</comments><msc-class>05C20, 05C60, 08A35</msc-class><acm-class>F.1.3; F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that the constraint satisfaction problem over general
relational structures can be reduced in polynomial time to digraphs. We present
a simple variant of such a reduction and use it to show that the algebraic
dichotomy conjecture is equivalent to its restriction to digraphs and that the
polynomial reduction can be made in logspace. We also show that our reduction
preserves the bounded width property, i.e., solvability by local consistency
methods. We discuss further algorithmic properties that are preserved and
related open problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2042</identifier>
 <datestamp>2014-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2042</id><created>2013-05-09</created><updated>2014-11-07</updated><authors><author><keyname>Herzog</keyname><forenames>Alexander</forenames></author><author><keyname>Righetti</keyname><forenames>Ludovic</forenames></author><author><keyname>Grimminger</keyname><forenames>Felix</forenames></author><author><keyname>Pastor</keyname><forenames>Peter</forenames></author><author><keyname>Schaal</keyname><forenames>Stefan</forenames></author></authors><title>Balancing experiments on a torque-controlled humanoid with hierarchical
  inverse dynamics</title><categories>cs.RO</categories><comments>appears in IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS), 2014</comments><doi>10.1109/IROS.2014.6942678</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently several hierarchical inverse dynamics controllers based on cascades
of quadratic programs have been proposed for application on torque controlled
robots. They have important theoretical benefits but have never been
implemented on a torque controlled robot where model inaccuracies and real-time
computation requirements can be problematic. In this contribution we present an
experimental evaluation of these algorithms in the context of balance control
for a humanoid robot. The presented experiments demonstrate the applicability
of the approach under real robot conditions (i.e. model uncertainty, estimation
errors, etc). We propose a simplification of the optimization problem that
allows us to decrease computation time enough to implement it in a fast torque
control loop. We implement a momentum-based balance controller which shows
robust performance in face of unknown disturbances, even when the robot is
standing on only one foot. In a second experiment, a tracking task is evaluated
to demonstrate the performance of the controller with more complicated
hierarchies. Our results show that hierarchical inverse dynamics controllers
can be used for feedback control of humanoid robots and that momentum-based
balance control can be efficiently implemented on a real robot.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2091</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2091</id><created>2013-05-08</created><authors><author><keyname>O'Donovan</keyname><forenames>Francis T.</forenames></author><author><keyname>Fournelle</keyname><forenames>Connie</forenames></author><author><keyname>Gaffigan</keyname><forenames>Steve</forenames></author><author><keyname>Brdiczka</keyname><forenames>Oliver</forenames></author><author><keyname>Shen</keyname><forenames>Jianqiang</forenames></author><author><keyname>Liu</keyname><forenames>Juan</forenames></author><author><keyname>Moore</keyname><forenames>Kendra E.</forenames></author></authors><title>Characterizing User Behavior and Information Propagation on a Social
  Multimedia Network</title><categories>cs.SI physics.soc-ph</categories><comments>6 pages, 5 figures, 2 tables, to be published in the proceedings of
  the Int. Workshop on Social Multimedia Research (SMMR) 2013. 2013 IEEE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An increasing portion of modern socializing takes place via online social
networks. Members of these communities often play distinct roles that can be
deduced from observations of users' online activities. One such activity is the
sharing of multimedia, the popularity of which can vary dramatically. Here we
discuss our initial analysis of anonymized, scraped data from consenting
Facebook users, together with associated demographic and psychological
profiles. We present five clusters of users with common observed online
behaviors, where these users also show correlated profile characteristics.
Finally, we identify some common properties of the most popular multimedia
content.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2103</identifier>
 <datestamp>2014-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2103</id><created>2013-05-09</created><updated>2014-07-16</updated><authors><author><keyname>Sroka</keyname><forenames>Jacek</forenames></author><author><keyname>Panasiuk</keyname><forenames>Adrian</forenames></author><author><keyname>Stencel</keyname><forenames>Krzysztof</forenames></author><author><keyname>Tyszkiewicz</keyname><forenames>Jerzy</forenames></author></authors><title>Translating Relational Queries into Spreadsheets</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spreadsheets are among the most commonly used applications for data
management and analysis. Perhaps they are even among the most widely used
computer applications of all kinds. They combine in a natural and intuitive way
data processing with very diverse supplementary features: statistical
functions, visualization tools, pivot tables, pivot charts, linear programming
solvers, Web queries periodically downloading data from external sources, etc.
However, the spreadsheet paradigm of computation still lacks sufficient
analysis.
  In this article we demonstrate that a spreadsheet can implement all data
transformations definable in SQL, without any use of macros or built-in
programming languages, merely by utilizing spreadsheet formulas. We provide a
query compiler, which translates any given SQL query into a worksheet of the
same semantics, including NULL values.
  Thereby database operations become available to the users who do not want to
migrate to a database. They can define their queries using a high-level
language and then get their execution plans in a plain vanilla spreadsheet. No
sophisticated database system, no spreadsheet plugins or macros are needed.
  The functions available in spreadsheets impose severe limitations on the
algorithms one can implement. In this paper we offer $O(n\log^2n)$ sorting
spreadsheet, but using a non-constant number of rows, improving on the
previously known $O(n^2)$ ones.
  It is therefore surprising, that a spreadsheet can implement, as we
demonstrate, Depth-First-Search and Breadth-First-Search on graphs, thereby
reaching beyond queries definable in SQL-92.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2108</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2108</id><created>2013-05-09</created><authors><author><keyname>Gupta</keyname><forenames>Sushmita</forenames></author><author><keyname>Kamali</keyname><forenames>Shahin</forenames></author><author><keyname>L&#xf3;pez-Ortiz</keyname><forenames>Alejandro</forenames></author></authors><title>On Advice Complexity of the k-server Problem under Sparse Metrics</title><categories>cs.DS</categories><comments>16 pages, 3 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the k-server problem under the advice model of computation when
the underlying metric space is sparse. On one side, we show that an advice of
size {\Omega}(n) is required to obtain a 1-competitive algorithm for sequences
of size n, even for the 2-server problem on a path metric of size N &gt;= 5.
Through another lower bound argument, we show that at least (n/2)(log {\alpha}
- 1.22) bits of advice is required to obtain an optimal solution for metric
spaces of treewidth {\alpha}, where 4 &lt;= {\alpha} &lt; 2k. On the other side, we
introduce {\Theta}(1)-competitive algorithms for a wide range of sparse graphs,
which require advice of (almost) linear size. Namely, we show that for graphs
of size N and treewidth {\alpha}, there is an online algorithm which receives
$O(n (log {\alpha} + log log N))$ bits of advice and optimally serves a
sequence of length n. With a different argument, we show that if a graph admits
a system of {\mu} collective tree (q,r)-spanners, then there is a
(q+r)-competitive algorithm which receives O(n (log {\mu} + log log N)) bits of
advice. Among other results, this gives a 3-competitive algorithm for planar
graphs, provided with O(n log log N) bits of advice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2112</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2112</id><created>2013-05-09</created><authors><author><keyname>Zou</keyname><forenames>Yulong</forenames></author><author><keyname>Wang</keyname><forenames>Xianbin</forenames></author><author><keyname>Shen</keyname><forenames>Weiming</forenames></author></authors><title>Intercept Probability Analysis of Cooperative Wireless Networks with
  Best Relay Selection in the Presence of Eavesdropping Attack</title><categories>cs.IT math.IT</categories><comments>5 pages. arXiv admin note: substantial text overlap with
  arXiv:1305.0817</comments><journal-ref>In Proceedings of 2013 IEEE International Conference on
  Communications (IEEE ICC 2013), pp. 1-5, Budapest, Hungary, Jun. 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the broadcast nature of wireless medium, wireless communication is
extremely vulnerable to eavesdropping attack. Physical-layer security is
emerging as a new paradigm to prevent the eavesdropper from interception by
exploiting the physical characteristics of wireless channels, which has
recently attracted a lot of research attentions. In this paper, we consider the
physical-layer security in cooperative wireless networks with multiple
decode-and-forward (DF) relays and investigate the best relay selection in the
presence of eavesdropping attack. For the comparison purpose, we also examine
the conventional direct transmission without relay and traditional max-min
relay selection. We derive closed-form intercept probability expressions of the
direct transmission, traditional max-min relay selection, and proposed best
relay selection schemes in Rayleigh fading channels. Numerical results show
that the proposed best relay selection scheme strictly outperforms the
traditional direct transmission and max-min relay selection schemes in terms of
intercept probability. In addition, as the number of relays increases, the
intercept probabilities of both traditional max-min relay selection and
proposed best relay selection schemes decrease significantly, showing the
advantage of exploiting multiple relays against eavesdropping attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2123</identifier>
 <datestamp>2013-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2123</id><created>2013-05-09</created><updated>2013-07-16</updated><authors><author><keyname>Wu</keyname><forenames>Xiaoxiao</forenames></author><author><keyname>Ma</keyname><forenames>Wing-Kin</forenames></author><author><keyname>So</keyname><forenames>Anthony Man-Cho</forenames></author></authors><title>Physical-Layer Multicasting by Stochastic Transmit Beamforming and
  Alamouti Space-Time Coding</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider transceiver designs in a multiuser multi-input single-output (MISO)
downlink channel, where the users are to receive the same data stream
simultaneously. This problem, known as physical-layer multicasting, has drawn
much interest. Presently, a popularized approach is transmit beamforming, in
which the beamforming optimization is handled by a rank-one approximation
method called semidefinite relaxation (SDR). SDR-based beamforming has been
shown to be promising for a small or moderate number of users. This paper
describes two new transceiver strategies for physical-layer multicasting. The
first strategy, called stochastic beamforming (SBF), randomizes the beamformer
in a per-symbol time-varying manner, so that the rank-one approximation in SDR
can be bypassed. We propose several efficiently realizable SBF schemes, and
prove that their multicast achievable rate gaps with respect to the MISO
multicast capacity must be no worse than 0.8314 bits/s/Hz, irrespective of any
other factors such as the number of users. The use of channel coding and the
assumption of sufficiently long code lengths play a crucial role in achieving
the above result. The second strategy combines transmit beamforming and the
Alamouti space-time code. The result is a rank-two generalization of SDR-based
beamforming. We show by analysis that this SDR-based beamformed Alamouti scheme
has a better worst-case effective signal-to-noise ratio (SNR) scaling, and
hence a better multicast rate scaling, than SDR-based beamforming. We further
the work by combining SBF and the beamformed Alamouti scheme, wherein an
improved constant rate gap of 0.39 bits/s/Hz is proven. Simulation results show
that under a channel-coded, many-user setting, the proposed multicast
transceiver schemes yield significant SNR gains over SDR-based beamforming at
the same bit error rate level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2135</identifier>
 <datestamp>2013-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2135</id><created>2013-05-07</created><updated>2013-07-15</updated><authors><author><keyname>Glashoff</keyname><forenames>Klaus</forenames></author><author><keyname>Bronstein</keyname><forenames>Michael M.</forenames></author></authors><title>Almost-commuting matrices are almost jointly diagonalizable</title><categories>cs.NA</categories><comments>Minor corrections; results unchanged</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the relation between approximate joint diagonalization of
self-adjoint matrices and the norm of their commutator, and show that almost
commuting self-adjoint matrices are almost jointly diagonalizable by a unitary
matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2136</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2136</id><created>2013-05-09</created><authors><author><keyname>Ngo</keyname><forenames>Minh</forenames></author><author><keyname>Massacci</keyname><forenames>Fabio</forenames></author><author><keyname>Gadyatskaya</keyname><forenames>Olga</forenames></author></authors><title>MAP-REDUCE Runtime Enforcement of Information Flow Policies</title><categories>cs.CR</categories><comments>40 pages</comments><report-no>DISI-13-019</report-no><acm-class>D.4.6; D.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a flexible framework that can be easily customized to enforce a
large variety of information flow properties. Our framework combines the ideas
of secure multi-execution and map-reduce computations. The information flow
property of choice can be obtained by simply changes to a map (or reduce)
program that control parallel executions.
  We present the architecture of the enforcement mechanism and its
customizations for non-interference (NI) (from Devriese and Piessens) and some
properties proposed by Mantel, such as removal of inputs (RI) and deletion of
inputs (DI), and demonstrate formally soundness and precision of enforcement
for these properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2154</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2154</id><created>2013-05-09</created><authors><author><keyname>Pak</keyname><forenames>Igor</forenames></author><author><keyname>Yang</keyname><forenames>Jed</forenames></author></authors><title>The complexity of generalized domino tilings</title><categories>math.CO cs.CC cs.CG</categories><comments>17 pages, 16 figures</comments><msc-class>52C22 (Primary) 05B45, 68Q17 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tiling planar regions with dominoes is a classical problem in which the
decision and counting problems are polynomial. We prove a variety of hardness
results (both NP- and #P-completeness) for different generalizations of
dominoes in three and higher dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2169</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2169</id><created>2013-05-09</created><authors><author><keyname>Ely</keyname><forenames>Gregory</forenames></author><author><keyname>Aeron</keyname><forenames>Shuchin</forenames></author></authors><title>Robust Hydraulic Fracture Monitoring (HFM) of Multiple Time Overlapping
  Events Using a Generalized Discrete Radon Transform</title><categories>physics.geo-ph cs.IT math.IT stat.AP</categories><doi>10.1109/IGARSS.2012.6351517</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we propose a novel algorithm for multiple-event localization for
Hydraulic Fracture Monitoring (HFM) through the exploitation of the sparsity of
the observed seismic signal when represented in a basis consisting of space
time propagators. We provide explicit construction of these propagators using a
forward model for wave propagation which depends non-linearly on the problem
parameters - the unknown source location and mechanism of fracture, time and
extent of event, and the locations of the receivers. Under fairly general
assumptions and an appropriate discretization of these parameters we first
build an over-complete dictionary of generalized Radon propagators and assume
that the data is well represented as a linear superposition of these
propagators. Exploiting this structure we propose sparsity penalized algorithms
and workflow for super-resolution extraction of time overlapping multiple
seismic events from single well data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2170</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2170</id><created>2013-05-09</created><authors><author><keyname>Ely</keyname><forenames>Gregory</forenames></author><author><keyname>Aeron</keyname><forenames>Shuchin</forenames></author><author><keyname>Miller</keyname><forenames>Eric L.</forenames></author></authors><title>Exploiting Structural Complexity for Robust and Rapid Hyperspectral
  Imaging</title><categories>physics.geo-ph cs.IT math.IT stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents several strategies for spectral de-noising of
hyperspectral images and hypercube reconstruction from a limited number of
tomographic measurements. In particular we show that the non-noisy spectral
data, when stacked across the spectral dimension, exhibits low-rank. On the
other hand, under the same representation, the spectral noise exhibits a banded
structure. Motivated by this we show that the de-noised spectral data and the
unknown spectral noise and the respective bands can be simultaneously estimated
through the use of a low-rank and simultaneous sparse minimization operation
without prior knowledge of the noisy bands. This result is novel for for
hyperspectral imaging applications. In addition, we show that imaging for the
Computed Tomography Imaging Systems (CTIS) can be improved under limited angle
tomography by using low-rank penalization. For both of these cases we exploit
the recent results in the theory of low-rank matrix completion using nuclear
norm minimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2173</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2173</id><created>2013-05-09</created><authors><author><keyname>Maleki</keyname><forenames>Hamed</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>Optimality of Orthogonal Access for One-dimensional Convex Cellular
  Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that a greedy orthogonal access scheme achieves the sum degrees
of freedom of all one-dimensional (all nodes placed along a straight line)
convex cellular networks (where cells are convex regions) when no channel
knowledge is available at the transmitters except the knowledge of the network
topology. In general, optimality of orthogonal access holds neither for
two-dimensional convex cellular networks nor for one-dimensional non-convex
cellular networks, thus revealing a fundamental limitation that exists only
when both one-dimensional and convex properties are simultaneously enforced, as
is common in canonical information theoretic models for studying cellular
networks. The result also establishes the capacity of the corresponding class
of index coding problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2190</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2190</id><created>2013-05-09</created><authors><author><keyname>Herzen</keyname><forenames>Julien</forenames></author><author><keyname>Westphal</keyname><forenames>Cedric</forenames></author><author><keyname>Thiran</keyname><forenames>Patrick</forenames></author></authors><title>Scalable Routing Easy as PIE: a Practical Isometric Embedding Protocol
  (Technical Report)</title><categories>cs.NI</categories><comments>This work has been previously published in IEEE ICNP'11. The present
  document contains an additional optional mechanism, presented in Section
  III-D, to further improve performance by using route asymmetry. It also
  contains new simulation results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present PIE, a scalable routing scheme that achieves 100% packet delivery
and low path stretch. It is easy to implement in a distributed fashion and
works well when costs are associated to links. Scalability is achieved by using
virtual coordinates in a space of concise dimensionality, which enables greedy
routing based only on local knowledge. PIE is a general routing scheme, meaning
that it works on any graph. We focus however on the Internet, where routing
scalability is an urgent concern. We show analytically and by using simulation
that the scheme scales extremely well on Internet-like graphs. In addition, its
geometric nature allows it to react efficiently to topological changes or
failures by finding new paths in the network at no cost, yielding better
delivery ratios than standard algorithms. The proposed routing scheme needs an
amount of memory polylogarithmic in the size of the network and requires only
local communication between the nodes. Although each node constructs its
coordinates and routes packets locally, the path stretch remains extremely low,
even lower than for centralized or less scalable state-of-the-art algorithms:
PIE always finds short paths and often enough finds the shortest paths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2218</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2218</id><created>2013-05-09</created><authors><author><keyname>Zhu</keyname><forenames>Shenghuo</forenames></author></authors><title>Stochastic gradient descent algorithms for strongly convex functions at
  O(1/T) convergence rates</title><categories>cs.LG cs.AI</categories><report-no>2013-TR053</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With a weighting scheme proportional to t, a traditional stochastic gradient
descent (SGD) algorithm achieves a high probability convergence rate of
O({\kappa}/T) for strongly convex functions, instead of O({\kappa} ln(T)/T). We
also prove that an accelerated SGD algorithm also achieves a rate of
O({\kappa}/T).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2221</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2221</id><created>2013-05-09</created><authors><author><keyname>Benzarti</keyname><forenames>Faouzi</forenames></author><author><keyname>Amiri</keyname><forenames>Hamid</forenames></author></authors><title>Repairing and Inpainting Damaged Images using Diffusion Tensor</title><categories>cs.CV</categories><journal-ref>IJCSI International Journal of Computer Science Issues, Vol 9,
  Issue 4, No 3, July 2012 ISSN 1694-0814</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Removing or repairing the imperfections of a digital images or videos is a
very active and attractive field of research belonging to the image inpainting
technique. This later has a wide range of applications, such as removing
scratches in old photographic image, removing text and logos or creating
cartoon and artistic effects. In this paper, we propose an efficient method to
repair a damaged image based on a non linear diffusion tensor. The idea is to
track perfectly the local geometry of the damaged image and allowing diffusion
only in the isophotes curves direction. To illustrate the effective performance
of our method, we present some experimental results on test and real
photographic color images
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2231</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2231</id><created>2013-05-09</created><authors><author><keyname>Houston</keyname><forenames>Robin</forenames></author></authors><title>Linear Logic without Units</title><categories>cs.LO math.CT math.LO</categories><comments>PhD thesis, University of Manchester, 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study categorical models for the unitless fragment of multiplicative
linear logic. We find that the appropriate notion of model is a special kind of
promonoidal category. Since the theory of promonoidal categories has not been
developed very thoroughly, at least in the published literature, we need to
develop it here. The most natural way to do this - and the simplest, once the
(substantial) groundwork has been laid - is to consider promonoidal categories
as an instance of the general theory of pseudomonoids in a monoidal bicategory.
Accordingly, we describe and explain the notions of monoidal bicategory and
pseudomonoid therein.
  The higher-dimensional nature of monoidal bicategories presents serious
notational difficulties, since to use the natural analogue of the commutative
diagrams used in ordinary category theory would require the use of
three-dimensional diagrams. We therefore introduce a novel technical device,
which we dub the calculus of components, that simplifies the business of
reasoning about a certain class of algebraic structure internal to a monoidal
bicategory. When viewed through this simplifying lens, the theory of
pseudomonoids turns out to be essentially formally identical to the ordinary
theory of monoidal categories. We indicate how the calculus of components may
be extended to cover structures that make use of the braiding in a braided
monoidal bicategory, and use this to study braided pseudomonoids.
  A higher-dimensional analogue of Cayley's theorem is proved, and used to
deduce a novel characterisation of the unit of a promonoidal category. This,
and the other preceding work, is then used to give two characterisations of the
categories that model the unitless fragment of intuitionistic multiplicative
linear logic. Finally we consider the non-intuitionistic case, where the second
characterisation in particular takes a surprisingly simple form.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2233</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2233</id><created>2013-05-09</created><authors><author><keyname>Bai</keyname><forenames>Tianyang</forenames></author><author><keyname>Heath,</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Asymptotic Coverage Probability and Rate in Massive MIMO Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Wireless Communications Letters, May 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive multiple-input multiple-output (MIMO) is a transmission technique for
cellular systems that uses many antennas to support not-as-many users. Thus
far, the performance of massive MIMO has only been examined in finite cellular
networks. In this letter, we analyze its performance in random cellular
networks with Poisson distributed base station locations. Specifically, we
provide analytical expressions for the asymptotic coverage probability and rate
in both downlink and uplink when each base station has a large number of
antennas. The results show that, though limited by pilot contamination, massive
MIMO can provide significantly higher asymptotic data rate per user than the
single-antenna network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2245</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2245</id><created>2013-05-09</created><authors><author><keyname>Eckford</keyname><forenames>Andrew W.</forenames></author><author><keyname>Thomas</keyname><forenames>Peter J.</forenames></author></authors><title>Capacity of a Simple Intercellular Signal Transduction Channel</title><categories>cs.IT math.IT q-bio.CB</categories><comments>5 pages, 1 figure. To appear in the 2013 IEEE International Symposium
  on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We model the ligand-receptor molecular communication channel with a
discrete-time Markov model, and show how to obtain the capacity of this
channel. We show that the capacity-achieving input distribution is iid;
further, unusually for a channel with memory, we show that feedback does not
increase the capacity of this channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2251</identifier>
 <datestamp>2015-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2251</id><created>2013-05-09</created><updated>2015-07-17</updated><authors><author><keyname>Srivastava</keyname><forenames>Madhur</forenames></author><author><keyname>Moulick</keyname><forenames>Subhayan R.</forenames></author><author><keyname>Panigrahi</keyname><forenames>Prasanta K.</forenames></author></authors><title>Quantum Image Representation Through Two-Dimensional Quantum States and
  Normalized Amplitude</title><categories>cs.MM quant-ph</categories><comments>5 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel method for image representation in quantum computers,
which uses the two-dimensional (2-D) quantum states to locate each pixel in an
image through row-location and column-location vectors for identifying each
pixel location. The quantum state of an image is the linear superposition of
the tensor product of the m-qubits row-location vector and the n-qubits
column-location vector of each pixel. It enables the natural quantum
representation of rectangular images that other methods lack. The
amplitude/intensity of each pixel is incorporated into the coefficient values
of the pixel's quantum state, without using any qubits. Due to the fact that
linear superposition, tensor product and qubits form the fundamental basis of
quantum computing, the proposed method presents the machine level
representation of images on quantum computers. Unlike other methods, this
method is a pure quantum representation without any classical components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2254</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2254</id><created>2013-05-10</created><authors><author><keyname>Wang</keyname><forenames>William Yang</forenames></author><author><keyname>Mazaitis</keyname><forenames>Kathryn</forenames></author><author><keyname>Cohen</keyname><forenames>William W.</forenames></author></authors><title>Programming with Personalized PageRank: A Locally Groundable First-Order
  Probabilistic Logic</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many probabilistic first-order representation systems, inference is
performed by &quot;grounding&quot;---i.e., mapping it to a propositional representation,
and then performing propositional inference. With a large database of facts,
groundings can be very large, making inference and learning computationally
expensive. Here we present a first-order probabilistic language which is
well-suited to approximate &quot;local&quot; grounding: every query $Q$ can be
approximately grounded with a small graph. The language is an extension of
stochastic logic programs where inference is performed by a variant of
personalized PageRank. Experimentally, we show that the approach performs well
without weight learning on an entity resolution task; that supervised
weight-learning improves accuracy; and that grounding time is independent of DB
size. We also show that order-of-magnitude speedups are possible by
parallelizing learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2265</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2265</id><created>2013-05-10</created><authors><author><keyname>Khouadjia</keyname><forenames>Mostepha Redouane</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author><author><keyname>Vidal</keyname><forenames>Vincent</forenames><affiliation>DCSD</affiliation></author><author><keyname>Dr&#xe9;o</keyname><forenames>Johann</forenames><affiliation>TRT</affiliation></author><author><keyname>Sav&#xe9;ant</keyname><forenames>Pierre</forenames><affiliation>TRT</affiliation></author></authors><title>Quality Measures of Parameter Tuning for Aggregated Multi-Objective
  Temporal Planning</title><categories>cs.AI</categories><comments>arXiv admin note: substantial text overlap with arXiv:1305.1169</comments><proxy>ccsd</proxy><journal-ref>LION7 - Learning and Intelligent OptimizatioN Conference (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parameter tuning is recognized today as a crucial ingredient when tackling an
optimization problem. Several meta-optimization methods have been proposed to
find the best parameter set for a given optimization algorithm and (set of)
problem instances. When the objective of the optimization is some scalar
quality of the solution given by the target algorithm, this quality is also
used as the basis for the quality of parameter sets. But in the case of
multi-objective optimization by aggregation, the set of solutions is given by
several single-objective runs with different weights on the objectives, and it
turns out that the hypervolume of the final population of each single-objective
run might be a better indicator of the global performance of the aggregation
method than the best fitness in its population. This paper discusses this issue
on a case study in multi-objective temporal planning using the evolutionary
planner DaE-YAHSP and the meta-optimizer ParamILS. The results clearly show how
ParamILS makes a difference between both approaches, and demonstrate that
indeed, in this context, using the hypervolume indicator as ParamILS target is
the best choice. Other issues pertaining to parameter tuning in the proposed
context are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2269</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2269</id><created>2013-05-10</created><authors><author><keyname>Wang</keyname><forenames>Fang</forenames></author><author><keyname>Li</keyname><forenames>Yi</forenames></author></authors><title>Beyond Physical Connections: Tree Models in Human Pose Estimation</title><categories>cs.CV</categories><comments>CVPR 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Simple tree models for articulated objects prevails in the last decade.
However, it is also believed that these simple tree models are not capable of
capturing large variations in many scenarios, such as human pose estimation.
This paper attempts to address three questions: 1) are simple tree models
sufficient? more specifically, 2) how to use tree models effectively in human
pose estimation? and 3) how shall we use combined parts together with single
parts efficiently?
  Assuming we have a set of single parts and combined parts, and the goal is to
estimate a joint distribution of their locations. We surprisingly find that no
latent variables are introduced in the Leeds Sport Dataset (LSP) during
learning latent trees for deformable model, which aims at approximating the
joint distributions of body part locations using minimal tree structure. This
suggests one can straightforwardly use a mixed representation of single and
combined parts to approximate their joint distribution in a simple tree model.
As such, one only needs to build Visual Categories of the combined parts, and
then perform inference on the learned latent tree. Our method outperformed the
state of the art on the LSP, both in the scenarios when the training images are
from the same dataset and from the PARSE dataset. Experiments on animal images
from the VOC challenge further support our findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2275</identifier>
 <datestamp>2014-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2275</id><created>2013-05-10</created><updated>2014-06-03</updated><authors><author><keyname>Choi</keyname><forenames>Jinho</forenames></author><author><keyname>Yu</keyname><forenames>Seung Min</forenames></author><author><keyname>Kim</keyname><forenames>Seong-Lyun</forenames></author></authors><title>Spreading Information in Mobile Wireless Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Device-to-device (D2D) communication enables us to spread information in the
local area without infrastructure support. In this paper, we focus on
information spreading in mobile wireless networks where all nodes move around.
The source nodes deliver a given information packet to mobile users using D2D
communication as an underlay to the cellular uplink. By stochastic geometry, we
derive the average number of nodes that have successfully received a given
information packet as a function of the transmission power and the number of
transmissions. Based on these results, we formulate a redundancy minimization
problem under the maximum transmission power and delay constraints. By solving
the problem, we provide an optimal rule for the transmission power of the
source node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2276</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2276</id><created>2013-05-10</created><authors><author><keyname>Sozcu</keyname><forenames>Omer Faruk</forenames></author><author><keyname>Ziatdinov</keyname><forenames>Rushan</forenames></author><author><keyname>Ipek</keyname><forenames>Ismail</forenames></author></authors><title>The effects of computer assisted and distance learning of geometric
  modelling</title><categories>cs.CY cs.GR</categories><journal-ref>European Researcher 39(1-2), 175-181, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The effects of computer-assisted and distance learning of geometric modeling
and computer aided geometric design are studied. It was shown that computer
algebra systems and dynamic geometric environments can be considered as
excellent tools for teaching mathematical concepts of mentioned areas, and
distance education technologies would be indispensable for consolidation of
successfully passed topics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2283</identifier>
 <datestamp>2014-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2283</id><created>2013-05-10</created><authors><author><keyname>Wen</keyname><forenames>Chengfeng</forenames></author><author><keyname>Lui</keyname><forenames>Lok Ming</forenames></author></authors><title>Geometric Registration of High-genus Surfaces</title><categories>cs.CG cs.GR math.DG</categories><journal-ref>SIAM Journal on Imaging Sciences. 2014 7:1, 337-365</journal-ref><doi>10.1137/130932053</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a method to obtain geometric registrations between
high-genus ($g\geq 1$) surfaces. Surface registration between simple surfaces,
such as simply-connected open surfaces, has been well studied. However, very
few works have been carried out for the registration of high-genus surfaces.
The high-genus topology of the surface poses great challenge for surface
registration. A possible approach is to partition surfaces into
simply-connected patches and registration is done patch by patch. Consistent
cuts are required, which are usually difficult to obtain and prone to error. In
this work, we propose an effective way to obtain geometric registration between
high-genus surfaces without introducing consistent cuts. The key idea is to
conformally parameterize the surface into its universal covering space, which
is either the Euclidean plane or the hyperbolic disk embedded in
$\mathbb{R}^2$. Registration can then be done on the universal covering space
by minimizing a shape mismatching energy measuring the geometric dissimilarity
between the two surfaces. Our proposed algorithm effectively computes a smooth
registration between high-genus surfaces that matches geometric information as
much as possible. The algorithm can also be applied to find a smooth and
bijective registration minimizing any general energy functionals. Numerical
experiments on high-genus surface data show that our proposed method is
effective for registering high-genus surfaces with geometric matching. We also
applied the method to register anatomical structures for medical imaging, which
demonstrates the usefulness of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2295</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2295</id><created>2013-05-10</created><authors><author><keyname>Gleissenthall</keyname><forenames>Klaus v.</forenames></author><author><keyname>Rybalchenko</keyname><forenames>Andrey</forenames></author></authors><title>An Epistemic Perspective on Consistency of Concurrent Computations</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consistency properties of concurrent computations, e.g., sequential
consistency, linearizability, or eventual consistency, are essential for
devising correct concurrent algorithms. In this paper, we present a logical
formalization of such consistency properties that is based on a standard logic
of knowledge. Our formalization provides a declarative perspective on what is
imposed by consistency requirements and provides some interesting unifying
insight on differently looking properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2299</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2299</id><created>2013-05-10</created><authors><author><keyname>Bialkowski</keyname><forenames>Joshua</forenames></author><author><keyname>Otte</keyname><forenames>Michael</forenames></author><author><keyname>Frazzoli</keyname><forenames>Emilio</forenames></author></authors><title>Fast Collision Checking: From Single Robots to Multi-Robot Teams</title><categories>cs.RO cs.AI cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine three different algorithms that enable the collision certificate
method from [Bialkowski, et al.] to handle the case of a centralized
multi-robot team. By taking advantage of symmetries in the configuration space
of multi-robot teams, our methods can significantly reduce the number of
collision checks vs. both [Bialkowski, et al.] and standard collision checking
implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2306</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2306</id><created>2013-05-10</created><authors><author><keyname>Jegatheesan</keyname><forenames>Sowmyan</forenames></author></authors><title>Cookies Invading Our Privacy for Marketing Advertising and Security
  Issues</title><categories>cs.CY cs.CR</categories><comments>8 Pages, International Journal of Scientific and Engineering Research
  Volume 4, Issue 5, May 2013, ISSN 2229-5518</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Privacy has been a major concern for everybody over the internet. Governments
across the globe have given their views on how the internet space can be
managed effectively so that there is some control on the flow of confidential
information and privacy to users and as well as to data is achieved. Taking
advantage of the lack of one unified body that could govern the online space
with its strict and stringent rules certain websites use the text files called
cookies in collecting data from users and using them for marketing them in
advertisements networks and third party websites with the help of JavaScript
and flash technologies. Even before many of us think what is happening around
us in the online usage we are being invaded by the cookies and are targeted
with their specific information that could tempt us to buy a product or service
to which we were longing for in the recent past. Though it may be argued its a
kind of marketing strategy to give the customer what he wants but it can no way
be something like the user is just being targeted because he has already shown
interest in something and he should be disturbed until he gets hold of
something. Its purely a security breach as most of the websites dont ask
permission for the usage of cookies and setting them into the users browser and
the most important thing is no privacy statement is issued that the information
is used for targeted marketing. This analysis paper has views from different
sources, an example of such an activity that is a potential security breach and
various other information of what these sites do to use the deadly cookies for
commercial tricks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2319</identifier>
 <datestamp>2013-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2319</id><created>2013-05-10</created><authors><author><keyname>Elkhatib</keyname><forenames>Yehia</forenames></author><author><keyname>Blair</keyname><forenames>Gordon S.</forenames></author><author><keyname>Surajbali</keyname><forenames>Bholanathsingh</forenames></author></authors><title>Experiences of Using a Hybrid Cloud to Construct an Environmental
  Virtual Observatory</title><categories>cs.DC</categories><journal-ref>In Proceedings of the Third Workshop on Cloud Data and Platforms
  (a EuroSys 2013 workshop), Prague, Czech Republic, April 14 2013</journal-ref><doi>10.1145/2460756.2460759</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Environmental science is often fragmented: data is collected using mismatched
formats and conventions, and models are misaligned and run in isolation. Cloud
computing offers a lot of potential in the way of resolving such issues by
supporting data from different sources and at various scales, by facilitating
the integration of models to create more sophisticated software services, and
by providing a sustainable source of suitable computational and storage
resources. In this paper, we highlight some of our experiences in building the
Environmental Virtual Observatory pilot (EVOp), a tailored cloud-based
infrastructure and associated web-based tools designed to enable users from
different backgrounds to access data concerning different environmental issues.
We review our architecture design, the current deployment and prototypes. We
also reflect on lessons learned. We believe that such experiences are of
benefit to other scientific communities looking to assemble virtual
observatories or similar virtual research environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2322</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2322</id><created>2013-05-10</created><authors><author><keyname>Razanamanampisoa</keyname><forenames>Harimalala</forenames><affiliation>PIMENT</affiliation></author><author><keyname>Randriamanantany</keyname><forenames>Zely Arivelo</forenames><affiliation>PIMENT</affiliation></author><author><keyname>Rakotondramiarana</keyname><forenames>Hery Tiana</forenames><affiliation>PIMENT</affiliation></author><author><keyname>Garde</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>PIMENT</affiliation></author><author><keyname>Boyer</keyname><forenames>Harry</forenames><affiliation>PIMENT</affiliation></author></authors><title>Simulation of a typical house in the region of Antananarivo, Madagascar.
  Determination of passive solutions using local materials</title><categories>cs.CE</categories><proxy>ccsd</proxy><journal-ref>3rd International Madagascar Conference in High-Energy Physics
  (HEP-MAD 07), Antanarivo : Madagascar (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with new proposals for the design of passive solutions
adapted to the climate of the highlands of Madagascar. While the strongest
population density is located in the central highlands, the problem of thermal
comfort in buildings occurs mainly during winter time. Currently, people use
raw wood to warm the poorly designed houses. This leads to a large scale
deforestation of the areas and causes erosion and environmental problems. The
methodology used consisted of the identification of a typical building and of a
typical meteorological year. Simulations were carried out using a thermal and
airflow software (CODYRUN) to improve each building component (roof, walls,
windows, and soil) in such a way as to estimate the influence of some technical
solutions on each component in terms of thermal comfort. The proposed solutions
also took into account the use of local materials and the standard of living of
the country.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2350</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2350</id><created>2013-05-10</created><authors><author><keyname>Hoefer</keyname><forenames>Martin</forenames></author><author><keyname>Kesselheim</keyname><forenames>Thomas</forenames></author></authors><title>Universally Truthful Secondary Spectrum Auctions</title><categories>cs.GT</categories><comments>17 pages, brief announcement in SPAA'13</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present algorithms for implementing local spectrum redistribution in
wireless networks using a mechanism design approach. For example, in single-hop
request scheduling, secondary users are modeled as rational agents that have
private utility when getting assigned a channel for successful transmission. We
present a rather simple algorithmic technique that allows to turn existing and
future approximation algorithms and heuristics into truthful mechanisms for a
large variety of networking problems. In contrast to previous work, our
approach works for virtually all known interference models in the literature,
including the physical model of interference based on SINR. It allows to
address single-hop and multi-hop scheduling, routing, and even more general
assignment and allocation problems. Our mechanisms are randomized and represent
the first universally-truthful mechanisms for these problems with rigorous
worst-case guarantees on the solution quality. In this way, our mechanisms can
be used to obtain guaranteed solution quality even with risk-averse or
risk-seeking bidders, for which existing approaches fail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2352</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2352</id><created>2013-05-09</created><authors><author><keyname>Makhijani</keyname><forenames>Rashmi</forenames></author><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author><author><keyname>Thakare</keyname><forenames>V M</forenames></author></authors><title>Speech Enhancement Using Pitch Detection Approach For Noisy Environment</title><categories>cs.SD cs.CL</categories><comments>Pages: 06 Figures : 05</comments><journal-ref>International Journal of Engineering Science and Technology
  (IJEST), 2011, ISSN : 0975-5462 Vol. 3 No. 2, pp 1764-1769</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acoustical mismatch among training and testing phases degrades outstandingly
speech recognition results. This problem has limited the development of
real-world nonspecific applications, as testing conditions are highly variant
or even unpredictable during the training process. Therefore the background
noise has to be removed from the noisy speech signal to increase the signal
intelligibility and to reduce the listener fatigue. Enhancement techniques
applied, as pre-processing stages; to the systems remarkably improve
recognition results. In this paper, a novel approach is used to enhance the
perceived quality of the speech signal when the additive noise cannot be
directly controlled. Instead of controlling the background noise, we propose to
reinforce the speech signal so that it can be heard more clearly in noisy
environments. The subjective evaluation shows that the proposed method improves
perceptual quality of speech in various noisy environments. As in some cases
speaking may be more convenient than typing, even for rapid typists: many
mathematical symbols are missing from the keyboard but can be easily spoken and
recognized. Therefore, the proposed system can be used in an application
designed for mathematical symbol recognition (especially symbols not available
on the keyboard) in schools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2353</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2353</id><created>2013-05-10</created><authors><author><keyname>Hogg</keyname><forenames>Jonathan</forenames></author><author><keyname>Scott</keyname><forenames>Jennifer</forenames></author></authors><title>Compressed threshold pivoting for sparse symmetric indefinite systems</title><categories>math.NA cs.DC cs.NA</categories><comments>Submitted to SIMAX</comments><report-no>STFC Preprint Series RAL-P-2013-007</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A key technique for controlling numerical stability in sparse direct solvers
is threshold partial pivoting. When selecting a pivot, the entire candidate
pivot column below the diagonal must be up-to-date and must be scanned. If the
factorization is parallelized across a large number of cores, communication
latencies can be the dominant computational cost.
  In this paper, we propose two alternative pivoting strategies for sparse
symmetric indefinite matrices that significantly reduce communication by
compressing the necessary data into a small matrix that can be used to select
pivots. Once pivots have been chosen, they can be applied in a
communication-efficient fashion.
  For an n x p submatrix on P processors, we show our methods perform a
factorization using O(log P) messages instead of the O(p log P) for threshold
partial pivoting. The additional costs in terms of operations and communication
bandwidth are relatively small.
  A stability proof is given and numerical results using a range of symmetric
indefinite matrices arising from practical problems are used to demonstrate the
practical robustness. Timing results on large random examples illustrate the
potential speedup on current multicore machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2357</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2357</id><created>2013-05-10</created><authors><author><keyname>Starnini</keyname><forenames>Michele</forenames></author><author><keyname>Machens</keyname><forenames>Anna</forenames></author><author><keyname>Cattuto</keyname><forenames>Ciro</forenames></author><author><keyname>Barrat</keyname><forenames>Alain</forenames></author><author><keyname>Satorras</keyname><forenames>Romualdo Pastor</forenames></author></authors><title>Immunization strategies for epidemic processes in time-varying contact
  networks</title><categories>physics.soc-ph cs.SI q-bio.PE</categories><journal-ref>J. Theor. Biol. 337:89-100 (2013)</journal-ref><doi>10.1016/j.jtbi.2013.07.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spreading processes represent a very efficient tool to investigate the
structural properties of networks and the relative importance of their
constituents, and have been widely used to this aim in static networks. Here we
consider simple disease spreading processes on empirical time-varying networks
of contacts between individuals, and compare the effect of several immunization
strategies on these processes. An immunization strategy is defined as the
choice of a set of nodes (individuals) who cannot catch nor transmit the
disease. This choice is performed according to a certain ranking of the nodes
of the contact network. We consider various ranking strategies, focusing in
particular on the role of the training window during which the nodes'
properties are measured in the time-varying network: longer training windows
correspond to a larger amount of information collected and could be expected to
result in better performances of the immunization strategies. We find instead
an unexpected saturation in the efficiency of strategies based on nodes'
characteristics when the length of the training window is increased, showing
that a limited amount of information on the contact patterns is sufficient to
design efficient immunization strategies. This finding is balanced by the large
variations of the contact patterns, which strongly alter the importance of
nodes from one period to the next and therefore significantly limit the
efficiency of any strategy based on an importance ranking of nodes. We also
observe that the efficiency of strategies that include an element of randomness
and are based on temporally local information do not perform as well but are
largely independent on the amount of information available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2362</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2362</id><created>2013-05-10</created><authors><author><keyname>Wipf</keyname><forenames>David</forenames></author><author><keyname>Zhang</keyname><forenames>Haichao</forenames></author></authors><title>Revisiting Bayesian Blind Deconvolution</title><categories>cs.CV cs.LG stat.ML</categories><comments>This paper has been submitted to JMLR. A conference version will
  appear at EMMCVPR 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blind deconvolution involves the estimation of a sharp signal or image given
only a blurry observation. Because this problem is fundamentally ill-posed,
strong priors on both the sharp image and blur kernel are required to
regularize the solution space. While this naturally leads to a standard MAP
estimation framework, performance is compromised by unknown trade-off parameter
settings, optimization heuristics, and convergence issues stemming from
non-convexity and/or poor prior selections. To mitigate some of these problems,
a number of authors have recently proposed substituting a variational Bayesian
(VB) strategy that marginalizes over the high-dimensional image space leading
to better estimates of the blur kernel. However, the underlying cost function
now involves both integrals with no closed-form solution and complex,
function-valued arguments, thus losing the transparency of MAP. Beyond standard
Bayesian-inspired intuitions, it thus remains unclear by exactly what mechanism
these methods are able to operate, rendering understanding, improvements and
extensions more difficult. To elucidate these issues, we demonstrate that the
VB methodology can be recast as an unconventional MAP problem with a very
particular penalty/prior that couples the image, blur kernel, and noise level
in a principled way. This unique penalty has a number of useful characteristics
pertaining to relative concavity, local minima avoidance, and scale-invariance
that allow us to rigorously explain the success of VB including its existing
implementational heuristics and approximations. It also provides strict
criteria for choosing the optimal image prior that, perhaps
counter-intuitively, need not reflect the statistics of natural scenes. In so
doing we challenge the prevailing notion of why VB is successful for blind
deconvolution while providing a transparent platform for introducing
enhancements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2369</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2369</id><created>2013-04-22</created><authors><author><keyname>Virmani</keyname><forenames>Deepali</forenames></author><author><keyname>Talwar</keyname><forenames>Dhruv</forenames></author><author><keyname>Dhingra</keyname><forenames>Arun</forenames></author><author><keyname>Bahl</keyname><forenames>Tushar</forenames></author></authors><title>Priority Based Energy-Efficient Data Forwarding Algorithm in Wireless
  Sensor Networks</title><categories>cs.NI</categories><comments>4 pages, 2 figures, International Journal of Advances in Computer
  Networks and its Security - IJCNS, Volume 1 : Issue 1, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Wireless Sensor Network(WSN) can be described as a collection of untethered
sensor nodes. An important application of WSNs is in the field of real-time
communication. Real-time communication is a critical service which requires a
qualitative routing protocol for energy-efficient network communication. The
judicious use of energy of the network nodes is essential and important for
sustainability and longevity of a WSN. This paper proposes an algorithm namely
Priority-Energy Based Data Forwarding Algorithm(PEDF) which empowers the node
to choose the most suitable packet forwarding path, based on the priority of
the packet and the current energy status of the forwarding node. The algorithm
hence dynamically adapts to the prevailing energy-scenario of the network and
takes routing decisions accordingly, based on packet priority. Minimizing
delay, minimizing energy utilization, maximizing throughput and maximizing
network lifetime are the key elements of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2370</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2370</id><created>2013-04-22</created><authors><author><keyname>Virmani</keyname><forenames>Deepali</forenames></author><author><keyname>Jain</keyname><forenames>Satbir</forenames></author></authors><title>Scalable, Robust and Real Time Communication Architecture For Wireless
  Sensor Networks</title><categories>cs.NI</categories><comments>Journal of Information Knowledge and Research in Computer
  Engineering, 2008. arXiv admin note: text overlap with arXiv:1107.4054 by
  other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose wireless sensor network architecture with layered
protocols, targeting different aspects of the awareness requirements in
wireless sensor networks. Under such a unified framework, we pay special
attention to the most important awareness issues in wireless sensor networks:
namely dynamic awareness, energy awareness and spatiotemporal awareness. First,
we propose the spatiotemporal aware routing protocol for wireless sensor
networks, which maintains a constant delivery speed for soft real-time
communication. Second, we introduce the time-energy aware aggregation scheme,
which increases the degree of aggregation and reduces energy consumption
without jeopardizing the end-to-end delay. It is the data aggregation scheme to
take the timely delivery of messages as well as protocol overhead into account
to adjust aggregation strategies adaptively in accordance with assessed traffic
conditions and expected wireless sensor network requirements. Third, we also
deal with dynamic awareness by proposing a new communication category based on
a lazy-binding concept. The evaluation of this integrated architecture
demonstrates its performance composability and its capability to be tailored
for applications with different awareness requirements. We believe that the
integrated architecture, supporting various kinds of awareness requirements,
lays a foundation for overall wireless sensor network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2384</identifier>
 <datestamp>2013-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2384</id><created>2013-05-07</created><updated>2013-07-16</updated><authors><author><keyname>Glashoff</keyname><forenames>Klaus</forenames></author><author><keyname>Bronstein</keyname><forenames>Michael M.</forenames></author></authors><title>Asymptotic metrics on the space of matrices under the commutation
  relation</title><categories>cs.NA math.NA</categories><comments>Minor correction; results unchanged</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the norm of the commutator defines &quot;almost a metric&quot; on the
quotient space of commuting matrices, in the sense that it is a semi-metric
satisfying the triangle inequality asymptotically for large matrices drawn from
a &quot;good&quot; distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2386</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2386</id><created>2013-05-10</created><authors><author><keyname>Ramezanian</keyname><forenames>Mohammad Ali Javidian Rasoul</forenames></author></authors><title>Disappointment in Social Choice Protocols</title><categories>cs.MA</categories><comments>15 pages</comments><msc-class>91B14</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social choice theory is a theoretical framework for analysis of combining
individual preferences, interests, or welfare to reach a collective decision or
social welfare in some sense. We introduce a new criterion for social choice
protocols called social disappointment. Social disappointment happens when the
outcome of a voting system occurs for those alternatives which are at the end
of at least half of individual preference profiles. Here we introduce some
protocols that prevent social disappointment and prove an impossibility theorem
based on this key concept.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2387</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2387</id><created>2013-05-10</created><authors><author><keyname>Liao</keyname><forenames>Jianxin</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author><author><keyname>Zhu</keyname><forenames>Xiaomin</forenames></author><author><keyname>Wang</keyname><forenames>Jingyu</forenames></author><author><keyname>Liao</keyname><forenames>Minyan</forenames></author></authors><title>Loss Rate Based Fountain Codes for Data Transfer</title><categories>cs.NI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fountain codes are becoming increasingly important for data transferring over
dedicated high-speed long-distance network. However, the encoding and decoding
complexity of traditional fountain codes such as LT and Raptor codes are still
high. In this paper, a new fountain codes named LRF (Loss Rate Based Fountain)
codes for data transfer is proposed. In order to improve the performance of
encoding and decoding efficiency and decrease the number of redundant encoding
symbols, an innovative degree distribution instead of robust soliton degree
distribution in LT (Luby Transfer) codes is proposed. In LRF codes, the degree
of encoding symbol is decided by loss rate property, and the window size is
extended dynamic. Simulations result using LRF codes show that the proposed
method has better performance in term of encoding ratio, degree ratio, encoding
and decoding efficiency with respect to LT and Raptor codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2388</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2388</id><created>2013-04-01</created><authors><author><keyname>Parsazad</keyname><forenames>Shafigh</forenames></author><author><keyname>Saboori</keyname><forenames>Ehsan</forenames></author><author><keyname>Allahyar</keyname><forenames>Amin</forenames></author></authors><title>Fast Feature Reduction in intrusion detection datasets</title><categories>cs.CR cs.LG</categories><journal-ref>Parsazad, Shafigh; Saboori, Ehsan; Allahyar, Amin; , &quot;Fast Feature
  Reduction in intrusion detection datasets,&quot; MIPRO, 2012 Proceedings of the
  35th International Convention , vol., no., pp.1023-1029, 21-25 May 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the most intrusion detection systems (IDS), a system tries to learn
characteristics of different type of attacks by analyzing packets that sent or
received in network. These packets have a lot of features. But not all of them
is required to be analyzed to detect that specific type of attack. Detection
speed and computational cost is another vital matter here, because in these
types of problems, datasets are very huge regularly. In this paper we tried to
propose a very simple and fast feature selection method to eliminate features
with no helpful information on them. Result faster learning in process of
redundant feature omission. We compared our proposed method with three most
successful similarity based feature selection algorithm including Correlation
Coefficient, Least Square Regression Error and Maximal Information Compression
Index. After that we used recommended features by each of these algorithms in
two popular classifiers including: Bayes and KNN classifier to measure the
quality of the recommendations. Experimental result shows that although the
proposed method can't outperform evaluated algorithms with high differences in
accuracy, but in computational cost it has huge superiority over them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2391</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2391</id><created>2013-04-12</created><authors><author><keyname>Tadaki</keyname><forenames>Kohtaro</forenames></author><author><keyname>Doi</keyname><forenames>Norihisa</forenames></author></authors><title>Cryptography and Algorithmic Randomness</title><categories>cs.CR</categories><comments>34 pages, LaTeX2e, no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The secure instantiation of the random oracle is one of the major open
problems in modern cryptography. We investigate this problem using concepts and
methods of algorithmic randomness. In modern cryptography, the random oracle
model is widely used as an imaginary framework in which the security of a
cryptographic scheme is discussed. In the random oracle model, the
cryptographic hash function used in a cryptographic scheme is formulated as a
random variable uniformly distributed over all possibility of the function,
called the random oracle. The main result of this paper is to show that, for
any secure signature scheme in the random oracle model, there exists a specific
computable function which can instantiate the random oracle while keeping the
security originally proved in the random oracle model. In modern cryptography
the generic group model is used also for a similar purpose to the random oracle
model. We show that the same results hold for the generic group model. In the
process of proving the results, we introduce the notion of effective security,
demonstrating the importance of this notion in modern cryptography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2395</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2395</id><created>2013-05-10</created><authors><author><keyname>Kubota</keyname><forenames>Toshiro</forenames></author><author><keyname>Ranck</keyname><forenames>Jessica</forenames></author><author><keyname>Acker</keyname><forenames>Briley</forenames></author><author><keyname>De Haan</keyname><forenames>Herman</forenames></author></authors><title>Shape Reconstruction and Recognition with Isolated Non-directional Cues</title><categories>cs.CV</categories><comments>28 pages, 14 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper investigates a hypothesis that our visual system groups visual cues
based on how they form a surface, or more specifically triangulation derived
from the visual cues. To test our hypothesis, we compare shape recognition with
three different representations of visual cues: a set of isolated dots
delineating the outline of the shape, a set of triangles obtained from Delaunay
triangulation of the set of dots, and a subset of Delaunay triangles excluding
those outside of the shape. Each participant was assigned to one particular
representation type and increased the number of dots (and consequentially
triangles) until the underlying shape could be identified. We compare the
average number of dots needed for identification among three types of
representations. Our hypothesis predicts that the results from the three
representations will be similar. However, they show statistically significant
differences. The paper also presents triangulation based algorithms for
reconstruction and recognition of a shape from a set of isolated dots.
Experiments showed that the algorithms were more effective and perceptually
agreeable than similar contour based ones. From these experiments, we conclude
that triangulation does affect our shape recognition. However, the surface
based approach presents a number of computational advantages over the contour
based one and should be studied further.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2398</identifier>
 <datestamp>2013-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2398</id><created>2013-05-10</created><updated>2013-12-10</updated><authors><author><keyname>Ziane</keyname><forenames>Mikal</forenames></author><author><keyname>Cinn&#xe9;ide</keyname><forenames>Mel &#xd3;</forenames></author></authors><title>The Case for Explicit Coupling Constraints</title><categories>cs.SE</categories><comments>to be submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A software element defined in one place is typically used in many places.
When it is changed, all its occurrences may need to be changed too, which can
severely hinder software evolution. This has led to the support of
encapsulation in modern programming languages. Unfortunately, as is shown in
this paper, this is not enough to express all the constraints that are needed
to decouple programming elements that evolve at different paces.
  In this paper we show that: a language can be defined to easily express very
general coupling constraints; violations to these constraints can be detected
automatically. We then demonstrate several places where the need for coupling
constraints arose in open-source Java projects. These constraints were
expressed in comments when explicit constraints would have enabled automatic
treatment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2401</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2401</id><created>2013-05-10</created><authors><author><keyname>Lozano</keyname><forenames>George A.</forenames></author></authors><title>Ethics of using language editing services in an era of digital
  communication and heavily multiauthored papers</title><categories>physics.soc-ph cs.DL</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scientists of many countries in which English is not the primary language
routinely use a variety of manuscript preparation, correction or editing
services, a practice that is openly endorsed by many journals and scientific
institutions. These services vary tremendously in their scope; at one end there
is simple proof-reading, and at the other extreme there is in-depth and
extensive peer-reviewing, proposal preparation, statistical analyses,
re-writing and co-writing. In this paper, the various types of service are
reviewed, along with authorship guidelines, and the question is raised of
whether the high-end services surpass most guidelines' criteria for authorship.
Three other factors are considered. First, the ease of collaboration possible
in the internet era allows multiple iterations between authors and the editing
service, so essentially, papers can be co-written. Second, 'editing services'
often offer subject-specific experts who comment not only on the language, but
interpret and improve scientific content. Third, the trend towards heavily
multi-authored papers implies that the threshold necessary to earn authorship
is declining. The inevitable conclusion is that at some point the contributions
by 'editing services' should be deemed sufficient to warrant authorship. Trying
to enforce any guidelines would likely be futile, but nevertheless, it might be
time to revisit the ethics of using some of the high-end 'editing services'. In
an increasingly international job market, recognizing this problem might prove
progressively more important in authorship disputes, the allocation of research
grants, and hiring decisions
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2402</identifier>
 <datestamp>2015-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2402</id><created>2013-05-10</created><updated>2014-12-30</updated><authors><author><keyname>Cusick</keyname><forenames>James</forenames></author></authors><title>Architecture and Production Readiness Reviews in Practice</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detailed description of procedures around architecture reviews. In order to
succeed in building and deploying complex software solutions, an architecture
is essential. For many in the industry structured reviews of these
architectures is also de rigor. Practices for such reviews have been developed
and reported on for years. One aspect that does not receive as much attention
but is no less important is the relationship between these architectures and
the requirements for deploying them into production environments. At Wolters
Kluwer's Corporate Legal Services we first established a typical architecture
review process and then established a two phase production preparation review
process. This paper describes in detail how these practices work and some of
the technical results of these reviews including the frequency and style of the
reviews, the process automation around them, and the number and nature of some
of the technical flaws eliminated by enforcing these reviews. This paper lays
the ground work for others who would be interested in following similar
practices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2415</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2415</id><created>2013-05-10</created><authors><author><keyname>Bouneffouf</keyname><forenames>Djallel</forenames></author></authors><title>Exponentiated Gradient LINUCB for Contextual Multi-Armed Bandits</title><categories>cs.AI</categories><acm-class>I.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present Exponentiated Gradient LINUCB, an algorithm for con-textual
multi-armed bandits. This algorithm uses Exponentiated Gradient to find the
optimal exploration of the LINUCB. Within a deliberately designed offline
simulation framework we conduct evaluations with real online event log data.
The experimental results demonstrate that our algorithm outperforms surveyed
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2426</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2426</id><created>2013-05-10</created><authors><author><keyname>Moreau</keyname><forenames>Thierry</forenames></author></authors><title>Towards a Better Approximation of Full Domain Hash - or - The Reef and
  Shoal Integrity Arrangement</title><categories>cs.CR</categories><report-no>C005404</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For RSA and Rabin-Williams public key digital signatures, proper message
hashing and padding procedures are critical to the overall digital signature
security. The theoretical work in this field coined the term `full domain hash'
for a conceptually simple approach, a message hashing step with an output value
as large as the signature public modulus. The practitioners learned from the
theory but did not adopt the full domain hash as originally expressed. The Reef
and Shoal proposal revisits the original concept and proposes the concatenation
of a conventional cryptographic hash and an independent large non-cryptographic
hash as an approximation of the full domain hash. The Badderlocks version 0.1
concrete proposal uses the CRC computation with large primitive polynomials
preceded by an S-box message expansion phase.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2432</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2432</id><created>2013-05-10</created><updated>2013-05-21</updated><authors><author><keyname>Babichenko</keyname><forenames>Yakov</forenames></author></authors><title>Small Support Equilibria in Large Games</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we provide a new proof for the results of Lipton et al. on the
existence of an approximate Nash equilibrium with logarithmic support size.
Besides its simplicity, the new proof leads to the following contributions:
  1. For n-player games, we improve the bound on the size of the support of an
approximate Nash equilibrium.
  2. We generalize the result of Daskalakis and Papadimitriou on small
probability games from the two-player case to the general n-player case.
  3. We provide a logarithmic bound on the size of the support of an
approximate Nash equilibrium in the case of graphical games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2436</identifier>
 <datestamp>2015-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2436</id><created>2013-05-10</created><updated>2015-01-01</updated><authors><author><keyname>Loh</keyname><forenames>Po-Ling</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author></authors><title>Regularized M-estimators with nonconvexity: Statistical and algorithmic
  theory for local optima</title><categories>math.ST cs.IT math.IT stat.ML stat.TH</categories><comments>58 pages, 13 figures. To appear in JMLR</comments><msc-class>62F12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide novel theoretical results regarding local optima of regularized
$M$-estimators, allowing for nonconvexity in both loss and penalty functions.
Under restricted strong convexity on the loss and suitable regularity
conditions on the penalty, we prove that \emph{any stationary point} of the
composite objective function will lie within statistical precision of the
underlying parameter vector. Our theory covers many nonconvex objective
functions of interest, including the corrected Lasso for errors-in-variables
linear models; regression for generalized linear models with nonconvex
penalties such as SCAD, MCP, and capped-$\ell_1$; and high-dimensional
graphical model estimation. We quantify statistical accuracy by providing
bounds on the $\ell_1$-, $\ell_2$-, and prediction error between stationary
points and the population-level optimum. We also propose a simple modification
of composite gradient descent that may be used to obtain a near-global optimum
within statistical precision $\epsilon$ in $\log(1/\epsilon)$ steps, which is
the fastest possible rate of any first-order method. We provide simulation
studies illustrating the sharpness of our theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2440</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2440</id><created>2013-05-10</created><authors><author><keyname>Tian</keyname><forenames>Chao</forenames></author></authors><title>Rate Region of the (4,3,3) Exact-Repair Regenerating Codes</title><categories>cs.IT math.IT</categories><comments>accepted, ISIT 2013, 5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Exact-repair regenerating codes are considered for the case (n,k,d)=(4,3,3),
for which a complete characterization of the rate region is provided. This
characterization answers in the affirmative the open question whether there
exists a non-vanishing gap between the optimal bandwidth-storage tradeoff of
the functional-repair regenerating codes (i.e., the cut-set bound) and that of
the exact-repair regenerating codes. The converse proof relies on the existence
of symmetric optimal solutions. For the achievability, only one non-trivial
corner point of the rate region needs to be addressed, for which an explicit
binary code construction is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2446</identifier>
 <datestamp>2014-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2446</id><created>2013-05-10</created><updated>2014-09-15</updated><authors><author><keyname>Feigenbaum</keyname><forenames>Itai</forenames></author><author><keyname>Sethuraman</keyname><forenames>Jay</forenames></author><author><keyname>Ye</keyname><forenames>Chun</forenames></author></authors><title>Approximately Optimal Mechanisms for Strategyproof Facility Location:
  Minimizing $L_p$ Norm of Costs</title><categories>cs.GT</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of locating a single facility on the real line. This
facility serves a set of agents, each of whom is located on the line, and
incurs a cost equal to his distance from the facility. An agent's location is
private information that is known only to him. Agents report their location to
a central planner who decides where to locate the facility. The planner's
objective is to minimize a &quot;social&quot; cost function that depends on the
agent-costs. However, agents might not report truthfully; to address this
issue, the planner must restrict himself to {\em strategyproof} mechanisms, in
which truthful reporting is a dominant strategy for each agent. A mechanism
that simply chooses the optimal solution is generally not strategyproof, and so
the planner aspires to use a mechanism that effectively {\em approximates} his
objective function. In our paper, we study the problem described above with the
social cost function being the $L_p$ norm of the vector of agent-costs. We show
that the median mechanism (which is known to be strategyproof) provides a
$2^{1-\frac{1}{p}}$ approximation ratio, and that is the optimal approximation
ratio among all deterministic strategyproof mechanisms. For randomized
mechanisms, we present two results. First, we present a negative result: we
show that for integer $\infty&gt;p&gt;2$, no mechanism---from a rather large class of
randomized mechanisms--- has an approximation ratio better than that of the
median mechanism. This is in contrast to the case of $p=2$ and $p=\infty$ where
a randomized mechanism provably helps improve the worst case approximation
ratio. Second, for the case of 2 agents, we show that a mechanism called LRM,
first designed by Procaccia and Tennenholtz for the special case of
$L_{\infty}$, provides the optimal approximation ratio among all randomized
mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2452</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2452</id><created>2013-05-10</created><authors><author><keyname>Foulds</keyname><forenames>James</forenames></author><author><keyname>Boyles</keyname><forenames>Levi</forenames></author><author><keyname>Dubois</keyname><forenames>Christopher</forenames></author><author><keyname>Smyth</keyname><forenames>Padhraic</forenames></author><author><keyname>Welling</keyname><forenames>Max</forenames></author></authors><title>Stochastic Collapsed Variational Bayesian Inference for Latent Dirichlet
  Allocation</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the internet era there has been an explosion in the amount of digital text
information available, leading to difficulties of scale for traditional
inference algorithms for topic models. Recent advances in stochastic
variational inference algorithms for latent Dirichlet allocation (LDA) have
made it feasible to learn topic models on large-scale corpora, but these
methods do not currently take full advantage of the collapsed representation of
the model. We propose a stochastic algorithm for collapsed variational Bayesian
inference for LDA, which is simpler and more efficient than the state of the
art method. We show connections between collapsed variational Bayesian
inference and MAP estimation for LDA, and leverage these connections to prove
convergence properties of the proposed algorithm. In experiments on large-scale
text corpora, the algorithm was found to converge faster and often to a better
solution than the previous method. Human-subject experiments also demonstrated
that the method can learn coherent topics in seconds on small corpora,
facilitating the use of topic models in interactive document analysis software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2459</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2459</id><created>2013-05-10</created><authors><author><keyname>Starr</keyname><forenames>Jonathan</forenames></author><author><keyname>Ayach</keyname><forenames>Omar El</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Interference Alignment in Distributed Antenna Systems</title><categories>cs.IT math.IT</categories><comments>29 pages, 7 figures, submitted to IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference alignment (IA) is a cooperative transmission strategy that
improves spectral efficiency in high signal-to-noise ratio (SNR) environments,
yet performs poorly in low-SNR scenarios. This limits IA's utility in cellular
systems as it is ineffective in improving cell-edge data rates. Modern cellular
architectures such as distributed antenna systems (DAS), however, promise to
boost cell-edge SNR, creating the environment needed to realize practical IA
gains. Existing IA solutions cannot be applied to DAS as they neglect the
per-remote-radio power constraints imposed on distributed precoders. This paper
considers two types of distributed antenna IA systems: ones with a limit on
maximum per-radio power, and ones with a strict equality constraint on
per-radio power. The rate-loss incurred by a simple power back-off strategy,
used in systems with maximum power constraints, is characterized analytically.
It is also shown that enforcing strict power constraints avoids such a
rate-loss but negatively affects IA feasibility. For such systems, an IA
algorithm is proposed and feasibility conditions are derived based on the
concept of system properness. Finally, numerical results validate the analysis
and demonstrate that IA and DAS can be successfully combined to mitigate
inter-cell interference and improve performance for most mobile users,
especially those at the cell-edge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2460</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2460</id><created>2013-05-10</created><authors><author><keyname>Ayach</keyname><forenames>Omar El</forenames></author><author><keyname>Rajagopal</keyname><forenames>Sridhar</forenames></author><author><keyname>Abu-Surra</keyname><forenames>Shadi</forenames></author><author><keyname>Pi</keyname><forenames>Zhouyue</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Spatially Sparse Precoding in Millimeter Wave MIMO Systems</title><categories>cs.IT math.IT</categories><comments>30 pages, 7 figures, submitted to IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Millimeter wave (mmWave) signals experience orders-of-magnitude more pathloss
than the microwave signals currently used in most wireless applications. MmWave
systems must therefore leverage large antenna arrays, made possible by the
decrease in wavelength, to combat pathloss with beamforming gain. Beamforming
with multiple data streams, known as precoding, can be used to further improve
mmWave spectral efficiency. Both beamforming and precoding are done digitally
at baseband in traditional multi-antenna systems. The high cost and power
consumption of mixed-signal devices in mmWave systems, however, make analog
processing in the RF domain more attractive. This hardware limitation restricts
the feasible set of precoders and combiners that can be applied by practical
mmWave transceivers. In this paper, we consider transmit precoding and receiver
combining in mmWave systems with large antenna arrays. We exploit the spatial
structure of mmWave channels to formulate the precoding/combining problem as a
sparse reconstruction problem. Using the principle of basis pursuit, we develop
algorithms that accurately approximate optimal unconstrained precoders and
combiners such that they can be implemented in low-cost RF hardware. We present
numerical results on the performance of the proposed algorithms and show that
they allow mmWave systems to approach their unconstrained performance limits,
even when transceiver hardware constraints are considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2461</identifier>
 <datestamp>2014-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2461</id><created>2013-05-10</created><updated>2013-08-14</updated><authors><author><keyname>Perez-Diaz</keyname><forenames>Sonia</forenames></author><author><keyname>Shen</keyname><forenames>Li-Yong</forenames></author></authors><title>Numerical Reparametrization of Rational Parametric Plane Curves</title><categories>math.AG cs.SC</categories><comments>31 pages, 23 figures</comments><acm-class>I.3.5; G.1.2</acm-class><journal-ref>Journal of Computational and Applied Mathematics Volume 277, 15
  March 2015, Pages 138-161</journal-ref><doi>10.1016/j.cam.2014.09.012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an algorithm for reparametrizing algebraic plane
curves from a numerical point of view. That is, we deal with mathematical
objects that are assumed to be given approximately. More precisely, given a
tolerance $\epsilon&gt;0$ and a rational parametrization $\cal P$ with perturbed
float coefficients of a plane curve $\cal C$, we present an algorithm that
computes a parametrization $\cal Q$ of a new plane curve $\cal D$ such that
${\cal Q}$ is an {\it $\epsilon$--proper reparametrization} of $\cal D$. In
addition, the error bound is carefully discussed and we present a formula that
measures the &quot;closeness&quot; between the input curve $\cal C$ and the output curve
$\cal D$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2462</identifier>
 <datestamp>2014-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2462</id><created>2013-05-10</created><updated>2013-06-03</updated><authors><author><keyname>Perez-Diaza</keyname><forenames>Sonia</forenames></author><author><keyname>Shen</keyname><forenames>Liyong</forenames></author></authors><title>Characterization of Rational Ruled Surfaces</title><categories>cs.SC cs.CG math.AG</categories><comments>31 pages</comments><acm-class>I.3.5; G.1.2</acm-class><journal-ref>Journal of Symbolic Computation Volume 63, May 2014, Pages 21-45</journal-ref><doi>10.1016/j.jsc.2013.11.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ruled surface is a typical modeling surface in computer aided geometric
design. It is usually given in the standard parametric form. However, it can
also be in the forms than the standard one. For these forms, it is necessary to
determine and find the standard form. In this paper, we present algorithms to
determine whether a given implicit surface is a rational ruled surface. A
parametrization of the surface is computed for the affirmative case. We also
consider the parametric situation. More precisely, after a given rational
parametric surface is determined as a ruled one, we reparameterize it to the
standard form.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2463</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2463</id><created>2013-05-10</created><authors><author><keyname>Perez-Diaz</keyname><forenames>Sonia</forenames></author><author><keyname>Shen</keyname><forenames>Li-Yong</forenames></author></authors><title>Determination and (re)parametrization of rational developable surfaces</title><categories>cs.SC cs.CG math.AG</categories><acm-class>I.3.5; G.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The developable surface is an important surface in computer aided design,
geometric modeling and industrial manufactory. It is often given in the stan-
dard parametric form, but it can also be in the implicit form which is commonly
used in algebraic geometry. Not all algebraic developable surfaces have
rational parametrizations. In this paper, we focus on the rational developable
surfaces. For a given algebraic surface, we first determine whether it is
developable by geometric inspection, and we give a rational proper
parametrization for the af- firmative case. For a rational parametric surface,
we can also determine the developability and give a proper reparametrization
for the developable surface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2467</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2467</id><created>2013-05-10</created><authors><author><keyname>Dvo&#x159;&#xe1;k</keyname><forenames>Zden&#x11b;k</forenames></author><author><keyname>Lidick&#xfd;</keyname><forenames>Bernard</forenames></author></authors><title>3-coloring triangle-free planar graphs with a precolored 8-cycle</title><categories>math.CO cs.DM</categories><comments>20 pages, 5 figures</comments><msc-class>05C15, 05C10</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let G be a planar triangle-free graph and let C be a cycle in G of length at
most 8. We characterize all situations where a 3-coloring of C does not extend
to a proper 3-coloring of the whole graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2480</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2480</id><created>2013-05-11</created><updated>2013-05-16</updated><authors><author><keyname>Nozaki</keyname><forenames>Takayuki</forenames></author><author><keyname>Maehara</keyname><forenames>Masaki</forenames></author><author><keyname>Kasai</keyname><forenames>Kenta</forenames></author><author><keyname>Sakaniwa</keyname><forenames>Kohichi</forenames></author></authors><title>Weight Distribution for Non-binary Cluster LDPC Code Ensemble</title><categories>cs.IT math.IT</categories><comments>12pages, 6 figures, To be presented in ISIT2013, Submitted to IEICE
  Trans. Fundamentals</comments><doi>10.1587/transfun.E96.A.2382</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we derive the average weight distributions for the irregular
non-binary cluster low-density parity-check (LDPC) code ensembles. Moreover, we
give the exponential growth rate of the average weight distribution in the
limit of large code length. We show that there exist $(2,d_c)$-regular
non-binary cluster LDPC code ensembles whose normalized typical minimum
distances are strictly positive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2490</identifier>
 <datestamp>2014-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2490</id><created>2013-05-11</created><updated>2014-04-15</updated><authors><author><keyname>Mitavskiy</keyname><forenames>Boris</forenames></author><author><keyname>He</keyname><forenames>Jun</forenames></author></authors><title>Combining Drift Analysis and Generalized Schema Theory to Design
  Efficient Hybrid and/or Mixed Strategy EAs</title><categories>cs.NE</categories><doi>10.1109/CEC.2013.6557808</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hybrid and mixed strategy EAs have become rather popular for tackling various
complex and NP-hard optimization problems. While empirical evidence suggests
that such algorithms are successful in practice, rather little theoretical
support for their success is available, not mentioning a solid mathematical
foundation that would provide guidance towards an efficient design of this type
of EAs. In the current paper we develop a rigorous mathematical framework that
suggests such designs based on generalized schema theory, fitness levels and
drift analysis. An example-application for tackling one of the classical
NP-hard problems, the &quot;single-machine scheduling problem&quot; is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2494</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2494</id><created>2013-05-11</created><authors><author><keyname>Selivanova</keyname><forenames>Svetlana</forenames></author><author><keyname>Selivanov</keyname><forenames>Victor</forenames></author></authors><title>Computing Solution Operators of Boundary-value Problems for Some Linear
  Hyperbolic Systems of PDEs</title><categories>cs.NA math.NA</categories><comments>33 pages</comments><msc-class>03D78, 58J45, 65M06, 65M25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss possibilities of application of Numerical Analysis methods to
proving computability, in the sense of the TTE approach, of solution operators
of boundary-value problems for systems of PDEs. We prove computability of the
solution operator for a symmetric hyperbolic system with computable real
coefficients and dissipative boundary conditions, and of the Cauchy problem for
the same system (in this case we also prove computable dependence on the
coefficients) in a cube $Q\subseteq\mathbb R^m$. Such systems describe a wide
variety of physical processes (e.g. elasticity, acoustics, Maxwell equations).
Moreover, many boundary-value problems for the wave equation also can be
reduced to this case, thus we partially answer a question raised in
\cite{wz02}. Compared with most of other existing methods of proving
computability for PDEs, this method does not require existence of explicit
solution formulas and is thus applicable to a broader class of (systems of)
equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2496</identifier>
 <datestamp>2013-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2496</id><created>2013-05-11</created><updated>2013-10-25</updated><authors><author><keyname>Szalay</keyname><forenames>Kristof Z.</forenames></author><author><keyname>Csermely</keyname><forenames>Peter</forenames></author></authors><title>Perturbation centrality and Turbine: a novel centrality measure obtained
  using a versatile network dynamics tool</title><categories>q-bio.MN cond-mat.dis-nn cs.SI physics.bio-ph</categories><comments>21 pages, 4 figues, 1 table, 58 references + a Supplement of 52
  pages, 10 figures, 9 tables and 39 references; Turbine algorithm is available
  at: http://www.turbine.linkgroup.hu</comments><journal-ref>PLoS ONE 8, e78059 (2013)</journal-ref><doi>10.1371/journal.pone.0078059</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analysis of network dynamics became a focal point to understand and predict
changes of complex systems. Here we introduce Turbine, a generic framework
enabling fast simulation of any algorithmically definable dynamics on very
large networks. Using a perturbation transmission model inspired by
communicating vessels, we define a novel centrality measure: perturbation
centrality. Hubs and inter-modular nodes proved to be highly efficient in
perturbation propagation. High perturbation centrality nodes of the Met-tRNA
synthetase protein structure network were identified as amino acids involved in
intra-protein communication by earlier studies. Changes in perturbation
centralities of yeast interactome nodes upon various stresses well
recapitulated the functional changes of stressed yeast cells. The novelty and
usefulness of perturbation centrality was validated in several other model,
biological and social networks. The Turbine software and the perturbation
centrality measure may provide a large variety of novel options to assess
signaling, drug action, environmental and social interventions. The Turbine
algorithm is available at: http://www.turbine.linkgroup.hu
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2498</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2498</id><created>2013-05-11</created><authors><author><keyname>Mitavskiy</keyname><forenames>Boris</forenames></author><author><keyname>He</keyname><forenames>Jun</forenames></author></authors><title>A Further Generalization of the Finite-Population Geiringer-like Theorem
  for POMDPs to Allow Recombination Over Arbitrary Set Covers</title><categories>cs.AI</categories><comments>arXiv admin note: text overlap with arXiv:1110.4657</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A popular current research trend deals with expanding the Monte-Carlo tree
search sampling methodologies to the environments with uncertainty and
incomplete information. Recently a finite population version of Geiringer
theorem with nonhomologous recombination has been adopted to the setting of
Monte-Carlo tree search to cope with randomness and incomplete information by
exploiting the entrinsic similarities within the state space of the problem.
The only limitation of the new theorem is that the similarity relation was
assumed to be an equivalence relation on the set of states. In the current
paper we lift this &quot;curtain of limitation&quot; by allowing the similarity relation
to be modeled in terms of an arbitrary set cover of the set of state-action
pairs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2500</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2500</id><created>2013-05-11</created><authors><author><keyname>Lakshminarayanan</keyname><forenames>RamKumar</forenames><affiliation>Department of IT, HCT</affiliation></author><author><keyname>Balaji</keyname><forenames>RD.</forenames><affiliation>Department of IT, HCT</affiliation></author><author><keyname>kumar</keyname><forenames>Binod</forenames><affiliation>Department of IT, HCT</affiliation></author><author><keyname>Balaji</keyname><forenames>Malathi</forenames><affiliation>Department of IT, HCT</affiliation></author></authors><title>Augmented Reality in ICT for Minimum Knowledge Loss</title><categories>cs.OH</categories><journal-ref>(IJCSIS) International Journal of Computer Science and Information
  Security, Vol. 11, No. 4, April 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Informatics world digitizes the human beings, with the contribution made by
all the industrial people. In the recent survey it is proved that people are
not accustomed or they are not able to access the electronic devices to its
extreme usage. Also people are more dependent to the technologies and their
day-to-day activities are ruled by the same. In this paper we discuss on one of
the advanced technology which will soon rule the world and make the people are
more creative and at the same time hassle-free. This concept is introduced as
6th sense technology by an IIT, Mumbai student who is presently Ph.D., scholar
in MIT, USA. Similar to this research there is one more research going on under
the title Augmented Reality. This research makes a new association with the
real world to digital world and allows us to share and manipulate the
information directly with our mental thoughts. A college which implements state
of the art technology for teaching and learning, Higher College of Technology,
Muscat, (HCT) tries to identify the opportunities and limitations of
implementing this augmented reality for teaching and learning. The research
team of HCT, here, tries to give two scenarios in which augmented reality can
fit in. Since this research is in the conceptual level we are trying to
illustrate the history of this technology and how it can be adopted in the
teaching environment
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2504</identifier>
 <datestamp>2013-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2504</id><created>2013-05-11</created><authors><author><keyname>Mitavskiy</keyname><forenames>Boris</forenames></author><author><keyname>Tuci</keyname><forenames>Elio</forenames></author><author><keyname>Cannings</keyname><forenames>Chris</forenames></author><author><keyname>Cannings</keyname><forenames>Chris</forenames></author><author><keyname>Rowe</keyname><forenames>Jonathan</forenames></author><author><keyname>He</keyname><forenames>Jun</forenames></author></authors><title>Geiringer Theorems: From Population Genetics to Computational
  Intelligence, Memory Evolutive Systems and Hebbian Learning</title><categories>cs.NE</categories><comments>arXiv admin note: text overlap with arXiv:1110.4657</comments><journal-ref>Natural Computing, Volume 12, Issue 4 , pp 473-484, 2013</journal-ref><doi>10.1007/s11047-013-9395-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical Geiringer theorem addresses the limiting frequency of
occurrence of various alleles after repeated application of crossover. It has
been adopted to the setting of evolutionary algorithms and, a lot more
recently, reinforcement learning and Monte-Carlo tree search methodology to
cope with a rather challenging question of action evaluation at the chance
nodes. The theorem motivates novel dynamic parallel algorithms that are
explicitly described in the current paper for the first time. The algorithms
involve independent agents traversing a dynamically constructed directed graph
that possibly has loops. A rather elegant and profound category-theoretic model
of cognition in biological neural networks developed by a well-known French
mathematician, professor Andree Ehresmann jointly with a neurosurgeon, Jan Paul
Vanbremeersch over the last thirty years provides a hint at the connection
between such algorithms and Hebbian learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2505</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2505</id><created>2013-05-11</created><authors><author><keyname>Kar</keyname><forenames>Purushottam</forenames></author><author><keyname>Sriperumbudur</keyname><forenames>Bharath K</forenames></author><author><keyname>Jain</keyname><forenames>Prateek</forenames></author><author><keyname>Karnick</keyname><forenames>Harish C</forenames></author></authors><title>On the Generalization Ability of Online Learning Algorithms for Pairwise
  Loss Functions</title><categories>cs.LG stat.ML</categories><comments>To appear in proceedings of the 30th International Conference on
  Machine Learning (ICML 2013)</comments><journal-ref>Journal of Machine Learning Research, W&amp;CP 28(3) (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the generalization properties of online learning
based stochastic methods for supervised learning problems where the loss
function is dependent on more than one training sample (e.g., metric learning,
ranking). We present a generic decoupling technique that enables us to provide
Rademacher complexity-based generalization error bounds. Our bounds are in
general tighter than those obtained by Wang et al (COLT 2012) for the same
problem. Using our decoupling technique, we are further able to obtain fast
convergence rates for strongly convex pairwise loss functions. We are also able
to analyze a class of memory efficient online learning algorithms for pairwise
learning problems that use only a bounded subset of past training samples to
update the hypothesis at each step. Finally, in order to complement our
generalization bounds, we propose a novel memory efficient online learning
algorithm for higher order learning problems with bounded regret guarantees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2524</identifier>
 <datestamp>2014-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2524</id><created>2013-05-11</created><updated>2014-02-04</updated><authors><author><keyname>Foygel</keyname><forenames>Rina</forenames></author><author><keyname>Mackey</keyname><forenames>Lester</forenames></author></authors><title>Corrupted Sensing: Novel Guarantees for Separating Structured Signals</title><categories>cs.IT math.IT math.OC stat.ML</categories><comments>http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6712045</comments><journal-ref>IEEE Transactions on Information Theory, 60(2): 1223-1247 (2014)</journal-ref><doi>10.1109/TIT.2013.2293654</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of corrupted sensing, a generalization of compressed
sensing in which one aims to recover a signal from a collection of corrupted or
unreliable measurements. While an arbitrary signal cannot be recovered in the
face of arbitrary corruption, tractable recovery is possible when both signal
and corruption are suitably structured. We quantify the relationship between
signal recovery and two geometric measures of structure, the Gaussian
complexity of a tangent cone and the Gaussian distance to a subdifferential. We
take a convex programming approach to disentangling signal and corruption,
analyzing both penalized programs that trade off between signal and corruption
complexity, and constrained programs that bound the complexity of signal or
corruption when prior information is available. In each case, we provide
conditions for exact signal recovery from structured corruption and stable
signal recovery from structured corruption with added unstructured noise. Our
simulations demonstrate close agreement between our theoretical recovery bounds
and the sharp phase transitions observed in practice. In addition, we provide
new interpretable bounds for the Gaussian complexity of sparse vectors,
block-sparse vectors, and low-rank matrices, which lead to sharper guarantees
of recovery when combined with our results and those in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2532</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2532</id><created>2013-05-11</created><authors><author><keyname>Ross</keyname><forenames>Stephane</forenames></author><author><keyname>Zhou</keyname><forenames>Jiaji</forenames></author><author><keyname>Yue</keyname><forenames>Yisong</forenames></author><author><keyname>Dey</keyname><forenames>Debadeepta</forenames></author><author><keyname>Bagnell</keyname><forenames>J. Andrew</forenames></author></authors><title>Learning Policies for Contextual Submodular Prediction</title><categories>cs.LG stat.ML</categories><comments>13 pages. To appear in proceedings of the International Conference on
  Machine Learning (ICML), 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many prediction domains, such as ad placement, recommendation, trajectory
prediction, and document summarization, require predicting a set or list of
options. Such lists are often evaluated using submodular reward functions that
measure both quality and diversity. We propose a simple, efficient, and
provably near-optimal approach to optimizing such prediction problems based on
no-regret learning. Our method leverages a surprising result from online
submodular optimization: a single no-regret online learner can compete with an
optimal sequence of predictions. Compared to previous work, which either learn
a sequence of classifiers or rely on stronger assumptions such as
realizability, we ensure both data-efficiency as well as performance guarantees
in the fully agnostic setting. Experiments validate the efficiency and
applicability of the approach on a wide range of problems including manipulator
trajectory optimization, news recommendation and document summarization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2540</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2540</id><created>2013-05-11</created><authors><author><keyname>Kosolobov</keyname><forenames>Dmitry</forenames></author><author><keyname>Rubinchik</keyname><forenames>Mikhail</forenames></author><author><keyname>Shur</keyname><forenames>Arseny M.</forenames></author></authors><title>Finding Distinct Subpalindromes Online</title><categories>cs.DS</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We exhibit an online algorithm finding all distinct palindromes inside a
given string in time $\Theta(n\log|\Sigma|)$ over an ordered alphabet and in
time $\Theta(n|\Sigma|)$ over an unordered alphabet. Using a reduction from a
dictionary-like data structure, we prove the optimality of this algorithm in
the comparison-based computation model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2545</identifier>
 <datestamp>2015-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2545</id><created>2013-05-11</created><updated>2015-07-31</updated><authors><author><keyname>Badanidiyuru</keyname><forenames>Ashwinkumar</forenames></author><author><keyname>Kleinberg</keyname><forenames>Robert</forenames></author><author><keyname>Slivkins</keyname><forenames>Aleksandrs</forenames></author></authors><title>Bandits with Knapsacks</title><categories>cs.DS cs.LG</categories><comments>An extended abstract of this work has appeared in the 54th IEEE
  Symposium on Foundations of Computer Science (FOCS 2013). 54 pages. Compared
  to the Aug'13 version, this version has a significantly revised presentation
  and reflects the current status of the follow-up work. Also, this version
  contains a stronger regret bound in one of the main results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-armed bandit problems are the predominant theoretical model of
exploration-exploitation tradeoffs in learning, and they have countless
applications ranging from medical trials, to communication networks, to Web
search and advertising. In many of these application domains the learner may be
constrained by one or more supply (or budget) limits, in addition to the
customary limitation on the time horizon. The literature lacks a general model
encompassing these sorts of problems. We introduce such a model, called
&quot;bandits with knapsacks&quot;, that combines aspects of stochastic integer
programming with online learning. A distinctive feature of our problem, in
comparison to the existing regret-minimization literature, is that the optimal
policy for a given latent distribution may significantly outperform the policy
that plays the optimal fixed arm. Consequently, achieving sublinear regret in
the bandits-with-knapsacks problem is significantly more challenging than in
conventional bandit problems.
  We present two algorithms whose reward is close to the information-theoretic
optimum: one is based on a novel &quot;balanced exploration&quot; paradigm, while the
other is a primal-dual algorithm that uses multiplicative updates. Further, we
prove that the regret achieved by both algorithms is optimal up to
polylogarithmic factors. We illustrate the generality of the problem by
presenting applications in a number of different domains including electronic
commerce, routing, and scheduling. As one example of a concrete application, we
consider the problem of dynamic posted pricing with limited supply and obtain
the first algorithm whose regret, with respect to the optimal dynamic policy,
is sublinear in the supply.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2548</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2548</id><created>2013-05-11</created><authors><author><keyname>Etkin</keyname><forenames>Ra&#xfa;l</forenames></author><author><keyname>Parvaresh</keyname><forenames>Farzad</forenames></author><author><keyname>Shomorony</keyname><forenames>Ilan</forenames></author><author><keyname>Avestimehr</keyname><forenames>A. Salman</forenames></author></authors><title>On Min-Cut Algorithms for Half-Duplex Relay Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory. Part of this
  work will be presented at ISIT 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing the cut-set bound in half-duplex relay networks is a challenging
optimization problem, since it requires finding the cut-set optimal half-duplex
schedule. This subproblem in general involves an exponential number of
variables, since the number of ways to assign each node to either transmitter
or receiver mode is exponential in the number of nodes. We present a general
technique that takes advantage of specific structures in the topology of a
given network and allows us to reduce the complexity of computing the
half-duplex schedule that maximizes the cut-set bound (with i.i.d. input
distribution). In certain classes of network topologies, our approach yields
polynomial time algorithms. We use simulations to show running time
improvements over alternative methods and compare the performance of various
half-duplex scheduling approaches in different SNR regimes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2550</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2550</id><created>2013-05-11</created><updated>2013-05-26</updated><authors><author><keyname>Niso</keyname><forenames>Guiomar</forenames></author><author><keyname>Bru&#xf1;a</keyname><forenames>Ricardo</forenames></author><author><keyname>Pereda</keyname><forenames>Ernesto</forenames></author><author><keyname>Guti&#xe9;rrez</keyname><forenames>Ricardo</forenames></author><author><keyname>Bajo</keyname><forenames>Ricardo</forenames></author><author><keyname>Maest&#xfa;</keyname><forenames>Fernando</forenames></author><author><keyname>del-Pozo</keyname><forenames>Francisco</forenames></author></authors><title>HERMES: towards an integrated toolbox to characterize functional and
  effective brain connectivity</title><categories>q-bio.NC cs.CE cs.MS physics.bio-ph physics.data-an</categories><comments>58 pages, 10 figures, 3 tables, Neuroinformatics 2013</comments><doi>10.1007/s12021-013-9186-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analysis of the interdependence between time series has become an
important field of research in the last years, mainly as a result of advances
in the characterization of dynamical systems from the signals they produce, the
introduction of concepts such as generalized and phase synchronization and the
application of information theory to time series analysis. In neurophysiology,
different analytical tools stemming from these concepts have added to the
'traditional' set of linear methods, which includes the cross-correlation and
the coherency function in the time and frequency domain, respectively, or more
elaborated tools such as Granger Causality. This increase in the number of
approaches to tackle the existence of functional (FC) or effective connectivity
(EC) between two (or among many) neural networks, along with the mathematical
complexity of the corresponding time series analysis tools, makes it desirable
to arrange them into a unified-easy-to-use software package. The goal is to
allow neuroscientists, neurophysiologists and researchers from related fields
to easily access and make use of these analysis methods from a single
integrated toolbox. Here we present HERMES (http://hermes.ctb.upm.es), a
toolbox for the Matlab environment (The Mathworks, Inc), which is designed for
the analysis functional and effective brain connectivity from
neurophysiological data such as multivariate EEG and/or MEG records. It
includes also visualization tools and statistical methods to address the
problem of multiple comparisons. We believe that this toolbox will be very
helpful to all the researchers working in the emerging field of brain
connectivity analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2553</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2553</id><created>2013-05-11</created><authors><author><keyname>Wang</keyname><forenames>Jun</forenames></author><author><keyname>Xiong</keyname><forenames>Xi</forenames></author><author><keyname>Liu</keyname><forenames>Peng</forenames></author></authors><title>Practical Fine-grained Privilege Separation in Multithreaded
  Applications</title><categories>cs.OS cs.CR</categories><report-no>PSU-S2-13-051</report-no><acm-class>D.4.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An inherent security limitation with the classic multithreaded programming
model is that all the threads share the same address space and, therefore, are
implicitly assumed to be mutually trusted. This assumption, however, does not
take into consideration of many modern multithreaded applications that involve
multiple principals which do not fully trust each other. It remains challenging
to retrofit the classic multithreaded programming model so that the security
and privilege separation in multi-principal applications can be resolved.
  This paper proposes ARBITER, a run-time system and a set of security
primitives, aimed at fine-grained and data-centric privilege separation in
multithreaded applications. While enforcing effective isolation among
principals, ARBITER still allows flexible sharing and communication between
threads so that the multithreaded programming paradigm can be preserved. To
realize controlled sharing in a fine-grained manner, we created a novel
abstraction named ARBITER Secure Memory Segment (ASMS) and corresponding OS
support. Programmers express security policies by labeling data and principals
via ARBITER's API following a unified model. We ported a widely-used, in-memory
database application (memcached) to ARBITER system, changing only around 100
LOC. Experiments indicate that only an average runtime overhead of 5.6% is
induced to this security enhanced version of application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2561</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2561</id><created>2013-05-12</created><authors><author><keyname>Talamadupula</keyname><forenames>Kartik</forenames></author><author><keyname>Udrea</keyname><forenames>Octavian</forenames></author><author><keyname>Riabov</keyname><forenames>Anton</forenames></author><author><keyname>Ranganathan</keyname><forenames>Anand</forenames></author></authors><title>Strategic Planning for Network Data Analysis</title><categories>cs.AI</categories><comments>9 pages</comments><msc-class>97R40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As network traffic monitoring software for cybersecurity, malware detection,
and other critical tasks becomes increasingly automated, the rate of alerts and
supporting data gathered, as well as the complexity of the underlying model,
regularly exceed human processing capabilities. Many of these applications
require complex models and constituent rules in order to come up with decisions
that influence the operation of entire systems. In this paper, we motivate the
novel &quot;strategic planning&quot; problem -- one of gathering data from the world and
applying the underlying model of the domain in order to come up with decisions
that will monitor the system in an automated manner. We describe our use of
automated planning methods to this problem, including the technique that we
used to solve it in a manner that would scale to the demands of a real-time,
real world scenario. We then present a PDDL model of one such application
scenario related to network administration and monitoring, followed by a
description of a novel integrated system that was built to accept generated
plans and to continue the execution process. Finally, we present evaluations of
two different automated planners and their different capabilities with our
integrated system, both on a six-month window of network data, and using a
simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2581</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2581</id><created>2013-05-12</created><authors><author><keyname>Shalev-Shwartz</keyname><forenames>Shai</forenames></author><author><keyname>Zhang</keyname><forenames>Tong</forenames></author></authors><title>Accelerated Mini-Batch Stochastic Dual Coordinate Ascent</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic dual coordinate ascent (SDCA) is an effective technique for
solving regularized loss minimization problems in machine learning. This paper
considers an extension of SDCA under the mini-batch setting that is often used
in practice. Our main contribution is to introduce an accelerated mini-batch
version of SDCA and prove a fast convergence rate for this method. We discuss
an implementation of our method over a parallel computing system, and compare
the results to both the vanilla stochastic dual coordinate ascent and to the
accelerated deterministic gradient descent method of
\cite{nesterov2007gradient}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2592</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2592</id><created>2013-05-12</created><authors><author><keyname>Domanovitz</keyname><forenames>Elad</forenames></author><author><keyname>Erez</keyname><forenames>Uri</forenames></author></authors><title>On the Performance Limits of Scalar Coding Over MISO Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communications, April 16
  2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance limits of scalar coding for multiple-input single-output
channels are revisited in this work. By employing randomized beamforming,
Narula et al. demonstrated that the loss of scalar coding is universally
bounded by ~ 2.51 dB (or 0.833 bits/symbol) for any number of antennas and
channel gains. In this work, by using randomized beamforming in conjunction
with space-time codes, it is shown that the bound can be tightened to ~ 1.1 dB
(or 0.39 bits/symbol).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2609</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2609</id><created>2013-05-12</created><authors><author><keyname>Balaji</keyname><forenames>Dr. R. D.</forenames></author><author><keyname>Ramniklal</keyname><forenames>Dr. Brijesh</forenames></author><author><keyname>Balasupramanian</keyname><forenames>N.</forenames></author><author><keyname>Malathi</keyname><forenames>Er. R.</forenames></author></authors><title>Mnemonics for Higher Education Using Contemporary Technologies</title><categories>cs.CY</categories><comments>Second International Conference of the Omani Society for Educational
  Society 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Education pierces into the contemporary world due to the influence of the
emerging technologies in the digital world. Education field is also bombarded
by the modern technologies and the demands of the digital society. It is
affected by cloud computing, green computing and Internet. Still the success of
this depends upon the minimization of the knowledge loss, while transferring
ideas from teacher to student. Teaching &amp; Learning is always an art. Even
though modern technology is introduced along with the traditional method of
teaching in Higher College of Technology (HCT), knowledge loss is very high
still. Mnemonics is an old tool; still suitable for digital era students with
the influence of recent technologies. Hence this paper discusses how to
implement this mnemonics with the help of modern technologies like E-Learning
and M-Learning. In this paper we have tried to discuss about E-learning and
M-learning usage for implementing Mnemonics, and also discussed how far this
concept can be used to make the Information and Communication Technology (ICT)
more efficient and effective in term of making the students learning experience
as a fun and without huge knowledge loss during the teaching and learning
process including practical subjects. This paper also explains the initial
research conducted with the students of database specialization of HCT and
findings of that research about the knowledge loss. We have also suggests the
future research areas in Mnemonics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2616</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2616</id><created>2013-05-12</created><authors><author><keyname>Lakshminarayanan</keyname><forenames>Ramkumar</forenames></author><author><keyname>Kumar</keyname><forenames>Binod</forenames></author><author><keyname>Raju</keyname><forenames>M.</forenames></author></authors><title>Cloud Computing Benefits for Educational Institutions</title><categories>cs.CY</categories><comments>Second Interenational Conference of the Omani Society for Educational
  Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Education today is becoming completely associated with the Information
Technology on the content delivery, communication and collaboration. The need
for servers, storage and software are highly demanding in the universities,
colleges and schools. Cloud Computing is an Internet based computing, whereby
shared resources, software and information, are provided to computers and
devices on-demand, like the electricity grid. Currently, IaaS (Infrastructure
as a Service), PaaS (Platform as a Service) and SaaS (Software as a Service)
are used as business model for Cloud Computing. The paper also introduces the
cloud computing infrastructure provided by Microsoft, Google and Amazon Web
Service. In this paper we will review the features the educational institutions
can use from the cloud computing providers to increase the benefits of students
and teachers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2623</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2623</id><created>2013-05-12</created><updated>2013-05-16</updated><authors><author><keyname>Zhao</keyname><forenames>Jun</forenames></author><author><keyname>Wang</keyname><forenames>Xinbing</forenames></author></authors><title>(k,m)-connectivity in Mobile Clustered Wireless Networks</title><categories>cs.IT cs.NI math.CO math.IT math.PR</categories><comments>This paper has been withdrawn by the author due to a crucial error in
  the calculation of Equation (28)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author due to a crucial error in the
calculation of Equation (28). We propose a novel concept of
$(k,m)$-connectivity in mobile clustered wireless networks, in which there are
$n$ mobile cluster members and $n^d$ static cluster heads, where $k,m,d$ are
all positive constants and $k\leq m$. $(k,m)$-connectivity signifies that in a
time period consisting of $m$ time slots, there exist at least $k$ time slots
for each cluster member and in any one of these $k$ time slots the cluster
member can directly communicate with at least one cluster head. We investigate
the critical transmission range of asymptotic $(k,m)$-connectivity when cluster
members move according to random walk or i.i.d. mobility model. Under random
walk mobility, we propose two general heterogeneous velocity models in which
cluster members may move with different velocities. Under both mobility models,
we also define weak and strong parameters conditions, resulting in different
accuracies of evaluations on the probability that the network is asymptotically
$(k,m)$-connected, denoted as $P(\mathcal {C})$ below for simplicity. For both
mobilities, under weak parameters condition, we provide bounds on $P(\mathcal
{C})$ and derive the critical transmission range for $(k,m)$-connectivity. For
random walk mobility with one kind of velocity model and i.i.d. mobility, under
strong parameters condition, we present a precise asymptotic probability
distribution of $P(\mathcal {C})$ in terms of the transmission radius. Our
results offer fundamental insights and theoretical guidelines on design of
large-scale wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2636</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2636</id><created>2013-05-12</created><authors><author><keyname>Korenblit</keyname><forenames>Mark</forenames></author></authors><title>Full Square Rhomboids and Their Algebraic Expressions</title><categories>cs.DS math.CO</categories><comments>13 pages, 10 figures. arXiv admin note: substantial text overlap with
  arXiv:1211.1661</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper investigates relationship between algebraic expressions and graphs.
We consider a digraph called a full square rhomboid that is an example of
non-series-parallel graphs. Our intention is to simplify the expressions of
full square rhomboids and eventually find their shortest representations. With
that end in view, we describe two decomposition methods for generating
expressions of full square rhomboids and carry out their comparative analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2642</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2642</id><created>2013-05-12</created><authors><author><keyname>Li</keyname><forenames>Sheng</forenames></author><author><keyname>de Lamare</keyname><forenames>Rodrigo C.</forenames></author></authors><title>Adaptive Frequency Domain Detectors for SC-FDE in Multiuser DS-UWB
  Systems with Structured Channel Estimation and Direct Adaptation</title><categories>cs.IT math.IT</categories><comments>8 figures IET Communications 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose two adaptive detection schemes based on
single-carrier frequency domain equalization (SC-FDE) for multiuser
direct-sequence ultra-wideband (DS-UWB) systems, which are termed structured
channel estimation (SCE) and direct adaptation (DA). Both schemes use the
minimum mean square error (MMSE) linear detection strategy and employ a cyclic
prefix. In the SCE scheme, we perform the adaptive channel estimation in the
frequency domain and implement the despreading in the time domain after the
FDE. In this scheme, the MMSE detection requires the knowledge of the number of
users and the noise variance. For this purpose, we propose simple algorithms
for estimating these parameters. In the DA scheme, the interference suppression
task is fulfilled with only one adaptive filter in the frequency domain and a
new signal expression is adopted to simplify the design of such a filter.
Least-mean squares (LMS), recursive least squares (RLS) and conjugate gradient
(CG) adaptive algorithms are then developed for both schemes. A complexity
analysis compares the computational complexity of the proposed algorithms and
schemes, and simulation results for the downlink illustrate their performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2645</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2645</id><created>2013-05-12</created><authors><author><keyname>Korenblit</keyname><forenames>Mark</forenames></author><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author></authors><title>On the Optimal Representation of Algebraic Expressions of Fibonacci
  Graphs</title><categories>cs.DS math.CO</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper investigates relationship between algebraic expressions and graphs.
We consider a digraph called a Fibonacci graph which gives a generic example of
non-series-parallel graphs. Our intention in this paper is to simplify the
expressions of Fibonacci graphs and eventually find their shortest
representations. With that end in view, we describe the optimal decomposition
method for generating Fibonacci graph expressions that is conjectured to
provide these representations. Proof (or disproof) of this conjecture is
presented as an open problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2647</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2647</id><created>2013-05-12</created><authors><author><keyname>Korenblit</keyname><forenames>Mark</forenames></author><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author></authors><title>Fibonacci Graphs and their Expressions</title><categories>cs.DS math.CO</categories><comments>39 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper investigates relationship between algebraic expressions and graphs.
We consider a digraph called a Fibonacci graph which gives a generic example of
non-series-parallel graphs. Our intention in this paper is to simplify the
expressions of Fibonacci graphs and eventually find their shortest
representations. With that end in view, we describe the number of methods for
generating Fibonacci graph expressions and carry out their comparative
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2648</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2648</id><created>2013-05-12</created><authors><author><keyname>Telgarsky</keyname><forenames>Matus</forenames></author></authors><title>Boosting with the Logistic Loss is Consistent</title><categories>cs.LG stat.ML</categories><comments>To appear, COLT 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This manuscript provides optimization guarantees, generalization bounds, and
statistical consistency results for AdaBoost variants which replace the
exponential loss with the logistic and similar losses (specifically, twice
differentiable convex losses which are Lipschitz and tend to zero on one side).
  The heart of the analysis is to show that, in lieu of explicit regularization
and constraints, the structure of the problem is fairly rigidly controlled by
the source distribution itself. The first control of this type is in the
separable case, where a distribution-dependent relaxed weak learning rate
induces speedy convergence with high probability over any sample. Otherwise, in
the nonseparable case, the convex surrogate risk itself exhibits
distribution-dependent levels of curvature, and consequently the algorithm's
output has small norm with high probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2661</identifier>
 <datestamp>2014-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2661</id><created>2013-05-12</created><updated>2014-01-04</updated><authors><author><keyname>Zbarsky</keyname><forenames>Samuel</forenames></author></authors><title>On Improved Bounds on Bounded Degree Spanning Trees for Points in
  Arbitrary Dimension</title><categories>cs.CG math.CO</categories><comments>17 pages, submitted to Discrete &amp; Computational Geometry</comments><journal-ref>S. Zbarsky. On Improved Bounds for Bounded Degree Spanning Trees
  for Points in Arbitrary Dimension. Discrete Comput. Geom.,51(1):427-437,2014</journal-ref><doi>10.1007/s00454-013-9566-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given points in Euclidean space of arbitrary dimension, we prove that there
exists a spanning tree having no vertices of degree greater than 3 with weight
at most 1.559 times the weight of the minimum spanning tree. We also prove that
there is a set of points such that no spanning tree of maximal degree 3 exists
that has this ratio be less than 1.447. Our central result is based on the
proof of the following claim:
  Given $n$ points in Euclidean space with one special point $V$, there exists
a Hamiltonian path with an endpoint at $V$ that is at most 1.559 times longer
than the sum of the distances of the points to $V$.
  These proofs also lead to a way to find the tree in linear time given the
minimal spanning tree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2670</identifier>
 <datestamp>2014-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2670</id><created>2013-05-13</created><updated>2014-01-03</updated><authors><author><keyname>Dvo&#x159;&#xe1;k</keyname><forenames>Zden&#x11b;k</forenames></author><author><keyname>Lidick&#xfd;</keyname><forenames>Bernard</forenames></author></authors><title>4-critical graphs on surfaces without contractible (&lt;=4)-cycles</title><categories>math.CO cs.DM</categories><comments>52 pages, 19 figures</comments><msc-class>05C15, 05C10</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that if G is a 4-critical graph embedded in a fixed surface $\Sigma$
so that every contractible cycle has length at least 5, then G can be expressed
as $G=G'\cup G_1\cup G_2\cup ... \cup G_k$, where $|V(G')|$ and $k$ are bounded
by a constant (depending linearly on the genus of $\Sigma$) and $G_1\ldots,G_k$
are graphs (of unbounded size) whose structure we describe exactly. The proof
is computer-assisted - we use computer to enumerate all plane 4-critical graphs
of girth 5 with a precolored cycle of length at most 16, that are used in the
basic case of the inductive proof of the statement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2679</identifier>
 <datestamp>2014-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2679</id><created>2013-05-13</created><updated>2013-06-26</updated><authors><author><keyname>Ong</keyname><forenames>Lawrence</forenames></author><author><keyname>Lim</keyname><forenames>Fabian</forenames></author><author><keyname>Ho</keyname><forenames>Chin Keong</forenames></author></authors><title>The Multi-Sender Multicast Index Coding</title><categories>cs.IT math.IT</categories><comments>This is an extended version of the same-titled paper accepted and to
  be presented at the IEEE International Symposium on Information Theory
  (ISIT), Istanbul, in July 2013</comments><journal-ref>Proceedings of the 2013 IEEE International Symposium on
  Information Theory Proceedings (ISIT), Istanbul. Turkey, 7-12 July 2013, pp.
  1147-1151</journal-ref><doi>10.1109/ISIT.2013.6620406</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We focus on the following instance of an index coding problem, where a set of
receivers are required to decode multiple messages, whilst each knows one of
the messages a priori. In particular, here we consider a generalized setting
where they are multiple senders, each sender only knows a subset of messages,
and all senders are required to collectively transmit the index code. For a
single sender, Ong and Ho (ICC, 2012) have established the optimal index
codelength, where the lower bound was obtained using a pruning algorithm. In
this paper, the pruning algorithm is simplified, and used in conjunction with
an appending technique to give a lower bound to the multi-sender case. An upper
bound is derived based on network coding. While the two bounds do not match in
general, for the special case where no two senders know any message bit in
common, the bounds match, giving the optimal index codelength. The results are
derived based on graph theory, and are expressed in terms of strongly connected
components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2680</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2680</id><created>2013-05-13</created><authors><author><keyname>AlDahri</keyname><forenames>Sulaiman S.</forenames></author></authors><title>A study for the effect of the Emphaticness and language and dialect for
  Voice Onset Time (VOT) in Modern Standard Arabic (MSA)</title><categories>cs.CL cs.SD</categories><comments>18 pages, Signal &amp; Image Processing:An International Journal (SIPIJ),
  2013 April</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The signal sound contains many different features, including Voice Onset Time
(VOT), which is a very important feature of stop sounds in many languages. The
only application of VOT values is stopping phoneme subsets. This subset of
consonant sounds is stop phonemes exist in the Arabic language, and in fact,
all languages. The pronunciation of these sounds is hard and unique especially
for less-educated Arabs and non-native Arabic speakers. VOT can be utilized by
the human auditory system to distinguish between voiced and unvoiced stops such
as /p/ and /b/ in English.This search focuses on computing and analyzing VOT of
Modern Standard Arabic (MSA), within the Arabic language, for all pairs of
non-emphatic (namely, /d/ and /t/) and emphatic pairs (namely, /d?/ and /t?/)
depending on carrier words. This research uses a database built by ourselves,
and uses the carrier words syllable structure: CV-CV-CV. One of the main
outcomes always found is the emphatic sounds (/d?/, /t?/) are less than 50% of
non-emphatic (counter-part) sounds ( /d/, /t/).Also, VOT can be used to
classify or detect for a dialect ina language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2684</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2684</id><created>2013-05-13</created><authors><author><keyname>Karray</keyname><forenames>Achraf</forenames></author><author><keyname>Teyeb</keyname><forenames>Rym</forenames></author><author><keyname>Jemaa</keyname><forenames>Maher Ben</forenames></author></authors><title>A Heuristic Approach for Web-Service Discovery and Selection</title><categories>cs.DC cs.SE</categories><journal-ref>International Journal of Computer Science &amp; Information Technology
  (IJCSIT) Vol 5, No 2, April 2013</journal-ref><doi>10.5121/ijcsit.2013.5210</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In today's businesses, service-oriented architectures represent the main
paradigm for IT infrastructures. Indeed, the emergence of Internet made it
possible to set up an exploitable environment to distribute applications on a
large scale, and this, by adapting the notion of &quot;service&quot;. With the
integration of this paradigm in Business to Business Domain (B2B), the number
of web services becomes very significant. Due to this increase, the discovery
and selection of web services meeting customer requirement become a very
difficult operation. Further, QoS properties must be taking into account in the
web service selection. Moreover, with the significant number of web service,
necessary time for the discovery of a service will be rather long. In this
paper, we propose an approach based on a new heuristic method called &quot;Bees
Algorithm&quot; inspired from honey bees behavior. We use this technique of
optimization in order to discover appropriate web services, meeting customer
requirements, in least time and taking into account the QoS properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2686</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2686</id><created>2013-05-13</created><authors><author><keyname>Tourani</keyname><forenames>Ali</forenames></author><author><keyname>Danesh</keyname><forenames>Amir Seyed</forenames></author></authors><title>Using Exclusive Web Crawlers to Store Better Results in Search Engines'
  Database</title><categories>cs.IR</categories><comments>8pages, 6figures</comments><journal-ref>International Journal of Web &amp; Semantic Technology Vol.4, No.2,
  April 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crawler-based search engines are the mostly used search engines among web and
Internet users, involve web crawling, storing in database, ranking, indexing
and displaying to the user. But it is noteworthy that because of increasing
changes in web sites search engines suffer high time and transfers costs which
are consumed to investigate the existence of each page in database while
crawling, updating database and even investigating its existence in any
crawling operations. &quot;Exclusive Web Crawler&quot; proposes guidelines for crawling
features, links, media and other elements and to store crawling results in a
certain table in its database on the web. With doing this, search engines store
each site's tables in their databases and implement their ranking results on
them. Thus, accuracy of data in every table (and its being up-to-date) is
ensured and no 404 result is shown in search results since, in fact, this data
crawler crawls data entered by webmaster and the database stores whatever he
wants to display.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2687</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2687</id><created>2013-05-13</created><authors><author><keyname>Chau</keyname><forenames>Duc Phu</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Thonnat</keyname><forenames>Monique</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Bremond</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Automatic Parameter Adaptation for Multi-object Tracking</title><categories>cs.CV</categories><comments>International Conference on Computer Vision Systems (ICVS) (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object tracking quality usually depends on video context (e.g. object
occlusion level, object density). In order to decrease this dependency, this
paper presents a learning approach to adapt the tracker parameters to the
context variations. In an offline phase, satisfactory tracking parameters are
learned for video context clusters. In the online control phase, once a context
change is detected, the tracking parameters are tuned using the learned values.
The experimental results show that the proposed approach outperforms the recent
trackers in state of the art. This paper brings two contributions: (1) a
classification method of video sequences to learn offline tracking parameters,
(2) a new method to tune online tracking parameters using tracking context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2694</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2694</id><created>2013-05-13</created><updated>2014-08-04</updated><authors><author><keyname>Le</keyname><forenames>Duc-Phong</forenames></author><author><keyname>Tan</keyname><forenames>Chik How</forenames></author></authors><title>Further Refinements of Miller Algorithm on Edwards curves</title><categories>cs.CR</categories><comments>10 pages</comments><acm-class>G.4; I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Edwards curves have received a lot of attention in the
cryptographic community due to their fast scalar multiplication algorithms.
Then, many works on the application of these curves to pairing-based
cryptography have been introduced. Xu and Lin (CT-RSA, 2010) presented
refinements to improve the Miller algorithm that is central role compute
pairings on Edwards curves. In this paper, we study further refinements to
Miller algorithm. Our approach is generic, hence it allow to compute both Weil
and Tate pairings on pairing-friendly Edwards curves of any embedding degree.
We analyze and show that our algorithm is faster than the original Miller
algorithm and the Xu-Lin's refinements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2704</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2704</id><created>2013-05-13</created><authors><author><keyname>Khan</keyname><forenames>Ahmad Alamgir</forenames></author></authors><title>Preventing Phishing Attacks using One Time Password and User Machine
  Identification</title><categories>cs.CR</categories><comments>5 Pages, 8 Figures, Published with International Journal of Computer
  Applications 0975 8887 Volume 68 No.3, April 2013</comments><journal-ref>International Journal of Computer Applications 68(3):7-11, April
  2013</journal-ref><doi>10.5120/11557-6839</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Phishing is a type of attack in which cyber criminals tricks the victims to
steal their personal and financial data. It has become an organized criminal
activity. Spoofed emails claiming to be from legitimate source are crafted in a
way to lead victims to reveal their personal, financial data by misdirecting
them to the counterfeit website.
  This research paper presents a novel approach to combat the Phishing attacks.
An approach is proposed where user will retrieve the one time password by SMS
or by alternate email address. After receiving the one time password the web
server will create an encrypted token for the users computer or device for
authentication. The encrypted token will be used for identification, any time
user wishes to access the website he or she must request the new password. The
one time password as name implies will expire after single use. The one time
password and encrypted token is a smart way to tackle this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2708</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2708</id><created>2013-05-13</created><authors><author><keyname>Khan</keyname><forenames>Rafiullah</forenames></author><author><keyname>Ali</keyname><forenames>Shaukat</forenames></author></authors><title>Conceptual Framework of Redundant Link Aggregation</title><categories>cs.NI</categories><comments>8 Pages, 4 figures</comments><doi>10.5121/cseij.2013.3202</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This is era of information blast. A huge quantity of information is pouring
in from various sources. The revolutionary advancement of Information and
Communication technologies bring the world close together. A pile of
information in different formats is just a click away. Which motivate the
organizations to get more internet bandwidth to consume and publish the
information over exploding cloud of Internet. The standard router redundancy
protocol is used to handle backup links however it cannot aggregate them.
Whereas the link standard aggregation protocol can aggregate the link but it
support only Ethernet technology. In this research paper a concept of Redundant
Link Aggregation (RLA) is proposed. RLA can aggregate and handle backup links
with main links regardless of carrier technology. Furthermore a data forwarding
mechanism Odd Load Balancing (OLB) is also proposed for RLA scheme. For the
sake of performance evaluation, Redundant Link Aggregation (RLA) is compared
with Virtual Router Redundancy Protocol (VRRP). The simulation result reveals
that Redundant Link Aggregation (RLA) can cover the bandwidth demand of the
network in peak hours by consuming backup links as well which with Virtual
Router Redundancy Protocol (VRRP) cannot. It is further noted that Odd Load
Balancing (OLB) feature can be used to save the cost in terms of money per
annum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2713</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2713</id><created>2013-05-13</created><updated>2013-05-14</updated><authors><author><keyname>Bukhari</keyname><forenames>Ijaz</forenames></author></authors><title>Early Detection of Alzheimer's - A Crucial Requirement</title><categories>cs.CV physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alzheimer's, an old age disease of people over 65 years causes problems with
memory, thinking and behavior. This disease progresses very slow and its
identification in early stages is very difficult. The symptoms of Alzheimer's
appear slowly and gradually will have worse effects. In its early stages, not
only the patients themselves but their loved ones are generally unable to
accept that the patient is suffering from disease. In this paper, we have
proposed a new algorithm to detect patients of Alzheimer's at early stages by
comparing the Magnetic Resonance Images (MRI) of the patients with normal
persons of their age. The progress of the disease can also be monitored by
periodic comparison of the previous and current MRI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2714</identifier>
 <datestamp>2013-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2714</id><created>2013-05-13</created><updated>2013-11-14</updated><authors><author><keyname>Oymak</keyname><forenames>Samet</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Sharp MSE Bounds for Proximal Denoising</title><categories>cs.IT math.IT math.OC</categories><comments>37 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Denoising has to do with estimating a signal $x_0$ from its noisy
observations $y=x_0+z$. In this paper, we focus on the &quot;structured denoising
problem&quot;, where the signal $x_0$ possesses a certain structure and $z$ has
independent normally distributed entries with mean zero and variance
$\sigma^2$. We employ a structure-inducing convex function $f(\cdot)$ and solve
$\min_x\{\frac{1}{2}\|y-x\|_2^2+\sigma\lambda f(x)\}$ to estimate $x_0$, for
some $\lambda&gt;0$. Common choices for $f(\cdot)$ include the $\ell_1$ norm for
sparse vectors, the $\ell_1-\ell_2$ norm for block-sparse signals and the
nuclear norm for low-rank matrices. The metric we use to evaluate the
performance of an estimate $x^*$ is the normalized mean-squared-error
$\text{NMSE}(\sigma)=\frac{\mathbb{E}\|x^*-x_0\|_2^2}{\sigma^2}$. We show that
NMSE is maximized as $\sigma\rightarrow 0$ and we find the \emph{exact} worst
case NMSE, which has a simple geometric interpretation: the
mean-squared-distance of a standard normal vector to the $\lambda$-scaled
subdifferential $\lambda\partial f(x_0)$. When $\lambda$ is optimally tuned to
minimize the worst-case NMSE, our results can be related to the constrained
denoising problem $\min_{f(x)\leq f(x_0)}\{\|y-x\|_2\}$. The paper also
connects these results to the generalized LASSO problem, in which, one solves
$\min_{f(x)\leq f(x_0)}\{\|y-Ax\|_2\}$ to estimate $x_0$ from noisy linear
observations $y=Ax_0+z$. We show that certain properties of the LASSO problem
are closely related to the denoising problem. In particular, we characterize
the normalized LASSO cost and show that it exhibits a &quot;phase transition&quot; as a
function of number of observations. Our results are significant in two ways.
First, we find a simple formula for the performance of a general convex
estimator. Secondly, we establish a connection between the denoising and linear
inverse problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2724</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2724</id><created>2013-05-13</created><authors><author><keyname>Broumi</keyname><forenames>Said</forenames></author></authors><title>Generalized Neutrosophic Soft Set</title><categories>cs.AI</categories><comments>14 pages, 11 figures</comments><journal-ref>International Journal of Computer Science, Engineering and
  Information Technology (IJCSEIT), Vol.3, No.2,April2013</journal-ref><doi>10.5121/ijcseit.2013.3202</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a new concept called generalized neutrosophic soft
set. This concept incorporates the beneficial properties of both generalized
neutrosophic set introduced by A.A. Salama [7]and soft set techniques proposed
by Molodtsov [4]. We also study some properties of this concept. Some
definitions and operations have been introduced on generalized neutrosophic
soft set. Finally we present an application of generalized neuutrosophic soft
set in decision making problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2732</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2732</id><created>2013-05-13</created><authors><author><keyname>Neu</keyname><forenames>Gergely</forenames></author><author><keyname>Bart&#xf3;k</keyname><forenames>G&#xe1;bor</forenames></author></authors><title>An efficient algorithm for learning with semi-bandit feedback</title><categories>cs.LG</categories><comments>submitted to ALT 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of online combinatorial optimization under
semi-bandit feedback. The goal of the learner is to sequentially select its
actions from a combinatorial decision set so as to minimize its cumulative
loss. We propose a learning algorithm for this problem based on combining the
Follow-the-Perturbed-Leader (FPL) prediction method with a novel loss
estimation procedure called Geometric Resampling (GR). Contrary to previous
solutions, the resulting algorithm can be efficiently implemented for any
decision set where efficient offline combinatorial optimization is possible at
all. Assuming that the elements of the decision set can be described with
d-dimensional binary vectors with at most m non-zero entries, we show that the
expected regret of our algorithm after T rounds is O(m sqrt(dT log d)). As a
side result, we also improve the best known regret bounds for FPL in the full
information setting to O(m^(3/2) sqrt(T log d)), gaining a factor of sqrt(d/m)
over previous bounds for this algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2738</identifier>
 <datestamp>2014-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2738</id><created>2013-05-13</created><authors><author><keyname>Nguyen</keyname><forenames>Vinh Phu</forenames></author><author><keyname>Kerfriden</keyname><forenames>Pierre</forenames></author><author><keyname>Bordas</keyname><forenames>Stephane</forenames></author></authors><title>Isogeometric cohesive elements for two and three dimensional composite
  delamination analysis</title><categories>math.NA cs.NA</categories><doi>10.1016/j.compositesb.2013.12.018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Isogeometric cohesive elements are presented for modeling two and three
dimensional delaminated composite structures. We exploit the knot insertion
algorithm offered by NURBS (Non Uniform Rational B-splines) to generate
cohesive elements along delamination planes in an automatic fashion. A complete
computational framework is presented including pre-processing, processing and
post-processing. They are explained in details and implemented in MIGFEM--an
open source Matlab Isogemetric Analysis code developed by the authors. The
composite laminates are modeled using both NURBS solid and shell elements.
Several two and three dimensional examples ranging from standard delamination
tests (the mixed mode bending test), the L-shaped specimen with a fillet, three
dimensional (3D) double cantilever beam and a 3D singly curved thick-walled
laminate are provided. To the authors' knowledge, it is the first time that
NURBS-based isogeometric analysis for two/three dimensional delamination
modeling is presented. For all examples considered, the proposed framework
outperforms conventional Lagrange finite elements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2741</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2741</id><created>2013-05-13</created><authors><author><keyname>Tadic</keyname><forenames>Bosiljka</forenames></author><author><keyname>Suvakov</keyname><forenames>Milovan</forenames></author></authors><title>Can Human-Like Bots Control Collective Mood: Agent-Based Simulations of
  Online Chats</title><categories>physics.soc-ph cs.SI</categories><comments>21 pages, 9 figures (multiple) color</comments><doi>10.1088/1742-5468/2013/10/P10014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using agent-based modeling approach, in this paper, we study self-organized
dynamics of interacting agents in the presence of chat Bots. Different Bots
with tunable ``human-like'' attributes, which exchange emotional messages with
agents, are considered, and collective emotional behavior of agents is
quantitatively analysed. In particular, using detrended fractal analysis we
determine persistent fluctuations and temporal correlations in time series of
agent's activity and statistics of avalanches carrying emotional messages of
agents when Bots favoring positive/negative affects are active. We determine
the impact of Bots and identify parameters that can modulate it. Our analysis
suggests that, by these measures, the emotional Bots induce collective emotion
among interacting agents by suitably altering the fractal characteristics of
the underlying stochastic process.Positive-emotion Bots are slightly more
effective than the negative ones. Moreover, the Bots which are periodically
alternating between positive and negative emotion, can enhance fluctuations in
the system leading to the avalanches of agent's messages that are reminiscent
of self-organized critical states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2743</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2743</id><created>2013-05-13</created><updated>2013-09-04</updated><authors><author><keyname>Guillemot</keyname><forenames>Sylvain</forenames></author><author><keyname>Marx</keyname><forenames>D&#xe1;niel</forenames></author></authors><title>A faster FPT algorithm for Bipartite Contraction</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The \textsc{Bipartite Contraction} problem is to decide, given a graph $G$
and a parameter $k$, whether we can can obtain a bipartite graph from $G$ by at
most $k$ edge contractions. The fixed-parameter tractability of the problem was
shown by [Heggernes et al. 2011], with an algorithm whose running time has
double-exponential dependence on $k$. We present a new randomized FPT algorithm
for the problem, which is both conceptually simpler and achieves an improved
$2^{O(k^2)} n m$ running time, i.e., avoiding the double-exponential dependence
on $k$. The algorithm can be derandomized using standard techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2744</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2744</id><created>2013-05-13</created><authors><author><keyname>Husainov</keyname><forenames>Ahmet A.</forenames></author><author><keyname>Kudryashova</keyname><forenames>E. S.</forenames></author></authors><title>Time Estimation Model of Concurrent Computing Systems</title><categories>cs.LO</categories><comments>6 pages</comments><msc-class>68Q10, 68Q85</msc-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We consider an asynchronous system with transitions corresponding to the
instructions of a computer system. For each instruction, a runtime is given. We
propose a mathematical model, allowing us to construct an algorithm for finding
the minimum time of the parallel process with a given trace. We consider a
problem of constructing a parallel process which transforms the initial state
to given and has the minimum execution time. We show that it is reduced to the
problem of finding the shortest path in a directed graph with edge lengths
equal to 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2752</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2752</id><created>2013-05-13</created><authors><author><keyname>Naseer</keyname><forenames>Oumair</forenames></author><author><keyname>Khan</keyname><forenames>Atif Ali</forenames></author></authors><title>Hybrid fuzzy logic and pid controller based ph neutralization pilot
  plant</title><categories>cs.SY cs.AI</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Use of Control theory within process control industries has changed rapidly
due to the increase complexity of instrumentation, real time requirements,
minimization of operating costs and highly nonlinear characteristics of
chemical process. Previously developed process control technologies which are
mostly based on a single controller are not efficient in terms of signal
transmission delays, processing power for computational needs and signal to
noise ratio. Hybrid controller with efficient system modelling is essential to
cope with the current challenges of process control in terms of control
performance. This paper presents an optimized mathematical modelling and
advance hybrid controller (Fuzzy Logic and PID) design along with practical
implementation and validation of pH neutralization pilot plant. This procedure
is particularly important for control design and automation of Physico-chemical
systems for process control industry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2755</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2755</id><created>2013-05-13</created><authors><author><keyname>Sahmoudi</keyname><forenames>Issam</forenames></author><author><keyname>Lachkar</keyname><forenames>Abdelmonaime</forenames></author></authors><title>Clustering Web Search Results For Effective Arabic Language Browsing</title><categories>cs.IR</categories><msc-class>68P20</msc-class><acm-class>H.3.3</acm-class><journal-ref>International Journal on Natural Language Computing (IJNLC) Vol.
  2, No.2, April 2013</journal-ref><doi>10.5121/ijnlc.2013.2202</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The process of browsing Search Results is one of the major problems with
traditional Web search engines for English, European, and any other languages
generally, and for Arabic Language particularly. This process is absolutely
time consuming and the browsing style seems to be unattractive. Organizing Web
search results into clusters facilitates users quick browsing through search
results. Traditional clustering techniques (data-centric clustering algorithms)
are inadequate since they don't generate clusters with highly readable names or
cluster labels. To solve this problem, Description-centric algorithms such as
Suffix Tree Clustering (STC) algorithm have been introduced and used
successfully and extensively with different adapted versions for English,
European, and Chinese Languages. However, till the day of writing this paper,
in our knowledge, STC algorithm has been never applied for Arabic Web Snippets
Search Results Clustering.In this paper, we propose first, to study how STC can
be applied for Arabic Language? We then illustrate by example that is
impossible to apply STC after Arabic Snippets pre-processing (stem or root
extraction) because the Merging process yields many redundant clusters.
Secondly, to overcome this problem, we propose to integrate STC in a new scheme
taking into a count the Arabic language properties in order to get the web more
and more adapted to Arabic users. The proposed approach automatically clusters
the web search results into high quality, and high significant clusters labels.
The obtained clusters not only are coherent, but also can convey the contents
to the users concisely and accurately. Therefore the Arabic users can decide at
a glance whether the contents of a cluster are of interest.....
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2758</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2758</id><created>2013-05-13</created><authors><author><keyname>Naseer</keyname><forenames>1Oumair</forenames></author><author><keyname>Naseer</keyname><forenames>2Ayesha</forenames></author><author><keyname>Khan</keyname><forenames>3Atif Ali</forenames></author><author><keyname>Naseer</keyname><forenames>4Humza</forenames></author></authors><title>Using Page Size for Controlling Duplicate Query Results in Semantic Web</title><categories>cs.DB</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Semantic web is a web of future. The Resource Description Framework (RDF) is
a language to represent resources in the World Wide Web. When these resources
are queried the problem of duplicate query results occurs. The present
techniques used hash index comparison to remove duplicate query results. The
major drawback of using the hash index to remove duplicate query results is
that, if there is a slight change in formatting or word order, then hash index
is changed and query results are no more considered as duplicate even though
they have same contents. We presented an algorithm for detection and
elimination of duplicate query results from semantic web using hash index and
page size comparisons. Experimental results showed that the proposed technique
removed duplicate query results from semantic web efficiently, solved the
problems of using hash index for duplicate handling and could be embedded in
existing SQL-Based query system for semantic web. Research could be carried out
for certain flexibilities in existing SQL-Based query system of semantic web to
accommodate other duplicate detection techniques as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2767</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2767</id><created>2013-05-13</created><authors><author><keyname>M&#xe9;riaux</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>E3S</affiliation></author><author><keyname>Lasaulce</keyname><forenames>Samson</forenames><affiliation>E3S</affiliation></author><author><keyname>Tembine</keyname><forenames>Hamidou</forenames><affiliation>E3S</affiliation></author></authors><title>Stochastic Differential Games and Energy-Efficient Power Control</title><categories>cs.NI cs.GT</categories><comments>The final publication is available at
  http://www.springerlink.com/openurl.asp?genre=article\&amp;id=doi:10.1007/s13235-012-0068-1</comments><proxy>ccsd</proxy><journal-ref>Dynamic ames and Applications 3, 1 (2013) 3-23</journal-ref><doi>10.1007/s13235-012-0068-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the contributions of this work is to formulate the problem of
energy-efficient power control in multiple access channels (namely, channels
which comprise several transmitters and one receiver) as a stochastic
differential game. The players are the transmitters who adapt their power level
to the quality of their time-varying link with the receiver, their battery
level, and the strategy updates of the others. The proposed model not only
allows one to take into account long-term strategic interactions but also
long-term energy constraints. A simple sufficient condition for the existence
of a Nash equilibrium in this game is provided and shown to be verified in a
typical scenario. As the uniqueness and determination of equilibria are
difficult issues in general, especially when the number of players goes large,
we move to two special cases: the single player case which gives us some useful
insights of practical interest and allows one to make connections with the case
of large number of players. The latter case is treated with a mean-field game
approach for which reasonable sufficient conditions for convergence and
uniqueness are provided. Remarkably, this recent approach for large system
analysis shows how scalability can be dealt with in large games and only relies
on the individual state information assumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2770</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2770</id><created>2013-05-13</created><authors><author><keyname>Aldhafferi</keyname><forenames>Nahier</forenames></author><author><keyname>Watson</keyname><forenames>Charles</forenames></author><author><keyname>Sajeev</keyname><forenames>A. S. M</forenames></author></authors><title>Personal Information Privacy Settings of Online Social Networks and
  their Suitability for Mobile Internet Devices</title><categories>cs.SI cs.CY</categories><journal-ref>International Journal of Security, Privacy and Trust Management
  (IJSPTM), vol 2, No 2, April 2013</journal-ref><doi>10.5121/ijsptm.2013.2201</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Protecting personal information privacy has become a controversial issue
among online social network providers and users. Most social network providers
have developed several techniques to decrease threats and risks to the users
privacy. These risks include the misuse of personal information which may lead
to illegal acts such as identity theft. This study aims to measure the
awareness of users on protecting their personal information privacy, as well as
the suitability of the privacy systems which they use to modify privacy
settings. Survey results show high percentage of the use of smart phones for
web services but the current privacy settings for online social networks need
to be improved to support different type of mobile phones screens. Because most
users use their mobile phones for Internet services, privacy settings that are
compatible with mobile phones need to be developed. The method of selecting
privacy settings should also be simplified to provide users with a clear
picture of the data that will be shared with others. Results of this study can
be used to develop a new privacy system which will help users control their
personal information easily from different devices, including mobile Internet
devices and computers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2772</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2772</id><created>2013-05-13</created><authors><author><keyname>Gill&#xe9;</keyname><forenames>Marc</forenames></author></authors><title>OBDD-Based Representation of Interval Graphs</title><categories>cs.DS cs.LO</categories><comments>29 pages, accepted for 39th International Workshop on Graph-Theoretic
  Concepts 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph $G = (V,E)$ can be described by the characteristic function of the
edge set $\chi_E$ which maps a pair of binary encoded nodes to 1 iff the nodes
are adjacent. Using \emph{Ordered Binary Decision Diagrams} (OBDDs) to store
$\chi_E$ can lead to a (hopefully) compact representation. Given the OBDD as an
input, symbolic/implicit OBDD-based graph algorithms can solve optimization
problems by mainly using functional operations, e.g. quantification or binary
synthesis. While the OBDD representation size can not be small in general, it
can be provable small for special graph classes and then also lead to fast
algorithms. In this paper, we show that the OBDD size of unit interval graphs
is $O(\ | V \ | /\log \ | V \ |)$ and the OBDD size of interval graphs is $O(\
| V \ | \log \ | V \ |)$ which both improve a known result from Nunkesser and
Woelfel (2009). Furthermore, we can show that using our variable order and node
labeling for interval graphs the worst-case OBDD size is $\Omega(\ | V \ | \log
\ | V \ |)$. We use the structure of the adjacency matrices to prove these
bounds. This method may be of independent interest and can be applied to other
graph classes. We also develop a maximum matching algorithm on unit interval
graphs using $O(\log \ | V \ |)$ operations and a coloring algorithm for unit
and general intervals graphs using $O(\log^2 \ | V \ |)$ operations and
evaluate the algorithms empirically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2776</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2776</id><created>2013-05-13</created><authors><author><keyname>Chen</keyname><forenames>Xu</forenames><affiliation>EE</affiliation></author><author><keyname>M&#xe9;riaux</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Valentin</keyname><forenames>Stefan</forenames></author></authors><title>Predicting a User's Next Cell With Supervised Learning Based on Channel
  States</title><categories>cs.NI</categories><comments>The 14th IEEE International Workshop on Signal Processing Advances
  for Wireless Communications (SPAWC), Darmstadt : Germany (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowing a user's next cell allows more efficient resource allocation and
enables new location-aware services. To anticipate the cell a user will
hand-over to, we introduce a new machine learning based prediction system.
Therein, we formulate the prediction as a classification problem based on
information that is readily available in cellular networks. Using only Channel
State Information (CSI) and handover history, we perform classification by
embedding Support Vector Machines (SVMs) into an efficient pre-processing
structure. Simulation results from a Manhattan Grid scenario and from a
realistic radio map of downtown Frankfurt show that our system provides timely
prediction at high accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2777</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2777</id><created>2013-05-13</created><updated>2013-05-16</updated><authors><author><keyname>Bille</keyname><forenames>Philip</forenames></author><author><keyname>Cording</keyname><forenames>Patrick Hagge</forenames></author><author><keyname>G&#xf8;rtz</keyname><forenames>Inge Li</forenames></author><author><keyname>Sach</keyname><forenames>Benjamin</forenames></author><author><keyname>Vildh&#xf8;j</keyname><forenames>Hjalte Wedel</forenames></author><author><keyname>Vind</keyname><forenames>S&#xf8;ren</forenames></author></authors><title>Fingerprints in Compressed Strings</title><categories>cs.DS</categories><comments>An extended abstract of this paper will appear at WADS 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Karp-Rabin fingerprint of a string is a type of hash value that due to
its strong properties has been used in many string algorithms. In this paper we
show how to construct a data structure for a string $S$ of size $N$ compressed
by a context-free grammar of size $n$ that answers fingerprint queries. That
is, given indices $i$ and $j$, the answer to a query is the fingerprint of the
substring $S[i,j]$. We present the first O(n) space data structures that answer
fingerprint queries without decompressing any characters. For Straight Line
Programs (SLP) we get $O(\log N)$ query time, and for Linear SLPs (an SLP
derivative that captures LZ78 compression and its variations) we get $O(\log
\log N)$ query time. Hence, our data structures has the same time and space
complexity as for random access in SLPs. We utilize the fingerprint data
structures to solve the longest common extension problem in query time $O(\log
N \log \lce)$ and $O(\log \lce \log\log \lce + \log\log N)$ for SLPs and Linear
SLPs, respectively. Here, $\lce$ denotes the length of the LCE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2788</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2788</id><created>2013-05-13</created><authors><author><keyname>Pedregosa</keyname><forenames>Fabian</forenames><affiliation>INRIA Paris - Rocquencourt, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Eickenberg</keyname><forenames>Michael</forenames><affiliation>INRIA Saclay - Ile de France, LNAO</affiliation></author><author><keyname>Thirion</keyname><forenames>Bertrand</forenames><affiliation>INRIA Saclay - Ile de France, LNAO</affiliation></author><author><keyname>Gramfort</keyname><forenames>Alexandre</forenames><affiliation>LTCI</affiliation></author></authors><title>HRF estimation improves sensitivity of fMRI encoding and decoding models</title><categories>cs.LG stat.AP</categories><comments>3nd International Workshop on Pattern Recognition in NeuroImaging
  (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extracting activation patterns from functional Magnetic Resonance Images
(fMRI) datasets remains challenging in rapid-event designs due to the inherent
delay of blood oxygen level-dependent (BOLD) signal. The general linear model
(GLM) allows to estimate the activation from a design matrix and a fixed
hemodynamic response function (HRF). However, the HRF is known to vary
substantially between subjects and brain regions. In this paper, we propose a
model for jointly estimating the hemodynamic response function (HRF) and the
activation patterns via a low-rank representation of task effects.This model is
based on the linearity assumption behind the GLM and can be computed using
standard gradient-based solvers. We use the activation patterns computed by our
model as input data for encoding and decoding studies and report performance
improvement in both settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2789</identifier>
 <datestamp>2014-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2789</id><created>2013-05-13</created><updated>2014-07-10</updated><authors><author><keyname>Pohl</keyname><forenames>Volker</forenames></author><author><keyname>Yang</keyname><forenames>Fanny</forenames></author><author><keyname>Boche</keyname><forenames>Holger</forenames></author></authors><title>Phaseless Signal Recovery in Infinite Dimensional Spaces using
  Structured Modulations</title><categories>cs.IT math.IT</categories><comments>Preprint accepted for publication in the Journal of Fourier Analysis
  and Applications</comments><msc-class>30D10, 94A20 (Primary) 42C15, 94A12 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the recovery of continuous signals in infinite
dimensional spaces from the magnitude of their frequency samples. It proposes a
sampling scheme which involves a combination of oversampling and modulations
with complex exponentials. Sufficient conditions are given such that almost
every signal with compact support can be reconstructed up to a unimodular
constant using only its magnitude samples in the frequency domain. Finally it
is shown that an average sampling rate of four times the Nyquist rate is enough
to reconstruct almost every time-limited signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2796</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2796</id><created>2013-05-13</created><authors><author><keyname>Pak</keyname><forenames>Igor</forenames></author><author><keyname>Yang</keyname><forenames>Jed</forenames></author></authors><title>Tiling simply connected regions with rectangles</title><categories>math.CO cs.CC cs.CG</categories><comments>18 pages, 13 figures</comments><msc-class>52C20 (Primary) 05B45, 68Q17 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In [BNRR], it was shown that tiling of general regions with two rectangles is
NP-complete, except for a few trivial special cases. In a different direction,
R\'emila showed that for simply connected regions by two rectangles, the
tileability can be solved in quadratic time (in the area). We prove that there
is a finite set of at most 10^6 rectangles for which the tileability problem of
simply connected regions is NP-complete, closing the gap between positive and
negative results in the field. We also prove that counting such rectangular
tilings is #P-complete, a first result of this kind.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2801</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2801</id><created>2013-05-13</created><authors><author><keyname>Redfern</keyname><forenames>Arthur J.</forenames></author><author><keyname>Shi</keyname><forenames>Kun</forenames></author></authors><title>Quantization Noise Shaping for Information Maximizing ADCs</title><categories>cs.IT math.IT</categories><comments>4 pages, 6 figures</comments><msc-class>94A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ADCs sit at the interface of the analog and digital worlds and fundamentally
determine what information is available in the digital domain for processing.
This paper shows that a configurable ADC can be designed for signals with non
constant information as a function of frequency such that within a fixed power
budget the ADC maximizes the information in the converted signal by frequency
shaping the quantization noise. Quantization noise shaping can be realized via
loop filter design for a single channel delta sigma ADC and extended to common
time and frequency interleaved multi channel structures. Results are presented
for example wireline and wireless style channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2827</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2827</id><created>2013-05-10</created><authors><author><keyname>Badar</keyname><forenames>Preeti</forenames></author><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author></authors><title>Human Mood Detection For Human Computer Interaction</title><categories>cs.CV</categories><comments>Pages: 04 Figures: 06 Tables: 01, Proceedings of ICETETS-08, Rajkot,
  India, 13-14 January 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose an easiest approach for facial expression
recognition. Here we are using concept of SVM for Expression Classification.
Main problem is sub divided in three main modules. First one is Face detection
in which we are using skin filter and Face segmentation. We are given more
stress on feature Extraction. This method is effective enough for application
where fast execution is required. Second, Facial Feature Extraction which is
essential part for expression recognition. In this module we used Edge
Projection Analysis. Finally extracted features vector is passed towards SVM
classifier for Expression Recognition. We are considering six basic Expressions
(Anger, Fear, Disgust, Joy, Sadness, and Surprise)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2828</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2828</id><created>2013-05-10</created><authors><author><keyname>Jain</keyname><forenames>Shweta</forenames></author><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author></authors><title>Image Optimization and Prediction</title><categories>cs.CV</categories><comments>Pages: 08 Figures: 02, Proceedings of International Conferences
  CAAM-09 BITS, Durg, India, 10 Jan 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image Processing, Optimization and Prediction of an Image play a key role in
Computer Science. Image processing provides a way to analyze and identify an
image .Many areas like medical image processing, Satellite images, natural
images and artificial images requires lots of analysis and research on
optimization. In Image Optimization and Prediction we are combining the
features of Query Optimization, Image Processing and Prediction . Image
optimization is used in Pattern analysis, object recognition, in medical Image
processing to predict the type of diseases, in satellite images for predicting
weather forecast, availability of water or mineral etc. Image Processing,
Optimization and analysis is a wide open area for research .Lots of research
has been conducted in the area of Image analysis and many techniques are
available for image analysis but, a single technique is not yet identified for
image analysis and prediction .our research is focused on identifying a global
technique for image analysis and Prediction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2830</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2830</id><created>2013-05-10</created><authors><author><keyname>Patel</keyname><forenames>Rahila</forenames></author><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author><author><keyname>Raghuwanshi</keyname><forenames>MM.</forenames></author><author><keyname>Jaiswal</keyname><forenames>Anil N.</forenames></author></authors><title>Performance Enhancement of Distributed Quasi Steady-State Genetic
  Algorithm</title><categories>cs.NE</categories><comments>Pages: 09 Figures: 08 Tables: 05, International Journal of Digital
  Technology, 2009 pp 52-60</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new scheme for performance enhancement of distributed
genetic algorithm (DGA). Initial population is divided in two classes i.e.
female and male. Simple distance based clustering is used for cluster formation
around females. For reclustering self-adaptive K-means is used, which produces
well distributed and well separated clusters. The self-adaptive K-means used
for reclustering automatically locates initial position of centroids and number
of clusters. Four plans of co-evolution are applied on these clusters
independently. Clusters evolve separately. Merging of clusters takes place
depending on their performance. For experimentation unimodal and multimodal
test functions have been used. Test result show that the new scheme of
distribution of population has given better performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2831</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2831</id><created>2013-05-10</created><authors><author><keyname>Thakkar</keyname><forenames>Khushboo</forenames></author><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author></authors><title>Test Model for Text Categorization and Text Summarization</title><categories>cs.IR</categories><comments>Pages: 07 Figures : 07</comments><journal-ref>International Journal on Computer Science and Engineering (IJCSE),
  ISSN : 0975-3397, Vol. 3 No. 4 Apr 2011 pp 1539-1545</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Text Categorization is the task of automatically sorting a set of documents
into categories from a predefined set and Text Summarization is a brief and
accurate representation of input text such that the output covers the most
important concepts of the source in a condensed manner. Document Summarization
is an emerging technique for understanding the main purpose of any kind of
documents. This paper presents a model that uses text categorization and text
summarization for searching a document based on user query.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2835</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2835</id><created>2013-05-13</created><authors><author><keyname>Kosmatopoulos</keyname><forenames>Andreas</forenames></author><author><keyname>Tsichlas</keyname><forenames>Kostas</forenames></author></authors><title>Dynamic Top-$k$ Dominating Queries</title><categories>cs.CG cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\mathcal{S}$ be a dataset of $n$ 2-dimensional points. The top-$k$
dominating query aims to report the $k$ points that dominate the most points in
$\mathcal{S}$. A point $p$ dominates a point $q$ iff all coordinates of $p$ are
smaller than or equal to those of $q$ and at least one of them is strictly
smaller. The top-$k$ dominating query combines the dominance concept of maxima
queries with the ranking function of top-$k$ queries and can be used as an
important tool in multi-criteria decision making systems. In this work, we
propose novel algorithms for answering semi-dynamic (insertions only) and fully
dynamic (insertions and deletions) top-$k$ dominating queries. To the best of
our knowledge, this is the first work towards handling (semi-)dynamic top-$k$
dominating queries that offers algorithms with asymptotic guarantees regarding
their time and space cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2836</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2836</id><created>2013-05-10</created><authors><author><keyname>Pathak</keyname><forenames>Smita</forenames></author><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author></authors><title>Infrastructure to Vehicle Real Time Secured Communication</title><categories>cs.NI</categories><comments>Pages: 05 Figures: 04, Proceedings of International Symposium on
  Computing, Communication, and Control, ISBN 978-1-84626, 2009. arXiv admin
  note: text overlap with arXiv:0912.5391 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Among civilian communication systems, vehicular networks emerge as one of the
most is convincing and yet most challenging instantiations of the mobile ad hoc
networking technology. Towards the deployment of vehicular communication
systems, security and privacy are critical factors and significant challenges
to be met. This Vehicular communication (VC) system has the potential to
improve road safety and driving comfort. Nevertheless, securing the operation
is a prerequisite for deployment so in this paper we are focusing on real time
experimental design of infrastructure to vehicle communication. We outline how
VANET will be a better option than GPS technology. We also try to discuss IP
address passing using DHCP in the network and the security issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2837</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2837</id><created>2013-05-10</created><authors><author><keyname>Chokhandre</keyname><forenames>Sumedha</forenames></author><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author></authors><title>An Algorithm to Improve Performance over Multihop Wireless Mesh Network</title><categories>cs.NI</categories><comments>Pages: 05 Figures: 07</comments><journal-ref>Journal of Computing, Volume 3, Issue 5, May 2011, ISSN 2151-9617,
  pp 155,159</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transmission Control Protocol (TCP) is the dominant reliable transport
protocol utilized in the Internet. Improving the performance of TCP associated
with the presence of multi-hop is one of the research challenges in wireless
mesh networks. Wireless mesh networks have large round trip time variations and
these variations are dependent on the number of hops. In wireless mesh network,
when congestion loss and wireless loss are co-existed the number of packets
dropped increases and will have adverse effects on TCP and its congestion
control mechanism which leads to low throughput. Here we have designed a new
TCP scheme for multi-hop wireless mesh networks, by modifying the sender side
congestion control functionality of TCP NewReno, which is tuned towards
improving the performance of TCP. The simulation results show that TCP SAC has
higher performance than TCP NewReno, Reno, Sack and Vegas in multi-hop wireless
mesh networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2838</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2838</id><created>2013-05-10</created><authors><author><keyname>Kapse</keyname><forenames>Vinay</forenames></author><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author></authors><title>Interference-Aware Channel Assignment for Maximizing Throughput in WMN</title><categories>cs.NI</categories><comments>Pages: 12 Figures: 11 Tables: 01, International Journal on AdHoc
  Networking Systems (IJANS), Vol. 1, No. 1, June 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Mesh network (WMN) is dynamically self-organizing and
self-configured, with the nodes in the network automatically establishing an
ad-hoc network and maintaining the mesh connectivity. The ability to use
multiple-radios and multiple channels can be cashed to increase aggregate
throughput of wireless mesh network. Thus the efficient use of available
interfaces and channels without interference becomes the key factor. In this
paper we propose, interference aware clustered based channel assignment schemes
which minimizes the interference and increases throughput. In our proposed
scheme we have given priority to minimize interference from nearby mesh nodes
in interference range than maximizing channel diversity. We simulated our
proposed work using NS-3 and results show that our scheme improves network
performance than BFSCA and Distributed Greedy CA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2846</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2846</id><created>2013-05-09</created><authors><author><keyname>Makhijani</keyname><forenames>Rashmi</forenames></author><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author><author><keyname>Thakare</keyname><forenames>V M</forenames></author></authors><title>Opportunities &amp; Challenges In Automatic Speech Recognition</title><categories>cs.CL cs.SD</categories><comments>Pages: 05 Figures : 01 Proceedings of the International Conference
  BEATS 2010, NIT Jalandhar, INDIA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic speech recognition enables a wide range of current and emerging
applications such as automatic transcription, multimedia content analysis, and
natural human-computer interfaces. This paper provides a glimpse of the
opportunities and challenges that parallelism provides for automatic speech
recognition and related application research from the point of view of speech
researchers. The increasing parallelism in computing platforms opens three
major possibilities for speech recognition systems: improving recognition
accuracy in non-ideal, everyday noisy environments; increasing recognition
throughput in batch processing of speech data; and reducing recognition latency
in realtime usage scenarios. This paper describes technical challenges,
approaches taken, and possible directions for future research to guide the
design of efficient parallel software and hardware infrastructures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2847</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2847</id><created>2013-05-09</created><authors><author><keyname>Mishra</keyname><forenames>Neema</forenames></author><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author><author><keyname>Thakare</keyname><forenames>V M</forenames></author></authors><title>An Overview of Hindi Speech Recognition</title><categories>cs.CL cs.SD</categories><comments>Pages: 05 Figures : 04 Tables : 03 Proceedings of the International
  Conference ICCSCT 2010, Tirunelveli, India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this age of information technology, information access in a convenient
manner has gained importance. Since speech is a primary mode of communication
among human beings, it is natural for people to expect to be able to carry out
spoken dialogue with computer. Speech recognition system permits ordinary
people to speak to the computer to retrieve information. It is desirable to
have a human computer dialogue in local language. Hindi being the most widely
spoken Language in India is the natural primary human language candidate for
human machine interaction. There are five pairs of vowels in Hindi languages;
one member is longer than the other one. This paper describes an overview of
speech recognition system that includes how speech is produced and the
properties and characteristics of Hindi Phoneme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2865</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2865</id><created>2013-04-10</created><authors><author><keyname>Ullah</keyname><forenames>Sultan</forenames></author><author><keyname>Xuefeng</keyname><forenames>Zheng</forenames></author><author><keyname>Feng</keyname><forenames>Zhou</forenames></author></authors><title>TCloud: A Dynamic Framework and Policies for Access Control across
  Multiple Domains in Cloud Computing</title><categories>cs.DC cs.CR</categories><journal-ref>International Journal of Computer Applications, Volume 62, No.2,
  January 2013, 01-07</journal-ref><doi>10.5120/10049-4636</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a cloud computing environment, access control policy is an effective means
of fortification cloud users and cloud resources services against security
infringements. Based on analysis of current cloud computing security
characteristics, the preamble of the concept of trust, role-based access
control policy, combined with the characteristics of the cloud computing
environment, there are multiple security management domains, so a new cross
domain framework is for access control is proposed which is based on trust. It
will establish and calculate the degree of trust in the single as well as
multiple domains. Role Based Access Control is used for the implementation of
the access control policies in a single domain environment with the
introduction of the trust concept. In multiple domains the access control will
be based on the conversion of roles. On the basis of trust, and role based
access control model, a new novel framework of flexible cross domain access
control framework is presented. The role assignment and conversion will take
place dynamically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2866</identifier>
 <datestamp>2014-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2866</id><created>2013-05-13</created><updated>2014-04-19</updated><authors><author><keyname>Viglietta</keyname><forenames>Giovanni</forenames></author></authors><title>Face-Guarding Polyhedra</title><categories>cs.CG cs.CC</categories><comments>24 pages, 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the Art Gallery Problem for face guards in polyhedral environments.
The problem can be informally stated as: how many (not necessarily convex)
windows should we place on the external walls of a dark building, in order to
completely illuminate its interior?
  We consider both closed and open face guards (i.e., faces with or without
their boundary), and we study several classes of polyhedra, including
orthogonal polyhedra, 4-oriented polyhedra, and 2-reflex orthostacks.
  We give upper and lower bounds on the minimum number of faces required to
guard the interior of a given polyhedron in each of these classes, in terms of
the total number of its faces, f. In several cases our bounds are tight: f/6
open face guards for orthogonal polyhedra and 2-reflex orthostacks, and f/4
open face guards for 4-oriented polyhedra. Additionally, for closed face guards
in 2-reflex orthostacks, we give a lower bound of (f+3)/9 and an upper bound of
(f+1)/7.
  Then we show that it is NP-hard to approximate the minimum number of (closed
or open) face guards within a factor of Omega(log f), even for polyhedra that
are orthogonal and simply connected. We also obtain the same hardness results
for polyhedral terrains.
  Along the way we discuss some applications, arguing that face guards are not
a reasonable model for guards patrolling on the surface of a polyhedron.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2876</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2876</id><created>2013-05-10</created><authors><author><keyname>Fabbri</keyname><forenames>Ricardo</forenames></author><author><keyname>Bastos</keyname><forenames>Ivan N.</forenames></author><author><keyname>Neto</keyname><forenames>Francisco D. Moura</forenames></author><author><keyname>Lopes</keyname><forenames>Francisco J. P.</forenames></author><author><keyname>Goncalves</keyname><forenames>Wesley N.</forenames></author><author><keyname>Bruno</keyname><forenames>Odemir M.</forenames></author></authors><title>Multi-q Pattern Classification of Polarization Curves</title><categories>cs.CE cs.CV</categories><comments>12 pages, 7 figures</comments><doi>10.1016/j.physa.2013.09.048</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Several experimental measurements are expressed in the form of
one-dimensional profiles, for which there is a scarcity of methodologies able
to classify the pertinence of a given result to a specific group. The
polarization curves that evaluate the corrosion kinetics of electrodes in
corrosive media are an application where the behavior is chiefly analyzed from
profiles. Polarization curves are indeed a classic method to determine the
global kinetics of metallic electrodes, but the strong nonlinearity from
different metals and alloys can overlap and the discrimination becomes a
challenging problem. Moreover, even finding a typical curve from replicated
tests requires subjective judgement. In this paper we used the so-called
multi-q approach based on the Tsallis statistics in a classification engine to
separate multiple polarization curve profiles of two stainless steels. We
collected 48 experimental polarization curves in aqueous chloride medium of two
stainless steel types, with different resistance against localized corrosion.
Multi-q pattern analysis was then carried out on a wide potential range, from
cathodic up to anodic regions. An excellent classification rate was obtained,
at a success rate of 90%, 80%, and 83% for low (cathodic), high (anodic), and
both potential ranges, respectively, using only 2% of the original profile
data. These results show the potential of the proposed approach towards
efficient, robust, systematic and automatic classification of highly non-linear
profile curves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2889</identifier>
 <datestamp>2014-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2889</id><created>2013-05-13</created><updated>2014-03-30</updated><authors><author><keyname>Solovey</keyname><forenames>Kiril</forenames></author><author><keyname>Salzman</keyname><forenames>Oren</forenames></author><author><keyname>Halperin</keyname><forenames>Dan</forenames></author></authors><title>Finding a needle in an exponential haystack: Discrete RRT for
  exploration of implicit roadmaps in multi-robot motion planning</title><categories>cs.RO</categories><comments>Kiril Solovey and Oren Salzman contributed equally to this paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a sampling-based framework for multi-robot motion planning which
combines an implicit representation of a roadmap with a novel approach for
pathfinding in geometrically embedded graphs tailored for our setting. Our
pathfinding algorithm, discrete-RRT (dRRT), is an adaptation of the celebrated
RRT algorithm for the discrete case of a graph, and it enables a rapid
exploration of the high-dimensional configuration space by carefully walking
through an implicit representation of a tensor product of roadmaps for the
individual robots. We demonstrate our approach experimentally on scenarios of
up to 60 degrees of freedom where our algorithm is faster by a factor of at
least ten when compared to existing algorithms that we are aware of.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2892</identifier>
 <datestamp>2013-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2892</id><created>2013-05-13</created><updated>2013-07-23</updated><authors><author><keyname>Abreu</keyname><forenames>Renato B.</forenames></author><author><keyname>Cordeiro</keyname><forenames>Lucas</forenames></author><author><keyname>Filho</keyname><forenames>Eddie B. L.</forenames></author></authors><title>Verifying Fixed-Point Digital Filters using SMT-Based Bounded Model
  Checking</title><categories>cs.SE cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The implementation of digital filters in processors based on fixed-point
arithmetic can lead to problems related to the finite word-length. In
particular, the processing of signals in such filters can produce overflows and
unwanted noise caused by quantization and round off effect during the
accumulative addition and multiplication operations. In this paper, we describe
a new approach to verify digital filters using an off-the-shelf bounded model
checker called ESBMC, which supports full C/C++ and is based on satisfiability
modulo theories solvers. In particular, we are able to verify the occurrence of
overflows, limit cycles, and time constraints based on a discrete-time model
implemented in C. The experiments show that the proposed approach can be used
to verify potential problems in fixed-point implementation of digital filters
and it can thus be effective in finding realistic design errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2902</identifier>
 <datestamp>2014-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2902</id><created>2013-05-13</created><updated>2014-11-04</updated><authors><author><keyname>Galanis</keyname><forenames>Andreas</forenames></author><author><keyname>Stefankovic</keyname><forenames>Daniel</forenames></author><author><keyname>Vigoda</keyname><forenames>Eric</forenames></author></authors><title>Inapproximability for Antiferromagnetic Spin Systems in the Tree
  Non-Uniqueness Region</title><categories>cs.CC math-ph math.MP math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A remarkable connection has been established for antiferromagnetic 2-spin
systems, including the Ising and hard-core models, showing that the
computational complexity of approximating the partition function for graphs
with maximum degree D undergoes a phase transition that coincides with the
statistical physics uniqueness/non-uniqueness phase transition on the infinite
D-regular tree. Despite this clear picture for 2-spin systems, there is little
known for multi-spin systems. We present the first analog of the above
inapproximability results for multi-spin systems.
  The main difficulty in previous inapproximability results was analyzing the
behavior of the model on random D-regular bipartite graphs, which served as the
gadget in the reduction. To this end one needs to understand the moments of the
partition function. Our key contribution is connecting: (i) induced matrix
norms, (ii) maxima of the expectation of the partition function, and (iii)
attractive fixed points of the associated tree recursions (belief propagation).
The view through matrix norms allows a simple and generic analysis of the
second moment for any spin system on random D-regular bipartite graphs. This
yields concentration results for any spin system in which one can analyze the
maxima of the first moment. The connection to fixed points of the tree
recursions enables an analysis of the maxima of the first moment for specific
models of interest.
  For k-colorings we prove that for even k, in the tree non-uniqueness region
(which corresponds to k&lt;D) it is NP-hard, unless NP=RP, to approximate the
number of colorings for triangle-free D-regular graphs. Our proof extends to
the antiferromagnetic Potts model, and, in fact, to every antiferromagnetic
model under a mild condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2938</identifier>
 <datestamp>2013-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2938</id><created>2013-05-13</created><updated>2013-11-01</updated><authors><author><keyname>Masuda</keyname><forenames>Naoki</forenames></author><author><keyname>Klemm</keyname><forenames>Konstantin</forenames></author><author><keyname>Egu&#xed;luz</keyname><forenames>V&#xed;ctor M.</forenames></author></authors><title>Temporal networks: slowing down diffusion by long lasting interactions</title><categories>physics.soc-ph cs.SI</categories><comments>5 pages, 2 figures, v2: minor revision + supplemental material</comments><journal-ref>Physical Review Letters 111, 188701 (2013)</journal-ref><doi>10.1103/PhysRevLett.111.188701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interactions among units in complex systems occur in a specific sequential
order thus affecting the flow of information, the propagation of diseases, and
general dynamical processes. We investigate the Laplacian spectrum of temporal
networks and compare it with that of the corresponding aggregate network.
First, we show that the spectrum of the ensemble average of a temporal network
has identical eigenmodes but smaller eigenvalues than the aggregate networks.
In large networks without edge condensation, the expected temporal dynamics is
a time-rescaled version of the aggregate dynamics. Even for single sequential
realizations, diffusive dynamics is slower in temporal networks. These
discrepancies are due to the noncommutability of interactions. We illustrate
our analytical findings using a simple temporal motif, larger network models
and real temporal networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2949</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2949</id><created>2013-05-13</created><updated>2013-05-29</updated><authors><author><keyname>Moghaddam</keyname><forenames>Reza Farrahi</forenames></author><author><keyname>Moghaddam</keyname><forenames>Fereydoun Farrahi</forenames></author><author><keyname>Cheriet</keyname><forenames>Mohamed</forenames></author></authors><title>Unsupervised ensemble of experts (EoE) framework for automatic
  binarization of document images</title><categories>cs.CV</categories><comments>6-page version, Accepted to be presented in ICDAR'13</comments><journal-ref>ICDAR 2013, pp 703-707</journal-ref><doi>10.1109/ICDAR.2013.144</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, a large number of binarization methods have been developed,
with varying performance generalization and strength against different
benchmarks. In this work, to leverage on these methods, an ensemble of experts
(EoE) framework is introduced, to efficiently combine the outputs of various
methods. The proposed framework offers a new selection process of the
binarization methods, which are actually the experts in the ensemble, by
introducing three concepts: confidentness, endorsement and schools of experts.
The framework, which is highly objective, is built based on two general
principles: (i) consolidation of saturated opinions and (ii) identification of
schools of experts. After building the endorsement graph of the ensemble for an
input document image based on the confidentness of the experts, the saturated
opinions are consolidated, and then the schools of experts are identified by
thresholding the consolidated endorsement graph. A variation of the framework,
in which no selection is made, is also introduced that combines the outputs of
all experts using endorsement-dependent weights. The EoE framework is evaluated
on the set of participating methods in the H-DIBCO'12 contest and also on an
ensemble generated from various instances of grid-based Sauvola method with
promising performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2952</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2952</id><created>2013-05-13</created><authors><author><keyname>Lemoine</keyname><forenames>Grady I.</forenames></author><author><keyname>Ou</keyname><forenames>M. Yvonne</forenames></author></authors><title>Finite Volume Modeling of Poroelastic-Fluid Wave Propagation with Mapped
  Grids</title><categories>math.NA cs.NA</categories><comments>Main text: 26 pages, 10 figures; appendices: 23 pages, 18 figures</comments><msc-class>65M08, 74S10, 74F10, 74J10, 74L05, 74L15, 86-08</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we develop a high-resolution mapped-grid finite volume method
code to model wave propagation in two dimensions in systems of multiple
orthotropic poroelastic media and/or fluids, with curved interfaces between
different media. We use a unified formulation to simplify modeling of the
various interface conditions -- open pores, imperfect hydraulic contact, or
sealed pores -- that may exist between such media. Our numerical code is based
on the Clawpack framework, but in order to obtain correct results at a material
interface we use a modified transverse Riemann solution scheme, and at such
interfaces are forced to drop the second-order correction term typical of
high-resolution finite volume methods. We verify our code against analytical
solutions for reflection and transmission of waves at a material interface, and
for scattering of an acoustic wave train around an isotropic poroelastic
cylinder. For reflection and transmission at a flat interface, we achieve
second-order convergence in the 1-norm, and first-order in the max-norm; for
the cylindrical scatterer, the highly distorted grid mapping degrades
performance but we still achieve convergence at a reduced rate. We also
simulate an acoustic pulse striking a simplified model of a human femur bone,
as an example of the capabilities of the code. To aid in reproducibility, at
the web site http://dx.doi.org/10.6084/m9.figshare.701483 we provide all of the
code used to generate the results here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2959</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2959</id><created>2013-05-09</created><authors><author><keyname>Mishra</keyname><forenames>Neema</forenames></author><author><keyname>Shrawankar</keyname><forenames>Urmila</forenames></author><author><keyname>Thakare</keyname><forenames>V M</forenames></author></authors><title>Automatic Speech Recognition Using Template Model for Man-Machine
  Interface</title><categories>cs.SD cs.CL</categories><comments>Pages: 05 Figures : 01 Tables : 03 Proceedings of the International
  Conference ICAET 2010, Chennai, India. arXiv admin note: text overlap with
  arXiv:1305.2847</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech is a natural form of communication for human beings, and computers
with the ability to understand speech and speak with a human voice are expected
to contribute to the development of more natural man-machine interfaces.
Computers with this kind of ability are gradually becoming a reality, through
the evolution of speech recognition technologies. Speech is being an important
mode of interaction with computers. In this paper Feature extraction is
implemented using well-known Mel-Frequency Cepstral Coefficients (MFCC).Pattern
matching is done using Dynamic time warping (DTW) algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2966</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2966</id><created>2013-05-13</created><authors><author><keyname>Azami</keyname><forenames>Mostafa</forenames></author><author><keyname>Ranjbar</keyname><forenames>Manij</forenames></author><author><keyname>rostami</keyname><forenames>Ali Shokouhi</forenames></author><author><keyname>Amiri</keyname><forenames>Amir Jahani</forenames></author></authors><title>Increasing the Network life Time by Simulated Annealing Algorithm in WSN
  with Point Coverage</title><categories>cs.NI</categories><comments>15 pages, 8 figures</comments><msc-class>2010</msc-class><acm-class>F.2.2</acm-class><journal-ref>International Journal of Ad hoc, Sensor &amp; Ubiquitous Computing (
  IJASUC ), 4(2), 31-45, 2013</journal-ref><doi>10.5121/ijasuc.2013.4203</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Since we are not able to replace the battery in a wireless sensor networks
(WSNs), the issues of energy and lifetime are the most important parameters. In
asymmetrical networks, different sensors with various abilities are used. Super
nodes, with higher power and wider range of communication in comparison with
common sensors, are used to cause connectivity and transmit data to base
stations in these networks. It is crucial to select the parameters of fit
function and monitoring sensors optimally in a point covering network. In this
paper, we utilized an algorithm to select monitoring sensors. The selection is
done by using a novel algorithm that used by simulated annealing. This
selection takes remained energy into consideration. This method increases
lifetime, decreases and balances energy consumption as confirmed by simulation
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2974</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2974</id><created>2013-05-13</created><authors><author><keyname>Li</keyname><forenames>Sheng</forenames></author><author><keyname>de Lamare</keyname><forenames>Rodrigo C.</forenames></author></authors><title>Blind Adaptive Reduced-Rank Detectors for DS-UWB Systems Based on Joint
  Iterative Optimization and the Constrained Constant Modulus Criterion</title><categories>cs.IT math.IT</categories><comments>10 figures, IEEE Transactions on Vehicular Technology 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel linear blind adaptive receiver based on joint iterative optimization
(JIO) and the constrained constant modulus (CCM) design criterion is proposed
for interference suppression in direct-sequence ultra-wideband (DS-UWB)
systems. The proposed blind receiver consists of two parts, a transformation
matrix that performs dimensionality reduction and a reduced-rank filter that
produces the output. In the proposed receiver, the transformation matrix and
the reduced-rank filter are updated jointly and iteratively to minimize the
constant modulus (CM) cost function subject to a constraint. Adaptive
implementations for the JIO receiver are developed by using the normalized
stochastic gradient (NSG) and recursive least-squares (RLS) algorithms. In
order to obtain a low-complexity scheme, the columns of the transformation
matrix with the RLS algorithm are updated individually. Blind channel
estimation algorithms for both versions (NSG and RLS) are implemented. Assuming
the perfect timing, the JIO receiver only requires the spreading code of the
desired user and the received data. Simulation results show that both versions
of the proposed JIO receivers have excellent performance in suppressing the
inter-symbol interference (ISI) and multiple access interference (MAI) with a
low complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2978</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2978</id><created>2013-05-13</created><authors><author><keyname>Bista</keyname><forenames>Sanat Kumar</forenames></author><author><keyname>Dahal</keyname><forenames>Keshav P</forenames></author><author><keyname>Cowling</keyname><forenames>Peter I</forenames></author></authors><title>Evolution of Cooperation in an Incentive Based Business Game Environment</title><categories>cs.CY cs.GT</categories><comments>Global Design to Gain a Competitive Edge. Vol. 1. Springer, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses our investigation into the evolution of cooperative
players in an online business environment. We explain our design of an
incentive based system with its foundation over binary reputation system whose
proportion of reward or punishment is a function of transaction value and the
players past history of cooperation. We compare the evolution of cooperation in
our setting with non-incentive based environment and our findings show that the
incentive based method is more suitable for the evolution of trustworthy
players.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2979</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2979</id><created>2013-05-13</created><authors><author><keyname>Bista</keyname><forenames>Sanat Kumar</forenames></author><author><keyname>Dahal</keyname><forenames>Keshav P.</forenames></author><author><keyname>Cowling</keyname><forenames>Peter I.</forenames></author><author><keyname>Tuladhar</keyname><forenames>Bhadra Man</forenames></author></authors><title>Unraveling the Evolution of Defectors in Online Business Games</title><categories>cs.GT cs.CY physics.soc-ph</categories><comments>SKIMA 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Anonymous online business environments have a social dilemma situation in it.
A dilemma on whether to cooperate or Defect. Defection by a buyer to seller
and/or seller to buyer might give each a better profit at the cost of the loss
of other. However, if these parties were to interact in future too, a bad past
reference might prevent cooperative actions, thus depriving each other from a
better gain. The anonymity of the players and an absence of central governing
body still make this environment tempting for the defectors. What might be the
evolutionary behavior of defectors in such environment? How could their
increasing population be controlled? It is these two questions basically that
we attempt to address in this research work. A genetic algorithm based spatial
iterated prisoners dilemma (SIPD) environment has been used to simulate the
experiments. A case where compensation for the looser is provided by the system
is modeled and analyzed through experiments. Our results show that compensation
can be useful in decreasing defective population in the society, however, this
might not be enough for the evolution of a cooperative and reliable society of
trustworthy players.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2981</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2981</id><created>2013-05-13</created><authors><author><keyname>Bista</keyname><forenames>Sanat Kumar</forenames></author><author><keyname>Dahal</keyname><forenames>Keshav P.</forenames></author><author><keyname>Cowling</keyname><forenames>Peter I.</forenames></author><author><keyname>Tuladhar</keyname><forenames>Bhadra Man</forenames></author></authors><title>Metrics for Computing Trust in a Multi-Agent Environment</title><categories>cs.CY cs.SI</categories><comments>SKIMA 2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the risks involved in multi agent community is in the identification
of trustworthy agent partners for transaction. In this paper we aim to describe
a trust model for measuring trust in the interacting agents. The trust metric
model works on the basis of the parameters that we have identified. The model
primarily analyses trust value on the basis of the agents reputation, as
provided by the agent itself, and the agents aggregate rating as provided by
the witness agents. The final computation of the trust value is given by a
weighted average of these two components. While computing the aggregate rating,
a weight based method has been adopted to discount the contribution of possibly
unfair ratings by the witness agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2982</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2982</id><created>2013-05-13</created><authors><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Estimating or Propagating Gradients Through Stochastic Neurons</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic neurons can be useful for a number of reasons in deep learning
models, but in many cases they pose a challenging problem: how to estimate the
gradient of a loss function with respect to the input of such stochastic
neurons, i.e., can we &quot;back-propagate&quot; through these stochastic neurons? We
examine this question, existing approaches, and present two novel families of
solutions, applicable in different settings. In particular, it is demonstrated
that a simple biologically plausible formula gives rise to an an unbiased (but
noisy) estimator of the gradient with respect to a binary stochastic neuron
firing probability. Unlike other estimators which view the noise as a small
perturbation in order to estimate gradients by finite differences, this
estimator is unbiased even without assuming that the stochastic perturbation is
small. This estimator is also interesting because it can be applied in very
general settings which do not allow gradient back-propagation, including the
estimation of the gradient with respect to future rewards, as required in
reinforcement learning setups. We also propose an approach to approximating
this unbiased but high-variance estimator by learning to predict it using a
biased estimator. The second approach we propose assumes that an estimator of
the gradient can be back-propagated and it provides an unbiased estimator of
the gradient, but can only work with non-linearities unlike the hard threshold,
but like the rectifier, that are not flat for all of their range. This is
similar to traditional sigmoidal units but has the advantage that for many
inputs, a hard decision (e.g., a 0 output) can be produced, which would be
convenient for conditional computation and achieving sparse representations and
sparse gradients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2985</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2985</id><created>2013-05-13</created><authors><author><keyname>Mishra</keyname><forenames>Shaunak</forenames></author><author><keyname>Wang</keyname><forenames>I-Hsiang</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas</forenames></author></authors><title>Opportunistic Interference Management for Multicarrier systems</title><categories>cs.IT math.IT</categories><comments>8 pages, 5 figures, a shorter version of this work will appear in the
  proceedings of ISIT 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study opportunistic interference management when there is bursty
interference in parallel 2-user linear deterministic interference channels. A
degraded message set communication problem is formulated to exploit the
burstiness of interference in M subcarriers allocated to each user. We focus on
symmetric rate requirements based on the number of interfered subcarriers
rather than the exact set of interfered subcarriers. Inner bounds are obtained
using erasure coding, signal-scale alignment and Han-Kobayashi coding strategy.
Tight outer bounds for a variety of regimes are obtained using the El
Gamal-Costa injective interference channel bounds and a sliding window subset
entropy inequality. The result demonstrates an application of techniques from
multilevel diversity coding to interference channels. We also conjecture outer
bounds indicating the sub-optimality of erasure coding across subcarriers in
certain regimes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.2999</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.2999</id><created>2013-05-13</created><authors><author><keyname>Lin</keyname><forenames>Xingqin</forenames></author><author><keyname>Viswanathan</keyname><forenames>Harish</forenames></author></authors><title>Dynamic Spectrum Refarming of GSM Spectrum for LTE Small Cells</title><categories>cs.IT cs.NI math.IT</categories><comments>8 pages, 7 figures, submitted to IEEE Globecom 2013 Intl. Workshop on
  Heterogeneous and Small Cell Networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a novel solution called dynamic spectrum refarming
(DSR) for deploying LTE small cells using the same spectrum as existing GSM
networks. The basic idea of DSR is that LTE small cells are deployed in the GSM
spectrum but suppress transmission of all signals including the reference
signals in some specific physical resource blocks corresponding to a portion of
the GSM carriers to ensure full GSM coverage. Our study shows that the proposed
solution can provide LTE mobile terminals with high speed data services when
they are in the coverage of the LTE small cells while minimally affecting the
service provided to GSM terminals located within the LTE small cell coverage
area. Thus, the proposal allows the normal operation of the existing GSM
networks even with LTE small cells deployed in that spectrum. Though the focus
of this paper is about GSM spectrum refarming, an analogous approach can be
applied to reuse code division multiple access (CDMA) spectrum for LTE small
cells.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3002</identifier>
 <datestamp>2014-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3002</id><created>2013-05-13</created><updated>2014-02-05</updated><authors><author><keyname>Huang</keyname><forenames>Hong</forenames></author><author><keyname>Misra</keyname><forenames>Satyajayant</forenames></author><author><keyname>Tang</keyname><forenames>Wei</forenames></author><author><keyname>Barani</keyname><forenames>Hajar</forenames></author><author><keyname>Al-Azzawi</keyname><forenames>Hussein</forenames></author></authors><title>Applications of Compressed Sensing in Communications Networks</title><categories>cs.NI cs.IT math.IT</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a tutorial for CS applications in communications
networks. The Shannon's sampling theorem states that to recover a signal, the
sampling rate must be as least the Nyquist rate. Compressed sensing (CS) is
based on the surprising fact that to recover a signal that is sparse in certain
representations, one can sample at the rate far below the Nyquist rate. Since
its inception in 2006, CS attracted much interest in the research community and
found wide-ranging applications from astronomy, biology, communications, image
and video processing, medicine, to radar. CS also found successful applications
in communications networks. CS was applied in the detection and estimation of
wireless signals, source coding, multi-access channels, data collection in
sensor networks, and network monitoring, etc. In many cases, CS was shown to
bring performance gains on the order of 10X. We believe this is just the
beginning of CS applications in communications networks, and the future will
see even more fruitful applications of CS in our field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3006</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3006</id><created>2013-05-13</created><authors><author><keyname>Chen</keyname><forenames>Dai-Qiang</forenames></author><author><keyname>Cheng</keyname><forenames>Li-Zhi</forenames></author></authors><title>Fast Linearized Alternating Direction Minimization Algorithm with
  Adaptive Parameter Selection for Multiplicative Noise Removal</title><categories>cs.CV math.NA</categories><comments>23pages</comments><msc-class>68U10</msc-class><journal-ref>Journal of Computational and Applied Mathematics 257 (2014) 29-45</journal-ref><doi>10.1016/j.cam.2013.08.012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Owing to the edge preserving ability and low computational cost of the total
variation (TV), variational models with the TV regularization have been widely
investigated in the field of multiplicative noise removal. The key points of
the successful application of these models lie in: the optimal selection of the
regularization parameter which balances the data-fidelity term with the TV
regularizer; the efficient algorithm to compute the solution. In this paper, we
propose two fast algorithms based on the linearized technique, which are able
to estimate the regularization parameter and recover the image simultaneously.
In the iteration step of the proposed algorithms, the regularization parameter
is adjusted by a special discrepancy function defined for multiplicative noise.
The convergence properties of the proposed algorithms are proved under certain
conditions, and numerical experiments demonstrate that the proposed algorithms
overall outperform some state-of-the-art methods in the PSNR values and
computational time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3011</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3011</id><created>2013-05-13</created><authors><author><keyname>Lee</keyname><forenames>Kuang-Chih</forenames></author><author><keyname>Jalali</keyname><forenames>Ali</forenames></author><author><keyname>Dasdan</keyname><forenames>Ali</forenames></author></authors><title>Real Time Bid Optimization with Smooth Budget Delivery in Online
  Advertising</title><categories>cs.GT cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today, billions of display ad impressions are purchased on a daily basis
through a public auction hosted by real time bidding (RTB) exchanges. A
decision has to be made for advertisers to submit a bid for each selected RTB
ad request in milliseconds. Restricted by the budget, the goal is to buy a set
of ad impressions to reach as many targeted users as possible. A desired action
(conversion), advertiser specific, includes purchasing a product, filling out a
form, signing up for emails, etc. In addition, advertisers typically prefer to
spend their budget smoothly over the time in order to reach a wider range of
audience accessible throughout a day and have a sustainable impact. However,
since the conversions occur rarely and the occurrence feedback is normally
delayed, it is very challenging to achieve both budget and performance goals at
the same time. In this paper, we present an online approach to the smooth
budget delivery while optimizing for the conversion performance. Our algorithm
tries to select high quality impressions and adjust the bid price based on the
prior performance distribution in an adaptive manner by distributing the budget
optimally across time. Our experimental results from real advertising campaigns
demonstrate the effectiveness of our proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3013</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3013</id><created>2013-05-13</created><authors><author><keyname>Chen</keyname><forenames>Dai-Qiang</forenames></author><author><keyname>Cheng</keyname><forenames>Li-Zhi</forenames></author></authors><title>Novel variational model for inpainting in the wavelet domain</title><categories>cs.CV</categories><comments>20pages</comments><msc-class>68U10, 65J22, 65T60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wavelet domain inpainting refers to the process of recovering the missing
coefficients during the image compression or transmission stage. Recently, an
efficient algorithm framework which is called Bregmanized operator splitting
(BOS) was proposed for solving the classical variational model of wavelet
inpainting. However, it is still time-consuming to some extent due to the inner
iteration. In this paper, a novel variational model is established to formulate
this reconstruction problem from the view of image decomposition. Then an
efficient iterative algorithm based on the split-Bregman method is adopted to
calculate an optimal solution, and it is also proved to be convergent. Compared
with the BOS algorithm the proposed algorithm avoids the inner iteration and
hence is more simple. Numerical experiments demonstrate that the proposed
method is very efficient and outperforms the current state-of-the-art methods,
especially in the computational time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3014</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3014</id><created>2013-05-13</created><authors><author><keyname>Jalali</keyname><forenames>Ali</forenames></author><author><keyname>Kolay</keyname><forenames>Santanu</forenames></author><author><keyname>Foldes</keyname><forenames>Peter</forenames></author><author><keyname>Dasdan</keyname><forenames>Ali</forenames></author></authors><title>Scalable Audience Reach Estimation in Real-time Online Advertising</title><categories>cs.LG cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online advertising has been introduced as one of the most efficient methods
of advertising throughout the recent years. Yet, advertisers are concerned
about the efficiency of their online advertising campaigns and consequently,
would like to restrict their ad impressions to certain websites and/or certain
groups of audience. These restrictions, known as targeting criteria, limit the
reachability for better performance. This trade-off between reachability and
performance illustrates a need for a forecasting system that can quickly
predict/estimate (with good accuracy) this trade-off. Designing such a system
is challenging due to (a) the huge amount of data to process, and, (b) the need
for fast and accurate estimates. In this paper, we propose a distributed fault
tolerant system that can generate such estimates fast with good accuracy. The
main idea is to keep a small representative sample in memory across multiple
machines and formulate the forecasting problem as queries against the sample.
The key challenge is to find the best strata across the past data, perform
multivariate stratified sampling while ensuring fuzzy fall-back to cover the
small minorities. Our results show a significant improvement over the uniform
and simple stratified sampling strategies which are currently widely used in
the industry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3021</identifier>
 <datestamp>2015-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3021</id><created>2013-05-14</created><updated>2015-08-07</updated><authors><author><keyname>Bukhari</keyname><forenames>Ijaz</forenames></author><author><keyname>Nuhman-ul-Haq</keyname></author><author><keyname>Hyat</keyname><forenames>Khizar</forenames></author></authors><title>Wave Atom Based Watermarking</title><categories>cs.MM cs.CR</categories><comments>I want to withdraw the paper due to serious error</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Watermarking helps in ensuring originality, ownership and copyrights of a
digital image. This paper aims at embedding a Watermark in an image using Wave
Atom Transform. Preference of Wave Atoms on other transformations has been due
to its sparser expansion, adaptability to the direction of local pattern, and
sharp frequency localization. In this scheme, we had tried to spread the
watermark in an image so that the information at one place is very small and
undetectable. In order to extract the watermark and verify ownership of an
image, one would have the advantage of prior knowledge of embedded locations. A
noise of high amplitude will be needed to be added to the image for watermark
distortion. Furthermore, the information spread will ensure the robustness of
the watermark data. The proposed scheme has the ability to withstand malicious
operations and attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3031</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3031</id><created>2013-05-14</created><authors><author><keyname>Paya</keyname><forenames>Ashkan</forenames></author><author><keyname>Marinescu</keyname><forenames>Dan C.</forenames></author></authors><title>Clustering Algorithms for Scale-free Networks and Applications to Cloud
  Resource Management</title><categories>cs.DC</categories><comments>14 pages, 8 Figurs, Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce algorithms for the construction of scale-free
networks and for clustering around the nerve centers, nodes with a high
connectivity in a scale-free networks. We argue that such overlay networks
could support self-organization in a complex system like a cloud computing
infrastructure and allow the implementation of optimal resource management
policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3038</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3038</id><created>2013-05-14</created><authors><author><keyname>Li</keyname><forenames>Gongming</forenames></author><author><keyname>An</keyname><forenames>Hong</forenames></author></authors><title>Phase-Priority based Directory Coherence for Multicore Processor</title><categories>cs.AR</categories><comments>15 pages. International Journal of Computer Science, Engineering and
  Information Technology, April 2013</comments><msc-class>Computer system organization</msc-class><acm-class>C.1.4</acm-class><doi>10.5121/ijcseit.2013.3201</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the number of cores in a single chip increases, a typical implementation
of coherence protocol adds significant hardware and complexity overhead.
Besides, the performance of CMP system depends on the data access latency,
which is highly affected by coherence protocol and on-chip interconnect. In
this paper, we propose PPB (Phase-Priority Based) cache coherence protocol, an
optimization of modern directory coherence protocol. We take advantage of the
observation that transient states occur in directory coherence protocol,
resulting in some unnecessary transient states and stalling. PPB cache
coherence protocol decouples a coherence transaction and introduces the idea of
phase message. This phase is considered as the priority of the message.
Additionally, we also add new priority-based arbitrators in on-chip network to
support PPB cache coherence protocol. This mechanism in on-chip network can
support effective cache access, which makes the on-chip network more efficient.
Our analysis on an execution-driven full system simulator using SPLASH-2
benchmark shows that PPB cache coherence outperforms a MESI based directory,
and the number of unnecessary transient states and stalling reduces up to 24%.
Also it reported the speedup of 7.4%. Other advantages of this strategy are
reduced delay of flits and significantly less energy consumption in on-chip
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3040</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3040</id><created>2013-05-14</created><authors><author><keyname>&#x15a;mieja</keyname><forenames>Marek</forenames></author></authors><title>Weighted Approach to General Entropy Function</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The definition of weighted entropy allows for easy calculation of the entropy
of the mixture of measures. In this paper we investigate the problem of
equivalent definition of the general entropy function in weighted form. We show
that under reasonable condition, which is satisfied by the well-known Shannon,
R\'enyi and Tsallis entropies, every entropy function can be defined
equivalently in the weighted way. As a corollary, we show how use the weighted
form to compute Tsallis entropy of the mixture of measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3041</identifier>
 <datestamp>2014-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3041</id><created>2013-05-14</created><updated>2014-10-17</updated><authors><author><keyname>Boyar</keyname><forenames>Joan</forenames></author><author><keyname>Find</keyname><forenames>Magnus</forenames></author></authors><title>Cancellation-Free Circuits in Unbounded and Bounded Depth</title><categories>cs.CC</categories><comments>IMADA-preprint 2013. This article supersedes arXiv:1207.5321. The
  publication is available from ScienceDirect</comments><doi>10.1016/j.tcs.2014.10.014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the notion of &quot;cancellation-free&quot; circuits. This is a restriction of
linear Boolean circuits (XOR circuits), but can be considered as being
equivalent to previously studied models of computation. The notion was coined
by Boyar and Peralta in a study of heuristics for a particular circuit
minimization problem. They asked how large a gap there can be between the
smallest cancellation-free circuit and the smallest linear circuit. We show
that the difference can be a factor $\Omega(n/\log^{2}n)$. This improves on a
recent result by Sergeev and Gashkov who have studied a similar problem.
Furthermore, our proof holds for circuits of constant depth. We also study the
complexity of computing the Sierpinski matrix using cancellation-free circuits
and give a tight $\Omega(n\log n)$ lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3046</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3046</id><created>2013-05-14</created><authors><author><keyname>Braca</keyname><forenames>Paolo</forenames></author></authors><title>Running Consensus for Decentralized Detection</title><categories>cs.SY cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis represents a culmination of work and learning that has taken
place over a period of almost three years (2007 - 2010) at the University of
Salerno, and at the University of Connecticut. It is mostly an unified
mathematical dissertation of the running consensus procedures. In the recent
years, the detection using the paradigm of the running consensus has been
recognized as one of the three possible classes of distributed detection in
which the phases of sensing and communication need not be mutually exclusive,
i.e., sensing and communication occur simultaneously. Considering that the
running consensus paradigm is just an intuitive inference procedure, i.e.
sub-optimal w.r.t. an ideal centralized system scheme which is optimal, the
most important result is that it asymptotically reaches the performance of this
ideal scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3051</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3051</id><created>2013-05-14</created><updated>2013-05-27</updated><authors><author><keyname>Mishra</keyname><forenames>Shaunak</forenames></author><author><keyname>Fragouli</keyname><forenames>Christina</forenames></author><author><keyname>Prabhakaran</keyname><forenames>Vinod</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas</forenames></author></authors><title>Using Feedback for Secrecy over Graphs</title><categories>cs.IT cs.CR math.IT</categories><comments>6 pages, 5 figures, a shorter version of this work will appear in the
  proceedings of ISIT 2013, minor changes in presentation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of secure message multicasting over graphs in the
presence of a passive (node) adversary who tries to eavesdrop in the network.
We show that use of feedback, facilitated through the existence of cycles or
undirected edges, enables higher rates than possible in directed acyclic graphs
of the same mincut. We demonstrate this using code constructions for canonical
combination networks (CCNs). We also provide general outer bounds as well as
schemes for node adversaries over CCNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3054</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3054</id><created>2013-05-14</created><authors><author><keyname>Chaaban</keyname><forenames>Anas</forenames></author><author><keyname>Ochs</keyname><forenames>Karlheinz</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author></authors><title>The Degrees of Freedom of the MIMO Y-channel</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, ISIT 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The degrees of freedom (DoF) of the MIMO Y-channel, a multi-way communication
network consisting of 3 users and a relay, are characterized for arbitrary
number of antennas. The converse is provided by cut-set bounds and novel
genie-aided bounds. The achievability is shown by a scheme that uses
beamforming to establish network coding on-the-fly at the relay in the uplink,
and zero-forcing pre-coding in the downlink. It is shown that the network has
min{2M_2+2M_3,M_1+M_2+M_3,2N} DoF, where M_j and N represent the number of
antennas at user j and the relay, respectively. Thus, in the extreme case where
M_1+M_2+M_3 dominates the DoF expression and is smaller than N, the network has
the same DoF as the MAC between the 3 users and the relay. In this case, a
decode and forward strategy is optimal. In the other extreme where 2N
dominates, the DoF of the network is twice that of the aforementioned MAC, and
hence network coding is necessary. As a byproduct of this work, it is shown
that channel output feedback from the relay to the users has no impact on the
DoF of this channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3055</identifier>
 <datestamp>2014-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3055</id><created>2013-05-14</created><updated>2014-10-26</updated><authors><author><keyname>Baldi</keyname><forenames>Marco</forenames></author><author><keyname>Bianchi</keyname><forenames>Marco</forenames></author><author><keyname>Chiaraluce</keyname><forenames>Franco</forenames></author><author><keyname>Laurenti</keyname><forenames>Nicola</forenames></author><author><keyname>Tomasin</keyname><forenames>Stefano</forenames></author><author><keyname>Renna</keyname><forenames>Francesco</forenames></author></authors><title>Secrecy Transmission on Block Fading Channels: Theoretical Limits and
  Performance of Practical Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a system where an agent (Alice) aims at transmitting a message to
a second agent (Bob) over a set of parallel channels, while keeping it secret
from a third agent (Eve) by using physical layer security techniques. We assume
that Alice perfectly knows the set of channels with respect to Bob, but she has
only a statistical knowledge of the channels with respect to Eve. We derive
bounds on the achievable outage secrecy rates, by considering coding either
within each channel or across all parallel channels. Transmit power is adapted
to the channel conditions, with a constraint on the average power over the
whole transmission. We also focus on the maximum cumulative outage secrecy rate
that can be achieved. Moreover, in order to assess the performance in a real
life scenario, we consider the use of practical error correcting codes. We
extend the definitions of security gap and equivocation rate, previously
applied to the single additive white Gaussian noise channel, to Rayleigh
distributed parallel channels, on the basis of the error rate targets and the
outage probability. Bounds on these metrics are also derived, taking into
account the statistics of the parallel channels. Numerical results are
provided, that confirm the feasibility of the considered physical layer
security techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3058</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3058</id><created>2013-05-14</created><authors><author><keyname>Abiteboul</keyname><forenames>Serge</forenames><affiliation>LSV</affiliation></author><author><keyname>Antoine</keyname><forenames>&#xc9;milien</forenames><affiliation>LSV</affiliation></author><author><keyname>Miklau</keyname><forenames>Gerome</forenames><affiliation>LSV, UMASS</affiliation></author><author><keyname>Stoyanovich</keyname><forenames>Julia</forenames><affiliation>LSV, McGill</affiliation></author><author><keyname>Testard</keyname><forenames>Jules</forenames><affiliation>LSV, McGill</affiliation></author></authors><title>Rule-Based Application Development using Webdamlog</title><categories>cs.DB</categories><comments>SIGMOD - Special Interest Group on Management Of Data (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the WebdamLog system for managing distributed data on the Web in a
peer-to-peer manner. We demonstrate the main features of the system through an
application called Wepic for sharing pictures between attendees of the sigmod
conference. Using Wepic, the attendees will be able to share, download, rate
and annotate pictures in a highly decentralized manner. We show how WebdamLog
handles heterogeneity of the devices and services used to share data in such a
Web setting. We exhibit the simple rules that define the Wepic application and
show how to easily modify the Wepic application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3082</identifier>
 <datestamp>2013-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3082</id><created>2013-05-14</created><authors><author><keyname>Han</keyname><forenames>Jialong</forenames></author><author><keyname>Wen</keyname><forenames>Ji-Rong</forenames></author></authors><title>Mining Frequent Neighborhood Patterns in Large Labeled Graphs</title><categories>cs.DB</categories><comments>9 pages</comments><acm-class>H.2.8</acm-class><doi>10.1145/2505515.2505530</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the years, frequent subgraphs have been an important sort of targeted
patterns in the pattern mining literatures, where most works deal with
databases holding a number of graph transactions, e.g., chemical structures of
compounds. These methods rely heavily on the downward-closure property (DCP) of
the support measure to ensure an efficient pruning of the candidate patterns.
When switching to the emerging scenario of single-graph databases such as
Google Knowledge Graph and Facebook social graph, the traditional support
measure turns out to be trivial (either 0 or 1). However, to the best of our
knowledge, all attempts to redefine a single-graph support resulted in measures
that either lose DCP, or are no longer semantically intuitive.
  This paper targets mining patterns in the single-graph setting. We resolve
the &quot;DCP-intuitiveness&quot; dilemma by shifting the mining target from frequent
subgraphs to frequent neighborhoods. A neighborhood is a specific topological
pattern where a vertex is embedded, and the pattern is frequent if it is shared
by a large portion (above a given threshold) of vertices. We show that the new
patterns not only maintain DCP, but also have equally significant semantics as
subgraph patterns. Experiments on real-life datasets display the feasibility of
our algorithms on relatively large graphs, as well as the capability of mining
interesting knowledge that is not discovered in prior works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3102</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3102</id><created>2013-05-14</created><authors><author><keyname>Fellows</keyname><forenames>Michael R.</forenames></author><author><keyname>Jansen</keyname><forenames>Bart M. P.</forenames></author></authors><title>FPT is Characterized by Useful Obstruction Sets</title><categories>cs.CC cs.DS</categories><comments>Extended abstract with appendix, as accepted to WG 2013</comments><msc-class>06A06, 68Q15, 68R10, 05C83</msc-class><acm-class>G.2; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many graph problems were first shown to be fixed-parameter tractable using
the results of Robertson and Seymour on graph minors. We show that the
combination of finite, computable, obstruction sets and efficient order tests
is not just one way of obtaining strongly uniform FPT algorithms, but that all
of FPT may be captured in this way. Our new characterization of FPT has a
strong connection to the theory of kernelization, as we prove that problems
with polynomial kernels can be characterized by obstruction sets whose elements
have polynomial size. Consequently we investigate the interplay between the
sizes of problem kernels and the sizes of the elements of such obstruction
sets, obtaining several examples of how results in one area yield new insights
in the other. We show how exponential-size minor-minimal obstructions for
pathwidth k form the crucial ingredient in a novel OR-cross-composition for
k-Pathwidth, complementing the trivial AND-composition that is known for this
problem. In the other direction, we show that OR-cross-compositions into a
parameterized problem can be used to rule out the existence of efficiently
generated quasi-orders on its instances that characterize the NO-instances by
polynomial-size obstructions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3103</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3103</id><created>2013-05-14</created><authors><author><keyname>Rashidi</keyname><forenames>Hassan</forenames></author></authors><title>A fast method for implementation of the property lists in programming
  languages</title><categories>cs.PL cs.DB</categories><comments>9 Pages, 5 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the major challenges in programming languages is to support different
data structures and their variations in both static and dynamic aspects. One of
the these data structures is the property list which applications use it as a
convenient way to store, organize, and access standard types of data. In this
paper, the standards methods for implementation of the Property Lists,
including the Static Array, Link List, Hash and Tree are reviewed. Then an
efficient method to implement the property list is presented. The experimental
results shows that our method is fast compared with the existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3105</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3105</id><created>2013-05-14</created><authors><author><keyname>Zhang</keyname><forenames>Daqiang</forenames></author><author><keyname>Zou</keyname><forenames>Qin</forenames></author><author><keyname>Sun</keyname><forenames>Zhiren</forenames></author></authors><title>SECA: Snapshot-based Event Detection for Checking Asynchronous Context
  Consistency in Ubiquitous Computing</title><categories>cs.DC cs.ET cs.NI</categories><comments>This paper is not presented in WCNC'2012 as I missed the time owing
  to the traffic jam. So the paper is not included in IEEE Explorer, although
  it is in the Proceedings of the WCNC'2012. in Proceedings of the 2012 IEEE
  Wireless Communications and Networking Conference (WCNC 2012), pp. 3339--3344</comments><acm-class>C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Context-consistency checking is challenging in the dynamic and uncertain
ubiquitous computing environments. This is because contexts are often noisy
owing to unreliable sensing data streams, inaccurate data measurement, fragile
connectivity and resource constraints. One of the state-of-the-art efforts is
CEDA, which concurrently detects context consistency by exploring the
\emph{happened-before} relation among events. However, CEDA is seriously
limited by several side effects --- centralized detection manner that easily
gets down the checker process, heavy computing complexity and false negative.
  In this paper, we propose SECA: Snapshot-based Event Detection for Checking
Asynchronous Context Consistency in ubiquitous computing. SECA introduces
snapshot-based timestamp to check event relations, which can detect scenarios
where CEDA fails. Moreover, it simplifies the logical clock instead of adopting
the vector clock, and thus significantly reduces both time and space
complexity. Empirical studies show that SECA outperforms CEDA in terms of
detection accuracy, scalability, and computing complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3107</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3107</id><created>2013-05-14</created><authors><author><keyname>Petrovic</keyname><forenames>Sasa</forenames></author><author><keyname>Osborne</keyname><forenames>Miles</forenames></author><author><keyname>Lavrenko</keyname><forenames>Victor</forenames></author></authors><title>I Wish I Didn't Say That! Analyzing and Predicting Deleted Messages in
  Twitter</title><categories>cs.SI cs.CL</categories><comments>Unpublished</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Twitter has become a major source of data for social media researchers. One
important aspect of Twitter not previously considered are {\em deletions} --
removal of tweets from the stream. Deletions can be due to a multitude of
reasons such as privacy concerns, rashness or attempts to undo public
statements. We show how deletions can be automatically predicted ahead of time
and analyse which tweets are likely to be deleted and how.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3120</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3120</id><created>2013-05-14</created><authors><author><keyname>Mairal</keyname><forenames>Julien</forenames><affiliation>INRIA Grenoble Rh&#xf4;ne-Alpes / LJK Laboratoire Jean Kuntzmann</affiliation></author></authors><title>Optimization with First-Order Surrogate Functions</title><categories>stat.ML cs.LG math.OC</categories><comments>to appear in the proceedings of ICML 2013; the arxiv paper contains
  the 9 pages main text followed by 26 pages of supplemental material.
  International Conference on Machine Learning (ICML 2013) (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study optimization methods consisting of iteratively
minimizing surrogates of an objective function. By proposing several
algorithmic variants and simple convergence analyses, we make two main
contributions. First, we provide a unified viewpoint for several first-order
optimization techniques such as accelerated proximal gradient, block coordinate
descent, or Frank-Wolfe algorithms. Second, we introduce a new incremental
scheme that experimentally matches or outperforms state-of-the-art solvers for
large-scale optimization problems typically arising in machine learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3122</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3122</id><created>2013-05-14</created><authors><author><keyname>Cuvelier</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>LAGA</affiliation></author><author><keyname>Japhet</keyname><forenames>Caroline</forenames><affiliation>LAGA, Inria Paris-Rocquencourt</affiliation></author><author><keyname>Scarella</keyname><forenames>Gilles</forenames><affiliation>LAGA</affiliation></author></authors><title>An efficient way to perform the assembly of finite element matrices in
  Matlab and Octave</title><categories>cs.NA cs.MS math.NA</categories><comments>Inria: No: RR-8305 (2013)</comments><proxy>ccsd</proxy><report-no>RR-8305</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe different optimization techniques to perform the assembly of
finite element matrices in Matlab and Octave, from the standard approach to
recent vectorized ones, without any low level language used. We finally obtain
a simple and efficient vectorized algorithm able to compete in performance with
dedicated software such as FreeFEM++. The principle of this assembly algorithm
is general, we present it for different matrices in the P1 finite elements case
and in linear elasticity. We present numerical results which illustrate the
computational costs of the different approaches
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3123</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3123</id><created>2013-05-14</created><authors><author><keyname>Hilman</keyname><forenames>Muhammad</forenames></author><author><keyname>Suhartanto</keyname><forenames>Heru</forenames></author><author><keyname>Yanuar</keyname><forenames>Arry</forenames></author></authors><title>Performance Analysis of Embarassingly Parallel Application on Cluster
  Computer Environment: A Case Study of Virtual Screening with Autodock Vina
  1.1 on Hastinapura Cluster</title><categories>cs.DC</categories><comments>2010 International Conference on Advanced Computer Science and
  Information Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  IT based scientific research requires high computational resources. The
limitation on funding and infrastructure led the high performance computing era
from supercomputer to cluster and grid computing technology. Parallel
application running well on cluster computer as well as supercomputer, one of
the type is embarrassingly parallel application. Many scientist loves EP
because it doesn't need any sophisticated technique but gives amazing
performance. This paper discuss the bioinformatics research that used
embarrassingly application and show its performance on cluster computer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3131</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3131</id><created>2013-05-14</created><authors><author><keyname>Tishkovsky</keyname><forenames>Dmitry</forenames></author><author><keyname>Schmidt</keyname><forenames>Renate A.</forenames></author></authors><title>Refinement in the Tableau Synthesis Framework</title><categories>cs.LO</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the possibilities of refining and improving
calculi generated in the tableau synthesis framework. A general method in the
tableau synthesis framework allows to reduce the branching factor of tableau
rules and preserves completeness if a general rule refinement condition holds.
In this paper we consider two approaches to satisfy this general rule
refinement condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3146</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3146</id><created>2013-05-14</created><authors><author><keyname>Rombach</keyname><forenames>M. Puck</forenames></author><author><keyname>Porter</keyname><forenames>Mason A.</forenames></author></authors><title>Discriminating Power of Centrality Measures</title><categories>cs.SI physics.soc-ph</categories><comments>Working paper; comments welcome. 10 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The calculation of centrality measures is common practice in the study of
networks, as they attempt to quantify the importance of individual vertices,
edges, or other components. Different centralities attempt to measure
importance in different ways. In this paper, we examine a conjecture posed by
E. Estrada regarding the ability of several measures to distinguish the
vertices of networks. Estrada conjectured that if all vertices of a graph have
the same subgraph centrality, then all vertices must also have the same degree,
eigenvector, closeness, and betweenness centralities. We provide a
counterexample for the latter two centrality measures and propose a revised
conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3149</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3149</id><created>2013-05-14</created><authors><author><keyname>Jin</keyname><forenames>Xiao-Bo</forenames></author><author><keyname>Lu</keyname><forenames>Qiang</forenames></author><author><keyname>Wang</keyname><forenames>Feng</forenames></author><author><keyname>Huo</keyname><forenames>Quan-gong</forenames></author></authors><title>Qualitative detection of oil adulteration with machine learning
  approaches</title><categories>cs.CE cs.LG</categories><comments>18 pages, 4 figures, 5 tables</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The study focused on the machine learning analysis approaches to identify the
adulteration of 9 kinds of edible oil qualitatively and answered the following
three questions: Is the oil sample adulterant? How does it constitute? What is
the main ingredient of the adulteration oil? After extracting the
high-performance liquid chromatography (HPLC) data on triglyceride from 370 oil
samples, we applied the adaptive boosting with multi-class Hamming loss
(AdaBoost.MH) to distinguish the oil adulteration in contrast with the support
vector machine (SVM). Further, we regarded the adulterant oil and the pure oil
samples as ones with multiple labels and with only one label, respectively.
Then multi-label AdaBoost.MH and multi-label learning vector quantization
(ML-LVQ) model were built to determine the ingredients and their relative ratio
in the adulteration oil. The experimental results on six measures show that
ML-LVQ achieves better performance than multi-label AdaBoost.MH.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3163</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3163</id><created>2013-05-14</created><updated>2014-08-14</updated><authors><author><keyname>Johnson</keyname><forenames>J. Ian</forenames></author><author><keyname>Van Horn</keyname><forenames>David</forenames></author></authors><title>Abstracting Abstract Control (Extended)</title><categories>cs.PL</categories><comments>To appear at DLS '14</comments><acm-class>F.3.2</acm-class><doi>10.1145/2661088.2661098</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The strength of a dynamic language is also its weakness: run-time flexibility
comes at the cost of compile-time predictability. Many of the hallmarks of
dynamic languages such as closures, continuations, various forms of reflection,
and a lack of static types make many programmers rejoice, while compiler
writers, tool developers, and verification engineers lament. The dynamism of
these features simply confounds statically reasoning about programs that use
them. Consequently, static analyses for dynamic languages are few, far between,
and seldom sound.
  The &quot;abstracting abstract machines&quot; (AAM) approach to constructing static
analyses has recently been proposed as a method to ameliorate the difficulty of
designing analyses for such language features. The approach, so called because
it derives a function for the sound and computable approximation of program
behavior starting from the abstract machine semantics of a language, provides a
viable approach to dynamic language analysis since all that is required is a
machine description of the interpreter.
  The original AAM recipe produces finite state abstractions, which cannot
faithfully represent an interpreter's control stack. Recent advances have shown
that higher-order programs can be approximated with pushdown systems. However,
these automata theoretic models either break down on features that inspect or
modify the control stack.
  In this paper, we tackle the problem of bringing pushdown flow analysis to
the domain of dynamic language features. We revise the abstracting abstract
machines technique to target the stronger computational model of pushdown
systems. In place of automata theory, we use only abstract machines and
memoization. As case studies, we show the technique applies to a language with
closures, garbage collection, stack-inspection, and first-class composable
continuations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3164</identifier>
 <datestamp>2013-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3164</id><created>2013-05-14</created><updated>2013-07-13</updated><authors><author><keyname>Gagie</keyname><forenames>Travis</forenames></author><author><keyname>Gawrychowski</keyname><forenames>Pawe&#x142;</forenames></author><author><keyname>Nekrich</keyname><forenames>Yakov</forenames></author></authors><title>Heaviest Induced Ancestors and Longest Common Substrings</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose we have two trees on the same set of leaves, in which nodes are
weighted such that children are heavier than their parents. We say a node from
the first tree and a node from the second tree are induced together if they
have a common leaf descendant. In this paper we describe data structures that
efficiently support the following heaviest-induced-ancestor query: given a node
from the first tree and a node from the second tree, find an induced pair of
their ancestors with maximum combined weight. Our solutions are based on a
geometric interpretation that enables us to find heaviest induced ancestors
using range queries. We then show how to use these results to build an
LZ-compressed index with which we can quickly find with high probability a
longest substring common to the indexed string and a given pattern.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3178</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3178</id><created>2013-05-14</created><authors><author><keyname>Zhao</keyname><forenames>Wenxiao</forenames></author><author><keyname>Chen</keyname><forenames>Han-Fu</forenames></author><author><keyname>Fang</keyname><forenames>Hai-Tao</forenames></author></authors><title>Convergence of Distributed Randomized PageRank Algorithms</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The PageRank algorithm employed by Google quantifies the importance of each
page by the link structure of the web. To reduce the computational burden the
distributed randomized PageRank algorithms (DRPA) recently appeared in
literature suggest pages to update their ranking values by locally
communicating with the linked pages. The main objective of the note is to show
that the estimates generated by DRPA converge to the true PageRank value almost
surely under the assumption that the randomization is realized in an
independent and identically distributed (iid) way. This is achieved with the
help of the stochastic approximation (SA) and its convergence results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3189</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3189</id><created>2013-05-14</created><authors><author><keyname>Bouachir</keyname><forenames>Wassim</forenames></author><author><keyname>Torabi</keyname><forenames>Atousa</forenames></author><author><keyname>Bilodeau</keyname><forenames>Guillaume-Alexandre</forenames></author><author><keyname>Blais</keyname><forenames>Pascal</forenames></author></authors><title>A Bag of Words Approach for Semantic Segmentation of Monitored Scenes</title><categories>cs.CV</categories><comments>\'Ecole Polytechnique de Montr\'eal, iWatchLife Inc</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a semantic segmentation method for outdoor scenes
captured by a surveillance camera. Our algorithm classifies each perceptually
homogenous region as one of the predefined classes learned from a collection of
manually labelled images. The proposed approach combines two different types of
information. First, color segmentation is performed to divide the scene into
perceptually similar regions. Then, the second step is based on SIFT keypoints
and uses the bag of words representation of the regions for the classification.
The prediction is done using a Na\&quot;ive Bayesian Network as a generative
classifier. Compared to existing techniques, our method provides more compact
representations of scene contents and the segmentation result is more
consistent with human perception due to the combination of the color
information with the image keypoints. The experiments conducted on a publicly
available data set demonstrate the validity of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3199</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3199</id><created>2013-05-14</created><authors><author><keyname>Winter</keyname><forenames>Philipp</forenames></author><author><keyname>Pulls</keyname><forenames>Tobias</forenames></author><author><keyname>Fuss</keyname><forenames>Juergen</forenames></author></authors><title>ScrambleSuit: A Polymorph Network Protocol to Circumvent Censorship</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep packet inspection technology became a cornerstone of Internet censorship
by facilitating cheap and effective filtering of what censors consider
undesired information. Moreover, filtering is not limited to simple pattern
matching but makes use of sophisticated techniques such as active probing and
protocol classification to block access to popular circumvention tools such as
Tor.
  In this paper, we propose ScrambleSuit; a thin protocol layer above TCP whose
purpose is to obfuscate the transported application data. By using morphing
techniques and a secret exchanged out-of-band, we show that ScrambleSuit can
defend against active probing and other fingerprinting techniques such as
protocol classification and regular expressions.
  We finally demonstrate that our prototype exhibits little overhead and
enables effective and lightweight obfuscation for application layer protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3203</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3203</id><created>2013-05-14</created><authors><author><keyname>Saini</keyname><forenames>Gurpreet Singh</forenames></author><author><keyname>Kots</keyname><forenames>Ashish</forenames></author><author><keyname>Kumar</keyname><forenames>Manoj</forenames></author></authors><title>DREAM_OLSR PROTOCOL (Distance Routing Effective Algorithm for Mobility -
  Optimized Link State Routing)</title><categories>cs.NI</categories><comments>Published at IJCTT, 2013 Volume4 Issue5
  http://www.ijcttjournal.org/volume-4/issue-5/IJCTT-V4I5P25.pdf</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper lays down a proposal of protocol named DREAM_OLSR. The protocol
has been developed so as to effect current OLSR (RFC 3626) [4] protocol. The
protocol establishes an optimized solution hence the name has been manipulated
from Open Link State Routing to DREAM Optimized Link State Routing. DREAM
specifies Distance Routing Effective Algorithm for Mobility wherein it
implements the Distance routing effective algorithm for the optimized solution.
This optimization includes higher efficiency and fewer overheads for the MANET.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3204</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3204</id><created>2013-05-14</created><authors><author><keyname>Pandya</keyname><forenames>Paritosh K.</forenames></author><author><keyname>Shah</keyname><forenames>Simoni S.</forenames></author></authors><title>The Unary Fragments of Metric Interval Temporal Logic: Bounded versus
  Lower bound Constraints (Full Version)</title><categories>cs.LO cs.FL</categories><comments>Presented at ATVA, 2012</comments><journal-ref>Proc. ATAV 2012, LNCS 7561, 2012. pp 77-91</journal-ref><doi>10.1007/978-3-642-33386-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study two unary fragments of the well-known metric interval temporal logic
MITL[U_I,S_I] that was originally proposed by Alur and Henzinger, and we pin
down their expressiveness as well as satisfaction complexities. We show that
MITL[F_\inf,P_\inf] which has unary modalities with only lower-bound
constraints is (surprisingly) expressively complete for Partially Ordered 2-Way
Deterministic Timed Automata (po2DTA) and the reduction from logic to automaton
gives us its NP-complete satisfiability. We also show that the fragment
MITL[F_b,P_b] having unary modalities with only bounded intervals has
\nexptime-complete satisfiability. But strangely, MITL[F_b,P_b] is strictly
less expressive than MITL[F_\inf,P_\inf]. We provide a comprehensive picture of
the decidability and expressiveness of various unary fragments of MITL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3207</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3207</id><created>2013-05-14</created><authors><author><keyname>Chan</keyname><forenames>Siu-On</forenames></author><author><keyname>Diakonikolas</keyname><forenames>Ilias</forenames></author><author><keyname>Servedio</keyname><forenames>Rocco A.</forenames></author><author><keyname>Sun</keyname><forenames>Xiaorui</forenames></author></authors><title>Efficient Density Estimation via Piecewise Polynomial Approximation</title><categories>cs.LG cs.DS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a highly efficient &quot;semi-agnostic&quot; algorithm for learning univariate
probability distributions that are well approximated by piecewise polynomial
density functions. Let $p$ be an arbitrary distribution over an interval $I$
which is $\tau$-close (in total variation distance) to an unknown probability
distribution $q$ that is defined by an unknown partition of $I$ into $t$
intervals and $t$ unknown degree-$d$ polynomials specifying $q$ over each of
the intervals. We give an algorithm that draws $\tilde{O}(t\new{(d+1)}/\eps^2)$
samples from $p$, runs in time $\poly(t,d,1/\eps)$, and with high probability
outputs a piecewise polynomial hypothesis distribution $h$ that is
$(O(\tau)+\eps)$-close (in total variation distance) to $p$. This sample
complexity is essentially optimal; we show that even for $\tau=0$, any
algorithm that learns an unknown $t$-piecewise degree-$d$ probability
distribution over $I$ to accuracy $\eps$ must use $\Omega({\frac {t(d+1)}
{\poly(1 + \log(d+1))}} \cdot {\frac 1 {\eps^2}})$ samples from the
distribution, regardless of its running time. Our algorithm combines tools from
approximation theory, uniform convergence, linear programming, and dynamic
programming.
  We apply this general algorithm to obtain a wide range of results for many
natural problems in density estimation over both continuous and discrete
domains. These include state-of-the-art results for learning mixtures of
log-concave distributions; mixtures of $t$-modal distributions; mixtures of
Monotone Hazard Rate distributions; mixtures of Poisson Binomial Distributions;
mixtures of Gaussians; and mixtures of $k$-monotone densities. Our general
technique yields computationally efficient algorithms for all these problems,
in many cases with provably optimal sample complexities (up to logarithmic
factors) in all parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3212</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3212</id><created>2013-05-14</created><authors><author><keyname>Jegatheesan</keyname><forenames>Sowmyan</forenames></author><author><keyname>El-kadri</keyname><forenames>Dr. Nour</forenames></author></authors><title>Privacy and Security in IPv6</title><categories>cs.CY cs.CR</categories><comments>arXiv admin note: text overlap with arXiv:1211.4704 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many Internet service providers (ISPs) throughout the world are now in the
process of integrating IPv6 into their Internet access products for retail
customers and corporate clients. One of the most important features of the IPv6
protocol is its huge address space. This will enable users to assign a
life-long stable, unique and globally routable IP address to each personal
device. All users will be able to set up public services at home and be able to
communicate from and to their devices from any point in the network. The
resulting end-to-end reachability is considered a major improvement over the
current situation.IPv6 evoked a new debate between privacy and security in
order to attract more unique IP addresses to locate users, especially with the
advent of mobile devices. While the initial IPv6 specification from 1995 does
already contain a variety of security considerations (namely, message integrity
protection as well as encryption based on IPsec), privacy aspects have not
played a major role in the beginning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3213</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3213</id><created>2013-05-14</created><authors><author><keyname>S</keyname><forenames>Senthur Balan</forenames></author><author><keyname>Jegatheesan</keyname><forenames>Sowmyan</forenames></author><author><keyname>M</keyname><forenames>Sakthi Ganesh</forenames></author></authors><title>The Product Promotion and Consumer Retention Gap in Online Shopping</title><categories>cs.CY</categories><comments>4 Pages,1 Table, 2012 4th International Conference on Electronics
  Computer Technology (ICECT 2012) 978-1-4673-1850-1/12 2012 IEEE Page 158-161</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the number of online shopping websites increases day by day, so are the
online advertisement strategies and promotional techniques. The number of
people who uses internet keeps on increasing daily and it has become a vast
marketplace to promote products, surely it will be a prime reason to drive any
companies growth in the future.This paper primarily focuses on the areas on
which online shopping lags product promotion and customer retention. Sellers
must concentrate on the areas in which online marketing lags product promotion
techniques; also they should introduce new strategies to increase their market
share to gain customers attention towards their products.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3215</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3215</id><created>2013-05-14</created><authors><author><keyname>Stoutemyer</keyname><forenames>David R.</forenames></author></authors><title>A computer algebra user interface manifesto</title><categories>cs.SC cs.MS</categories><comments>38 pages, 12 figures, to be published in Communications in Computer
  Algebra</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many computer algebra systems have more than 1000 built-in functions, making
expertise difficult. Using mock dialog boxes, this article describes a proposed
interactive general-purpose wizard for organizing optional transformations and
allowing easy fine grain control over the form of the result even by amateurs.
This wizard integrates ideas including:
  * flexible subexpression selection;
  * complete control over the ordering of variables and commutative operands,
with well-chosen defaults;
  * interleaving the choice of successively less main variables with applicable
function choices to provide detailed control without incurring a combinatorial
number of applicable alternatives at any one level;
  * quick applicability tests to reduce the listing of inapplicable
transformations;
  * using an organizing principle to order the alternatives in a helpful
manner;
  * labeling quickly-computed alternatives in dialog boxes with a preview of
their results,
  * using ellipsis elisions if necessary or helpful;
  * allowing the user to retreat from a sequence of choices to explore other
branches of the tree of alternatives or to return quickly to branches already
visited;
  * allowing the user to accumulate more than one of the alternative forms;
  * integrating direct manipulation into the wizard; and
  * supporting not only the usual input-result pair mode, but also the useful
alternative derivational and in situ replacement modes in a uni?ed window.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3218</identifier>
 <datestamp>2013-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3218</id><created>2013-05-14</created><updated>2013-10-21</updated><authors><author><keyname>Fukuyama</keyname><forenames>Junichiro</forenames></author></authors><title>Computing Cliques is Intractable</title><categories>cs.CC</categories><comments>This paper has been withdrawn by the author. Due to the dependence of
  f(\sigma) on z, Lemma 5.3 is incorrect</comments><acm-class>F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The class P is in fact a proper sub-class of NP. We explore topological
properties of the Hamming space 2^[n] where [n]={1, 2,..., n}. With the
developed theory, we show: (i) a theorem that is closely related to Erdos and
Rado's sunflower lemma, and claims a stronger statement in most cases, (ii) a
new approach to prove the exponential monotone circuit complexity of the clique
problem, (iii) NC \ne NP through the impossibility of a Boolean circuit with
poly-log depth to compute cliques, based on the construction of (ii), and (iv)
P \ne NP through the exponential circuit complexity of the clique problem,
based on the construction of (iii). Item (i) leads to the existence of a
sunflower with a small core in certain families of sets, which is not an
obvious consequence of the sunflower lemma. In (iv), we show that any Boolean
circuit computing the clique function CLIQUE_{n,k} (k=n^{1/4}) has a size
exponential in n. Thus, we will separate P/poly from NP also. Razborov and
Rudich showed strong evidence that no natural proof can prove exponential
circuit complexity of a Boolean function. We confirm that the proofs for (iii)
and (iv) are not natural.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3224</identifier>
 <datestamp>2013-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3224</id><created>2013-05-14</created><updated>2013-10-05</updated><authors><author><keyname>Mazumdar</keyname><forenames>Arya</forenames></author><author><keyname>Chandar</keyname><forenames>Venkat</forenames></author><author><keyname>Wornell</keyname><forenames>Gregory W.</forenames></author></authors><title>Update-Efficiency and Local Repairability Limits for Capacity
  Approaching Codes</title><categories>cs.IT math.IT</categories><comments>Accepted to appear in JSAC</comments><msc-class>68P30, 94A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by distributed storage applications, we investigate the degree to
which capacity achieving encodings can be efficiently updated when a single
information bit changes, and the degree to which such encodings can be
efficiently (i.e., locally) repaired when single encoded bit is lost.
  Specifically, we first develop conditions under which optimum
error-correction and update-efficiency are possible, and establish that the
number of encoded bits that must change in response to a change in a single
information bit must scale logarithmically in the block-length of the code if
we are to achieve any nontrivial rate with vanishing probability of error over
the binary erasure or binary symmetric channels. Moreover, we show there exist
capacity-achieving codes with this scaling.
  With respect to local repairability, we develop tight upper and lower bounds
on the number of remaining encoded bits that are needed to recover a single
lost bit of the encoding. In particular, we show that if the code-rate is
$\epsilon$ less than the capacity, then for optimal codes, the maximum number
of codeword symbols required to recover one lost symbol must scale as
$\log1/\epsilon$.
  Several variations on---and extensions of---these results are also developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3240</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3240</id><created>2013-05-14</created><authors><author><keyname>Seslija</keyname><forenames>Marko</forenames></author><author><keyname>Scherpen</keyname><forenames>Jacquelien M. A.</forenames></author><author><keyname>van der Schaft</keyname><forenames>Arjan</forenames></author></authors><title>Reaction-Diffusion Systems as Complex Networks</title><categories>math.OC cs.SY math.AP</categories><comments>A discussion paper for the 1st IFAC Workshop on Control of Systems
  Governed by Partial Differential Equations</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The spatially distributed reaction networks are indispensable for the
understanding of many important phenomena concerning the development of
organisms, coordinated cell behavior, and pattern formation. The purpose of
this brief discussion paper is to point out some open problems in the theory of
PDE and compartmental ODE models of balanced reaction-diffusion networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3241</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3241</id><created>2013-05-14</created><updated>2013-08-16</updated><authors><author><keyname>Mehta</keyname><forenames>Ruta</forenames></author><author><keyname>Vazirani</keyname><forenames>Vijay V.</forenames></author></authors><title>An Incentive Compatible, Efficient Market for Air Traffic Flow
  Management</title><categories>cs.GT</categories><comments>arXiv admin note: substantial text overlap with arXiv:1109.5214</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a market-based approach to the Air Traffic Flow Management (ATFM)
problem. The goods in our market are delays and buyers are airline companies;
the latter pay money to the FAA to buy away the desired amount of delay on a
per flight basis. We give a notion of equilibrium for this market and an LP
whose solution gives an equilibrium allocation of flights to landing slots as
well as equilibrium prices for the landing slots. Via a reduction to matching,
we show that this equilibrium can be computed combinatorially in strongly
polynomial time. Moreover, there is a special set of equilibrium prices, which
can be computed easily, that is identical to the VCG solution, and therefore
the market is incentive compatible in dominant strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3248</identifier>
 <datestamp>2013-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3248</id><created>2013-05-11</created><updated>2013-07-26</updated><authors><author><keyname>Kish</keyname><forenames>Laszlo B.</forenames></author><author><keyname>Kwan</keyname><forenames>Chiman</forenames></author></authors><title>Physical uncloneable function hardware keys utilizing
  Kirchhoff-law-Johnson-noise secure key exchange and noise-based logic</title><categories>cs.CR</categories><comments>some clarifications/enhancements; in publication process</comments><journal-ref>Fluct. Noise Lett. 12, 1350018 (2013)</journal-ref><doi>10.1142/S0219477513500181</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Weak physical uncloneable function (WPUF) encryption key means that the
manufacturer of the hardware can clone the key but anybody else is unable to so
that. Strong physical uncloneable function (SPUF) encryption key means that
even the manufacturer of the hardware is unable to clone the key. In this
paper, first we introduce a &quot;ultra&quot;-strong PUF with intrinsic dynamical
randomness, which is not only not cloneable but it also gets renewed to an
independent key (with fresh randomness) during each use via the unconditionally
secure key exchange. The solution utilizes the Kirchhoff-law-Johnson-noise
(KLJN) method for dynamical key renewal and a one-time-pad secure key for the
challenge/response process. The secure key is stored in a flash memory on the
chip to provide tamper-resistance and non-volatile storage with zero power
requirements in standby mode. Simplified PUF keys are shown: a strong PUF
utilizing KLJN protocol during the first run and noise-based logic (NBL)
hyperspace vector string verification method for the challenge/response during
the rest of its life or until it is re-initialized. Finally, the simplest PUF
utilizes NBL without KLJN thus it can be cloned by the manufacturer but not by
anybody else.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3250</identifier>
 <datestamp>2013-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3250</id><created>2013-05-14</created><updated>2013-06-28</updated><authors><author><keyname>Popescu</keyname><forenames>Marian</forenames></author><author><keyname>Dugan</keyname><forenames>Peter J.</forenames></author><author><keyname>Pourhomayoun</keyname><forenames>Mohammad</forenames></author><author><keyname>Risch</keyname><forenames>Denise</forenames></author><author><keyname>Lewis</keyname><forenames>Harold W.</forenames><suffix>III</suffix></author><author><keyname>Clark</keyname><forenames>Christopher W.</forenames></author></authors><title>Bioacoustical Periodic Pulse Train Signal Detection and Classification
  using Spectrogram Intensity Binarization and Energy Projection</title><categories>cs.CV</categories><comments>ICML 2013 Workshop on Machine Learning for Bioacoustics, 2013, 6
  pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The following work outlines an approach for automatic detection and
recognition of periodic pulse train signals using a multi-stage process based
on spectrogram edge detection, energy projection and classification. The method
has been implemented to automatically detect and recognize pulse train songs of
minke whales. While the long term goal of this work is to properly identify and
detect minke songs from large multi-year datasets, this effort was developed
using sounds off the coast of Massachusetts, in the Stellwagen Bank National
Marine Sanctuary. The detection methodology is presented and evaluated on 232
continuous hours of acoustic recordings and a qualitative analysis of machine
learning classifiers and their performance is described. The trained automatic
detection and classification system is applied to 120 continuous hours,
comprised of various challenges such as broadband and narrowband noises, low
SNR, and other pulse train signatures. This automatic system achieves a TPR of
63% for FPR of 0.6% (or 0.87 FP/h), at a Precision (PPV) of 84% and an F1 score
of 71%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3251</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3251</id><created>2013-05-13</created><authors><author><keyname>Sinha</keyname><forenames>Amitabha</forenames></author><author><keyname>Acharyya</keyname><forenames>Soumojit</forenames></author><author><keyname>Chakraborty</keyname><forenames>Suranjan</forenames></author><author><keyname>Sarkar</keyname><forenames>Mitrava</forenames></author></authors><title>Field Programmable DSP Arrays - A Novel Reconfigurable Architecture for
  Efficient Realization of Digital Signal Processing Functions</title><categories>cs.OH</categories><comments>18 pages, 17 figures. This paper has been published into Signal &amp;
  Image Processing : An International Journal (SIPIJ - AIRCC) Vol.4, No.2,
  April 2013. http://airccse.org/journal/sipij/current2013.html</comments><journal-ref>Signal &amp; Image Processing : An International Journal (SIPIJ -
  AIRCC) Vol.4, No.2, April 2013</journal-ref><doi>10.5121/sipij.2013.4204</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital Signal Processing functions are widely used in real time high speed
applications. Those functions are generally implemented either on ASICs with
inflexibility, or on FPGAs with bottlenecks of relatively smaller utilization
factor or lower speed compared to ASIC. The proposed reconfigurable DSP
processor is redolent to FPGA, but with basic fixed Common Modules (CMs) (like
adders, subtractors, multipliers, scaling units, shifters) instead of CLBs.
This paper introduces the development of a reconfigurable DSP processor that
integrates different filter and transform functions. The switching between DSP
functions is occurred by reconfiguring the interconnection between CMs.
Validation of the proposed reconfigurable architecture has been achieved on
Virtex5 FPGA. The architecture provides sufficient amount of flexibility,
parallelism and scalability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3252</identifier>
 <datestamp>2013-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3252</id><created>2013-05-14</created><updated>2013-05-21</updated><authors><author><keyname>Osella</keyname><forenames>Esteban N.</forenames></author><author><keyname>Haimovich</keyname><forenames>Hernan</forenames></author><author><keyname>Seron</keyname><forenames>Mar&#xed;a M.</forenames></author></authors><title>Fault-tolerant control under controller-driven sampling using virtual
  actuator strategy</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new output feedback fault tolerant control strategy for
continuous-time linear systems. The strategy combines a digital nominal
controller under controller-driven (varying) sampling with virtual-actuator
(VA)-based controller reconfiguration to compensate for actuator faults. In the
proposed scheme, the controller controls both the plant and the sampling
period, and performs controller reconfiguration by engaging in the loop the VA
adapted to the diagnosed fault. The VA also operates under controller-driven
sampling. Two independent objectives are considered: (a) closed-loop stability
with setpoint tracking and (b) controller reconfiguration under faults. Our
main contribution is to extend an existing VA-based controller reconfiguration
strategy to systems under controller-driven sampling in such a way that if
objective (a) is possible under controller-driven sampling (without VA) and
objective (b) is possible under uniform sampling (without controller-driven
sampling), then closed-loop stability and setpoint tracking will be preserved
under both healthy and faulty operation for all possible sampling rate
evolutions that may be selected by the controller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3253</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3253</id><created>2013-05-14</created><authors><author><keyname>Sheth</keyname><forenames>Ketul</forenames></author><author><keyname>Shah</keyname><forenames>Shreya</forenames></author><author><keyname>Shah</keyname><forenames>Darshan</forenames></author><author><keyname>Odhekar</keyname><forenames>Anuja</forenames></author></authors><title>Social Network for Smart Devices using Embedded Ethernet</title><categories>cs.NI cs.SI</categories><comments>15 pages, 8 figures, Submitted to: 'Computer Science and Engineering:
  An International Journal', Currently we are working on further enhancing the
  website to give the appearance of a social networking website</comments><journal-ref>Computer Science &amp; Engineering: An International Journal (CSEIJ),
  Vol. 3, No. 2, April 2013, Pg no. 41-55</journal-ref><doi>10.5121/cseij.2013.3204</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Embedded Ethernet is nothing but a microcontroller which is able to
communicate with the network. A design of AVR controller-based embedded
Ethernet interface is presented. In the design, an existing SPI serial device
can be converted into a network interface peripheral to obtain compatibility
with the network. By typing the IP-address of LAN on the web browser, the user
gets a web page on screen; this page contains all the information about the
status of the devices. The user can also control the devices interfaced to the
web server by pressing buttons provided in the web page. This creates a network
for easy communication among the devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3255</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3255</id><created>2013-05-14</created><authors><author><keyname>Arantes</keyname><forenames>Fl&#xe1;via Linhalis</forenames></author></authors><title>Requirements Engineering of a Web Portal using Organizational Semiotics
  Artifacts and Participatory Practices</title><categories>cs.SE</categories><journal-ref>International Journal of Computer Science &amp; Information Technology
  (IJCSIT) Vol 5, No 2, April 2013</journal-ref><doi>10.5121/ijcsit.2013.5212</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Software requirements are key elements that contribute to the quality and
users satisfaction of the final system. In this work, Requirements Engineering
(RE) of web sites is presented using an organizational semiotics perspective.
They are shown as being part of an organization, with particular practices,
rules and views considering stakeholders several differences and opinions. The
main contribution of this paper is to relate an experience, from elicitation to
validation, showing how organizational semiotics artifacts were exploited in a
collaborative and participatory way to RE of a web portal. A case study is
described in order to demonstrate the feasibility of using such artifacts to RE
when we think about the system as being part of a social organization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3257</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3257</id><created>2013-05-14</created><updated>2013-05-15</updated><authors><author><keyname>Drummond-Cole</keyname><forenames>Gabriel C.</forenames></author></authors><title>An update on domineering on rectangular boards</title><categories>math.CO cs.GT</categories><comments>9 pages. References fixed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Domineering is a combinatorial game played on a subset of a rectangular grid
between two players. Each board position can be put into one of four outcome
classes based on who the winner will be if both players play optimally. In this
note, we review previous work, establish the outcome classes for several
dimensions of rectangular board, and restrict the outcome class in several
more.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3265</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3265</id><created>2013-05-14</created><updated>2013-05-17</updated><authors><author><keyname>Karakus</keyname><forenames>Can</forenames></author><author><keyname>Wang</keyname><forenames>I-Hsiang</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas</forenames></author></authors><title>Interference Channel with Intermittent Feedback</title><categories>cs.IT math.IT</categories><comments>Extended version of the same-titled paper that appears in IEEE
  International Symposium on Information Theory (ISIT) 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate how to exploit intermittent feedback for interference
management. Focusing on the two-user linear deterministic interference channel,
we completely characterize the capacity region. We find that the
characterization only depends on the forward channel parameters and the
marginal probability distribution of each feedback link. The scheme we propose
makes use of block Markov encoding and quantize-map-and-forward at the
transmitters, and backward decoding at the receivers. Matching outer bounds are
derived based on novel genie-aided techniques. As a consequence, the
perfect-feedback capacity can be achieved once the two feedback links are
active with large enough probabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3268</identifier>
 <datestamp>2013-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3268</id><created>2013-05-14</created><updated>2013-12-02</updated><authors><author><keyname>Bri&#xeb;t</keyname><forenames>Jop</forenames></author><author><keyname>Dadush</keyname><forenames>Daniel</forenames></author><author><keyname>Pokutta</keyname><forenames>Sebastian</forenames></author></authors><title>On the existence of 0/1 polytopes with high semidefinite extension
  complexity</title><categories>cs.CC math.CO</categories><msc-class>90C05, 68W25, 90C60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Rothvo\ss{} it was shown that there exists a 0/1 polytope (a polytope
whose vertices are in \{0,1\}^{n}) such that any higher-dimensional polytope
projecting to it must have 2^{\Omega(n)} facets, i.e., its linear extension
complexity is exponential. The question whether there exists a 0/1 polytope
with high PSD extension complexity was left open. We answer this question in
the affirmative by showing that there is a 0/1 polytope such that any
spectrahedron projecting to it must be the intersection of a semidefinite cone
of dimension~2^{\Omega(n)} and an affine space. Our proof relies on a new
technique to rescale semidefinite factorizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3282</identifier>
 <datestamp>2013-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3282</id><created>2013-05-14</created><authors><author><keyname>Louf</keyname><forenames>R&#xe9;mi</forenames></author><author><keyname>Jensen</keyname><forenames>Pablo</forenames></author><author><keyname>Barthelemy</keyname><forenames>Marc</forenames></author></authors><title>Emergence of hierarchy in cost driven growth of spatial networks</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI</categories><comments>11 pages, 11 figures, 1 table</comments><journal-ref>Proc. Natl. Acad. Sci. USA 110(22), 8824-8829 (2013)</journal-ref><doi>10.1073/pnas.1222441110</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most important features of spatial networks such as transportation
networks, power grids, Internet, neural networks, is the existence of a cost
associated with the length of links. Such a cost has a profound influence on
the global structure of these networks which usually display a hierarchical
spatial organization. The link between local constraints and large-scale
structure is however not elucidated and we introduce here a generic model for
the growth of spatial networks based on the general concept of cost benefit
analysis. This model depends essentially on one single scale and produces a
family of networks which range from the star-graph to the minimum spanning tree
and which are characterised by a continuously varying exponent. We show that
spatial hierarchy emerges naturally, with structures composed of various hubs
controlling geographically separated service areas, and appears as a
large-scale consequence of local cost-benefit considerations. Our model thus
provides the first building blocks for a better understanding of the evolution
of spatial networks and their properties. We also find that, surprisingly, the
average detour is minimal in the intermediate regime, as a result of a large
diversity in link lengths. Finally, we estimate the important parameters for
various world railway networks and find that --remarkably-- they all fall in
this intermediate regime, suggesting that spatial hierarchy is a crucial
feature for these systems and probably possesses an important evolutionary
advantage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3288</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3288</id><created>2013-05-14</created><updated>2013-05-16</updated><authors><author><keyname>Sk&#xf3;rski</keyname><forenames>Maciej</forenames></author></authors><title>A Convex Analysis Approach to Computational Entropy</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the notion of computational entropy. Using techniques from
convex optimization, we investigate the following problems: (a) Can we
derandomize the computational entropy? More precisely, for the computational
entropy, what is the real difference in security defined using the three
important classes of circuits: deterministic boolean, deterministic real
valued, or (the most powerful) randomized ones? (b) How large the difference in
the computational entropy for an unbounded versus efficient adversary can be?
(c) Can we obtain useful, simpler characterizations for the computational
entropy?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3289</identifier>
 <datestamp>2014-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3289</id><created>2013-05-14</created><authors><author><keyname>Kim</keyname><forenames>Yongjune</forenames></author><author><keyname>Kumar</keyname><forenames>B. V. K. Vijaya</forenames></author></authors><title>Redundancy Allocation of Partitioned Linear Block Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, to appear in IEEE International Symposium on
  Information Theory (ISIT), Jul. 2013</comments><doi>10.1109/ISIT.2013.6620651</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most memories suffer from both permanent defects and intermittent random
errors. The partitioned linear block codes (PLBC) were proposed by Heegard to
efficiently mask stuck-at defects and correct random errors. The PLBC have two
separate redundancy parts for defects and random errors. In this paper, we
investigate the allocation of redundancy between these two parts. The optimal
redundancy allocation will be investigated using simulations and the simulation
results show that the PLBC can significantly reduce the probability of decoding
failure in memory with defects. In addition, we will derive the upper bound on
the probability of decoding failure of PLBC and estimate the optimal redundancy
allocation using this upper bound. The estimated redundancy allocation matches
the optimal redundancy allocation well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3311</identifier>
 <datestamp>2014-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3311</id><created>2013-05-14</created><updated>2014-06-09</updated><authors><author><keyname>Taneja</keyname><forenames>Harsh</forenames></author><author><keyname>Wu</keyname><forenames>Angela Xiao</forenames></author></authors><title>Does the Great Firewall really isolate the Chinese? Integrating access
  blockage with cultural factors to explain web user behavior</title><categories>cs.CY cs.SI physics.soc-ph</categories><comments>Pre-Publication Copy. Cite as: Taneja, H. &amp; Wu, A.X. (Forthcoming).
  Does the Great Firewall really isolate the Chinese? Integrating access
  blockage with cultural factors to explain web user behavior. The Information
  Society</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dominant understanding of Internet censorship posits that blocking access
to foreign-based websites creates isolated communities of Internet users. We
question this discourse for its assumption that if given access people would
use all websites. We develop a conceptual framework that integrates access
blockage with social structures to explain web users' choices, and argue that
users visit websites they find culturally proximate and access blockage matters
only when such sites are blocked. We examine the case of China, where online
blockage is notoriously comprehensive, and compare Chinese web usage patterns
with those elsewhere. Analyzing audience traffic among the 1000 most visited
websites, we find that websites cluster according to language and geography.
Chinese websites constitute one cluster, which resembles other such
geo-linguistic clusters in terms of both its composition and degree of
isolation. Our sociological investigation reveals a greater role of cultural
proximity than access blockage in explaining online behaviors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3312</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3312</id><created>2013-05-14</created><updated>2013-11-22</updated><authors><author><keyname>Chi</keyname><forenames>Eric C.</forenames></author><author><keyname>Lange</keyname><forenames>Kenneth</forenames></author></authors><title>Stable Estimation of a Covariance Matrix Guided by Nuclear Norm
  Penalties</title><categories>stat.ME cs.NA</categories><comments>25 pages, 3 figures</comments><journal-ref>Computational Statistics &amp; Data Analysis 80:117-128, 2014</journal-ref><doi>10.1016/j.csda.2014.06.018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimation of covariance matrices or their inverses plays a central role in
many statistical methods. For these methods to work reliably, estimated
matrices must not only be invertible but also well-conditioned. In this paper
we present an intuitive prior that shrinks the classic sample covariance
estimator towards a stable target. We prove that our estimator is consistent
and asymptotically efficient. Thus, it gracefully transitions towards the
sample covariance matrix as the number of samples grows relative to the number
of covariates. We also demonstrate the utility of our estimator in two standard
situations -- discriminant analysis and EM clustering -- when the number of
samples is dominated by or comparable to the number of covariates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3314</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3314</id><created>2013-05-14</created><authors><author><keyname>Chechik</keyname><forenames>Shiri</forenames></author></authors><title>Approximate Distance Oracle with Constant Query Time</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An approximate distance oracle is a succinct data structure that provides
fast answers to distance queries between any two nodes. In this paper we
consider approximate distance oracles for general undirected graphs with
non-negative edge weights with constant query time. We present a distance
oracle of size O(k n^{1+1/k}), with 2k-1 stretch and O(1) query time. This
improves the O(log{k}) query time of Wulff-Nilsen's distance oracle [SODA '13],
which in turn improved the O(k) query time of Thorup and Zwick's distance
oracle [J. ACM '05].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3317</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3317</id><created>2013-05-14</created><authors><author><keyname>Li</keyname><forenames>Sheng</forenames></author><author><keyname>de Lamare</keyname><forenames>Rodrigo C.</forenames></author></authors><title>Linear Reduced-Rank Interference Suppression for DS-UWB Systems Using
  Switched Approximations of Adaptive Basis Functions</title><categories>cs.IT math.IT</categories><comments>9 figures. arXiv admin note: text overlap with arXiv:1305.2974</comments><journal-ref>IEEE Transactions on Vehicular Technology, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose a novel low-complexity reduced-rank scheme and
consider its application to linear interference suppression in direct-sequence
ultra-wideband (DS-UWB) systems. Firstly, we investigate a generic reduced-rank
scheme that jointly optimizes a projection vector and a reduced-rank filter by
using the minimum mean-squared error (MMSE) criterion. Then a low-complexity
scheme, denoted switched approximation of adaptive basis functions (SAABF), is
proposed. The SAABF scheme is an extension of the generic scheme, in which the
complexity reduction is achieved by using a multi-branch framework to simplify
the structure of the projection vector. Adaptive implementations for the SAABF
scheme are developed by using least-mean squares (LMS) and recursive
least-squares (RLS) algorithms. We also develop algorithms for selecting the
branch number and the model order of the SAABF scheme. Simulations show that in
the scenarios with severe inter-symbol interference (ISI) and multiple access
interference (MAI), the proposed SAABF scheme has fast convergence and
remarkable interference suppression performance with low complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3321</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3321</id><created>2013-05-14</created><authors><author><keyname>Jabbour</keyname><forenames>Said</forenames></author><author><keyname>Sais</keyname><forenames>Lakhdar</forenames></author><author><keyname>Salhi</keyname><forenames>Yakoub</forenames></author></authors><title>A Mining-Based Compression Approach for Constraint Satisfaction Problems</title><categories>cs.AI</categories><comments>arXiv admin note: substantial text overlap with arXiv:1304.4415</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an extension of our Mining for SAT framework to
Constraint satisfaction Problem (CSP). We consider n-ary extensional
constraints (table constraints). Our approach aims to reduce the size of the
CSP by exploiting the structure of the constraints graph and of its associated
microstructure. More precisely, we apply itemset mining techniques to search
for closed frequent itemsets on these two representation. Using Tseitin
extension, we rewrite the whole CSP to another compressed CSP equivalent with
respect to satisfiability. Our approach contrast with previous proposed
approach by Katsirelos and Walsh, as we do not change the structure of the
constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3328</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3328</id><created>2013-05-14</created><authors><author><keyname>Lapinski</keyname><forenames>Scott</forenames></author><author><keyname>Piwowar</keyname><forenames>Heather</forenames></author><author><keyname>Priem</keyname><forenames>Jason</forenames></author></authors><title>Riding the crest of the altmetrics wave: How librarians can help prepare
  faculty for the next generation of research impact metrics</title><categories>cs.DL</categories><comments>4 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As scholars migrate into online spaces like Mendeley, blogs, Twitter, and
more, they leave new traces of once-invisible interactions like reading,
saving, discussing, and recommending. Observing these traces can inform new
metrics of scholarly influence and impact -- so-called &quot;altmetrics.&quot;
Stakeholders in academia are beginning to discuss how and where altmetrics can
be useful towards evaluating a researcher's academic contribution. As this
interest grows, libraries are in a unique position to help support an informed
dialog on campus. We suggest that librarians can provide this support in three
main ways: informing emerging conversations with the latest research,
supporting experimentation with emerging altmetrics tools, and engaging in
early altmetrics education and outreach. We include examples and lists of
resources to help librarians fill these roles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3333</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3333</id><created>2013-05-14</created><authors><author><keyname>Fotakis</keyname><forenames>Dimitris</forenames></author><author><keyname>Tzamos</keyname><forenames>Christos</forenames></author></authors><title>Strategy-Proof Facility Location for Concave Cost Functions</title><categories>cs.GT</categories><acm-class>F.2.0; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider k-Facility Location games, where n strategic agents report their
locations on the real line, and a mechanism maps them to k facilities. Each
agent seeks to minimize his connection cost, given by a nonnegative increasing
function of his distance to the nearest facility. Departing from previous work,
that mostly considers the identity cost function, we are interested in
mechanisms without payments that are (group) strategyproof for any given cost
function, and achieve a good approximation ratio for the social cost and/or the
maximum cost of the agents.
  We present a randomized mechanism, called Equal Cost, which is group
strategyproof and achieves a bounded approximation ratio for all k and n, for
any given concave cost function. The approximation ratio is at most 2 for Max
Cost and at most n for Social Cost. To the best of our knowledge, this is the
first mechanism with a bounded approximation ratio for instances with k &gt; 2
facilities and any number of agents. Our result implies an interesting
separation between deterministic mechanisms, whose approximation ratio for Max
Cost jumps from 2 to unbounded when k increases from 2 to 3, and randomized
mechanisms, whose approximation ratio remains at most 2 for all k. On the
negative side, we exclude the possibility of a mechanism with the properties of
Equal Cost for strictly convex cost functions. We also present a randomized
mechanism, called Pick the Loser, which applies to instances with k facilities
and n = k+1 agents, and for any given concave cost function, is strongly group
strategyproof and achieves an approximation ratio of 2 for Social Cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3334</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3334</id><created>2013-05-14</created><authors><author><keyname>Tekin</keyname><forenames>Cem</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author></authors><title>Online Learning in a Contract Selection Problem</title><categories>cs.LG cs.GT math.OC stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an online contract selection problem there is a seller which offers a set
of contracts to sequentially arriving buyers whose types are drawn from an
unknown distribution. If there exists a profitable contract for the buyer in
the offered set, i.e., a contract with payoff higher than the payoff of not
accepting any contracts, the buyer chooses the contract that maximizes its
payoff. In this paper we consider the online contract selection problem to
maximize the sellers profit. Assuming that a structural property called ordered
preferences holds for the buyer's payoff function, we propose online learning
algorithms that have sub-linear regret with respect to the best set of
contracts given the distribution over the buyer's type. This problem has many
applications including spectrum contracts, wireless service provider data plans
and recommendation systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3336</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3336</id><created>2013-05-14</created><authors><author><keyname>Barman</keyname><forenames>Siddharth</forenames></author><author><keyname>Bhaskar</keyname><forenames>Umang</forenames></author><author><keyname>Echenique</keyname><forenames>Federico</forenames></author><author><keyname>Wierman</keyname><forenames>Adam</forenames></author></authors><title>The Empirical Implications of Rank in Bimatrix Games</title><categories>cs.GT</categories><comments>To appear in the ACM Conference on Electronic Commerce 2013 (EC'13)</comments><acm-class>F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the structural complexity of bimatrix games, formalized via rank,
from an empirical perspective. We consider a setting where we have data on
player behavior in diverse strategic situations, but where we do not observe
the relevant payoff functions. We prove that high complexity (high rank) has
empirical consequences when arbitrary data is considered. Additionally, we
prove that, in more restrictive classes of data (termed laminar), any
observation is rationalizable using a low-rank game: specifically a zero-sum
game. Hence complexity as a structural property of a game is not always
testable. Finally, we prove a general result connecting the structure of the
feasible data sets with the highest rank that may be needed to rationalize a
set of observations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3338</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3338</id><created>2013-05-14</created><authors><author><keyname>Hsu</keyname><forenames>Ching-Hsien</forenames></author><author><keyname>Zhang</keyname><forenames>Daqiang</forenames></author><author><keyname>Yang</keyname><forenames>Chao-Tung</forenames></author><author><keyname>Chu</keyname><forenames>Hai-Cheng</forenames></author></authors><title>An Efficient Method for Optimizing RFID Reader Deployment and Energy
  Saving</title><categories>cs.NI cs.DC cs.SY</categories><comments>To appear in Sensor Letters, 2013</comments><acm-class>C.2.1; I.3.2; H.2.4</acm-class><journal-ref>Sensor Letters ISSN: 1546-198X (Print): EISSN: 1546-1971 (Online)
  , http://www.aspbs.com/sensorlett/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapid proliferation of Radio Frequency IDentification (RFID) systems
realizes integration of physical world with the cyber ones. One of the most
promising is the Internet of Things (IoT), a vision in which the Internet
extends into our daily activities through wireless networks of uniquely
identifiable objects. Given that modern RFID systems are being deployed in
large-scale for different applications, without optimizing reader's
distribution, many of the readers will be redundant, resulting waste of energy.
Additionally, eliminating redundant eaders can also decrease probability of
reader collisions, as a result, enhancing system performance and efficiency. In
this paper, an overlap aware (OA) technique is proposed for eliminating
redundant readers. The OA is a distributed approach, which does not need to
collect global information for centralizing control, aims to detect maximum
amount of redundant readers could be safely removed or turned off with
preserving original RFID network coverage. A significant improvement of the OA
scheme is that the amount of &quot;write-to-tag&quot; operations could be largely reduced
during the redundant reader identification phase. In order to accurately
evaluate the performance of the proposed method, it was performed in a variety
of scenarios. The experiment results show that the proposed method can provide
reliable performance with detecting higher redundancy and has lower algorithm
overheads as compared with several well known methods, such as the RRE, LEO,
the hybrid algorithm (LEO+RRE) and the DRRE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3345</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3345</id><created>2013-05-14</created><authors><author><keyname>Sun</keyname><forenames>Weibin</forenames></author><author><keyname>Ricci</keyname><forenames>Robert</forenames></author></authors><title>Augmenting Operating Systems With the GPU</title><categories>cs.OS</categories><comments>5 pages, 2 figures, old white paper submitted for KGPU citation</comments><acm-class>D.4.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The most popular heterogeneous many-core platform, the CPU+GPU combination,
has received relatively little attention in operating systems research. This
platform is already widely deployed: GPUs can be found, in some form, in most
desktop and laptop PCs. Used for more than just graphics processing, modern
GPUs have proved themselves versatile enough to be adapted to other
applications as well. Though GPUs have strengths that can be exploited in
systems software, this remains a largely untapped resource. We argue that
augmenting the OS kernel with GPU computing power opens the door to a number of
new opportunities. GPUs can be used to speed up some kernel functions, make
other scale better, and make it feasible to bring some computation-heavy
functionality into the kernel. We present our framework for using the GPU as a
co-processor from an OS kernel, and demonstrate a prototype in Linux.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3351</identifier>
 <datestamp>2014-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3351</id><created>2013-05-14</created><updated>2014-04-22</updated><authors><author><keyname>Ghosh</keyname><forenames>Arnob</forenames></author><author><keyname>Sarkar</keyname><forenames>Saswati</forenames></author></authors><title>Quality Sensitive Price Competition in Spectrum Oligopoly</title><categories>cs.GT</categories><comments>Presented in ISIT' 2013, Istanbul Version 2 contains some modified
  versions of proofs of version 1. In IEEE Proceedings of International
  Symposium on Information Theory, 2013</comments><doi>10.1109/ISIT.2013.6620730</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate a spectrum oligopoly where primary users allow secondary
access in lieu of financial remuneration. Transmission qualities of the
licensed bands fluctuate randomly. Each primary needs to select the price of
its channel with the knowledge of its own channel state but not that of its
competitors. Secondaries choose among the channels available on sale based on
their states and prices. We formulate the price selection as a non-cooperative
game and prove that a symmetric Nash equilibrium (NE) strategy profile exists
uniquely. We explicitly compute this strategy profile and analytically and
numerically evaluate its efficiency. Our structural results provide certain key
insights about the unique symmetric NE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3354</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3354</id><created>2013-05-15</created><authors><author><keyname>Chakraborty</keyname><forenames>Sandip</forenames></author><author><keyname>Majumder</keyname><forenames>Soumyadip</forenames></author><author><keyname>Goswami</keyname><forenames>Diganta</forenames></author></authors><title>Approximate Congestion Games for Load Balancing in Distributed
  Environment</title><categories>cs.NI cs.DC cs.GT</categories><comments>A version of this work has been presented at International Workshop
  on Distributed System (IWDS) 2010, IIT Kanpur, India, as a &quot;work-in-progress&quot;
  report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of game theoretic models has been quite successful in describing
various cooperative and non-cooperative optimization problems in networks and
other domains of computer systems. In this paper, we study an application of
game theoretic models in the domain of distributed system, where nodes play a
game to balance the total processing loads among themselves. We have used
congestion gaming model, a model of game theory where many agents compete for
allocating resources, and studied the existence of Nash Equilibrium for such
types of games. As the classical congestion game is known to be PLS-Complete,
we use an approximation, called the \epsilon-Congestion game, which converges
to \epsilon-Nash equilibrium within finite number of steps under selected
conditions. Our focus is to define the load balancing problem using the model
of \epsilon-congestion games, and finally provide a greedy algorithm for load
balancing in distributed systems. We have simulated our proposed system to show
the effect of \epsilon-congestion game, and the distribution of load at
equilibrium state.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3356</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3356</id><created>2013-05-15</created><authors><author><keyname>Wang</keyname><forenames>He</forenames></author><author><keyname>Zhou</keyname><forenames>Xiangyun</forenames></author><author><keyname>Reed</keyname><forenames>Mark C.</forenames></author></authors><title>Analytical Evaluation of Coverage-Oriented Femtocell Network Deployment</title><categories>cs.IT cs.NI math.IT</categories><comments>6 pages, 7 figures, published in IEEE International Conference on
  Communications (ICC'13)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a coverage-oriented femtocell network deployment scheme,
in which the femtocell base stations (BSs) can decide whether to be active or
inactive depending on their distances from the macrocell BSs. Specifically, as
the areas close to the macrocell BSs already have satisfactory cellular
coverage, the femtocell BSs located inside such areas are kept to be inactive.
Thus, all the active femtocells are located in the poor macrocell coverage
areas. Based on a stochastic geometric framework, the coverage probability can
be analyzed with tractable results. Surprisingly, the results show that the
proposed scheme, although with a lower defacto femtocell density, can achieve
better coverage performance than that keeping all femtocells in the entire
network to be active. The analytical results further identify the achievable
optimal performance of the new scheme, which provides mobile operators a
guideline for femtocell deployment and operation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3358</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3358</id><created>2013-05-15</created><authors><author><keyname>Thakor</keyname><forenames>Satyajit</forenames></author><author><keyname>Chan</keyname><forenames>Terence</forenames></author><author><keyname>Shum</keyname><forenames>Kenneth W.</forenames></author></authors><title>Symmetry in Distributed Storage Systems</title><categories>cs.IT math.IT</categories><comments>Accepted, ISIT 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The max-flow outer bound is achievable by regenerating codes for functional
repair distributed storage system. However, the capacity of exact repair
distributed storage system is an open problem. In this paper, the linear
programming bound for exact repair distributed storage systems is formulated. A
notion of symmetrical sets for a set of random variables is given and
equalities of joint entropies for certain subsets of random variables in a
symmetrical set is established. Concatenation coding scheme for exact repair
distributed storage systems is proposed and it is shown that concatenation
coding scheme is sufficient to achieve any admissible rate for any exact repair
distributed storage system. Equalities of certain joint entropies of random
variables induced by concatenation scheme is shown. These equalities of joint
entropies are new tools to simplify the linear programming bound and to obtain
stronger converse results for exact repair distributed storage systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3364</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3364</id><created>2013-05-15</created><authors><author><keyname>Kolte</keyname><forenames>Ritesh</forenames></author><author><keyname>&#xd6;zg&#xfc;r</keyname><forenames>Ayfer</forenames></author></authors><title>Generalized Diversity-Multiplexing Tradeoff of Half-Duplex Relay
  Networks</title><categories>cs.IT math.IT</categories><comments>to be presented at IEEE International Symposium on Information Theory
  (ISIT) 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diversity-multiplexing trade-off has been studied extensively to quantify the
benefits of different relaying strategies in terms of error and rate
performance. However, even in the case of a single half-duplex relay, which
seems fully characterized, implications are not clear. When all channels in the
system are assumed to be independent and identically fading, a fixed schedule
where the relay listens half of the total duration for communication and
transmits the second half combined with quantize-map-and-forward relaying
(static QMF) is known to achieve the full-duplex performance [1]. However, when
there is no direct link between the source and the destination, a dynamic
decode-and-forward (DDF) strategy is needed [2]. It is not clear which one of
these two conclusions would carry to a less idealized setup, where the direct
link can be neither as strong as the other links nor fully non-existent.
  In this paper, we provide a generalized diversity-multiplexing trade-off for
the half-duplex relay channel which accounts for different channel strengths
and recovers the two earlier results as two special cases. We show that these
two strategies are sufficient to achieve the diversity-multiplexing trade-off
across all channel configurations, by characterizing the best achievable
trade-off when channel state information (CSI) is only available at the
receivers (CSIR). However, for general relay networks we show that a
generalization of these two schemes through a dynamic QMF strategy is needed to
achieve optimal performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3375</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3375</id><created>2013-05-15</created><authors><author><keyname>Viswanatha</keyname><forenames>Kumar</forenames></author><author><keyname>Akyol</keyname><forenames>Emrah</forenames></author><author><keyname>Rose</keyname><forenames>Kenneth</forenames></author></authors><title>On the Role of Common Codewords in Quadratic Gaussian Multiple
  Descriptions Coding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the problem of $L-$channel quadratic Gaussian multiple
description (MD) coding. We recently introduced a new encoding scheme in [1]
for general $L-$channel MD problem, based on a technique called `Combinatorial
Message Sharing' (CMS), where every subset of the descriptions shares a
distinct common message. The new achievable region subsumes the most well known
region for the general problem, due to Venkataramani, Kramer and Goyal (VKG)
[2]. Moreover, we showed in [3] that the new scheme provides a strict
improvement of the achievable region for any source and distortion measures for
which some 2-description subset is such that the Zhang and Berger (ZB) scheme
achieves points outside the El-Gamal and Cover (EC) region. In this paper, we
show a more surprising result: CMS outperforms VKG for a general class of
sources and distortion measures, which includes scenarios where for all
2-description subsets, the ZB and EC regions coincide. In particular, we show
that CMS strictly extends VKG region, for the $L$-channel quadratic Gaussian MD
problem for all $L\geq3$, despite the fact that the EC region is complete for
the corresponding 2-descriptions problem. Using the encoding principles
derived, we show that the CMS scheme achieves the complete rate-distortion
region for several asymmetric cross-sections of the $L-$channel quadratic
Gaussian MD problem, which have not been considered earlier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3376</identifier>
 <datestamp>2014-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3376</id><created>2013-05-15</created><authors><author><keyname>Bernad&#xf3;</keyname><forenames>Laura</forenames></author><author><keyname>Zemen</keyname><forenames>Thomas</forenames></author><author><keyname>Tufvesson</keyname><forenames>Fredrik</forenames></author><author><keyname>Molisch</keyname><forenames>Andreas F.</forenames></author><author><keyname>Mecklenbr&#xe4;uker</keyname><forenames>Christoph F.</forenames></author></authors><title>Delay and Doppler Spreads of Non-Stationary Vehicular Channels for
  Safety Relevant Scenarios</title><categories>cs.NI</categories><comments>18 pages, 5 figures, submitted to IEEE Transactions on Vehicular
  Communications for possible publication</comments><journal-ref>IEEE Transactions on Vehicular Technology, vol. 63, no. 1, pp.
  82-93, January 2014</journal-ref><doi>10.1109/TVT.2013.2271956</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicular communication channels are characterized by a non-stationary time-
and frequency-selective fading process due to rapid changes in the environment.
The non-stationary fading process can be characterized by assuming local
stationarity for a region with finite extent in time and frequency. For this
finite region the wide-sense stationarity and uncorrelated-scattering (WSSUS)
assumption holds approximately and we are able to calculate a time and
frequency dependent local scattering function (LSF). In this paper, we estimate
the LSF from a large set of measurements collected in the DRIVEWAY'09
measurement campaign, which focuses on scenarios for intelligent transportation
systems. We then obtain the time-frequency-varying power delay profile (PDP)
and the time-frequency-varying Doppler power spectral density (DSD) from the
LSF. Based on the PDP and the DSD, we analyze the time-frequency-varying root
mean square (RMS) delay spread and the RMS Doppler spread. We show that the
distribution of these channel parameters follows a bi-modal Gaussian mixture
distribution. High RMS delay spread values are observed in situations with rich
scattering, while high RMS Doppler spreads are obtained in drive-by scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3384</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3384</id><created>2013-05-15</created><authors><author><keyname>Biadsy</keyname><forenames>Naseem</forenames></author><author><keyname>Rokach</keyname><forenames>Lior</forenames></author><author><keyname>Shmilovici</keyname><forenames>Armin</forenames></author></authors><title>Transfer Learning for Content-Based Recommender Systems using Tree
  Matching</title><categories>cs.LG cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a new approach to content-based transfer learning
for solving the data sparsity problem in cases when the users' preferences in
the target domain are either scarce or unavailable, but the necessary
information on the preferences exists in another domain. We show that training
a system to use such information across domains can produce better performance.
Specifically, we represent users' behavior patterns based on topological graph
structures. Each behavior pattern represents the behavior of a set of users,
when the users' behavior is defined as the items they rated and the items'
rating values. In the next step we find a correlation between behavior patterns
in the source domain and behavior patterns in the target domain. This mapping
is considered a bridge between the two domains. Based on the correlation and
content-attributes of the items, we train a machine learning model to predict
users' ratings in the target domain. When we compare our approach to the
popularity approach and KNN-cross-domain on a real world dataset, the results
show that on an average of 83$%$ of the cases our approach outperforms both
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3388</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3388</id><created>2013-05-15</created><authors><author><keyname>Birolo</keyname><forenames>Giovanni</forenames></author></authors><title>A Witness Extraction Technique by Proof Normalization Based on
  Interactive Realizability</title><categories>math.LO cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new set of reductions for derivations in natural deduction that
can extract witnesses from closed derivations of simply existential formulas in
Heyting Arithmetic (HA) plus the Excluded Middle Law restricted to simply
existential formulas (EM1), a system motivated by its interest in proof mining.
  The reduction we have for classical logic are quite different from all
existing ones. They are inspired by the informal idea of learning by making
falsifiable hypothesis and checking them, and by the interactive realizability
interpretation. We extract the witnesses directly from derivations in HA+EM1 by
reduction, without encoding derivations by a realizability interpretation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3396</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3396</id><created>2013-05-15</created><authors><author><keyname>Augot</keyname><forenames>Daniel</forenames></author><author><keyname>Finiasz</keyname><forenames>Matthieu</forenames></author></authors><title>Exhaustive Search for Small Dimension Recursive MDS Diffusion Layers for
  Block Ciphers and Hash Functions</title><categories>cs.CR</categories><comments>Published at ISIT 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents a new algorithm to find MDS matrices that are well
suited for use as a diffusion layer in lightweight block ciphers. Using an
recursive construction, it is possible to obtain matrices with a very compact
description. Classical field multiplications can also be replaced by simple
F2-linear transformations (combinations of XORs and shifts) which are much
lighter. Using this algorithm, it was possible to design a 16x16 matrix on a
5-bit alphabet, yielding an efficient 80-bit diffusion layer with maximal
branch number.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3407</identifier>
 <datestamp>2014-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3407</id><created>2013-05-15</created><updated>2014-01-20</updated><authors><author><keyname>Niedermayer</keyname><forenames>Johannes</forenames></author><author><keyname>Z&#xfc;fle</keyname><forenames>Andreas</forenames></author><author><keyname>Emrich</keyname><forenames>Tobias</forenames></author><author><keyname>Renz</keyname><forenames>Matthias</forenames></author><author><keyname>Mamoulis</keyname><forenames>Nikos</forenames></author><author><keyname>Chen</keyname><forenames>Lei</forenames></author><author><keyname>Kriegel</keyname><forenames>Hans-Peter</forenames></author></authors><title>Probabilistic Nearest Neighbor Queries on Uncertain Moving Object
  Trajectories</title><categories>cs.DB</categories><comments>12 pages</comments><journal-ref>PVLDB 7(3): 205-216 (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nearest neighbor (NN) queries in trajectory databases have received
significant attention in the past, due to their application in spatio-temporal
data analysis. Recent work has considered the realistic case where the
trajectories are uncertain; however, only simple uncertainty models have been
proposed, which do not allow for accurate probabilistic search. In this paper,
we fill this gap by addressing probabilistic nearest neighbor queries in
databases with uncertain trajectories modeled by stochastic processes,
specifically the Markov chain model. We study three nearest neighbor query
semantics that take as input a query state or trajectory $q$ and a time
interval. For some queries, we show that no polynomial time solution can be
found. For problems that can be solved in PTIME, we present exact query
evaluation algorithms, while for the general case, we propose a sophisticated
sampling approach, which uses Bayesian inference to guarantee that sampled
trajectories conform to the observation data stored in the database. This
sampling approach can be used in Monte-Carlo based approximation solutions. We
include an extensive experimental study to support our theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3422</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3422</id><created>2013-05-15</created><authors><author><keyname>Stotz</keyname><forenames>David</forenames></author><author><keyname>Riegler</keyname><forenames>Erwin</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>Almost Lossless Analog Signal Separation</title><categories>cs.IT math.IT</categories><comments>To be presented at IEEE Int. Symp. Inf. Theory 2013, Istanbul, Turkey</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an information-theoretic framework for analog signal separation.
Specifically, we consider the problem of recovering two analog signals from a
noiseless sum of linear measurements of the signals. Our framework is inspired
by the groundbreaking work of Wu and Verd\'u (2010) on almost lossless analog
compression. The main results of the present paper are a general achievability
bound for the compression rate in the analog signal separation problem, an
exact expression for the optimal compression rate in the case of signals that
have mixed discrete-continuous distributions, and a new technique for showing
that the intersection of generic subspaces with subsets of sufficiently small
Minkowski dimension is empty. This technique can also be applied to obtain a
simplified proof of a key result in Wu and Verd\'u (2010).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3437</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3437</id><created>2013-05-15</created><authors><author><keyname>Younis</keyname><forenames>Abdelhamid</forenames></author><author><keyname>Thompson</keyname><forenames>William</forenames></author><author><keyname>Di Renzo</keyname><forenames>Marco</forenames></author><author><keyname>Wang</keyname><forenames>Cheng-Xiang</forenames></author><author><keyname>Beach</keyname><forenames>Mark A.</forenames></author><author><keyname>Haas</keyname><forenames>Harald</forenames></author><author><keyname>Grant</keyname><forenames>Peter M.</forenames></author></authors><title>Performance of Spatial Modulation using Measured Real-World Channels</title><categories>cs.IT math.IT</categories><comments>IEEE Vehicular Technology Conference Fall 2013 (VTC-Fall 2013),
  Accepted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, for the first time real-world channel measurements are used to
analyse the performance of spatial modulation (SM), where a full analysis of
the average bit error rate performance (ABER) of SM using measured urban
correlated and uncorrelated Rayleigh fading channels is provided. The channel
measurements are taken from an outdoor urban multiple input multiple output
(MIMO) measurement campaign. Moreover, ABER performance results using simulated
Rayleigh fading channels are provided and compared with a derived analytical
bound for the ABER of SM, and the ABER results for SM using the measured urban
channels. The ABER results using the measured urban channels validate the
derived analytical bound and the ABER results using the simulated channels.
  Finally, the ABER of SM is compared with the performance of spatial
multiplexing (SMX) using the measured urban channels for small and large scale
MIMO. It is shown that SM offers nearly the same or a slightly better
performance than SMX for small scale MIMO. However, SM offers large reduction
in ABER for large scale MIMO.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3446</identifier>
 <datestamp>2013-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3446</id><created>2013-05-15</created><updated>2013-07-10</updated><authors><author><keyname>Parekh</keyname><forenames>Sanjeel</forenames></author><author><keyname>Shah</keyname><forenames>Pratik</forenames></author></authors><title>Nyquist Filter Design using POCS Methods: Including Constraints in
  Design</title><categories>cs.IT cs.NA math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of constrained finite impulse response (FIR) filter design is
central to signal processing and arises in a variety of disciplines. This paper
surveys the design of such filters using Projection onto convex sets (POCS) and
discusses certain commonly encountered time and frequency domain constraints.
We study in particular the design of Nyquist filters and propose a simple
extension to the work carried out by Haddad, Stark, and Galatsanos in [1]. The
flexibility and the ease that this design method provides in terms of
accommodating constraints is one of its outstanding features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3450</identifier>
 <datestamp>2014-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3450</id><created>2013-05-15</created><authors><author><keyname>Quattrociocchi</keyname><forenames>Walter</forenames></author><author><keyname>Caldarelli</keyname><forenames>Guido</forenames></author><author><keyname>Scala</keyname><forenames>Antonio</forenames></author></authors><title>Self-healing networks: redundancy and structure</title><categories>physics.soc-ph cs.SI</categories><doi>10.1371/journal.pone.0087986</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the concept of self-healing in the field of complex networks.
Obvious applications range from infrastructural to technological networks. By
exploiting the presence of redundant links in recovering the connectivity of
the system, we introduce self-healing capabilities through the application of
distributed communication protocols granting the &quot;smartness&quot; of the system. We
analyze the interplay between redundancies and smart reconfiguration protocols
in improving the resilience of networked infrastructures to multiple failures;
in particular, we measure the fraction of nodes still served for increasing
levels of network damages. We study the effects of different connectivity
patterns (planar square-grids, small-world, scale-free networks) on the healing
performances. The study of small-world topologies shows us that the
introduction of some long-range connections in the planar grids greatly
enhances the resilience to multiple failures giving results comparable to the
most resilient (but less realistic) scale-free structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3456</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3456</id><created>2013-05-15</created><updated>2013-05-16</updated><authors><author><keyname>Forni</keyname><forenames>Fulvio</forenames></author><author><keyname>Sepulchre</keyname><forenames>Rodolphe</forenames></author></authors><title>On differentially dissipative dynamical systems</title><categories>cs.SY math.DS</categories><journal-ref>9th IFAC Symposium on Nonlinear Control Systems, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dissipativity is an essential concept of systems theory. The paper provides
an extension of dissipativity, named differential dissipativity, by lifting
storage functions and supply rates to the tangent bundle. Differential
dissipativity is connected to incremental stability in the same way as
dissipativity is connected to stability. It leads to a natural formulation of
differential passivity when restricting to quadratic supply rates. The paper
also shows that the interconnection of differentially passive systems is
differentially passive, and provides preliminary examples of differentially
passive electrical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3483</identifier>
 <datestamp>2015-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3483</id><created>2013-05-15</created><updated>2015-01-06</updated><authors><author><keyname>Fyhn</keyname><forenames>Karsten</forenames></author><author><keyname>Duarte</keyname><forenames>Marco F.</forenames></author><author><keyname>Jensen</keyname><forenames>S&#xf8;ren Holdt</forenames></author></authors><title>Compressive Parameter Estimation for Sparse Translation-Invariant
  Signals Using Polar Interpolation</title><categories>cs.IT math.IT</categories><comments>13 pages, 5 figures, to appear in IEEE Transactions on Signal
  Processing; minor edits and corrections</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose new compressive parameter estimation algorithms that make use of
polar interpolation to improve the estimator precision. Our work extends
previous approaches involving polar interpolation for compressive parameter
estimation in two aspects: (i) we extend the formulation from real non-negative
amplitude parameters to arbitrary complex ones, and (ii) we allow for mismatch
between the manifold described by the parameters and its polar approximation.
To quantify the improvements afforded by the proposed extensions, we evaluate
six algorithms for estimation of parameters in sparse translation-invariant
signals, exemplified with the time delay estimation problem. The evaluation is
based on three performance metrics: estimator precision, sampling rate and
computational complexity. We use compressive sensing with all the algorithms to
lower the necessary sampling rate and show that it is still possible to attain
good estimation precision and keep the computational complexity low. Our
numerical experiments show that the proposed algorithms outperform existing
approaches that either leverage polynomial interpolation or are based on a
conversion to a frequency-estimation problem followed by a super-resolution
algorithm. The algorithms studied here provide various tradeoffs between
computational complexity, estimation precision, and necessary sampling rate.
The work shows that compressive sensing for the class of sparse
translation-invariant signals allows for a decrease in sampling rate and that
the use of polar interpolation increases the estimation precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3485</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3485</id><created>2013-05-15</created><authors><author><keyname>Fernandes</keyname><forenames>Ana Isabel</forenames></author><author><keyname>Goul&#xe3;o</keyname><forenames>Miguel</forenames></author><author><keyname>Rodrigues</keyname><forenames>Armanda</forenames></author></authors><title>A Comparison of Maps Application Programming Interfaces</title><categories>cs.SE</categories><comments>16th AGILE Conference on Geographic Information Science, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of web applications that manipulate geo-referenced
information is often supported by Application Programming Interfaces (APIs),
al-lowing a fast development cycle for high quality applications. APIs can be
used by programmers with different expertise levels and choosing an adequate
API may have a dramatic impact on the productivity achieved by those
programmers. Our goal is to compare maps APIs with respect to their usability.
We compare three different APIs: the Google Maps JavaScript API, the ArcGIS API
for JavaScript, and the OpenLayers JavaScript Mapping Library. Our comparison
is supported by a set of software metrics and is performed in two orthogonal
ways: the comparison of three implementations of the same system prototype,
each using one of the APIs under scrutiny; the comparison of the APIs
specifications. The main results of the study are related to the size of the
APIs, with the Google API being significantly smaller than the others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3486</identifier>
 <datestamp>2013-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3486</id><created>2013-05-15</created><updated>2013-07-18</updated><authors><author><keyname>Heckel</keyname><forenames>Reinhard</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>Noisy Subspace Clustering via Thresholding</title><categories>cs.IT cs.LG math.IT math.ST stat.ML stat.TH</categories><comments>Presented at the IEEE Int. Symp. Inf. Theory (ISIT) 2013, Istanbul,
  Turkey. The version posted here corrects a minor error in the published
  version. Specifically, the exponent -c n_l in the success probability of
  Theorem 1 and in the corresponding proof outline has been corrected to
  -c(n_l-1)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of clustering noisy high-dimensional data points into
a union of low-dimensional subspaces and a set of outliers. The number of
subspaces, their dimensions, and their orientations are unknown. A
probabilistic performance analysis of the thresholding-based subspace
clustering (TSC) algorithm introduced recently in [1] shows that TSC succeeds
in the noisy case, even when the subspaces intersect. Our results reveal an
explicit tradeoff between the allowed noise level and the affinity of the
subspaces. We furthermore find that the simple outlier detection scheme
introduced in [1] provably succeeds in the noisy case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3490</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3490</id><created>2013-05-15</created><authors><author><keyname>Guillemin</keyname><forenames>Fabrice</forenames></author><author><keyname>Simonian</keyname><forenames>Alain</forenames></author></authors><title>Stationary analysis of the Shortest Queue First service policy</title><categories>cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the so-called Shortest Queue First (SQF) queueing discipline
whereby a unique server addresses queues in parallel by serving at any time
that queue with the smallest workload. Considering a stationary system composed
of two parallel queues and assuming Poisson arrivals and general service time
distributions, we first establish the functional equations satisfied by the
Laplace transforms of the workloads in each queue. We further specialize these
equations to the so-called &quot;symmetric case&quot;, with same arrival rates and
identical exponential service time distributions at each queue; we then obtain
a functional equation $$ M(z) = q(z) \cdot M \circ h(z) + L(z) $$ for unknown
function $M$, where given functions $q$, $L$ and $h$ are related to one branch
of a cubic polynomial equation. We study the analyticity domain of function $M$
and express it by a series expansion involving all iterates of function $h$.
This allows us to determine empty queue probabilities along with the tail of
the workload distribution in each queue. This tail appears to be identical to
that of the Head-of-Line preemptive priority system, which is the key feature
desired for the SQF discipline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3496</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3496</id><created>2013-05-15</created><authors><author><keyname>Guillemin</keyname><forenames>Fabrice</forenames></author><author><keyname>Simonian</keyname><forenames>Alain</forenames></author></authors><title>Stationary analysis of the &quot;Shortest Queue First&quot; service policy: the
  asymmetric case</title><categories>cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a follow-up to a recent paper considering two symmetric queues, the
\textit{Shortest Queue First} service discipline is presently analysed for two
general asymmetric queues. Using the results previously established and
assuming exponentially distributed service times, the bivariate Laplace
transform of workloads in each queue is shown to depend on the solution
$\mathbf{M}$ to a two-dimensional functional equation $$ \mathbf{M} = Q_1 \cdot
\mathbf{M}\circ h_1 + Q_2 \cdot \mathbf{M}\circ h_2 + \mathbf{L} $$ with given
matrices $Q_1$, $Q_2$ and vector $\mathbf{L}$ and where functions $h_1$ and
$h_2$ are defined each on some rational curve; solution $\mathbf{M}$ can then
represented by a series expansion involving the semi-group $&lt; h_1, h_2 &gt;$
generated by these two functions. The empty queue probabilities along with the
tail behaviour of the workload distribution at each queue are characterised.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3498</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3498</id><created>2013-05-15</created><authors><author><keyname>Goparaju</keyname><forenames>Sreechakra</forenames></author><author><keyname>Tamo</keyname><forenames>Itzhak</forenames></author><author><keyname>Calderbank</keyname><forenames>Robert</forenames></author></authors><title>An Improved Sub-Packetization Bound for Minimum Storage Regenerating
  Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed storage systems employ codes to provide resilience to failure of
multiple storage disks. Specifically, an $(n, k)$ MDS code stores $k$ symbols
in $n$ disks such that the overall system is tolerant to a failure of up to
$n-k$ disks. However, access to at least $k$ disks is still required to repair
a single erasure. To reduce repair bandwidth, array codes are used where the
stored symbols or packets are vectors of length $\ell$. MDS array codes have
the potential to repair a single erasure using a fraction $1/(n-k)$ of data
stored in the remaining disks. We introduce new methods of analysis which
capitalize on the translation of the storage system problem into a geometric
problem on a set of operators and subspaces. In particular, we ask the
following question: for a given $(n, k)$, what is the minimum vector-length or
sub-packetization factor $\ell$ required to achieve this optimal fraction? For
\emph{exact recovery} of systematic disks in an MDS code of low redundancy,
i.e. $k/n &gt; 1/2$, the best known explicit codes \cite{WTB12} have a
sub-packetization factor $\ell$ which is exponential in $k$. It has been
conjectured \cite{TWB12} that for a fixed number of parity nodes, it is in fact
necessary for $\ell$ to be exponential in $k$. In this paper, we provide a new
log-squared converse bound on $k$ for a given $\ell$, and prove that $k \le
2\log_2\ell\left(\log_{\delta}\ell+1\right)$, for an arbitrary number of parity
nodes $r = n-k$, where $\delta = r/(r-1)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3506</identifier>
 <datestamp>2014-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3506</id><created>2013-05-15</created><updated>2014-02-02</updated><authors><author><keyname>Clark</keyname><forenames>Tim</forenames></author><author><keyname>Ciccarese</keyname><forenames>Paolo N.</forenames></author><author><keyname>Goble</keyname><forenames>Carole A.</forenames></author></authors><title>Micropublications: a Semantic Model for Claims, Evidence, Arguments and
  Annotations in Biomedical Communications</title><categories>cs.DL</categories><comments>Version 4. Minor revisions</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The Micropublications semantic model for scientific claims, evidence,
argumentation and annotation in biomedical publications, is a metadata model of
scientific argumentation, designed to support several key requirements for
exchange and value-addition of semantic metadata across the biomedical
publications ecosystem.
  Micropublications allow formalizing the argument structure of scientific
publications so that (a) their internal structure is semantically clear and
computable; (b) citation networks can be easily constructed across large
corpora; (c) statements can be formalized in multiple useful abstraction
models; (d) statements in one work may cite statements in another,
individually; (e) support, similarity and challenge of assertions can be
modelled across corpora; (f) scientific assertions, particularly in review
articles, may be transitively closed to supporting evidence and methods.
  The model supports natural language statements; data; methods and materials
specifications; discussion and commentary; as well as challenge and
disagreement. A detailed analysis of nine use cases is provided, along with an
implementation in OWL 2 and SWRL, with several example instantiations in RDF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3530</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3530</id><created>2013-05-15</created><updated>2013-06-23</updated><authors><author><keyname>Metcalfe</keyname><forenames>George</forenames><affiliation>University of Bern</affiliation></author><author><keyname>R&#xf6;thlisberger</keyname><forenames>Christoph</forenames><affiliation>University of Bern</affiliation></author></authors><title>Admissibility in Finitely Generated Quasivarieties</title><categories>cs.LO math.LO</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 2 (June 25,
  2013) lmcs:733</journal-ref><doi>10.2168/LMCS-9(2:9)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Checking the admissibility of quasiequations in a finitely generated (i.e.,
generated by a finite set of finite algebras) quasivariety Q amounts to
checking validity in a suitable finite free algebra of the quasivariety, and is
therefore decidable. However, since free algebras may be large even for small
sets of small algebras and very few generators, this naive method for checking
admissibility in $\Q$ is not computationally feasible. In this paper,
algorithms are introduced that generate a minimal (with respect to a multiset
well-ordering on their cardinalities) finite set of algebras such that the
validity of a quasiequation in this set corresponds to admissibility of the
quasiequation in Q. In particular, structural completeness (validity and
admissibility coincide) and almost structural completeness (validity and
admissibility coincide for quasiequations with unifiable premises) can be
checked. The algorithms are illustrated with a selection of well-known finitely
generated quasivarieties, and adapted to handle also admissibility of rules in
finite-valued logics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3532</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3532</id><created>2013-05-15</created><authors><author><keyname>Barrat</keyname><forenames>Alain</forenames></author><author><keyname>Cattuto</keyname><forenames>Ciro</forenames></author></authors><title>Temporal networks of face-to-face human interactions</title><categories>physics.soc-ph cs.SI</categories><comments>Chapter of the book &quot;Temporal Networks&quot;, Springer, 2013. Series:
  Understanding Complex Systems. Holme, Petter; Saram\&quot;aki, Jari (Eds.)</comments><doi>10.1007/978-3-642-36461-7_10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ever increasing adoption of mobile technologies and ubiquitous services
allows to sense human behavior at unprecedented levels of details and scale.
Wearable sensors are opening up a new window on human mobility and proximity at
the finest resolution of face-to-face proximity. As a consequence, empirical
data describing social and behavioral networks are acquiring a longitudinal
dimension that brings forth new challenges for analysis and modeling. Here we
review recent work on the representation and analysis of temporal networks of
face-to-face human proximity, based on large-scale datasets collected in the
context of the SocioPatterns collaboration. We show that the raw behavioral
data can be studied at various levels of coarse-graining, which turn out to be
complementary to one another, with each level exposing different features of
the underlying system. We briefly review a generative model of temporal contact
networks that reproduces some statistical observables. Then, we shift our focus
from surface statistical features to dynamical processes on empirical temporal
networks. We discuss how simple dynamical processes can be used as probes to
expose important features of the interaction patterns, such as burstiness and
causal constraints. We show that simulating dynamical processes on empirical
temporal networks can unveil differences between datasets that would otherwise
look statistically similar. Moreover, we argue that, due to the temporal
heterogeneity of human dynamics, in order to investigate the temporal
properties of spreading processes it may be necessary to abandon the notion of
wall-clock time in favour of an intrinsic notion of time for each individual
node, defined in terms of its activity level. We conclude highlighting several
open research questions raised by the nature of the data at hand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3536</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3536</id><created>2013-05-15</created><authors><author><keyname>Guillemin</keyname><forenames>Fabrice</forenames></author></authors><title>Analysis of a non-work conserving Generalized Processor Sharing queue</title><categories>cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider in this paper a non work-conserving Generalized Processor Sharing
(GPS) system composed of two queues with Poisson arrivals and exponential
service times. Using general results due to Fayolle \emph{et al}, we first
establish the stability condition for this system. We then determine the
functional equation satisfied by the generating function of the numbers of jobs
in both queues and the associated Riemann-Hilbert problem. We prove the
existence and the uniqueness of the solution. This allows us to completely
characterize the system, in particular to compute the empty queue probability.
We finally derive the tail asymptotics of the number of jobs in one queue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3537</identifier>
 <datestamp>2014-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3537</id><created>2013-05-15</created><authors><author><keyname>Tanbourgi</keyname><forenames>Ralph</forenames></author><author><keyname>J&#xe4;kel</keyname><forenames>Holger</forenames></author><author><keyname>Jondral</keyname><forenames>Friedrich K.</forenames></author></authors><title>Cooperative Relaying in a Poisson Field of Interferers: A Diversity
  Order Analysis</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures. To be presented at ISIT 2013</comments><journal-ref>IEEE International Symposium on Information Theory, pp.3100--3104,
  7-12 July 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work analyzes the gains of cooperative relaying in interference-limited
networks, in which outages can be due to interference and fading. A stochastic
model based on point process theory is used to capture the spatial randomness
present in contemporary wireless networks. Using a modification of the
diversity order metric, the reliability gain of selection decode-and-forward is
studied for several cases. The main results are as follows: the achievable
\emph{spatial-contention} diversity order (SC-DO) is equal to one irrespective
of the type of channel which is due to the ineffectiveness of the relay in the
MAC-phase (transmit diversity). In the BC-phase (receive diversity), the SC-DO
depends on the amount of fading and spatial interference correlation. In the
absence of fading, there is a hard transition between SC-DO of either one or
two, depending on the system parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3568</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3568</id><created>2013-05-15</created><authors><author><keyname>Jin</keyname><forenames>Xin</forenames></author><author><keyname>Li</keyname><forenames>Li Erran</forenames></author><author><keyname>Vanbever</keyname><forenames>Laurent</forenames></author><author><keyname>Rexford</keyname><forenames>Jennifer</forenames></author></authors><title>SoftCell: Taking Control of Cellular Core Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing cellular networks suffer from inflexible and expensive equipment,
and complex control-plane protocols. To address these challenges, we present
SoftCell, a scalable architecture for supporting fine-grained policies for
mobile devices in cellular core networks. The SoftCell controller realizes
high-level service polices by directing traffic over paths that traverse a
sequence of middleboxes, optimized to the network conditions and user
locations. To ensure scalability, the core switches forward traffic on
hierarchical addresses (grouped by base station) and policy tags (identifying
paths through middleboxes). This minimizes data-plane state in the core
switches, and pushes all fine-grained state to software switches at the base
stations. These access switches apply fine-grained rules, specified by the
controller, to map all traffic to the appropriate addresses and tags. SoftCell
guarantees that packets in the same connection traverse the same sequence of
middleboxes in both directions, even in the presence of mobility. Our
characterization of real LTE workloads, micro-benchmarks on our prototype
controller, and large-scale simulations demonstrate that SoftCell improves the
flexibility of cellular core networks, while enabling the use of inexpensive
commodity switches and middleboxes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3570</identifier>
 <datestamp>2014-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3570</id><created>2013-05-15</created><updated>2014-11-03</updated><authors><author><keyname>Elphick</keyname><forenames>Clive</forenames></author><author><keyname>Wocjan</keyname><forenames>Pawel</forenames></author></authors><title>New measures of graph irregularity</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we define and compare four new measures of graph irregularity.
We use these measures to prove upper bounds for the chromatic number and the
Colin de Verdiere parameter. We also strengthen the concise Turan theorem for
irregular graphs and investigate to what extent Turan's theorem can be
similarly strengthened for generalized r-partite graphs. We conclude by
relating these new measures to the Randic index and using the measures to
devise new normalised indices of network heterogeneity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3578</identifier>
 <datestamp>2013-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3578</id><created>2013-05-15</created><updated>2013-07-15</updated><authors><author><keyname>Gelenbe</keyname><forenames>Erol</forenames></author><author><keyname>Abdelrahman</keyname><forenames>Omer H.</forenames></author></authors><title>Search in Random Media with L\'evy Flights</title><categories>cond-mat.stat-mech cs.PF</categories><comments>To appear in the special volume &quot;First-Passage Phenomena and Their
  Applications&quot;, Eds. R. Metzler, G. Oshanin, S. Redner. World Scientific
  (2013); Final version, added two figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review some of our work regarding search which has been motivated by a
variety of applications in engineering and technology, including traffic
routing and security in communication networks, explosive mine detection and
removal, tactical operations as well as emergency management. We develop the
basic mathematical model representing N searchers that proceed independently,
and which can be affected by destruction or loss, and time-outs. An approach
based on Laplace transform is then developed for the case where the success of
the search requires that k out of the N searchers be successful, and we
estimate the amount of energy expended and the number of searchers that are
required to conduct a successful search in time B, provided B is large.
Finally, we present an iterative numerical solution approach that allows us to
analyse the search time and the energy needed to find an object when the search
space is non-homogeneous.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3584</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3584</id><created>2013-05-15</created><authors><author><keyname>Kordalewski</keyname><forenames>David</forenames></author></authors><title>New Greedy Heuristics For Set Cover and Set Packing</title><categories>cs.DS cs.DM</categories><comments>49 pages, 8 figures, submitted for M.Sc. degree</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Set Cover problem (SCP) and Set Packing problem (SPP) are standard
NP-hard combinatorial optimization problems. Their decision problem versions
are shown to be NP-Complete in Karp's 1972 paper. We specify a rough guide to
constructing approximation heuristics that may have widespread applications and
apply it to devise greedy approximation algorithms for SCP and SPP, where the
selection heuristic is a variation of that in the standard greedy approximation
algorithm. Our technique involves assigning to each input set a valuation and
then selecting, in each round, the set whose valuation is highest. We prove
that the technique we use for determining a valuation of the input sets yields
a unique value for all Set Cover instances. For both SCP and SPP we give
experimental evidence that the valuations we specify are unique and can be
computed to high precision quickly by an iterative algorithm. Others have
experimented with testing the observed approximation ratio of various
algorithms over a variety of randomly generated instances, and we have
extensive experimental evidence to show the quality of the new algorithm
relative to greedy heuristics in common use. Our algorithms are somewhat more
computationally intensive than the standard heuristics, though they are still
practical for large instances. We discuss some ways to speed up our algorithms
that do not significantly distort their effectiveness in practice on random
instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3586</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3586</id><created>2013-05-15</created><authors><author><keyname>Bethanabhotla</keyname><forenames>Dilip</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author><author><keyname>Neely</keyname><forenames>Michael J.</forenames></author></authors><title>Utility Optimal Scheduling and Admission Control for Adaptive Video
  Streaming in Small Cell Networks</title><categories>cs.IT cs.MM cs.NI math.IT</categories><comments>5 pages, 4 figures. Accepted and will be presented at IEEE
  International Symposium on Information Theory (ISIT) 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the jointly optimal design of a transmission scheduling and
admission control policy for adaptive video streaming over small cell networks.
We formulate the problem as a dynamic network utility maximization and observe
that it naturally decomposes into two subproblems: admission control and
transmission scheduling. The resulting algorithms are simple and suitable for
distributed implementation. The admission control decisions involve each user
choosing the quality of the video chunk asked for download, based on the
network congestion in its neighborhood. This form of admission control is
compatible with the current video streaming technology based on the DASH
protocol over TCP connections. Through simulations, we evaluate the performance
of the proposed algorithm under realistic assumptions for a small-cell network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3595</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3595</id><created>2013-05-15</created><updated>2013-05-17</updated><authors><author><keyname>Tutuncuoglu</keyname><forenames>Kaya</forenames></author><author><keyname>Ozel</keyname><forenames>Omur</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Binary Energy Harvesting Channel with Finite Energy Storage</title><categories>cs.IT cs.NI math.IT</categories><comments>to appear in Proceedings of the 2013 International Symposium on
  Information Theory (ISIT)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the capacity of an energy harvesting communication channel with a
finite-sized battery. As an abstraction of this problem, we consider a system
where energy arrives at the encoder in multiples of a fixed quantity, and the
physical layer is modeled accordingly as a finite discrete alphabet channel
based on this fixed quantity. Further, for tractability, we consider the case
of binary energy arrivals into a unit-capacity battery over a noiseless binary
channel. Viewing the available energy as state, this is a state-dependent
channel with causal state information available only at the transmitter.
Further, the state is correlated over time and the channel inputs modify the
future states. We show that this channel is equivalent to an additive
geometric-noise timing channel with causal information of the noise available
at the transmitter.We provide a single-letter capacity expression involving an
auxiliary random variable, and evaluate this expression with certain auxiliary
random variable selection, which resembles noise concentration and lattice-type
coding in the timing channel. We evaluate the achievable rates by the proposed
auxiliary selection and extend our results to noiseless ternary channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3596</identifier>
 <datestamp>2013-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3596</id><created>2013-05-15</created><authors><author><keyname>Badr</keyname><forenames>Ahmed</forenames></author><author><keyname>Khisti</keyname><forenames>Ashish</forenames></author><author><keyname>Tan</keyname><forenames>Wai-Tian</forenames></author><author><keyname>Apostolopoulos</keyname><forenames>John</forenames></author></authors><title>Robust Streaming Erasure Codes based on Deterministic Channel
  Approximations</title><categories>cs.IT math.IT</categories><comments>An abridged version of this paper will appear in ISIT 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study near optimal error correction codes for real-time communication. In
our setup the encoder must operate on an incoming source stream in a sequential
manner, and the decoder must reconstruct each source packet within a fixed
playback deadline of $T$ packets. The underlying channel is a packet erasure
channel that can introduce both burst and isolated losses.
  We first consider a class of channels that in any window of length ${T+1}$
introduce either a single erasure burst of a given maximum length $B,$ or a
certain maximum number $N$ of isolated erasures. We demonstrate that for a
fixed rate and delay, there exists a tradeoff between the achievable values of
$B$ and $N,$ and propose a family of codes that is near optimal with respect to
this tradeoff. We also consider another class of channels that introduce both a
burst {\em and} an isolated loss in each window of interest and develop the
associated streaming codes.
  All our constructions are based on a layered design and provide significant
improvements over baseline codes in simulations over the Gilbert-Elliott
channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3616</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3616</id><created>2013-05-15</created><authors><author><keyname>Rodriguez</keyname><forenames>Manuel Gomez</forenames></author><author><keyname>Leskovec</keyname><forenames>Jure</forenames></author><author><keyname>Schoelkopf</keyname><forenames>Bernhard</forenames></author></authors><title>Modeling Information Propagation with Survival Theory</title><categories>cs.SI cs.DS physics.soc-ph stat.ML</categories><comments>To appear at ICML '13</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Networks provide a skeleton for the spread of contagions, like, information,
ideas, behaviors and diseases. Many times networks over which contagions
diffuse are unobserved and need to be inferred. Here we apply survival theory
to develop general additive and multiplicative risk models under which the
network inference problems can be solved efficiently by exploiting their
convexity. Our additive risk model generalizes several existing network
inference models. We show all these models are particular cases of our more
general model. Our multiplicative model allows for modeling scenarios in which
a node can either increase or decrease the risk of activation of another node,
in contrast with previous approaches, which consider only positive risk
increments. We evaluate the performance of our network inference algorithms on
large synthetic and real cascade datasets, and show that our models are able to
predict the length and duration of cascades in real data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3625</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3625</id><created>2013-05-15</created><authors><author><keyname>Gjerden</keyname><forenames>Knut Skogstrand</forenames></author></authors><title>Making the case of GPUs in courses on computational physics</title><categories>physics.comp-ph cs.MS physics.ed-ph</categories><comments>11 pages, 2 figures</comments><msc-class>82-01, 82-08, 65Z05, 97Q99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most relatively modern desktop or even laptop computers contain a graphics
card useful for more than showing colors on a screen. In this paper, we make a
case for why you should learn enough about GPU (graphics processing unit)
computing to use as an accelerator or even replacement to your CPU code. We
include an example of our own as a case study to show what can be realistically
expected.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3633</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3633</id><created>2013-05-15</created><updated>2013-06-17</updated><authors><author><keyname>Pourhomayoun</keyname><forenames>Mohammad</forenames></author><author><keyname>Dugan</keyname><forenames>Peter</forenames></author><author><keyname>Popescu</keyname><forenames>Marian</forenames></author><author><keyname>Risch</keyname><forenames>Denise</forenames></author><author><keyname>Lewis</keyname><forenames>Hal</forenames></author><author><keyname>Clark</keyname><forenames>Christopher</forenames></author></authors><title>Classification for Big Dataset of Bioacoustic Signals Based on Human
  Scoring System and Artificial Neural Network</title><categories>cs.CV</categories><comments>To be Submitted to &quot;ICML 2013 Workshop on Machine Learning for
  Bioacoustics&quot;, 6 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a method to improve sound classification
performance by combining signal features, derived from the time-frequency
spectrogram, with human perception. The method presented herein exploits an
artificial neural network (ANN) and learns the signal features based on the
human perception knowledge. The proposed method is applied to a large acoustic
dataset containing 24 months of nearly continuous recordings. The results show
a significant improvement in performance of the detection-classification
system; yielding as much as 20% improvement in true positive rate for a given
false positive rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3635</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3635</id><created>2013-05-15</created><updated>2013-06-17</updated><authors><author><keyname>Pourhomayoun</keyname><forenames>Mohammad</forenames></author><author><keyname>Dugan</keyname><forenames>Peter</forenames></author><author><keyname>Popescu</keyname><forenames>Marian</forenames></author><author><keyname>Clark</keyname><forenames>Christopher</forenames></author></authors><title>Bioacoustic Signal Classification Based on Continuous Region Processing,
  Grid Masking and Artificial Neural Network</title><categories>cs.CV</categories><comments>To be Submitted to &quot;ICML 2013 Workshop on Machine Learning for
  Bioacoustics&quot;, 6 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop a novel method based on machine-learning and image
processing to identify North Atlantic right whale (NARW) up-calls in the
presence of high levels of ambient and interfering noise. We apply a continuous
region algorithm on the spectrogram to extract the regions of interest, and
then use grid masking techniques to generate a small feature set that is then
used in an artificial neural network classifier to identify the NARW up-calls.
It is shown that the proposed technique is effective in detecting and capturing
even very faint up-calls, in the presence of ambient and interfering noises.
The method is evaluated on a dataset recorded in Massachusetts Bay, United
States. The dataset includes 20000 sound clips for training, and 10000 sound
clips for testing. The results show that the proposed technique can achieve an
error rate of less than FPR = 4.5% for a 90% true positive rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3639</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3639</id><created>2013-05-15</created><authors><author><keyname>Hellander</keyname><forenames>Andreas</forenames></author><author><keyname>Lawson</keyname><forenames>Michael</forenames></author><author><keyname>Drawert</keyname><forenames>Brian</forenames></author><author><keyname>Petzold</keyname><forenames>Linda</forenames></author></authors><title>Local error estimates for adaptive simulation of the Reaction-Diffusion
  Master Equation via operator splitting</title><categories>cs.NA math.NA</categories><doi>10.1016/j.jcp.2014.02.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The efficiency of exact simulation methods for the reaction-diffusion master
equation (RDME) is severely limited by the large number of diffusion events if
the mesh is fine or if diffusion constants are large. Furthermore, inherent
properties of exact kinetic-Monte Carlo simulation methods limit the efficiency
of parallel implementations. Several approximate and hybrid methods have
appeared that enable more efficient simulation of the RDME. A common feature to
most of them is that they rely on splitting the system into its reaction and
diffusion parts and updating them sequentially over a discrete timestep. This
use of operator splitting enables more efficient simulation but it comes at the
price of a temporal discretization error that depends on the size of the
timestep. So far, existing methods have not attempted to estimate or control
this error in a systematic manner. This makes the solvers hard to use for
practitioners since they must guess an appropriate timestep. It also makes the
solvers potentially less efficient than if the timesteps are adapted to control
the error. Here, we derive estimates of the local error and propose a strategy
to adaptively select the timestep when the RDME is simulated via a first order
operator splitting. While the strategy is general and applicable to a wide
range of approximate and hybrid methods, we exemplify it here by extending a
previously published approximate method, the Diffusive Finite-State Projection
(DFSP) method, to incorporate temporal adaptivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3668</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3668</id><created>2013-05-15</created><authors><author><keyname>Shakarian</keyname><forenames>Paulo</forenames></author><author><keyname>Roos</keyname><forenames>Patrick</forenames></author><author><keyname>Callahan</keyname><forenames>Devon</forenames></author><author><keyname>Kirk</keyname><forenames>Cory</forenames></author></authors><title>Mining for Geographically Disperse Communities in Social Networks by
  Leveraging Distance Modularity</title><categories>cs.SI physics.soc-ph</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Social networks where the actors occupy geospatial locations are prevalent in
military, intelligence, and policing operations such as counter-terrorism,
counter-insurgency, and combating organized crime. These networks are often
derived from a variety of intelligence sources. The discovery of communities
that are geographically disperse stems from the requirement to identify
higher-level organizational structures, such as a logistics group that provides
support to various geographically disperse terrorist cells. We apply a variant
of Newman-Girvan modularity to this problem known as distance modularity. To
address the problem of finding geographically disperse communities, we modify
the well-known Louvain algorithm to find partitions of networks that provide
near-optimal solutions to this quantity. We apply this algorithm to numerous
samples from two real-world social networks and a terrorism network data set
whose nodes have associated geospatial locations. Our experiments show this to
be an effective approach and highlight various practical considerations when
applying the algorithm to distance modularity maximization. Several military,
intelligence, and law-enforcement organizations are working with us to further
test and field software for this emerging application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3671</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3671</id><created>2013-05-15</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Sparse Adaptive Dirichlet-Multinomial-like Processes</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>32 LaTeX pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online estimation and modelling of i.i.d. data for short sequences over large
or complex &quot;alphabets&quot; is a ubiquitous (sub)problem in machine learning,
information theory, data compression, statistical language processing, and
document analysis. The Dirichlet-Multinomial distribution (also called Polya
urn scheme) and extensions thereof are widely applied for online i.i.d.
estimation. Good a-priori choices for the parameters in this regime are
difficult to obtain though. I derive an optimal adaptive choice for the main
parameter via tight, data-dependent redundancy bounds for a related model. The
1-line recommendation is to set the 'total mass' = 'precision' =
'concentration' parameter to m/2ln[(n+1)/m], where n is the (past) sample size
and m the number of different symbols observed (so far). The resulting
estimator (i) is simple, (ii) online, (iii) fast, (iv) performs well for all m,
small, middle and large, (v) is independent of the base alphabet size, (vi)
non-occurring symbols induce no redundancy, (vii) the constant sequence has
constant redundancy, (viii) symbols that appear only finitely often have
bounded/constant contribution to the redundancy, (ix) is competitive with
(slow) Bayesian mixing over all sub-alphabets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3688</identifier>
 <datestamp>2013-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3688</id><created>2013-05-16</created><updated>2013-08-06</updated><authors><author><keyname>Gao</keyname><forenames>Jianhang</forenames></author><author><keyname>Zhao</keyname><forenames>Qing</forenames></author><author><keyname>Swami</keyname><forenames>Ananthram</forenames></author></authors><title>The Thinnest Path Problem</title><categories>cs.NI cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We formulate and study the thinnest path problem in wireless ad hoc networks.
The objective is to find a path from a source to its destination that results
in the minimum number of nodes overhearing the message by a judicious choice of
relaying nodes and their corresponding transmission power. We adopt a directed
hypergraph model of the problem and establish the NP-completeness of the
problem in 2-D networks. We then develop two polynomial-time approximation
algorithms that offer $\sqrt{\frac{n}{2}}$ and $\frac{n}{2\sqrt{n-1}}$
approximation ratios for general directed hypergraphs (which can model
non-isomorphic signal propagation in space) and constant approximation ratios
for ring hypergraphs (which result from isomorphic signal propagation). We also
consider the thinnest path problem in 1-D networks and 1-D networks embedded in
2-D field of eavesdroppers with arbitrary unknown locations (the so-called
1.5-D networks). We propose a linear-complexity algorithm based on nested
backward induction that obtains the optimal solution to both 1-D and 1.5-D
networks. This algorithm does not require the knowledge of eavesdropper
locations and achieves the best performance offered by any algorithm that
assumes complete location information of the eavesdroppers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3694</identifier>
 <datestamp>2014-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3694</id><created>2013-05-16</created><updated>2014-01-07</updated><authors><author><keyname>Wang</keyname><forenames>He</forenames></author><author><keyname>Zhou</keyname><forenames>Xiangyun</forenames></author><author><keyname>Reed</keyname><forenames>Mark C.</forenames></author></authors><title>Coverage and Throughput Analysis with a Non-Uniform Small Cell
  Deployment</title><categories>cs.IT cs.NI math.IT</categories><comments>12 pages, 7 figures, to be published in IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Small cell network (SCN) offers, for the first time, a low-cost and scalable
mechanism to meet the forecast data-traffic demand. In this paper, we propose a
non-uniform SCN deployment scheme. The small cell base stations (BSs) in this
scheme will not be utilized in the region within a prescribed distance away
from any macrocell BSs, defined as the inner region. Based upon the analytical
framework provided in this work, the downlink coverage and single user
throughput are precisely characterized. Provided that the inner region size is
appropriately chosen, we find that the proposed non-uniform SCN deployment
scheme can maintain the same level of cellular coverage performance even with
50% less small cell BSs used than the uniform SCN deployment, which is commonly
considered in the literature. Furthermore, both the coverage and the single
user throughput performance will significantly benefit from the proposed
scheme, if its average small cell density is kept identical to the uniform SCN
deployment. This work demonstrates the benefits obtained from a simple
non-uniform SCN deployment, thus highlighting the importance of deploying small
cells selectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3699</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3699</id><created>2013-05-16</created><authors><author><keyname>Chauvet</keyname><forenames>Jean-Marie</forenames></author><author><keyname>Mah&#xe9;</keyname><forenames>Eric</forenames></author></authors><title>Secrets from the GPU</title><categories>cs.CR</categories><comments>10 pages, 2 figures</comments><acm-class>E.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acceleration of cryptographic applications on massively parallel computing
platforms, such as Graphics Processing Units (GPUs), becomes a real challenge
as their decreasing cost and mass production makes practical implementations
attractive. We propose a layered trusted architecture integrating random bits
generation and parallelized RSA cryptographic computations on such platforms.
The GPU-resident, three-tier, MR architecture consists of a RBG, using the GPU
as a deep entropy pool; a bignum modular arithmetic library using the Residue
Number System; and GPU APIs for RSA key generation, encryption and decryption.
Evaluation results of an experimental OpenCL implementation show a 32-40 GB/s
throughput of random integers, and encryptions with up to 16,128-bit long
exponents on a commercial mid-range GPUs. This suggests an ubiquitous solution
for autonomous trusted architectures combining low cost and high throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3700</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3700</id><created>2013-05-16</created><updated>2013-08-12</updated><authors><author><keyname>Wu</keyname><forenames>Baofeng</forenames></author><author><keyname>Zheng</keyname><forenames>Jia</forenames></author><author><keyname>Liu</keyname><forenames>Zhuojun</forenames></author></authors><title>New classes of quadratic bent functions in polynomial forms</title><categories>cs.CR math.CO</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new construction of quadratic bent functions in
polynomial forms. Right Euclid algorithm in skew-polynomial rings over finite
fields of characteristic 2 is applied in the proof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3706</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3706</id><created>2013-05-16</created><updated>2016-02-10</updated><authors><author><keyname>Thakor</keyname><forenames>Satyajit</forenames></author><author><keyname>Grant</keyname><forenames>Alex</forenames></author><author><keyname>Chan</keyname><forenames>Terence</forenames></author></authors><title>Cut-Set Bounds on Network Information Flow</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Explicit characterization of the capacity region of communication networks is
a long standing problem. While it is known that network coding can outperform
routing and replication, the set of feasible rates is not known in general.
Characterizing the network coding capacity region requires determination of the
set of all entropic vectors. Furthermore, computing the explicitly known linear
programming bound is infeasible in practice due to an exponential growth in
complexity as a function of network size. This paper focuses on the fundamental
problems of characterization and computation of outer bounds for networks with
correlated sources. Starting from the known local functional dependencies
induced by the communications network, we introduce the notion of irreducible
sets, which characterize implied functional dependencies. We provide recursions
for computation of all maximal irreducible sets. These sets act as
information-theoretic bottlenecks, and provide an easily computable outer
bound. We extend the notion of irreducible sets (and resulting outer bound) for
networks with independent sources. We compare our bounds with existing bounds
in the literature. We find that our new bounds are the best among the known
graph theoretic bounds for networks with correlated sources and for networks
with independent sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3733</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3733</id><created>2013-05-16</created><authors><author><keyname>Hachem</keyname><forenames>Jad</forenames></author><author><keyname>Wang</keyname><forenames>I-Hsiang</forenames></author><author><keyname>Fragouli</keyname><forenames>Christina</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas</forenames></author></authors><title>Coding with Encoding Uncertainty</title><categories>cs.IT math.IT</categories><comments>12 pages; a shorter version of this work will appear in the
  proceedings of ISIT 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the channel coding problem when errors and uncertainty occur in the
encoding process. For simplicity we assume the channel between the encoder and
the decoder is perfect. Focusing on linear block codes, we model the encoding
uncertainty as erasures on the edges in the factor graph of the encoder
generator matrix. We first take a worst-case approach and find the maximum
tolerable number of erasures for perfect error correction. Next, we take a
probabilistic approach and derive a sufficient condition on the rate of a set
of codes, such that decoding error probability vanishes as blocklength tends to
infinity. In both scenarios, due to the inherent asymmetry of the problem, we
derive the results from first principles, which indicates that robustness to
encoding errors requires new properties of codes different from classical
properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3735</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3735</id><created>2013-05-16</created><authors><author><keyname>Hartung</keyname><forenames>Sepp</forenames></author><author><keyname>Komusiewicz</keyname><forenames>Christian</forenames></author><author><keyname>Nichterlein</keyname><forenames>Andr&#xe9;</forenames></author><author><keyname>Such&#xfd;</keyname><forenames>Ondrej</forenames></author></authors><title>On Structural Parameterizations for the 2-Club Problem</title><categories>cs.CC cs.DS math.CO</categories><comments>An extended abstract of this paper appeared in Proceedings of the
  39th International Conference on Current Trends in Theory and Practice of
  Computer Science (SOFSEM'13), Jan. 2013, volume 7741 of LNCS, pages 233-243,
  Springer, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The NP-hard 2-Club problem is, given an undirected graph G=(V,E) and l\in N,
to decide whether there is a vertex set S\subseteq V of size at least l such
that the induced subgraph G[S] has diameter at most two. We make progress
towards a systematic classification of the complexity of 2-Club with respect to
a hierarchy of prominent structural graph parameters. First, we present the
following tight NP-hardness results: 2-Club is NP-hard on graphs that become
bipartite by deleting one vertex, on graphs that can be covered by three
cliques, and on graphs with domination number two and diameter three. Then, we
consider the parameter h-index of the input graph. This parameter is motivated
by real-world instances and the fact that 2-Club is fixed-parameter tractable
with respect to the larger parameter maximum degree. We present an algorithm
that solves 2-Club in |V|^{f(k)} time with k being the h-index. By showing
W[1]-hardness for this parameter, we provide evidence that the above algorithm
cannot be improved to a fixed-parameter algorithm. Furthermore, the reduction
used for this hardness result can be modified to show that 2-Club is NP-hard if
the input graph has constant degeneracy. Finally, we show that 2-Club is
fixed-parameter tractable with respect to distance to cographs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3753</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3753</id><created>2013-05-16</created><authors><author><keyname>Sengupta</keyname><forenames>Madhumita</forenames></author><author><keyname>Mandal</keyname><forenames>J. K.</forenames></author></authors><title>Wavelet Based Authentication/Secret Transmission Through Image
  Resizing(WASTIR)</title><categories>cs.CR</categories><comments>10 Page Journal Paper, Sipij</comments><report-no>4213sipij05</report-no><journal-ref>Signal &amp; Image Processing : An International Journal (SIPIJ), ISSN
  : 0976 - 710X (Online) ; 2229 - 3922 (print), 2013</journal-ref><doi>10.5121/sipij.2013.4205</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper is aimed for a wavelet based steganographic or watermarking
technique in frequency domain termed as WASTIR for secret message or image
transmission or image authentication. Number system conversion of the secret
image by changing radix form decimal to quaternary is the pre-processing of the
technique. Cover image scaling through inverse discrete wavelet transformation
with false Horizontal and vertical coefficients are embedded with quaternary
digits through hash function and a secret key. Experimental results are
computed and compared with the existing steganographic techniques like WTSIC,
Yuancheng Lis Method and Region-Based in terms of Mean Square Error (MSE), Peak
Signal to Noise Ratio (PSNR) and Image Fidelity (IF) which show better
performances in WASTIR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3758</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3758</id><created>2013-05-16</created><authors><author><keyname>Warrender</keyname><forenames>Jennifer D.</forenames></author><author><keyname>Lord</keyname><forenames>Phillip</forenames></author></authors><title>The Karyotype Ontology: a computational representation for human
  cytogenetic patterns</title><categories>cs.CE q-bio.GN</categories><comments>4 pages, 1 figure, to be submitted to Bio-Ontologies 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The karyotype ontology describes the human chromosome complement as
determined cytogenetically, and is designed as an initial step toward the goal
of replacing the current system which is based on semantically meaningful
strings. This ontology uses a novel, semi-programmatic methodology based around
the tawny library to construct many classes rapidly. Here, we describe our use
case, methodology and the event-based approach that we use to represent
karyotypes.
  The ontology is available at http://www.purl.org/ontolink/karyotype/. The
clojure code is available at http://code.google.com/p/karyotype-clj/.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3767</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3767</id><created>2013-05-16</created><authors><author><keyname>Yu</keyname><forenames>Changtao</forenames></author></authors><title>On dually flat $(\alpha,\beta)$-metrics</title><categories>math.DG cs.IT math.IT</categories><comments>16pages, no figure, any comments are welcome</comments><msc-class>53B40, 53C60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, I will show how to use $\beta$-deformations to deal with dual
flatness of $(\alpha,\beta)$-metrics. It is a natural continuation of the
research on dually flat Randers metrics(see arxiv:1209.1150).
$\beta$-deformations is a new method in Riemann-Finsler geometry, it is
introduced by the author(see arxiv:1209.0845).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3769</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3769</id><created>2013-05-16</created><updated>2013-06-04</updated><authors><author><keyname>Li</keyname><forenames>Fada</forenames></author><author><keyname>Bao</keyname><forenames>Wansu</forenames></author><author><keyname>Fu</keyname><forenames>Xiangqun</forenames></author><author><keyname>Zhang</keyname><forenames>Yuchao</forenames></author><author><keyname>Li</keyname><forenames>Tan</forenames></author></authors><title>A reduction from LWE problem to dihedral coset problem</title><categories>quant-ph cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning with Errors (LWE) problems are the foundations for numerous
applications in lattice-based cryptography and are provably as hard as
approximate lattice problems in the worst case. Here we present a reduction
from LWE problem to dihedral coset problem(DCP). We present a quantum algorithm
to generate the input of the two point problem which hides the solution of LWE.
We then give a new reduction from two point problem to dihedral coset problem
on D_{{{({n^{13}})}^{n\log n}}}. Our reduction implicate that any algorithm
solves DCP in subexponential time would lead a quantum algorithm for LWE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3774</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3774</id><created>2013-05-16</created><authors><author><keyname>Bouman</keyname><forenames>Niek</forenames></author><author><keyname>Borst</keyname><forenames>Sem</forenames></author><author><keyname>van Leeuwaarden</keyname><forenames>Johan</forenames></author></authors><title>Delay Performance and Mixing Times in Random-Access Networks</title><categories>cs.NI math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the achievable delay performance in wireless random-access
networks. While relatively simple and inherently distributed in nature,
suitably designed queue-based random-access schemes provide the striking
capability to match the optimal throughput performance of centralized
scheduling mechanisms in a wide range of scenarios. The specific type of
activation rules for which throughput optimality has been established, may
however yield excessive queues and delays.
  Motivated by that issue, we examine whether the poor delay performance is
inherent to the basic operation of these schemes, or caused by the specific
kind of activation rules. We derive delay lower bounds for queue-based
activation rules, which offer fundamental insight in the cause of the excessive
delays. For fixed activation rates we obtain lower bounds indicating that
delays and mixing times can grow dramatically with the load in certain
topologies as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3778</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3778</id><created>2013-05-16</created><authors><author><keyname>Bereyhi</keyname><forenames>Ali</forenames></author><author><keyname>Bahrami</keyname><forenames>Mohsen</forenames></author><author><keyname>Mirmohseni</keyname><forenames>Mahtab</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>Empirical Coordination in a Triangular Multiterminal Network</title><categories>cs.IT math.IT</categories><comments>Accepted in ISIT 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the problem of the empirical coordination in a
triangular multiterminal network. A triangular multiterminal network consists
of three terminals where two terminals observe two external i.i.d correlated
sequences. The third terminal wishes to generate a sequence with desired
empirical joint distribution. For this problem, we derive inner and outer
bounds on the empirical coordination capacity region. It is shown that the
capacity region of the degraded source network and the inner and outer bounds
on the capacity region of the cascade multiterminal network can be directly
obtained from our inner and outer bounds. For a cipher system, we establish key
distribution over a network with a reliable terminal, using the results of the
empirical coordination. As another example, the problem of rate distortion in
the triangular multiterminal network is investigated in which a distributed
doubly symmetric binary source is available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3794</identifier>
 <datestamp>2013-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3794</id><created>2013-05-16</created><updated>2013-05-22</updated><authors><author><keyname>Kronberger</keyname><forenames>Gabriel</forenames></author><author><keyname>Kommenda</keyname><forenames>Michael</forenames></author></authors><title>Evolution of Covariance Functions for Gaussian Process Regression using
  Genetic Programming</title><categories>cs.NE cs.LG stat.ML</categories><comments>Presented at the Workshop &quot;Theory and Applications of Metaheuristic
  Algorithms&quot;, EUROCAST2013. To appear in selected papers of Computer Aided
  Systems Theory - EUROCAST 2013; Volumes Editors: Roberto Moreno-D\'iaz, Franz
  R. Pichler, Alexis Quesada-Arencibia; LNCS Springer</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this contribution we describe an approach to evolve composite covariance
functions for Gaussian processes using genetic programming. A critical aspect
of Gaussian processes and similar kernel-based models such as SVM is, that the
covariance function should be adapted to the modeled data. Frequently, the
squared exponential covariance function is used as a default. However, this can
lead to a misspecified model, which does not fit the data well. In the proposed
approach we use a grammar for the composition of covariance functions and
genetic programming to search over the space of sentences that can be derived
from the grammar. We tested the proposed approach on synthetic data from
two-dimensional test functions, and on the Mauna Loa CO2 time series. The
results show, that our approach is feasible, finding covariance functions that
perform much better than a default covariance function. For the CO2 data set a
composite covariance function is found, that matches the performance of a
hand-tuned covariance function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3797</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3797</id><created>2013-05-16</created><authors><author><keyname>Mulla</keyname><forenames>Ameer K.</forenames></author><author><keyname>Kalaimani</keyname><forenames>Rachel K.</forenames></author><author><keyname>Chakraborty</keyname><forenames>Debraj</forenames></author><author><keyname>Belur</keyname><forenames>Madhu N.</forenames></author></authors><title>Formation control with pole placement for multi-agent systems</title><categories>math.OC cs.MA cs.SY</categories><comments>7 pages, 12 figures. Submitted to the CDC 2013 (Italy)</comments><msc-class>05C50, 93B55, 94C15</msc-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The problem of distributed controller synthesis for formation control of
multi-agent systems is considered. The agents (single integrators) communicate
over a communication graph and a decentralized linear feedback structure is
assumed. One of the agents is designated as the leader. If the communication
graph contains a directed spanning tree with the leader node as the root, then
it is possible to place the poles of the ensemble system with purely local
feedback controller gains. Given a desired formation, first one of the poles is
placed at the origin. Then it is shown that the inter-agent weights can be
independently adjusted to assign an eigenvector corresponding to the formation
positions, to the zero eigenvalue. Then, only the leader input is enough to
bring the agents to the desired formation and keep it there with no further
inputs. Moreover, given a formation, the computation of the inter-agent weights
that encode the formation information, can be calculated in a decentralized
fashion using only local information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3803</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3803</id><created>2013-05-16</created><authors><author><keyname>Mansour</keyname><forenames>Hassan</forenames></author><author><keyname>Yilmaz</keyname><forenames>Ozgur</forenames></author></authors><title>A fast randomized Kaczmarz algorithm for sparse solutions of consistent
  linear systems</title><categories>cs.NA cs.IT math.IT math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Kaczmarz algorithm is a popular solver for overdetermined linear systems
due to its simplicity and speed. In this paper, we propose a modification that
speeds up the convergence of the randomized Kaczmarz algorithm for systems of
linear equations with sparse solutions. The speedup is achieved by projecting
every iterate onto a weighted row of the linear system while maintaining the
random row selection criteria of Strohmer and Vershynin. The weights are chosen
to attenuate the contribution of row elements that lie outside of the estimated
support of the sparse solution. While the Kaczmarz algorithm and its variants
can only find solutions to overdetermined linear systems, our algorithm
surprisingly succeeds in finding sparse solutions to underdetermined linear
systems as well. We present empirical studies which demonstrate the
acceleration in convergence to the sparse solution using this modified approach
in the overdetermined case. We also demonstrate the sparse recovery
capabilities of our approach in the underdetermined case and compare the
performance with that of $\ell_1$ minimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3814</identifier>
 <datestamp>2013-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3814</id><created>2013-05-16</created><updated>2013-07-24</updated><authors><author><keyname>Hadian</keyname><forenames>Ali</forenames></author><author><keyname>Minaei-Bidgoli</keyname><forenames>Behrouz</forenames></author></authors><title>Multi-View Learning for Web Spam Detection</title><categories>cs.IR cs.LG</categories><comments>I want to upload a major revision in a couple of months</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spam pages are designed to maliciously appear among the top search results by
excessive usage of popular terms. Therefore, spam pages should be removed using
an effective and efficient spam detection system. Previous methods for web spam
classification used several features from various information sources (page
contents, web graph, access logs, etc.) to detect web spam. In this paper, we
follow page-level classification approach to build fast and scalable spam
filters. We show that each web page can be classified with satisfiable accuracy
using only its own HTML content. In order to design a multi-view classification
system, we used state-of-the-art spam classification methods with distinct
feature sets (views) as the base classifiers. Then, a fusion model is learned
to combine the output of the base classifiers and make final prediction.
Results show that multi-view learning significantly improves the classification
performance, namely AUC by 22%, while providing linear speedup for parallel
execution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3827</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3827</id><created>2013-05-16</created><authors><author><keyname>Jafargholi</keyname><forenames>Zahra</forenames></author><author><keyname>Viola</keyname><forenames>Emanuele</forenames></author></authors><title>3SUM, 3XOR, Triangles</title><categories>cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that if one can solve 3SUM on a set of size n in time n^{1+\e} then
one can list t triangles in a graph with m edges in time
O(m^{1+\e}t^{1/3-\e/3}). This is a reversal of Patrascu's reduction from 3SUM
to listing triangles (STOC '10). Our result builds on and extends works by the
Paghs (PODS '06) and by Vassilevska and Williams (FOCS '10). We make our
reductions deterministic using tools from pseudorandomness.
  We then re-execute both Patrascu's reduction and our reversal for the variant
3XOR of 3SUM where integer summation is replaced by bit-wise xor. As a
corollary we obtain that if 3XOR is solvable in linear time but 3SUM requires
quadratic randomized time, or vice versa, then the randomized time complexity
of listing m triangles in a graph with $m$ edges is m^{4/3} up to a factor
m^\alpha for any \alpha &gt; 0.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3828</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3828</id><created>2013-05-16</created><updated>2015-04-02</updated><authors><author><keyname>De Stefani</keyname><forenames>Lorenzo</forenames></author><author><keyname>Silvestri</keyname><forenames>Francesco</forenames></author></authors><title>Exploiting non-constant safe memory in resilient algorithms and data
  structures</title><categories>cs.DS</categories><comments>To appear in Theoretical Computer Science, 2015</comments><msc-class>68W40, 68P05, 68M15</msc-class><acm-class>F.2.2; I.1.2; E.1; F.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the Faulty RAM model by Finocchi and Italiano (2008) by adding a
safe memory of arbitrary size $S$, and we then derive tradeoffs between the
performance of resilient algorithmic techniques and the size of the safe
memory. Let $\delta$ and $\alpha$ denote, respectively, the maximum amount of
faults which can happen during the execution of an algorithm and the actual
number of occurred faults, with $\alpha \leq \delta$. We propose a resilient
algorithm for sorting $n$ entries which requires $O\left(n\log n+\alpha
(\delta/S + \log S)\right)$ time and uses $\Theta(S)$ safe memory words. Our
algorithm outperforms previous resilient sorting algorithms which do not
exploit the available safe memory and require $O\left(n\log n+
\alpha\delta\right)$ time. Finally, we exploit our sorting algorithm for
deriving a resilient priority queue. Our implementation uses $\Theta(S)$ safe
memory words and $\Theta(n)$ faulty memory words for storing $n$ keys, and
requires $O\left(\log n + \delta/S\right)$ amortized time for each insert and
deletemin operation. Our resilient priority queue improves the $O\left(\log n +
\delta\right)$ amortized time required by the state of the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3835</identifier>
 <datestamp>2015-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3835</id><created>2013-05-16</created><updated>2014-04-24</updated><authors><author><keyname>Rijke</keyname><forenames>Egbert</forenames></author><author><keyname>Spitters</keyname><forenames>Bas</forenames></author></authors><title>Sets in homotopy type theory</title><categories>math.CT cs.LO</categories><msc-class>03-XX, 03B15, 18B05, 18G30</msc-class><acm-class>F.4.1</acm-class><journal-ref>Special issue of Mathematical Structures in Computer Science: From
  type theory and homotopy theory to univalent foundations. 2014</journal-ref><doi>10.1017/S0960129514000553</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Homotopy Type Theory may be seen as an internal language for the
$\infty$-category of weak $\infty$-groupoids which in particular models the
univalence axiom. Voevodsky proposes this language for weak $\infty$-groupoids
as a new foundation for mathematics called the Univalent Foundations of
Mathematics. It includes the sets as weak $\infty$-groupoids with contractible
connected components, and thereby it includes (much of) the traditional set
theoretical foundations as a special case. We thus wonder whether those
`discrete' groupoids do in fact form a (predicative) topos. More generally,
homotopy type theory is conjectured to be the internal language of `elementary'
$\infty$-toposes. We prove that sets in homotopy type theory form a $\Pi
W$-pretopos. This is similar to the fact that the $0$-truncation of an
$\infty$-topos is a topos. We show that both a subobject classifier and a
$0$-object classifier are available for the type theoretical universe of sets.
However, both of these are large and moreover, the $0$-object classifier for
sets is a function between $1$-types (i.e. groupoids) rather than between sets.
Assuming an impredicative propositional resizing rule we may render the
subobject classifier small and then we actually obtain a topos of sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3842</identifier>
 <datestamp>2015-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3842</id><created>2013-05-16</created><authors><author><keyname>Ciampaglia</keyname><forenames>Giovanni Luca</forenames></author></authors><title>A framework for the calibration of social simulation models</title><categories>physics.soc-ph cs.SI</categories><comments>31 pages, 7 figures, accepted on Adv. Compl. Sys</comments><doi>10.1142/S0219525913500306</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Simulation with agent-based models is increasingly used in the study of
complex socio-technical systems and in social simulation in general. This
paradigm offers a number of attractive features, namely the possibility of
modeling emergent phenomena within large populations. As a consequence, often
the quantity in need of calibration may be a distribution over the population
whose relation with the parameters of the model is analytically intractable.
Nevertheless, we can simulate. In this paper we present a simulation-based
framework for the calibration of agent-based models with distributional output
based on indirect inference. We illustrate our method step by step on a model
of norm emergence in an online community of peer production, using data from
three large Wikipedia communities. Model fit and diagnostics are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3849</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3849</id><created>2013-05-16</created><authors><author><keyname>Grolleau</keyname><forenames>Emmanuel</forenames><affiliation>LIAS-ISAE/ENSMA</affiliation></author><author><keyname>Goossens</keyname><forenames>Jo&#xeb;l</forenames><affiliation>ULB</affiliation></author><author><keyname>Cucu-Grosjean</keyname><forenames>Liliana</forenames><affiliation>INRIA</affiliation></author></authors><title>On the periodic behavior of real-time schedulers on identical
  multiprocessor platforms</title><categories>cs.OS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is proposing a general periodicity result concerning any
deterministic and memoryless scheduling algorithm (including
non-work-conserving algorithms), for any context, on identical multiprocessor
platforms. By context we mean the hardware architecture (uniprocessor,
multicore), as well as task constraints like critical sections, precedence
constraints, self-suspension, etc. Since the result is based only on the
releases and deadlines, it is independent from any other parameter. Note that
we do not claim that the given interval is minimal, but it is an upper bound
for any cycle of any feasible schedule provided by any deterministic and
memoryless scheduler.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3853</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3853</id><created>2013-05-16</created><updated>2013-06-13</updated><authors><author><keyname>Ellis-Braithwaite</keyname><forenames>Richard</forenames></author></authors><title>Analysing the Assumed Benefits of Software Requirements</title><categories>cs.SE</categories><comments>19th International Working Conference on Requirements Engineering:
  Foundation for Software Quality. Proceedings of the Workshops CreaRE, IWSPM,
  RePriCo and the Doctoral Symposium. (2013)</comments><acm-class>D.2.1</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Often during the requirements engineering (RE) process, the value of a
requirement is assessed, e.g., in requirement prioritisation, release planning,
and trade-off analysis. In order to support these activities, this research
evaluates Goal Oriented Requirements Engineering (GORE) methods for the
description of a requirement's value. Specifically, we investigate the
goal-to-goal contribution relationship for its ability to demonstrate the value
of a requirement, and propose that it is enriched with concepts such as
correlation, confidence, and utility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3865</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3865</id><created>2013-05-16</created><authors><author><keyname>Miritello</keyname><forenames>Giovanna</forenames></author><author><keyname>Lara</keyname><forenames>Rub&#xe9;n</forenames></author><author><keyname>Moro</keyname><forenames>Esteban</forenames></author></authors><title>Time allocation in social networks: correlation between social structure
  and human communication dynamics</title><categories>physics.soc-ph cs.SI</categories><comments>16 pages, 7 figures, Chapter of the book &quot;Temporal Networks&quot;,
  Springer, 2013. Series: Understanding Complex Systems. Holme, Petter;
  Saramaki, Jari (Eds.)</comments><doi>10.1007/978-3-642-36461-7_9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent research has shown the deep impact of the dynamics of human
interactions (or temporal social networks) on the spreading of information,
opinion formation, etc. In general, the bursty nature of human interactions
lowers the interaction between people to the extent that both the speed and
reach of information diffusion are diminished. Using a large database of 20
million users of mobile phone calls we show evidence this effect is not
homogeneous in the social network but in fact, there is a large correlation
between this effect and the social topological structure around a given
individual. In particular, we show that social relations of hubs in a network
are relatively weaker from the dynamical point than those that are poorer
connected in the information diffusion process. Our results show the importance
of the temporal patterns of communication when analyzing and modeling dynamical
process on social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3869</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3869</id><created>2013-05-16</created><authors><author><keyname>Blasiak</keyname><forenames>Anna</forenames></author></authors><title>Multicut Lower Bounds via Network Coding</title><categories>math.CO cs.DM cs.DS cs.IT math.IT</categories><comments>6 pages, Netcod 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new technique to certify lower bounds on the multicut size
using network coding. In directed networks the network coding rate is not a
lower bound on the multicut, but we identify a class of networks on which the
rate is equal to the size of the minimum multicut and show this class is closed
under the strong graph product. We then show that the famous construction of
Saks et al. that gives a $\Theta(k)$ gap between the multicut and the
multicommodity flow rate is contained in this class. This allows us to apply
our result to strengthen their multicut lower bound, determine the exact value
of the minimum multicut, and give an optimal network coding solution with rate
matching the multicut.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3876</identifier>
 <datestamp>2014-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3876</id><created>2013-05-16</created><updated>2014-03-20</updated><authors><author><keyname>Cici</keyname><forenames>Blerim</forenames></author><author><keyname>Markopoulou</keyname><forenames>Athina</forenames></author><author><keyname>Fr&#xed;as-Mart&#xed;nez</keyname><forenames>Enrique</forenames></author><author><keyname>Laoutaris</keyname><forenames>Nikolaos</forenames></author></authors><title>Assessing the Potential of Ride-Sharing Using Mobile and Social Data</title><categories>cs.CY cs.SI physics.soc-ph</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ride-sharing on the daily home-work-home commute can help individuals save on
gasoline and other car-related costs, while at the same time it can reduce
traffic and pollution. This paper assesses the potential of ride-sharing for
reducing traffic in a city, based on mobility data extracted from 3G Call
Description Records (CDRs, for the cities of Barcelona and Madrid) and from
Online Social Networks (Twitter, collected for the cities of New York and Los
Angeles). We first analyze these data sets to understand mobility patterns,
home and work locations, and social ties between users. We then develop an
efficient algorithm for matching users with similar mobility patterns,
considering a range of constraints. The solution provides an upper bound to the
potential reduction of cars in a city that can be achieved by ride-sharing. We
use our framework to understand the different constraints and city
characteristics on this potential benefit. For example, our study shows that
traffic in the city of Madrid can be reduced by 59% if users are willing to
share a ride with people who live and work within 1 km; if they can only accept
a pick-up and drop-off delay up to 10 minutes, this potential benefit drops to
24%; if drivers also pick up passengers along the way, this number increases to
53%. If users are willing to ride only with people they know (&quot;friends&quot; in the
CDR and OSN data sets), the potential of ride-sharing becomes negligible; if
they are willing to ride with friends of friends, the potential reduction is up
to 31%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3882</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3882</id><created>2013-05-16</created><updated>2013-05-17</updated><authors><author><keyname>Christen</keyname><forenames>Daniel</forenames></author></authors><title>Rule-Based Semantic Tagging. An Application Undergoing Dictionary
  Glosses</title><categories>cs.CL</categories><comments>12 pages, 2 Tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The project presented in this article aims to formalize criteria and
procedures in order to extract semantic information from parsed dictionary
glosses. The actual purpose of the project is the generation of a semantic
network (nearly an ontology) issued from a monolingual Italian dictionary,
through unsupervised procedures. Since the project involves rule-based Parsing,
Semantic Tagging and Word Sense Disambiguation techniques, its outcomes may
find an interest also beyond this immediate intent. The cooperation of both
syntactic and semantic features in meaning construction are investigated, and
procedures which allows a translation of syntactic dependencies in semantic
relations are discussed. The procedures that rise from this project can be
applied also to other text types than dictionary glosses, as they convert the
output of a parsing process into a semantic representation. In addition some
mechanism are sketched that may lead to a kind of procedural semantics, through
which multiple paraphrases of an given expression can be generated. Which means
that these techniques may find an application also in 'query expansion'
strategies, interesting Information Retrieval, Search Engines and Question
Answering Systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3883</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3883</id><created>2013-05-16</created><authors><author><keyname>Rawat</keyname><forenames>Sanjay</forenames></author><author><keyname>Ceara</keyname><forenames>Dumitru</forenames></author><author><keyname>Mounier</keyname><forenames>Laurent</forenames></author><author><keyname>Potet</keyname><forenames>Marie-Laure</forenames></author></authors><title>Combining Static and Dynamic Analysis for Vulnerability Detection</title><categories>cs.CR</categories><comments>There are 15 pages with 1 figure</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we present a hybrid approach for buffer overflow detection in
C code. The approach makes use of static and dynamic analysis of the
application under investigation. The static part consists in calculating taint
dependency sequences (TDS) between user controlled inputs and vulnerable
statements. This process is akin to program slice of interest to calculate
tainted data- and control-flow path which exhibits the dependence between
tainted program inputs and vulnerable statements in the code. The dynamic part
consists of executing the program along TDSs to trigger the vulnerability by
generating suitable inputs. We use genetic algorithm to generate inputs. We
propose a fitness function that approximates the program behavior (control
flow) based on the frequencies of the statements along TDSs. This runtime
aspect makes the approach faster and accurate. We provide experimental results
on the Verisec benchmark to validate our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3885</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3885</id><created>2013-05-16</created><authors><author><keyname>Prasad</keyname><forenames>Dilip K.</forenames></author></authors><title>Geometric primitive feature extraction - concepts, algorithms, and
  applications</title><categories>cs.CV cs.CG</categories><comments>333 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis presents important insights and concepts related to the topic of
the extraction of geometric primitives from the edge contours of digital
images. Three specific problems related to this topic have been studied, viz.,
polygonal approximation of digital curves, tangent estimation of digital
curves, and ellipse fitting anddetection from digital curves. For the problem
of polygonal approximation, two fundamental problems have been addressed.
First, the nature of the performance evaluation metrics in relation to the
local and global fitting characteristics has been studied. Second, an explicit
error bound of the error introduced by digitizing a continuous line segment has
been derived and used to propose a generic non-heuristic parameter independent
framework which can be used in several dominant point detection methods. For
the problem of tangent estimation for digital curves, a simple method of
tangent estimation has been proposed. It is shown that the method has a
definite upper bound of the error for conic digital curves. It has been shown
that the method performs better than almost all (seventy two) existing tangent
estimation methods for conic as well as several non-conic digital curves. For
the problem of fitting ellipses on digital curves, a geometric distance
minimization model has been considered. An unconstrained, linear,
non-iterative, and numerically stable ellipse fitting method has been proposed
and it has been shown that the proposed method has better selectivity for
elliptic digital curves (high true positive and low false positive) as compared
to several other ellipse fitting methods. For the problem of detecting ellipses
in a set of digital curves, several innovative and fast pre-processing,
grouping, and hypotheses evaluation concepts applicable for digital curves have
been proposed and combined to form an ellipse detection method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3886</identifier>
 <datestamp>2013-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3886</id><created>2013-05-16</created><updated>2013-11-26</updated><authors><author><keyname>Horstmeyer</keyname><forenames>Roarke</forenames></author><author><keyname>Judkewitz</keyname><forenames>Benjamin</forenames></author><author><keyname>Vellekoop</keyname><forenames>Ivo</forenames></author><author><keyname>Assawaworrarit</keyname><forenames>Sid</forenames></author><author><keyname>Yang</keyname><forenames>Changhuei</forenames></author></authors><title>Physical key-protected one-time pad</title><categories>physics.optics cs.CR</categories><comments>6 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an encrypted communication principle that can form a perfectly
secure link between two parties without electronically saving either of their
keys. Instead, cryptographic key bits are kept safe within the unique
mesoscopic randomness of two volumetric scattering materials. We demonstrate
how a shared set of patterned optical probes can generate 10 gigabits of
statistically verified randomness between a pair of unique 2 cubic millimeter
scattering objects. This shared randomness is used to facilitate
information-theoretically secure communication following a modified one-time
pad protocol. Benefits of volumetric physical storage over electronic memory
include the inability to probe, duplicate or selectively reset any random bits
without fundamentally altering the entire key space. Beyond the demonstrated
communication scheme, our ability to securely couple the randomness contained
within two unique physical objects may help strengthen the hardware for a large
class of cryptographic protocols, which is currently a critically weak link in
the security pipeline of our increasingly mobile communication culture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3887</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3887</id><created>2013-05-16</created><authors><author><keyname>de Lamare</keyname><forenames>Rodrigo C.</forenames></author><author><keyname>Nascimento</keyname><forenames>Vitor H.</forenames></author></authors><title>Joint Model-Order and Step-Size Adaptation using Convex Combinations of
  Adaptive Reduced-Rank Filters</title><categories>cs.IT math.IT</categories><comments>5 figures</comments><journal-ref>ISWCS 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we propose schemes for joint model-order and step-size
adaptation of reduced-rank adaptive filters. The proposed schemes employ
reduced-rank adaptive filters in parallel operating with different orders and
step sizes, which are exploited by convex combination strategies. The
reduced-rank adaptive filters used in the proposed schemes are based on a joint
and iterative decimation and interpolation (JIDF) method recently proposed. The
unique feature of the JIDF method is that it can substantially reduce the
number of coefficients for adaptation, thereby making feasible the use of
multiple reduced-rank filters in parallel. We investigate the performance of
the proposed schemes in an interference suppression application for CDMA
systems. Simulation results show that the proposed schemes can significantly
improve the performance of the existing reduced-rank adaptive filters based on
the JIDF method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3905</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3905</id><created>2013-05-16</created><updated>2014-10-10</updated><authors><author><keyname>Schieler</keyname><forenames>Curt</forenames></author><author><keyname>Cuff</keyname><forenames>Paul</forenames></author></authors><title>Rate-Distortion Theory for Secrecy Systems</title><categories>cs.IT cs.CR math.IT</categories><comments>Update version, to appear in IEEE Transactions on Information Theory</comments><journal-ref>IEEE Trans. on Inf. Theory, 60(12):7584-605, December, 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secrecy in communication systems is measured herein by the distortion that an
adversary incurs. The transmitter and receiver share secret key, which they use
to encrypt communication and ensure distortion at an adversary. A model is
considered in which an adversary not only intercepts the communication from the
transmitter to the receiver, but also potentially has side information.
Specifically, the adversary may have causal or noncausal access to a signal
that is correlated with the source sequence or the receiver's reconstruction
sequence. The main contribution is the characterization of the optimal tradeoff
among communication rate, secret key rate, distortion at the adversary, and
distortion at the legitimate receiver. It is demonstrated that causal side
information at the adversary plays a pivotal role in this tradeoff. It is also
shown that measures of secrecy based on normalized equivocation are a special
case of the framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3931</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3931</id><created>2013-05-16</created><authors><author><keyname>Akyol</keyname><forenames>Emrah</forenames></author><author><keyname>Rose</keyname><forenames>Kenneth</forenames></author><author><keyname>Basar</keyname><forenames>Tamer</forenames></author></authors><title>Gaussian Sensor Networks with Adversarial Nodes</title><categories>cs.IT cs.SY math.IT math.OC</categories><comments>5 pages, will be presented at ISIT 2013, Istanbul, Turkey</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a particular sensor network model which involves one
single Gaussian source observed by many sensors, subject to additive
independent Gaussian observation noise. Sensors communicate with the receiver
over an additive Gaussian multiple access channel. The aim of the receiver is
to reconstruct the underlying source with minimum mean squared error. The
scenario of interest here is one where some of the sensors act as adversary
(jammer): they strive to maximize distortion. We show that the ability of
transmitter sensors to secretly agree on a random event, that is
&quot;coordination&quot;, plays a key role in the analysis. Depending on the coordination
capability of sensors and the receiver, we consider two problem settings. The
first setting involves transmitters with coordination capabilities in the sense
that all transmitters can use identical realization of randomized encoding for
each transmission. In this case, the optimal strategy for the adversary sensors
also requires coordination, where they all generate the same realization of
independent and identically distributed Gaussian noise. In the second setting,
the transmitter sensors are restricted to use fixed, deterministic encoders and
this setting, which corresponds to a Stackelberg game, does not admit a
saddle-point solution. We show that the the optimal strategy for all sensors is
uncoded communications where encoding functions of adversaries and transmitters
are in opposite directions. For both settings, digital compression and
communication is strictly suboptimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3932</identifier>
 <datestamp>2013-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3932</id><created>2013-05-16</created><updated>2013-11-15</updated><authors><author><keyname>Priedhorsky</keyname><forenames>Reid</forenames><affiliation>Los Alamos National Laboratory</affiliation></author><author><keyname>Culotta</keyname><forenames>Aron</forenames><affiliation>Illinois Institute of Technology</affiliation></author><author><keyname>Del Valle</keyname><forenames>Sara Y.</forenames><affiliation>Los Alamos National Laboratory</affiliation></author></authors><title>Inferring the Origin Locations of Tweets with Quantitative Confidence</title><categories>cs.SI cs.HC cs.LG</categories><comments>14 pages, 6 figures. Version 2: Move mathematics to appendix, 2 new
  references, various other presentation improvements. Version 3: Various
  presentation improvements, accepted at ACM CSCW 2014</comments><report-no>LA-UR 13-23557</report-no><acm-class>D.2.8; H.3.5; I.2.6; I.2.7; K.4.1</acm-class><doi>10.1145/2531602.2531607</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social Internet content plays an increasingly critical role in many domains,
including public health, disaster management, and politics. However, its
utility is limited by missing geographic information; for example, fewer than
1.6% of Twitter messages (tweets) contain a geotag. We propose a scalable,
content-based approach to estimate the location of tweets using a novel yet
simple variant of gaussian mixture models. Further, because real-world
applications depend on quantified uncertainty for such estimates, we propose
novel metrics of accuracy, precision, and calibration, and we evaluate our
approach accordingly. Experiments on 13 million global, comprehensively
multi-lingual tweets show that our approach yields reliable, well-calibrated
results competitive with previous computationally intensive methods. We also
show that a relatively small number of training data are required for good
estimates (roughly 30,000 tweets) and models are quite time-invariant
(effective on tweets many weeks newer than the training set). Finally, we show
that toponyms and languages with small geographic footprint provide the most
useful location signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3934</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3934</id><created>2013-05-16</created><authors><author><keyname>Kao</keyname><forenames>David T. H.</forenames></author><author><keyname>Sabharwal</keyname><forenames>Ashutosh</forenames></author></authors><title>An Upper Bound on the Capacity of Vector Dirty Paper with Unknown Spin
  and Stretch</title><categories>cs.IT math.IT</categories><comments>to be presented at ISIT 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dirty paper codes are a powerful tool for combating known interference.
However, there is a significant difference between knowing the transmitted
interference sequence and knowing the received interference sequence,
especially when the channel modifying the interference is uncertain. We present
an upper bound on the capacity of a compound vector dirty paper channel where
although an additive Gaussian sequence is known to the transmitter, the channel
matrix between the interferer and receiver is uncertain but known to lie within
a bounded set. Our bound is tighter than previous bounds in the low-SIR regime
for the scalar version of the compound dirty paper channel and employs a
construction that focuses on the relationship between the dimension of the
message-bearing signal and the dimension of the additive state sequence.
Additionally, a bound on the high-SNR behavior of the system is established.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3937</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3937</id><created>2013-05-16</created><authors><author><keyname>Shaska</keyname><forenames>T.</forenames></author><author><keyname>Wang</keyname><forenames>Q.</forenames></author></authors><title>On the automorphism groups of some AG-codes based on $C_{a, b}$ curves</title><categories>cs.IT math.GR math.IT</categories><comments>arXiv admin note: text overlap with arXiv:quant-ph/0501074 by other
  authors</comments><journal-ref>Serdica J. Comput. 1 (2007), no. 2, 193-206</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study $C_{a, b}$ curves and their applications to coding theory. Recently,
Joyner and Ksir have suggested a decoding algorithm based on the automorphisms
of the code. We show how $C_{a, b}$ curves can be used to construct MDS codes
and focus on some $C_{a, b}$ curves with extra automorphisms, namely
$y^3=x^4+1, y^3=x^4-x, y^3-y=x^4$. The automorphism groups of such codes are
determined in most characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3939</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3939</id><created>2013-05-16</created><authors><author><keyname>Djimeli</keyname><forenames>A.</forenames></author><author><keyname>Tchiotsop</keyname><forenames>D.</forenames></author><author><keyname>Tchinda</keyname><forenames>R.</forenames></author></authors><title>Analysis Of Interest Points Of Curvelet Coefficients Contributions Of
  Microscopic Images And Improvement Of Edges</title><categories>cs.CV</categories><comments>9 pages, 7 figures</comments><journal-ref>Signal &amp; Image Processing : An International Journal (SIPIJ)
  Vol.4, No.2, April 2013</journal-ref><doi>10.5121/sipij.2013.4201</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper focuses on improved edge model based on Curvelet coefficients
analysis. Curvelet transform is a powerful tool for multiresolution
representation of object with anisotropic edge. Curvelet coefficients
contributions have been analyzed using Scale Invariant Feature Transform
(SIFT), commonly used to study local structure in images. The permutation of
Curvelet coefficients from original image and edges image obtained from
gradient operator is used to improve original edges. Experimental results show
that this method brings out details on edges when the decomposition scale
increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3941</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3941</id><created>2013-05-16</created><updated>2013-09-07</updated><authors><author><keyname>Elezi</keyname><forenames>A.</forenames></author><author><keyname>Shaska</keyname><forenames>T.</forenames></author></authors><title>Quantum codes from superelliptic curves</title><categories>cs.IT math.AG math.IT</categories><comments>The article has been posted without journal's permission and must be
  withdrawn</comments><journal-ref>Albanian J. Math. 5 (2011), no. 4, 175--191</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\X$ be an algebraic curve of genus $g \geq 2$ defined over a field
$\F_q$ of characteristic $p &gt; 0$. From $\X$, under certain conditions, we can
construct an algebraic geometry code $C$. If the code $C$ is self-orthogonal
under the symplectic product then we can construct a quantum code $Q$, called a
QAG-code. In this paper we study the construction of such codes from curves
with automorphisms and the relation between the automorphism group of the curve
$\X$ and the codes $C$ and $Q$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3944</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3944</id><created>2013-05-16</created><authors><author><keyname>Avis</keyname><forenames>David</forenames></author><author><keyname>Friedmann</keyname><forenames>Oliver</forenames></author></authors><title>An exponential lower bound for Cunningham's rule</title><categories>cs.CC</categories><msc-class>90C05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we give an exponential lower bound for Cunningham's least
recently considered (round-robin) rule as applied to parity games, Markhov
decision processes and linear programs. This improves a recent subexponential
bound of Friedmann for this rule on these problems. The round-robin rule fixes
a cyclical order of the variables and chooses the next pivot variable starting
from the previously chosen variable and proceeding in the given circular order.
It is perhaps the simplest example from the class of history-based pivot rules.
Our results are based on a new lower bound construction for parity games. Due
to the nature of the construction we are also able to obtain an exponential
lower bound for the round-robin rule applied to acyclic unique sink
orientations of hypercubes (AUSOs). Furthermore these AUSOs are realizable as
polytopes. We believe these are the first such results for history based rules
for AUSOs, realizable or not. The paper is self-contained and requires no
previous knowledge of parity games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3945</identifier>
 <datestamp>2016-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3945</id><created>2013-05-16</created><updated>2013-12-18</updated><authors><author><keyname>Joshi</keyname><forenames>Gauri</forenames></author><author><keyname>Liu</keyname><forenames>Yanpei</forenames></author><author><keyname>Soljanin</keyname><forenames>Emina</forenames></author></authors><title>On the Delay-Storage Trade-off in Content Download from Coded
  Distributed Storage Systems</title><categories>cs.DC cs.IT cs.PF math.IT</categories><comments>Paper accepted by JSAC-DS 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study how coding in distributed storage reduces expected
download time, in addition to providing reliability against disk failures. The
expected download time is reduced because when a content file is encoded to add
redundancy and distributed across multiple disks, reading only a subset of the
disks is sufficient to reconstruct the content. For the same total storage
used, coding exploits the diversity in storage better than simple replication,
and hence gives faster download. We use a novel fork-join queuing framework to
model multiple users requesting the content simultaneously, and derive bounds
on the expected download time. Our system model and results are a novel
generalization of the fork-join system that is studied in queueing theory
literature. Our results demonstrate the fundamental trade-off between the
expected download time and the amount of storage space. This trade-off can be
used for design of the amount of redundancy required to meet the delay
constraints on content delivery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3959</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3959</id><created>2013-05-16</created><authors><author><keyname>Joung</keyname><forenames>Jingon</forenames></author><author><keyname>Ho</keyname><forenames>Chin Keong</forenames></author><author><keyname>Sun</keyname><forenames>Sumei</forenames></author></authors><title>Spectral Efficiency and Energy Efficiency of OFDM Systems: Impact of
  Power Amplifiers and Countermeasures</title><categories>cs.IT math.IT</categories><comments>to be published, IEEE J. Sel. Areas Commun</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In wireless communication systems, the nonlinear effect and inefficiency of
power amplifier (PA) have posed practical challenges for system designs to
achieve high spectral efficiency (SE) and energy efficiency (EE). In this
paper, we analyze the impact of PA on the SE-EE tradeoff of orthogonal
frequency division multiplex (OFDM) systems. An ideal PA that is always linear
and incurs no additional power consumption can be shown to yield a decreasing
convex function in the SE-EE tradeoff. In contrast, we show that a practical PA
has an SE-EE tradeoff that has a turning point and decreases sharply after its
maximum EE point. In other words, the Pareto-optimal tradeoff boundary of the
SE-EE curve is very narrow. A wide range of SE-EE tradeoff, however, is desired
for future wireless communications that have dynamic demand depending on the
traffic loads, channel conditions, and system applications, e.g.,
high-SE-with-low-EE for rate-limited systems and high-EE-with-low-SE for
energy-limited systems. For the SE-EE tradeoff improvement, we propose a PA
switching (PAS) technique. In a PAS transmitter, one or more PAs are switched
on intermittently to maximize the EE and deliver an overall required SE. As a
consequence, a high EE over a wide range SE can be achieved, which is verified
by numerical evaluations: with 15% SE reduction for low SE demand, the PAS
between a low power PA and a high power PA can improve EE by 323%, while a
single high power PA transmitter improves EE by only 68%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3969</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3969</id><created>2013-05-16</created><authors><author><keyname>Issa</keyname><forenames>Ibrahim</forenames></author><author><keyname>Fong</keyname><forenames>Silas L.</forenames></author><author><keyname>Avestimehr</keyname><forenames>A. Salman</forenames></author></authors><title>Two-Hop Interference Channels: Impact of Linear Time-Varying Schemes</title><categories>cs.IT math.IT</categories><comments>To appear in Proc. of ISIT 2013 (proof of lemma added)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the two-hop interference channel (IC) with constant real channel
coefficients, which consists of two source-destination pairs, separated by two
relays. We analyze the achievable degrees of freedom (DoF) of such network when
relays are restricted to perform scalar amplify-forward (AF) operations, with
possibly time-varying coefficients. We show that, somewhat surprisingly, by
providing the flexibility of choosing time-varying AF coefficients at the
relays, it is possible to achieve 4/3 sum-DoF. We also develop a novel outer
bound that matches our achievability, hence characterizing the sum-DoF of
two-hop interference channels with time-varying AF relaying strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3971</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3971</id><created>2013-05-16</created><authors><author><keyname>Ye</keyname><forenames>Chengxi</forenames></author><author><keyname>Tao</keyname><forenames>Dacheng</forenames></author><author><keyname>Song</keyname><forenames>Mingli</forenames></author><author><keyname>Jacobs</keyname><forenames>David W.</forenames></author><author><keyname>Wu</keyname><forenames>Min</forenames></author></authors><title>Sparse Norm Filtering</title><categories>cs.GR cs.CV cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimization-based filtering smoothes an image by minimizing a fidelity
function and simultaneously preserves edges by exploiting a sparse norm penalty
over gradients. It has obtained promising performance in practical problems,
such as detail manipulation, HDR compression and deblurring, and thus has
received increasing attentions in fields of graphics, computer vision and image
processing. This paper derives a new type of image filter called sparse norm
filter (SNF) from optimization-based filtering. SNF has a very simple form,
introduces a general class of filtering techniques, and explains several
classic filters as special implementations of SNF, e.g. the averaging filter
and the median filter. It has advantages of being halo free, easy to implement,
and low time and memory costs (comparable to those of the bilateral filter).
Thus, it is more generic than a smoothing operator and can better adapt to
different tasks. We validate the proposed SNF by a wide variety of applications
including edge-preserving smoothing, outlier tolerant filtering, detail
manipulation, HDR compression, non-blind deconvolution, image segmentation, and
colorization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3976</identifier>
 <datestamp>2015-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3976</id><created>2013-05-17</created><updated>2014-05-19</updated><authors><author><keyname>Wiens</keyname><forenames>Jeffrey K.</forenames></author><author><keyname>Stockie</keyname><forenames>John M.</forenames></author></authors><title>An efficient parallel immersed boundary algorithm using a
  pseudo-compressible fluid solver</title><categories>cs.DC math.NA physics.flu-dyn</categories><msc-class>74F10, 76M12, 76D27, 65Y05</msc-class><journal-ref>Journal of Computational Physics, 281:917-941, 2015</journal-ref><doi>10.1016/j.jcp.2014.10.058</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an efficient algorithm for the immersed boundary method on
distributed-memory architectures, with the computational complexity of a
completely explicit method and excellent parallel scaling. The algorithm
utilizes the pseudo-compressibility method recently proposed by Guermond and
Minev [Comptes Rendus Mathematique, 348:581-585, 2010] that uses a directional
splitting strategy to discretize the incompressible Navier-Stokes equations,
thereby reducing the linear systems to a series of one-dimensional tridiagonal
systems. We perform numerical simulations of several fluid-structure
interaction problems in two and three dimensions and study the accuracy and
convergence rates of the proposed algorithm. For these problems, we compare the
proposed algorithm against other second-order projection-based fluid solvers.
Lastly, the strong and weak scaling properties of the proposed algorithm are
investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3978</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3978</id><created>2013-05-17</created><authors><author><keyname>Kumar</keyname><forenames>Puneet</forenames></author><author><keyname>Kumar</keyname><forenames>Dharminder</forenames></author></authors><title>A Conceptual E-Governance Framework for Improving Child Immunization
  Process in India</title><categories>cs.CY</categories><comments>Published with International Journal of Computer Applications (IJCA)</comments><journal-ref>Puneet Kumar, Dharminder Kumar. Article: A Conceptual E-Governance
  Framework, International Journal of Computer Applications 69(1):39-43, May
  2013. Published by Foundation of Computer Science, New York, USA</journal-ref><doi>10.5120/11808-7464</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  India is country having high population and great variations in the
educational level, economic conditions, population densities, cultures and
awareness levels. Due to these variations the immunization process is not so
much successful as per expectations of the state and central governments. In
some zones the significant amount of vaccines are wasted whereas some are
running out of vaccines. One of the reasons for such an imbalance is improper
quantity estimation of vaccines in a particular zone. Further a huge amount of
liquidity will be wasted in the form of vaccines. If we inculcate ICT
(Information and Communication Technology) in the process of immunization then
the problem can be rectified to some extent and hence we are proposing a
conceptual model using ICT to improve the process of vaccination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.3981</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.3981</id><created>2013-05-17</created><authors><author><keyname>Zhang</keyname><forenames>Kaixu</forenames></author><author><keyname>Wang</keyname><forenames>Can</forenames></author><author><keyname>Sun</keyname><forenames>Maosong</forenames></author></authors><title>Binary Tree based Chinese Word Segmentation</title><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Chinese word segmentation is a fundamental task for Chinese language
processing. The granularity mismatch problem is the main cause of the errors.
This paper showed that the binary tree representation can store outputs with
different granularity. A binary tree based framework is also designed to
overcome the granularity mismatch problem. There are two steps in this
framework, namely tree building and tree pruning. The tree pruning step is
specially designed to focus on the granularity problem. Previous work for
Chinese word segmentation such as the sequence tagging can be easily employed
in this framework. This framework can also provide quantitative error analysis
methods. The experiments showed that after using a more sophisticated tree
pruning function for a state-of-the-art conditional random field based
baseline, the error reduction can be up to 20%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4000</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4000</id><created>2013-05-17</created><authors><author><keyname>Cai</keyname><forenames>Yang</forenames></author><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author><author><keyname>Weinberg</keyname><forenames>S. Matthew</forenames></author></authors><title>Reducing Revenue to Welfare Maximization: Approximation Algorithms and
  other Generalizations</title><categories>cs.GT cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It was recently shown in [http://arxiv.org/abs/1207.5518] that revenue
optimization can be computationally efficiently reduced to welfare optimization
in all multi-dimensional Bayesian auction problems with arbitrary (possibly
combinatorial) feasibility constraints and independent additive bidders with
arbitrary (possibly combinatorial) demand constraints. This reduction provides
a poly-time solution to the optimal mechanism design problem in all auction
settings where welfare optimization can be solved efficiently, but it is
fragile to approximation and cannot provide solutions to settings where welfare
maximization can only be tractably approximated. In this paper, we extend the
reduction to accommodate approximation algorithms, providing an approximation
preserving reduction from (truthful) revenue maximization to (not necessarily
truthful) welfare maximization. The mechanisms output by our reduction choose
allocations via black-box calls to welfare approximation on randomly selected
inputs, thereby generalizing also our earlier structural results on optimal
multi-dimensional mechanisms to approximately optimal mechanisms. Unlike
[http://arxiv.org/abs/1207.5518], our results here are obtained through novel
uses of the Ellipsoid algorithm and other optimization techniques over {\em
non-convex regions}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4002</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4002</id><created>2013-05-17</created><authors><author><keyname>Cai</keyname><forenames>Yang</forenames></author><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author><author><keyname>Weinberg</keyname><forenames>S. Matthew</forenames></author></authors><title>Understanding Incentives: Mechanism Design becomes Algorithm Design</title><categories>cs.GT cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a computationally efficient black-box reduction from mechanism
design to algorithm design in very general settings. Specifically, we give an
approximation-preserving reduction from truthfully maximizing \emph{any}
objective under \emph{arbitrary} feasibility constraints with \emph{arbitrary}
bidder types to (not necessarily truthfully) maximizing the same objective plus
virtual welfare (under the same feasibility constraints). Our reduction is
based on a fundamentally new approach: we describe a mechanism's behavior
indirectly only in terms of the expected value it awards bidders for certain
behavior, and never directly access the allocation rule at all.
  Applying our new approach to revenue, we exhibit settings where our reduction
holds \emph{both ways}. That is, we also provide an approximation-sensitive
reduction from (non-truthfully) maximizing virtual welfare to (truthfully)
maximizing revenue, and therefore the two problems are computationally
equivalent. With this equivalence in hand, we show that both problems are
NP-hard to approximate within any polynomial factor, even for a single monotone
submodular bidder.
  We further demonstrate the applicability of our reduction by providing a
truthful mechanism maximizing fractional max-min fairness. This is the first
instance of a truthful mechanism that optimizes a non-linear objective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4008</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4008</id><created>2013-05-17</created><authors><author><keyname>Herzet</keyname><forenames>C.</forenames></author><author><keyname>Soussen</keyname><forenames>C.</forenames></author><author><keyname>Idier</keyname><forenames>J.</forenames></author><author><keyname>Gribonval</keyname><forenames>R.</forenames></author></authors><title>Exact Recovery Conditions for Sparse Representations with Partial
  Support Information</title><categories>cs.IT math.IT</categories><comments>arXiv admin note: substantial text overlap with arXiv:1211.7283</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the exact recovery of a k-sparse vector in the noiseless setting
when some partial information on the support is available. This partial
information takes the form of either a subset of the true support or an
approximate subset including wrong atoms as well. We derive a new sufficient
and worst-case necessary (in some sense) condition for the success of some
procedures based on lp-relaxation, Orthogonal Matching Pursuit (OMP) and
Orthogonal Least Squares (OLS). Our result is based on the coherence &quot;mu&quot; of
the dictionary and relaxes the well-known condition mu&lt;1/(2k-1) ensuring the
recovery of any k-sparse vector in the non-informed setup. It reads
mu&lt;1/(2k-g+b-1) when the informed support is composed of g good atoms and b
wrong atoms. We emphasize that our condition is complementary to some
restricted-isometry based conditions by showing that none of them implies the
other.
  Because this mutual coherence condition is common to all procedures, we carry
out a finer analysis based on the Null Space Property (NSP) and the Exact
Recovery Condition (ERC). Connections are established regarding the
characterization of lp-relaxation procedures and OMP in the informed setup.
First, we emphasize that the truncated NSP enjoys an ordering property when p
is decreased. Second, the partial ERC for OMP (ERC-OMP) implies in turn the
truncated NSP for the informed l1 problem, and the truncated NSP for p&lt;1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4014</identifier>
 <datestamp>2014-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4014</id><created>2013-05-17</created><authors><author><keyname>Fronczak</keyname><forenames>Piotr</forenames></author><author><keyname>Fronczak</keyname><forenames>Agata</forenames></author><author><keyname>Bujok</keyname><forenames>Maksymilian</forenames></author></authors><title>Exponential random graph models for networks with community structure</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI</categories><comments>8 pages, 2 figures</comments><journal-ref>Phys. Rev. E 88, 032810 (2013)</journal-ref><doi>10.1103/PhysRevE.88.032810</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although the community structure organization is one of the most important
characteristics of real-world networks, the traditional network models fail to
reproduce the feature. Therefore, the models are useless as benchmark graphs
for testing community detection algorithms. They are also inadequate to predict
various properties of real networks. With this paper we intend to fill the gap.
We develop an exponential random graph approach to networks with community
structure. To this end we mainly built upon the idea of blockmodels. We
consider both, the classical blockmodel and its degree-corrected counterpart,
and study many of their properties analytically. We show that in the
degree-corrected blockmodel, node degrees display an interesting scaling
property, which is reminiscent of what is observed in real-world fractal
networks. The scaling feature comes as a surprise, especially that in this
study, contrary to what is suggested in the literature, the scaling property is
not attributed to any specific network construction procedure. It is an
intrinsic feature of the degree-corrected blockmodel. A short description of
Monte Carlo simulations of the models is also given in the hope of being useful
to others working in the field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4018</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4018</id><created>2013-05-17</created><authors><author><keyname>Zhao</keyname><forenames>Junzhou</forenames></author><author><keyname>Wang</keyname><forenames>Pinghui</forenames></author><author><keyname>Tao</keyname><forenames>Jing</forenames></author><author><keyname>Ma</keyname><forenames>Xiaobo</forenames></author><author><keyname>Guan</keyname><forenames>Xiaohong</forenames></author></authors><title>A Peep on the Interplays between Online Video Websites and Online Social
  Networks</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many online video websites provide the shortcut links to facilitate the video
sharing to other websites especially to the online social networks (OSNs). Such
video sharing behavior greatly changes the interplays between the two types of
websites. For example, users in OSNs may watch and re-share videos shared by
their friends from online video websites, and this can also boost the
popularity of videos in online video websites and attract more people to watch
and share them. Characterizing these interplays can provide great insights for
understanding the relationships among online video websites, OSNs, ISPs and so
on. In this paper we conduct empirical experiments to study the interplays
between video sharing websites and OSNs using three totally different data
sources: online video websites, OSNs, and campus network traffic. We find that,
a) there are many factors that can affect the external sharing probability of
videos in online video websites. b) The popularity of a video itself in online
video websites can greatly impact on its popularity in OSNs. Videos in Renren,
Qzone (the top two most popular Chinese OSNs) usually attract more viewers than
in Sina and Tencent Weibo (the top two most popular Chinese microblogs), which
indicates the different natures of the two kinds of OSNs. c) The analysis based
on real traffic data illustrates that 10\% of video flows are related to OSNs,
and they account for 25\% of traffic generated by all videos.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4029</identifier>
 <datestamp>2015-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4029</id><created>2013-05-17</created><authors><author><keyname>Zhou</keyname><forenames>Jian-Ming</forenames></author></authors><title>Computability vs. Nondeterministic and P vs. NP</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper demonstrates the relativity of Computability and Nondeterministic;
the nondeterministic is just Turing's undecidable Decision rather than the
Nondeterministic Polynomial time.
  Based on analysis about TM, UM, DTM, NTM, Turing Reducible, beta-reduction,
P-reducible, isomorph, tautology, semi-decidable, checking relation, the oracle
and NP-completeness, etc., it reinterprets The Church-Turing Thesis that is
equivalent of the Polynomial time and actual time; it redefines the NTM based
on its undecidable set of its internal state. It comes to the conclusions: The
P-reducible is misdirected from the Turing Reducible with its oracle; The
NP-completeness is a reversal to The Church-Turing Thesis; The Cook-Levin
theorem is an equipollent of two uncertains. This paper brings forth new
concepts: NP (nondeterministic problem) and NP-algorithm (defined as the
optimal algorithm to get the best fit approximation value of NP). P versus NP
is the relativity of Computability and Nondeterministic, P/=NP. The
NP-algorithm is effective approximate way to NP by TM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4038</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4038</id><created>2013-05-17</created><authors><author><keyname>Wilhelm</keyname><forenames>Matthias</forenames></author><author><keyname>Martinovic</keyname><forenames>Ivan</forenames></author><author><keyname>Schmitt</keyname><forenames>Jens B.</forenames></author><author><keyname>Lenders</keyname><forenames>Vincent</forenames></author></authors><title>Air Dominance in Sensor Networks: Guarding Sensor Motes using Selective
  Interference</title><categories>cs.NI</categories><comments>16 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Securing wireless sensor networks (WSNs) is a hard problem. In particular,
network access control is notoriously difficult to achieve due to the inherent
broadcast characteristics of wireless communications: an attacker can easily
target any node in its transmission range and affect large parts of a sensor
network simultaneously. In this paper, we therefore propose a distributed
guardian system to protect a WSN based on physically regulating channel access
by means of selective interference. The guardians are deployed alongside a
sensor network, inspecting all local traffic, classifying packets based on
their content, and destroying any malicious packet while still on the air. In
that sense, the system tries to gain &quot;air dominance&quot; over attackers. A key
challenge in implementing the guardian system is the resulting real-time
requirement in order to classify and destroy packets during transmission. We
present a USRP2 software radio based guardian implementation for IEEE 802.15.4
that meets this challenge; using an FPGA-based design we can even check for the
content of the very last payload byte of a packet and still prevent its
reception by a potential victim mote. Our evaluation shows that the guardians
effectively block 99.9% of unauthorized traffic in 802.15.4 networks in our
experiments, without disturbing the legitimate operations of the WSN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4045</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4045</id><created>2013-05-17</created><authors><author><keyname>Kuzuno</keyname><forenames>Hiroki</forenames></author><author><keyname>Tonami</keyname><forenames>Satoshi</forenames></author></authors><title>Signature Generation for Sensitive Information Leakage in Android
  Applications</title><categories>cs.CR</categories><comments>8 pages, 4 figures</comments><journal-ref>29th IEEE International Conference on Data Engineering (ICDE)
  Workshops 2013 Mobile Data Analytics (MoDA)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, there has been rapid growth in mobile devices such as
smartphones, and a number of applications are developed specifically for the
smartphone market. In particular, there are many applications that are ``free''
to the user, but depend on advertisement services for their revenue. Such
applications include an advertisement module - a library provided by the
advertisement service - that can collect a user's sensitive information and
transmit it across the network. Users accept this business model, but in most
cases the applications do not require the user's acknowledgment in order to
transmit sensitive information. Therefore, such applications' behavior becomes
an invasion of privacy. In our analysis of 1,188 Android applications' network
traffic and permissions, 93% of the applications we analyzed connected to
multiple destinations when using the network. 61% required a permission
combination that included both access to sensitive information and use of
networking services. These applications have the potential to leak the user's
sensitive information. In an effort to enable users to control the transmission
of their private information, we propose a system which, using a novel
clustering method based on the HTTP packet destination and content distances,
generates signatures from the clustering result and uses them to detect
sensitive information leakage from Android applications. Our system does not
require an Android framework modification or any special privileges. Thus users
can easily introduce our system to their devices, and manage suspicious
applications' network behavior in a fine grained manner. Our system accurately
detected 94% of the sensitive information leakage from the applications
evaluated and produced only 5% false negative results, and less than 3% false
positive results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4047</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4047</id><created>2013-05-17</created><authors><author><keyname>Robert</keyname><forenames>Gwezheneg</forenames></author><author><keyname>Loidreau</keyname><forenames>Pierre</forenames></author><author><keyname>Augot</keyname><forenames>Daniel</forenames></author></authors><title>Rank metric and Gabidulin codes in characteristic zero</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We transpose the theory of rank metric and Gabidulin codes to the case of
fields of characteristic zero. The Frobenius automorphism is then replaced by
any element of the Galois group. We derive some conditions on the automorphism
to be able to easily transpose the results obtained by Gabidulin as well and a
classical polynomial-time decoding algorithm. We also provide various
definitions for the rank-metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4048</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4048</id><created>2013-05-17</created><authors><author><keyname>Horsch</keyname><forenames>Martin</forenames></author><author><keyname>Becker</keyname><forenames>Stefan</forenames></author><author><keyname>Castillo</keyname><forenames>Juan Manuel</forenames></author><author><keyname>Deublein</keyname><forenames>Stephan</forenames></author><author><keyname>Fr&#xf6;scher</keyname><forenames>Agnes</forenames></author><author><keyname>Reiser</keyname><forenames>Steffen</forenames></author><author><keyname>Werth</keyname><forenames>Stephan</forenames></author><author><keyname>Vrabec</keyname><forenames>Jadran</forenames></author><author><keyname>Hasse</keyname><forenames>Hans</forenames></author></authors><title>Molecular modelling and simulation of electrolyte solutions,
  biomolecules, and wetting of component surfaces</title><categories>cond-mat.soft cond-mat.mes-hall cs.CE physics.comp-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massively-parallel molecular dynamics simulation is applied to systems
containing electrolytes, vapour-liquid interfaces, and biomolecules in contact
with water-oil interfaces. Novel molecular models of alkali halide salts are
presented and employed for the simulation of electrolytes in aqueous solution.
The enzymatically catalysed hydroxylation of oleic acid is investigated by
molecular dynamics simulation taking the internal degrees of freedom of the
macromolecules into account. Thereby, Ewald summation methods are used to
compute the long range electrostatic interactions. In systems with a phase
boundary, the dispersive interaction, which is modelled by the Lennard-Jones
potential here, has a more significant long range contribution than in
homogeneous systems. This effect is accounted for by implementing the Janecek
cutoff correction scheme. On this basis, the HPC infrastructure at the
Steinbuch Centre for Computing was accessed and efficiently used, yielding new
insights on the molecular systems under consideration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4054</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4054</id><created>2013-05-17</created><authors><author><keyname>Assaf</keyname><forenames>Ahmad</forenames></author><author><keyname>Senart</keyname><forenames>Aline</forenames></author></authors><title>Data Quality Principles in the Semantic Web</title><categories>cs.DL cs.IR</categories><comments>ICSC '12 Proceedings of the 2012 IEEE Sixth International Conference
  on Semantic Computing</comments><doi>10.1109/ICSC.2012.39</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing size and availability of web data make data quality a core
challenge in many applications. Principles of data quality are recognized as
essential to ensure that data fit for their intended use in operations,
decision-making, and planning. However, with the rise of the Semantic Web, new
data quality issues appear and require deeper consideration. In this paper, we
propose to extend the data quality principles to the context of Semantic Web.
Based on our extensive industrial experience in data integration, we identify
five main classes suited for data quality in Semantic Web. For each class, we
list the principles that are involved at all stages of the data management
process. Following these principles will provide a sound basis for better
decision-making within organizations and will maximize long-term data
integration and interoperability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4063</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4063</id><created>2013-05-17</created><authors><author><keyname>Hurley</keyname><forenames>Ted</forenames></author></authors><title>Cryptography. key exchange, public key</title><categories>cs.CR math.RA</categories><msc-class>94A50, 16S34</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  General cryptographic schemes are presented where keys can be one-time or
ephemeral. Processes for key exchange are derived. Public key cryptographic
schemes based on the new systems are established. Authentication and signature
schemes are easy to implement. The schemes may be integrated with
error-correcting coding schemes so that encryption/coding and
decryption/decoding may be done simultaneously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4064</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4064</id><created>2013-05-17</created><authors><author><keyname>Bashir</keyname><forenames>Syed Muhammad Arsalan</forenames></author></authors><title>Font Acknowledgment and Character Extraction of Digital and Scanned
  Images</title><categories>cs.CV</categories><comments>5 pages, 5 figures, 1 table, Published with International Journal of
  Computer Applications (IJCA)</comments><journal-ref>International Journal of Computer Applications 70(8):1-5, May 2013</journal-ref><doi>10.5120/11979-7850</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The font recognition and character extraction is of immense importance as
these are many scenarios where data are in such a form, which cannot be
processed like in image form or as a hard copy. So the procedure developed in
this paper is basically related to identifying the font (Times New Roman, Arial
and Comic Sans MS) and afterwards recovering the text using simple correlation
based method where the binary templates are correlated to the input image text
characters. All of this extraction is done in the presence of a little noise as
images may have noisy patterns due to photocopying. The significance of this
method exists in extraction of data from various monitoring (Surveillance)
camera footages or even more. The method is developed on Matlab\c{opyright}
which takes input image and recovers text and font information from it in a
text file.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4076</identifier>
 <datestamp>2014-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4076</id><created>2013-05-17</created><updated>2014-04-23</updated><authors><author><keyname>Chen</keyname><forenames>Fu-qiang</forenames></author><author><keyname>Wu</keyname><forenames>Yan</forenames></author><author><keyname>Zhao</keyname><forenames>Guo-dong</forenames></author><author><keyname>Zhang</keyname><forenames>Jun-ming</forenames></author><author><keyname>Zhu</keyname><forenames>Ming</forenames></author><author><keyname>Bai</keyname><forenames>Jing</forenames></author></authors><title>Contractive De-noising Auto-encoder</title><categories>cs.LG</categories><comments>Figures edited</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Auto-encoder is a special kind of neural network based on reconstruction.
De-noising auto-encoder (DAE) is an improved auto-encoder which is robust to
the input by corrupting the original data first and then reconstructing the
original input by minimizing the reconstruction error function. And contractive
auto-encoder (CAE) is another kind of improved auto-encoder to learn robust
feature by introducing the Frobenius norm of the Jacobean matrix of the learned
feature with respect to the original input. In this paper, we combine
de-noising auto-encoder and contractive auto- encoder, and propose another
improved auto-encoder, contractive de-noising auto- encoder (CDAE), which is
robust to both the original input and the learned feature. We stack CDAE to
extract more abstract features and apply SVM for classification. The experiment
result on benchmark dataset MNIST shows that our proposed CDAE performed better
than both DAE and CAE, proving the effective of our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4077</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4077</id><created>2013-05-17</created><updated>2013-07-05</updated><authors><author><keyname>Messaoudi</keyname><forenames>Abir</forenames></author><author><keyname>Bouslimi</keyname><forenames>Riadh</forenames></author><author><keyname>Akaichi</keyname><forenames>Jalel</forenames></author></authors><title>Indexing Medical Images based on Collaborative Experts Reports</title><categories>cs.CV cs.IR</categories><comments>9 pages, 8 figures. International Journal of Computer Applications,
  May 2013</comments><doi>10.5120/11955-7787</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A patient is often willing to quickly get, from his physician, reliable
analysis and concise explanation according to provided linked medical images.
The fact of making choices individually by the patient's physician may lead to
malpractices and consequently generates unforeseeable damages. The Institute of
Medicine of the National Sciences Academy(IMNAS) in USA published a study
estimating that up to 98,000 hospital deathseach year can be attributed to
medical malpractice [1]. Moreover, physician, in charge of medical image
analysis, might be unavailable at the right time, which may complicate the
patient's state. The goal of this paper is to provide to physicians and
patients, a social network that permits to foster cooperation and to overcome
the problem of unavailability of doctors on site any time. Therefore, patients
can submit their medical images to be diagnosed and commented by several
experts instantly. Consequently, the need to process opinions and to extract
information automatically from the proposed social network became a necessity
due to the huge number of comments expressing specialist's reviews. For this
reason, we propose a kind of comments' summary keywords-based method which
extracts the major current terms and relevant words existing on physicians'
annotations. The extracted keywords will present a new and robust method for
image indexation. In fact, significant extracted terms will be used later to
index images in order to facilitate their discovery for any appropriate use. To
overcome this challenge, we propose our Terminology Extraction of Annotation
(TEA) mixed approach which focuses on algorithms mainly based on statistical
methods and on external semantic resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4081</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4081</id><created>2013-05-17</created><authors><author><keyname>Hop</keyname><forenames>Patrick</forenames></author><author><keyname>Pan</keyname><forenames>Xinghao</forenames></author></authors><title>Conditions for Convergence in Regularized Machine Learning Objectives</title><categories>cs.LG cs.NA math.OC</categories><comments>3 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analysis of the convergence rates of modern convex optimization algorithms
can be achived through binary means: analysis of emperical convergence, or
analysis of theoretical convergence. These two pathways of capturing
information diverge in efficacy when moving to the world of distributed
computing, due to the introduction of non-intuitive, non-linear slowdowns
associated with broadcasting, and in some cases, gathering operations. Despite
these nuances in the rates of convergence, we can still show the existence of
convergence, and lower bounds for the rates. This paper will serve as a helpful
cheat-sheet for machine learning practitioners encountering this problem class
in the field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4094</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4094</id><created>2013-05-17</created><updated>2013-06-04</updated><authors><author><keyname>Geisel</keyname><forenames>I.</forenames></author><author><keyname>Cordes</keyname><forenames>K.</forenames></author><author><keyname>Mahnke</keyname><forenames>J.</forenames></author><author><keyname>J&#xf6;llenbeck</keyname><forenames>S.</forenames></author><author><keyname>Ostermann</keyname><forenames>J.</forenames></author><author><keyname>Arlt</keyname><forenames>J.</forenames></author><author><keyname>Ertmer</keyname><forenames>W.</forenames></author><author><keyname>Klempt</keyname><forenames>C.</forenames></author></authors><title>Evolutionary optimization of an experimental apparatus</title><categories>quant-ph cond-mat.quant-gas cs.NE</categories><comments>minor revision</comments><journal-ref>Appl. Phys. Lett. 102, 214105 (2013)</journal-ref><doi>10.1063/1.4808213</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent decades, cold atom experiments have become increasingly complex.
While computers control most parameters, optimization is mostly done manually.
This is a time-consuming task for a high-dimensional parameter space with
unknown correlations. Here we automate this process using a genetic algorithm
based on Differential Evolution. We demonstrate that this algorithm optimizes
21 correlated parameters and that it is robust against local maxima and
experimental noise. The algorithm is flexible and easy to implement. Thus, the
presented scheme can be applied to a wide range of experimental optimization
tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4095</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4095</id><created>2013-05-17</created><authors><author><keyname>Sacuto</keyname><forenames>Fabien</forenames></author><author><keyname>Labeau</keyname><forenames>Fabrice</forenames></author><author><keyname>Agba</keyname><forenames>Basile. L</forenames></author></authors><title>Wide Band Time-Correlated Model for Wireless Communications under
  Impulsive Noise within Power Substation</title><categories>cs.NI cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The installation of wireless technologies in power substations requires
characterizing the impulsive noise produced by the high-voltage equipment.
Substation impulsive noise might interfere with classic wireless communications
and none of the existing models can reliably represent this noise in wide band.
Previous studies have shown that impulsive noise is characterized by series of
damped oscillations with the amplitude, the duration and the occurrence times
of the impulses that are random. All these characteristics make this noise
time-correlated and the partitioned Markov chain remains an efficient model
that can ensure the correlation between the samples. In this study, we propose
to design a partitioned Markov chain to generate an impulsive noise that is
similar to the noise measured in existing substations, in time and frequency
domains. We configure our Markov chain to produce the impulses with the damped
oscillation effect, then, we determine the probability transition matrix and
the distribution of each state of the Markov chain. Finally, we generate noise
samples and we study the distribution of the impulsive noise characteristics.
Our Markov chain model can replicate the correlation between the measured noise
samples; also the distributions of the noise characteristics are similar in the
simulations and the measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4096</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4096</id><created>2013-05-17</created><authors><author><keyname>Gensollen</keyname><forenames>Nicolas</forenames></author><author><keyname>Gauthier</keyname><forenames>Vincent</forenames></author><author><keyname>Marot</keyname><forenames>Michel</forenames></author><author><keyname>Becker</keyname><forenames>Monique</forenames></author></authors><title>Modeling and optimizing a distributed power network : A complex system
  approach of the prosumer management in the smart grid</title><categories>cs.SY</categories><comments>18 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most important goals of the 21st century is to change radically
the way our society produces and distributes energy. This broad objective
embodies in the smart grid's futuristic vision of a completely decentralized
system powered by renewable plants. Imagine indeed such a real time power
network in which everyone could be a consumer or a producer. Based on a coupled
information system, each user would be able to buy or sell energy at a time
depending price that would allow a homogenization of the consumption,
eradicating the well known morning or evening peak. This attractive idea is
currently booming in the scientific community as it generates intellectual
challenges in various domains.
  Nevertheless, lots of unanswered questions remain. The first steps are
currently accomplished with the appearance of smart meters or the development
of more efficient energy storage devices. However, the design of the
decentralized information system of the smart grid, which will have to deal
with huge amounts of sensor's data in order to control the system within its
stability region, seems to be still in search.
  In the following survey, we concentrate on the telecommunication part of the
smart grid system. We begin by identifying different control level in the
system, and we focus on high control levels, which are commonly attributed to
the information system. We then define a few concepts of the smart grid and
present some interesting approaches using models from the complex system
theory. In the last part, we review ongoing works aiming at establishing
telecommunication requirements for smart grid applications, and underline the
necessity of building accountable models for testing these values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4102</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4102</id><created>2013-04-11</created><authors><author><keyname>Rudder</keyname><forenames>Andrew</forenames></author><author><keyname>Goodridge</keyname><forenames>Wayne</forenames></author><author><keyname>Mohammed</keyname><forenames>Shareeda</forenames></author></authors><title>Using Bias Optimization for Reversible Data Hiding Using Image
  Interpolation</title><categories>cs.MM cs.CR</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we propose a reversible data hiding method in the spatial
domain for compressed grayscale images. The proposed method embeds secret bits
into a compressed thumbnail of the original image by using a novel
interpolation method and the Neighbour Mean Interpolation (NMI) technique as
scaling up to the original image occurs. Experimental results presented in this
paper show that the proposed method has significantly improved embedding
capacities over the approach proposed by Jung and Yoo.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4103</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4103</id><created>2013-04-23</created><authors><author><keyname>Br&#xe1;zdil</keyname><forenames>Tom&#xe1;&#x161;</forenames></author><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Forejt</keyname><forenames>Vojt&#x11b;ch</forenames></author><author><keyname>Ku&#x10d;era</keyname><forenames>Anton&#xed;n</forenames></author></authors><title>Trading Performance for Stability in Markov Decision Processes</title><categories>cs.SY</categories><comments>Extended version of a paper presented at LICS 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of central controller synthesis problems for
finite-state Markov decision processes, where the objective is to optimize both
the expected mean-payoff performance of the system and its stability.
  We argue that the basic theoretical notion of expressing the stability in
terms of the variance of the mean-payoff (called global variance in our paper)
is not always sufficient, since it ignores possible instabilities on respective
runs. For this reason we propose alernative definitions of stability, which we
call local and hybrid variance, and which express how rewards on each run
deviate from the run's own mean-payoff and from the expected mean-payoff,
respectively.
  We show that a strategy ensuring both the expected mean-payoff and the
variance below given bounds requires randomization and memory, under all the
above semantics of variance. We then look at the problem of determining whether
there is a such a strategy. For the global variance, we show that the problem
is in PSPACE, and that the answer can be approximated in pseudo-polynomial
time. For the hybrid variance, the analogous decision problem is in NP, and a
polynomial-time approximating algorithm also exists. For local variance, we
show that the decision problem is in NP. Since the overall performance can be
traded for stability (and vice versa), we also present algorithms for
approximating the associated Pareto curve in all the three cases.
  Finally, we study a special case of the decision problems, where we require a
given expected mean-payoff together with zero variance. Here we show that the
problems can be all solved in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4119</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4119</id><created>2013-05-17</created><authors><author><keyname>Attie</keyname><forenames>Paul C</forenames></author><author><keyname>Zaraket</keyname><forenames>Fadi A</forenames></author><author><keyname>Fawaz</keyname><forenames>Mohammad</forenames></author><author><keyname>Noureddine</keyname><forenames>Mohammad</forenames></author></authors><title>Semantic Guidance and Feedback for the Construction of Specifications
  and Implementations</title><categories>cs.SE cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of writing a specification which accurately reflects the intent
of the developer has long been recognized as fundamental. We propose a method
and a supporting tool to write and check a specification and an implementation
using a set of use cases, \ie input-output pairs that the developer supplies.
These are instances of both good (correct) and bad (incorrect) behavior. We
assume that the use cases are accurate, as it is easier to generate use cases
than to write an accurate specification. We incrementally construct a
specification (precondition and postcondition) based on semantic feedback
generated from these use cases. We check the accuracy of the constructed
specification using two proposed algorithms. The first algorithm checks the
accuracy of the specification against an automatically generated specification
from a supplied finite domain of use cases. The second checks the accuracy of
the specification via reducing its domain to a finite yet equally satisfiable
domain if possible. When the specification is mature, we start to also
construct a program that satisfies the specification. However, our method makes
provision for the continued modification of the specification, if needed. We
illustrate our method with two examples; linear search and text justify.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4130</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4130</id><created>2013-05-17</created><authors><author><keyname>Gelfand</keyname><forenames>Andrew</forenames></author><author><keyname>Shin</keyname><forenames>Jinwoo</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author></authors><title>Belief Propagation for Linear Programming</title><categories>cs.AI cs.DS</categories><comments>To appear in ISIT 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Belief Propagation (BP) is a popular, distributed heuristic for performing
MAP computations in Graphical Models. BP can be interpreted, from a variational
perspective, as minimizing the Bethe Free Energy (BFE). BP can also be used to
solve a special class of Linear Programming (LP) problems. For this class of
problems, MAP inference can be stated as an integer LP with an LP relaxation
that coincides with minimization of the BFE at ``zero temperature&quot;. We
generalize these prior results and establish a tight characterization of the LP
problems that can be formulated as an equivalent LP relaxation of MAP
inference. Moreover, we suggest an efficient, iterative annealing BP algorithm
for solving this broader class of LP problems. We demonstrate the algorithm's
performance on a set of weighted matching problems by using it as a cutting
plane method to solve a sequence of LPs tightened by adding ``blossom''
inequalities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4131</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4131</id><created>2013-05-17</created><authors><author><keyname>Perrucci</keyname><forenames>Daniel</forenames></author><author><keyname>Roy</keyname><forenames>Marie-Francoise</forenames></author></authors><title>Zero-nonzero and real-nonreal sign determination</title><categories>math.AG cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider first the zero-nonzero determination problem, which consists in
determining the list of zero-nonzero conditions realized by a finite list of
polynomials on a finite set Z included in C^k with C an algebraic closed field.
We describe an algorithm to solve the zero-nonzero determination problem and we
perform its bit complexity analysis. This algorithm, which is in many ways an
adaptation of the methods used to solve the more classical sign determination
problem, presents also new ideas which can be used to improve sign
determination. Then, we consider the real-nonreal sign determination problem,
which deals with both the sign determination and the zero-nonzero determination
problem. We describe an algorithm to solve the real-nonreal sign determination
problem, we perform its bit complexity analysis and we discuss this problem in
a parametric context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4133</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4133</id><created>2013-05-17</created><authors><author><keyname>Akbas</keyname><forenames>Mustafa Ilhan</forenames></author><author><keyname>Brust</keyname><forenames>Matthias R.</forenames></author><author><keyname>Turgut</keyname><forenames>Damla</forenames></author></authors><title>Social Network Generation and Role Determination Based on Smartphone
  Data</title><categories>cs.SI physics.soc-ph</categories><comments>IEEE International Conference on Computer Communications (INFOCOM'12)
  Student Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We deal with the problem of automatically generating social networks by
analyzing and assessing smartphone usage and interaction data. We start by
assigning weights to the different types of interactions such as messaging,
email, phone calls, chat and physical proximity. Next, we propose a ranking
algorithm which recognizes the pattern of interaction taking into account the
changes in the collected data over time. Both algorithms are based on recent
findings from social network research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4147</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4147</id><created>2013-05-17</created><authors><author><keyname>Beasely</keyname><forenames>LeRoy</forenames></author><author><keyname>Lee</keyname><forenames>Troy</forenames></author><author><keyname>Klauck</keyname><forenames>Hartmut</forenames></author><author><keyname>Theis</keyname><forenames>Dirk Oliver</forenames></author></authors><title>Dagstuhl Report 13082: Communication Complexity, Linear Optimization,
  and lower bounds for the nonnegative rank of matrices</title><categories>math.CO cs.CC cs.DM math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report documents the program and the outcomes of Dagstuhl Seminar 13082
&quot;Communication Complexity, Linear Optimization, and lower bounds for the
nonnegative rank of matrices&quot;, held in February 2013 at Dagstuhl Castle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4148</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4148</id><created>2013-05-17</created><authors><author><keyname>Abdulla</keyname><forenames>Mouhamed</forenames></author><author><keyname>Shayan</keyname><forenames>Yousef R.</forenames></author></authors><title>On the Peculiarities of Design: An Engineering Perspective</title><categories>cs.HC</categories><comments>Proc. 2013 Canadian Engineering Education Association (CEEA13) Conf</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is a fact of our existence, that no matter where we are, we most often
find ourselves either hearing, seeing, talking, or even engaged in design
related activities. Despite this reality, the notion of 'design', and in
particular 'engineering design', is often ambiguous, and at times obscure.
Thus, the transfer of knowledge of this crucial topic to engineering students
engaged in practical hands-on learning or analytical research is usually
perplexing to accomplish. In light of this, it becomes worthwhile to dissect
and reflect on the abstraction of the design process in engineering. In fact,
the aim of this article is to investigate the facets of applied design, and
elaborate on its diversity, complexity and elements. Eventually, by
concretizing this subject matter, we hope to slightly assist engineering
students in alleviating some of the vagueness associated with the principle of
design, and enhance their technical skillset during innovative conceptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4163</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4163</id><created>2013-05-17</created><authors><author><keyname>Namiot</keyname><forenames>Dmitry</forenames></author><author><keyname>Sneps-Sneppe</keyname><forenames>Manfred</forenames></author></authors><title>Local Messages for Smartphones</title><categories>cs.NI cs.CY</categories><comments>6 pages. Submitted to CFIC Coimbra 2013 The Conference on Future
  Internet Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a new model for local messaging based on the network
proximity. We present a novelty mobile mashup which combines Wi-Fi proximity
measurements with Cloud Messaging. Our mobile mashup combines passive
monitoring for smart phones and cloud based messaging for mobile operational
systems. Passive monitoring can determine the location of mobile subscribers
(mobile phones, actually) without the active participation of mobile users.
This paper describes how to combine the passive monitoring and notifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4168</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4168</id><created>2013-05-17</created><authors><author><keyname>Willomitzer</keyname><forenames>Florian</forenames></author><author><keyname>Ettl</keyname><forenames>Svenja</forenames></author><author><keyname>Faber</keyname><forenames>Christian</forenames></author><author><keyname>H&#xe4;usler</keyname><forenames>Gerd</forenames></author></authors><title>Flying Triangulation - towards the 3D movie camera</title><categories>cs.CV physics.optics</categories><comments>Proceedings of the 7th International Fringe Workshop on Advanced
  Optical Imaging and Metrology, 2013, N\&quot;urtingen, Germany</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Flying Triangulation sensors enable a free-hand and motion-robust 3D data
acquisition of complex shaped objects. The measurement principle is based on a
multi-line light-sectioning approach and uses sophisticated algorithms for
real-time registration (S. Ettl et al., Appl. Opt. 51 (2012) 281-289). As
&quot;single-shot principle&quot;, light sectioning enables the option to get surface
data from one single camera exposure. But there is a drawback: A pixel-dense
measurement is not possible because of fundamental information-theoretical
reasons. By &quot;pixel-dense&quot; we understand that each pixel displays individually
measured distance information, neither interpolated from its neighbour pixels
nor using lateral context information. Hence, for monomodal single-shot
principles, the 3D data generated from one 2D raw image display a significantly
lower space-bandwidth than the camera permits. This is the price one must pay
for motion robustness. Currently, our sensors project about 10 lines (each with
1000 pixels), reaching an considerable lower data efficiency than theoretically
possible for a single-shot sensor. Our aim is to push Flying Triangulation to
its information-theoretical limits. Therefore, the line density as well as the
measurement depth needs to be significantly increased. This causes serious
indexing ambiguities. On the road to a single-shot 3D movie camera, we are
working on solutions to overcome the problem of false line indexing by
utilizing yet unexploited information. We will present several approaches and
will discuss profound information-theoretical questions about the information
efficiency of 3D sensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4170</identifier>
 <datestamp>2013-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4170</id><created>2013-05-17</created><updated>2013-11-29</updated><authors><author><keyname>Dujmovic</keyname><forenames>Vida</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author><author><keyname>Smid</keyname><forenames>Michiel</forenames></author></authors><title>Average Stretch Factor: How Low Does It Go?</title><categories>cs.CG cs.NI math.MG</categories><comments>30 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a geometric graph, $G$, the \emph{stretch factor} between two vertices,
$u$ and $w$, is the ratio between the Euclidean length of the shortest path
from $u$ to $w$ in $G$ and the Euclidean distance between $u$ and $w$. The
\emph{average stretch factor} of $G$ is the average stretch factor taken over
all pairs of vertices in $G$. We show that, for any constant dimension, $d$,
and any set, $V$, of $n$ points in $\mathbb{R}^d$, there exists a geometric
graph with vertex set $V$, that has $O(n)$ edges, and that has average stretch
factor $1+ o_n(1)$. More precisely, the average stretch factor of this graph is
$1+O((\log n/n)^{1/(2d+1)})$. We complement this upper-bound with a lower
bound: There exist $n$-point sets in $\mathbb{R}^2$ for which any graph with
$O(n)$ edges has average stretch factor $1+\Omega(1/\sqrt{n})$. Bounds of this
type are not possible for the more commonly studied worst-case stretch factor.
In particular, there exists point sets, $V$, such that any graph with
worst-case stretch factor $1+o_n(1)$ has a superlinear number of edges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4195</identifier>
 <datestamp>2013-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4195</id><created>2013-05-17</created><updated>2013-07-09</updated><authors><author><keyname>Davidson</keyname><forenames>Susan B.</forenames></author><author><keyname>Huang</keyname><forenames>Xiaocheng</forenames></author><author><keyname>Stoyanovich</keyname><forenames>Julia</forenames></author><author><keyname>Yuan</keyname><forenames>Xiaojie</forenames></author></authors><title>Search and Result Presentation in Scientific Workflow Repositories</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of searching a repository of complex hierarchical
workflows whose component modules, both composite and atomic, have been
annotated with keywords. Since keyword search does not use the graph structure
of a workflow, we develop a model of workflows using context-free bag grammars.
We then give efficient polynomial-time algorithms that, given a workflow and a
keyword query, determine whether some execution of the workflow matches the
query. Based on these algorithms we develop a search and ranking solution that
efficiently retrieves the top-k grammars from a repository. Finally, we propose
a novel result presentation method for grammars matching a keyword query, based
on representative parse-trees. The effectiveness of our approach is validated
through an extensive experimental evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4196</identifier>
 <datestamp>2013-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4196</id><created>2013-05-17</created><updated>2013-11-18</updated><authors><author><keyname>Meyer</keyname><forenames>R.</forenames></author></authors><title>Efficient Parallelization of Short-Range Molecular Dynamics Simulations
  on Many-Core Systems</title><categories>physics.comp-ph cs.DC</categories><comments>12 pages, 8 figures</comments><acm-class>D.1.3</acm-class><journal-ref>Phys. Rev. E 88, 053309 (2013)</journal-ref><doi>10.1103/PhysRevE.88.053309</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article introduces a highly parallel algorithm for molecular dynamics
simulations with short-range forces on single node multi- and many-core
systems. The algorithm is designed to achieve high parallel speedups for
strongly inhomogeneous systems like nanodevices or nanostructured materials. In
the proposed scheme the calculation of the forces and the generation of
neighbor lists is divided into small tasks. The tasks are then executed by a
thread pool according to a dependent task schedule. This schedule is
constructed in such a way that a particle is never accessed by two threads at
the same time.Benchmark simulations on a typical 12 core machine show that the
described algorithm achieves excellent parallel efficiencies above 80 % for
different kinds of systems and all numbers of cores. For inhomogeneous systems
the speedups are strongly superior to those obtained with spatial
decomposition. Further benchmarks were performed on an Intel Xeon Phi
coprocessor. These simulations demonstrate that the algorithm scales well to
large numbers of cores.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4199</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4199</id><created>2013-05-17</created><authors><author><keyname>Li</keyname><forenames>Di</forenames></author><author><keyname>Lai</keyname><forenames>Lifeng</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Quickest Change Point Detection and Identification Across a Generic
  Sensor Array</title><categories>cs.IT math.IT</categories><comments>Quickest change detection, identification, sensor network,
  decentralized detection</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of quickest change point detection and
identification over a linear array of $N$ sensors, where the change pattern
could first reach any of these sensors, and then propagate to the other
sensors. Our goal is not only to detect the presence of such a change as
quickly as possible, but also to identify which sensor that the change pattern
first reaches. We jointly design two decision rules: a stopping rule, which
determines when we should stop sampling and claim a change occurred, and a
terminal decision rule, which decides which sensor that the change pattern
reaches first, with the objective to strike a balance among the detection
delay, the false alarm probability, and the false identification probability.
We show that this problem can be converted to a Markov optimal stopping time
problem, from which some technical tools could be borrowed. Furthermore, to
avoid the high implementation complexity issue of the optimal rules, we develop
a scheme with a much simpler structure and certain performance guarantee.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4204</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4204</id><created>2013-05-17</created><authors><author><keyname>Chester</keyname><forenames>Uzi</forenames></author><author><keyname>Ratsaby</keyname><forenames>Joel</forenames></author></authors><title>Machine learning on images using a string-distance</title><categories>cs.LG cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new method for image feature-extraction which is based on
representing an image by a finite-dimensional vector of distances that measure
how different the image is from a set of image prototypes. We use the recently
introduced Universal Image Distance (UID) \cite{RatsabyChesterIEEE2012} to
compare the similarity between an image and a prototype image. The advantage in
using the UID is the fact that no domain knowledge nor any image analysis need
to be done. Each image is represented by a finite dimensional feature vector
whose components are the UID values between the image and a finite set of image
prototypes from each of the feature categories. The method is automatic since
once the user selects the prototype images, the feature vectors are
automatically calculated without the need to do any image analysis. The
prototype images can be of different size, in particular, different than the
image size. Based on a collection of such cases any supervised or unsupervised
learning algorithm can be used to train and produce an image classifier or
image cluster analysis. In this paper we present the image feature-extraction
method and use it on several supervised and unsupervised learning experiments
for satellite image data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4210</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4210</id><created>2013-05-17</created><authors><author><keyname>Abdelrahman</keyname><forenames>Omer H.</forenames></author><author><keyname>Gelenbe</keyname><forenames>Erol</forenames></author><author><keyname>G&#xf6;rbil</keyname><forenames>G&#xf6;k&#xe7;e</forenames></author><author><keyname>Oklander</keyname><forenames>Boris</forenames></author></authors><title>Mobile Network Anomaly Detection and Mitigation: The NEMESYS Approach</title><categories>cs.CR cs.NI</categories><comments>To Appear in the Proceedings of the 28th International Symposium on
  Computer and Information Sciences (ISCIS 2013), Springer LNEE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile malware and mobile network attacks are becoming a significant threat
that accompanies the increasing popularity of smart phones and tablets. Thus in
this paper we present our research vision that aims to develop a network-based
security solution combining analytical modelling, simulation and learning,
together with billing and control-plane data, to detect anomalies and attacks,
and eliminate or mitigate their effects, as part of the EU FP7 NEMESYS project.
These ideas are supplemented with a careful review of the state-of-the-art
regarding anomaly detection techniques that mobile network operators may use to
protect their infrastructure and secure users against malware.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4219</identifier>
 <datestamp>2014-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4219</id><created>2013-05-17</created><updated>2014-09-23</updated><authors><author><keyname>Lin</keyname><forenames>Xingqin</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Ghosh</keyname><forenames>Amitava</forenames></author></authors><title>Spectrum Sharing for Device-to-Device Communication in Cellular Networks</title><categories>cs.IT math.IT</categories><comments>14 pages; 11 figures; submitted to IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses two fundamental and interrelated issues in
device-to-device (D2D) enhanced cellular networks. The first issue is how D2D
users should access spectrum, and we consider two choices: overlay (orthogonal
spectrum between D2D and cellular UEs) and underlay (non-orthogonal). The
second issue is how D2D users should choose between communicating directly or
via the base station, a choice that depends on distance between the potential
D2D transmitter and receiver. We propose a tractable hybrid network model where
the positions of mobiles are modeled by random spatial Poisson point process,
with which we present a general analytical approach that allows a unified
performance evaluation for these questions. Then, we derive analytical rate
expressions and apply them to optimize the two D2D spectrum sharing scenarios
under a weighted proportional fair utility function. We find that as the
proportion of potential D2D mobiles increases, the optimal spectrum partition
in the overlay is almost invariant (when D2D mode selection threshold is large)
while the optimal spectrum access factor in the underlay decreases. Further,
from a coverage perspective, we reveal a tradeoff between the spectrum access
factor and the D2D mode selection threshold in the underlay: as more D2D links
are allowed (due to a more relaxed mode selection threshold), the network
should actually make less spectrum available to them to limit their
interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4228</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4228</id><created>2013-05-18</created><authors><author><keyname>Yu</keyname><forenames>Wei</forenames></author><author><keyname>Chen</keyname><forenames>Junpeng</forenames></author></authors><title>The state-of-the-art in web-scale semantic information processing for
  cloud computing</title><categories>cs.DC cs.AI</categories><comments>20 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based on integrated infrastructure of resource sharing and computing in
distributed environment, cloud computing involves the provision of dynamically
scalable and provides virtualized resources as services over the Internet.
These applications also bring a large scale heterogeneous and distributed
information which pose a great challenge in terms of the semantic ambiguity. It
is critical for application services in cloud computing environment to provide
users intelligent service and precise information. Semantic information
processing can help users deal with semantic ambiguity and information overload
efficiently through appropriate semantic models and semantic information
processing technology. The semantic information processing have been
successfully employed in many fields such as the knowledge representation,
natural language understanding, intelligent web search, etc. The purpose of
this report is to give an overview of existing technologies for semantic
information processing in cloud computing environment, to propose a research
direction for addressing distributed semantic reasoning and parallel semantic
computing by exploiting semantic information newly available in cloud computing
environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4229</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4229</id><created>2013-05-18</created><authors><author><keyname>Parviz</keyname><forenames>Maghsood</forenames></author><author><keyname>Mousavi</keyname><forenames>Seyed Hassan</forenames></author><author><keyname>Mirahmadi</keyname><forenames>Saeed</forenames></author></authors><title>Key classification attack on block ciphers</title><categories>cs.CR</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper, security analysis of block ciphers with key length greater
than block length is proposed. When key length is significantly greater than
block length and the statistical distribution of cipher system is like a
uniform distribution, there are more than one key which map fixed input to
fixed output. If a block cipher designed sufficiently random, it is expected
that the key space can be classified into same classes. Using such classes of
keys, our proposed algorithm would be able to recover the key of block cipher
with complexity O(max(2^n, 2^{k-n}) where n is block length and k is key
length. We applied our algorithm to 2- round KASUMI block cipher as sample
block cipher by using weakness of functions that used in KASUMI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4237</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4237</id><created>2013-05-18</created><authors><author><keyname>Hon</keyname><forenames>W.</forenames></author><author><keyname>Kloks</keyname><forenames>T.</forenames></author><author><keyname>Liu</keyname><forenames>S.</forenames></author><author><keyname>Poon</keyname><forenames>S.</forenames></author><author><keyname>Wang</keyname><forenames>Y.</forenames></author></authors><title>Independent set in categorical products of cographs and splitgraphs</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that there are polynomial-time algorithms to compute maximum
independent sets in the categorical products of two cographs and two
splitgraphs. We show that the ultimate categorical independence ratio is
computable in polynomial time for cographs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4240</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4240</id><created>2013-05-18</created><authors><author><keyname>Cui</keyname><forenames>Hongyu</forenames></author><author><keyname>Zhang</keyname><forenames>Rongqing</forenames></author><author><keyname>Song</keyname><forenames>Lingyang</forenames></author><author><keyname>Jiao</keyname><forenames>Bingli</forenames></author></authors><title>Relay Selection for Bidirectional AF Relay Network with Outdated CSI</title><categories>cs.IT math.IT</categories><comments>accepted by IEEE Transactions on Vehicular Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most previous researches on bidirectional relay selection (RS) typically
assume perfect channel state information (CSI). However, outdated CSI, caused
by the the time-variation of channel, cannot be ignored in the practical
system, and it will deteriorate the performance. In this paper, the effect of
outdated CSI on the performance of bidirectional amplify-and-forward RS is
investigated. The optimal single RS scheme in minimizing the symbol error rate
(SER) is revised by incorporating the outdated channels. The analytical
expressions of end-to-end signal to noise ratio (SNR) and symbol error rate
(SER) are derived in a closed-form, along with the asymptotic SER expression in
high SNR. All the analytical expressions are verified by the Monte-Carlo
simulations. The analytical and the simulation results reveal that once CSI is
outdated, the diversity order degrades to one from full diversity. Furthermore,
a multiple RS scheme is proposed and verified that this scheme is a feasible
solution to compensate the diversity loss caused by outdated CSI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4242</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4242</id><created>2013-05-18</created><updated>2013-08-13</updated><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Park</keyname><forenames>Han Woo</forenames></author><author><keyname>Wagner</keyname><forenames>Caroline</forenames></author></authors><title>International Co-authorship Relations in the Social Science Citation
  Index: Is Internationalization Leading the Network?</title><categories>cs.DL physics.soc-ph</categories><comments>Journal of the American Society for Information Science and
  Technology (forthcoming)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze international co-authorship relations in the Social Science
Citation Index 2011 using all citable items in the DVD-version of this index.
Network statistics indicate four groups of nations: (i) an Asian-Pacific one to
which all Anglo-Saxon nations (including the UK and Ireland) are attributed;
(ii) a continental European one including also the Latin-American countries;
(iii) the Scandinavian nations; and (iv) a community of African nations. Within
the EU-28 (including Croatia), eleven of the EU-15 states have dominant
positions. Collapsing the EU-28 into a single node leads to a bi-polar
structure between the US and EU-28; China is part of the US-pole. We develop an
information-theoretical test to distinguish whether international
collaborations or domestic collaborations prevail; the results are mixed, but
the international dimension is more important than the national one in the
aggregated sets (this was found in both SSCI and SCI). In France, however, the
national distribution is more important than the international one, while the
reverse is true for most European nations in the core group (UK, Germany, the
Netherlands, etc.). Decomposition of the USA in terms of states shows a
similarly mixed result; more US states are domestically oriented in SSCI,
whereas more internationally in SCI. The international networks have grown
during the last decades in addition to the national ones, but not by replacing
them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4247</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4247</id><created>2013-05-18</created><authors><author><keyname>Sba&#xef;</keyname><forenames>Zohra</forenames></author><author><keyname>Escheikh</keyname><forenames>Mohamed</forenames></author></authors><title>Model Checking Techniques for Verification of an Encryption Scheme for
  Wireless Sensor Networks</title><categories>cs.LO</categories><comments>6 pages, 8 figures, 2 tables, IPWIS 2012, Proceeding of the
  International Conference on Information Processing and Wireless Systems
  (IPWiS), 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we deal with the formal verification of an encryption scheme
for Wireless Sensor Networks (WSNs). Especially, we present our first results
on building a framework dedicated to modelling and verification of WSNs
aspects. To achieve our goal, we propose to specify WSNs models written in
Petri nets using Promela constructs in order to verify correctness properties
of them using SPIN Model checker. We first specify in Promela a Petri net
description of an encryption scheme for WSNs that describes its behavior. Then,
correctness properties that express requirements on the system's behavior are
formulated in Linear Temporal Logic (LTL). Finally, SPIN model checker is used
to check if a specific correctness property holds for the model, and, if not,
to provide a counterexample: a computation that does not satisfy this property.
This counterexample will help to detect the source of the eventual problem and
to correct it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4255</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4255</id><created>2013-05-18</created><authors><author><keyname>Li</keyname><forenames>Lvzhou</forenames></author><author><keyname>Qiu</keyname><forenames>Daowen</forenames></author></authors><title>Decidability of minimization of fuzzy automata</title><categories>cs.FL</categories><comments>20pages, comments are welcome</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State minimization is a fundamental problem in automata theory. The problem
is also of great importance in the study of fuzzy automata. However, most work
in the literature considered only state reduction of fuzzy automata, whereas
the state minimization problem is almost untouched for fuzzy automata. Thus in
this paper we focus on the latter problem. Formally, the decision version of
the minimization problem of fuzzy automata is as follows: \begin{itemize}
  \item Given a fuzzy automaton $\mathcal{A}$ and a natural number $k$, that
is, a pair $\langle \mathcal{A}, k\rangle$, is there a $k$-state fuzzy
automaton equivalent to $\mathcal{A}$? \end{itemize} We prove for the first
time that the above problem is decidable for fuzzy automata over totally
ordered lattices. To this end, we first give the concept of systems of fuzzy
polynomial equations and then present a procedure to solve these systems.
Afterwards, we apply the solvability of a system of fuzzy polynomial equations
to the minimization problem mentioned above, obtaining the decidability.
Finally, we point out that the above problem is at least as hard as
PSAPCE-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4263</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4263</id><created>2013-05-18</created><authors><author><keyname>Blanchard</keyname><forenames>Peva</forenames></author><author><keyname>Dolev</keyname><forenames>Shlomi</forenames></author><author><keyname>Beauquier</keyname><forenames>Joffroy</forenames></author><author><keyname>Dela&#xeb;t</keyname><forenames>Sylvie</forenames></author></authors><title>Self-Stabilizing Paxos</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the first self-stabilizing consensus and replicated state machine
for asynchronous message passing systems. The scheme does not require that all
participants make a certain number of steps prior to reaching a practically
infinite execution where the replicated state machine exhibits the desired
behavior. In other words, the system reaches a configuration from which it
operates according to the specified requirements of the replicated
state-machine, for a long enough execution regarding all practical
considerations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4274</identifier>
 <datestamp>2013-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4274</id><created>2013-05-18</created><updated>2013-06-28</updated><authors><author><keyname>Abbe</keyname><forenames>Emmanuel</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Conditional Random Fields, Planted Constraint Satisfaction, and Entropy
  Concentration</title><categories>math.PR cs.IT math.CO math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a class of probabilistic models on graphs, where edge
variables depend on incident node variables through a fixed probability kernel.
The class includes planted con- straint satisfaction problems (CSPs), as well
as more general structures motivated by coding and community clustering
problems. It is shown that under mild assumptions on the kernel and for sparse
random graphs, the conditional entropy of the node variables given the edge
variables concentrates around a deterministic threshold. This implies in
particular the concentration of the number of solutions in a broad class of
planted CSPs, the existence of a threshold function for the disassortative
stochastic block model, and the proof of a conjecture on parity check codes. It
also establishes new connections among coding, clustering and satisfiability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4277</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4277</id><created>2013-05-18</created><authors><author><keyname>Rei&#xdf;ig</keyname><forenames>Gunther</forenames></author></authors><title>On the maximum rank of Toeplitz block matrices of blocks of a given
  pattern</title><categories>math.CO cs.SY</categories><msc-class>05B20, 15A03, 05C50</msc-class><journal-ref>Proc. 16th Intl. Symp. on Math. Th. of Networks and Systems
  (MTNS), Leuven, Belgium, July 5-9, 2004,B. de Moor, B. Motmans, J. Willems,
  P. Van Dooren, and V. Blondel, editors. ISBN 0-5682-517-8</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the maximum rank of block lower triangular Toeplitz block
matrices equals their term rank if the blocks fulfill a structural condition,
i.e., only the locations but not the values of their nonzeros are fixed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4288</identifier>
 <datestamp>2013-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4288</id><created>2013-05-18</created><updated>2013-07-17</updated><authors><author><keyname>Galliani</keyname><forenames>Pietro</forenames><affiliation>University of Helsinki</affiliation></author></authors><title>Upwards Closed Dependencies in Team Semantics</title><categories>math.LO cs.LO</categories><comments>In Proceedings GandALF 2013, arXiv:1307.4162</comments><proxy>EPTCS</proxy><acm-class>F.4.1</acm-class><journal-ref>EPTCS 119, 2013, pp. 93-106</journal-ref><doi>10.4204/EPTCS.119.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that adding upwards closed first-order dependency atoms to
first-order logic with team semantics does not increase its expressive power
(with respect to sentences), and that the same remains true if we also add
constancy atoms. As a consequence, the negations of functional dependence,
conditional independence, inclusion and exclusion atoms can all be added to
first-order logic without increasing its expressive power.
  Furthermore, we define a class of bounded upwards closed dependencies and we
prove that unbounded dependencies cannot be defined in terms of bounded ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4298</identifier>
 <datestamp>2015-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4298</id><created>2013-05-18</created><authors><author><keyname>Wu</keyname><forenames>Yue</forenames></author><author><keyname>Tracey</keyname><forenames>Brian</forenames></author><author><keyname>Natarajan</keyname><forenames>Premkumar</forenames></author><author><keyname>Noonan</keyname><forenames>Joseph P.</forenames></author></authors><title>Blockwise SURE Shrinkage for Non-Local Means</title><categories>cs.CV</categories><journal-ref>Signal Processing 103 (2014): 45-59</journal-ref><doi>10.1016/j.sigpro.2014.01.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we investigate the shrinkage problem for the non-local means
(NLM) image denoising. In particular, we derive the closed-form of the optimal
blockwise shrinkage for NLM that minimizes the Stein's unbiased risk estimator
(SURE). We also propose a constant complexity algorithm allowing fast blockwise
shrinkage. Simulation results show that the proposed blockwise shrinkage method
improves NLM performance in attaining higher peak signal noise ratio (PSNR) and
structural similarity index (SSIM), and makes NLM more robust against parameter
changes. Similar ideas can be applicable to other patchwise image denoising
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4299</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4299</id><created>2013-05-18</created><authors><author><keyname>Piedrah&#xed;ta</keyname><forenames>Pablo</forenames></author><author><keyname>Borge-Holthoefer</keyname><forenames>Javier</forenames></author><author><keyname>Moreno</keyname><forenames>Yamir</forenames></author><author><keyname>Arenas</keyname><forenames>Alex</forenames></author></authors><title>Modeling self-sustained activity cascades in socio-technical networks</title><categories>physics.soc-ph cs.SI</categories><comments>5 pages, 3 figures</comments><doi>10.1209/0295-5075/104/48004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to understand and eventually predict the emergence of information
and activation cascades in social networks is core to complex socio-technical
systems research. However, the complexity of social interactions makes this a
challenging enterprise. Previous works on cascade models assume that the
emergence of this collective phenomenon is related to the activity observed in
the local neighborhood of individuals, but do not consider what determines the
willingness to spread information in a time-varying process. Here we present a
mechanistic model that accounts for the temporal evolution of the individual
state in a simplified setup. We model the activity of the individuals as a
complex network of interacting integrate-and-fire oscillators. The model
reproduces the statistical characteristics of the cascades in real systems, and
provides a framework to study time-evolution of cascades in a state-dependent
activity scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4300</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4300</id><created>2013-05-18</created><authors><author><keyname>Krivulin</keyname><forenames>Nikolai</forenames></author></authors><title>Solution of linear equations and inequalities in idempotent vector
  spaces</title><categories>math.OC cs.SY</categories><comments>24 pages, 8 figures</comments><msc-class>15A80 (Primary), 65K10, 65F05, 12K10 (Secondary)</msc-class><journal-ref>International Journal of Applied Mathematics and Informatics,
  2013. Vol.7, no.1, pp.14-23. ISSN 2074-1278</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear vector equations and inequalities are considered defined in terms of
idempotent mathematics. To solve the equations, we apply an approach that is
based on the analysis of distances between vectors in idempotent vector spaces.
The approach reduces the solution of the equation to that of an optimization
problem in the idempotent algebra setting. Based on the approach, existence and
uniqueness conditions are established for the solution of equations, and a
general solution to both linear equations and inequalities are given. Finally,
a problem of simultaneous solution of equations and inequalities is also
considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4308</identifier>
 <datestamp>2013-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4308</id><created>2013-05-18</created><updated>2013-07-05</updated><authors><author><keyname>Ene</keyname><forenames>Alina</forenames></author><author><keyname>Korula</keyname><forenames>Nitish</forenames></author><author><keyname>Vakilian</keyname><forenames>Ali</forenames></author></authors><title>Connected Domatic Packings in Node-capacitated Graphs</title><categories>cs.DS cs.DM</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A set of vertices in a graph is a dominating set if every vertex outside the
set has a neighbor in the set. A dominating set is connected if the subgraph
induced by its vertices is connected. The connected domatic partition problem
asks for a partition of the nodes into connected dominating sets. The connected
domatic number of a graph is the size of a largest connected domatic partition
and it is a well-studied graph parameter with applications in the design of
wireless networks. In this note, we consider the fractional counterpart of the
connected domatic partition problem in \emph{node-capacitated} graphs. Let $n$
be the number of nodes in the graph and let $k$ be the minimum capacity of a
node separator in $G$. Fractionally we can pack at most $k$ connected
dominating sets subject to the capacities on the nodes, and our algorithms
construct packings whose sizes are proportional to $k$. Some of our main
contributions are the following: \begin{itemize} \item An algorithm for
constructing a fractional connected domatic packing of size $\Omega(k)$ for
node-capacitated planar and minor-closed families of graphs. \item An algorithm
for constructing a fractional connected domatic packing of size $\Omega(k /
\ln{n})$ for node-capacitated general graphs. \end{itemize}
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4311</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4311</id><created>2013-05-18</created><authors><author><keyname>Singh</keyname><forenames>Kuwar Pratap</forenames></author><author><keyname>Gupta</keyname><forenames>P K</forenames></author><author><keyname>Singh</keyname><forenames>G</forenames></author></authors><title>Performance Evaluation of Enhanced Interior Gateway Routing Protocol in
  IPv6 Network</title><categories>cs.NI</categories><comments>6 pages</comments><doi>10.5120/11962-7802</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the explosive growth in communication and network technologies, there is
a great demand of IPv6 addressing scheme. However, the modern operating systems
has option for this and with the development of IPv6 which removes the
limitations imposed by IPv4 and provides the large number of address space. In
this paper, authors have considered the Enhanced Interior Gateway Routing
Protocol and presented a scenario for its performance evaluation in IPv6
networks and obtained results are highly considerable for the short distance of
communication and don't represent any problem of performance degradation while
sending or receiving the data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4314</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4314</id><created>2013-05-18</created><authors><author><keyname>Satpathy</keyname><forenames>Sanket</forenames></author><author><keyname>Cuff</keyname><forenames>Paul</forenames></author></authors><title>Secure Cascade Channel Synthesis</title><categories>cs.IT math.IT</categories><comments>ISIT 2013, 5 pages, uses IEEEtran.cls</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate channel synthesis in a cascade setting where nature provides
an iid sequence $X^n$ at node 1. Node 1 can send a message at rate $R_1$ to
node 2 and node 2 can send a message at rate $R_2$ to node 3. Additionally, all
3 nodes share bits of common randomness at rate $R_0$. We want to generate
sequences $Y^n$ and $Z^n$ along nodes in the cascade such that $(X^n,Y^n,Z^n)$
appears to be appropriately correlated and iid even to an eavesdropper who is
cognizant of the messages being sent. We characterize the optimal tradeoff
between the amount of common randomness used and the required rates of
communication. We also solve the problem for arbitrarily long cascades and
provide an inner bound for cascade channel synthesis without an eavesdropper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4319</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4319</id><created>2013-05-18</created><authors><author><keyname>Mori</keyname><forenames>Hiromu</forenames></author><author><keyname>Matsumoto</keyname><forenames>Yoshihiro</forenames></author><author><keyname>Kryssanov</keyname><forenames>Victor</forenames></author><author><keyname>Cooper</keyname><forenames>Eric</forenames></author><author><keyname>Ogawa</keyname><forenames>Hitoshi</forenames></author><author><keyname>Makino</keyname><forenames>Shoji</forenames></author><author><keyname>Struzik</keyname><forenames>Zbigniew R.</forenames></author><author><keyname>Rutkowski</keyname><forenames>Tomasz M.</forenames></author></authors><title>Multi-command Tactile Brain Computer Interface: A Feasibility Study</title><categories>q-bio.NC cs.HC</categories><comments>Haptic and Audio Interaction Design 2013, Daejeon, Korea, April
  18-19, 2013, 15 pages, 4 figures, The final publication will be available at
  link.springer.com</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study presented explores the extent to which tactile stimuli delivered to
the ten digits of a BCI-naive subject can serve as a platform for a brain
computer interface (BCI) that could be used in an interactive application such
as robotic vehicle operation. The ten fingertips are used to evoke
somatosensory brain responses, thus defining a tactile brain computer interface
(tBCI). Experimental results on subjects performing online (real-time) tBCI,
using stimuli with a moderately fast inter-stimulus-interval (ISI), provide a
validation of the tBCI prototype, while the feasibility of the concept is
illuminated through information-transfer rates obtained through the case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4324</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4324</id><created>2013-05-19</created><authors><author><keyname>Bartlett</keyname><forenames>Peter</forenames></author><author><keyname>Grunwald</keyname><forenames>Peter</forenames></author><author><keyname>Harremoes</keyname><forenames>Peter</forenames></author><author><keyname>Hedayati</keyname><forenames>Fares</forenames></author><author><keyname>Kotlowski</keyname><forenames>Wojciech</forenames></author></authors><title>Horizon-Independent Optimal Prediction with Log-Loss in Exponential
  Families</title><categories>cs.LG stat.ML</categories><comments>23 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study online learning under logarithmic loss with regular parametric
models. Hedayati and Bartlett (2012b) showed that a Bayesian prediction
strategy with Jeffreys prior and sequential normalized maximum likelihood
(SNML) coincide and are optimal if and only if the latter is exchangeable, and
if and only if the optimal strategy can be calculated without knowing the time
horizon in advance. They put forward the question what families have
exchangeable SNML strategies. This paper fully answers this open problem for
one-dimensional exponential families. The exchangeability can happen only for
three classes of natural exponential family distributions, namely the Gaussian,
Gamma, and the Tweedie exponential family of order 3/2. Keywords: SNML
Exchangeability, Exponential Family, Online Learning, Logarithmic Loss,
Bayesian Strategy, Jeffreys Prior, Fisher Information1
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4328</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4328</id><created>2013-05-19</created><updated>2014-01-21</updated><authors><author><keyname>Gleeson</keyname><forenames>James P.</forenames></author><author><keyname>Ward</keyname><forenames>Jonathan A.</forenames></author><author><keyname>O'Sullivan</keyname><forenames>Kevin P.</forenames></author><author><keyname>Lee</keyname><forenames>William T.</forenames></author></authors><title>Competition-induced criticality in a model of meme popularity</title><categories>physics.soc-ph cs.SI nlin.AO</categories><comments>This version accepted for publication in Physical Review Letters. 6
  pages main text, 12 pages Supplementary Material</comments><journal-ref>Phys. Rev. Lett. 112, 048701 (2014)</journal-ref><doi>10.1103/PhysRevLett.112.048701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Heavy-tailed distributions of meme popularity occur naturally in a model of
meme diffusion on social networks. Competition between multiple memes for the
limited resource of user attention is identified as the mechanism that poises
the system at criticality. The popularity growth of each meme is described by a
critical branching process, and asymptotic analysis predicts power-law
distributions of popularity with very heavy tails (exponent $\alpha&lt;2$, unlike
preferential-attachment models), similar to those seen in empirical data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4330</identifier>
 <datestamp>2013-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4330</id><created>2013-05-19</created><updated>2013-12-10</updated><authors><author><keyname>Enge</keyname><forenames>Andreas</forenames><affiliation>INRIA Bordeaux - Sud-Ouest</affiliation></author><author><keyname>Thom&#xe9;</keyname><forenames>Emmanuel</forenames><affiliation>INRIA Nancy - Grand Est / LORIA</affiliation></author></authors><title>Computing class polynomials for abelian surfaces</title><categories>cs.CR math.NT</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a quasi-linear algorithm for computing Igusa class polynomials of
Jacobians of genus 2 curves via complex floating-point approximations of their
roots. After providing an explicit treatment of the computations in quartic CM
fields and their Galois closures, we pursue an approach due to Dupont for
evaluating $\theta$- constants in quasi-linear time using Newton iterations on
the Borchardt mean. We report on experiments with our implementation and
present an example with class number 17608.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4339</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4339</id><created>2013-05-19</created><authors><author><keyname>Hamada</keyname><forenames>Michiaki</forenames></author><author><keyname>Kiryu</keyname><forenames>Hisanori</forenames></author><author><keyname>Iwasaki</keyname><forenames>Wataru</forenames></author><author><keyname>Asai</keyname><forenames>Kiyoshi</forenames></author></authors><title>Generalized Centroid Estimators in Bioinformatics</title><categories>q-bio.QM cs.LG</categories><comments>35 pages. This is a corrected version of the published paper: PLoS
  ONE 6(2):e16450, 2011. The original version is available from
  http://www.plosone.org/article/info:doi/10.1371/journal.pone.0016450</comments><journal-ref>PLoS ONE 6(2):e16450, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a number of estimation problems in bioinformatics, accuracy measures of
the target problem are usually given, and it is important to design estimators
that are suitable to those accuracy measures. However, there is often a
discrepancy between an employed estimator and a given accuracy measure of the
problem. In this study, we introduce a general class of efficient estimators
for estimation problems on high-dimensional binary spaces, which representmany
fundamental problems in bioinformatics. Theoretical analysis reveals that the
proposed estimators generally fit with commonly-used accuracy measures (e.g.
sensitivity, PPV, MCC and F-score) as well as it can be computed efficiently in
many cases, and cover a wide range of problems in bioinformatics from the
viewpoint of the principle of maximum expected accuracy (MEA). It is also shown
that some important algorithms in bioinformatics can be interpreted in a
unified manner. Not only the concept presented in this paper gives a useful
framework to design MEA-based estimators but also it is highly extendable and
sheds new light on many problems in bioinformatics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4345</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4345</id><created>2013-05-19</created><authors><author><keyname>Schclar</keyname><forenames>Alon</forenames></author><author><keyname>Rokach</keyname><forenames>Lior</forenames></author><author><keyname>Amit</keyname><forenames>Amir</forenames></author></authors><title>Ensembles of Classifiers based on Dimensionality Reduction</title><categories>cs.LG</categories><comments>31 pages, 4 figures, 4 tables, Submitted to Pattern Analysis and
  Applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel approach for the construction of ensemble classifiers
based on dimensionality reduction. Dimensionality reduction methods represent
datasets using a small number of attributes while preserving the information
conveyed by the original dataset. The ensemble members are trained based on
dimension-reduced versions of the training set. These versions are obtained by
applying dimensionality reduction to the original training set using different
values of the input parameters. This construction meets both the diversity and
accuracy criteria which are required to construct an ensemble classifier where
the former criterion is obtained by the various input parameter values and the
latter is achieved due to the decorrelation and noise reduction properties of
dimensionality reduction. In order to classify a test sample, it is first
embedded into the dimension reduced space of each individual classifier by
using an out-of-sample extension algorithm. Each classifier is then applied to
the embedded sample and the classification is obtained via a voting scheme. We
present three variations of the proposed approach based on the Random
Projections, the Diffusion Maps and the Random Subspaces dimensionality
reduction algorithms. We also present a multi-strategy ensemble which combines
AdaBoost and Diffusion Maps. A comparison is made with the Bagging, AdaBoost,
Rotation Forest ensemble classifiers and also with the base classifier which
does not incorporate dimensionality reduction. Our experiments used seventeen
benchmark datasets from the UCI repository. The results obtained by the
proposed algorithms were superior in many cases to other algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4348</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4348</id><created>2013-05-19</created><authors><author><keyname>Namiot</keyname><forenames>Dmitry</forenames></author><author><keyname>Sneps-Sneppe</keyname><forenames>Manfred</forenames></author></authors><title>Mobile Services and Network Proximity</title><categories>cs.NI</categories><comments>6 pages. arXiv admin note: text overlap with arXiv:1303.5175</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses several practical use cases for deploying network
proximity in mobile services. Our research presents here mobile services
oriented for either discovering new data for mobile subscribers or for
delivering some customized information to them. All applications share the same
approach and use the common platform, based on the Wi-Fi proximity. The typical
deployment areas for our approach are context-aware services and ubiquitous
computing applications. Our own examples include proximity marketing as the
model use case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4359</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4359</id><created>2013-05-19</created><authors><author><keyname>Scott</keyname><forenames>Michael James</forenames></author><author><keyname>Ghinea</keyname><forenames>Gheorghita</forenames></author></authors><title>Promoting Game Accessibility: Experiencing an Induction on Inclusive
  Design Practice at the Global Games Jam</title><categories>cs.CY</categories><comments>Presented at the Conference on the Foundations of Digital Games
  (Inaugural Workshop on the Global Games Jam), May 14-17, 2013, Chania, Greece</comments><acm-class>K.3.2</acm-class><journal-ref>Proceedings of the Inaugural Workshop on the Global Games Jam
  (2013) SASDG: Santa Cruz, California. 17--20</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Global Games Jam (GGJ) attracts many people who are passionate about
games development, coming from a range of educational backgrounds. Therefore,
the event can be experienced by novices and student developers as an
opportunity for learning. This provides an opening to promote themes and ideas
that could help form future thinking about games design, emerging as a form of
induction on key design issues for new practitioners. Such an approach aims to
raise awareness about issues which learners could help develop and take with
them into industry. However, the experience itself affords a deep experiential
rhetoric and dialogue with experts that could be an effective pedagogical tool
for issues seldom addressed deeply in formal educational settings. This paper
describes an account by one such individual, being introduced to game
accessibility through participation in the GGJ. As such, it is not intended as
a rigorous empirical analysis, but rather a perspective on one way a game jam
can be experienced, inviting further research on the topic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4365</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4365</id><created>2013-05-19</created><authors><author><keyname>Koundinya</keyname><forenames>Anjan K.</forenames></author><author><keyname>G.</keyname><forenames>Harish</forenames></author><author><keyname>K.</keyname><forenames>Srinath N.</forenames></author><author><keyname>E.</keyname><forenames>Raghavendra G.</forenames></author><author><keyname>V.</keyname><forenames>Pramod Y.</forenames></author><author><keyname>R.</keyname><forenames>Sandeep</forenames></author><author><keyname>G</keyname><forenames>Punith Kumar</forenames></author></authors><title>Performance Analysis of Parallel Pollard's Rho Algorithm</title><categories>cs.DC</categories><comments>8 pages, 4 figures, Journal</comments><doi>10.5121/ijcsit.2013.5214</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Integer factorization is one of the vital algorithms discussed as a part of
analysis of any black-box cipher suites where the cipher algorithm is based on
number theory. The origin of the problem is from Discrete Logarithmic Problem
which appears under the analysis of the crypto-graphic algorithms as seen by a
crypt-analyst. The integer factorization algorithm poses a potential in
computational science too, obtaining the factors of a very large number is
challenging with a limited computing infrastructure. This paper analyses the
Pollards Rho heuristic with a varying input size to evaluate the performance
under a multi-core environment and also to estimate the threshold for each
computing infrastructure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4367</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4367</id><created>2013-05-19</created><authors><author><keyname>Jolly</keyname><forenames>Rapha&#xeb;l</forenames></author></authors><title>Parallelizing Stream with Future</title><categories>cs.DC</categories><acm-class>D.3.3; G.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stream is re-interpreted in terms of a Lazy monad. Future is substituted for
Lazy in the obtained construct, resulting in possible parallelization of any
algorithm expressible as a Stream computation. The principle is tested against
two example algorithms. Performance is evaluated, and a way to improve it
briefly discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4372</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4372</id><created>2013-05-19</created><updated>2013-05-26</updated><authors><author><keyname>Qin</keyname><forenames>Junjie</forenames></author><author><keyname>Zhang</keyname><forenames>Baosen</forenames></author><author><keyname>Rajagopal</keyname><forenames>Ram</forenames></author></authors><title>Risk Limiting Dispatch with Ramping Constraints</title><categories>math.OC cs.SY</categories><comments>Shorter version submitted to smartgrid comm 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reliable operation in power systems is becoming more difficult as the
penetration of random renewable resources increases. In particular, operators
face the risk of not scheduling enough traditional generators in the times when
renewable energies becomes lower than expected. In this paper we study the
optimal trade-off between system and risk, and the cost of scheduling reserve
generators. We explicitly model the ramping constraints on the generators. We
model the problem as a multi-period stochastic control problem, and we show the
structure of the optimal dispatch. We then show how to efficiently compute the
dispatch using two methods: i) solving a surrogate chance constrained program,
ii) a MPC-type look ahead controller. Using real world data, we show the chance
constrained dispatch outperforms the MPC controller and is also robust to
changes in the probability distribution of the renewables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4375</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4375</id><created>2013-05-19</created><authors><author><keyname>Paporovic</keyname><forenames>Sasa</forenames></author></authors><title>Realized collaboration across borders - Linux and the bioinformatic part</title><categories>cs.CY</categories><comments>6 pages, 2 figures, 1 table</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In year 2006 Biolinux inter alia with the work of Tim Booth gives its rise
and provide an operating system that was and is specialized in providing an
environment for the needs of bioinformatics. Since than some years have been
seen and the information about Biolinux has not only widespread within the
bio-science community, also the Linux community at whole had a ear for it. This
has caused a process called collaboration across borders and makes as the
keywords say the different work groups cooperating together. In this paper we
will have a look into the history of this collaboration, will show its growth
until we reach the actual state and we will talk about the quo vadis of this
process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4376</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4376</id><created>2013-05-19</created><authors><author><keyname>Swierczewski</keyname><forenames>Lukasz</forenames></author></authors><title>3DES ECB Optimized for Massively Parallel CUDA GPU Architecture</title><categories>cs.DC</categories><comments>4 pages, 4 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Modern computers have graphics cards with much higher theoretical efficiency
than conventional CPU. The paper presents application possibilities GPU CUDA
acceleration for encryption of data using the new architecture tailored to the
3DES algorithm, characterized by increased security compared to the normal DES.
The algorithm used in ECB mode (Electronic Codebook), in which 64-bit data
blocks are encrypted independently by stream processors (CUDA cores).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4378</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4378</id><created>2013-05-19</created><authors><author><keyname>Karanxha</keyname><forenames>Klajdi</forenames></author><author><keyname>Vallipuram</keyname><forenames>Kapies</forenames></author><author><keyname>Sonfack</keyname><forenames>Herman</forenames></author><author><keyname>Pereira</keyname><forenames>Gustavo Barbieri</forenames></author></authors><title>Software Requirements Specification - Softbody Simulation System</title><categories>cs.SE</categories><comments>arXiv admin note: text overlap with arXiv:1212.6250 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this document is to give the vision for interactive computer
graphics physical based simulation systems. It focuses on the needs of
stakeholders and the reasons for such needs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4389</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4389</id><created>2013-05-19</created><authors><author><keyname>Sergeev</keyname><forenames>Igor S.</forenames></author></authors><title>Implementation of linear maps with circulant matrices via modulo 2
  rectifier circuits of bounded depth</title><categories>cs.DS</categories><comments>3 pages, in English; 4 pages, in Russian</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present note we show that for any positive integer k an arbitrary
Boolean circulant matrix can be implemented via modulo 2 rectifier circuit of
depth 2k-1 and complexity O(n^{1+1/k}), and also via circuit of depth 2k and
complexity O(n^{1+1/k} log^{-1/k} n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4401</identifier>
 <datestamp>2013-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4401</id><created>2013-05-19</created><updated>2013-10-03</updated><authors><author><keyname>Kalka</keyname><forenames>Arkadius</forenames></author><author><keyname>Teicher</keyname><forenames>Mina</forenames></author></authors><title>Non-associative key establishment for left distributive systems</title><categories>cs.CR math.GR</categories><comments>19 pages. arXiv admin note: text overlap with arXiv:1210.8270 Version
  written in documentclass amsart</comments><msc-class>20N02 (Primary) 20F36 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct non-associative key establishment protocols for all left
self-distributive (LD), multi-LD-, and other left distributive systems.
Instantiations of these protocols using generalized shifted conjugacy in braid
groups lead to instances of a natural and apparently new group-theoretic
problem, which we call the (subgroup) conjugacy coset problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4403</identifier>
 <datestamp>2015-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4403</id><created>2013-05-19</created><updated>2015-10-08</updated><authors><author><keyname>Agrawal</keyname><forenames>Mayur</forenames></author><author><keyname>Love</keyname><forenames>David</forenames></author><author><keyname>Balakrishnan</keyname><forenames>Venkataramanan</forenames></author></authors><title>Communicating over Filter-and-Forward Relay Networks with Channel Output
  Feedback</title><categories>cs.IT math.IT</categories><comments>15 pages, 8 figures, to appear in IEEE Transactions on Signal
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Relay networks aid in increasing the rate of communication from source to
destination. However, the capacity of even a three-terminal relay channel is an
open problem. In this work, we propose a new lower bound for the capacity of
the three-terminal relay channel with destination-to-source feedback in the
presence of correlated noise. Our lower bound improves on the existing bounds
in the literature. We then extend our lower bound to general relay network
configurations using an arbitrary number of filter-and-forward relay nodes.
Such network configurations are common in many multi-hop communication systems
where the intermediate nodes can only perform minimal processing due to limited
computational power. Simulation results show that significant improvements in
the achievable rate can be obtained through our approach. We next derive a
coding strategy (optimized using post processed signal-to-noise ratio as a
criterion) for the three-terminal relay channel with noisy channel output
feedback for two transmissions. This coding scheme can be used in conjunction
with open-loop codes for applications like automatic repeat request (ARQ) or
hybrid-ARQ.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4419</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4419</id><created>2013-05-19</created><authors><author><keyname>Mukherjee</keyname><forenames>Amitav</forenames></author></authors><title>Imbalanced Beamforming by a Multi-antenna Source for Secure Utilization
  of an Untrusted Relay</title><categories>cs.IT math.IT</categories><comments>To appear, IEEE Communications Letters, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate a relay network where a multiantenna source can potentially
utilize an unauthenticated (untrusted) relay to augment its direct transmission
of a confidential message to the destination. Since the relay is untrusted, it
is desirable to protect the confidential data from it while simultaneously
making use of it to increase the reliability of the transmission. We present a
low-complexity scheme denoted as imbalanced beamforming based on linear
beamforming and constellation mapping that ensures perfect physical-layer
security even while utilizing the untrusted relay. Furthermore, the security of
the scheme holds even if the relay adopts the conventional decodeand- forward
protocol, unlike prior work. Simulation results show that the proposed
imbalanced signaling maintains a constant BER of 0.5 at the eavesdropper at any
SNR and number of source antennas, while maintaining or improving the detection
performance of the destination compared to not utilizing the relay or existing
security methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4429</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4429</id><created>2013-05-19</created><authors><author><keyname>Lin</keyname><forenames>Youfang</forenames></author><author><keyname>Jia</keyname><forenames>Xuguang</forenames></author><author><keyname>Lin</keyname><forenames>Mingjie</forenames></author><author><keyname>Gregory</keyname><forenames>Steve</forenames></author><author><keyname>Wan</keyname><forenames>Huaiyu</forenames></author><author><keyname>Wu</keyname><forenames>Zhihao</forenames></author></authors><title>Inferring High Quality Co-Travel Networks</title><categories>cs.SI physics.soc-ph</categories><comments>20 pages, 23 figures</comments><acm-class>H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social networks provide a new perspective for enterprises to better
understand their customers and have attracted substantial attention in
industry. However, inferring high quality customer social networks is a great
challenge while there are no explicit customer relations in many traditional
OLTP environments. In this paper, we study this issue in the field of passenger
transport and introduce a new member to the family of social networks, which is
named Co-Travel Networks, consisting of passengers connected by their co-travel
behaviors. We propose a novel method to infer high quality co-travel networks
of civil aviation passengers from their co-booking behaviors derived from the
PNRs (Passenger Naming Records). In our method, to accurately evaluate the
strength of ties, we present a measure of Co-Journey Times to count the
co-travel times of complete journeys between passengers. We infer a high
quality co-travel network based on a large encrypted PNR dataset and conduct a
series of network analyses on it. The experimental results show the
effectiveness of our inferring method, as well as some special characteristics
of co-travel networks, such as the sparsity and high aggregation, compared with
other kinds of social networks. It can be expected that such co-travel networks
will greatly help the industry to better understand their passengers so as to
improve their services. More importantly, we contribute a special kind of
social networks with high strength of ties generated from very close and high
cost travel behaviors, for further scientific researches on human travel
behaviors, group travel patterns, high-end travel market evolution, etc., from
the perspective of social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4433</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4433</id><created>2013-05-20</created><authors><author><keyname>Kong</keyname><forenames>Xiangnan</forenames></author><author><keyname>Cao</keyname><forenames>Bokai</forenames></author><author><keyname>Yu</keyname><forenames>Philip S.</forenames></author><author><keyname>Ding</keyname><forenames>Ying</forenames></author><author><keyname>Wild</keyname><forenames>David J.</forenames></author></authors><title>Meta Path-Based Collective Classification in Heterogeneous Information
  Networks</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collective classification has been intensively studied due to its impact in
many important applications, such as web mining, bioinformatics and citation
analysis. Collective classification approaches exploit the dependencies of a
group of linked objects whose class labels are correlated and need to be
predicted simultaneously. In this paper, we focus on studying the collective
classification problem in heterogeneous networks, which involves multiple types
of data objects interconnected by multiple types of links. Intuitively, two
objects are correlated if they are linked by many paths in the network.
However, most existing approaches measure the dependencies among objects
through directly links or indirect links without considering the different
semantic meanings behind different paths. In this paper, we study the
collective classification problem taht is defined among the same type of
objects in heterogenous networks. Moreover, by considering different linkage
paths in the network, one can capture the subtlety of different types of
dependencies among objects. We introduce the concept of meta-path based
dependencies among objects, where a meta path is a path consisting a certain
sequence of linke types. We show that the quality of collective classification
results strongly depends upon the meta paths used. To accommodate the large
network size, a novel solution, called HCC (meta-path based Heterogenous
Collective Classification), is developed to effectively assign labels to a
group of instances that are interconnected through different meta-paths. The
proposed HCC model can capture different types of dependencies among objects
with respect to different meta paths. Empirical studies on real-world networks
demonstrate that effectiveness of the proposed meta path-based collective
classification approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4440</identifier>
 <datestamp>2013-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4440</id><created>2013-05-20</created><updated>2013-07-01</updated><authors><author><keyname>SaiToh</keyname><forenames>Akira</forenames></author></authors><title>Realistic cost for the model of coherent computing</title><categories>quant-ph cs.CC</categories><comments>10 pages, 1 figure, v2: proof of Proposition 1 modified, v3: major
  revision, more detailed explanation in the proof</comments><msc-class>68Q10, 68Q17</msc-class><acm-class>C.4</acm-class><journal-ref>in Proc. TQC 2013 (LIPIcs vol.22), pp.244-253 (2013)</journal-ref><doi>10.4230/LIPIcs.TQC.2013.244</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the model of so-called coherent computing recently proposed by Yamamoto
et al. [Y. Yamamoto et al., New Gen. Comput. 30 (2012) 327-355], a theoretical
analysis of the success probability is given. Although it was claimed as their
prospect that the Ising spin configuration problem would be efficiently
solvable in the model, here it is shown that the probability of finding a
desired spin configuration decreases exponentially in the number of spins for
certain hard instances. The model is thus physically unfeasible for solving the
problem within a polynomial cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4443</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4443</id><created>2013-05-20</created><authors><author><keyname>Ziatdinov</keyname><forenames>Rushan</forenames></author><author><keyname>Musa</keyname><forenames>Sajid</forenames></author></authors><title>Rapid mental computation system as a tool for algorithmic thinking of
  elementary school students development</title><categories>cs.CY</categories><journal-ref>European Researcher 25 (7), 1105-1110, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we describe the possibilities of using a rapid mental
computation system in elementary education. The system consists of a number of
readily memorized operations that allow one to perform arithmetic computations
very quickly. These operations are actually simple algorithms which can develop
or improve the algorithmic thinking of pupils. Using a rapid mental computation
system allows forming the basis for the study of computer science in secondary
school.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4444</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4444</id><created>2013-05-20</created><authors><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Li</keyname><forenames>Xinran</forenames></author><author><keyname>Fu</keyname><forenames>Fang-Wei</forenames></author></authors><title>Multi-receiver Authentication Scheme for Multiple Messages Based on
  Linear Codes</title><categories>cs.CR cs.IT math.IT</categories><comments>16 pages. arXiv admin note: substantial text overlap with
  arXiv:1303.0930</comments><msc-class>94A62</msc-class><acm-class>D.4.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we construct an authentication scheme for multi-receivers and
multiple messages based on a linear code $C$. This construction can be regarded
as a generalization of the authentication scheme given by Safavi-Naini and
Wang. Actually, we notice that the scheme of Safavi-Naini and Wang is
constructed with Reed-Solomon codes. The generalization to linear codes has the
similar advantages as generalizing Shamir's secret sharing scheme to linear
secret sharing sceme based on linear codes. For a fixed message base field
$\f$, our scheme allows arbitrarily many receivers to check the integrity of
their own messages, while the scheme of Safavi-Naini and Wang has a constraint
on the number of verifying receivers $V\leqslant q$. And we introduce access
structure in our scheme. Massey characterized the access structure of linear
secret sharing scheme by minimal codewords in the dual code whose first
component is 1. We slightly modify the definition of minimal codewords in
\cite{Massey93}. Let $C$ be a $[V,k]$ linear code. For any coordinate $i\in
\{1,2,\cdots,V\}$, a codeword $\vec{c}$ in $C$ is called minimal respect to $i$
if the codeword $\vec{c}$ has component 1 at the $i$-th coordinate and there is
no other codeword whose $i$-th component is 1 with support strictly contained
in that of $\vec{c}$. Then the security of receiver $R_i$ in our authentication
scheme is characterized by the minimal codewords respect to $i$ in the dual
code $C^\bot$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4446</identifier>
 <datestamp>2014-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4446</id><created>2013-05-20</created><updated>2014-07-21</updated><authors><author><keyname>Bigot</keyname><forenames>J&#xe9;r&#xe9;mie</forenames><affiliation>DMIA</affiliation></author><author><keyname>Boyer</keyname><forenames>Claire</forenames><affiliation>IMT</affiliation></author><author><keyname>Weiss</keyname><forenames>Pierre</forenames><affiliation>ITAV</affiliation></author></authors><title>An analysis of block sampling strategies in compressed sensing</title><categories>cs.IT math.IT math.ST stat.TH</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing is a theory which guarantees the exact recovery of sparse
signals from a small number of linear projections. The sampling schemes
suggested by current compressed sensing theories are often of little practical
relevance since they cannot be implemented on real acquisition systems. In this
paper, we study a new random sampling approach that consists in projecting the
signal over blocks of sensing vectors. A typical example is the case of blocks
made of horizontal lines in the 2D Fourier plane. We provide theoretical
results on the number of blocks that are required for exact sparse signal
reconstruction. This number depends on two properties named intra and
inter-support block coherence. We then show through a series of examples
including Gaussian measurements, isolated measurements or blocks in
time-frequency bases, that the main result is sharp in the sense that the
minimum amount of blocks necessary to reconstruct sparse signals cannot be
improved up to a multiplicative logarithmic factor. The proposed results
provide a good insight on the possibilities and limits of block compressed
sensing in imaging devices such as magnetic resonance imaging,
radio-interferometry or ultra-sound imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4447</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4447</id><created>2013-05-20</created><authors><author><keyname>Duchamp</keyname><forenames>G&#xe9;rard Henry Edmond</forenames><affiliation>LIPN</affiliation></author><author><keyname>Kane</keyname><forenames>Ladji</forenames><affiliation>LIPN</affiliation></author><author><keyname>Minh</keyname><forenames>Vincel Hoang Ngoc</forenames><affiliation>LIPN</affiliation></author><author><keyname>Tollu</keyname><forenames>Christophe</forenames><affiliation>LIPN</affiliation></author></authors><title>Dual bases for non commutative symmetric and quasi-symmetric functions
  via monoidal factorization</title><categories>math.CO cs.SC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, an effective construction, via Sch\&quot;utzenberger's monoidal
factorization, of dual bases for the non commutative symmetric and
quasi-symmetric functions is proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4450</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4450</id><created>2013-05-20</created><authors><author><keyname>Bui</keyname><forenames>Chen</forenames><affiliation>LIPN</affiliation></author><author><keyname>Duchamp</keyname><forenames>G&#xe9;rard Henry Edmond</forenames><affiliation>LIPN</affiliation></author><author><keyname>Minh</keyname><forenames>Vincel Hoang Ngoc</forenames><affiliation>LIPN</affiliation></author></authors><title>Sch\&quot;utzenberger's factorization on the (completed) Hopf algebra of
  $q-$stuffle product</title><categories>math.CO cs.SC</categories><comments>arXiv admin note: text overlap with arXiv:1302.5391</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to extend the Sch\&quot;utzenberger's factorization, the combinatorial
Hopf algebra of the $q$-stuffles product is developed systematically in a
parallel way with that of the shuffle product and and in emphasizing the Lie
elements as studied by Ree. In particular, we will give here an effective
construction of pair of bases in duality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4452</identifier>
 <datestamp>2015-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4452</id><created>2013-05-20</created><updated>2015-07-28</updated><authors><author><keyname>Dalcin</keyname><forenames>Lisandro</forenames></author><author><keyname>Collier</keyname><forenames>Nathan</forenames></author><author><keyname>Vignal</keyname><forenames>Philippe</forenames></author><author><keyname>Cortes</keyname><forenames>Adriano M. A.</forenames></author><author><keyname>Calo</keyname><forenames>V. M.</forenames></author></authors><title>PetIGA: A Framework for High-Performance Isogeometric Analysis</title><categories>cs.MS math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present PetIGA, a code framework to approximate the solution of partial
differential equations using isogeometric analysis. PetIGA can be used to
assemble matrices and vectors which come from a Galerkin weak form, discretized
with Non-Uniform Rational B-spline basis functions. We base our framework on
PETSc, a high-performance library for the scalable solution of partial
differential equations, which simplifies the development of large-scale
scientific codes, provides a rich environment for prototyping, and separates
parallelism from algorithm choice. We describe the implementation of PetIGA,
and exemplify its use by solving a model nonlinear problem. To illustrate the
robustness and flexibility of PetIGA, we solve some challenging nonlinear
partial differential equations that include problems in both solid and fluid
mechanics. We show strong scaling results on up to 4096 cores, which confirm
the suitability of PetIGA for large scale simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4454</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4454</id><created>2013-05-20</created><updated>2013-05-30</updated><authors><author><keyname>Chakraborty</keyname><forenames>Shantanav</forenames></author><author><keyname>Banerjee</keyname><forenames>Subhashish</forenames></author><author><keyname>Adhikari</keyname><forenames>Satyabrata</forenames></author><author><keyname>Kumar</keyname><forenames>Atul</forenames></author></authors><title>Entanglement in the Grover's Search Algorithm</title><categories>quant-ph cs.DS</categories><comments>6 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum Algorithms have long captured the imagination of computer scientists
and physicists primarily because of the speed up achieved by them over their
classical counterparts using principles of quantum mechanics. Entanglement is
believed to be the primary phenomena behind this speed up. However their
precise role in quantum algorithms is yet unclear. In this article, we explore
the nature of entanglement in the Grover's search algorithm. This algorithm
enables searching of elements from an unstructured database quadratically
faster than the best known classical algorithm. Geometric measure of
entanglement has been used to quantify and analyse entanglement across
iterations of the algorithm. We reveal how the entanglement varies with
increase in the number of qubits and also with the number of marked or solution
states. Numerically, it is seen that the behaviour of the maximum value of
entanglement is monotonous with the number of qubits. Also, for a given value
of the number of qubits, a change in the marked states alters the amount of
entanglement. The amount of entanglement in the final state of the algorithm
has been shown to depend solely on the nature of the marked states. Explicit
analytical expressions are given showing the variation of entanglement with the
number of iterations and the global maximum value of entanglement attained
across all iterations of the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4455</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4455</id><created>2013-05-20</created><authors><author><keyname>Vandervalk</keyname><forenames>Ben P</forenames></author><author><keyname>McCarthy</keyname><forenames>E Luke</forenames></author><author><keyname>Wilkinson</keyname><forenames>Mark D</forenames></author></authors><title>SHARE: A Web Service Based Framework for Distributed Querying and
  Reasoning on the Semantic Web</title><categories>cs.DL cs.AI cs.SE</categories><comments>Third Asian Semantic Web Conference, ASWC2008 Bangkok, Thailand
  December 2008, Workshops Proceedings (NEFORS2008), pp69-78</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Here we describe the SHARE system, a web service based framework for
distributed querying and reasoning on the semantic web. The main innovations of
SHARE are: (1) the extension of a SPARQL query engine to perform on-demand data
retrieval from web services, and (2) the extension of an OWL reasoner to test
property restrictions by means of web service invocations. In addition to
enabling queries across distributed datasets, the system allows for a target
dataset that is significantly larger than is possible under current,
centralized approaches. Although the architecture is equally applicable to all
types of data, the SHARE system targets bioinformatics, due to the large number
of interoperable web services that are already available in this area. SHARE is
built entirely on semantic web standards, and is the successor of the BioMOBY
project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4508</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4508</id><created>2013-05-20</created><authors><author><keyname>Kaya</keyname><forenames>Abidin</forenames></author><author><keyname>Yildiz</keyname><forenames>Bahattin</forenames></author><author><keyname>Siap</keyname><forenames>&#x130;rfan</forenames></author></authors><title>Quadratic Residue Codes over F_p+vF_p and their Gray Images</title><categories>cs.IT math.IT</categories><comments>research article, under review since November 2012</comments><journal-ref>Journal of Pure and Applied Algebra Volume 218 Issue 11 2014</journal-ref><doi>10.1016/j.jpaa.2014.03.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper quadratic residue codes over the ring Fp + vFp are introduced
in terms of their idempotent generators. The structure of these codes is
studied and it is observed that these codes share similar properties with
quadratic residue codes over finite fields. For the case p = 2, Euclidean and
Hermitian self-dual families of codes as extended quadratic residue codes are
considered and two optimal Hermitian self-dual codes are obtained as examples.
Moreover, a substantial number of good p-ary codes are obtained as images of
quadratic residue codes over Fp +vFp in the cases where p is an odd prime.
These results are presented in tables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4519</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4519</id><created>2013-05-20</created><updated>2015-10-18</updated><authors><author><keyname>Fulek</keyname><forenames>Radoslav</forenames></author><author><keyname>Kyn&#x10d;l</keyname><forenames>Jan</forenames></author><author><keyname>Malinovi&#x107;</keyname><forenames>Igor</forenames></author><author><keyname>P&#xe1;lv&#xf6;lgyi</keyname><forenames>D&#xf6;m&#xf6;t&#xf6;r</forenames></author></authors><title>Clustered planarity testing revisited</title><categories>cs.CG cs.DM math.CO</categories><comments>27 pages, 18 figures; small corrections</comments><msc-class>05C10, 68R10, 15A06, 05B35</msc-class><acm-class>G.2.2</acm-class><journal-ref>The Electronic Journal of Combinatorics 22 (2015), Issue 4, P4.24,
  29 pp</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Hanani--Tutte theorem is a classical result proved for the first time in
the 1930s that characterizes planar graphs as graphs that admit a drawing in
the plane in which every pair of edges not sharing a vertex cross an even
number of times. We generalize this result to clustered graphs with two
disjoint clusters, and show that a straightforward extension to flat clustered
graphs with three or more disjoint clusters is not possible. For general
clustered graphs we show a variant of the Hanani--Tutte theorem in the case
when each cluster induces a connected subgraph. Di Battista and Frati proved
that clustered planarity of embedded clustered graphs whose every face is
incident with at most five vertices can be tested in polynomial time. We give a
new and short proof of this result, using the matroid intersection algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4525</identifier>
 <datestamp>2013-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4525</id><created>2013-05-20</created><updated>2013-10-18</updated><authors><author><keyname>Kursa</keyname><forenames>Miron B.</forenames></author></authors><title>Robustness of Random Forest-based gene selection methods</title><categories>cs.LG q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gene selection is an important part of microarray data analysis because it
provides information that can lead to a better mechanistic understanding of an
investigated phenomenon. At the same time, gene selection is very difficult
because of the noisy nature of microarray data. As a consequence, gene
selection is often performed with machine learning methods. The Random Forest
method is particularly well suited for this purpose. In this work, four
state-of-the-art Random Forest-based feature selection methods were compared in
a gene selection context. The analysis focused on the stability of selection
because, although it is necessary for determining the significance of results,
it is often ignored in similar studies.
  The comparison of post-selection accuracy in the validation of Random Forest
classifiers revealed that all investigated methods were equivalent in this
context. However, the methods substantially differed with respect to the number
of selected genes and the stability of selection. Of the analysed methods, the
Boruta algorithm predicted the most genes as potentially important.
  The post-selection classifier error rate, which is a frequently used measure,
was found to be a potentially deceptive measure of gene selection quality. When
the number of consistently selected genes was considered, the Boruta algorithm
was clearly the best. Although it was also the most computationally intensive
method, the Boruta algorithm's computational demands could be reduced to levels
comparable to those of other algorithms by replacing the Random Forest
importance with a comparable measure from Random Ferns (a similar but
simplified classifier). Despite their design assumptions, the minimal optimal
selection methods, were found to select a high fraction of false positives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4537</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4537</id><created>2013-05-20</created><updated>2014-08-19</updated><authors><author><keyname>Marku&#x161;</keyname><forenames>Nenad</forenames></author><author><keyname>Frljak</keyname><forenames>Miroslav</forenames></author><author><keyname>Pand&#x17e;i&#x107;</keyname><forenames>Igor S.</forenames></author><author><keyname>Ahlberg</keyname><forenames>J&#xf6;rgen</forenames></author><author><keyname>Forchheimer</keyname><forenames>Robert</forenames></author></authors><title>Object Detection with Pixel Intensity Comparisons Organized in Decision
  Trees</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a method for visual object detection based on an ensemble of
optimized decision trees organized in a cascade of rejectors. The trees use
pixel intensity comparisons in their internal nodes and this makes them able to
process image regions very fast. Experimental analysis is provided through a
face detection problem. The obtained results are encouraging and demonstrate
that the method has practical value. Additionally, we analyse its sensitivity
to noise and show how to perform fast rotation invariant object detection.
Complete source code is provided at https://github.com/nenadmarkus/pico.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4538</identifier>
 <datestamp>2014-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4538</id><created>2013-05-20</created><updated>2014-04-23</updated><authors><author><keyname>Valls</keyname><forenames>V&#xed;ctor</forenames></author><author><keyname>Leith</keyname><forenames>Douglas J.</forenames></author></authors><title>Proportional Fair MU-MIMO in 802.11 WLANs</title><categories>cs.NI</categories><doi>10.1109/WCL.2014.020314.130884</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the proportional fair rate allocation in an 802.11 WLAN that
supports multi-user MIMO (MU-MIMO) transmission by one or more stations. We
characterise, for the first time, the proportional fair allocation of MU-MIMO
spatial streams and station transmission opportunities. While a number of
features carry over from the case without MU-MIMO, in general neither flows nor
stations need to be allocated equal airtime when MU-MIMO is available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4544</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4544</id><created>2013-05-20</created><authors><author><keyname>Salvi</keyname><forenames>Govind</forenames></author><author><keyname>Sharma</keyname><forenames>Puneet</forenames></author><author><keyname>Raman</keyname><forenames>Shanmuganathan</forenames></author></authors><title>Efficient Image Retargeting for High Dynamic Range Scenes</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of the real world scenes have a very high dynamic range (HDR). The
mobile phone cameras and the digital cameras available in markets are limited
in their capability in both the range and spatial resolution. Same argument can
be posed about the limited dynamic range display devices which also differ in
the spatial resolution and aspect ratios.
  In this paper, we address the problem of displaying the high contrast low
dynamic range (LDR) image of a HDR scene in a display device which has
different spatial resolution compared to that of the capturing digital camera.
The optimal solution proposed in this work can be employed with any camera
which has the ability to shoot multiple differently exposed images of a scene.
Further, the proposed solutions provide the flexibility in the depiction of
entire contrast of the HDR scene as a LDR image with an user specified spatial
resolution. This task is achieved through an optimized content aware
retargeting framework which preserves salient features along with the algorithm
to combine multi-exposure images. We show the proposed approach performs
exceedingly well in the generation of high contrast LDR image of varying
spatial resolution compared to an alternate approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4548</identifier>
 <datestamp>2014-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4548</id><created>2013-05-20</created><updated>2014-06-05</updated><authors><author><keyname>Sarwate</keyname><forenames>Anand D.</forenames></author><author><keyname>Javidi</keyname><forenames>Tara</forenames></author></authors><title>Distributed Learning of Distributions via Social Sampling</title><categories>math.OC cs.MA cs.SY</categories><comments>17 pages, accepted to IEEE Transactions on Automatic Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A protocol for distributed estimation of discrete distributions is proposed.
Each agent begins with a single sample from the distribution, and the goal is
to learn the empirical distribution of the samples. The protocol is based on a
simple message-passing model motivated by communication in social networks.
Agents sample a message randomly from their current estimates of the
distribution, resulting in a protocol with quantized messages. Using tools from
stochastic approximation, the algorithm is shown to converge almost surely.
Examples illustrate three regimes with different consensus phenomena.
Simulations demonstrate this convergence and give some insight into the effect
of network topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4558</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4558</id><created>2013-05-20</created><authors><author><keyname>Bacinoglu</keyname><forenames>Baran Tan</forenames></author><author><keyname>Uysal-Biyikoglu</keyname><forenames>Elif</forenames></author></authors><title>Finite-horizon Online Transmission Rate and Power Adaptation on a
  Communication Link with Markovian Energy Harvesting</title><categories>cs.IT cs.SY math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As energy harvesting communication systems emerge, there is a need for
transmission schemes that dynamically adapt to the energy harvesting process.
In this paper, after exhibiting a finite-horizon online throughput-maximizing
scheduling problem formulation and the structure of its optimal solution within
a dynamic programming formulation, a low complexity online scheduling policy is
proposed. The policy exploits the existence of thresholds for choosing rate and
power levels as a function of stored energy, harvest state and time until the
end of the horizon. The policy, which is based on computing an expected
threshold, performs close to optimal on a wide range of example energy harvest
patterns. Moreover, it achieves higher throughput values for a given delay,
than throughput-optimal online policies developed based on infinite-horizon
formulations in recent literature. The solution is extended to include ergodic
time-varying (fading) channels, and a corresponding low complexity policy is
proposed and evaluated for this case as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4560</identifier>
 <datestamp>2013-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4560</id><created>2013-05-20</created><updated>2013-05-23</updated><authors><author><keyname>Williamson</keyname><forenames>Adam R.</forenames></author><author><keyname>Chen</keyname><forenames>Tsung-Yi</forenames></author><author><keyname>Wesel</keyname><forenames>Richard D.</forenames></author></authors><title>Reliability-based Error Detection for Feedback Communication with Low
  Latency</title><categories>cs.IT math.IT</categories><comments>To be published at the 2013 IEEE International Symposium on
  Information Theory, Istanbul, Turkey. 5 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a reliability-based decoding scheme for variable-length
coding with feedback and demonstrates via simulation that it can achieve higher
rates than Polyanskiy et al.'s random coding lower bound for variable-length
feedback (VLF) coding on both the BSC and AWGN channel. The proposed scheme
uses the reliability output Viterbi algorithm (ROVA) to compute the word error
probability after each decoding attempt, which is compared against a target
error threshold and used as a stopping criterion to terminate transmission. The
only feedback required is a single bit for each decoding attempt, informing the
transmitter whether the ROVA-computed word-error probability is sufficiently
low. Furthermore, the ROVA determines whether transmission/decoding may be
terminated without the need for a rate-reducing CRC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4561</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4561</id><created>2013-05-20</created><updated>2013-06-14</updated><authors><author><keyname>Ferrer-i-Cancho</keyname><forenames>Ramon</forenames></author></authors><title>Random crossings in dependency trees</title><categories>cs.CL cs.DM cs.SI physics.soc-ph</categories><comments>minor corrections; a new appendix added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been hypothesized that the rather small number of crossings in real
syntactic dependency trees is a side-effect of pressure for dependency length
minimization. Here we answer a related important research question: what would
be the expected number of crossings if the natural order of a sentence was
lost? We show that this number depends only on the number of vertices of the
dependency tree (the sentence length) and the second moment of vertex degrees.
The expected number of crossings is minimum for a star tree (crossings are
impossible) and maximum for a linear tree (the number of crossings is of the
order of the square of the sequence length).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4573</identifier>
 <datestamp>2013-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4573</id><created>2013-05-20</created><updated>2013-05-27</updated><authors><author><keyname>Souviron</keyname><forenames>Jean</forenames></author></authors><title>Correcting self-intersecting polygons using minimal memory A simple and
  efficient algorithm and thoughts on line-segment intersection algorithms</title><categories>cs.CG</categories><comments>15 pages, 9 figures. Added 1 figure in Section 2.5 plus comments on
  expected value of exponent in abstract and body of paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While well-known methods to list the intersections of either a list of
segments or a complex polygon aim at achieving optimal time-complexity they
often do so at the cost of memory comsumption and complex code. Real-life
software optimisation however lies in optimising at the same time speed and
memory usage as well as keeping code simple. This paper first presents some
thoughts on the available algorithms in terms of memory usage leading to a very
simple scan-line-based algorithm aiming at answering that challenge. Although
sub-optimal in terms of speed it is optimal if both speed and memory space are
taken together and is very easy to implement. For N segments and k
intersections it uses only N additional integers and lists the intersections in
O(N^1.26) or corrects them in O((N+k) N^0.26) at most in average, with a high
probability of a much lower exponent around 0.16 and even as low as 0.1. It is
therefore well adapted for inclusion in larger software and seems like a good
compromise. Worst-case is in O(N^2). Then the paper will focus on differences
between available methods and the brute-force algorithm and a solution is
proposed. Although sub-optimal its applications could mainly be to answer in a
fast way a number of scattered unrelated intersection queries using minimal
complexity and additional resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4580</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4580</id><created>2013-05-20</created><authors><author><keyname>Benerjee</keyname><forenames>Krishna Gopal</forenames></author><author><keyname>Gupta</keyname><forenames>Manish K.</forenames></author><author><keyname>Agrawal</keyname><forenames>Nikhil</forenames></author></authors><title>Reconstruction and Repair Degree of Fractional Repetition Codes</title><categories>cs.IT math.IT</categories><comments>A one page abstract of this paper appears as a poster in IEEE Netcod
  2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a Fractional Repetition code, finding the reconstruction and repair
degree in a distributed storage system is an important problem. In this work,
we present algorithms for computing the reconstruction and repair degree of
fractional repetition codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4581</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4581</id><created>2013-05-20</created><authors><author><keyname>Khot</keyname><forenames>Subhash A.</forenames></author><author><keyname>Vishnoi</keyname><forenames>Nisheeth K.</forenames></author></authors><title>The Unique Games Conjecture, Integrality Gap for Cut Problems and
  Embeddability of Negative Type Metrics into $\ell_1$</title><categories>cs.CC cs.DS math.MG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we disprove a conjecture of Goemans and Linial; namely, that
every negative type metric embeds into $\ell_1$ with constant distortion. We
show that for an arbitrarily small constant $\delta&gt; 0$, for all large enough
$n$, there is an $n$-point negative type metric which requires distortion at
least $(\log\log n)^{1/6-\delta}$ to embed into $\ell_1.$
  Surprisingly, our construction is inspired by the Unique Games Conjecture
(UGC) of Khot, establishing a previously unsuspected connection between
probabilistically checkable proof systems (PCPs) and the theory of metric
embeddings. We first prove that the UGC implies a super-constant hardness
result for the (non-uniform) Sparsest Cut problem. Though this hardness result
relies on the UGC, we demonstrate, nevertheless, that the corresponding PCP
reduction can be used to construct an &quot;integrality gap instance&quot; for Sparsest
Cut. Towards this, we first construct an integrality gap instance for a natural
SDP relaxation of Unique Games. Then we &quot;simulate&quot; the PCP reduction and
&quot;translate&quot; the integrality gap instance of Unique Games to an integrality gap
instance of Sparsest Cut. This enables us to prove a $(\log \log
n)^{1/6-\delta}$ integrality gap for Sparsest Cut, which is known to be
equivalent to the metric embedding lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4583</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4583</id><created>2013-05-20</created><updated>2013-11-03</updated><authors><author><keyname>Zhao</keyname><forenames>Xin</forenames></author></authors><title>Parallel Coordinates Guided High Dimensional Transfer Function Design</title><categories>cs.GR</categories><comments>6 pages, 5 figures. This paper has been withdrawn by the author due
  to publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High-dimensional transfer function design is widely used to provide
appropriate data classification for direct volume rendering of various
datasets. However, its design is a complicated task. Parallel coordinate plot
(PCP), as a powerful visualization tool, can efficiently display
high-dimensional geometry and accurately analyze multivariate data. In this
paper, we propose to combine parallel coordinates with dimensional reduction
methods to guide high-dimensional transfer function design. Our pipeline has
two major advantages: (1) combine and display extracted high-dimensional
features in parameter space; and (2) select appropriate high-dimensional
parameters, with the help of dimensional reduction methods, to obtain
sophisticated data classification as transfer function for volume rendering. In
order to efficiently design high-dimensional transfer functions, the
combination of both parallel coordinate components and dimension reduction
results is necessary to generate final visualization results. We demonstrate
the capability of our method for direct volume rendering using various CT and
MRI datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4584</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4584</id><created>2013-05-20</created><authors><author><keyname>Court&#xe8;s</keyname><forenames>Ludovic</forenames></author></authors><title>Functional Package Management with Guix</title><categories>cs.PL</categories><comments>European Lisp Symposium (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe the design and implementation of GNU Guix, a purely functional
package manager designed to support a complete GNU/Linux distribution. Guix
supports transactional upgrades and roll-backs, unprivileged package
management, per-user profiles, and garbage collection. It builds upon the
low-level build and deployment layer of the Nix package manager. Guix uses
Scheme as its programming interface. In particular, we devise an embedded
domain-specific language (EDSL) to describe and compose packages. We
demonstrate how it allows us to benefit from the host general-purpose
programming language while not compromising on expressiveness. Second, we show
the use of Scheme to write build programs, leading to &quot;two-tier&quot; programming
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4610</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4610</id><created>2013-05-20</created><authors><author><keyname>Geng</keyname><forenames>Chunhua</forenames></author><author><keyname>Naderializadeh</keyname><forenames>Navid</forenames></author><author><keyname>Avestimehr</keyname><forenames>A. Salman</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>On the Optimality of Treating Interference as Noise</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that in the K-user interference channel, if for each user the
desired signal strength is no less than the sum of the strengths of the
strongest interference from this user and the strongest interference to this
user (all values in dB scale), then the simple scheme of using point to point
Gaussian codebooks with appropriate power levels at each transmitter and
treating interference as noise at every receiver (in short, TIN scheme)
achieves all points in the capacity region to within a constant gap. The
generalized degrees of freedom (GDoF) region under this condition is a
polyhedron, which is shown to be fully achieved by the same scheme, without the
need for time-sharing. The results are proved by first deriving a polyhedral
relaxation of the GDoF region achieved by TIN, then providing a dual
characterization of this polyhedral region via the use of potential functions,
and finally proving the optimality of this region in the desired regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4632</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4632</id><created>2013-05-20</created><updated>2015-06-02</updated><authors><author><keyname>El-kadri</keyname><forenames>Dr. Nour</forenames></author><author><keyname>Ricketti</keyname><forenames>Julia</forenames></author><author><keyname>Pethanasamy</keyname><forenames>Raja</forenames></author><author><keyname>Jegatheesan</keyname><forenames>Sowmyan</forenames></author></authors><title>The Process of Mobile Spectrum Allocation and its impact on Electronic
  Commerce and Mobile Commerce</title><categories>cs.CY cs.GT</categories><comments>Content not relevant anymore</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum being a very scarce natural resource of a country has to be
judicially used for the purpose of nation building and the allocation process
to telecom operators should be very transparent and ethical. There are various
ways of how spectrum can be allocated and there is no best way that can be
adopted universally. The market situation, Government policies, competition etc
determine the price of the spectrum and this is purely a regulatory or a
government decision to sell spectrum to telecom companies. The different
allocation methods, their implications with case studies across the globe is
analysed and presented in this paper. The reason why spectrum allocation should
be fair and transparent and the cost should be reasonable is analysed and
described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4650</identifier>
 <datestamp>2013-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4650</id><created>2013-05-20</created><updated>2013-11-25</updated><authors><author><keyname>Poulson</keyname><forenames>Jack</forenames></author><author><keyname>Demanet</keyname><forenames>Laurent</forenames></author><author><keyname>Maxwell</keyname><forenames>Nicholas</forenames></author><author><keyname>Ying</keyname><forenames>Lexing</forenames></author></authors><title>A parallel butterfly algorithm</title><categories>math.NA cs.NA</categories><comments>To appear in SIAM Journal on Scientific Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The butterfly algorithm is a fast algorithm which approximately evaluates a
discrete analogue of the integral transform \int K(x,y) g(y) dy at large
numbers of target points when the kernel, K(x,y), is approximately low-rank
when restricted to subdomains satisfying a certain simple geometric condition.
In d dimensions with O(N^d) quasi-uniformly distributed source and target
points, when each appropriate submatrix of K is approximately rank-r, the
running time of the algorithm is at most O(r^2 N^d log N). A parallelization of
the butterfly algorithm is introduced which, assuming a message latency of
\alpha and per-process inverse bandwidth of \beta, executes in at most O(r^2
N^d/p log N + \beta r N^d/p + \alpha)log p) time using p processes. This
parallel algorithm was then instantiated in the form of the open-source
DistButterfly library for the special case where K(x,y)=exp(i \Phi(x,y)), where
\Phi(x,y) is a black-box, sufficiently smooth, real-valued phase function.
Experiments on Blue Gene/Q demonstrate impressive strong-scaling results for
important classes of phase functions. Using quasi-uniform sources, hyperbolic
Radon transforms and an analogue of a 3D generalized Radon transform were
respectively observed to strong-scale from 1-node/16-cores up to
1024-nodes/16,384-cores with greater than 90% and 82% efficiency, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4651</identifier>
 <datestamp>2013-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4651</id><created>2013-05-20</created><authors><author><keyname>Bj&#xf6;rnson</keyname><forenames>Emil</forenames></author><author><keyname>Hoydis</keyname><forenames>Jakob</forenames></author><author><keyname>Kountouris</keyname><forenames>Marios</forenames></author><author><keyname>Debbah</keyname><forenames>M&#xe9;rouane</forenames></author></authors><title>Hardware Impairments in Large-scale MISO Systems: Energy Efficiency,
  Estimation, and Capacity Limits</title><categories>cs.IT math.IT</categories><comments>Published at International Conference on Digital Signal Processing
  (DSP 2013), 6 pages, 5 figures</comments><doi>10.1109/ICDSP.2013.6622755</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of large-scale antenna arrays has the potential to bring substantial
improvements in energy efficiency and/or spectral efficiency to future wireless
systems, due to the greatly improved spatial beamforming resolution. Recent
asymptotic results show that by increasing the number of antennas one can
achieve a large array gain and at the same time naturally decorrelate the user
channels; thus, the available energy can be focused very accurately at the
intended destinations without causing much inter-user interference. Since these
results rely on asymptotics, it is important to investigate whether the
conventional system models are still reasonable in the asymptotic regimes. This
paper analyzes the fundamental limits of large-scale multiple-input
single-output (MISO) communication systems using a generalized system model
that accounts for transceiver hardware impairments. As opposed to the case of
ideal hardware, we show that these practical impairments create finite ceilings
on the estimation accuracy and capacity of large-scale MISO systems.
Surprisingly, the performance is only limited by the hardware at the
single-antenna user terminal, while the impact of impairments at the
large-scale array vanishes asymptotically. Furthermore, we show that an
arbitrarily high energy efficiency can be achieved by reducing the power while
increasing the number of antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4675</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4675</id><created>2013-05-20</created><authors><author><keyname>Trehan</keyname><forenames>Amitabh</forenames></author></authors><title>Algorithms for Self-Healing Networks</title><categories>cs.DS cs.DC cs.NI</categories><comments>Ph.D. Dissertation. University of New Mexico Computer Science, May
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many modern networks are \emph{reconfigurable}, in the sense that the
topology of the network can be changed by the nodes in the network. For
example, peer-to-peer, wireless and ad-hoc networks are reconfigurable. More
generally, many social networks, such as a company's organizational chart;
infrastructure networks, such as an airline's transportation network; and
biological networks, such as the human brain, are also reconfigurable. Modern
reconfigurable networks have a complexity unprecedented in the history of
engineering, resembling more a dynamic and evolving living animal rather than a
structure of steel designed from a blueprint. Unfortunately, our mathematical
and algorithmic tools have not yet developed enough to handle this complexity
and fully exploit the flexibility of these networks.
  We believe that it is no longer possible to build networks that are scalable
and never have node failures. Instead, these networks should be able to admit
small, and maybe, periodic failures and still recover like skin heals from a
cut. This process, where the network can recover itself by maintaining key
invariants in response to attack by a powerful adversary is what we call
\emph{self-healing}.
  Here, we present several fast and provably good distributed algorithms for
self-healing in reconfigurable dynamic networks. Each of these algorithms have
different properties, a different set of gaurantees and limitations. We also
discuss future directions and theoretical questions we would like to answer.
%in the final dissertation that this document is proposed to lead to.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4677</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4677</id><created>2013-05-20</created><authors><author><keyname>Kurmyshev</keyname><forenames>E.</forenames></author><author><keyname>Ju&#xe1;rez</keyname><forenames>H. A.</forenames></author></authors><title>What is a leader of opinion formation in bounded confidence models?</title><categories>physics.soc-ph cs.SI nlin.AO</categories><comments>18 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Taking a decision in democratic social groups is based on the opinion of the
majority or on the consensus. So, the study of opinion dynamics is of great
interest in analyzing social phenomena. Among the different models of opinion
dynamics, bounded confidence models have been studied in different contexts and
shown interesting dynamics [1-3]. In [E. Kurmyshev, H.A. Ju\'arez, and R.A.
Gonz\'alez-Silva, Phys. A 390, 16 (2011)] we proposed a new bounded confidence
model and studied the self-formation of opinion in heterogeneous societies
composed by agents of two psychological types, concord (C-) and partial
antagonism (PA-) agents. In this work we study the influence of &quot;leaders&quot; on
the clustering of opinions. Mixed C/PA-societies along with the pure C- and
PA-society are studied. The influence of the leader's connectivity in the
network, his toughness or tolerance and his opinion on the opinion dynamics is
studied as a function of the initial opinion uncertainty (tolerance) of the
population. Numerical results obtained with leaders at low, high and average
tolerance show complex bifurcation patterns of the group opinion; a decrease or
even the total lost of control of the leader over the society is observed in
different intervals of tolerance of agents in the case of C/PA-societies. We
found that in the C-society a leader showing high opinion tolerance has more
control over the population. In the PA-society a leader changes the bifurcation
pattern of group opinion in a drastic and unexpected way, contrary to the
common sense, and generates stronger polarization in the opposite opinion
groups; the connectivity of the leader is an important factor that usually
improves the adhesion of agents to the leader's opinion. A low tolerance
(authoritarian) leader has greater control over a PA-society than that of a
high tolerance (democratic) one; the opposite result is obtained in the
C-society.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4682</identifier>
 <datestamp>2013-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4682</id><created>2013-05-20</created><updated>2013-08-07</updated><authors><author><keyname>Chen</keyname><forenames>Jiayi</forenames></author><author><keyname>Zhang</keyname><forenames>Q. T.</forenames></author></authors><title>Joint Space Decomposition-and-Synthesis Theory for K-User MIMO Channels:
  Interference Alignment and DoF Region</title><categories>cs.IT math.IT</categories><comments>Withdraw because lack of converse theorem for the result</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies DoF of interference alignment in K-user MIMO interference
channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4684</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4684</id><created>2013-05-20</created><updated>2013-07-28</updated><authors><author><keyname>Messerschmitt</keyname><forenames>David G.</forenames></author></authors><title>End-to-end interstellar communication system design for power efficiency</title><categories>astro-ph.IM cs.IT math.IT physics.pop-ph</categories><journal-ref>Acta Astronautica, Feb.-March 2015</journal-ref><doi>10.1016/j.actaastro.2014.11.007</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Radio communication over interstellar distances is studied, accounting for
noise, dispersion, scattering and motion. Large transmitted powers suggest
maximizing power efficiency (ratio of information rate to average signal power)
as opposed to restricting bandwidth. The fundamental limit to reliable
communication is determined, and is not affected by carrier frequency,
dispersion, scattering, or motion. The available efficiency is limited by noise
alone, and the available information rate is limited by noise and available
average power. A set of five design principles (well within our own
technological capability) can asymptotically approach the fundamental limit; no
other civilization can achieve greater efficiency. Bandwidth can be expanded in
a way that avoids invoking impairment by dispersion or scattering. The
resulting power-efficient signals have characteristics very different from
current SETI targets, with wide bandwidth relative to the information rate and
a sparse distribution of energy in both time and frequency. Information-free
beacons achieving the lowest average power consistent with a given receiver
observation time are studied. They need not have wide bandwidth, but do
distribute energy more sparsely in time as average power is reduced. The
discovery of both beacons and information-bearing signals is analyzed, and most
closely resembles approaches that have been employed in optical SETI. No
processing is needed to account for impairments other than noise. A direct
statistical tradeoff between a larger number of observations and a lower
average power (including due to lower information rate) is established. The
&quot;false alarms&quot; in current searches are characteristic signatures of these
signals. Joint searches for beacons and information-bearing signals require
straightforward modifications to current SETI pattern recognition approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4686</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4686</id><created>2013-05-20</created><authors><author><keyname>Sarraute</keyname><forenames>Carlos</forenames></author></authors><title>Aplicacion de las Redes Neuronales al Reconocimiento de Sistemas
  Operativos</title><categories>cs.CR</categories><comments>Master's Thesis. 99 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this work we present a family of neural networks, the multi-layer
perceptron networks, and some of the algorithms used to train those networks
(we hope that with enough details and precision as to satisfy a mathematical
public). Then we study how to use those networks to solve a problem that arises
from the field of information security: the remote identification of Operating
Systems (part of the information gathering steps of the penetration testing
methodology). This is the contribution of this work: it is an application of
classic Artificial Intelligence techniques to a classification problem that
gave better results than the classic techniques used to solve it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4696</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4696</id><created>2013-05-20</created><authors><author><keyname>Braverman</keyname><forenames>Mark</forenames></author><author><keyname>Ellen</keyname><forenames>Faith</forenames></author><author><keyname>Oshman</keyname><forenames>Rotem</forenames></author><author><keyname>Pitassi</keyname><forenames>Toniann</forenames></author><author><keyname>Vaikuntanathan</keyname><forenames>Vinod</forenames></author></authors><title>Tight Bounds for Set Disjointness in the Message Passing Model</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a multiparty message-passing model of communication, there are $k$
players. Each player has a private input, and they communicate by sending
messages to one another over private channels. While this model has been used
extensively in distributed computing and in multiparty computation, lower
bounds on communication complexity in this model and related models have been
somewhat scarce. In recent work \cite{phillips12,woodruff12,woodruff13}, strong
lower bounds of the form $\Omega(n \cdot k)$ were obtained for several
functions in the message-passing model; however, a lower bound on the classical
Set Disjointness problem remained elusive.
  In this paper, we prove tight lower bounds of the form $\Omega(n \cdot k)$
for the Set Disjointness problem in the message passing model. Our bounds are
obtained by developing information complexity tools in the message-passing
model, and then proving an information complexity lower bound for Set
Disjointness. As a corollary, we show a tight lower bound for the task
allocation problem \cite{DruckerKuhnOshman} via a reduction from Set
Disjointness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4703</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4703</id><created>2013-05-20</created><authors><author><keyname>Yerramalli</keyname><forenames>Srinivas</forenames></author><author><keyname>Jain</keyname><forenames>Rahul</forenames></author><author><keyname>Mitra</keyname><forenames>Urbashi</forenames></author></authors><title>Broadcast Channel Games: Equilibrium Characterization and a MIMO MAC-BC
  Game Duality</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Journal on Selected Areas in Communications,
  Special Issue on Device to Device Cooperation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The emergence of heterogeneous decentralized networks without a central
controller, such as device-to-device communication systems, has created the
need for new problem frameworks to design and analyze the performance of such
networks. As a key step towards such an analysis for general networks, this
paper examines the strategic behavior of \emph{receivers} in a Gaussian
broadcast channel (BC) and \emph{transmitters} in a multiple access channel
(MAC) with sum power constraints (sum power MAC) using the framework of
non-cooperative game theory. These signaling scenarios are modeled as
generalized Nash equilibrium problems (GNEPs) with jointly convex and coupled
constraints and the existence and uniqueness of equilibrium achieving
strategies and equilibrium utilities are characterized for both the Gaussian BC
and the sum power MAC. The relationship between Pareto-optimal boundary points
of the capacity region and the generalized Nash equilibria (GNEs) are derived
for the several special cases and in all these cases it is shown that all the
GNEs are Pareto-optimal, demonstrating that there is no loss in efficiency when
players adopt strategic behavior in these scenarios. Several key equivalence
relations are derived and used to demonstrate a game-theoretic duality between
the Gaussian MAC and the Gaussian BC. This duality allows a parametrized
computation of the equilibria of the BC in terms of the equilibria of the MAC
and paves the way to translate several MAC results to the dual BC scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4711</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4711</id><created>2013-05-21</created><authors><author><keyname>Yang</keyname><forenames>Yu</forenames></author><author><keyname>Wang</keyname><forenames>Deqiang</forenames></author><author><keyname>Wang</keyname><forenames>Hua</forenames></author><author><keyname>Liu</keyname><forenames>Hongbo</forenames></author></authors><title>On BC-trees and BC-subtrees</title><categories>cs.DM math.CO</categories><comments>14 pages, 3 figures</comments><msc-class>68R10</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A BC-tree (block-cutpoint-tree) is a tree (with at least two vertices) where
the distance between any two leaves is even. Motivated from the study of the
&quot;core&quot; of a graph, BC-trees provide an interesting class of trees. We consider
questions related to BC-trees as an effort to make modest progress towards the
understanding of this concept. Constructive algorithms are provided for
BC-trees with given order and number of leaves whenever possible. The concept
of BC-subtrees is naturally introduced. Inspired by analogous work on trees and
subtrees, we also present some extremal results and briefly discuss the &quot;middle
part&quot; of a tree with respect to the number of BC-subtrees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4723</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4723</id><created>2013-05-21</created><authors><author><keyname>Lu</keyname><forenames>Zhaosong</forenames></author><author><keyname>Xiao</keyname><forenames>Lin</forenames></author></authors><title>On the Complexity Analysis of Randomized Block-Coordinate Descent
  Methods</title><categories>math.OC cs.LG cs.NA math.NA stat.ML</categories><comments>26 pages (submitted)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we analyze the randomized block-coordinate descent (RBCD)
methods proposed in [8,11] for minimizing the sum of a smooth convex function
and a block-separable convex function. In particular, we extend Nesterov's
technique developed in [8] for analyzing the RBCD method for minimizing a
smooth convex function over a block-separable closed convex set to the
aforementioned more general problem and obtain a sharper expected-value type of
convergence rate than the one implied in [11]. Also, we obtain a better
high-probability type of iteration complexity, which improves upon the one in
[11] by at least the amount $O(n/\epsilon)$, where $\epsilon$ is the target
solution accuracy and $n$ is the number of problem blocks. In addition, for
unconstrained smooth convex minimization, we develop a new technique called
{\it randomized estimate sequence} to analyze the accelerated RBCD method
proposed by Nesterov [11] and establish a sharper expected-value type of
convergence rate than the one given in [11].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4729</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4729</id><created>2013-05-21</created><authors><author><keyname>Ejov</keyname><forenames>Vladimir</forenames></author><author><keyname>Haythorpe</keyname><forenames>Michael</forenames></author><author><keyname>Rossomakhine</keyname><forenames>Serguei</forenames></author></authors><title>A Linear-size Conversion of HCP to 3HCP</title><categories>math.CO cs.DM</categories><msc-class>05C45 (Primary), 05C85, 68R10 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide an algorithm that converts any instance of the Hamiltonian cycle
problem (HCP) into a cubic instance of HCP (3HCP), and prove that the input
size of the new instance is only a linear function of that of the original
instance. This is achieved by first considering various restrictions of HCP.
Known conversions from directed HCP to undirected HCP, and sub-cubic HCP to
cubic HCP are given. We introduce a subgraph called a 4-gate and show that it
may be used to convert sub-quartic HCP into sub-cubic HCP. We further
generalise this idea by first introducing the 5-gate, and then the s-gate for
any s &gt;= 4. We prove that these subgraphs may be used to convert general
instances of HCP into cubic HCP instances, where the input size of the
converted instance is a quadratic function of that of the original instance.
This result improves upon the previously best known approach which results in
cubic growth in the size of the instance. We further prove that the quadratic
function is reduced to a linear function if the maximum initial degree is
bounded above by a constant. Motivated by this result, we describe an algorithm
to convert general HCP to HCP of bounded degree and prove that it results in
only linear growth. All of the above results are then used in the proof that
any instance of HCP may be converted to an equivalent instance 3HCP with only
linear growth in the input size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4731</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4731</id><created>2013-05-21</created><updated>2013-06-04</updated><authors><author><keyname>De Donno</keyname><forenames>D.</forenames></author><author><keyname>Catarinucci</keyname><forenames>L.</forenames></author><author><keyname>Tarricone</keyname><forenames>L.</forenames></author></authors><title>An UHF RFID Energy-Harvesting System Enhanced by a DC-DC Charge Pump in
  Silicon-on-Insulator Technology</title><categories>cs.OH</categories><journal-ref>IEEE Microwave and Wireless Components Letters, vol. 23, no. 6,
  pp. 315-317, June 2013</journal-ref><doi>10.1109/LMWC.2013.2258002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An RF-DC converter enhanced by a DC-DC voltage booster in
silicon-on-insulator technology for UHF radio frequency identification (RFID)
energy harvesting is presented in this letter. When the received RF power level
is -14 dBm or higher, the system, fabricated on an FR4 substrate using
off-the-shelf low-cost discrete components and connected to a flexible dipole
antenna, is able to produce 2.4-V DC voltage to power general-purpose
electronic devices. As a simple proof of concept,a device comprising
microcontroller, temperature sensor, and EEPROM is considered in this work. The
experimental results demonstrate the capability of the system to autonomously
perform temperature data logging up to a distance of 5 m from a conventional
UHF RFID reader used as an RF energy source.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4732</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4732</id><created>2013-05-21</created><authors><author><keyname>De Donno</keyname><forenames>D.</forenames></author><author><keyname>Catarinucci</keyname><forenames>L.</forenames></author><author><keyname>Tarricone</keyname><forenames>L.</forenames></author></authors><title>Enabling Self-Powered Autonomous Wireless Sensors with New-Generation
  I2C-RFID Chips</title><categories>cs.OH</categories><journal-ref>2013 IEEE MTT-S International Microwave Symposium Digest (MTT),
  pp. 1-4, Seattle, WA, June 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A self-powered autonomous RFID device with sensing and computing capabilities
is presented in this paper. Powered by an RF energy-harvesting circuit enhanced
by a DC-DC voltage booster in silicon-on-insulator (SOI) technology, the device
relies on a microcontroller and a new generation I2C-RFID chip to wirelessly
deliver sensor data to standard RFID EPC Class-1 Generation-2 (Gen2) readers.
When the RF power received from the interrogating reader is -14 dBm or higher,
the device, fabricated on an FR4 substrate using low-cost discrete components,
is able to produce 2.4-V DC voltage to power its circuitry. The experimental
results demonstrate the effectiveness of the device to perform reliable sensor
data transmissions up to 5 meters in fully-passive mode. To the best of our
knowledge, this represents the longest read range ever reported for passive UHF
RFID sensors compliant with the EPC Gen2 standard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4738</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4738</id><created>2013-05-21</created><authors><author><keyname>Prasad</keyname><forenames>Manju</forenames></author><author><keyname>Dharani</keyname><forenames>Andhe</forenames></author></authors><title>A qoi based energy efficient clustering for dense wireless sensor
  network</title><categories>cs.NI</categories><comments>9 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a wireless sensor network Quality of Information (QoI), Energy Efficiency,
Redundant data avoidance, congestion control are the important metrics that
affect the performance of wireless sensor network. As many approaches were
proposed to increase the performance of a wireless sensor network among them
clustering is one of the efficient approaches in sensor network. Many
clustering algorithms concentrate mainly on power Optimization like FSCH,
LEACH, and EELBCRP. There is necessity of the above metrics in wireless sensor
network where nodes are densely deployed in a given network area. As the nodes
are deployed densely there is maximum possibility of nodes appear in the
sensing region of other nodes. So there exists an option that nodes have to
send the information that is already reached the base station by its own
cluster members or by members of other clusters. This mechanism will affect the
QoI, Energy factor and congestion control of the wireless sensor networks. Even
though clustering uses TDMA (Time Division Multiple Access) for avoiding
congestion control for intra clustering data transmission, but it may fail in
some critical situation. This paper proposed a energy efficient clustering
which avoid data redundancy in a dense sensor network until the network becomes
sparse and hence uses the TDMA efficiently during high density of the nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4744</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4744</id><created>2013-05-21</created><authors><author><keyname>Galliani</keyname><forenames>Pietro</forenames></author></authors><title>The Doxastic Interpretation of Team Semantics</title><categories>cs.AI cs.LO math.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We advance a doxastic interpretation for many of the logical connectives
considered in Dependence Logic and in its extensions, and we argue that Team
Semantics is a natural framework for reasoning about beliefs and belief
updates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4745</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4745</id><created>2013-05-21</created><authors><author><keyname>Ailon</keyname><forenames>Nir</forenames></author></authors><title>A Lower Bound for Fourier Transform Computation in a Linear Model Over
  2x2 Unitary Gates Using Matrix Entropy</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Obtaining a non-trivial (super-linear) lower bound for computation of the
Fourier transform in the linear circuit model has been a long standing open
problem. All lower bounds so far have made strong restrictions on the
computational model. One of the most well known results, by Morgenstern from
1973, provides an $\Omega(n \log n)$ lower bound for the \emph{unnormalized}
FFT when the constants used in the computation are bounded. The proof uses a
potential function related to a determinant. The determinant of the
unnormalized Fourier transform is $n^{n/2}$, and thus by showing that it can
grow by at most a constant factor after each step yields the result.
  This classic result, however, does not explain why the \emph{normalized}
Fourier transform, which has a unit determinant, should take $\Omega(n\log n)$
steps to compute. In this work we show that in a layered linear circuit model
restricted to unitary $2\times 2$ gates, one obtains an $\Omega(n\log n)$ lower
bound. The well known FFT works in this model. The main argument concluded from
this work is that a potential function that might eventually help proving the
$\Omega(n\log n)$ conjectured lower bound for computation of Fourier transform
is not related to matrix determinant, but rather to a notion of matrix entropy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4746</identifier>
 <datestamp>2015-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4746</id><created>2013-05-21</created><updated>2015-08-06</updated><authors><author><keyname>Chou</keyname><forenames>Remi A.</forenames></author><author><keyname>Bloch</keyname><forenames>Matthieu R.</forenames></author><author><keyname>Abbe</keyname><forenames>Emmanuel</forenames></author></authors><title>Polar Coding for Secret-Key Generation</title><categories>cs.IT math.IT</categories><comments>26 pages, 9 figures, accepted to IEEE Transactions on Information
  Theory; parts of the results were presented at the 2013 IEEE Information
  Theory Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Practical implementations of secret-key generation are often based on
sequential strategies, which handle reliability and secrecy in two successive
steps, called reconciliation and privacy amplification. In this paper, we
propose an alternative approach based on polar codes that jointly deals with
reliability and secrecy. Specifically, we propose secret-key capacity-achieving
polar coding schemes for the following models: (i) the degraded binary
memoryless source (DBMS) model with rate-unlimited public communication, (ii)
the DBMS model with one-way rate-limited public communication, (iii) the 1-to-m
broadcast model and (iv) the Markov tree model with uniform marginals. For
models (i) and (ii) our coding schemes remain valid for non-degraded sources,
although they may not achieve the secret-key capacity. For models (i), (ii) and
(iii), our schemes rely on pre-shared secret seed of negligible rate; however,
we provide special cases of these models for which no seed is required.
Finally, we show an application of our results to secrecy and privacy for
biometric systems. We thus provide the first examples of low-complexity
secret-key capacity-achieving schemes that are able to handle vector
quantization for model (ii), or multiterminal communication for models (iii)
and (iv).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4747</identifier>
 <datestamp>2013-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4747</id><created>2013-05-21</created><updated>2013-12-02</updated><authors><author><keyname>de Montgolfier</keyname><forenames>Fabien</forenames></author><author><keyname>Raffinot</keyname><forenames>Mathieu</forenames></author><author><keyname>Rusu</keyname><forenames>Irena</forenames></author></authors><title>Easy identification of generalized common and conserved nested intervals</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we explain how to easily compute gene clusters, formalized by
classical or generalized nested common or conserved intervals, between a set of
K genomes represented as K permutations. A b-nested common (resp. conserved)
interval I of size |I| is either an interval of size 1 or a common (resp.
conserved) interval that contains another b-nested common (resp. conserved)
interval of size at least |I|-b. When b=1, this corresponds to the classical
notion of nested interval. We exhibit two simple algorithms to output all
b-nested common or conserved intervals between K permutations in O(Kn+nocc)
time, where nocc is the total number of such intervals. We also explain how to
count all b-nested intervals in O(Kn) time. New properties of the family of
conserved intervals are proposed to do so.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4755</identifier>
 <datestamp>2014-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4755</id><created>2013-05-21</created><updated>2014-01-26</updated><authors><author><keyname>Girnyk</keyname><forenames>Maksym A.</forenames></author><author><keyname>Vehkaper&#xe4;</keyname><forenames>Mikko</forenames></author><author><keyname>Rasmussen</keyname><forenames>Lars K.</forenames></author></authors><title>Large-System Analysis of Correlated MIMO Multiple Access Channels with
  Arbitrary Signaling in the Presence of Interference</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Presence of multiple antennas on both sides of a communication channel
promises significant improvements in system throughput and power efficiency. In
effect, a new class of large multiple-input multiple-output (MIMO)
communication systems has recently emerged and attracted both scientific and
industrial attention. To analyze these systems in realistic scenarios, one has
to include such aspects as co-channel interference, multiple access and spatial
correlation. In this paper, we study the properties of correlated MIMO
multiple-access channels in the presence of external interference. Using the
replica method from statistical physics, we derive the ergodic sum-rate of the
communication for arbitrary signal constellations when the numbers of antennas
at both ends of the channel grow large. Based on these asymptotic expressions,
we also address the problem of sum-rate maximization using statistical channel
information and linear precoding. The numerical results demonstrate that when
the interfering terminals use discrete constellations, the resulting
interference becomes easier to handle compared to Gaussian signals. Thus, it
may be possible to accommodate more interfering transmitter-receiver pairs
within the same area as compared to the case of Gaussian signals. In addition,
we demonstrate numerically for the Gaussian and QPSK signaling schemes that it
is possible to design precoder matrices that significantly improve the
achievable rates at low-to-mid range of signal-to-noise ratios when compared to
isotropic precoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4757</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4757</id><created>2013-05-21</created><authors><author><keyname>Raman</keyname><forenames>Parasaran</forenames></author><author><keyname>Venkatasubramanian</keyname><forenames>Suresh</forenames></author></authors><title>Power to the Points: Validating Data Memberships in Clusterings</title><categories>cs.LG cs.CG</categories><comments>18 pages, 9 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A clustering is an implicit assignment of labels of points, based on
proximity to other points. It is these labels that are then used for downstream
analysis (either focusing on individual clusters, or identifying
representatives of clusters and so on). Thus, in order to trust a clustering as
a first step in exploratory data analysis, we must trust the labels assigned to
individual data. Without supervision, how can we validate this assignment? In
this paper, we present a method to attach affinity scores to the implicit
labels of individual points in a clustering. The affinity scores capture the
confidence level of the cluster that claims to &quot;own&quot; the point. This method is
very general: it can be used with clusterings derived from Euclidean data,
kernelized data, or even data derived from information spaces. It smoothly
incorporates importance functions on clusters, allowing us to eight different
clusters differently. It is also efficient: assigning an affinity score to a
point depends only polynomially on the number of clusters and is independent of
the number of points in the data. The dimensionality of the underlying space
only appears in preprocessing. We demonstrate the value of our approach with an
experimental study that illustrates the use of these scores in different data
analysis tasks, as well as the efficiency and flexibility of the method. We
also demonstrate useful visualizations of these scores; these might prove
useful within an interactive analytics framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4760</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4760</id><created>2013-05-21</created><authors><author><keyname>Bui-Xuan</keyname><forenames>Binh-Minh</forenames></author><author><keyname>Jones</keyname><forenames>Nick S.</forenames></author></authors><title>How modular structure can simplify tasks on networks</title><categories>cs.SI cs.DS physics.soc-ph q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By considering the task of finding the shortest walk through a network we
find an algorithm for which the run time is not as O(2^n), with n being the
number of nodes, but instead scales with the number of nodes in a coarsened
network. This coarsened network has a number of nodes related to the number of
dense regions in the original graph. Since we exploit a form of local community
detection as a preprocessing, this work gives support to the project of
developing heuristic algorithms for detecting dense regions in networks:
preprocessing of this kind can accelerate optimization tasks on networks. Our
work also suggests a class of empirical conjectures for how structural features
of efficient networked systems might scale with system size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4776</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4776</id><created>2013-05-21</created><authors><author><keyname>Kawalerowicz</keyname><forenames>Marcin</forenames></author></authors><title>Classification of automatic software build methods</title><categories>cs.SE</categories><comments>Short paper (4 pages, 1 figure)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The process of creating working software from source code and other
components (like libraries, database files, etc.) is called &quot;software build&quot;.
Apart from linking and compiling, it can include other steps like automated
testing, static code analysis, documentation generation, deployment and other.
All that steps can be automated using a build description of some sort (e.g.
script). This article classifies the automatic software build processes
beginning at build script and reaching the various types of continuous
integration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4778</identifier>
 <datestamp>2014-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4778</id><created>2013-05-21</created><updated>2014-12-11</updated><authors><author><keyname>Ziliotto</keyname><forenames>Bruno</forenames></author></authors><title>Zero-sum repeated games: counterexamples to the existence of the
  asymptotic value and the conjecture maxmin=lim v(n)</title><categories>math.OC cs.LG</categories><msc-class>91A05, 91A15, 91A20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide an example of a two-player zero-sum repeated game with public
signals and perfect observation of the actions, where neither the value of the
lambda-discounted game nor the value of the n-stage game converges, when
respectively lambda goes to 0 and n goes to infinity. It is a counterexample to
two long-standing conjectures, formulated by Mertens: first, in any zero-sum
repeated game, the asymptotic value exists, and secondly, when Player 1 is more
informed than Player 2, Player 1 is able to guarantee the limit value of the
n-stage game in the long run. The aforementioned example involves seven states,
two actions and two signals for each player. Remarkably, players observe the
payoffs, and play in turn (at each step the action of one player only has an
effect on the payoff and the transition). Moreover, it can be adapted to fit in
the class of standard stochastic games where the state is not observed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4781</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4781</id><created>2013-05-21</created><authors><author><keyname>Horsch</keyname><forenames>Martin</forenames></author><author><keyname>Niethammer</keyname><forenames>Christoph</forenames></author><author><keyname>Vrabec</keyname><forenames>Jadran</forenames></author><author><keyname>Hasse</keyname><forenames>Hans</forenames></author></authors><title>Computational molecular engineering as an emerging technology in process
  engineering</title><categories>cs.DC physics.comp-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present level of development of molecular force field methods is assessed
from the point of view of simulation-based engineering, outlining the immediate
perspective for further development and highlighting the newly emerging
discipline of Computational Molecular Engineering (CME) which makes basic
research in soft matter physics fruitful for industrial applications. Within
the coming decade, major breakthroughs can be reached if a research focus is
placed on processes at interfaces, combining aspects where an increase in the
accessible length and time scales due to massively parallel high-performance
computing will lead to particularly significant improvements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4786</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4786</id><created>2013-05-21</created><authors><author><keyname>Jacobsen</keyname><forenames>Rasmus Melchior</forenames></author><author><keyname>Popovski</keyname><forenames>Petar</forenames></author></authors><title>Reliable Reception of Wireless Metering Data with Protocol Coding</title><categories>cs.NI</categories><comments>Conference submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stationary collectors reading wireless, battery powered smart meters, often
operate in harsh channel conditions to cut network installation cost to a
minimum, challenging the individual link to each meter. The desired performance
measure is reliable reception of at least some data from as many as possible
meters, rather than increasing the fraction of received packets from one meter.
As a first step for improving reliable reception, and motivated by the recent
revision of Wireless M-Bus, we propose the use of a deterministic packet
transmission interval to group packets from the same meter. We derive the
probability of falsely pairing packets from different senders in the simple
case of no channel errors, and show through simulation and data from an
experimental deployment the probability of false pairing with channel errors.
The pairing is an essential step towards recovery of metering data from as many
as possible meters under harsh channel conditions. From the experiment we find
that more than 15% of all conducted pairings are between two erroneous packets,
which sets an upper bound on the number of additional meters that can be
reliably recovered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4787</identifier>
 <datestamp>2013-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4787</id><created>2013-05-21</created><updated>2013-10-20</updated><authors><author><keyname>Saez</keyname><forenames>Yessica</forenames></author><author><keyname>Kish</keyname><forenames>Laszlo B.</forenames></author></authors><title>Errors and their mitigation at the Kirchhoff-law-Johnson-noise secure
  key exchange</title><categories>cs.ET cs.CR</categories><comments>On October 15th, 2013, this version is accepted for publication at
  PLOS ONE</comments><journal-ref>PLoS ONE 8 (2013) e81103</journal-ref><doi>10.1371/journal.pone.0081103</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A method to quantify the error probability at the Kirchhoff-law-Johnson-noise
(KLJN) secure key exchange is introduced. The types of errors due to
statistical inaccuracies in noise voltage measurements are classified and the
error probability is calculated. The most interesting finding is that the error
probability decays exponentially with the duration of the time window of single
bit exchange. The results indicate that it is feasible to have so small error
probabilities of the exchanged bits that error correction algorithms are not
required. The results are demonstrated with practical considerations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4801</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4801</id><created>2013-05-21</created><authors><author><keyname>Min</keyname><forenames>Fan</forenames></author><author><keyname>Zhu</keyname><forenames>William</forenames></author></authors><title>Mining top-k granular association rules for recommendation</title><categories>cs.IR</categories><comments>12 pages, 5 figures, submitted to Advances in Granular Computing and
  Advances in Rough Sets, 2013. arXiv admin note: substantial text overlap with
  arXiv:1305.1372</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recommender systems are important for e-commerce companies as well as
researchers. Recently, granular association rules have been proposed for
cold-start recommendation. However, existing approaches reserve only globally
strong rules; therefore some users may receive no recommendation at all. In
this paper, we propose to mine the top-k granular association rules for each
user. First we define three measures of granular association rules. These are
the source coverage which measures the user granule size, the target coverage
which measures the item granule size, and the confidence which measures the
strength of the association. With the confidence measure, rules can be ranked
according to their strength. Then we propose algorithms for training the
recommender and suggesting items to each user. Experimental are undertaken on a
publicly available data set MovieLens. Results indicate that the appropriate
setting of granule can avoid over-fitting and at the same time, help obtaining
high recommending accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4807</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4807</id><created>2013-05-21</created><updated>2014-08-12</updated><authors><author><keyname>Rosvall</keyname><forenames>Martin</forenames></author><author><keyname>Esquivel</keyname><forenames>Alcides V.</forenames></author><author><keyname>Lancichinetti</keyname><forenames>Andrea</forenames></author><author><keyname>West</keyname><forenames>Jevin D.</forenames></author><author><keyname>Lambiotte</keyname><forenames>Renaud</forenames></author></authors><title>Memory in network flows and its effects on spreading dynamics and
  community detection</title><categories>physics.soc-ph cs.SI</categories><comments>23 pages and 16 figures</comments><journal-ref>Nature Communications 5, 4630 (2014)</journal-ref><doi>10.1038/ncomms5630</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random walks on networks is the standard tool for modelling spreading
processes in social and biological systems. This first-order Markov approach is
used in conventional community detection, ranking, and spreading analysis
although it ignores a potentially important feature of the dynamics: where flow
moves to may depend on where it comes from. Here we analyse pathways from
different systems, and while we only observe marginal consequences for disease
spreading, we show that ignoring the effects of second-order Markov dynamics
has important consequences for community detection, ranking, and information
spreading. For example, capturing dynamics with a second-order Markov model
allows us to reveal actual travel patterns in air traffic and to uncover
multidisciplinary journals in scientific communication. These findings were
achieved only by using more available data and making no additional
assumptions, and therefore suggest that accounting for higher-order memory in
network flows can help us better understand how real systems are organized and
function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4818</identifier>
 <datestamp>2013-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4818</id><created>2013-05-21</created><updated>2013-07-19</updated><authors><author><keyname>Gerhold</keyname><forenames>Stefan</forenames></author><author><keyname>Kauers</keyname><forenames>Manuel</forenames></author><author><keyname>Koutschan</keyname><forenames>Christoph</forenames></author><author><keyname>Paule</keyname><forenames>Peter</forenames></author><author><keyname>Schneider</keyname><forenames>Carsten</forenames></author><author><keyname>Zimmermann</keyname><forenames>Burkhard</forenames></author></authors><title>Computer-Assisted Proofs of Some Identities for Bessel Functions of
  Fractional Order</title><categories>cs.SC</categories><comments>Final version, some typos were corrected. 21 pages, uses svmult.cls</comments><journal-ref>In Carsten Schneider and Johannes Bluemlein (eds.): Computer
  Algebra in Quantum Field Theory: Integration, Summation and Special
  Functions. Texts &amp; Monographs in Symbolic Computation, Springer-Verlag Wien
  2013</journal-ref><doi>10.1007/978-3-7091-1616-6_3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We employ computer algebra algorithms to prove a collection of identities
involving Bessel functions with half-integer orders and other special
functions. These identities appear in the famous Handbook of Mathematical
Functions, as well as in its successor, the DLMF, but their proofs were lost.
We use generating functions and symbolic summation techniques to produce new
proofs for them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4820</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4820</id><created>2013-05-21</created><authors><author><keyname>Jelassi</keyname><forenames>Mohamed Nader</forenames></author><author><keyname>Yahia</keyname><forenames>Sadok Ben</forenames></author><author><keyname>Nguifo</keyname><forenames>Engelbert Mephu</forenames></author></authors><title>Nouvelle approche de recommandation personnalisee dans les folksonomies
  basee sur le profil des utilisateurs</title><categories>cs.IR</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In folksonomies, users use to share objects (movies, books, bookmarks, etc.)
by annotating them with a set of tags of their own choice. With the rise of the
Web 2.0 age, users become the core of the system since they are both the
contributors and the creators of the information. Yet, each user has its own
profile and its own ideas making thereby the strength as well as the weakness
of folksonomies. Indeed, it would be helpful to take account of users' profile
when suggesting a list of tags and resources or even a list of friends, in
order to make a personal recommandation, instead of suggesting the more used
tags and resources in the folksonomy. In this paper, we consider users' profile
as a new dimension of a folksonomy classically composed of three dimensions
&lt;users, tags, ressources&gt; and we propose an approach to group users with
equivalent profiles and equivalent interests as quadratic concepts. Then, we
use such structures to propose our personalized recommendation system of users,
tags and resources according to each user's profile. Carried out experiments on
two real-world datasets, i.e., MovieLens and BookCrossing highlight encouraging
results in terms of precision as well as a good social evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4832</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4832</id><created>2013-05-21</created><authors><author><keyname>Rane</keyname><forenames>Shantanu</forenames></author><author><keyname>Wang</keyname><forenames>Ye</forenames></author><author><keyname>Draper</keyname><forenames>Stark. C.</forenames></author><author><keyname>Ishwar</keyname><forenames>Prakash</forenames></author></authors><title>Secure Biometrics: Concepts, Authentication Architectures and Challenges</title><categories>cs.CR cs.IT math.IT</categories><comments>16 pages, 11 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BIOMETRICS are an important and widely used class of methods for identity
verification and access control. Biometrics are attractive because they are
inherent properties of an individual. They need not be remembered like
passwords, and are not easily lost or forged like identifying documents. At the
same time, bio- metrics are fundamentally noisy and irreplaceable. There are
always slight variations among the measurements of a given biometric, and,
unlike passwords or identification numbers, biometrics are derived from
physical characteristics that cannot easily be changed. The proliferation of
biometric usage raises critical privacy and security concerns that, due to the
noisy nature of biometrics, cannot be addressed using standard cryptographic
methods. In this article we present an overview of &quot;secure biometrics&quot;, also
referred to as &quot;biometric template protection&quot;, an emerging class of methods
that address these concerns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4840</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4840</id><created>2013-05-21</created><updated>2013-09-02</updated><authors><author><keyname>Randriambololona</keyname><forenames>Hugues</forenames></author></authors><title>An upper bound of Singleton type for componentwise products of linear
  codes</title><categories>cs.IT math.IT</categories><comments>9 pages; major improvements in v3: now works for an arbitrary number
  of codes, and the low-weight codeword can be taken in product form; submitted
  to IEEE Trans. Inform. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an upper bound that relates the minimum weight of a nonzero
componentwise product of codewords from some given number of linear codes, with
the dimensions of these codes. Its shape is a direct generalization of the
classical Singleton bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4859</identifier>
 <datestamp>2014-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4859</id><created>2013-05-21</created><updated>2014-06-11</updated><authors><author><keyname>Xu</keyname><forenames>Jia</forenames></author><author><keyname>Shironoshita</keyname><forenames>Patrick</forenames></author><author><keyname>Visser</keyname><forenames>Ubbo</forenames></author><author><keyname>John</keyname><forenames>Nigel</forenames></author><author><keyname>Kabuka</keyname><forenames>Mansur</forenames></author></authors><title>Extract ABox Modules for Efficient Ontology Querying</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The extraction of logically-independent fragments out of an ontology ABox can
be useful for solving the tractability problem of querying ontologies with
large ABoxes. In this paper, we propose a formal definition of an ABox module,
such that it guarantees complete preservation of facts about a given set of
individuals, and thus can be reasoned independently w.r.t. the ontology TBox.
With ABox modules of this type, isolated or distributed (parallel) ABox
reasoning becomes feasible, and more efficient data retrieval from ontology
ABoxes can be attained. To compute such an ABox module, we present a
theoretical approach and also an approximation for $\mathcal{SHIQ}$ ontologies.
Evaluation of the module approximation on different types of ontologies shows
that, on average, extracted ABox modules are significantly smaller than the
entire ABox, and the time for ontology reasoning based on ABox modules can be
improved significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4868</identifier>
 <datestamp>2014-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4868</id><created>2013-05-21</created><updated>2014-02-13</updated><authors><author><keyname>Cachin</keyname><forenames>Christian</forenames></author><author><keyname>Dobre</keyname><forenames>Dan</forenames></author><author><keyname>Vukolic</keyname><forenames>Marko</forenames></author></authors><title>Asynchronous BFT Storage with 2t+1 Data Replicas</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The cost of Byzantine Fault Tolerant (BFT) storage is the main concern
preventing its adoption in practice. This cost stems from the need to maintain
at least 3t+1 replicas in different storage servers in the asynchronous model,
so that t Byzantine replica faults can be tolerated. In this paper, we present
MDStore, the first fully asynchronous read/write BFT storage protocol that
reduces the number of data replicas to as few as 2t+1, maintaining 3t+1
replicas of metadata at (possibly) different servers. At the heart of MDStore
store is its metadata service that is built upon a new abstraction we call
timestamped storage. Timestamped storage both allows for conditional writes
(facilitating the implementation of a metadata service) and has consensus
number one (making it implementable wait-free in an asynchronous system despite
faults). In addition to its low data replication factor, MDStore offers very
strong guarantees implementing multi-writer multi-reader atomic wait-free
semantics and tolerating any number of Byzantine readers and crash-faulty
writers. We further show that MDStore data replication overhead is optimal;
namely, we prove a lower bound of 2t+1 on the number of data replicas that
applies even to crash-tolerant storage with a fault-free metadata service
oracle. Finally, we prove that separating data from metadata for reducing the
cost of BFT storage is not possible without cryptographic assumptions. However,
our MDStore protocol uses only lightweight cryptographic hash functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4874</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4874</id><created>2013-05-21</created><authors><author><keyname>Hart</keyname><forenames>Sergiu</forenames></author><author><keyname>Nisan</keyname><forenames>Noam</forenames></author></authors><title>The Query Complexity of Correlated Equilibria</title><categories>cs.GT cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the complexity of finding a Correlated Equilibrium in an n-player
game in a model that allows the algorithm to make queries for players'
utilities at pure strategy profiles. Many randomized regret-matching dynamics
are known to yield an approximate correlated equilibrium quickly: in time that
is polynomial in the number of players, the number of strategies of each
player, and the approximation error. Here we show that both randomization and
approximation are necessary: no efficient deterministic algorithm can reach
even an approximate equilibrium and no efficient randomized algorithm can reach
an exact equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4883</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4883</id><created>2013-05-21</created><authors><author><keyname>Kiwi</keyname><forenames>Marcos</forenames></author><author><keyname>Fernandes</keyname><forenames>Cristina G.</forenames></author></authors><title>Repetition-free longest common subsequence of random sequences</title><categories>math.CO cs.DS</categories><comments>15 pages, 1 figure</comments><msc-class>05A19, 05A15</msc-class><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A repetition free Longest Common Subsequence (LCS) of two sequences x and y
is an LCS of x and y where each symbol may appear at most once. Let R denote
the length of a repetition free LCS of two sequences of n symbols each one
chosen randomly, uniformly, and independently over a k-ary alphabet. We study
the asymptotic, in n and k, behavior of R and establish that there are three
distinct regimes, depending on the relative speed of growth of n and k. For
each regime we establish the limiting behavior of R. In fact, we do more, since
we actually establish tail bounds for large deviations of R from its limiting
behavior.
  Our study is motivated by the so called exemplar model proposed by Sankoff
(1999) and the related similarity measure introduced by Adi et al. (2007). A
natural question that arises in this context, which as we show is related to
long standing open problems in the area of probabilistic combinatorics, is to
understand the asymptotic, in n and k, behavior of parameter R.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4886</identifier>
 <datestamp>2015-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4886</id><created>2013-05-21</created><authors><author><keyname>Paciorek</keyname><forenames>Christopher J.</forenames></author><author><keyname>Lipshitz</keyname><forenames>Benjamin</forenames></author><author><keyname>Zhuo</keyname><forenames>Wei</forenames></author><author><keyname>Prabhat</keyname></author><author><keyname>Kaufman</keyname><forenames>Cari G.</forenames></author><author><keyname>Thomas</keyname><forenames>Rollin C.</forenames></author></authors><title>Parallelizing Gaussian Process Calculations in R</title><categories>stat.CO cs.MS</categories><comments>21 pages, 8 figures</comments><journal-ref>Journal of Statistical Software 2015, Vol. 63, Number 10, 1-23</journal-ref><doi>10.18637/jss.v063.i10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider parallel computation for Gaussian process calculations to
overcome computational and memory constraints on the size of datasets that can
be analyzed. Using a hybrid parallelization approach that uses both threading
(shared memory) and message-passing (distributed memory), we implement the core
linear algebra operations used in spatial statistics and Gaussian process
regression in an R package called bigGP that relies on C and MPI. The approach
divides the matrix into blocks such that the computational load is balanced
across processes while communication between processes is limited. The package
provides an API enabling R programmers to implement Gaussian process-based
methods by using the distributed linear algebra operations without any C or MPI
coding. We illustrate the approach and software by analyzing an astrophysics
dataset with n=67,275 observations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4890</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4890</id><created>2013-05-21</created><authors><author><keyname>Klein</keyname><forenames>Martin</forenames></author><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author></authors><title>Extending Sitemaps for ResourceSync</title><categories>cs.DL</categories><comments>4 pages, 6 listings, accepted at JCDL 2013</comments><acm-class>H.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The documents used in the ResourceSync synchronization framework are based on
the widely adopted document format defined by the Sitemap protocol. In order to
address requirements of the framework, extensions to the Sitemap format were
necessary. This short paper describes the concerns we had about introducing
such extensions, the tests we did to evaluate their validity, and aspects of
the framework to address them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4897</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4897</id><created>2013-05-21</created><updated>2013-11-04</updated><authors><author><keyname>Lutz</keyname><forenames>Jonathan</forenames></author><author><keyname>Colbourn</keyname><forenames>Charles J.</forenames></author><author><keyname>Syrotiuk</keyname><forenames>Violet R.</forenames></author></authors><title>ATLAS: Adaptive Topology- and Load-Aware Scheduling</title><categories>cs.NI</categories><comments>This paper has been submitted to IEEE Transactions on Mobile
  Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The largest strength of contention-based MAC protocols is simultaneously the
largest weakness of their scheduled counterparts: the ability to adapt to
changes in network conditions. For scheduling to be competitive in mobile
wireless networks, continuous adaptation must be addressed. We propose ATLAS,
an Adaptive Topology- and Load-Aware Scheduling protocol to address this
problem. In ATLAS, each node employs a random schedule achieving its
persistence, the fraction of time a node is permitted to transmit, that is
computed in a topology and load dependent manner. A distributed auction (REACT)
piggybacks offers and claims onto existing network traffic to compute a
lexicographic max-min channel allocation. A node's persistence p is related to
its allocation. Its schedule achieving p is updated where and when needed,
without waiting for a frame boundary.We study how ATLAS adapts to controlled
changes in topology and load. Our results show that ATLAS adapts to most
network changes in less than 0.1s, with about 20% relative error, scaling with
network size. We further study ATLAS in more dynamic networks showing that it
keeps up with changes in topology and load sufficient for TCP to sustain
multi-hop flows, a struggle in IEEE 802.11 networks. The stable performance of
ATLAS supports the design of higher-layer services that inform, and are
informed by, the underlying communication network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4905</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4905</id><created>2013-05-21</created><authors><author><keyname>Yin</keyname><forenames>Xunrui</forenames></author><author><keyname>Wang</keyname><forenames>Yan</forenames></author><author><keyname>Li</keyname><forenames>Zongpeng</forenames></author><author><keyname>Wang</keyname><forenames>Xin</forenames></author><author><keyname>Xue</keyname><forenames>Xiangyang</forenames></author></authors><title>A Graph Minor Perspective to Multicast Network Coding</title><categories>cs.IT cs.DS math.IT</categories><comments>26 pages, 12 (sub-)figures, partially presented in INFOCOM 2013,
  submitted to Trans. IT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network Coding encourages information coding across a communication network.
While the necessity, benefit and complexity of network coding are sensitive to
the underlying graph structure of a network, existing theory on network coding
often treats the network topology as a black box, focusing on algebraic or
information theoretic aspects of the problem. This work aims at an in-depth
examination of the relation between algebraic coding and network topologies. We
mathematically establish a series of results along the direction of: if network
coding is necessary/beneficial, or if a particular finite field is required for
coding, then the network must have a corresponding hidden structure embedded in
its underlying topology, and such embedding is computationally efficient to
verify. Specifically, we first formulate a meta-conjecture, the NC-Minor
Conjecture, that articulates such a connection between graph theory and network
coding, in the language of graph minors. We next prove that the NC-Minor
Conjecture is almost equivalent to the Hadwiger Conjecture, which connects
graph minors with graph coloring. Such equivalence implies the existence of
$K_4$, $K_5$, $K_6$, and $K_{O(q/\log{q})}$ minors, for networks requiring
$\mathbb{F}_3$, $\mathbb{F}_4$, $\mathbb{F}_5$ and $\mathbb{F}_q$,
respectively. We finally prove that network coding can make a difference from
routing only if the network contains a $K_4$ minor, and this minor containment
result is tight. Practical implications of the above results are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4912</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4912</id><created>2013-05-21</created><updated>2015-04-03</updated><authors><author><keyname>Je&#x159;&#xe1;bek</keyname><forenames>Emil</forenames></author></authors><title>Rules with parameters in modal logic I</title><categories>cs.LO math.LO</categories><comments>63 pages</comments><msc-class>03B45, 68T15</msc-class><acm-class>F.4.1; F.4.2</acm-class><journal-ref>Annals of Pure and Applied Logic 166 (2015), no. 9, pp. 881--933</journal-ref><doi>10.1016/j.apal.2015.04.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study admissibility of inference rules and unification with parameters in
transitive modal logics (extensions of K4), in particular we generalize various
results on parameter-free admissibility and unification to the setting with
parameters.
  Specifically, we give a characterization of projective formulas generalizing
Ghilardi's characterization in the parameter-free case, leading to new proofs
of Rybakov's results that admissibility with parameters is decidable and
unification is finitary for logics satisfying suitable frame extension
properties (called cluster-extensible logics in this paper). We construct
explicit bases of admissible rules with parameters for cluster-extensible
logics, and give their semantic description. We show that in the case of
finitely many parameters, these logics have independent bases of admissible
rules, and determine which logics have finite bases.
  As a sideline, we show that cluster-extensible logics have various nice
properties: in particular, they are finitely axiomatizable, and have an
exponential-size model property. We also give a rather general characterization
of logics with directed (filtering) unification.
  In the sequel, we will use the same machinery to investigate the
computational complexity of admissibility and unification with parameters in
cluster-extensible logics, and we will adapt the results to logics with unique
top cluster (e.g., S4.2) and superintuitionistic logics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4914</identifier>
 <datestamp>2013-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4914</id><created>2013-05-21</created><updated>2013-06-23</updated><authors><author><keyname>Cygan</keyname><forenames>Marek</forenames></author><author><keyname>Grandoni</keyname><forenames>Fabrizio</forenames></author><author><keyname>Hermelin</keyname><forenames>Danny</forenames></author></authors><title>Tight Kernel Bounds for Problems on Graphs with Small Degeneracy</title><categories>cs.DS</categories><comments>Full version of ESA 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider kernelization for problems on d-degenerate graphs,
i.e. graphs such that any subgraph contains a vertex of degree at most $d$.
This graph class generalizes many classes of graphs for which effective
kernelization is known to exist, e.g. planar graphs, H-minor free graphs, and
H-topological-minor free graphs. We show that for several natural problems on
d-degenerate graphs the best known kernelization upper bounds are essentially
tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4917</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4917</id><created>2013-05-21</created><authors><author><keyname>Levin</keyname><forenames>Mark Sh.</forenames></author></authors><title>Note on Evaluation of Hierarchical Modular Systems</title><categories>cs.AI cs.SY</categories><comments>15 pages, 23 figures, 4 tables</comments><msc-class>68T20, 06A99, 90B50, 90C29, 90C59, 93-02, 93A13, 93B50, 93B51</msc-class><acm-class>A.1; H.1.1; H.4.2; I.1.2; I.2.8; I.5.2; J.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This survey note describes a brief systemic view to approaches for evaluation
of hierarchical composite (modular) systems. The list of considered issues
involves the following: (i) basic assessment scales (quantitative scale,
ordinal scale, multicriteria description, two kinds of poset-like scales), (ii)
basic types of scale transformations problems, (iii) basic types of scale
integration methods. Evaluation of the modular systems is considered as
assessment of system components (and their compatibility) and integration of
the obtained local estimates into the total system estimate(s). This process is
based on the above-mentioned problems (i.e., scale transformation and
integration). Illustrations of the assessment problems and evaluation
approaches are presented (including numerical examples).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4924</identifier>
 <datestamp>2014-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4924</id><created>2013-05-21</created><updated>2014-05-04</updated><authors><author><keyname>Garland</keyname><forenames>Joshua</forenames></author><author><keyname>Bradley</keyname><forenames>Elizabeth</forenames></author></authors><title>On the importance of nonlinear modeling in computer performance
  prediction</title><categories>nlin.CD cs.PF</categories><comments>Appeared in &quot;Proceedings of the 12th International Symposium on
  Intelligent Data Analysis&quot;</comments><journal-ref>Advances in Intelligent Data Analysis XII: Springer Lecture Notes
  in Computer Science, 2013</journal-ref><doi>10.1007/978-3-642-41398-8_19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computers are nonlinear dynamical systems that exhibit complex and sometimes
even chaotic behavior. The models used in the computer systems community,
however, are linear. This paper is an exploration of that disconnect: when
linear models are adequate for predicting computer performance and when they
are not. Specifically, we build linear and nonlinear models of the processor
load of an Intel i7-based computer as it executes a range of different
programs. We then use those models to predict the processor loads forward in
time and compare those forecasts to the true continuations of the time series
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4947</identifier>
 <datestamp>2013-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4947</id><created>2013-05-21</created><authors><author><keyname>Carvalho</keyname><forenames>Arthur</forenames></author><author><keyname>Araujo</keyname><forenames>Aluizio F. R.</forenames></author></authors><title>Improving NSGA-II with an Adaptive Mutation Operator</title><categories>cs.NE</categories><doi>10.1145/1570256.1570387</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of a Multiobjective Evolutionary Algorithm (MOEA) is
crucially dependent on the parameter setting of the operators. The most desired
control of such parameters presents the characteristic of adaptiveness, i.e.,
the capacity of changing the value of the parameter, in distinct stages of the
evolutionary process, using feedbacks from the search for determining the
direction and/or magnitude of changing. Given the great popularity of the
algorithm NSGA-II, the objective of this research is to create adaptive
controls for each parameter existing in this MOEA. With these controls, we
expect to improve even more the performance of the algorithm.
  In this work, we propose an adaptive mutation operator that has an adaptive
control which uses information about the diversity of candidate solutions for
controlling the magnitude of the mutation. A number of experiments considering
different problems suggest that this mutation operator improves the ability of
the NSGA-II for reaching the Pareto optimal Front and for getting a better
diversity among the final solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4952</identifier>
 <datestamp>2015-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4952</id><created>2013-05-21</created><updated>2014-03-13</updated><authors><author><keyname>Chamanbaz</keyname><forenames>Mohammadreza</forenames></author><author><keyname>Dabbene</keyname><forenames>Fabrizio</forenames></author><author><keyname>Tempo</keyname><forenames>Roberto</forenames></author><author><keyname>Venkataramanan</keyname><forenames>Venkatakrishnan</forenames></author><author><keyname>Wang</keyname><forenames>Qing-Guo</forenames></author></authors><title>A Statistical Learning Theory Approach for Uncertain Linear and Bilinear
  Matrix Inequalities</title><categories>math.OC cs.SY</categories><comments>19 pages, 2 figures, Accepted for Publication in Automatica</comments><doi>10.1016/j.automatica.2014.04.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of minimizing a linear functional
subject to uncertain linear and bilinear matrix inequalities, which depend in a
possibly nonlinear way on a vector of uncertain parameters. Motivated by recent
results in statistical learning theory, we show that probabilistic guaranteed
solutions can be obtained by means of randomized algorithms. In particular, we
show that the Vapnik-Chervonenkis dimension (VC-dimension) of the two problems
is finite, and we compute upper bounds on it. In turn, these bounds allow us to
derive explicitly the sample complexity of these problems. Using these bounds,
in the second part of the paper, we derive a sequential scheme, based on a
sequence of optimization and validation steps. The algorithm is on the same
lines of recent schemes proposed for similar problems, but improves both in
terms of complexity and generality. The effectiveness of this approach is shown
using a linear model of a robot manipulator subject to uncertain parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4955</identifier>
 <datestamp>2013-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4955</id><created>2013-05-21</created><updated>2013-06-26</updated><authors><author><keyname>Oliveira</keyname><forenames>Renato</forenames></author><author><keyname>Adeodato</keyname><forenames>Paulo</forenames></author><author><keyname>Carvalho</keyname><forenames>Arthur</forenames></author><author><keyname>Viegas</keyname><forenames>Icamaan</forenames></author><author><keyname>Diego</keyname><forenames>Christian</forenames></author><author><keyname>Ing-Ren</keyname><forenames>Tsang</forenames></author></authors><title>A Data Mining Approach to Solve the Goal Scoring Problem</title><categories>cs.AI cs.LG</categories><doi>10.1109/IJCNN.2009.5178616</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In soccer, scoring goals is a fundamental objective which depends on many
conditions and constraints. Considering the RoboCup soccer 2D-simulator, this
paper presents a data mining-based decision system to identify the best time
and direction to kick the ball towards the goal to maximize the overall chances
of scoring during a simulated soccer match. Following the CRISP-DM methodology,
data for modeling were extracted from matches of major international
tournaments (10691 kicks), knowledge about soccer was embedded via
transformation of variables and a Multilayer Perceptron was used to estimate
the scoring chance. Experimental performance assessment to compare this
approach against previous LDA-based approach was conducted from 100 matches.
Several statistical metrics were used to analyze the performance of the system
and the results showed an increase of 7.7% in the number of kicks, producing an
overall increase of 78% in the number of goals scored.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4957</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4957</id><created>2013-05-21</created><authors><author><keyname>Bau</keyname><forenames>Alexander</forenames></author><author><keyname>Waldmann</keyname><forenames>Johannes</forenames></author></authors><title>Propositional Encoding of Constraints over Tree-Shaped Data</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a functional programming language for specifying constraints over
tree-shaped data. The language allows for Haskell-like algebraic data types and
pattern matching. Our constraint compiler CO4 translates these programs into
satisfiability problems in propositional logic. We present an application from
the area of automated analysis of (non-)termination of rewrite systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4974</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4974</id><created>2013-05-21</created><authors><author><keyname>Newman</keyname><forenames>M. E. J.</forenames></author></authors><title>Community detection and graph partitioning</title><categories>cs.SI physics.data-an physics.soc-ph</categories><comments>5 pages, 2 figures</comments><journal-ref>Europhys. Lett. 103, 28003 (2013)</journal-ref><doi>10.1209/0295-5075/103/28003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many methods have been proposed for community detection in networks. Some of
the most promising are methods based on statistical inference, which rest on
solid mathematical foundations and return excellent results in practice. In
this paper we show that two of the most widely used inference methods can be
mapped directly onto versions of the standard minimum-cut graph partitioning
problem, which allows us to apply any of the many well-understood partitioning
algorithms to the solution of community detection problems. We illustrate the
approach by adapting the Laplacian spectral partitioning method to perform
community inference, testing the resulting algorithm on a range of examples,
including computer-generated and real-world networks. Both the quality of the
results and the running time rival the best previous methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4976</identifier>
 <datestamp>2014-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4976</id><created>2013-05-21</created><updated>2013-11-07</updated><authors><author><keyname>Choi</keyname><forenames>Junil</forenames></author><author><keyname>Chance</keyname><forenames>Zachary</forenames></author><author><keyname>Love</keyname><forenames>David J.</forenames></author><author><keyname>Madhow</keyname><forenames>Upamanyu</forenames></author></authors><title>Noncoherent Trellis Coded Quantization: A Practical Limited Feedback
  Technique for Massive MIMO Systems</title><categories>cs.IT math.IT</categories><comments>30 pages, 13 figures, IEEE Transactions on Communications, accepted
  for publication (typos corrected)</comments><doi>10.1109/TCOMM.2013.111413.130379</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate channel state information (CSI) is essential for attaining
beamforming gains in single-user (SU) multiple-input multiple-output (MIMO) and
multiplexing gains in multi-user (MU) MIMO wireless communication systems.
State-of-the-art limited feedback schemes, which rely on pre-defined codebooks
for channel quantization, are only appropriate for a small number of transmit
antennas and low feedback overhead. In order to scale informed transmitter
schemes to emerging massive MIMO systems with a large number of transmit
antennas at the base station, one common approach is to employ time division
duplexing (TDD) and to exploit the implicit feedback obtained from channel
reciprocity. However, most existing cellular deployments are based on frequency
division duplexing (FDD), hence it is of great interest to explore backwards
compatible massive MIMO upgrades of such systems. For a fixed feedback rate per
antenna, the number of codewords for quantizing the channel grows exponentially
with the number of antennas, hence generating feedback based on look-up from a
standard vector quantized codebook does not scale. In this paper, we propose
noncoherent trellis-coded quantization (NTCQ), whose encoding complexity scales
linearly with the number of antennas. The approach exploits the duality between
source encoding in a Grassmannian manifold and noncoherent sequence detection.
Furthermore, since noncoherent detection can be realized near-optimally using a
bank of coherent detectors, we obtain a low-complexity implementation of NTCQ
encoding using an off-the-shelf Viterbi algorithm applied to standard trellis
coded quantization. We also develop advanced NTCQ schemes which utilize various
channel properties such as temporal/spatial correlations. Simulation results
show the proposed NTCQ and its extensions can achieve near-optimal performance
with moderate complexity and feedback overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4979</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4979</id><created>2013-05-21</created><authors><author><keyname>Khabbazibasmenj</keyname><forenames>Arash</forenames></author><author><keyname>Hassanien</keyname><forenames>Aboulnasr</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author><author><keyname>Morency</keyname><forenames>Matthew W.</forenames></author></authors><title>Efficient Transmit Beamspace Design for Search-free Based DOA Estimation
  in MIMO Radar</title><categories>cs.IT math.IT</categories><comments>32 pages, 10 figures, submitted to the IEEE Trans. Signal Processing
  in May 2013</comments><journal-ref>A. Khabbazibasmenj, A. Hassanien, S.A. Vorobyov, M.W. Morency,
  &quot;Efficient transmit beamspace design for search-free based DOA estimation in
  MIMO radar,&quot; IEEE Trans. Signal Processing, vol. 62, no. 6, pp. 1490-1500,
  Mar. 2014</journal-ref><doi>10.1109/TSP.2014.2299513</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the problem of transmit beamspace design for
multiple-input multiple-output (MIMO) radar with colocated antennas in
application to direction-of-arrival (DOA) estimation. A new method for
designing the transmit beamspace matrix that enables the use of search-free DOA
estimation techniques at the receiver is introduced. The essence of the
proposed method is to design the transmit beamspace matrix based on minimizing
the difference between a desired transmit beampattern and the actual one under
the constraint of uniform power distribution across the transmit array
elements. The desired transmit beampattern can be of arbitrary shape and is
allowed to consist of one or more spatial sectors. The number of transmit
waveforms is even but otherwise arbitrary. To allow for simple search-free DOA
estimation algorithms at the receive array, the rotational invariance property
is established at the transmit array by imposing a specific structure on the
beamspace matrix. Semi-definite relaxation is used to transform the proposed
formulation into a convex problem that can be solved efficiently. We also
propose a spatial-division based design (SDD) by dividing the spatial domain
into several subsectors and assigning a subset of the transmit beams to each
subsector. The transmit beams associated with each subsector are designed
separately. Simulation results demonstrate the improvement in the DOA
estimation performance offered by using the proposed joint and SDD transmit
beamspace design methods as compared to the traditional MIMO radar technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4980</identifier>
 <datestamp>2014-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4980</id><created>2013-05-21</created><authors><author><keyname>Fang</keyname><forenames>Hao</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author><author><keyname>Jiang</keyname><forenames>Hai</forenames></author><author><keyname>Taheri</keyname><forenames>Omid</forenames></author></authors><title>Permutation Meets Parallel Compressed Sensing: How to Relax Restricted
  Isometry Property for 2D Sparse Signals</title><categories>cs.IT math.IT</categories><comments>30 pages, 10 figures, 3 tables, submitted to the IEEE Trans. Signal
  Processing in November 2012</comments><journal-ref>H. Fang, S.A. Vorobyov, H. Jiang, O. Taheri, &quot;Permutation meets
  parallel compressed sensing. How to relax RIP for 2D srarse signals,&quot; IEEE
  Trans. Signal Processing, vol. 62, no. 1, pp. 196-210, Jan. 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional compressed sensing considers sampling a 1D signal. For a
multidimensional signal, if reshaped into a vector, the required size of the
sensing matrix becomes dramatically large, which increases the storage and
computational complexity significantly. To solve this problem, we propose to
reshape the multidimensional signal into a 2D signal and sample the 2D signal
using compressed sensing column by column with the same sensing matrix. It is
referred to as parallel compressed sensing, and it has much lower storage and
computational complexity. For a given reconstruction performance of parallel
compressed sensing, if a so-called acceptable permutation is applied to the 2D
signal, we show that the corresponding sensing matrix has a smaller required
order of restricted isometry property condition, and thus, storage and
computation requirements are further lowered. A zigzag-scan-based permutation,
which is shown to be particularly useful for signals satisfying a layer model,
is introduced and investigated. As an application of the parallel compressed
sensing with the zigzag-scan-based permutation, a video compression scheme is
presented. It is shown that the zigzag-scan-based permutation increases the
peak signal-to-noise ratio of reconstructed images and video frames.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4987</identifier>
 <datestamp>2014-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4987</id><created>2013-05-21</created><updated>2014-04-29</updated><authors><author><keyname>Tibshirani</keyname><forenames>Julie</forenames></author><author><keyname>Manning</keyname><forenames>Christopher D.</forenames></author></authors><title>Robust Logistic Regression using Shift Parameters (Long Version)</title><categories>cs.AI cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Annotation errors can significantly hurt classifier performance, yet datasets
are only growing noisier with the increased use of Amazon Mechanical Turk and
techniques like distant supervision that automatically generate labels. In this
paper, we present a robust extension of logistic regression that incorporates
the possibility of mislabelling directly into the objective. Our model can be
trained through nearly the same means as logistic regression, and retains its
efficiency on high-dimensional datasets. Through named entity recognition
experiments, we demonstrate that our approach can provide a significant
improvement over the standard model when annotation errors are present.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4993</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4993</id><created>2013-05-21</created><authors><author><keyname>Chen</keyname><forenames>Shengbo</forenames></author><author><keyname>Bansal</keyname><forenames>Tarun</forenames></author><author><keyname>Sun</keyname><forenames>Yin</forenames></author><author><keyname>Sinha</keyname><forenames>Prasun</forenames></author><author><keyname>Shroff</keyname><forenames>Ness B.</forenames></author></authors><title>Life-Add: Lifetime Adjustable Design for WiFi Networks with
  Heterogeneous Energy Supplies</title><categories>cs.IT cs.NI cs.SY math.IT</categories><comments>This is the technical report of our WiOpt paper. The paper received
  the best student paper award at IEEE WiOpt 2013. The first three authors are
  co-primary authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  WiFi usage significantly reduces the battery lifetime of handheld devices
such as smartphones and tablets, due to its high energy consumption. In this
paper, we propose &quot;Life-Add&quot;: a Lifetime Adjustable design for WiFi networks,
where the devices are powered by battery, electric power, and/or renewable
energy. In Life-Add, a device turns off its radio to save energy when the
channel is sensed to be busy, and sleeps for a random time period before
sensing the channel again. Life-Add carefully controls the devices' average
sleep periods to improve their throughput while satisfying their operation time
requirement. It is proven that Life-Add achieves near-optimal proportional-fair
utility performance for single access point (AP) scenarios. Moreover, Life-Add
alleviates the near-far effect and hidden terminal problem in general multiple
AP scenarios. Our ns-3 simulations show that Life-Add simultaneously improves
the lifetime, throughput, and fairness performance of WiFi networks, and
coexists harmoniously with IEEE 802.11.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4996</identifier>
 <datestamp>2013-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4996</id><created>2013-05-21</created><authors><author><keyname>Gong</keyname><forenames>Jie</forenames></author><author><keyname>Thompson</keyname><forenames>John S.</forenames></author><author><keyname>Zhou</keyname><forenames>Sheng</forenames></author><author><keyname>Niu</keyname><forenames>Zhisheng</forenames></author></authors><title>Base Station Sleeping and Resource Allocation in Renewable Energy
  Powered Cellular Networks</title><categories>cs.IT math.IT</categories><comments>30 pages, 10 figures, submitted to IEEE Transaction on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider energy-efficient wireless resource management in cellular
networks where BSs are equipped with energy harvesting devices, using
statistical information for traffic intensity and harvested energy. The problem
is formulated as adapting BSs' on-off states, active resource blocks (e.g.
subcarriers) as well as power allocation to minimize the average grid power
consumption in a given time period while satisfying the users' quality of
service (blocking probability) requirements. It is transformed into an
unconstrained optimization problem to minimize a weighted sum of grid power
consumption and blocking probability. A two-stage dynamic programming (DP)
algorithm is then proposed to solve this optimization problem, by which the
BSs' on-off states are optimized in the first stage, and the active BS's
resource blocks are allocated iteratively in the second stage. Compared with
the optimal joint BSs' on-off states and active resource blocks allocation
algorithm, the proposed algorithm greatly reduces the computational complexity,
while at the same time achieves close to the optimal energy saving performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.4999</identifier>
 <datestamp>2013-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.4999</id><created>2013-05-21</created><updated>2013-12-08</updated><authors><author><keyname>Mehdian</keyname><forenames>Saied</forenames></author><author><keyname>Liang</keyname><forenames>Ben</forenames></author></authors><title>Optimal Frame Transmission for Scalable Video with Hierarchical
  Prediction Structure</title><categories>cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An optimal frame transmission scheme is presented for streaming scalable
video over a link with limited capacity. The objective is to select a
transmission sequence of frames and their transmission schedule such that the
overall video quality is maximized. The problem is solved for two general
classes of hierarchical prediction structures, which include as a special case
the popular dyadic structure. Based on a new characterization of the
interdependence among frames in terms of trees, structural properties of an
optimal transmission schedule are derived. These properties lead to the
development of a jointly optimal frame selection and scheduling algorithm,
which has computational complexity that is quadratic in the number of frames.
Simulation results show that the optimal scheme substantially outperforms three
existing alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5019</identifier>
 <datestamp>2013-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5019</id><created>2013-05-22</created><authors><author><keyname>Sambhanthan</keyname><forenames>Arunasalam</forenames></author><author><keyname>Thelijjagoda</keyname><forenames>Samantha</forenames></author><author><keyname>Tan</keyname><forenames>Joseph</forenames></author></authors><title>Implications for Utilizing YouTube based Community Interactions for
  Destination Marketing</title><categories>cs.CY cs.HC</categories><comments>Conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent time, YouTube has evolved into a powerful medium for social
interaction. Utilizing YouTube for enhancing marketing endeavors is a strategy
practiced by marketing professionals across several industries. This paper
rationalizes on the different ways and means of leveraging YouTube-based
platforms for effective destination marketing by the hospitality industry
(hotels). More specifically, the typology of virtual communities is adapted to
evaluate the YouTube platform for effective destination marketing. Comments
made by YouTube users have been subjected to a content analysis and the results
are reported here under the five broad clusters of virtual communities.
Implications for utilizing YouTube-based community interactions for destination
marketing are also highlighted as part of the outcome of this research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5024</identifier>
 <datestamp>2013-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5024</id><created>2013-05-22</created><authors><author><keyname>Gulati</keyname><forenames>Shilpa</forenames></author><author><keyname>Jhurani</keyname><forenames>Chetan</forenames></author><author><keyname>Kuipers</keyname><forenames>Benjamin</forenames></author></authors><title>A Nonlinear Constrained Optimization Framework for Comfortable and
  Customizable Motion Planning of Nonholonomic Mobile Robots - Part I</title><categories>cs.RO cs.CE math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this series of papers, we present a motion planning framework for planning
comfortable and customizable motion of nonholonomic mobile robots such as
intelligent wheelchairs and autonomous cars. In this first one we present the
mathematical foundation of our framework.
  The motion of a mobile robot that transports a human should be comfortable
and customizable. We identify several properties that a trajectory must have
for comfort. We model motion discomfort as a weighted cost functional and
define comfortable motion planning as a nonlinear constrained optimization
problem of computing trajectories that minimize this discomfort given the
appropriate boundary conditions and constraints. The optimization problem is
infinite-dimensional and we discretize it using conforming finite elements. We
also outline a method by which different users may customize the motion to
achieve personal comfort.
  There exists significant past work in kinodynamic motion planning, to the
best of our knowledge, our work is the first comprehensive formulation of
kinodynamic motion planning for a nonholonomic mobile robot as a nonlinear
optimization problem that includes all of the following - a careful analysis of
boundary conditions, continuity requirements on trajectory, dynamic
constraints, obstacle avoidance constraints, and a robust numerical
implementation.
  In this paper, we present the mathematical foundation of the motion planning
framework and formulate the full nonlinear constrained optimization problem. We
describe, in brief, the discretization method using finite elements and the
process of computing initial guesses for the optimization problem. Details of
the above two are presented in Part II of the series.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5025</identifier>
 <datestamp>2013-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5025</id><created>2013-05-22</created><authors><author><keyname>Gulati</keyname><forenames>Shilpa</forenames></author><author><keyname>Jhurani</keyname><forenames>Chetan</forenames></author><author><keyname>Kuipers</keyname><forenames>Benjamin</forenames></author></authors><title>A Nonlinear Constrained Optimization Framework for Comfortable and
  Customizable Motion Planning of Nonholonomic Mobile Robots - Part II</title><categories>cs.RO cs.CE math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this series of papers, we present a motion planning framework for planning
comfortable and customizable motion of nonholonomic mobile robots such as
intelligent wheelchairs and autonomous cars. In Part I, we presented the
mathematical foundation of our framework, where we model motion discomfort as a
weighted cost functional and define comfortable motion planning as a nonlinear
constrained optimization problem of computing trajectories that minimize this
discomfort given the appropriate boundary conditions and constraints.
  In this paper, we discretize the infinite-dimensional optimization problem
using conforming finite elements. We describe shape functions to handle
different kinds of boundary conditions and the choice of unknowns to obtain a
sparse Hessian matrix. We also describe in detail how any trajectory
computation problem can have infinitely many locally optimal solutions and our
method of handling them. Additionally, since we have a nonlinear and
constrained problem, computation of high quality initial guesses is crucial for
efficient solution. We show how to compute them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5029</identifier>
 <datestamp>2014-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5029</id><created>2013-05-22</created><updated>2014-04-29</updated><authors><author><keyname>Zhang</keyname><forenames>Yuchen</forenames></author><author><keyname>Duchi</keyname><forenames>John C.</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author></authors><title>Divide and Conquer Kernel Ridge Regression: A Distributed Algorithm with
  Minimax Optimal Rates</title><categories>math.ST cs.LG stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish optimal convergence rates for a decomposition-based scalable
approach to kernel ridge regression. The method is simple to describe: it
randomly partitions a dataset of size N into m subsets of equal size, computes
an independent kernel ridge regression estimator for each subset, then averages
the local solutions into a global predictor. This partitioning leads to a
substantial reduction in computation time versus the standard approach of
performing kernel ridge regression on all N samples. Our two main theorems
establish that despite the computational speed-up, statistical optimality is
retained: as long as m is not too large, the partition-based estimator achieves
the statistical minimax rate over all estimators using the set of N samples. As
concrete examples, our theory guarantees that the number of processors m may
grow nearly linearly for finite-rank kernels and Gaussian kernels and
polynomially in N for Sobolev spaces, which in turn allows for substantial
reductions in computational cost. We conclude with experiments on both
simulated data and a music-prediction task that complement our theoretical
results, exhibiting the computational and statistical benefits of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5030</identifier>
 <datestamp>2013-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5030</id><created>2013-05-22</created><authors><author><keyname>Tolpin</keyname><forenames>David</forenames></author><author><keyname>Beja</keyname><forenames>Tal</forenames></author><author><keyname>Shimony</keyname><forenames>Solomon Eyal</forenames></author><author><keyname>Felner</keyname><forenames>Ariel</forenames></author><author><keyname>Karpas</keyname><forenames>Erez</forenames></author></authors><title>Towards Rational Deployment of Multiple Heuristics in A*</title><categories>cs.AI</categories><comments>7 pages, IJCAI 2013, to appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The obvious way to use several admissible heuristics in A* is to take their
maximum. In this paper we aim to reduce the time spent on computing heuristics.
We discuss Lazy A*, a variant of A* where heuristics are evaluated lazily: only
when they are essential to a decision to be made in the A* search process. We
present a new rational meta-reasoning based scheme, rational lazy A*, which
decides whether to compute the more expensive heuristics at all, based on a
myopic value of information estimate. Both methods are examined theoretically.
Empirical evaluation on several domains supports the theoretical results, and
shows that lazy A* and rational lazy A* are state-of-the-art heuristic
combination methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5040</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5040</id><created>2013-05-22</created><updated>2013-06-04</updated><authors><author><keyname>Bercher</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>LIGM</affiliation></author></authors><title>Some properties of generalized Fisher information in the context of
  nonextensive thermostatistics</title><categories>math-ph cond-mat.stat-mech cs.IT math.IT math.MP</categories><proxy>ccsd</proxy><journal-ref>Physica A: Statistical Mechanics and its Applications 392, 15
  (2013) 3140-3154</journal-ref><doi>10.1016/j.physa.2013.03.062</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present two extended forms of Fisher information that fit well in the
context of nonextensive thermostatistics. We show that there exists an
interplay between these generalized Fisher information, the generalized
$q$-Gaussian distributions and the $q$-entropies. The minimum of the
generalized Fisher information among distributions with a fixed moment, or with
a fixed $q$-entropy is attained, in both cases, by a generalized $q$-Gaussian
distribution. This complements the fact that the $q$-Gaussians maximize the
$q$-entropies subject to a moment constraint, and yields new variational
characterizations of the generalized $q$-Gaussians. We show that the
generalized Fisher information naturally pop up in the expression of the time
derivative of the $q$-entropies, for distributions satisfying a certain
nonlinear heat equation. This result includes as a particular case the
classical de Bruijn identity. Then we study further properties of the
generalized Fisher information and of their minimization. We show that, though
non additive, the generalized Fisher information of a combined system is upper
bounded. In the case of mixing, we show that the generalized Fisher information
is convex for $q\geq1.$ Finally, we show that the minimization of the
generalized Fisher information subject to moment constraints satisfies a
Legendre structure analog to the Legendre structure of thermodynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1305.5046</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1305.5046</id><created>2013-05-22</created><updated>2015-03-11</updated><authors><author><keyname>Zhang</keyname><forenames>Wen-yi</forenames></author><author><keyname>Guan</keyname><forenames>Wei</forenames></author><author><keyname>Ma</keyname><forenames>Ji-hui</forenames></author><author><keyname>Tian</keyname><forenames>Jun-fang</forenames></author></authors><title>A Nonlinear Pairwise Swapping Dynamics to Model the Selfish Rerouting
  Evolutionary Game</title><categories>math.OC cs.GT</categories><comments>19 pages and 5 figures in Networks and Spatial Economics (Published
  Online in Jan., 2015)</comments><doi>10.1007/s11067-014-9281-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a nonlinear revision protocol is proposed and embedded into
the traffic evolution equation of the classical proportional-switch adjustment
process (PAP), developing the present nonlinear pairwise swapping dynamics
(NPSD) to describe the selfish rerouting evolutionary game. It is demonstrated
that i) NPSD and PAP require the same amount of network information acquisition
in the route-swaps, ii) NPSD is able to prevent the over-swapping deficiency
under a plausible behavior description; iii) NPSD can maintain the solution
invariance, which makes the trial and error process to identify a feasible
step-length in a NPSD-based swapping algorithm is unnecessary, and iv) NPSD is
a rational behavior swapping process and the continuous-time NPSD is globally
convergent. Using the day-to-day NPSD, a numerical example is conducted to
explore the effects of the reaction sensitivity on traffic evolution and
characterize the convergence of discrete-time NPSD.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="45000" completeListSize="102538">1122234|46001</resumptionToken>
</ListRecords>
</OAI-PMH>
