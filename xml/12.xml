<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:42:19Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|11001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2331</identifier>
 <datestamp>2010-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2331</id><created>2010-01-14</created><authors><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Information Theoretic Bounds for Low-Rank Matrix Completion</title><categories>cs.IT cs.CC math.IT math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the low-rank matrix completion problem from an information
theoretic perspective. The completion problem is rephrased as a communication
problem of an (uncoded) low-rank matrix source over an erasure channel. The
paper then uses achievability and converse arguments to present order-wise
optimal bounds for the completion problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2334</identifier>
 <datestamp>2010-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2334</id><created>2010-01-13</created><updated>2010-08-31</updated><authors><author><keyname>Fanous</keyname><forenames>Anthony</forenames></author><author><keyname>Ephremides</keyname><forenames>Anthony</forenames></author></authors><title>Network-Level Cooperative Protocols for Wireless Multicasting: Stable
  Throughput Analysis and Use of Network Coding</title><categories>cs.IT math.IT</categories><comments>12 pages, 4 figures. Final version adjusted to be in conform with the
  ITW'10 published version. Minor modifications. Results unchanged</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the impact of network coding at the relay node
on the stable throughput rate in multicasting cooperative wireless networks.
The proposed protocol adopts Network-level cooperation in contrast to the
traditional physical layer cooperative protocols and in addition uses random
linear network coding at the relay node. The traffic is assumed to be bursty
and the relay node forwards its packets during the periods of source silence
which allows better utilization for channel resources. Our results show that
cooperation will lead to higher stable throughput rates than conventional
retransmission policies and that the use of random linear network coding at the
relay can further increase the stable throughput with increasing Network Coding
field size or number of packets over which encoding is performed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2356</identifier>
 <datestamp>2011-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2356</id><created>2010-01-13</created><authors><author><keyname>Duan</keyname><forenames>Runyao</forenames></author><author><keyname>Grassl</keyname><forenames>Markus</forenames></author><author><keyname>Ji</keyname><forenames>Zhengfeng</forenames></author><author><keyname>Zeng</keyname><forenames>Bei</forenames></author></authors><title>Multi-Error-Correcting Amplitude Damping Codes</title><categories>quant-ph cs.IT math.IT</categories><comments>5 pages. Submitted to ISIT 2010</comments><journal-ref>Proceedings 2010 IEEE International Symposium on Information
  Theory (ISIT 2010), Austin, USA, June 2010, pp. 2672-2676</journal-ref><doi>10.1109/ISIT.2010.5513648</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct new families of multi-error-correcting quantum codes for the
amplitude damping channel. Our key observation is that, with proper encoding,
two uses of the amplitude damping channel simulate a quantum erasure channel.
This allows us to use concatenated codes with quantum erasure-correcting codes
as outer codes for correcting multiple amplitude damping errors. Our new codes
are degenerate stabilizer codes and have parameters which are better than the
amplitude damping codes obtained by any previously known construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2362</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2362</id><created>2010-01-13</created><updated>2010-01-22</updated><authors><author><keyname>Ganesh</keyname><forenames>Arvind</forenames></author><author><keyname>Wright</keyname><forenames>John</forenames></author><author><keyname>Li</keyname><forenames>Xiaodong</forenames></author><author><keyname>Candes</keyname><forenames>Emmanuel J.</forenames></author><author><keyname>Ma</keyname><forenames>Yi</forenames></author></authors><title>Dense Error Correction for Low-Rank Matrices via Principal Component
  Pursuit</title><categories>cs.IT math.IT</categories><comments>Submitted to ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of recovering a low-rank matrix when some of its
entries, whose locations are not known a priori, are corrupted by errors of
arbitrarily large magnitude. It has recently been shown that this problem can
be solved efficiently and effectively by a convex program named Principal
Component Pursuit (PCP), provided that the fraction of corrupted entries and
the rank of the matrix are both sufficiently small. In this paper, we extend
that result to show that the same convex program, with a slightly improved
weighting parameter, exactly recovers the low-rank matrix even if &quot;almost all&quot;
of its entries are arbitrarily corrupted, provided the signs of the errors are
random. We corroborate our result with simulations on randomly generated
matrices and errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2363</identifier>
 <datestamp>2010-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2363</id><created>2010-01-13</created><authors><author><keyname>Zhou</keyname><forenames>Zihan</forenames></author><author><keyname>Li</keyname><forenames>Xiaodong</forenames></author><author><keyname>Wright</keyname><forenames>John</forenames></author><author><keyname>Candes</keyname><forenames>Emmanuel</forenames></author><author><keyname>Ma</keyname><forenames>Yi</forenames></author></authors><title>Stable Principal Component Pursuit</title><categories>cs.IT math.IT</categories><comments>5-page paper submitted to ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the problem of recovering a low-rank matrix (the
principal components) from a high-dimensional data matrix despite both small
entry-wise noise and gross sparse errors. Recently, it has been shown that a
convex program, named Principal Component Pursuit (PCP), can recover the
low-rank matrix when the data matrix is corrupted by gross sparse errors. We
further prove that the solution to a related convex program (a relaxed PCP)
gives an estimate of the low-rank matrix that is simultaneously stable to small
entrywise noise and robust to gross sparse errors. More precisely, our result
shows that the proposed convex program recovers the low-rank matrix even though
a positive fraction of its entries are arbitrarily corrupted, with an error
bound proportional to the noise level. We present simulation results to support
our result and demonstrate that the new convex program accurately recovers the
principal components (the low-rank matrix) under quite broad conditions. To our
knowledge, this is the first result that shows the classical Principal
Component Analysis (PCA), optimal for small i.i.d. noise, can be made robust to
gross sparse errors; or the first that shows the newly proposed PCP can be made
stable to small entry-wise perturbations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2376</identifier>
 <datestamp>2010-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2376</id><created>2010-01-14</created><authors><author><keyname>Datta</keyname><forenames>Tanumay</forenames></author><author><keyname>Srinidhi</keyname><forenames>N.</forenames></author><author><keyname>Chockalingam</keyname><forenames>A.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>A Hybrid RTS-BP Algorithm for Improved Detection of Large-MIMO M-QAM
  Signals</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-complexity near-optimal detection of large-MIMO signals has attracted
recent research. Recently, we proposed a local neighborhood search algorithm,
namely `reactive tabu search' (RTS) algorithm, as well as a factor-graph based
`belief propagation' (BP) algorithm for low-complexity large-MIMO detection.
The motivation for the present work arises from the following two observations
on the above two algorithms: $i)$ RTS works for general M-QAM. Although RTS was
shown to achieve close to optimal performance for 4-QAM in large dimensions,
significant performance improvement was still possible for higher-order QAM
(e.g., 16- and 64-QAM). ii) BP also was shown to achieve near-optimal
performance for large dimensions, but only for $\{\pm 1\}$ alphabet. In this
paper, we improve the large-MIMO detection performance of higher-order QAM
signals by using a hybrid algorithm that employs RTS and BP. In particular,
motivated by the observation that when a detection error occurs at the RTS
output, the least significant bits (LSB) of the symbols are mostly in error, we
propose to first reconstruct and cancel the interference due to bits other than
LSBs at the RTS output and feed the interference cancelled received signal to
the BP algorithm to improve the reliability of the LSBs. The output of the BP
is then fed back to RTS for the next iteration. Our simulation results show
that in a 32 x 32 V-BLAST system, the proposed RTS-BP algorithm performs better
than RTS by about 3.5 dB at $10^{-3}$ uncoded BER and by about 2.5 dB at
$3\times 10^{-4}$ rate-3/4 turbo coded BER with 64-QAM at the same order of
complexity as RTS. We also illustrate the performance of large-MIMO detection
in frequency-selective fading channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2386</identifier>
 <datestamp>2010-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2386</id><created>2010-01-14</created><authors><author><keyname>Kuhn</keyname><forenames>Adrian</forenames></author><author><keyname>Erni</keyname><forenames>David</forenames></author><author><keyname>Nierstrasz</keyname><forenames>Oscar</forenames></author></authors><title>Towards Improving the Mental Model of Software Developers through
  Cartographic Visualization</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software is intangible and knowledge about software systems is typically
tacit. The mental model of software developers is thus an important factor in
software engineering. It is our vision that developers should be able to refer
to code as being &quot;up in the north&quot;, &quot;over in the west&quot;, or &quot;down-under in the
south&quot;. We want to provide developers, and everyone else involved in software
development, with a *shared*, spatial and stable mental model of their software
project. We aim to reinforce this by embedding a cartographic visualization in
the IDE (Integrated Development Environment). The visualization is always
visible in the bottom-left, similar to the GPS navigation device for car
drivers. For each development task, related information is displayed on the
map. In this paper we present CODEMAP, an eclipse plug-in, and report on
preliminary results from an ongoing user study with professional developers and
students.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2391</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2391</id><created>2010-01-14</created><updated>2010-04-04</updated><authors><author><keyname>Raveh</keyname><forenames>Barak</forenames></author><author><keyname>Enosh</keyname><forenames>Angela</forenames></author><author><keyname>Halperin</keyname><forenames>Dan</forenames></author></authors><title>A Little More, a Lot Better: Improving Path Quality by a Simple Path
  Merging Algorithm</title><categories>cs.RO cs.AI</categories><comments>8 pages, 5 figures</comments><acm-class>I.2.9</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sampling-based motion planners are an effective means for generating
collision-free motion paths. However, the quality of these motion paths (with
respect to quality measures such as path length, clearance, smoothness or
energy) is often notoriously low, especially in high-dimensional configuration
spaces. We introduce a simple algorithm for merging an arbitrary number of
input motion paths into a hybrid output path of superior quality, for a broad
and general formulation of path quality. Our approach is based on the
observation that the quality of certain sub-paths within each solution may be
higher than the quality of the entire path. A dynamic-programming algorithm,
which we recently developed for comparing and clustering multiple motion paths,
reduces the running time of the merging algorithm significantly. We tested our
algorithm in motion-planning problems with up to 12 degrees of freedom. We show
that our algorithm is able to merge a handful of input paths produced by
several different motion planners to produce output paths of much higher
quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2405</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2405</id><created>2010-01-14</created><authors><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Dendritic Cells for Real-Time Anomaly Detection</title><categories>cs.AI cs.NE</categories><comments>2 pages, 1 figure, Workshop on Artificial Immune Systems and Immune
  System Modelling (AISB06), Bristol, UK</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dendritic Cells (DCs) are innate immune system cells which have the power to
activate or suppress the immune system. The behaviour of human of human DCs is
abstracted to form an algorithm suitable for anomaly detection. We test this
algorithm on the real-time problem of port scan detection. Our results show a
significant difference in artificial DC behaviour for an outgoing portscan when
compared to behaviour for normal processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2410</identifier>
 <datestamp>2010-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2410</id><created>2010-01-14</created><updated>2010-05-04</updated><authors><author><keyname>Kobayashi</keyname><forenames>Mari</forenames><affiliation>Shitz</affiliation></author><author><keyname>Piantanida</keyname><forenames>Pablo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Yang</keyname><forenames>Sheng</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>On the Secrecy Degress of Freedom of the Multi-Antenna Block Fading
  Wiretap Channels</title><categories>cs.IT math.IT</categories><comments>to appear in Proc. of IEEE International Symposium on Information
  Theory (ISIT2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the multi-antenna wiretap channel in which the transmitter wishes
to send a confidential message to its receiver while keeping it secret to the
eavesdropper. It has been known that the secrecy capacity of such a channel
does not increase with signal-to-noise ratio when the transmitter has no
channel state information (CSI) under mild conditions. Motivated by Jafar's
robust interference alignment technique, we study the so-called staggered
multi-antenna block-fading wiretap channel where the legitimate receiver and
the eavesdropper have different temporal correlation structures. Assuming no
CSI at transmitter, we characterize lower and upper bounds on the secrecy
degrees of freedom (s.d.o.f.) of the channel at hand. Our results show that a
positive s.d.o.f. can be ensured whenever two receivers experience different
fading variation. Remarkably, very simple linear precoding schemes provide the
optimal s.d.o.f. in some cases of interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2411</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2411</id><created>2010-01-14</created><authors><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Twycross</keyname><forenames>Jamie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Dendritic Cells for Anomaly Detection</title><categories>cs.AI cs.NE</categories><comments>8 pages, 10 tables, 4 figures, IEEE Congress on Evolutionary
  Computation (CEC2006), Vancouver, Canada</comments><journal-ref>Proceedings of the IEEE Congress on Evolutionary Computation
  (CEC2006), Vancouver, Canada</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificial immune systems, more specifically the negative selection
algorithm, have previously been applied to intrusion detection. The aim of this
research is to develop an intrusion detection system based on a novel concept
in immunology, the Danger Theory. Dendritic Cells (DCs) are antigen presenting
cells and key to the activation of the human signals from the host tissue and
correlate these signals with proteins know as antigens. In algorithmic terms,
individual DCs perform multi-sensor data fusion based on time-windows. The
whole population of DCs asynchronously correlates the fused signals with a
secondary data stream. The behaviour of human DCs is abstracted to form the DC
Algorithm (DCA), which is implemented using an immune inspired framework,
libtissue. This system is used to detect context switching for a basic machine
learning dataset and to detect outgoing portscans in real-time. Experimental
results show a significant difference between an outgoing portscan and normal
traffic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2416</identifier>
 <datestamp>2014-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2416</id><created>2010-01-14</created><updated>2012-08-27</updated><authors><author><keyname>Wild</keyname><forenames>Marcel</forenames></author></authors><title>Computing the output distribution and selection probabilities of a stack
  filter from the DNF of its positive Boolean function</title><categories>cs.LO cs.DM</categories><comments>This is the version published in Journal of Mathematical Imaging and
  Vision, online first, 1 august 2012</comments><journal-ref>Journal of Mathematical Imaging and Vision 46 (2013) 66-73</journal-ref><doi>10.1007/s10851-012-0370-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many nonlinear filters used in practise are stack filters. An algorithm is
presented which calculates the output distribution of an arbitrary stack filter
S from the disjunctive normal form (DNF) of its underlying positive Boolean
function. The so called selection probabilities can be computed along the way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2421</identifier>
 <datestamp>2010-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2421</id><created>2010-01-14</created><authors><author><keyname>Kobayashi</keyname><forenames>Mari</forenames></author><author><keyname>Yang</keyname><forenames>Sheng</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author><author><keyname>Belfiore</keyname><forenames>Jean-Claude</forenames></author></authors><title>Outage Efficient Strategies for Network MIMO with Partial CSIT</title><categories>cs.IT math.IT</categories><comments>26 pages, 8 figures, submitted to IEEE Trans. on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a multi-cell MIMO downlink (network MIMO) where $B$ base-stations
(BS) with $M$ antennas connected to a central station (CS) serve $K$
single-antenna user terminals (UT). Although many works have shown the
potential benefits of network MIMO, the conclusion critically depends on the
underlying assumptions such as channel state information at transmitters (CSIT)
and backhaul links. In this paper, by focusing on the impact of partial CSIT,
we propose an outage-efficient strategy. Namely, with side information of all
UT's messages and local CSIT, each BS applies zero-forcing (ZF) beamforming in
a distributed manner. For a small number of UTs ($K\leq M$), the ZF beamforming
creates $K$ parallel MISO channels. Based on the statistical knowledge of these
parallel channels, the CS performs a robust power allocation that
simultaneously minimizes the outage probability of all UTs and achieves a
diversity gain of $B(M-K+1)$ per UT. With a large number of UTs ($K \geq M$),
we propose a so-called distributed diversity scheduling (DDS) scheme to select
a subset of $\Ks$ UTs with limited backhaul communication. It is proved that
DDS achieves a diversity gain of $B\frac{K}{\Ks}(M-\Ks+1)$, which scales
optimally with the number of cooperative BSs $B$ as well as UTs. Numerical
results confirm that even under realistic assumptions such as partial CSIT and
limited backhaul communications, network MIMO can offer high data rates with a
sufficient reliability to individual UTs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2447</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2447</id><created>2010-01-14</created><updated>2010-05-08</updated><authors><author><keyname>Guha</keyname><forenames>Saikat</forenames></author><author><keyname>Habif</keyname><forenames>Jonathan L.</forenames></author><author><keyname>Takeoka</keyname><forenames>Masahiro</forenames></author></authors><title>PPM demodulation: On approaching fundamental limits of optical
  communications</title><categories>quant-ph cs.IT math.IT</categories><comments>5 pages, 6 figures, IEEE ISIT, Austin, TX (2010)</comments><journal-ref>Journal of Modern Optics, Volume 58 Issue 3, 257, 2011</journal-ref><doi>10.1080/09500340.2010.533204</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of demodulating M-ary optical PPM (pulse-position
modulation) waveforms, and propose a structured receiver whose mean probability
of symbol error is smaller than all known receivers, and approaches the quantum
limit. The receiver uses photodetection coupled with optimized phase-coherent
optical feedback control and a phase-sensitive parametric amplifier. We present
a general framework of optical receivers known as the conditional pulse nulling
receiver, and present new results on ultimate limits and achievable regions of
spectral versus photon efficiency tradeoffs for the single-spatial-mode
pure-loss optical communication channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2463</identifier>
 <datestamp>2010-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2463</id><created>2010-01-14</created><authors><author><keyname>Kindarji</keyname><forenames>Bruno</forenames></author><author><keyname>Cohen</keyname><forenames>G&#xe9;rard</forenames></author><author><keyname>Chabanne</keyname><forenames>Herv&#xe9;</forenames></author></authors><title>On the Threshold of Maximum-Distance Separable Codes</title><categories>cs.IT cs.DM math.IT</categories><comments>Sumitted to ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Starting from a practical use of Reed-Solomon codes in a cryptographic scheme
published in Indocrypt'09, this paper deals with the threshold of linear
$q$-ary error-correcting codes. The security of this scheme is based on the
intractability of polynomial reconstruction when there is too much noise in the
vector. Our approach switches from this paradigm to an Information Theoretical
point of view: is there a class of elements that are so far away from the code
that the list size is always superpolynomial? Or, dually speaking, is
Maximum-Likelihood decoding almost surely impossible?
  We relate this issue to the decoding threshold of a code, and show that when
the minimal distance of the code is high enough, the threshold effect is very
sharp. In a second part, we explicit lower-bounds on the threshold of
Maximum-Distance Separable codes such as Reed-Solomon codes, and compute the
threshold for the toy example that motivates this study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2464</identifier>
 <datestamp>2010-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2464</id><created>2010-01-14</created><authors><author><keyname>Butt</keyname><forenames>M. Majid</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Ralf R.</forenames></author></authors><title>Linear Finite-Field Deterministic Networks With Many Sources and One
  Destination</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We find the capacity region of linear finite-field deterministic networks
with many sources and one destination. Nodes in the network are subject to
interference and broadcast constraints, specified by the linear finite-field
deterministic model. Each node can inject its own information as well as relay
other nodes' information. We show that the capacity region coincides with the
cut-set region. Also, for a specific case of correlated sources we provide
necessary and sufficient conditions for the sources transmissibility. Given the
&quot;deterministic model&quot; approximation for the corresponding Gaussian network
model, our results may be relevant to wireless sensor networks where the
sensing nodes multiplex the relayed data from the other nodes with their own
data, and where the goal is to decode all data at a single &quot;collector&quot; node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2488</identifier>
 <datestamp>2010-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2488</id><created>2010-01-14</created><authors><author><keyname>Kleiner</keyname><forenames>Marius</forenames></author><author><keyname>Rimoldi</keyname><forenames>Bixio</forenames></author></authors><title>A Tight Bound on the Performance of a Minimal-Delay Joint Source-Channel
  Coding Scheme</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to IEEE International Symposium on Information
  Theory (ISIT) 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An analog source is to be transmitted across a Gaussian channel in more than
one channel use per source symbol. This paper derives a lower bound on the
asymptotic mean squared error for a strategy that consists of repeatedly
quantizing the source, transmitting the quantizer outputs in the first channel
uses, and sending the remaining quantization error uncoded in the last channel
use. The bound coincides with the performance achieved by a suboptimal decoder
studied by the authors in a previous paper, thereby establishing that the bound
is tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2503</identifier>
 <datestamp>2010-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2503</id><created>2010-01-14</created><authors><author><keyname>Chang</keyname><forenames>Chi-Yuan</forenames></author><author><keyname>Su</keyname><forenames>Yu T.</forenames></author><author><keyname>Chen</keyname><forenames>Yu-Liang</forenames></author><author><keyname>Liu</keyname><forenames>Yin-Chen</forenames></author></authors><title>Check Reliability Based Bit-Flipping Decoding Algorithms for LDPC Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, submitted to 2010 IEEE International Symposium on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce new reliability definitions for bit and check nodes. Maximizing
global reliability, which is the sum reliability of all bit nodes, is shown to
be equivalent to minimizing a decoding metric which is closely related to the
maximum likelihood decoding metric. We then propose novel bit-flipping (BF)
decoding algorithms that take into account the check node reliability. Both
hard-decision (HD) and soft-decision (SD) versions are considered. The former
performs better than the conventional BF algorithm and, in most cases, suffers
less than 1 dB performance loss when compared with some well known SD BF
decoders. For one particular code it even outperforms those SD BF decoders. The
performance of the SD version is superior to that of SD BF decoders and is
comparable to or even better than that of the sum-product algorithm (SPA). The
latter is achieved with a complexity much less than that required by the SPA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2508</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2508</id><created>2010-01-14</created><updated>2010-02-24</updated><authors><author><keyname>Boigelot</keyname><forenames>Bernard</forenames></author><author><keyname>Brusten</keyname><forenames>Julien</forenames></author><author><keyname>Bruyere</keyname><forenames>Veronique</forenames></author></authors><title>On the Sets of Real Numbers Recognized by Finite Automata in Multiple
  Bases</title><categories>cs.LO cs.FL</categories><comments>17 pages</comments><acm-class>F.1.1; F.4.1; F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 1 (February
  24, 2010) lmcs:818</journal-ref><doi>10.2168/LMCS-6(1:6)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article studies the expressive power of finite automata recognizing sets
of real numbers encoded in positional notation. We consider Muller automata as
well as the restricted class of weak deterministic automata, used as symbolic
set representations in actual applications. In previous work, it has been
established that the sets of numbers that are recognizable by weak
deterministic automata in two bases that do not share the same set of prime
factors are exactly those that are definable in the first order additive theory
of real and integer numbers. This result extends Cobham's theorem, which
characterizes the sets of integer numbers that are recognizable by finite
automata in multiple bases.
  In this article, we first generalize this result to multiplicatively
independent bases, which brings it closer to the original statement of Cobham's
theorem. Then, we study the sets of reals recognizable by Muller automata in
two bases. We show with a counterexample that, in this setting, Cobham's
theorem does not generalize to multiplicatively independent bases. Finally, we
prove that the sets of reals that are recognizable by Muller automata in two
bases that do not share the same set of prime factors are exactly those
definable in the first order additive theory of real and integer numbers. These
sets are thus also recognizable by weak deterministic automata. This result
leads to a precise characterization of the sets of real numbers that are
recognizable in multiple bases, and provides a theoretical justification to the
use of weak automata as symbolic representations of sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2545</identifier>
 <datestamp>2010-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2545</id><created>2010-01-14</created><authors><author><keyname>Bakshi</keyname><forenames>Mayank</forenames></author><author><keyname>Jaggi</keyname><forenames>Sidharth</forenames></author><author><keyname>Effros</keyname><forenames>Michelle</forenames></author></authors><title>Concatenated Polar Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polar codes have attracted much recent attention as the first codes with low
computational complexity that provably achieve optimal rate-regions for a large
class of information-theoretic problems. One significant drawback, however, is
that for current constructions the probability of error decays
sub-exponentially in the block-length (more detailed designs improve the
probability of error at the cost of significantly increased computational
complexity \cite{KorUS09}). In this work we show how the the classical idea of
code concatenation -- using &quot;short&quot; polar codes as inner codes and a
&quot;high-rate&quot; Reed-Solomon code as the outer code -- results in substantially
improved performance. In particular, code concatenation with a careful choice
of parameters boosts the rate of decay of the probability of error to almost
exponential in the block-length with essentially no loss in computational
complexity. We demonstrate such performance improvements for three sets of
information-theoretic problems -- a classical point-to-point channel coding
problem, a class of multiple-input multiple output channel coding problems, and
some network source coding problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2547</identifier>
 <datestamp>2010-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2547</id><created>2010-01-14</created><authors><author><keyname>Bakshi</keyname><forenames>Mayank</forenames></author><author><keyname>Effros</keyname><forenames>MIchelle</forenames></author></authors><title>On Zero-Error Source Coding with Feedback</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of zero error source coding with limited feedback
when side information is present at the receiver. First, we derive an
achievable rate region for arbitrary joint distributions on the source and the
side information. When all source pairs of source and side information symbols
are observable with non-zero probability, we show that this characterization
gives the entire rate region. Next, we demonstrate a class of sources for which
asymptotically zero feedback suffices to achieve zero-error coding at the rate
promised by the Slepian-Wolf bound for asymptotically lossless coding. Finally,
we illustrate these results with the aid of three simple examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2554</identifier>
 <datestamp>2010-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2554</id><created>2010-01-14</created><authors><author><keyname>Leducq</keyname><forenames>Elodie</forenames><affiliation>IMJ</affiliation></author></authors><title>A new proof of Delsarte, Goethals and Mac Williams theorem on minimal
  weight codewords of generalized Reed-Muller code</title><categories>cs.IT math.IT</categories><proxy>ccsd hal-00446913</proxy><msc-class>94B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new proof of Delsarte, Goethals and Mac williams theorem on minimal
weight codewords of generalized Reed-Muller codes published in 1970. To prove
this theorem, we consider intersection of support of minimal weight codewords
with affine hyperplanes and we proceed by recursion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2566</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2566</id><created>2010-01-14</created><authors><author><keyname>Jafarian</keyname><forenames>Amin</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>On Achievable Rates for Non-Linear Deterministic Interference Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper extends the literature on interference alignment to more general
classes of deterministic channels which incorporate non-linear input-output
relationships. It is found that the concept of alignment extends naturally to
these deterministic interference channels, and in many cases, the achieved
degrees of freedom (DoF) can be shown to be optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2569</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2569</id><created>2010-01-14</created><authors><author><keyname>Wolinsky</keyname><forenames>David Isaac</forenames></author><author><keyname>Lee</keyname><forenames>Kyungyong</forenames></author><author><keyname>Choi</keyname><forenames>Tae Woong</forenames></author><author><keyname>Boykin</keyname><forenames>P. Oscar</forenames></author><author><keyname>Figueiredo</keyname><forenames>Renato</forenames></author></authors><title>Virtual Private Overlays: Secure Group Commounication in NAT-Constrained
  Environments</title><categories>cs.NI cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Structured P2P overlays provide a framework for building distributed
applications that are self-configuring, scalable, and resilient to node
failures. Such systems have been successfully adopted in large-scale Internet
services such as content delivery networks and file sharing; however,
widespread adoption in small/medium scales has been limited due in part to
security concerns and difficulty bootstrapping in NAT-constrained environments.
Nonetheless, P2P systems can be designed to provide guaranteed lookup times,
NAT traversal, point-to-point overlay security, and distributed data stores. In
this paper we propose a novel way of creating overlays that are both secure and
private and a method to bootstrap them using a public overlay. Private overlay
nodes use the public overlay's distributed data store to discover each other,
and the public overlay's connections to assist with NAT hole punching and as
relays providing STUN and TURN NAT traversal techniques. The security framework
utilizes groups, which are created and managed by users through a web based
user interface. Each group acts as a Public Key Infrastructure (PKI) relying on
the use of a centrally-managed web site providing an automated Certificate
Authority (CA). We present a reference implementation which has been used in a
P2P VPN (Virtual Private Network). To evaluate our contributions, we apply our
techniques to an overlay network modeler, event-driven simulations using
simulated time delays, and deployment in the PlanetLab wide-area testbed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2572</identifier>
 <datestamp>2010-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2572</id><created>2010-01-14</created><updated>2010-04-29</updated><authors><author><keyname>Grohe</keyname><forenames>Martin</forenames></author></authors><title>Fixed-Point Definability and Polynomial Time on Chordal Graphs and Line
  Graphs</title><categories>cs.LO cs.CC math.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The question of whether there is a logic that captures polynomial time was
formulated by Yuri Gurevich in 1988. It is still wide open and regarded as one
of the main open problems in finite model theory and database theory. Partial
results have been obtained for specific classes of structures. In particular,
it is known that fixed-point logic with counting captures polynomial time on
all classes of graphs with excluded minors. The introductory part of this paper
is a short survey of the state-of-the-art in the quest for a logic capturing
polynomial time.
  The main part of the paper is concerned with classes of graphs defined by
excluding induced subgraphs. Two of the most fundamental such classes are the
class of chordal graphs and the class of line graphs. We prove that capturing
polynomial time on either of these classes is as hard as capturing it on the
class of all graphs. In particular, this implies that fixed-point logic with
counting does not capture polynomial time on these classes. Then we prove that
fixed-point logic with counting does capture polynomial time on the class of
all graphs that are both chordal and line graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2575</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2575</id><created>2010-01-14</created><authors><author><keyname>Wolinsky</keyname><forenames>David Isaac</forenames></author><author><keyname>Abraham</keyname><forenames>Linton</forenames></author><author><keyname>Lee</keyname><forenames>Kyungyong</forenames></author><author><keyname>Liu</keyname><forenames>Yonggang</forenames></author><author><keyname>Xu</keyname><forenames>Jiangyan</forenames></author><author><keyname>Boykin</keyname><forenames>P. Oscar</forenames></author><author><keyname>Figueiredo</keyname><forenames>Renato</forenames></author></authors><title>On the Design and Implementation of Structured P2P VPNs</title><categories>cs.NI cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Centralized Virtual Private Networks (VPNs) when used in distributed systems
have performance constraints as all traffic must traverse through a central
server. In recent years, there has been a paradigm shift towards the use of P2P
in VPNs to alleviate pressure placed upon the central server by allowing
participants to communicate directly with each other, relegating the server to
handling session management and supporting NAT traversal using relays when
necessary. Another, less common, approach uses unstructured P2P systems to
remove all centralization from the VPN. These approaches currently lack the
depth in security options provided by other VPN solutions, and their
scalability constraints have not been well studied.
  In this paper, we propose and implement a novel VPN architecture, which uses
a structured P2P system for peer discovery, session management, NAT traversal,
and autonomic relay selection and a central server as a partially-automated
public key infrastructure (PKI) via a user-friendly web interface. Our model
also provides the first design and implementation of a P2P VPN with full
tunneling support, whereby all non-P2P based Internet traffic routes through a
trusted third party and does so in a way that is more secure than existing full
tunnel techniques. To verify our model, we evaluate our reference
implementation by comparing it quantitatively to other VPN technologies
focusing on latency, bandwidth, and memory usage. We also discuss some of our
experiences with developing, maintaining, and deploying a P2P VPN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2576</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2576</id><created>2010-01-14</created><updated>2010-08-12</updated><authors><author><keyname>Belov</keyname><forenames>S.</forenames></author><author><keyname>Dudko</keyname><forenames>L.</forenames></author><author><keyname>Kekelidze</keyname><forenames>D.</forenames></author><author><keyname>Sherstnev</keyname><forenames>A.</forenames></author></authors><title>HepML, an XML-based format for describing simulated data in high energy
  physics</title><categories>hep-ph cs.DL cs.SE</categories><comments>21 pages, 4 eps figures, elsart.cls</comments><journal-ref>Comput.Phys.Commun.181:1758,2010</journal-ref><doi>10.1016/j.cpc.2010.06.026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe a HepML format and a corresponding C++ library
developed for keeping complete description of parton level events in a unified
and flexible form. HepML tags contain enough information to understand what
kind of physics the simulated events describe and how the events have been
prepared. A HepML block can be included into event files in the LHEF format.
The structure of the HepML block is described by means of several XML Schemas.
The Schemas define necessary information for the HepML block and how this
information should be located within the block. The library libhepml is a C++
library intended for parsing and serialization of HepML tags, and representing
the HepML block in computer memory. The library is an API for external
software. For example, Matrix Element Monte Carlo event generators can use the
library for preparing and writing a header of a LHEF file in the form of HepML
tags. In turn, Showering and Hadronization event generators can parse the HepML
header and get the information in the form of C++ classes. libhepml can be used
in C++, C, and Fortran programs. All necessary parts of HepML have been
prepared and we present the project to the HEP community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2582</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2582</id><created>2010-01-14</created><updated>2010-10-01</updated><authors><author><keyname>Koo</keyname><forenames>Joseph C.</forenames></author><author><keyname>Wu</keyname><forenames>William</forenames></author><author><keyname>Gill</keyname><forenames>John</forenames></author></authors><title>Delay-rate tradeoff for ergodic interference alignment in the Gaussian
  case</title><categories>cs.IT math.IT</categories><comments>7 pages, 2 figures, presented at 48th Allerton Conference on
  Communication Control and Computing, 2010. Includes appendix detailing Markov
  chain analysis</comments><doi>10.1109/ALLERTON.2010.5707028</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In interference alignment, users sharing a wireless channel are each able to
achieve data rates of up to half of the non-interfering channel capacity, no
matter the number of users. In an ergodic setting, this is achieved by pairing
complementary channel realizations in order to amplify signals and cancel
interference. However, this scheme has the possibility for large delays in
decoding message symbols. We show that delay can be mitigated by using outputs
from potentially more than two channel realizations, although data rate may be
reduced. We further demonstrate the tradeoff between rate and delay via a
time-sharing strategy. Our analysis considers Gaussian channels; an extension
to finite field channels is also possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2596</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2596</id><created>2010-01-14</created><authors><author><keyname>Chen</keyname><forenames>Jinhui</forenames></author><author><keyname>Slock</keyname><forenames>Dirk T. M.</forenames></author></authors><title>On Optimum End-to-End Distortion in Wideband MIMO Systems</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the impact of frequency diversity on the optimum expected
end-to-end distortion (EED) in an outage-free wideband multiple-input
multiple-output (MIMO) system. We provide the closed-form expression of optimum
asymptotic expected EED comprised of the optimum distortion exponent and the
multiplicative optimum distortion factor for high signal-to-noise ratio (SNR).
It is shown that frequency diversity can improve EED though it has no effect on
ergodic capacity. The improvement becomes slight when the frequency diversity
order is greater than a certain number. The lower bounds related to infinite
frequency diversity are derived. The results for outage-free systems are the
bounds for outage-suffering systems and they are instructive for system design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2603</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2603</id><created>2010-01-14</created><authors><author><keyname>Yao</keyname><forenames>Hongyi</forenames></author><author><keyname>Dikaliotis</keyname><forenames>Theodoros K.</forenames></author><author><keyname>Jaggi</keyname><forenames>Sidharth</forenames></author><author><keyname>Ho</keyname><forenames>Tracey</forenames></author></authors><title>Multiple Access Network Information-flow And Correction codes</title><categories>cs.NI</categories><comments>5 pages, 2 figures, submitted to ISIT2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The network communication scenario where one or more receivers request all
the information transmitted by different sources is considered. We introduce
distributed polynomial-time network codes in the presence of malicious nodes.
Our codes can achieve any point inside the rate region of multiple-source
multicast transmission scenarios both in the cases of coherent and non-coherent
network coding. For both cases the encoding and decoding algorithm runs in
poly(|E|)exp(s) time, where poly(|E|) is a polynomial function of the number of
edges |E| in the network and exp(s) is an exponential function of the number of
sources s. Our codes are fully distributed and different sources require no
knowledge of the data transmitted by their peers. Our codes are &quot;end-to-end&quot;,
that is, all nodes apart from the sources and the receivers are oblivious to
the adversaries present in the network and simply implement random linear
network coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2604</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2604</id><created>2010-01-14</created><authors><author><keyname>Wu</keyname><forenames>Kui</forenames></author><author><keyname>Jiang</keyname><forenames>Yuming</forenames></author><author><keyname>Li</keyname><forenames>Jie</forenames></author></authors><title>On the Model Transform in Stochastic Network Calculus</title><categories>cs.PF cs.NI</categories><report-no>CS. Dept Research Report, University of Victoria, DCS-332-IR</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic network calculus requires special care in the search of proper
stochastic traffic arrival models and stochastic service models. Tradeoff must
be considered between the feasibility for the analysis of performance bounds,
the usefulness of performance bounds, and the ease of their numerical
calculation. In theory, transform between different traffic arrival models and
transform between different service models are possible. Nevertheless, the
impact of the model transform on performance bounds has not been thoroughly
investigated. This paper is to investigate the effect of the model transform
and to provide practical guidance in the model selection in stochastic network
calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2605</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2605</id><created>2010-01-14</created><authors><author><keyname>Qiao</keyname><forenames>Hong</forenames></author><author><keyname>Zhang</keyname><forenames>Peng</forenames></author><author><keyname>Wang</keyname><forenames>Di</forenames></author><author><keyname>Zhang</keyname><forenames>Bo</forenames></author></authors><title>An Explicit Nonlinear Mapping for Manifold Learning</title><categories>cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Manifold learning is a hot research topic in the field of computer science
and has many applications in the real world. A main drawback of manifold
learning methods is, however, that there is no explicit mappings from the input
data manifold to the output embedding. This prohibits the application of
manifold learning methods in many practical problems such as classification and
target detection. Previously, in order to provide explicit mappings for
manifold learning methods, many methods have been proposed to get an
approximate explicit representation mapping with the assumption that there
exists a linear projection between the high-dimensional data samples and their
low-dimensional embedding. However, this linearity assumption may be too
restrictive. In this paper, an explicit nonlinear mapping is proposed for
manifold learning, based on the assumption that there exists a polynomial
mapping between the high-dimensional data samples and their low-dimensional
representations. As far as we know, this is the first time that an explicit
nonlinear mapping for manifold learning is given. In particular, we apply this
to the method of Locally Linear Embedding (LLE) and derive an explicit
nonlinear manifold learning algorithm, named Neighborhood Preserving Polynomial
Embedding (NPPE). Experimental results on both synthetic and real-world data
show that the proposed mapping is much more effective in preserving the local
neighborhood information and the nonlinear geometry of the high-dimensional
data samples than previous work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2612</identifier>
 <datestamp>2011-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2612</id><created>2010-01-15</created><updated>2011-05-11</updated><authors><author><keyname>Zhu</keyname><forenames>Minghui</forenames></author><author><keyname>Martinez</keyname><forenames>Sonia</forenames></author></authors><title>On distributed convex optimization under inequality and equality
  constraints via primal-dual subgradient methods</title><categories>math.OC cs.SY</categories><comments>44 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a general multi-agent convex optimization problem where the
agents are to collectively minimize a global objective function subject to a
global inequality constraint, a global equality constraint, and a global
constraint set. The objective function is defined by a sum of local objective
functions, while the global constraint set is produced by the intersection of
local constraint sets. In particular, we study two cases: one where the
equality constraint is absent, and the other where the local constraint sets
are identical. We devise two distributed primal-dual subgradient algorithms
which are based on the characterization of the primal-dual optimal solutions as
the saddle points of the Lagrangian and penalty functions. These algorithms can
be implemented over networks with changing topologies but satisfying a standard
connectivity property, and allow the agents to asymptotically agree on optimal
solutions and optimal values of the optimization problem under the Slater's
condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2613</identifier>
 <datestamp>2010-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2613</id><created>2010-01-15</created><updated>2010-05-02</updated><authors><author><keyname>Bhaskara</keyname><forenames>Aditya</forenames></author><author><keyname>Vijayaraghavan</keyname><forenames>Aravindan</forenames></author></authors><title>Approximating Matrix p-norms</title><categories>cs.DS cs.CC</categories><comments>25 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of computing the q-&gt;p norm of a matrix A, which is
defined for p,q \ge 1, as |A|_{q-&gt;p} = max_{x !=0 } |Ax|_p / |x|_q. This is in
general a non-convex optimization problem, and is a natural generalization of
the well-studied question of computing singular values (this corresponds to
p=q=2). Different settings of parameters give rise to a variety of known
interesting problems (such as the Grothendieck problem when p=1 and q=\infty).
However, very little is understood about the approximability of the problem for
different values of p,q. Our first result is an efficient algorithm for
computing the q-&gt;p norm of matrices with non-negative entries, when q \ge p \ge
1. The algorithm we analyze is based on a natural fixed point iteration, which
can be seen as an analog of power iteration for computing eigenvalues. We then
present an application of our techniques to the problem of constructing a
scheme for oblivious routing in the l_p norm. This makes constructive a recent
existential result of Englert and R\&quot;acke [ER] on O(log n)-competitive
oblivious routing schemes (which they make constructive only for p=2). On the
other hand, when we do not have any restrictions on the entries (such as
non-negativity), we prove that the problem is NP-hard to approximate to any
constant factor, for 2 &lt; p \le q, and p \le q &lt; 2 (these are precisely the
ranges of p,q with p\le q, where constant factor approximations are not known).
In this range, our techniques also show that if NP does not have
quasi-polynomial time algorithms, the q-&gt;p cannot be approximated to a factor
2^{(log n)^{1-eps}}, for any \eps&gt;0.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2620</identifier>
 <datestamp>2011-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2620</id><created>2010-01-15</created><updated>2011-03-14</updated><authors><author><keyname>Ceragioli</keyname><forenames>Francesca</forenames></author><author><keyname>De Persis</keyname><forenames>Claudio</forenames></author><author><keyname>Frasca</keyname><forenames>Paolo</forenames></author></authors><title>Discontinuities and hysteresis in quantized average consensus</title><categories>math.OC cs.SY</categories><comments>26 pages, 7 figures. Accepted for publication in Automatica. v4 is
  minor revision of v3</comments><msc-class>93C30 (Primary), 93D15, 68R10 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider continuous-time average consensus dynamics in which the agents'
states are communicated through uniform quantizers. Solutions to the resulting
system are defined in the Krasowskii sense and are proven to converge to
conditions of &quot;practical consensus&quot;. To cope with undesired chattering
phenomena we introduce a hysteretic quantizer, and we study the convergence
properties of the resulting dynamics by a hybrid system approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2623</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2623</id><created>2010-01-15</created><authors><author><keyname>Kojima</keyname><forenames>Tetsuya</forenames></author><author><keyname>Horii</keyname><forenames>Yoshiya</forenames></author></authors><title>A Steganography Based on CT-CDMA Communication Scheme Using Complete
  Complementary Codes</title><categories>cs.IT cs.CR math.IT</categories><comments>5 pages, 7 figures, zipped file, submitted to ISIT2010 Conference</comments><acm-class>E.4; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been shown that complete complementary codes can be applied into some
communication systems like approximately synchronized CDMA systems because of
its good correlation properties. CT-CDMA is one of the communication systems
based on complete complementary codes. In this system, the information data of
the multiple users can be transmitted by using the same set of complementary
codes through a single frequency band. In this paper, we propose to apply
CT-CDMA systems into a kind of steganography. It is shown that a large amount
of secret data can be embedded in the stego image by the proposed method
through some numerical experiments using color images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2625</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2625</id><created>2010-01-15</created><updated>2010-03-06</updated><authors><author><keyname>Bhattacharya</keyname><forenames>Arnab</forenames></author><author><keyname>Bhowmick</keyname><forenames>Abhishek</forenames></author><author><keyname>Singh</keyname><forenames>Ambuj K.</forenames></author></authors><title>Finding top-k similar pairs of objects annotated with terms from an
  ontology</title><categories>cs.DB</categories><comments>17 pages, 13 figures</comments><acm-class>H.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the growing focus on semantic searches and interpretations, an
increasing number of standardized vocabularies and ontologies are being
designed and used to describe data. We investigate the querying of objects
described by a tree-structured ontology. Specifically, we consider the case of
finding the top-k best pairs of objects that have been annotated with terms
from such an ontology when the object descriptions are available only at
runtime. We consider three distance measures. The first one defines the object
distance as the minimum pairwise distance between the sets of terms describing
them, and the second one defines the distance as the average pairwise term
distance. The third and most useful distance measure, earth mover's distance,
finds the best way of matching the terms and computes the distance
corresponding to this best matching. We develop lower bounds that can be
aggregated progressively and utilize them to speed up the search for top-k
object pairs when the earth mover's distance is used. For the minimum pairwise
distance, we devise an algorithm that runs in O(D + Tk log k) time, where D is
the total information size and T is the total number of terms in the ontology.
We also develop a novel best-first search strategy for the average pairwise
distance that utilizes lower bounds generated in an ordered manner. Experiments
on real and synthetic datasets demonstrate the practicality and scalability of
our algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2636</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2636</id><created>2010-01-15</created><authors><author><keyname>Semin</keyname><forenames>Benoit</forenames><affiliation>FAST</affiliation></author><author><keyname>Fran&#xe7;ois</keyname><forenames>Marc Louis Maurice</forenames><affiliation>FAST</affiliation></author><author><keyname>Auradou</keyname><forenames>Harold</forenames><affiliation>FAST</affiliation></author></authors><title>Analytical shape determination of fiber-like objects with Virtual Image
  Correlation</title><categories>cs.CV physics.comp-ph</categories><comments>17 pages</comments><proxy>ccsd hal-00442849</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reports a method allowing for the determination of the shape of
deformed fiber-like objects. Compared to existing methods, it provides
analytical results including the local slope and curvature which are of first
importance, for instance, in beam mechanics. The presented VIC (Virtual Image
Correlation) method consists in looking for the best correlation between the
image of the fiber-like object and a virtual beam image, using an algorithm
close to the Digital Image Correlation method developed in experimental solid
mechanics. The computation only involves the part of the image in the vicinity
of the fiber: the method is thus insensitive to the picture background and the
computational cost remains low. Two examples are reported: the first proves the
precision of the method, the second its ability to identify a complex shape
with multiple loops.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2647</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2647</id><created>2010-01-15</created><authors><author><keyname>Bayramoglu</keyname><forenames>Muhammet Fatih</forenames></author><author><keyname>Yilmaz</keyname><forenames>Ali Ozgur</forenames></author></authors><title>A General Euclidean Geometric Representation for the Classical Detection
  Theory</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an Euclidean geometric representation for the classical detection
theory. The proposed representation is so generic that can be employed to
almost all communication problems. The hypotheses and observations are mapped
into R^N in such a way that a posteriori probability of an hypothesis given an
observation decreases exponentially with the square of the Euclidean distance
between the vectors corresponding to the hypothesis and the observation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2662</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2662</id><created>2010-01-15</created><updated>2010-07-21</updated><authors><author><keyname>Mori</keyname><forenames>Ryuhei</forenames></author><author><keyname>Tanaka</keyname><forenames>Toshiyuki</forenames></author></authors><title>Channel Polarization on q-ary Discrete Memoryless Channels by Arbitrary
  Kernels</title><categories>cs.IT math.IT</categories><comments>5 pages, a final version of a manuscript for ISIT2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method of channel polarization, proposed by Arikan, allows us to construct
efficient capacity-achieving channel codes. In the original work, binary input
discrete memoryless channels are considered. A special case of $q$-ary channel
polarization is considered by Sasoglu, Telatar, and Arikan. In this paper, we
consider more general channel polarization on $q$-ary channels. We further show
explicit constructions using Reed-Solomon codes, on which asymptotically fast
channel polarization is induced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2665</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2665</id><created>2010-01-15</created><authors><author><keyname>Al-Hammadi</keyname><forenames>Yousof</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Detecting Botnets Through Log Correlation</title><categories>cs.AI cs.CR</categories><comments>4 pages, 7 figures, Workshop on Monitoring, Attack Detection and
  Mitigation (MonAM2006)</comments><journal-ref>Proceedings of the Workshop on Monitoring, Attack Detection and
  Mitigation (MonAM2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Botnets, which consist of thousands of compromised machines, can cause
significant threats to other systems by launching Distributed Denial of Service
(SSoS) attacks, keylogging, and backdoors. In response to these threats, new
effective techniques are needed to detect the presence of botnets. In this
paper, we have used an interception technique to monitor Windows Application
Programming Interface (API) functions calls made by communication applications
and store these calls with their arguments in log files. Our algorithm detects
botnets based on monitoring abnormal activity by correlating the changes in log
file sizes from different hosts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2686</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2686</id><created>2010-01-15</created><updated>2011-04-05</updated><authors><author><keyname>Ay</keyname><forenames>Nihat</forenames></author><author><keyname>Mueller</keyname><forenames>Markus</forenames></author><author><keyname>Szkola</keyname><forenames>Arleta</forenames></author></authors><title>Effective complexity of stationary process realizations</title><categories>cs.IT math.IT</categories><comments>14 pages, no figures</comments><doi>10.3390/e13061200</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of effective complexity of an object as the minimal description
length of its regularities has been initiated by Gell-Mann and Lloyd. The
regularities are modeled by means of ensembles, that is probability
distributions on finite binary strings. In our previous paper we propose a
definition of effective complexity in precise terms of algorithmic information
theory. Here we investigate the effective complexity of binary strings
generated by stationary, in general not computable, processes. We show that
under not too strong conditions long typical process realizations are
effectively simple. Our results become most transparent in the context of
coarse effective complexity which is a modification of the original notion of
effective complexity that uses less parameters in its definition. A similar
modification of the related concept of sophistication has been suggested by
Antunes and Fortnow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2709</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2709</id><created>2010-01-15</created><authors><author><keyname>Dinuzzo</keyname><forenames>Francesco</forenames></author></authors><title>Kernel machines with two layers and multiple kernel learning</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the framework of kernel machines with two layers is
introduced, generalizing classical kernel methods. The new learning methodology
provide a formal connection between computational architectures with multiple
layers and the theme of kernel learning in standard regularization methods.
First, a representer theorem for two-layer networks is presented, showing that
finite linear combinations of kernels on each layer are optimal architectures
whenever the corresponding functions solve suitable variational problems in
reproducing kernel Hilbert spaces (RKHS). The input-output map expressed by
these architectures turns out to be equivalent to a suitable single-layer
kernel machines in which the kernel function is also learned from the data.
Recently, the so-called multiple kernel learning methods have attracted
considerable attention in the machine learning literature. In this paper,
multiple kernel learning methods are shown to be specific cases of kernel
machines with two layers in which the second layer is linear. Finally, a simple
and effective multiple kernel learning method called RLS2 (regularized least
squares with two layers) is introduced, and his performances on several
learning problems are extensively analyzed. An open source MATLAB toolbox to
train and validate RLS2 models with a Graphic User Interface is available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2734</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2734</id><created>2010-01-15</created><authors><author><keyname>Gudmundsson</keyname><forenames>Joachim</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author></authors><title>Planar Visibility: Testing and Counting</title><categories>cs.CG cs.GR</categories><comments>22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider query versions of visibility testing and visibility
counting. Let $S$ be a set of $n$ disjoint line segments in $\R^2$ and let $s$
be an element of $S$. Visibility testing is to preprocess $S$ so that we can
quickly determine if $s$ is visible from a query point $q$. Visibility counting
involves preprocessing $S$ so that one can quickly estimate the number of
segments in $S$ visible from a query point $q$.
  We present several data structures for the two query problems. The structures
build upon a result by O'Rourke and Suri (1984) who showed that the subset,
$V_S(s)$, of $\R^2$ that is weakly visible from a segment $s$ can be
represented as the union of a set, $C_S(s)$, of $O(n^2)$ triangles, even though
the complexity of $V_S(s)$ can be $\Omega(n^4)$. We define a variant of their
covering, give efficient output-sensitive algorithms for computing it, and
prove additional properties needed to obtain approximation bounds. Some of our
bounds rely on a new combinatorial result that relates the number of segments
of $S$ visible from a point $p$ to the number of triangles in $\bigcup_{s\in S}
C_S(s)$ that contain $p$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2735</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2735</id><created>2010-01-15</created><updated>2013-02-03</updated><authors><author><keyname>DasGupta</keyname><forenames>Bhaskar</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author></authors><title>Stochastic Budget Optimization in Internet Advertising</title><categories>cs.CC cs.GT cs.SI</categories><comments>FINAL version</comments><msc-class>68Q17, 68Q25, 91B26, 91B32</msc-class><acm-class>F.2.2; J.4</acm-class><journal-ref>Algorithmica, 65 (3), 634-661, 2013</journal-ref><doi>10.1007/s00453-012-9614-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet advertising is a sophisticated game in which the many advertisers
&quot;play&quot; to optimize their return on investment. There are many &quot;targets&quot; for the
advertisements, and each &quot;target&quot; has a collection of games with a potentially
different set of players involved. In this paper, we study the problem of how
advertisers allocate their budget across these &quot;targets&quot;. In particular, we
focus on formulating their best response strategy as an optimization problem.
Advertisers have a set of keywords (&quot;targets&quot;) and some stochastic information
about the future, namely a probability distribution over scenarios of cost vs
click combinations. This summarizes the potential states of the world assuming
that the strategies of other players are fixed. Then, the best response can be
abstracted as stochastic budget optimization problems to figure out how to
spread a given budget across these keywords to maximize the expected number of
clicks.
  We present the first known non-trivial poly-logarithmic approximation for
these problems as well as the first known hardness results of getting better
than logarithmic approximation ratios in the various parameters involved. We
also identify several special cases of these problems of practical interest,
such as with fixed number of scenarios or with polynomial-sized parameters
related to cost, which are solvable either in polynomial time or with improved
approximation ratios. Stochastic budget optimization with scenarios has
sophisticated technical structure. Our approximation and hardness results come
from relating these problems to a special type of (0/1, bipartite) quadratic
programs inherent in them. Our research answers some open problems raised by
the authors in (Stochastic Models for Budget Optimization in Search-Based
Advertising, Algorithmica, 58 (4), 1022-1044, 2010).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2738</identifier>
 <datestamp>2010-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2738</id><created>2010-01-15</created><updated>2010-05-06</updated><authors><author><keyname>Gross</keyname><forenames>David</forenames></author><author><keyname>Nesme</keyname><forenames>Vincent</forenames></author></authors><title>Note on sampling without replacing from a finite collection of matrices</title><categories>cs.IT math.IT quant-ph</categories><comments>3 pages. Answers a question raised in arXiv:0910.1879. v2: minus one
  typo.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This technical note supplies an affirmative answer to a question raised in a
recent pre-print [arXiv:0910.1879] in the context of a &quot;matrix recovery&quot;
problem. Assume one samples m Hermitian matrices X_1, ..., X_m with replacement
from a finite collection. The deviation of the sum X_1+...+X_m from its
expected value in terms of the operator norm can be estimated by an &quot;operator
Chernoff-bound&quot; due to Ahlswede and Winter. The question arose whether the
bounds obtained this way continue to hold if the matrices are sampled without
replacement. We remark that a positive answer is implied by a classical
argument by Hoeffding. Some consequences for the matrix recovery problem are
sketched.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2752</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2752</id><created>2010-01-15</created><authors><author><keyname>Sauerbier</keyname><forenames>Charles</forenames></author></authors><title>A Polynomial Diophantine Generator Function for Integer Residuals</title><categories>cs.DM</categories><comments>7 pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two Diophantine equation generator function for integer residuals produced by
integer division over closed intervals are presented. One each for the closed
intervals [1,Floor(n^0.5)] and [Ceiling(n^0.5),n], respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2763</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2763</id><created>2010-01-15</created><authors><author><keyname>Bose</keyname><forenames>Prosenjit</forenames></author><author><keyname>Devroye</keyname><forenames>Luc</forenames></author><author><keyname>Douieb</keyname><forenames>Karim</forenames></author><author><keyname>Dujmovic</keyname><forenames>Vida</forenames></author><author><keyname>King</keyname><forenames>James</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author></authors><title>Point Location in Disconnected Planar Subdivisions</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $G$ be a (possibly disconnected) planar subdivision and let $D$ be a
probability measure over $\R^2$. The current paper shows how to preprocess
$(G,D)$ into an O(n) size data structure that can answer planar point location
queries over $G$. The expected query time of this data structure, for a query
point drawn according to $D$, is $O(H+1)$, where $H$ is a lower bound on the
expected query time of any linear decision tree for point location in $G$. This
extends the results of Collette et al (2008, 2009) from connected planar
subdivisions to disconnected planar subdivisions. A version of this structure,
when combined with existing results on succinct point location, provides a
succinct distribution-sensitive point location structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2766</identifier>
 <datestamp>2010-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2766</id><created>2010-01-15</created><updated>2010-01-28</updated><authors><author><keyname>Hassani</keyname><forenames>S. Hamed</forenames></author><author><keyname>Urbanke</keyname><forenames>Rudiger</forenames></author></authors><title>On the scaling of Polar codes: I. The behavior of polarized channels</title><categories>cs.IT math.IT</categories><comments>Submitted to ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the asymptotic behavior of the polarization process for polar
codes when the blocklength tends to infinity. In particular, we study the
problem of asymptotic analysis of the cumulative distribution $\mathbb{P}(Z_n
\leq z)$, where $Z_n=Z(W_n)$ is the Bhattacharyya process, and its dependence
to the rate of transmission R. We show that for a BMS channel $W$, for $R &lt;
I(W)$ we have $\lim_{n \to \infty} \mathbb{P} (Z_n \leq
2^{-2^{\frac{n}{2}+\sqrt{n} \frac{Q^{-1}(\frac{R}{I(W)})}{2} +o(\sqrt{n})}}) =
R$ and for $R&lt;1- I(W)$ we have $\lim_{n \to \infty} \mathbb{P} (Z_n \geq
1-2^{-2^{\frac{n}{2}+ \sqrt{n} \frac{Q^{-1}(\frac{R}{1-I(W)})}{2}
+o(\sqrt{n})}}) = R$, where $Q(x)$ is the probability that a standard normal
random variable will obtain a value larger than $x$. As a result, if we denote
by $\mathbb{P}_e ^{\text{SC}}(n,R)$ the probability of error using polar codes
of block-length $N=2^n$ and rate $R&lt;I(W)$ under successive cancellation
decoding, then $\log(-\log(\mathbb{P}_e ^{\text{SC}}(n,R)))$ scales as
$\frac{n}{2}+\sqrt{n}\frac{Q^{-1}(\frac{R}{I(W)})}{2}+ o(\sqrt{n})$. We also
prove that the same result holds for the block error probability using the MAP
decoder, i.e., for $\log(-\log(\mathbb{P}_e ^{\text{MAP}}(n,R)))$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2767</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2767</id><created>2010-01-15</created><authors><author><keyname>Gupte</keyname><forenames>Mangesh</forenames></author><author><keyname>Sundararajan</keyname><forenames>Mukund</forenames></author></authors><title>Universally Optimal Privacy Mechanisms for Minimax Agents</title><categories>cs.CR cs.DB cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A scheme that publishes aggregate information about sensitive data must
resolve the trade-off between utility to information consumers and privacy of
the database participants. Differential privacy is a well-established
definition of privacy--this is a universal guarantee against all attackers,
whatever their side-information or intent. In this paper, we present a
universal treatment of utility based on the standard minimax rule from decision
theory (in contrast to the utility model in, which is Bayesian). In our model,
information consumers are minimax (risk-averse) agents, each possessing some
side-information about the query, and each endowed with a loss-function which
models their tolerance to inaccuracies. Further, information consumers are
rational in the sense that they actively combine information from the mechanism
with their side-information in a way that minimizes their loss. Under this
assumption of rational behavior, we show that for every fixed count query, a
certain geometric mechanism is universally optimal for all minimax information
consumers. Additionally, our solution makes it possible to release query
results at multiple levels of privacy in a collusion-resistant manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2778</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2778</id><created>2010-01-15</created><authors><author><keyname>Vafopoulos</keyname><forenames>Michalis</forenames></author><author><keyname>Amarantidis</keyname><forenames>Efstathios</forenames></author><author><keyname>Antoniou</keyname><forenames>Ioannis</forenames></author></authors><title>Modeling Web Evolution</title><categories>cs.NI cs.CC</categories><comments>15 pages, 7 figures</comments><acm-class>H.5.3; H.3.3; H.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Web is the largest human information construct in history transforming
our society. How can we understand, measure and model the Web evolution in
order to design effective policies and optimize its social benefit? Early
measurements of the Internet traffic and the Web graph indicated the scale-free
structure of the Web and other Complex Networks. Going a step further
Kouroupas, Koutsoupias, Papadimitriou and Sideri (KKPS) presented an
economic-inspired model which explains the scale-free behavior as the
interaction of Documents, Users and Search engines. The purpose of this paper
is to clarify the open issues arising within the KKPS model through analysis
and simulations and to highlight future research developments in Web modeling,
which is the backbone of Web Science.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2781</identifier>
 <datestamp>2010-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2781</id><created>2010-01-15</created><updated>2010-06-01</updated><authors><author><keyname>Ma</keyname><forenames>Nan</forenames></author><author><keyname>Ishwar</keyname><forenames>Prakash</forenames></author></authors><title>Interaction Strictly Improves the Wyner-Ziv Rate-distortion function</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to IEEE International Symposium on Information
  Theory (ISIT) 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1985 Kaspi provided a single-letter characterization of the
sum-rate-distortion function for a two-way lossy source coding problem in which
two terminals send multiple messages back and forth with the goal of
reproducing each other's sources. Yet, the question remained whether more
messages can strictly improve the sum-rate-distortion function. Viewing the
sum-rate as a functional of the distortions and the joint source distribution
and leveraging its convex-geometric properties, we construct an example which
shows that two messages can strictly improve the one-message (Wyner-Ziv)
rate-distortion function. The example also shows that the ratio of the
one-message rate to the two-message sum-rate can be arbitrarily large and
simultaneously the ratio of the backward rate to the forward rate in the
two-message sum-rate can be arbitrarily small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2785</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2785</id><created>2010-01-18</created><updated>2010-01-20</updated><authors><author><keyname>Godard</keyname><forenames>Emmanuel</forenames><affiliation>LIF</affiliation></author><author><keyname>M&#xe9;tivier</keyname><forenames>Yves</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Tel</keyname><forenames>Gerard</forenames></author></authors><title>Termination Detection of Local Computations</title><categories>cs.DC</categories><proxy>ccsd hal-00446554</proxy><report-no>RR-1466-09</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Contrary to the sequential world, the processes involved in a distributed
system do not necessarily know when a computation is globally finished. This
paper investigates the problem of the detection of the termination of local
computations. We define four types of termination detection: no detection,
detection of the local termination, detection by a distributed observer,
detection of the global termination. We give a complete characterisation
(except in the local termination detection case where a partial one is given)
for each of this termination detection and show that they define a strict
hierarchy. These results emphasise the difference between computability of a
distributed task and termination detection. Furthermore, these
characterisations encompass all standard criteria that are usually formulated :
topological restriction (tree, rings, or triangu- lated networks ...),
topological knowledge (size, diameter ...), and local knowledge to distinguish
nodes (identities, sense of direction). These results are now presented as
corollaries of generalising theorems. As a very special and important case, the
techniques are also applied to the election problem. Though given in the model
of local computations, these results can give qualitative insight for similar
results in other standard models. The necessary conditions involve graphs
covering and quasi-covering; the sufficient conditions (constructive local
computations) are based upon an enumeration algorithm of Mazurkiewicz and a
stable properties detection algorithm of Szymanski, Shi and Prywes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2786</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2786</id><created>2010-01-15</created><authors><author><keyname>Sankar</keyname><forenames>Lalitha</forenames></author><author><keyname>Erkip</keyname><forenames>Elza</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>A General Coding Scheme for Two-User Fading Interference Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Han-Kobayashi based achievable scheme is presented for ergodic fading
two-user Gaussian interference channels (IFCs) with perfect channel state
information at all nodes and Gaussian codebooks with no time-sharing. Using
max-min optimization techniques, it is shown that jointly coding across all
states performs at least as well as separable coding for the sub-classes of
uniformly weak (every sub-channel is weak) and hybrid (mix of strong and weak
sub-channels that do not achieve the interference-free sum-capacity) IFCs. For
the uniformly weak IFCs, sufficient conditions are obtained for which the
sum-rate is maximized when interference is ignored at both receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2805</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2805</id><created>2010-01-15</created><authors><author><keyname>Ali</keyname><forenames>Mortuza</forenames></author><author><keyname>Kuijper</keyname><forenames>Margreta</forenames></author></authors><title>Source Coding With Side Information Using List Decoding</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The problem of source coding with side information (SCSI) is closely related
to channel coding. Therefore, existing literature focuses on using the most
successful channel codes namely, LDPC codes, turbo codes, and their variants,
to solve this problem assuming classical unique decoding of the underlying
channel code. In this paper, in contrast to classical decoding, we have taken
the list decoding approach. We show that syndrome source coding using list
decoding can achieve the theoretical limit. We argue that, as opposed to
channel coding, the correct sequence from the list produced by the list decoder
can effectively be recovered in case of SCSI, since we are dealing with a
virtual noisy channel rather than a real noisy channel. Finally, we present a
guideline for designing constructive SCSI schemes using Reed Solomon code, BCH
code, and Reed-Muller code, which are the known list-decodable codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2806</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2806</id><created>2010-01-18</created><authors><author><keyname>Liu</keyname><forenames>Ruoheng</forenames><affiliation>Shitz</affiliation></author><author><keyname>Liu</keyname><forenames>Tie</forenames><affiliation>Shitz</affiliation></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>MIMO Gaussian Broadcast Channels with Confidential and Common Messages</title><categories>cs.IT cs.CR math.IT</categories><comments>Submitted to 2010 IEEE International Symposium on Information Theory,
  Austin, Texas</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper considers the problem of secret communication over a two-receiver
multiple-input multiple-output (MIMO) Gaussian broadcast channel. The
transmitter has two independent, confidential messages and a common message.
Each of the confidential messages is intended for one of the receivers but
needs to be kept perfectly secret from the other, and the common message is
intended for both receivers. It is shown that a natural scheme that combines
secret dirty-paper coding with Gaussian superposition coding achieves the
secrecy capacity region. To prove this result, a channel-enhancement approach
and an extremal entropy inequality of Weingarten et al. are used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2811</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2811</id><created>2010-01-16</created><updated>2010-02-01</updated><authors><author><keyname>Godhal</keyname><forenames>Yashdeep</forenames></author><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas A.</forenames></author></authors><title>Synthesis of AMBA AHB from Formal Specification</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The standard procedure for hardware design consists of describing circuit in
a hardware description language at logic level followed by extensive
verification and logic-synthesis. However, this process consumes significant
time and needs a lot of effort. An alternative is to use formal specification
language as a high-level hardware description language and synthesize hardware
from formal specification. Bloem et.al. gave formal specifications and
synthesize the AMBA AHB Arbiter. Our contributions are as follows:(1) We
present more complete and compact formal specifications for the AMBA AHB
Arbiter, and obtain significant (order of magnitude) improvement in synthesis
results (both with respect to time and the number of gates of the synthesize
circuit); (2) we present formal specification and synthesize to generate
compact circuits for the remaining two components of the AMBA AHB protocol,
namely, the AMBA AHB Master and AMBA AHB Slave; and (3) from the lessons learnt
we present few principles for writing formal specifications for efficient
hardware synthesis. Thus with intelligently written complete formal
specifications we are able to automatically synthesize an important and widely
used industrial protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2813</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2813</id><created>2010-01-17</created><authors><author><keyname>Di Franco</keyname><forenames>Anthony</forenames></author></authors><title>A Monte Carlo Algorithm for Universally Optimal Bayesian Sequence
  Prediction and Planning</title><categories>nlin.AO cond-mat.dis-nn cs.AI cs.LG stat.ML</categories><comments>Submitted to MDPI Algorithms Special Issue &quot;Algorithmic Complexity in
  Physics &amp; Embedded Artificial Intelligences&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this work is to address the question of whether we can in
principle design rational decision-making agents or artificial intelligences
embedded in computable physics such that their decisions are optimal in
reasonable mathematical senses. Recent developments in rare event probability
estimation, recursive bayesian inference, neural networks, and probabilistic
planning are sufficient to explicitly approximate reinforcement learners of the
AIXI style with non-trivial model classes (here, the class of resource-bounded
Turing machines). Consideration of the effects of resource limitations in a
concrete implementation leads to insights about possible architectures for
learning systems using optimal decision makers as components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2817</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2817</id><created>2010-01-16</created><authors><author><keyname>Breslav</keyname><forenames>Andrey</forenames></author></authors><title>Grammatical Aspects for Language Descriptions</title><categories>cs.PL cs.SE</categories><comments>Submitted to LDTA, 15 pages</comments><acm-class>D.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the purposes of tool development, computer languages are usually
described using context-free grammars with annotations such as semantic actions
or pretty-printing instructions.
  These descriptions are processed by generators which automatically build
software, e.g., parsers, pretty-printers and editing support.
  In many cases the annotations make grammars unreadable, and when generating
code for several tools supporting the same language, one usually needs to
duplicate the grammar in order to provide different annotations for different
generators.
  We present an approach to describing languages which improves readability of
grammars and reduces the duplication. To achieve this we use Aspect-Oriented
Programming principles. This approach has been implemented in an open-source
tool named Grammatic. We show how it can be used to generate pretty-printers
and syntax highlighters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2837</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2837</id><created>2010-01-16</created><authors><author><keyname>Lemarchand</keyname><forenames>Guillermo A.</forenames></author></authors><title>The long-term dynamics of co-authorship scientific networks,
  Iberoamerican Countries (1973-2006)</title><categories>physics.soc-ph cs.DL</categories><comments>37 pages; 18 figures; 15 tables, co-authorship networks,
  self-organization, preferential attachment</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the national production of academic knowledge in all Iberoamerican
countries (IAC) between 1973 and 2007. We show that the total number of
mainstream scientific publications listed in SCI,SSCI and A&amp;HCI follows an
exponential growth, the same as the national productivity expressed in the
number of publications per capita. We also explore the temporal evolution of
the co-authorship patterns between a sample of 12 IAC responsible for 98% of
the total regional publications, with a group of other 45 nations. We show that
the scientific co-authorship among countries follows a power-law and behaves as
a self-organizing scale-free network, where each country appears as a node and
each co-publication as a link. We develop a mathematical model to study the
temporal evolution of co-authorship networks, based on a preferential
attachment strategy and we show that the number of co-publications among
countries growths quadraticly against time. We empirically determine the
quadratic growth constants for 352 different networks within. We corroborate
that the connectivity of regional countries with larger scientific networks is
growing faster than with other less connected countries. We determine the
dates, at which the co-authorship connectivities trigger the self-organizing
scale free network for each of the 352 cases. We find that the last follows a
normal distribution around year 1981.4 +/-2.2 and we connect the last effect
with a brain-drainage process generated in the region. We show how the number
of co-publications Pki (t) between country k and country i, is related with a
power-law against the coupling growth coefficients aki.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2848</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2848</id><created>2010-01-16</created><authors><author><keyname>Jasem</keyname><forenames>Hayder Natiq</forenames></author><author><keyname>Zukarnain</keyname><forenames>Zuriati Ahmad</forenames></author><author><keyname>Othman</keyname><forenames>Mohamed</forenames></author><author><keyname>Subramaniam</keyname><forenames>Shamala</forenames></author></authors><title>Evaluation Study for Delay and Link Utilization with the New-Additive
  Increase Multiplicative Decrease Congestion Avoidance and Control Algorithm</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the Internet becomes increasingly heterogeneous, the issue of congestion
avoidance and control becomes ever more important. And the queue length,
end-to-end delays and link utilization is some of the important things in term
of congestion avoidance and control mechanisms. In this work we continue to
study the performances of the New-AIMD (Additive Increase Multiplicative
Decrease) mechanism as one of the core protocols for TCP congestion avoidance
and control algorithm, we want to evaluate the effect of using the AIMD
algorithm after developing it to find a new approach, as we called it the
New-AIMD algorithm to measure the Queue length, delay and bottleneck link
utilization, and use the NCTUns simulator to get the results after make the
modification for the mechanism. And we will use the Droptail mechanism as the
active queue management mechanism (AQM) in the bottleneck router. After
implementation of our new approach with different number of flows, we expect
the delay will less when we measure the delay dependent on the throughput for
all the system, and also we expect to get end-to-end delay less. And we will
measure the second type of delay a (queuing delay), as we shown in the figure 1
bellow. Also we will measure the bottleneck link utilization, and we expect to
get high utilization for bottleneck link with using this mechanism, and avoid
the collisions in the link.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2860</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2860</id><created>2010-01-16</created><updated>2010-02-14</updated><authors><author><keyname>Belazzougui</keyname><forenames>Djamal</forenames></author></authors><title>Succinct Dictionary Matching With No Slowdown</title><categories>cs.DS</categories><comments>Corrected typos and other minor errors</comments><doi>10.1007/978-3-642-13509-5_9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of dictionary matching is a classical problem in string matching:
given a set S of d strings of total length n characters over an (not
necessarily constant) alphabet of size sigma, build a data structure so that we
can match in a any text T all occurrences of strings belonging to S. The
classical solution for this problem is the Aho-Corasick automaton which finds
all occ occurrences in a text T in time O(|T| + occ) using a data structure
that occupies O(m log m) bits of space where m &lt;= n + 1 is the number of states
in the automaton. In this paper we show that the Aho-Corasick automaton can be
represented in just m(log sigma + O(1)) + O(d log(n/d)) bits of space while
still maintaining the ability to answer to queries in O(|T| + occ) time. To the
best of our knowledge, the currently fastest succinct data structure for the
dictionary matching problem uses space O(n log sigma) while answering queries
in O(|T|log log n + occ) time. In this paper we also show how the space
occupancy can be reduced to m(H0 + O(1)) + O(d log(n/d)) where H0 is the
empirical entropy of the characters appearing in the trie representation of the
set S, provided that sigma &lt; m^epsilon for any constant 0 &lt; epsilon &lt; 1. The
query time remains unchanged.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2862</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2862</id><created>2010-01-16</created><authors><author><keyname>Gansner</keyname><forenames>Emden R.</forenames></author><author><keyname>Hu</keyname><forenames>Yifan</forenames></author><author><keyname>Kobourov</keyname><forenames>Stephen G.</forenames></author></authors><title>On Touching Triangle Graphs</title><categories>cs.DM cs.DS</categories><comments>13 pages, 9 figures, 19 references, 1 appendix</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of representing graphs by triangles
whose sides touch. As a simple necessary condition, we show that pairs of
vertices must have a small common neighborhood. On the positive side, we
present linear time algorithms for creating touching triangle representations
for outerplanar graphs, square grid graphs, and hexagonal grid graphs. We note
that this class of graphs is not closed under minors, making characterization
difficult. However, we present a complete characterization of the subclass of
biconnected graphs that can be represented as triangulations of some polygon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2888</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2888</id><created>2010-01-18</created><authors><author><keyname>Lutz</keyname><forenames>Jack H.</forenames></author><author><keyname>Shutters</keyname><forenames>Brad</forenames></author></authors><title>Approximate Self-Assembly of the Sierpinski Triangle</title><categories>cs.CC cs.DM</categories><acm-class>F.1.1</acm-class><doi>10.1007/978-3-642-13962-8_32</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Tile Assembly Model is a Turing universal model that Winfree introduced
in order to study the nanoscale self-assembly of complex (typically aperiodic)
DNA crystals. Winfree exhibited a self-assembly that tiles the first quadrant
of the Cartesian plane with specially labeled tiles appearing at exactly the
positions of points in the Sierpinski triangle. More recently, Lathrop, Lutz,
and Summers proved that the Sierpinski triangle cannot self-assemble in the
&quot;strict&quot; sense in which tiles are not allowed to appear at positions outside
the target structure. Here we investigate the strict self-assembly of sets that
approximate the Sierpinski triangle. We show that every set that does strictly
self-assemble disagrees with the Sierpinski triangle on a set with fractal
dimension at least that of the Sierpinski triangle (roughly 1.585), and that no
subset of the Sierpinski triangle with fractal dimension greater than 1
strictly self-assembles. We show that our bounds are tight, even when
restricted to supersets of the Sierpinski triangle, by presenting a strict
self-assembly that adds communication fibers to the fractal structure without
disturbing it. To verify this strict self-assembly we develop a generalization
of the local determinism method of Soloveichik and Winfree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2891</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2891</id><created>2010-01-17</created><authors><author><keyname>Bhaskara</keyname><forenames>Aditya</forenames></author><author><keyname>Charikar</keyname><forenames>Moses</forenames></author><author><keyname>Chlamtac</keyname><forenames>Eden</forenames></author><author><keyname>Feige</keyname><forenames>Uriel</forenames></author><author><keyname>Vijayaraghavan</keyname><forenames>Aravindan</forenames></author></authors><title>Detecting High Log-Densities -- an O(n^1/4) Approximation for Densest
  k-Subgraph</title><categories>cs.DS</categories><comments>23 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Densest k-Subgraph problem, given a graph G and a parameter k, one
needs to find a subgraph of G induced on k vertices that contains the largest
number of edges. There is a significant gap between the best known upper and
lower bounds for this problem. It is NP-hard, and does not have a PTAS unless
NP has subexponential time algorithms. On the other hand, the current best
known algorithm of Feige, Kortsarz and Peleg, gives an approximation ratio of
n^(1/3-epsilon) for some specific epsilon &gt; 0 (estimated at around 1/60).
  We present an algorithm that for every epsilon &gt; 0 approximates the Densest
k-Subgraph problem within a ratio of n^(1/4+epsilon) in time n^O(1/epsilon). In
particular, our algorithm achieves an approximation ratio of O(n^1/4) in time
n^O(log n). Our algorithm is inspired by studying an average-case version of
the problem where the goal is to distinguish random graphs from graphs with
planted dense subgraphs. The approximation ratio we achieve for the general
case matches the distinguishing ratio we obtain for this planted problem.
  At a high level, our algorithms involve cleverly counting appropriately
defined trees of constant size in G, and using these counts to identify the
vertices of the dense subgraph. Our algorithm is based on the following
principle. We say that a graph G(V,E) has log-density alpha if its average
degree is Theta(|V|^alpha). The algorithmic core of our result is a family of
algorithms that output k-subgraphs of nontrivial density whenever the
log-density of the densest k-subgraph is larger than the log-density of the
host graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2892</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2892</id><created>2010-01-17</created><updated>2012-02-02</updated><authors><author><keyname>Mirmohseni</keyname><forenames>Mahtab</forenames></author><author><keyname>Akhbari</keyname><forenames>Bahareh</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>On the Capacity of Causal Cognitive Interference Channel With Delay</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the authors due to the acceptance in
  IEEE Transactions on Information Theory with a different title, which is
  available in arXiv:1202.0204</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce the Causal Cognitive Interference Channel With
Delay (CC-IFC-WD) in which the cognitive user transmission can depend on $L$
future received symbols as well as the past ones. Taking the effect of the link
delays into account, CC-IFC-WD fills the gap between the genie-aided and causal
1cognitive radio channels. We study three special cases: 1) Classical CC-IFC
(L=0), 2) CC-IFC without delay (L=1) and 3) CC-IFC with a block length delay
(L=n). In each case, we obtain an inner bound on the capacity region. Our
coding schemes make use of cooperative strategy by generalized block Markov
superposition coding, collaborative strategy by rate splitting, and
Gel'fand-Pinsker coding in order to pre-cancel part of the interference.
Moreover, instantaneous relaying and non-causal partial Decode-and-Forward
strategies are employed in the second and third cases, respectively. The
derived regions under special conditions, reduce to several previously known
results. Moreover, we show that the coding strategy which we use to derive
achievable rate region for the classical CC-IFC achieves capacity for a special
case of this channel. Furthermore, we extend our achievable rate regions to
Gaussian case. Providing a numerical example for Gaussian CC-IFC-WD, we
investigate the rate gain of the cognitive link for different delay values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2897</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2897</id><created>2010-01-17</created><authors><author><keyname>Adell</keyname><forenames>Jose A.</forenames></author><author><keyname>Lekuona</keyname><forenames>Alberto</forenames></author><author><keyname>Yu</keyname><forenames>Yaming</forenames></author></authors><title>Sharp Bounds on the Entropy of the Poisson Law and Related Quantities</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>To appear, IEEE Trans. Inform. Theory</comments><journal-ref>IEEE Trans. Inform. Theory 56 (2010) 2299 - 2306</journal-ref><doi>10.1109/TIT.2010.2044057</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the difficulties in calculating the capacity of certain Poisson
channels is that H(lambda), the entropy of the Poisson distribution with mean
lambda, is not available in a simple form. In this work we derive upper and
lower bounds for H(lambda) that are asymptotically tight and easy to compute.
The derivation of such bounds involves only simple probabilistic and analytic
tools. This complements the asymptotic expansions of Knessl (1998), Jacquet and
Szpankowski (1999), and Flajolet (1999). The same method yields tight bounds on
the relative entropy D(n, p) between a binomial and a Poisson, thus refining
the work of Harremoes and Ruzankin (2004). Bounds on the entropy of the
binomial also follow easily.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2900</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2900</id><created>2010-01-17</created><authors><author><keyname>Anand</keyname><forenames>M.</forenames></author><author><keyname>Kumar</keyname><forenames>P. R.</forenames></author></authors><title>A digital interface for Gaussian relay networks: lifting codes from the
  discrete superposition model to Gaussian relay networks</title><categories>cs.IT math.IT</categories><comments>5 pages, 2010 IEEE Information Theory Workshop, Cairo</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For every Gaussian relay network with a single source-destination pair, it is
known that there exists a corresponding deterministic network called the
discrete superposition network that approximates its capacity uniformly over
all SNR's to within a bounded number of bits. The next step in this program of
rigorous approximation is to determine whether coding schemes for discrete
superposition models can be lifted to Gaussian relay networks with a bounded
rate loss independent of SNR. We establish precisely this property and show
that the superposition model can thus serve as a strong surrogate for designing
codes for Gaussian relay networks.
  We show that a code for a Gaussian relay network, with a single
source-destination pair and multiple relay nodes, can be designed from any code
for the corresponding discrete superposition network simply by pruning it. In
comparison to the rate of the discrete superposition network's code, the rate
of the Gaussian network's code only reduces at most by a constant that is a
function only of the number of nodes in the network and independent of channel
gains.
  This result is also applicable for coding schemes for MIMO Gaussian relay
networks, with the reduction depending additionally on the number of antennas.
  Hence, the discrete superposition model can serve as a digital interface for
operating Gaussian relay networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2913</identifier>
 <datestamp>2012-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2913</id><created>2010-01-17</created><authors><author><keyname>Bose</keyname><forenames>Prosenjit</forenames></author><author><keyname>Damian</keyname><forenames>Mirela</forenames></author><author><keyname>Douieb</keyname><forenames>Karim</forenames></author><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author><author><keyname>Seamone</keyname><forenames>Ben</forenames></author><author><keyname>Smid</keyname><forenames>Michiel</forenames></author><author><keyname>Wuhrer</keyname><forenames>Stefanie</forenames></author></authors><title>Pi/2-Angle Yao Graphs are Spanners</title><categories>cs.CG cs.DS</categories><comments>20 pages, 9 figures</comments><acm-class>F.2.2</acm-class><journal-ref>International Journal of Computational Geometry &amp; Applications,
  22(1):61-82, 2012</journal-ref><doi>10.1142/S0218195912600047</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the Yao graph Y4 in the L2 metric is a spanner with stretch
factor 8(29+23sqrt(2)). Enroute to this, we also show that the Yao graph Y4 in
the Linf metric is a planar spanner with stretch factor 8.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2931</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2931</id><created>2010-01-17</created><updated>2010-11-25</updated><authors><author><keyname>Talyansky</keyname><forenames>Roman</forenames></author><author><keyname>Scheuermann</keyname><forenames>Bernd</forenames></author><author><keyname>Kolbeck</keyname><forenames>Bjorn</forenames></author><author><keyname>Stender</keyname><forenames>Jan</forenames></author></authors><title>Towards Transactional Load over XtreemFS</title><categories>cs.DC cs.PF</categories><comments>The paper is withdrawn by the author due to affiliation incorrectness</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We propose using trace-based assessment of the performance of distributed
file systems (DFS) under transactional IO load. The assessment includes
simulations and experiments using the IO traces. Our experiments suggest that
DFS, and specifically XtreemFS have a good potential to support transactional
IO load in distributed environments: they demonstrate good performance, high
availability and scalability, while at the same time opening the way to TCO
reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2932</identifier>
 <datestamp>2013-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2932</id><created>2010-01-17</created><updated>2010-02-03</updated><authors><author><keyname>Je&#x17c;</keyname><forenames>Artur</forenames></author><author><keyname>Okhotin</keyname><forenames>Alexander</forenames></author></authors><title>On equations over sets of integers</title><categories>cs.FL cs.LO</categories><comments>12 apges, 0 figures</comments><acm-class>F.4.3; F.4.1</acm-class><journal-ref>Theory of Computing Systems 51:2, 2012, pages 196-228</journal-ref><doi>10.1007/s00224-011-9352-5</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Systems of equations with sets of integers as unknowns are considered. It is
shown that the class of sets representable by unique solutions of equations
using the operations of union and addition $S+T=\makeset{m+n}{m \in S, \: n \in
T}$ and with ultimately periodic constants is exactly the class of
hyper-arithmetical sets. Equations using addition only can represent every
hyper-arithmetical set under a simple encoding. All hyper-arithmetical sets can
also be represented by equations over sets of natural numbers equipped with
union, addition and subtraction $S \dotminus T=\makeset{m-n}{m \in S, \: n \in
T, \: m \geqslant n}$. Testing whether a given system has a solution is
$\Sigma^1_1$-complete for each model. These results, in particular, settle the
expressive power of the most general types of language equations, as well as
equations over subsets of free groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2938</identifier>
 <datestamp>2011-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2938</id><created>2010-01-17</created><authors><author><keyname>Ng</keyname><forenames>Chris T. K.</forenames></author><author><keyname>Foschini</keyname><forenames>Gerard J.</forenames></author></authors><title>Transmit Signal and Bandwidth Optimization in Multiple-Antenna Relay
  Channels</title><categories>cs.IT math.IT</categories><comments>16 pages, 10 figures</comments><journal-ref>IEEE Transactions on Communications, vol. 59, no. 11, pp.
  2987-2992, Nov. 2011</journal-ref><doi>10.1109/TCOMM.2011.063011.100030</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transmit signal and bandwidth optimization is considered in multiple-antenna
relay channels. Assuming all terminals have channel state information, the
cut-set capacity upper bound and decode-and-forward rate under full-duplex
relaying are evaluated by formulating them as convex optimization problems. For
half-duplex relays, bandwidth allocation and transmit signals are optimized
jointly. Moreover, achievable rates based on the compress-and-forward
transmission strategy are presented using rate-distortion and Wyner-Ziv
compression schemes. It is observed that when the relay is close to the source,
decode-and-forward is almost optimal, whereas compress-and-forward achieves
good performance when the relay is close to the destination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2940</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2940</id><created>2010-01-17</created><authors><author><keyname>Qin</keyname><forenames>Xiaolin</forenames></author><author><keyname>Feng</keyname><forenames>Yong</forenames></author><author><keyname>Chen</keyname><forenames>Jingwei</forenames></author><author><keyname>Zhang</keyname><forenames>Jingzhong</forenames></author></authors><title>Parallel computation of real solving bivariate polynomial systems by
  zero-matching method</title><categories>cs.SC cs.NA</categories><comments>10 pages</comments><acm-class>F.1.2; G.1.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new algorithm for solving the real roots of a bivariate
polynomial system $\Sigma=\{f(x,y),g(x,y)\}$ with a finite number of solutions
by using a zero-matching method. The method is based on a lower bound for
bivariate polynomial system when the system is non-zero. Moreover, the
multiplicities of the roots of $\Sigma=0$ can be obtained by a given
neighborhood. From this approach, the parallelization of the method arises
naturally. By using a multidimensional matching method this principle can be
generalized to the multivariate equation systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2942</identifier>
 <datestamp>2010-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2942</id><created>2010-01-17</created><updated>2010-05-20</updated><authors><author><keyname>Zhang</keyname><forenames>Xiyong</forenames></author><author><keyname>Guo</keyname><forenames>Hua</forenames></author><author><keyname>Li</keyname><forenames>Yifa</forenames></author></authors><title>Proof of a Conjecture about Rotation Symmetric Functions</title><categories>cs.CR cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rotation symmetric Boolean functions have important applications in the
design of cryptographic algorithms. In this paper, the Conjecture about
rotation symmetric Boolean functions (RSBFs) of degree 3 proposed by Cusik and
St\u{a}nic\u{a} is proved. As a result, the nonlinearity of such kind of
functions is determined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2945</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2945</id><created>2010-01-17</created><authors><author><keyname>Debiao</keyname><forenames>He</forenames></author><author><keyname>Jianhua</keyname><forenames>Chen</forenames></author><author><keyname>Jin</keyname><forenames>Hu</forenames></author></authors><title>Weakness Analysis and Improvement of a Gateway-Oriented Password-Based
  Authenticated Key Exchange Protocol</title><categories>cs.CR</categories><comments>6 pages</comments><acm-class>D.4.6; C.2.1</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Recently, Abdalla et al. proposed a new gateway-oriented password-based
authenticated key exchange (GPAKE) protocol among a client, a gateway, and an
authentication server, where each client shares a human-memorable password with
a trusted server so that they can resort to the server for authentication when
want to establish a shared session key with the gateway. In the letter, we show
that a malicious client of GPAKE is still able to gain information of password
by performing an undetectable on-line password guessing attack and can not
provide the implicit key confirmation. At last, we present a countermeasure to
against the attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2947</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2947</id><created>2010-01-17</created><updated>2010-01-21</updated><authors><author><keyname>Wu</keyname><forenames>Tianyu</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>Design and Analysis of Multi-User SDMA Systems with Noisy Limited CSIT
  Feedback</title><categories>cs.IT math.IT</categories><comments>13 pages, 7 figures, accepted by IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider spatial-division multiple-access (SDMA) systems
with one base station with multiple antennae and a number of single antenna
mobiles under noisy limited CSIT feedback. We propose a robust noisy limited
feedback design for SDMA systems. The solution consists of a real-time robust
SDMA precoding, user selection and rate adaptation as well as an offline
feedback index assignment algorithm. The index assignment problem is cast into
a Traveling Sales Man problem (TSP). Based on the specific structure of the
feedback constellation and the precoder, we derive a low complex but
asymptotically optimal solution. Simulation results show that the proposed
framework has significant goodput gain compared to the traditional naive
designs under noisy limited feedback channel. Furthermore, we show that despite
the noisy feedback channel, the average SDMA system goodput grows with the
number of feedback bits in the interference limited regime while in noise
limited regime increases linearly with the number of transmit antenna and the
forward channel SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2951</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2951</id><created>2010-01-17</created><updated>2010-07-01</updated><authors><author><keyname>Zhou</keyname><forenames>Haijun</forenames></author></authors><title>Solution space heterogeneity of the random K-satisfiability problem:
  Theory and simulations</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.DS</categories><comments>11 pages, 4 figures. Final version as will appear in Journal of
  Physics: Conference Series (Proceedings of the International Workshop on
  Statistical-Mechanical Informatics, March 7-10, 2010, Kyoto, Japan)</comments><doi>10.1088/1742-6596/233/1/012011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The random K-satisfiability (K-SAT) problem is an important problem for
studying typical-case complexity of NP-complete combinatorial satisfaction; it
is also a representative model of finite-connectivity spin-glasses. In this
paper we review our recent efforts on the solution space fine structures of the
random K-SAT problem. A heterogeneity transition is predicted to occur in the
solution space as the constraint density alpha reaches a critical value
alpha_cm. This transition marks the emergency of exponentially many solution
communities in the solution space. After the heterogeneity transition the
solution space is still ergodic until alpha reaches a larger threshold value
alpha_d, at which the solution communities disconnect from each other to become
different solution clusters (ergodicity-breaking). The existence of solution
communities in the solution space is confirmed by numerical simulations of
solution space random walking, and the effect of solution space heterogeneity
on a stochastic local search algorithm SEQSAT, which performs a random walk of
single-spin flips, is investigated. The relevance of this work to glassy
dynamics studies is briefly mentioned.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2957</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2957</id><created>2010-01-18</created><updated>2010-03-16</updated><authors><author><keyname>Watanabe</keyname><forenames>Sumio</forenames></author></authors><title>Asymptotic Learning Curve and Renormalizable Condition in Statistical
  Learning Theory</title><categories>cs.LG</categories><doi>10.1088/1742-6596/233/1/012014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bayes statistics and statistical physics have the common mathematical
structure, where the log likelihood function corresponds to the random
Hamiltonian. Recently, it was discovered that the asymptotic learning curves in
Bayes estimation are subject to a universal law, even if the log likelihood
function can not be approximated by any quadratic form. However, it is left
unknown what mathematical property ensures such a universal law. In this paper,
we define a renormalizable condition of the statistical estimation problem, and
show that, under such a condition, the asymptotic learning curves are ensured
to be subject to the universal law, even if the true distribution is
unrealizable and singular for a statistical model. Also we study a
nonrenormalizable case, in which the learning curves have the different
asymptotic behaviors from the universal law.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.2961</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.2961</id><created>2010-01-18</created><authors><author><keyname>Merigot</keyname><forenames>Quentin</forenames></author></authors><title>Size of the medial axis and stability of Federer's curvature measures</title><categories>math.MG cs.CG</categories><comments>15 pages, 2 figures</comments><msc-class>28A78; 52A39; 35F21</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we study the (d-1)-volume and the covering numbers of the
medial axis of a compact set of the Euclidean d-space. In general, this volume
is infinite; however, the (d-1)-volume and covering numbers of a filtered
medial axis (the mu-medial axis) that is at distance greater than R from the
compact set will be explicitely bounded. The behaviour of the bound we obtain
with respect to mu, R and the covering numbers of the compact set K are
optimal.
  From this result we deduce that the projection function on a compact subset K
of the Euclidean d-space depends continuously on the compact set K, in the L^1
sense. This implies in particular that Federer's curvature measure of a compact
set with positive reach can be reliably estimated from a Hausdorff
approximation of this set, regardless of any regularity assumption on the
approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3017</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3017</id><created>2010-01-18</created><authors><author><keyname>Cayrel</keyname><forenames>Pierre-Louis</forenames></author><author><keyname>Veron</keyname><forenames>Pascal</forenames></author></authors><title>Improved code-based identification scheme</title><categories>cs.CR</categories><comments>submitted to ISIT 2010</comments><acm-class>D.4.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit the 3-pass code-based identification scheme proposed by Stern at
Crypto'93, and give a new 5-pass protocol for which the probability of the
cheater is 1/2 (instead of 2/3 in the original Stern's proposal). Furthermore,
we propose to use quasi-cyclic construction in order to dramatically reduce the
size of the public key. The proposed scheme is zero-knowledge and relies on an
NP-complete problem coming from coding theory (namely the q-ary Syndrome
Decoding problem). Taking into account a recent study of a generalization of
Stern's information-set-decoding algorithm for decoding linear codes over
arbitrary finite fields Fq we suggest parameters so that the public key be
34Kbits while those of Stern's scheme is about 66Kbits. This provides a very
practical identification (and possibly signature) scheme which is mostly
attractive for light-weight cryptography
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3036</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3036</id><created>2010-01-18</created><authors><author><keyname>Fabregas</keyname><forenames>Albert Guillen i</forenames></author><author><keyname>Martinez</keyname><forenames>Alfonso</forenames></author></authors><title>Shaping Bits</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to the 2010 IEEE International Symposium on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of bit-interleaved coded modulation (BICM) with bit shaping
(i.e., non-equiprobable bit probabilities in the underlying binary code) is
studied. For the Gaussian channel, the rates achievable with BICM and bit
shaping are practically identical to those of coded modulation or multilevel
coding. This identity holds for the whole range of values of signal-to-noise
ratio. Moreover, the random coding error exponent of BICM significantly exceeds
that of multilevel coding and is very close to that of coded modulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3038</identifier>
 <datestamp>2011-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3038</id><created>2010-01-18</created><updated>2011-02-09</updated><authors><author><keyname>Mello</keyname><forenames>Louis</forenames></author></authors><title>Mortality and Longevity Valuation - A Quantitative Approach</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines several computer algorithms designed to assess mortality
and longevity risk.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3044</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3044</id><created>2010-01-18</created><updated>2010-02-03</updated><authors><author><keyname>Bienkowski</keyname><forenames>Marcin</forenames></author><author><keyname>Klonowski</keyname><forenames>Marek</forenames></author><author><keyname>Korzeniowski</keyname><forenames>Miroslaw</forenames></author><author><keyname>Kowalski</keyname><forenames>Dariusz R.</forenames></author></authors><title>Dynamic sharing of a multiple access channel</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the mutual exclusion problem on a multiple access
channel. Mutual exclusion is one of the fundamental problems in distributed
computing. In the classic version of this problem, n processes perform a
concurrent program which occasionally triggers some of them to use shared
resources, such as memory, communication channel, device, etc. The goal is to
design a distributed algorithm to control entries and exits to/from the shared
resource in such a way that in any time there is at most one process accessing
it. We consider both the classic and a slightly weaker version of mutual
exclusion, called ep-mutual-exclusion, where for each period of a process
staying in the critical section the probability that there is some other
process in the critical section is at most ep. We show that there are channel
settings, where the classic mutual exclusion is not feasible even for
randomized algorithms, while ep-mutual-exclusion is. In more relaxed channel
settings, we prove an exponential gap between the makespan complexity of the
classic mutual exclusion problem and its weaker ep-exclusion version. We also
show how to guarantee fairness of mutual exclusion algorithms, i.e., that each
process that wants to enter the critical section will eventually succeed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3052</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3052</id><created>2010-01-18</created><updated>2011-02-14</updated><authors><author><keyname>Marichal</keyname><forenames>Jean-Luc</forenames></author><author><keyname>Mathonet</keyname><forenames>Pierre</forenames></author></authors><title>Weighted Banzhaf power and interaction indexes through weighted
  approximations of games</title><categories>math.OC cs.DM</categories><msc-class>91A12, 93E24 (Primary) 39A70, 41A10 (Secondary)</msc-class><journal-ref>European Journal of Operational Research 211 (2) (2011) 352-358</journal-ref><doi>10.1016/j.ejor.2010.11.027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Banzhaf power index was introduced in cooperative game theory to measure
the real power of players in a game. The Banzhaf interaction index was then
proposed to measure the interaction degree inside coalitions of players. It was
shown that the power and interaction indexes can be obtained as solutions of a
standard least squares approximation problem for pseudo-Boolean functions.
Considering certain weighted versions of this approximation problem, we define
a class of weighted interaction indexes that generalize the Banzhaf interaction
index. We show that these indexes define a subclass of the family of
probabilistic interaction indexes and study their most important properties.
Finally, we give an interpretation of the Banzhaf and Shapley interaction
indexes as centers of mass of this subclass of interaction indexes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3053</identifier>
 <datestamp>2012-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3053</id><created>2010-01-18</created><updated>2012-02-27</updated><authors><author><keyname>Ganesan</keyname><forenames>Ashwin</forenames></author></authors><title>On some upper bounds on the fractional chromatic number of weighted
  graphs</title><categories>cs.IT math.CO math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a weighted graph $G_\bx$, where $(x(v): v \in V)$ is a non-negative,
real-valued weight assigned to the vertices of G, let $B(G_\bx)$ be an upper
bound on the fractional chromatic number of the weighted graph $G_\bx$; so
$\chi_f(G_\bx) \le B(G_\bx)$. To investigate the worst-case performance of the
upper bound $B$, we study the graph invariant $$\beta(G) = \sup_{\bx \ne 0}
\frac{B(G_\bx)}{\chi_f(G_\bx)}.$$
  \noindent This invariant is examined for various upper bounds $B$ on the
fractional chromatic number. In some important cases, this graph invariant is
shown to be related to the size of the largest star subgraph in the graph. This
problem arises in the area of resource estimation in distributed systems and
wireless networks; the results presented here have implications on the design
and performance of decentralized communication networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3056</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3056</id><created>2010-01-18</created><updated>2012-10-03</updated><authors><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author><author><keyname>Huber</keyname><forenames>Anna</forenames></author><author><keyname>Levavi</keyname><forenames>Ariel</forenames></author></authors><title>Strong Robustness of Randomized Rumor Spreading Protocols</title><categories>cs.DM</categories><comments>Accepted for publication in &quot;Discrete Applied Mathematics&quot;. A short
  version appeared in the proceedings of the 20th International Symposium on
  Algorithms and Computation (ISAAC 2009). Minor typos fixed in the second
  version. Proofs of Lemma 11 and Theorem 12 fixed in the third version. Proof
  of Lemma 8 fixed in the fourth version</comments><journal-ref>Discrete Applied Mathematics, Volume 161 (6):778-793, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Randomized rumor spreading is a classical protocol to disseminate information
across a network. At SODA 2008, a quasirandom version of this protocol was
proposed and competitive bounds for its run-time were proven. This prompts the
question: to what extent does the quasirandom protocol inherit the second
principal advantage of randomized rumor spreading, namely robustness against
transmission failures?
  In this paper, we present a result precise up to $(1 \pm o(1))$ factors. We
limit ourselves to the network in which every two vertices are connected by a
direct link. Run-times accurate to their leading constants are unknown for all
other non-trivial networks.
  We show that if each transmission reaches its destination with a probability
of $p \in (0,1]$, after $(1+\e)(\frac{1}{\log_2(1+p)}\log_2n+\frac{1}{p}\ln n)$
rounds the quasirandom protocol has informed all $n$ nodes in the network with
probability at least $1-n^{-p\e/40}$. Note that this is faster than the
intuitively natural $1/p$ factor increase over the run-time of approximately
$\log_2 n + \ln n $ for the non-corrupted case.
  We also provide a corresponding lower bound for the classical model. This
demonstrates that the quasirandom model is at least as robust as the fully
random model despite the greatly reduced degree of independent randomness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3087</identifier>
 <datestamp>2010-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3087</id><created>2010-01-18</created><updated>2010-04-28</updated><authors><author><keyname>Arikan</keyname><forenames>Erdal</forenames></author></authors><title>Source Polarization</title><categories>cs.IT math.IT</categories><comments>To be presented at the IEEE 2010 International Symposium on
  Information Theory.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of source polarization is introduced and investigated. This
complements the earlier work on channel polarization. An application to
Slepian-Wolf coding is also considered. The paper is restricted to the case of
binary alphabets. Extension of results to non-binary alphabets is discussed
briefly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3090</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3090</id><created>2010-01-18</created><updated>2010-06-13</updated><authors><author><keyname>Huang</keyname><forenames>Dayu</forenames></author><author><keyname>Meyn</keyname><forenames>Sean</forenames></author></authors><title>Feature Extraction for Universal Hypothesis Testing via Rank-constrained
  Optimization</title><categories>cs.IT cs.LG math.IT math.ST stat.TH</categories><comments>5 pages, 4 figures, submitted to ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper concerns the construction of tests for universal hypothesis
testing problems, in which the alternate hypothesis is poorly modeled and the
observation space is large. The mismatched universal test is a feature-based
technique for this purpose. In prior work it is shown that its
finite-observation performance can be much better than the (optimal) Hoeffding
test, and good performance depends crucially on the choice of features. The
contributions of this paper include: 1) We obtain bounds on the number of
\epsilon distinguishable distributions in an exponential family. 2) This
motivates a new framework for feature extraction, cast as a rank-constrained
optimization problem. 3) We obtain a gradient-based algorithm to solve the
rank-constrained optimization problem and prove its local convergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3102</identifier>
 <datestamp>2010-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3102</id><created>2010-01-18</created><updated>2010-07-06</updated><authors><author><keyname>Dupuy</keyname><forenames>Florian</forenames></author><author><keyname>Loubaton</keyname><forenames>Philippe</forenames></author></authors><title>On the Capacity Achieving Covariance Matrix for Frequency Selective MIMO
  Channels Using the Asymptotic Approach</title><categories>cs.IT math.IT</categories><comments>presented at ISIT 2010 Conference, Austin, Texas, June 13-18, 2010 (5
  pages, 1 figure, 2 tables)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this contribution, an algorithm for evaluating the capacity-achieving
input covariance matrices for frequency selective Rayleigh MIMO channels is
proposed. In contrast with the flat fading Rayleigh cases, no closed-form
expressions for the eigenvectors of the optimum input covariance matrix are
available. Classically, both the eigenvectors and eigenvalues are computed
numerically and the corresponding optimization algorithms remain
computationally very demanding. In this paper, it is proposed to optimize
(w.r.t. the input covariance matrix) a large system approximation of the
average mutual information derived by Moustakas and Simon. An algorithm based
on an iterative water filling scheme is proposed, and its convergence is
studied. Numerical simulation results show that, even for a moderate number of
transmit and receive antennas, the new approach provides the same results as
direct maximization approaches of the average mutual information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3107</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3107</id><created>2010-01-18</created><authors><author><keyname>Bantwal</keyname><forenames>Srikanth Pai</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>A Practical Dirty Paper Coding Applicable for Broadcast Channel</title><categories>cs.IT math.IT</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a practical dirty paper coding scheme using trellis
coded modulation for the dirty paper channel $Y=X+S+W,$ $\mathbb{E}\{X^2\} \leq
P$, where $W$ is white Gaussian noise with power $\sigma_w ^2$, $P$ is the
average transmit power and $S$ is the Gaussian interference with power
$\sigma_s ^2$ that is non-causally known at the transmitter. We ensure that the
dirt in our scheme remains distinguishable to the receiver and thus, our
designed scheme is applicable to broadcast channel. Following Costa's idea, we
recognize the criteria that the transmit signal must be as orthogonal to the
dirt as possible. Finite constellation codes are constructed using trellis
coded modulation and by using a Viterbi algorithm at the encoder so that the
code satisfies the design criteria and simulation results are presented with
codes constructed via trellis coded modulation using QAM signal sets to
illustrate our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3113</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3113</id><created>2010-01-18</created><updated>2010-06-17</updated><authors><author><keyname>Drozda</keyname><forenames>Martin</forenames></author><author><keyname>Schildt</keyname><forenames>Sebastian</forenames></author><author><keyname>Schaust</keyname><forenames>Sven</forenames></author><author><keyname>Szczerbicka</keyname><forenames>Helena</forenames></author></authors><title>An Immuno-Inspired Approach to Misbehavior Detection in Ad Hoc Wireless
  Networks</title><categories>cs.NI cs.AI cs.NE</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose and evaluate an immuno-inspired approach to misbehavior detection
in ad hoc wireless networks. Node misbehavior can be the result of an
intrusion, or a software or hardware failure. Our approach is motivated by
co-stimulatory signals present in the Biological immune system. The results
show that co-stimulation in ad hoc wireless networks can both substantially
improve energy efficiency of detection and, at the same time, help achieve low
false positives rates. The energy efficiency improvement is almost two orders
of magnitude, if compared to misbehavior detection based on watchdogs.
  We provide a characterization of the trade-offs between detection approaches
executed by a single node and by several nodes in cooperation. Additionally, we
investigate several feature sets for misbehavior detection. These feature sets
impose different requirements on the detection system, most notably from the
energy efficiency point of view.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3116</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3116</id><created>2010-01-18</created><updated>2010-01-18</updated><authors><author><keyname>Choi</keyname><forenames>Vicky</forenames></author></authors><title>Minor-embedding in adiabatic quantum computation: II. Minor-universal
  graph design</title><categories>quant-ph cs.CC</categories><comments>10 pages, 5 figures</comments><journal-ref>Quantum Information Processing: Volume 10, Issue 3 (2011), Page
  343</journal-ref><doi>10.1007/s11128-010-0200-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In [Choi08], we introduced the notion of minor-embedding in adiabatic quantum
optimization. A minor-embedding of a graph G in a quantum hardware graph U is a
subgraph of U such that G can be obtained from it by contracting edges. In this
paper, we describe the intertwined adiabatic quantum architecture design
problem, which is to construct a hardware graph U that satisfies all known
physical constraints and, at the same time, permits an efficient
minor-embedding algorithm. We illustrate an optimal complete-graph-minor
hardware graph. Given a family F of graphs, a (host) graph U is called
F-minor-universal if for each graph G in F, U contains a minor-embedding of G.
The problem for designing a F-minor-universal hardware graph U_{sparse} in
which F consists of a family of sparse graphs (e.g., bounded degree graphs) is
open.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3118</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3118</id><created>2010-01-18</created><authors><author><keyname>Tenenbaum</keyname><forenames>Adam J.</forenames></author><author><keyname>Adve</keyname><forenames>Raviraj S.</forenames></author></authors><title>Energy Optimization across Training and Data for Multiuser Minimum
  Sum-MSE Linear Precoding</title><categories>cs.IT math.IT</categories><comments>Submitted to CISS 2010(6 pages, 4 figures). Uses IEEEtran.cls V1.7a</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers minimum sum mean-squared error (sum-MSE) linear
transceiver designs in multiuser downlink systems with imperfect channel state
information. Specifically, we derive the optimal energy allocations for
training and data phases for such a system. Under MMSE estimation of
uncorrelated Rayleigh block fading channels with equal average powers, we prove
the separability of the energy allocation and transceiver design optimization
problems. A closed-form optimum energy allocation is derived and applied to
existing transceiver designs. Analysis and simulation results demonstrate the
improvements that can be realized with the proposed design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3122</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3122</id><created>2010-01-18</created><authors><author><keyname>van Enter</keyname><forenames>Aernout</forenames></author><author><keyname>Verbitskiy</keyname><forenames>Evgeny</forenames></author></authors><title>Erasure entropies and Gibbs measures</title><categories>math-ph cs.IT math.IT math.MP math.PR</categories><comments>1o pages, to appear in Markov Processes and Related Fields</comments><msc-class>82B20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently Verdu and Weissman introduced erasure entropies, which are meant to
measure the information carried by one or more symbols given all of the
remaining symbols in the realization of the random process or field. A natural
relation to Gibbs measures has also been observed. In his short note we study
this relation further, review a few earlier contributions from statistical
mechanics, and provide the formula for the erasure entropy of a Gibbs measure
in terms of the corresponding potentia. For some
  2-dimensonal Ising models, for which Verdu and Weissman suggested a numerical
procedure, we show how to obtain an exact formula for the erasure entropy. l
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3150</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3150</id><created>2010-01-18</created><authors><author><keyname>Cherubini</keyname><forenames>Mauro</forenames></author><author><keyname>de Oliveira</keyname><forenames>Rodrigo</forenames></author><author><keyname>Oliver</keyname><forenames>Nuria</forenames></author><author><keyname>Ferran</keyname><forenames>Christian</forenames></author></authors><title>Gaze and Gestures in Telepresence: multimodality, embodiment, and roles
  of collaboration</title><categories>cs.HC</categories><comments>Position paper, International Workshop New Frontiers in Telepresence
  2010, part of CSCW2010, Savannah, GA, USA, 7th of February, 2010.
  http://research.microsoft.com/en-us/events/nft2010/</comments><acm-class>H.5.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a controlled experiment to further investigate the
usefulness of gaze awareness and gesture recognition in the support of
collaborative work at a distance. We propose to redesign experiments conducted
several years ago with more recent technology that would: a) enable to better
study of the integration of communication modalities, b) allow users to freely
move while collaborating at a distance and c) avoid asymmetries of
communication between collaborators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3159</identifier>
 <datestamp>2010-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3159</id><created>2010-01-18</created><updated>2010-05-28</updated><authors><author><keyname>Sardari</keyname><forenames>Mohsen</forenames></author><author><keyname>Restrepo</keyname><forenames>Ricardo</forenames></author><author><keyname>Fekri</keyname><forenames>Faramarz</forenames></author><author><keyname>Soljanin</keyname><forenames>Emina</forenames></author></authors><title>Memory Allocation in Distributed Storage Networks</title><categories>cs.IT math.IT</categories><comments>To appear in ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of distributing a file in a network of storage nodes
whose storage budget is limited but at least equals to the size file. We first
generate $T$ encoded symbols (from the file) which are then distributed among
the nodes. We investigate the optimal allocation of $T$ encoded packets to the
storage nodes such that the probability of reconstructing the file by using any
$r$ out of $n$ nodes is maximized. Since the optimal allocation of encoded
packets is difficult to find in general, we find another objective function
which well approximates the original problem and yet is easier to optimize. We
find the optimal symmetric allocation for all coding redundancy constraints
using the equivalent approximate problem. We also investigate the optimal
allocation in random graphs. Finally, we provide simulations to verify the
theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3171</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3171</id><created>2010-01-18</created><authors><author><keyname>ParandehGheibi</keyname><forenames>Ali</forenames></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames></author><author><keyname>Effros</keyname><forenames>Michelle</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>Optimal Reverse Carpooling Over Wireless Networks - A Distributed
  Optimization Approach</title><categories>cs.NI cs.MA</categories><comments>submitted to CISS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We focus on a particular form of network coding, reverse carpooling, in a
wireless network where the potentially coded transmitted messages are to be
decoded immediately upon reception. The network is fixed and known, and the
system performance is measured in terms of the number of wireless broadcasts
required to meet multiple unicast demands. Motivated by the structure of the
coding scheme, we formulate the problem as a linear program by introducing a
flow variable for each triple of connected nodes. This allows us to have a
formulation polynomial in the number of nodes. Using dual decomposition and
projected subgradient method, we present a decentralized algorithm to obtain
optimal routing schemes in presence of coding opportunities. We show that the
primal sub-problem can be expressed as a shortest path problem on an
\emph{edge-graph}, and the proposed algorithm requires each node to exchange
information only with its neighbors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3173</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3173</id><created>2010-01-18</created><updated>2010-09-02</updated><authors><author><keyname>Banavar</keyname><forenames>Mahesh K.</forenames></author><author><keyname>Smith</keyname><forenames>Anthony D.</forenames></author><author><keyname>Tepedelenlioglu</keyname><forenames>Cihan</forenames></author><author><keyname>Spanias</keyname><forenames>Andreas</forenames></author></authors><title>Distributed Detection over Fading MACs with Multiple Antennas at the
  Fusion Center</title><categories>cs.IT math.IT</categories><comments>21 pages, 9 figures, submitted to the IEEE Transactions on Signal
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A distributed detection problem over fading Gaussian multiple-access channels
is considered. Sensors observe a phenomenon and transmit their observations to
a fusion center using the amplify and forward scheme. The fusion center has
multiple antennas with different channel models considered between the sensors
and the fusion center, and different cases of channel state information are
assumed at the sensors. The performance is evaluated in terms of the error
exponent for each of these cases, where the effect of multiple antennas at the
fusion center is studied. It is shown that for zero-mean channels between the
sensors and the fusion center when there is no channel information at the
sensors, arbitrarily large gains in the error exponent can be obtained with
sufficient increase in the number of antennas at the fusion center. In stark
contrast, when there is channel information at the sensors, the gain in error
exponent due to having multiple antennas at the fusion center is shown to be no
more than a factor of (8/pi) for Rayleigh fading channels between the sensors
and the fusion center, independent of the number of antennas at the fusion
center, or correlation among noise samples across sensors. Scaling laws for
such gains are also provided when both sensors and antennas are increased
simultaneously. Simple practical schemes and a numerical method using
semidefinite relaxation techniques are presented that utilize the limited
possible gains available. Simulations are used to establish the accuracy of the
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3178</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3178</id><created>2010-01-18</created><updated>2010-01-20</updated><authors><author><keyname>Ali</keyname><forenames>Olfa Ben Sik</forenames></author><author><keyname>Cardinal</keyname><forenames>Christian</forenames></author><author><keyname>Gagnon</keyname><forenames>Francois</forenames></author></authors><title>A performance analysis of multi-hop ad hoc networks with adaptive
  antenna array systems</title><categories>cs.IT math.IT</categories><comments>Submitted to ISIT'10</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Based on a stochastic geometry framework, we establish an analysis of the
multi-hop spatial reuse aloha protocol (MSR-Aloha) in ad hoc networks. We
compare MSR-Aloha to a simple routing strategy, where a node selects the next
relay of the treated packet as to be its nearest receiver with a forward
progress toward the final destination (NFP). In addition, performance gains
achieved by employing adaptive antenna array systems are quantified in this
paper. We derive a tight upper bound on the spatial density of progress of
MSR-Aloha. Our analytical results demonstrate that the spatial density of
progress scales as the square root of the density of users, and the optimal
contention density (that maximizes the spatial density of progress) is
independent of the density of users. These two facts are consistent with the
observations of Baccelli et al., established through an analytical lower bound
and through simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3181</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3181</id><created>2010-01-18</created><updated>2010-12-13</updated><authors><author><keyname>Zhao</keyname><forenames>Jichang</forenames></author><author><keyname>Wu</keyname><forenames>Junjie</forenames></author><author><keyname>Xu</keyname><forenames>Ke</forenames></author></authors><title>Weak ties: Subtle role of information diffusion in online social
  networks</title><categories>cs.SI cond-mat.stat-mech physics.soc-ph</categories><comments>Final version published in PRE</comments><journal-ref>Jichang Zhao, Junjie Wu and Ke Xu. Weak ties: Subtle role of
  information diffusion in online social networks. Phys. Rev. E 82, 016105
  (2010)</journal-ref><doi>10.1103/PhysRevE.82.016105</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a social media, online social networks play a vital role in the social
information diffusion. However, due to its unique complexity, the mechanism of
the diffusion in online social networks is different from the ones in other
types of networks and remains unclear to us. Meanwhile, few works have been
done to reveal the coupled dynamics of both the structure and the diffusion of
online social networks. To this end, in this paper, we propose a model to
investigate how the structure is coupled with the diffusion in online social
networks from the view of weak ties. Through numerical experiments on
large-scale online social networks, we find that in contrast to some previous
research results, selecting weak ties preferentially to republish cannot make
the information diffuse quickly, while random selection can achieve this goal.
However, when we remove the weak ties gradually, the coverage of the
information will drop sharply even in the case of random selection. We also
give a reasonable explanation for this by extra analysis and experiments.
Finally, we conclude that weak ties play a subtle role in the information
diffusion in online social networks. On one hand, they act as bridges to
connect isolated local communities together and break through the local
trapping of the information. On the other hand, selecting them as preferential
paths to republish cannot help the information spread further in the network.
As a result, weak ties might be of use in the control of the virus spread and
the private information diffusion in real-world applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3187</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3187</id><created>2010-01-18</created><authors><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Liang</keyname><forenames>Ying-Chang</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Dynamic Resource Allocation in Cognitive Radio Networks: A Convex
  Optimization Perspective</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE Signal Processing Magazine, special issue on convex
  optimization for signal processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article provides an overview of the state-of-art results on
communication resource allocation over space, time, and frequency for emerging
cognitive radio (CR) wireless networks. Focusing on the
interference-power/interference-temperature (IT) constraint approach for CRs to
protect primary radio transmissions, many new and challenging problems
regarding the design of CR systems are formulated, and some of the
corresponding solutions are shown to be obtainable by restructuring some
classic results known for traditional (non-CR) wireless networks. It is
demonstrated that convex optimization plays an essential role in solving these
problems, in a both rigorous and efficient way. Promising research directions
on interference management for CR and other related multiuser communication
systems are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3193</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3193</id><created>2010-01-18</created><authors><author><keyname>Ahmed</keyname><forenames>Mohammed F. A.</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author></authors><title>Sidelobe Control in Collaborative Beamforming via Node Selection</title><categories>cs.IT math.IT</categories><comments>30 pages, 10 figures, submitted to the IEEE Trans. Signal Processing</comments><journal-ref>M.F.A. Ahmed and S.A. Vorobyov, &quot;Sidelobe control in collaborative
  beamforming via node selection,&quot; IEEE Trans. Signal Processing, vol. 58, no.
  12, pp. 6168-6180, Dec. 2010</journal-ref><doi>10.1109/TSP.2010.2077631</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collaborative beamforming (CB) is a power efficient method for data
communications in wireless sensor networks (WSNs) which aims at increasing the
transmission range in the network by radiating the power from a cluster of
sensor nodes in the directions of the intended base station(s) or access
point(s) (BSs/APs). The CB average beampattern expresses a deterministic
behavior and can be used for characterizing/controling the transmission at
intended direction(s), since the mainlobe of the CB beampattern is independent
on the particular random node locations. However, the CB for a cluster formed
by a limited number of collaborative nodes results in a sample beampattern with
sidelobes that severely depend on the particular node locations. High level
sidelobes can cause unacceptable interference when they occur at directions of
unintended BSs/APs. Therefore, sidelobe control in CB has a potential to
increase the network capacity and wireless channel availability by decreasing
the interference. Traditional sidelobe control techniques are proposed for
centralized antenna arrays and, therefore, are not suitable for WSNs. In this
paper, we show that distributed, scalable, and low-complexity sidelobe control
techniques suitable for CB in WSNs can be developed based on node selection
technique which make use of the randomness of the node locations. A node
selection algorithm with low-rate feedback is developed to search over
different node combinations. The performance of the proposed algorithm is
analyzed in terms of the average number of trials required to select the
collaborative nodes and the resulting interference. Our simulation results
approve the theoretical analysis and show that the interference is
significantly reduced when node selection is used with CB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3199</identifier>
 <datestamp>2010-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3199</id><created>2010-01-19</created><updated>2010-05-04</updated><authors><author><keyname>Barman</keyname><forenames>Kishor</forenames></author><author><keyname>Dabeer</keyname><forenames>Onkar</forenames></author></authors><title>Local Popularity Based Collaborative Filters</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to International Symposium on Information Theory,
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by applications such as recommendation systems, we consider the
estimation of a binary random field X obtained by row and column permutations
of a block constant random matrix. The estimation of X is based on observations
Y, which are obtained by passing entries of X through a binary symmetric
channel (BSC) and an erasure channel. We focus on the analysis of a specific
algorithm based on local popularity when the erasure rate approaches unity at a
specified rate. We study the bit error rate (BER) in the limit as the matrix
size approaches infinity. Our main result states that if the cluster size (that
is, the size of the constancy blocks in the original matrix) is above a certain
threshold, then the BER approaches zero, but below the threshold, the BER is
lower bounded away from zero. The lower bound depends on the noise level in the
observations and the size of the clusters in relation to the threshold. The
threshold depends on the rate at which the erasure probability approaches
unity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3206</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3206</id><created>2010-01-19</created><updated>2010-01-20</updated><authors><author><keyname>Damen</keyname><forenames>Mohamed Oussama</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author><author><keyname>Badr</keyname><forenames>Ahmed A.</forenames></author></authors><title>A New Class of TAST Codes With A Simplified Tree Structure</title><categories>cs.IT cs.CR math.IT math.NT</categories><comments>7 pages, 3 figures, Conference Paper, accepted in WCC'09 (Workshop
  for Coding and Cryptography 2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider in this paper the design of full diversity and high rate
space-time codes with moderate decoding complexity for arbitrary number of
transmit and receive antennas and arbitrary input alphabets. We focus our
attention to codes from the threaded algebraic space-time (TAST) framework
since the latter includes most known full diversity space-time codes. We
propose a new construction of the component single-input single-output (SISO)
encoders such that the equivalent code matrix has an upper triangular form. We
accomplish this task by designing each SISO encoder to create an ISI-channel in
each thread. This, in turn, greatly simplifies the QR-decomposition of the
composite channel and code matrix, which is essential for optimal or
near-optimal tree search algorithms, such as the sequential decoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3213</identifier>
 <datestamp>2012-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3213</id><created>2010-01-19</created><updated>2012-05-21</updated><authors><author><keyname>Chancelier</keyname><forenames>Jean-Philippe</forenames><affiliation>CERMICS</affiliation></author><author><keyname>Lelong</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>LJK</affiliation></author><author><keyname>Lapeyre</keyname><forenames>Bernard</forenames><affiliation>CERMICS</affiliation></author></authors><title>Using Premia and Nsp for Constructing a Risk Management Benchmark for
  Testing Parallel Architecture</title><categories>cs.CE cs.DC cs.MS cs.NA q-fin.CP q-fin.PR</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Financial institutions have massive computations to carry out overnight which
are very demanding in terms of the consumed CPU. The challenge is to price many
different products on a cluster-like architecture. We have used the Premia
software to valuate the financial derivatives. In this work, we explain how
Premia can be embedded into Nsp, a scientific software like Matlab, to provide
a powerful tool to valuate a whole portfolio. Finally, we have integrated an
MPI toolbox into Nsp to enable to use Premia to solve a bunch of pricing
problems on a cluster. This unified framework can then be used to test
different parallel architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3215</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3215</id><created>2010-01-19</created><authors><author><keyname>Schon</keyname><forenames>Walter</forenames><affiliation>HEUDIASYC</affiliation></author></authors><title>S\'ecurit\'e des syst\`emes critiques et cybercriminalit\'e : vers une
  s\'ecurit\'e globale ?</title><categories>cs.CR</categories><proxy>ccsd hal-00337751</proxy><journal-ref>Cahiers de la S\'ecurit\'e (2008) n\degree 6 La criminalit\'e
  num\'erique p. 146-154</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For modern critical systems, it is necessary to consider their ability to
avoid catastrophic behavior following fortuitous events such as internal
failures in hardware components, environmental disturbances or even involuntary
human error in the design and operation, but also non fortuitous events such as
malicious attacks. Unfortunately, in French the same word &quot;s\'ecurit\'e&quot; is
used to cover two different problematics, what in English is expressed in two
different words : safety and security. The interconnected modern information
systems, such as rail traffic signalling systems point out the need to deal in
an overall way with both safety and security
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3217</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3217</id><created>2010-01-19</created><authors><author><keyname>Vey</keyname><forenames>Georges Le</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Optimal control theory : a method for the design of wind instruments</title><categories>math.OC cs.SD physics.class-ph</categories><comments>To appear in Acta Acustica united with Acustica, 2010</comments><proxy>ccsd hal-00447989</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been asserted previously by the author that optimal control theory can
be a valuable framework for theoretical studies about the shape that a wind
instrument should have in order to satisfy some optimization criterion, inside
a fairly general class. The purpose of the present work is to develop this new
approach with a look at a specific criterion to be optimized. In this setting,
the Webster horn equation is regarded as a controlled dynamical equation in the
space variable. Pressure is the state, the control being made of two parts: one
variable part, the inside diameter of the duct and one constant part, the
weights of the elementary time-harmonic components of the velocity potential.
Then one looks for a control that optimizes a criterion related to the
definition of an {oscillation regime} as the cooperation of several natural
modes of vibration with the excitation, the {playing frequency} being the one
that maximizes the total generation of energy, as exposed by A.H. Benade,
following H. Bouasse. At the same time the relevance of this criterion is
questioned with the simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3219</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3219</id><created>2010-01-19</created><authors><author><keyname>Ehrhard</keyname><forenames>Thomas</forenames><affiliation>PPS</affiliation></author></authors><title>A finiteness structure on resource terms</title><categories>cs.LO</categories><proxy>ccsd hal-00448431</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In our paper &quot;Uniformity and the Taylor expansion of ordinary lambda-terms&quot;
(with Laurent Regnier), we studied a translation of lambda-terms as infinite
linear combinations of resource lambda-terms, from a calculus similar to
Boudol's lambda-calculus with resources and based on ideas coming from
differential linear logic and differential lambda-calculus. The good properties
of this translation wrt. beta-reduction were guaranteed by a coherence relation
on resource terms: normalization is &quot;linear and stable&quot; (in the sense of the
coherence space semantics of linear logic) wrt. this coherence relation. Such
coherence properties are lost when one considers non-deterministic or algebraic
extensions of the lambda-calculus (the algebraic lambda-calculus is an
extension of the lambda-calculus where terms can be linearly combined). We
introduce a &quot;finiteness structure&quot; on resource terms which induces a linearly
topologized vector space structure on terms and prevents the appearance of
infinite coefficients during reduction, in typed settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3225</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3225</id><created>2010-01-19</created><authors><author><keyname>Uribe</keyname><forenames>Paula</forenames><affiliation>CMM</affiliation></author><author><keyname>Maureira</keyname><forenames>Juan-Carlos</forenames><affiliation>INRIA Sophia Antipolis / Laboratoire I3S</affiliation></author><author><keyname>Dalle</keyname><forenames>Olivier</forenames><affiliation>INRIA Sophia Antipolis / Laboratoire I3S</affiliation></author></authors><title>Extending INET Framework for Directional and Asymmetrical Wireless
  Communications</title><categories>cs.NI</categories><proxy>ccsd inria-00448033</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reports our work on extending the Omnet INET Framework with a
directional radio model, putting a special emphasis on the implementation of
asymmetrical communications. We first analyze the original INET radio model,
focusing on its design and components. Then we discuss the modifications that
have been done to support directional communications. Our preliminary results
show that the new model is flexible enough to allow the user to provide any
antenna pattern shape, with only an additional reasonable computational cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3242</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3242</id><created>2010-01-19</created><authors><author><keyname>Chen</keyname><forenames>Jen-Yeu</forenames></author><author><keyname>Pandurangan</keyname><forenames>Gopal</forenames></author></authors><title>Optimal Gossip-Based Aggregate Computation</title><categories>cs.DS cs.CC cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the first provably almost-optimal gossip-based algorithms for
aggregate computation that are both time optimal and message-optimal. Given a
$n$-node network, our algorithms guarantee that all the nodes can compute the
common aggregates (such as Min, Max, Count, Sum, Average, Rank etc.) of their
values in optimal $O(\log n)$ time and using $O(n \log \log n)$ messages. Our
result improves on the algorithm of Kempe et al. \cite{kempe} that is
time-optimal, but uses $O(n \log n)$ messages as well as on the algorithm of
Kashyap et al. \cite{efficient-gossip} that uses $O(n \log \log n)$ messages,
but is not time-optimal (takes $O(\log n \log \log n)$ time). Furthermore, we
show that our algorithms can be used to improve gossip-based aggregate
computation in sparse communication networks, such as in peer-to-peer networks.
  The main technical ingredient of our algorithm is a technique called {\em
distributed random ranking (DRR)} that can be useful in other applications as
well. DRR gives an efficient distributed procedure to partition the network
into a forest of (disjoint) trees of small size.
  Our algorithms are non-address oblivious. In contrast, we show a lower bound
of $\Omega(n\log n)$ on the message complexity of any address-oblivious
algorithm for computing aggregates. This shows that non-address oblivious
algorithms are needed to obtain significantly better message complexity. Our
lower bound holds regardless of the number of rounds taken or the size of the
messages used. Our lower bound is the first non-trivial lower bound for
gossip-based aggregate computation and also gives the first formal proof that
computing aggregates is strictly harder than rumor spreading in the
address-oblivious model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3246</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3246</id><created>2010-01-19</created><authors><author><keyname>Remmelzwaal</keyname><forenames>Leendert A.</forenames></author><author><keyname>Tapson</keyname><forenames>Jonathan</forenames></author><author><keyname>Ellis</keyname><forenames>George F. R.</forenames></author></authors><title>Salience-Affected Neural Networks</title><categories>cs.NE q-bio.NC</categories><comments>24 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a simple neural network model which combines a locally-connected
feedforward structure, as is traditionally used to model inter-neuron
connectivity, with a layer of undifferentiated connections which model the
diffuse projections from the human limbic system to the cortex. This new layer
makes it possible to model global effects such as salience, at the same time as
the local network processes task-specific or local information. This simple
combination network displays interactions between salience and regular
processing which correspond to known effects in the developing brain, such as
enhanced learning as a result of heightened affect.
  The cortex biases neuronal responses to affect both learning and memory,
through the use of diffuse projections from the limbic system to the cortex.
Standard ANNs do not model this non-local flow of information represented by
the ascending systems, which are a significant feature of the structure of the
brain, and although they do allow associational learning with multiple-trial,
they simply don't provide the capacity for one-time learning.
  In this research we model this effect using an artificial neural network
(ANN), creating a salience-affected neural network (SANN). We adapt an ANN to
embody the capacity to respond to an input salience signal and to produce a
reverse salience signal during testing.
  This research demonstrates that input combinations similar to the inputs in
the training data sets will produce similar reverse salience signals during
testing. Furthermore, this research has uncovered a novel method for training
ANNs with a single training iteration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3251</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3251</id><created>2010-01-19</created><updated>2010-02-03</updated><authors><author><keyname>Mertzios</keyname><forenames>George B.</forenames></author><author><keyname>Sau</keyname><forenames>Ignasi</forenames></author><author><keyname>Zaks</keyname><forenames>Shmuel</forenames></author></authors><title>The Recognition of Tolerance and Bounded Tolerance Graphs</title><categories>cs.CC cs.DM</categories><comments>12 pages, 4 figures, 1 algorithm, Proceedings of the 27th
  International Symposium on Theoretical Aspects of Computer Science (STACS),
  Nancy, France, March 2010</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Tolerance graphs model interval relations in such a way that intervals can
tolerate a certain degree of overlap without being in conflict. This subclass
of perfect graphs has been extensively studied, due to both its interesting
structure and its numerous applications. Several efficient algorithms for
optimization problems that are NP-hard on general graphs have been designed for
tolerance graphs. In spite of this, the recognition of tolerance graphs -
namely, the problem of deciding whether a given graph is a tolerance graph - as
well as the recognition of their main subclass of bounded tolerance graphs,
have been the most fundamental open problems on this class of graphs (cf. the
book on tolerance graphs \cite{GolTol04}) since their introduction in 1982
\cite{GoMo82}. In this article we prove that both recognition problems are
NP-complete, even in the case where the input graph is a trapezoid graph. The
presented results are surprising because, on the one hand, most subclasses of
perfect graphs admit polynomial recognition algorithms and, on the other hand,
bounded tolerance graphs were believed to be efficiently recognizable as they
are a natural special case of trapezoid graphs (which can be recognized in
polynomial time) and share a very similar structure with them. For our
reduction we extend the notion of an \emph{acyclic orientation} of permutation
and trapezoid graphs. Our main tool is a new algorithm that uses \emph{vertex
splitting} to transform a given trapezoid graph into a permutation graph, while
preserving this new acyclic orientation property. This method of vertex
splitting is of independent interest; very recently, it has been proved a
powerful tool also in the design of efficient recognition algorithms for other
classes of graphs \cite{MC-Trapezoid}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3257</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3257</id><created>2010-01-19</created><authors><author><keyname>Khajeh-Hosseini</keyname><forenames>Ali</forenames></author><author><keyname>Sommerville</keyname><forenames>Ian</forenames></author><author><keyname>Sriram</keyname><forenames>Ilango</forenames></author></authors><title>Research Challenges for Enterprise Cloud Computing</title><categories>cs.DC cs.CY</categories><comments>Submitted to the 1st ACM Symposium on Cloud Computing, SOCC 2010</comments><acm-class>C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing represents a shift away from computing as a product that is
purchased, to computing as a service that is delivered to consumers over the
internet from large-scale data centers - or &quot;clouds&quot;. This paper discusses some
of the research challenges for cloud computing from an enterprise or
organizational perspective, and puts them in context by reviewing the existing
body of literature in cloud computing. Various research challenges relating to
the following topics are discussed: the organizational changes brought about by
cloud computing; the economic and organizational implications of its utility
billing model; the security, legal and privacy issues that cloud computing
raises. It is important to highlight these research challenges because cloud
computing is not simply about a technological improvement of data centers but a
fundamental change in how IT is provisioned and used. This type of research has
the potential to influence wider adoption of cloud computing in enterprise, and
in the consumer market too.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3259</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3259</id><created>2010-01-19</created><authors><author><keyname>Sriram</keyname><forenames>Ilango</forenames></author><author><keyname>Khajeh-Hosseini</keyname><forenames>Ali</forenames></author></authors><title>Research Agenda in Cloud Technologies</title><categories>cs.DC</categories><comments>Submitted to the 1st ACM Symposium on Cloud Computing, SOCC 2010</comments><acm-class>C.2.4; A.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing is the latest effort in delivering computing resources as a
service. It represents a shift away from computing as a product that is
purchased, to computing as a service that is delivered to consumers over the
internet from large-scale data centres - or &quot;clouds&quot;. Whilst cloud computing is
gaining growing popularity in the IT industry, academia appeared to be lagging
behind the rapid developments in this field. This paper is the first systematic
review of peer-reviewed academic research published in this field, and aims to
provide an overview of the swiftly developing advances in the technical
foundations of cloud computing and their research efforts. Structured along the
technical aspects on the cloud agenda, we discuss lessons from related
technologies; advances in the introduction of protocols, interfaces, and
standards; techniques for modelling and building clouds; and new use-cases
arising through cloud computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3263</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3263</id><created>2010-01-19</created><authors><author><keyname>Schuh</keyname><forenames>Bernd R.</forenames></author></authors><title>A Real World Mechanism for Testing Satisfiability in Polynomial Time</title><categories>cs.LO cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Whether the satisfiability of any formula F of propositional calculus can be
determined in polynomial time is an open question. I propose a simple procedure
based on some real world mechanisms to tackle this problem. The main result is
the blueprint for a machine which is able to test any formula in conjunctive
normal form (CNF) for satisfiability in linear time. The device uses light and
some electrochemical properties to function. It adapts itself to the scope of
the problem without growing exponentially in mass with the size of the formula.
It requires infinite precision in its components instead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3265</identifier>
 <datestamp>2012-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3265</id><created>2010-01-19</created><updated>2012-08-26</updated><authors><author><keyname>Borokhovich</keyname><forenames>Michael</forenames></author><author><keyname>Avin</keyname><forenames>Chen</forenames></author><author><keyname>Lotker</keyname><forenames>Zvi</forenames></author></authors><title>Bounds for Algebraic Gossip on Graphs</title><categories>cs.IT cs.NI math.IT math.PR</categories><comments>17 pages. arXiv admin note: text overlap with arXiv:1101.4372</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the stopping times of gossip algorithms for network coding. We
analyze algebraic gossip (i.e., random linear coding) and consider three gossip
algorithms for information spreading Pull, Push, and Exchange. The stopping
time of algebraic gossip is known to be linear for the complete graph, but the
question of determining a tight upper bound or lower bounds for general graphs
is still open. We take a major step in solving this question, and prove that
algebraic gossip on any graph of size n is O(D*n) where D is the maximum degree
of the graph. This leads to a tight bound of Theta(n) for bounded degree graphs
and an upper bound of O(n^2) for general graphs. We show that the latter bound
is tight by providing an example of a graph with a stopping time of Omega(n^2).
Our proofs use a novel method that relies on Jackson's queuing theorem to
analyze the stopping time of network coding; this technique is likely to become
useful for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3277</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3277</id><created>2010-01-19</created><updated>2010-01-21</updated><authors><author><keyname>Sharma</keyname><forenames>Sugam</forenames></author><author><keyname>Pei</keyname><forenames>Tzusheng</forenames></author><author><keyname>Cohly</keyname><forenames>Hari</forenames></author></authors><title>On Utilization and Importance of Perl Status Reporter (SRr) in Text
  Mining</title><categories>cs.IR</categories><comments>7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/; Volume 6, No. 3, ISSN 1947 5500</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 253-259, December 2009, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Bioinformatics, text mining and text data mining sometimes interchangeably
used is a process to derive high-quality information from text. Perl Status
Reporter (SRr) is a data fetching tool from a flat text file and in this
research paper we illustrate the use of SRr in text or data mining. SRr needs a
flat text input file where the mining process to be performed. SRr reads input
file and derives the high quality information from it. Typically text mining
tasks are text categorization, text clustering, concept and entity extraction,
and document summarization. SRr can be utilized for any of these tasks with
little or none customizing efforts. In our implementation we perform text
categorization mining operation on input file. The input file has two
parameters of interest (firstKey and secondKey). The composition of these two
parameters describes the uniqueness of entries in that file in the similar
manner as done by composite key in database. SRr reads the input file line by
line and extracts the parameters of interest and form a composite key by
joining them together. It subsequently generates an output file consisting of
the name as firstKey secondKey. SRr reads the input file and tracks the
composite key. It further stores all that data lines, having the same composite
key, in output file generated by SRr based on that composite key.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3297</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3297</id><created>2010-01-19</created><authors><author><keyname>Ekrem</keyname><forenames>Ersen</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Gaussian MIMO Broadcast Channels with Common and Confidential Messages</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE ISIT, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the two-user Gaussian multiple-input multiple-output (MIMO)
broadcast channel with common and confidential messages. In this channel, the
transmitter sends a common message to both users, and a confidential message to
each user which is kept perfectly secret from the other user. We obtain the
entire capacity region of this channel. We also explore the connections between
the capacity region we obtained for the Gaussian MIMO broadcast channel with
common and confidential messages and the capacity region of its
non-confidential counterpart, i.e., the Gaussian MIMO broadcast channel with
common and private messages, which is not known completely.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3331</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3331</id><created>2010-01-19</created><authors><author><keyname>Parakh</keyname><forenames>Abhishek</forenames></author><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>Recursive Secret Sharing for Distributed Storage and Information Hiding</title><categories>cs.CR</categories><comments>To appear in Proceedings of 3rd IEEE International Symposium on
  Advanced Networks and Telecommunication Systems (IEEE ANTS 2009), Dec. 14-16,
  New Delhi, India, 2009. (3 pages)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a recursive computational multi-secret sharing technique
that hides k-2 secrets of size b each into n shares of a single secret S of
size b, such that any k of the n shares suffice to recreate the secret S as
well as all the hidden secrets. This may act as a steganographic channel to
transmit hidden information or used for authentication and verification of
shares and the secret itself. Further, such a recursive technique may be used
as a computational secret sharing technique that has potential applications in
secure and reliable storage of information on the Web, in sensor networks and
information dispersal schemes. The presented technique, unlike previous
computational techniques, does not require the use of any encryption key or
storage of public information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3332</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3332</id><created>2010-01-19</created><authors><author><keyname>Bar-Yehuda</keyname><forenames>Reuven</forenames></author><author><keyname>Hermelin</keyname><forenames>Danny</forenames></author><author><keyname>Rawitz</keyname><forenames>Dror</forenames></author></authors><title>Minimum Vertex Cover in Rectangle Graphs</title><categories>cs.DS cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the Vertex Cover problem in intersection graphs of axis-parallel
rectangles on the plane. We present two algorithms: The first is an EPTAS for
non-crossing rectangle families, rectangle families $\calR$ where $R_1
\setminus R_2$ is connected for every pair of rectangles $R_1,R_2 \in \calR$.
This algorithm extends to intersection graphs of pseudo-disks. The second
algorithm achieves a factor of $(1.5 + \varepsilon)$ in general rectangle
families, for any fixed $\varepsilon &gt; 0$, and works also for the weighted
variant of the problem. Both algorithms exploit the plane properties of
axis-parallel rectangles in a non-trivial way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3355</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3355</id><created>2010-01-19</created><updated>2011-04-15</updated><authors><author><keyname>Sutton</keyname><forenames>Charles</forenames></author><author><keyname>Jordan</keyname><forenames>Michael I.</forenames></author></authors><title>Bayesian inference for queueing networks and modeling of internet
  services</title><categories>stat.ML cs.NI cs.PF stat.AP stat.CO</categories><comments>Published in at http://dx.doi.org/10.1214/10-AOAS392 the Annals of
  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AOAS-AOAS392</report-no><journal-ref>Annals of Applied Statistics 2011, Vol. 5, No. 1, 254-282</journal-ref><doi>10.1214/10-AOAS392</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern Internet services, such as those at Google, Yahoo!, and Amazon, handle
billions of requests per day on clusters of thousands of computers. Because
these services operate under strict performance requirements, a statistical
understanding of their performance is of great practical interest. Such
services are modeled by networks of queues, where each queue models one of the
computers in the system. A key challenge is that the data are incomplete,
because recording detailed information about every request to a heavily used
system can require unacceptable overhead. In this paper we develop a Bayesian
perspective on queueing models in which the arrival and departure times that
are not observed are treated as latent variables. Underlying this viewpoint is
the observation that a queueing model defines a deterministic transformation
between the data and a set of independent variables called the service times.
With this viewpoint in hand, we sample from the posterior distribution over
missing data and model parameters using Markov chain Monte Carlo. We evaluate
our framework on data from a benchmark Web application. We also present a
simple technique for selection among nested queueing models. We are unaware of
any previous work that considers inference in networks of queues in the
presence of missing data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3364</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3364</id><created>2010-01-19</created><authors><author><keyname>Robillard</keyname><forenames>David E.</forenames></author></authors><title>Practical Parallel External Memory Algorithms via Simulation of Parallel
  Algorithms</title><categories>cs.DC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis introduces PEMS2, an improvement to PEMS (Parallel External
Memory System). PEMS executes Bulk-Synchronous Parallel (BSP) algorithms in an
External Memory (EM) context, enabling computation with very large data sets
which exceed the size of main memory. Many parallel algorithms have been
designed and implemented for Bulk-Synchronous Parallel models of computation.
Such algorithms generally assume that the entire data set is stored in main
memory at once. PEMS overcomes this limitation without requiring any
modification to the algorithm by using disk space as memory for additional
&quot;virtual processors&quot;. Previous work has shown this to be a promising approach
which scales well as computational resources (i.e. processors and disks) are
added. However, the technique incurs significant overhead when compared with
purpose-built EM algorithms. PEMS2 introduces refinements to the simulation
process intended to reduce this overhead as well as the amount of disk space
required to run the simulation. New functionality is also introduced, including
asynchronous I/O and support for multi-core processors. Experimental results
show that these changes significantly improve the runtime of the simulation.
PEMS2 narrows the performance gap between simulated BSP algorithms and their
hand-crafted EM counterparts, providing a practical system for using BSP
algorithms with data sets which exceed the size of RAM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3365</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3365</id><created>2010-01-19</created><authors><author><keyname>Jamal</keyname><forenames>Nadia</forenames></author><author><keyname>Saffar</keyname><forenames>Hamidreza Ebrahimzadeh</forenames></author><author><keyname>Mitran</keyname><forenames>Patrick</forenames></author></authors><title>Asymptotic Scheduling Gains in Point-to-Multipoint Cognitive Networks</title><categories>cs.IT math.IT</categories><comments>15 pages double column, 7 figures .pdf, submitted to IEEE
  Transactions on Information Theory</comments><msc-class>94A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider collocated primary and secondary networks that have simultaneous
access to the same frequency bands. Particularly, we examine three different
levels at which primary and secondary networks may coexist: pure interference,
asymmetric co-existence, and symmetric co-existence. At the asymmetric
co-existence level, the secondary network selectively deactivates its users
based on knowledge of the interference and channel gains, whereas at the
symmetric level, the primary network also schedules its users in the same way.
Our aim is to derive optimal sum-rates (i.e., throughputs)of both networks at
each co-existence level as the number of users grows asymptotically and
evaluate how the sum-rates scale with network size. In order to find the
asymptotic throughput results, we derive a key lemma on extreme order
statistics and a proposition on the sum of lower order statistics. As a
baseline comparison, we calculate the sum-rates for channel sharing via
time-division (TD). We compare the asymptotic secondary sum-rate in TD with
that under simultaneous transmission, while ensuring the primary network
maintains the same throughput in both cases. The results indicate that
simultaneous transmission at both asymmetric and symmetric co-existence levels
can outperform TD. Furthermore, this enhancement is achievable when uplink
activation or deactivation of users is based only on the interference gains to
the opposite network and not on a network's own channel gains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3368</identifier>
 <datestamp>2011-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3368</id><created>2010-01-19</created><updated>2011-01-14</updated><authors><author><keyname>Alves</keyname><forenames>Sandra</forenames><affiliation>University of Porto</affiliation></author><author><keyname>Fern&#xe1;ndez</keyname><forenames>Maribel</forenames><affiliation>King's College London</affiliation></author><author><keyname>Florido</keyname><forenames>M&#xe1;rio</forenames><affiliation>University of Porto</affiliation></author><author><keyname>Mackie</keyname><forenames>Ian</forenames><affiliation>&#xc9;cole Polytechnique</affiliation></author></authors><title>Linear Recursion</title><categories>cs.LO cs.PL</categories><comments>24 pages</comments><acm-class>F.4.1; F.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the full PCF language can be encoded in Lrec, a linear
lambda-calculus extended with numbers, pairs and an unbounded recursor that
preserves the syntactic linearity of the calculus. Thus, Lrec is a Turing
complete extension of the linear lambda-calculus. We discuss evaluation
strategies and implementation techniques for Lrec, exploiting the linearity of
the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3387</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3387</id><created>2010-01-19</created><authors><author><keyname>Silva</keyname><forenames>Danilo</forenames></author><author><keyname>Kschischang</keyname><forenames>Frank R.</forenames></author></authors><title>Universal Secure Error-Correcting Schemes for Network Coding</title><categories>cs.IT cs.CR math.IT</categories><comments>5 pages, submitted to IEEE ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of securing a linear network coding system
against an adversary that is both an eavesdropper and a jammer. The network is
assumed to transport n packets from source to each receiver, and the adversary
is allowed to eavesdrop on \mu arbitrarily chosen links and also to inject up
to t erroneous packets into the network. The goal of the system is to achieve
zero-error communication that is information-theoretically secure from the
adversary. Moreover, this goal must be attained in a universal fashion, i.e.,
regardless of the network topology or the underlying network code. An upper
bound on the achievable rate under these requirements is shown to be n-\mu-2t
packets per transmission. A scheme is proposed that can achieve this maximum
rate, for any n and any field size q, provided the packet length m is at least
n symbols. The scheme is based on rank-metric codes and admits low-complexity
encoding and decoding. In addition, the scheme is shown to be optimal in the
sense that the required packet length is the smallest possible among all
universal schemes that achieve the maximum rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3388</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3388</id><created>2010-01-19</created><updated>2010-06-09</updated><authors><author><keyname>Feigenbaum</keyname><forenames>Joan</forenames></author><author><keyname>Jaggard</keyname><forenames>Aaron D.</forenames></author><author><keyname>Schapira</keyname><forenames>Michael</forenames></author></authors><title>Approximate Privacy: PARs for Set Problems</title><categories>cs.CR</categories><comments>34 pages, nine figures, one table. Version 2 adds acknowledgements
  and Appendix B</comments><report-no>DIMACS TR 2010-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In previous work (arXiv:0910.5714), we introduced the Privacy Approximation
Ratio (PAR) and used it to study the privacy of protocols for second-price
Vickrey auctions and Yao's millionaires problem. Here, we study the PARs of
multiple protocols for both the disjointness problem (in which two
participants, each with a private subset of {1,...,k}, determine whether their
sets are disjoint) and the intersection problem (in which the two participants,
each with a private subset of {1,...,k}, determine the intersection of their
private sets).
  We show that the privacy, as measured by the PAR, provided by any protocol
for each of these problems is necessarily exponential (in k). We also consider
the ratio between the subjective PARs with respect to each player in order to
show that one protocol for each of these problems is significantly fairer than
the others (in the sense that it has a similarly bad effect on the privacy of
both players).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3392</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3392</id><created>2010-01-19</created><authors><author><keyname>Marouni</keyname><forenames>Abbass</forenames><affiliation>IETR</affiliation></author><author><keyname>Nasser</keyname><forenames>Youssef</forenames><affiliation>IETR</affiliation></author><author><keyname>H&#xe9;lard</keyname><forenames>Maryline</forenames><affiliation>IETR</affiliation></author><author><keyname>El-Mokdad</keyname><forenames>Haidar</forenames></author></authors><title>Adaptive resource allocation at the cell border using cooperative
  technique</title><categories>cs.NI</categories><proxy>ccsd hal-00448736</proxy><journal-ref>Majestic, France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The technique of cooperative communication has recently gained momentum in
the research community; this technique utilizes the notion of relay, as an
intermediate node between the source and the destination, to enhance the
overall system performance. In this paper we ex-plored the benefits of adaptive
cooperation, in which the relay adapts its relaying process in response to
channel conditions and data priorities. We are particularly interested in
applying this concept to the cell border situation, in which two mobile nodes
acting as destinations com-municate with base stations (sources) through a
relay. The adaptive cooperation is proposed here since the transmission channel
conditions (Packet Error Rate for example) and data priori-ties are not the
same for both mobiles. We show that using the adaptive resource allocation
technique in combination with the cross layer design techniques, we can achieve
Real-Time data constraints with no additional overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3395</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3395</id><created>2010-01-19</created><authors><author><keyname>Nasser</keyname><forenames>Youssef</forenames><affiliation>IETR</affiliation></author><author><keyname>Farhat</keyname><forenames>H.</forenames><affiliation>IETR</affiliation></author><author><keyname>H&#xe9;lard</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>IETR</affiliation></author></authors><title>Positioning based information technique in cooperative MIMO-OFDM systems</title><categories>cs.NI</categories><proxy>ccsd hal-00448734</proxy><journal-ref>IEEE PIMRC, France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Future Communication networks are tending towards a diverse wireless
networking world where the positioning information (PI) could be helpful in
different techniques like the dynamic resource allocation. On the other hand,
the PI could be widely used for cooperative techniques in the relay and/or
routing selection process. In this paper, we propose to use the PI in the
selection of the relays and then to apply an efficient double layer distributed
space time block code (DLSTBC) scheme between the different relays. Using the
amplify and forward (AF) technique, we show that the proposed code is very
efficient whatever the transmitted power is. Moreover, we show that the relay
selection process based on PI yields very powerful results when compared to the
random relay selection (RS) process
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3403</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3403</id><created>2010-01-19</created><authors><author><keyname>Motahari</keyname><forenames>Abolfazl Seyed</forenames></author><author><keyname>Oveis-Gharan</keyname><forenames>Shahab</forenames></author><author><keyname>Maddah-Ali</keyname><forenames>Mohammad-Ali</forenames></author><author><keyname>Khandani</keyname><forenames>Amir Keyvan</forenames></author></authors><title>Real Interference Alignment</title><categories>cs.IT math.IT math.NT</categories><comments>Submitted to ISIT 2010. For the full version, please visit
  arXiv:0908.2282</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show that the total Degrees-Of-Freedoms (DOF) of the
$K$-user Gaussian Interference Channel (GIC) can be achieved by incorporating a
new alignment technique known as \emph{real interference alignment}. This
technique compared to its ancestor \emph{vector interference alignment}
performs on a single real line and exploits the properties of real numbers to
provide optimal signaling. The real interference alignment relies on a new
coding scheme in which several data streams having fractional multiplexing
gains are sent by transmitters and interfering streams are aligned at
receivers. The coding scheme is backed up by a recent result in the field of
Diophantine approximation, which states that the convergence part of the
Khintchine-Groshev theorem holds for points on non-degenerate manifolds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3404</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3404</id><created>2010-01-20</created><updated>2011-12-14</updated><authors><author><keyname>Gamal</keyname><forenames>Abbas El</forenames></author><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author></authors><title>Lecture Notes on Network Information Theory</title><categories>cs.IT cs.NI math.IT math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  These lecture notes have been converted to a book titled Network Information
Theory published recently by Cambridge University Press. This book provides a
significantly expanded exposition of the material in the lecture notes as well
as problems and bibliographic notes at the end of each chapter. The authors are
currently preparing a set of slides based on the book that will be posted in
the second half of 2012. More information about the book can be found at
http://www.cambridge.org/9781107008731/. The previous (and obsolete) version of
the lecture notes can be found at http://arxiv.org/abs/1001.3404v4/.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3405</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3405</id><created>2010-01-19</created><authors><author><keyname>Whitbeck</keyname><forenames>John</forenames></author><author><keyname>Conan</keyname><forenames>Vania</forenames></author></authors><title>HYMAD: Hybrid DTN-MANET Routing for Dense and Highly Dynamic Wireless
  Networks</title><categories>cs.NI</categories><comments>7 pages, 6 figures</comments><journal-ref>In Proceedings: IEEE WoWMoM Workshop on Autonomic and
  Opportunistic Communications (AOC 2009) - Kos, Greece - June 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose HYMAD, a Hybrid DTN-MANET routing protocol which
uses DTN between disjoint groups of nodes while using MANET routing within
these groups. HYMAD is fully decentralized and only makes use of topological
information exchanges between the nodes. We evaluate the scheme in simulation
by replaying real life traces which exhibit this highly dynamic connectivity.
The results show that HYMAD outperforms the multi-copy Spray-and-Wait DTN
routing protocol it extends, both in terms of delivery ratio and delay, for any
number of message copies. Our conclusion is that such a Hybrid DTN-MANET
approach offers a promising venue for the delivery of elastic data in mobile
ad-hoc networks as it retains the resilience of a pure DTN protocol while
significantly improving performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3421</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3421</id><created>2010-01-19</created><updated>2011-03-03</updated><authors><author><keyname>Planjery</keyname><forenames>Shiva Kumar</forenames></author><author><keyname>Declercq</keyname><forenames>David</forenames></author><author><keyname>Chilappagari</keyname><forenames>Shashi Kiran</forenames></author><author><keyname>Vasi&#x107;</keyname><forenames>Bane</forenames></author></authors><title>Multilevel Decoders Surpassing Belief Propagation on the Binary
  Symmetric Channel</title><categories>cs.IT math.IT</categories><comments>5 pages, in Proc. of 2010 IEEE International Symposium on Information
  Theory (ISIT)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new class of quantized message-passing decoders
for LDPC codes over the BSC. The messages take values (or levels) from a finite
set. The update rules do not mimic belief propagation but instead are derived
using the knowledge of trapping sets. We show that the update rules can be
derived to correct certain error patterns that are uncorrectable by algorithms
such as BP and min-sum. In some cases even with a small message set, these
decoders can guarantee correction of a higher number of errors than BP and
min-sum. We provide particularly good 3-bit decoders for 3-left-regular LDPC
codes. They significantly outperform the BP and min-sum decoders, but more
importantly, they achieve this at only a fraction of the complexity of the BP
and min-sum decoders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3439</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3439</id><created>2010-01-19</created><authors><author><keyname>Whitbeck</keyname><forenames>John</forenames></author><author><keyname>Conan</keyname><forenames>Vania</forenames></author><author><keyname>de Amorim</keyname><forenames>Marcelo Dias</forenames></author></authors><title>Tuning Message Size in Opportunistic Mobile Networks</title><categories>cs.NI</categories><comments>2 pages, 2 figures (Short paper accompanying a poster)</comments><acm-class>C.2.1; C.2.4</acm-class><journal-ref>In Proceedings: ACM SIGCOMM Workshop on Networking, Systems,
  Applications on Mobile Handhelds (Mobiheld 2009) - Barcelona, Spain - August
  2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new model for studying intermittently connected mobile
networks, based on Markovian random temporal graphs, that captures the
influence of message size, maximum tolerated delay and link stability on the
delivery ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3448</identifier>
 <datestamp>2012-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3448</id><created>2010-01-19</created><updated>2011-01-27</updated><authors><author><keyname>Bayati</keyname><forenames>Mohsen</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>The dynamics of message passing on dense graphs, with applications to
  compressed sensing</title><categories>cs.IT cs.LG math.IT math.ST stat.TH</categories><comments>41 pages</comments><journal-ref>IEEE Transactions on Information Theory, Vol 57, Issue 2 pp.
  764-785, 2011</journal-ref><doi>10.1109/TIT.2010.2094817</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Approximate message passing algorithms proved to be extremely effective in
reconstructing sparse signals from a small number of incoherent linear
measurements. Extensive numerical experiments further showed that their
dynamics is accurately tracked by a simple one-dimensional iteration termed
state evolution. In this paper we provide the first rigorous foundation to
state evolution. We prove that indeed it holds asymptotically in the large
system limit for sensing matrices with independent and identically distributed
gaussian entries.
  While our focus is on message passing algorithms for compressed sensing, the
analysis extends beyond this setting, to a general class of algorithms on dense
graphs. In this context, state evolution plays the role that density evolution
has for sparse graphs.
  The proof technique is fundamentally different from the standard approach to
density evolution, in that it copes with large number of short loops in the
underlying factor graph. It relies instead on a conditioning technique recently
developed by Erwin Bolthausen in the context of spin glass theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3451</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3451</id><created>2010-01-19</created><authors><author><keyname>Whitbeck</keyname><forenames>John</forenames></author><author><keyname>Conan</keyname><forenames>Vania</forenames></author><author><keyname>de Amorim</keyname><forenames>Marcelo Dias</forenames></author></authors><title>Dimensionnement des messages dans un reseau mobile opportuniste</title><categories>cs.NI</categories><comments>12 pages, 7 figures. Text in French</comments><acm-class>C.2.1; C.2.4</acm-class><journal-ref>In Proceedings: CFIP 2009 - Strasbourg, France - October 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding transport capacity in intermittently connected mobile networks
(ICMN) is crucial since different applications have different interactivity and
bandwidth requirements. One practical issue is how to transform an
application's messages into packets suitable for transport over an ICMN. In
this paper, we propose a new Markovian model for random temporal graphs and
show, both analytically and by replaying a real life trace obtained in a
rollerblading tour, that the size of the messages sent over an ICMN has a
decisive impact on their delivery ratio. A given message could therefore be
broken down into smaller packets to increase reliability. However, we also show
that this gain in reliability only appears under tight constraints on the
maximum delay tolerated. Mobile application designers should therefore balance
message size against both application requirements and network topology
dynamics to improve performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3460</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3460</id><created>2010-01-20</created><authors><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author><author><keyname>rani</keyname><forenames>R. Selva</forenames></author><author><keyname>Saraf</keyname><forenames>Vighnaraju</forenames></author></authors><title>Execution and Result Integration Scheme in FPU Farms for Co-ordinated
  Performance</title><categories>cs.IT math.IT</categories><comments>7 pages, 2 figures, InterJRI Science and Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  - The main goal of this research is to develop the concept of an innovative
processor system called Functional Processor System. The particular work
carried out in this paper focuses on the execution of functions in the
heterogeneous functional processor units(FPU) and integration of functions to
bring net results. As the functional programs are super-level programs, the
requirements of execution are only at functional level. The Execution and
integration of results of functions in FPUs are a challenge. The methodology of
executing the functions in the functional processor farm and the integration of
results of functions according to the assigned addresses are investigated here.
The concept of feeding the functions into the processor is promoted rather than
the processor fetching the instructions/functions and executing in this
paradigm. This work is carried out at conceptual levels and it takes a long way
to go into the realization of this model in hardware, possibly only with a
large industry team and with a realistic time frame.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3464</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3464</id><created>2010-01-20</created><authors><author><keyname>Ripon</keyname><forenames>Shamim H.</forenames></author><author><keyname>Butler</keyname><forenames>Michael</forenames></author></authors><title>Formalizing cCSP Synchronous Semantics in PVS</title><categories>cs.LO</categories><comments>9 pages</comments><acm-class>F.4.1; F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compensating CSP (cCSP) is a language defined to model long running business
transactions within the framework of standard CSP process algebra. In earlier
work, we have defined both traces and operational semantics of the language. We
have shown the consistency between the two semantic models by defining a
relationship between them. Synchronization was missing from the earlier
semantic definitions which is an important feature for any process algebra. In
this paper, we address this issue by extending the syntax and semantics to
support synchronization and define a relationship between the semantic models.
Moreover, we improve the scalability of our proof technique by mechanically
verifying the semantic relationship using theorem prover PVS. We show how to
embed process algebra terms and semantics into PVS and to use these embeddings
to prove the semantic relationship.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3473</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3473</id><created>2010-01-20</created><authors><author><keyname>Selvarani</keyname><forenames>R.</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author><author><keyname>Ramachandran</keyname><forenames>Muthu</forenames></author><author><keyname>Prasad</keyname><forenames>Kamakshi</forenames></author></authors><title>Software Metrics Evaluation Based on Entropy</title><categories>cs.SE</categories><comments>9 pages, 2 figures</comments><journal-ref>Volume 8, pp 20-28, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software engineering activities in the Industry has come a long way with
various improve- ments brought in various stages of the software development
life cycle. The complexity of modern software, the commercial constraints and
the expectation for high quality products demand the accurate fault prediction
based on OO design metrics in the class level in the early stages of software
development. The object oriented class metrics are used as quality predictors
in the entire OO software development life cycle even when a highly iterative,
incremental model or agile software process is employed. Recent research has
shown some of the OO design metrics are useful for predicting fault-proneness
of classes. In this paper the empirical validation of a set of metrics proposed
by Chidamber and Kemerer is performed to assess their ability in predicting the
software quality in terms of fault proneness and degradation. We have also
proposed the design complexity of object-oriented software with Weighted
Methods per Class metric (WMC-CK metric) expressed in terms of Shannon entropy,
and error proneness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3475</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3475</id><created>2010-01-20</created><authors><author><keyname>Niu</keyname><forenames>Bo</forenames></author><author><keyname>Beluri</keyname><forenames>Mihaela C.</forenames></author><author><keyname>Lin</keyname><forenames>Zinan</forenames></author><author><keyname>Chitrapu</keyname><forenames>Prabhakar</forenames></author></authors><title>Relay Assisted Cooperative OSTBC Communication with SNR Imbalance and
  Channel Estimation Errors</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, IEEE 69th Vehicular Technology Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a two-hop relay assisted cooperative Orthogonal Space-Time
Block Codes (OSTBC) transmission scheme is considered for the downlink
communication of a cellular system, where the base station (BS) and the relay
station (RS) cooperate and transmit data to the user equipment (UE) in a
distributed fashion. We analyze the impact of the SNR imbalance between the
BS-UE and RS-UE links, as well as the imperfect channel estimation at the UE
receiver. The performance is analyzed in the presence of Rayleigh flat fading
and our results show that the SNR imbalance does not impact the spatial
diversity order. On the other hand, channel estimation errors have a larger
impact on the system performance. Simulation results are then provided to
confirm the analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3476</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3476</id><created>2010-01-20</created><authors><author><keyname>Shilpa</keyname><forenames>G</forenames></author><author><keyname>Thangaraj</keyname><forenames>Andrew</forenames></author><author><keyname>Bhashyam</keyname><forenames>Srikrishna</forenames></author></authors><title>Dirty Paper Coding using Sign-bit Shaping and LDPC Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dirty paper coding (DPC) refers to methods for pre-subtraction of known
interference at the transmitter of a multiuser communication system. There are
numerous applications for DPC, including coding for broadcast channels.
Recently, lattice-based coding techniques have provided several designs for
DPC. In lattice-based DPC, there are two codes - a convolutional code that
defines a lattice used for shaping and an error correction code used for
channel coding. Several specific designs have been reported in the recent
literature using convolutional and graph-based codes for capacity-approaching
shaping and coding gains. In most of the reported designs, either the encoder
works on a joint trellis of shaping and channel codes or the decoder requires
iterations between the shaping and channel decoders. This results in high
complexity of implementation. In this work, we present a lattice-based DPC
scheme that provides good shaping and coding gains with moderate complexity at
both the encoder and the decoder. We use a convolutional code for sign-bit
shaping, and a low-density parity check (LDPC) code for channel coding. The
crucial idea is the introduction of a one-codeword delay and careful parsing of
the bits at the transmitter, which enable an LDPC decoder to be run first at
the receiver. This provides gains without the need for iterations between the
shaping and channel decoders. Simulation results confirm that at high rates the
proposed DPC method performs close to capacity with moderate complexity. As an
application of the proposed DPC method, we show a design for superposition
coding that provides rates better than time-sharing over a Gaussian broadcast
channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3477</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3477</id><created>2010-01-20</created><authors><author><keyname>Robiah</keyname><forenames>Y.</forenames></author><author><keyname>Rahayu</keyname><forenames>S. Siti</forenames></author><author><keyname>Shahrin</keyname><forenames>S.</forenames></author><author><keyname>Faizal</keyname><forenames>M. A.</forenames></author><author><keyname>Zaki</keyname><forenames>M. Mohd</forenames></author><author><keyname>Marliza</keyname><forenames>R.</forenames></author></authors><title>New Multi-step Worm Attack Model</title><categories>cs.CR</categories><journal-ref>Journal of Computing, Vol. 2, Issue 1, January 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The traditional worms such as Blaster, Code Red, Slammer and Sasser, are
still infecting vulnerable machines on the internet. They will remain as
significant threats due to their fast spreading nature on the internet. Various
traditional worms attack pattern has been analyzed from various logs at
different OSI layers such as victim logs, attacker logs and IDS alert log.
These worms attack pattern can be abstracted to form worms' attack model which
describes the process of worms' infection. For the purpose of this paper, only
Blaster variants were used during the experiment. This paper proposes a
multi-step worm attack model which can be extended into research areas in alert
correlation and computer forensic investigation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3478</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3478</id><created>2010-01-20</created><authors><author><keyname>Kannan</keyname><forenames>S.</forenames></author><author><keyname>Bhaskaran</keyname><forenames>R.</forenames></author></authors><title>Role of Interestingness Measures in CAR Rule Ordering for Associative
  Classifier: An Empirical Approach</title><categories>cs.LG</categories><journal-ref>Journal of Computing, Vol. 2, Issue 1, January 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Associative Classifier is a novel technique which is the integration of
Association Rule Mining and Classification. The difficult task in building
Associative Classifier model is the selection of relevant rules from a large
number of class association rules (CARs). A very popular method of ordering
rules for selection is based on confidence, support and antecedent size (CSA).
Other methods are based on hybrid orderings in which CSA method is combined
with other measures. In the present work, we study the effect of using
different interestingness measures of Association rules in CAR rule ordering
and selection for associative classifier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3479</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3479</id><created>2010-01-20</created><updated>2010-01-23</updated><authors><author><keyname>Stankovic</keyname><forenames>Srdjan</forenames></author><author><keyname>Simic</keyname><forenames>Dejan</forenames></author></authors><title>A Holistic Approach to Securing Web Applications</title><categories>cs.CR</categories><journal-ref>Journal of Computing, Vol. 2, Issue 1, January 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Protection of Web applications is an activity that requires constant
monitoring of security threats as well as looking for solutions in this field.
Since protection has moved from the lower layers of OSI models to the
application layer and having in mind the fact that 75% of all the attacks are
performed at the application layer, special attention should be paid to the
application layer. It is possible to improve protection of Web application on
the level of the system architecture by introducing new components which will
realize protection on higher levels of OSI models. This paper deals with
Intrusion Detection Systems, Intrusion Prevention Systems, Web Application
Firewall and gives a holistic approach to securing Web applications using
aforementioned components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3480</identifier>
 <datestamp>2011-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3480</id><created>2010-01-20</created><authors><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author><author><keyname>Roch</keyname><forenames>Sebastien</forenames></author><author><keyname>Sly</keyname><forenames>Allan</forenames></author></authors><title>On the inference of large phylogenies with long branches: How long is
  too long?</title><categories>math.PR cs.CE cs.DS math.ST q-bio.PE stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work has highlighted deep connections between sequence-length
requirements for high-probability phylogeny reconstruction and the related
problem of the estimation of ancestral sequences. In [Daskalakis et al.'09],
building on the work of [Mossel'04], a tight sequence-length requirement was
obtained for the CFN model. In particular the required sequence length for
high-probability reconstruction was shown to undergo a sharp transition (from
$O(\log n)$ to $\hbox{poly}(n)$, where $n$ is the number of leaves) at the
&quot;critical&quot; branch length $\critmlq$ (if it exists) of the ancestral
reconstruction problem.
  Here we consider the GTR model. For this model, recent results of [Roch'09]
show that the tree can be accurately reconstructed with sequences of length
$O(\log(n))$ when the branch lengths are below $\critksq$, known as the
Kesten-Stigum (KS) bound. Although for the CFN model $\critmlq = \critksq$, it
is known that for the more general GTR models one has $\critmlq \geq \critksq$
with a strict inequality in many cases. Here, we show that this phenomenon also
holds for phylogenetic reconstruction by exhibiting a family of symmetric
models $Q$ and a phylogenetic reconstruction algorithm which recovers the tree
from $O(\log n)$-length sequences for some branch lengths in the range
$(\critksq,\critmlq)$. Second we prove that phylogenetic reconstruction under
GTR models requires a polynomial sequence-length for branch lengths above
$\critmlq$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3481</identifier>
 <datestamp>2010-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3481</id><created>2010-01-20</created><updated>2010-02-03</updated><authors><author><keyname>Vijayasankar</keyname><forenames>U.</forenames></author><author><keyname>Prasadh.</keyname><forenames>S.</forenames></author><author><keyname>Selvakumar</keyname><forenames>A. Arul Lawrence</forenames></author></authors><title>Resolution scalability improvement for JPEG2000 standard color image</title><categories>cs.GR</categories><comments>Removed by arXiv administration. This article was plagiarised from
  http://www.dmi.unict.it/~battiato/download/NSIP_2003_VQ.pdf and other
  locations</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Removed by arXiv administration. This article was plagiarised from
http://www.dmi.unict.it/~battiato/download/NSIP_2003_VQ.pdf and other
locations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3483</identifier>
 <datestamp>2010-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3483</id><created>2010-01-20</created><updated>2010-02-03</updated><authors><author><keyname>Nazer</keyname><forenames>G. Mohammed</forenames></author><author><keyname>Selvakumar</keyname><forenames>A. Arul Lawrence</forenames></author></authors><title>BGP Converges to stable solution in Interdomain routing</title><categories>cs.NI</categories><comments>Withdrawn by arXiv administration. This article was plagiarised
  directly from http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=5061961
  , which appeared in the conference INFOCOM 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Withdrawn by arXiv administration. This article was plagiarised directly from
http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=5061961 , which
appeared in the conference INFOCOM 2009.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3484</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3484</id><created>2010-01-20</created><authors><author><keyname>Filote</keyname><forenames>C.</forenames></author><author><keyname>Nemtoi</keyname><forenames>G.</forenames></author></authors><title>Information criminality - a phenomenon met within the informatics field</title><categories>cs.CY</categories><journal-ref>Journal of Computing, Vol. 2, Issue 1, January 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The phenomenon described as &quot;information criminality&quot; has taken significant
proportions in the last decade, fact that carried out towards an international
legislative frame, by implementing judicial forms, which might stop its
occurrences. As matter of fact, the information criminality represents an
information technology aiming towards fraud and prejudicing the users of
informational data, by various means to infringement of the law. In this way,
some international organizations have dealt with performing a legislative
framework, able to punish the phenomenon of information criminality and
implicitly to protect the users of computers. The transnational expansions,
extremely fast as concerns the computer networks, and extending the access to
these networks, by means of mobile telephony, have brought the increasing of
these systems' vulnerability and the creating of opportunities of breaking the
law. Considering these aspects, the world legislation is continuously changing,
due to a more and more accelerated development of the information technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3485</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3485</id><created>2010-01-20</created><authors><author><keyname>Chang</keyname><forenames>Weiling</forenames></author><author><keyname>Fang</keyname><forenames>Binxing</forenames></author><author><keyname>Yun</keyname><forenames>Xiaochun</forenames></author><author><keyname>Wang</keyname><forenames>Shupeng</forenames></author><author><keyname>Yu</keyname><forenames>Xiangzhan</forenames></author></authors><title>Randomness Testing of Compressed Data</title><categories>cs.CC</categories><journal-ref>Journal of Computing, Vol. 2, Issue 1, January 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random Number Generators play a critical role in a number of important
applications. In practice, statistical testing is employed to gather evidence
that a generator indeed produces numbers that appear to be random. In this
paper, we reports on the studies that were conducted on the compressed data
using 8 compression algorithms or compressors. The test results suggest that
the output of compression algorithms or compressors has bad randomness, the
compression algorithms or compressors are not suitable as random number
generator. We also found that, for the same compression algorithm, there exists
positive correlation relationship between compression ratio and randomness,
increasing the compression ratio increases randomness of compressed data. As
time permits, additional randomness testing efforts will be conducted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3486</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3486</id><created>2010-01-20</created><authors><author><keyname>Shayevitz</keyname><forenames>Ofer</forenames></author></authors><title>A Symbolic Dynamical System Approach to Lossy Source Coding with
  Feedforward</title><categories>cs.IT math.IT</categories><comments>10 pages, 2 figures, to appear in the Data Compression Conference
  (DCC), March 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that modeling an information source via a symbolic dynamical
system evolving over the unit interval, leads to a natural lossless compression
scheme attaining the entropy rate of the source, under general conditions. We
extend this notion to the lossy compression regime assuming a feedforward link
is available, by modeling a source via a two-dimensional symbolic dynamical
system where one component corresponds to the compressed signal, and the other
essentially corresponds to the feedforward signal. For memoryless sources and
an arbitrary bounded distortion measure, we show this approach leads to a
family of simple deterministic compression schemes that attain the
rate-distortion function of the source. The construction is dual to a recent
optimal scheme for channel coding with feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3487</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3487</id><created>2010-01-20</created><authors><author><keyname>Kent</keyname><forenames>Chow Kok</forenames></author><author><keyname>Salim</keyname><forenames>Naomie</forenames></author></authors><title>Features Based Text Similarity Detection</title><categories>cs.CV</categories><journal-ref>Journal of Computing, Vol. 2, Issue 1, January 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the Internet help us cross cultural border by providing different
information, plagiarism issue is bound to arise. As a result, plagiarism
detection becomes more demanding in overcoming this issue. Different plagiarism
detection tools have been developed based on various detection techniques.
Nowadays, fingerprint matching technique plays an important role in those
detection tools. However, in handling some large content articles, there are
some weaknesses in fingerprint matching technique especially in space and time
consumption issue. In this paper, we propose a new approach to detect
plagiarism which integrates the use of fingerprint matching technique with four
key features to assist in the detection process. These proposed features are
capable to choose the main point or key sentence in the articles to be
compared. Those selected sentence will be undergo the fingerprint matching
process in order to detect the similarity between the sentences. Hence, time
and space usage for the comparison process is reduced without affecting the
effectiveness of the plagiarism detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3488</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3488</id><created>2010-01-20</created><authors><author><keyname>Gautam</keyname><forenames>Pratima</forenames></author><author><keyname>Khare</keyname><forenames>Neelu</forenames></author><author><keyname>Pardasani</keyname><forenames>K. R.</forenames></author></authors><title>A Model for Mining Multilevel Fuzzy Association Rule in Database</title><categories>cs.DB</categories><journal-ref>Journal of Computing, Vol. 2, Issue 1, January 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of developing models and algorithms for multilevel association
mining pose for new challenges for mathematics and computer science. These
problems become more challenging, when some form of uncertainty like fuzziness
is present in data or relationships in data. This paper proposes a multilevel
fuzzy association rule mining models for extracting knowledge implicit in
transactions database with different support at each level. The proposed
algorithm adopts a top-down progressively deepening approach to derive large
itemsets. This approach incorporates fuzzy boundaries instead of sharp boundary
intervals. An example is also given to demonstrate that the proposed mining
algorithm can derive the multiple-level association rules under different
supports in a simple and effective manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3489</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3489</id><created>2010-01-20</created><authors><author><keyname>Plakalovic</keyname><forenames>D.</forenames></author><author><keyname>Simic</keyname><forenames>D.</forenames></author></authors><title>Applying MVC and PAC patterns in mobile applications</title><categories>cs.SE</categories><journal-ref>Journal of Computing, Vol. 2, Issue 1, January 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Additional requirements are set for mobile applications in relation to
applications for desktop computers. These requirements primarily concern the
support to different platforms on which such applications are performed, as
well as the requirement for providing more modalities of input/output
interaction. These requirements have influence on the user interface and
therefore it is needed to consider the usability of MVC (Model-View-Controller)
and PAC (Presentation-Abstraction-Control) design patterns for the separation
of the user interface tasks from the business logic, specifically in mobile
applications. One of the questions is making certain choices of design patterns
for certain classes of mobile applications. When using these patterns the
possibilities of user interface automatic transformation should be kept in
mind. Although the MVC design pattern is widely used in mobile applications, it
is not universal, especially in cases where there are requirements for
heterogeneous multi-modal input-output interactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3491</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3491</id><created>2010-01-20</created><authors><author><keyname>Sujin</keyname><forenames>P. R.</forenames></author><author><keyname>Prakash</keyname><forenames>T. Ruban Deva</forenames></author><author><keyname>Linda</keyname><forenames>M. Mary</forenames></author></authors><title>Particle Swarm Optimization Based Reactive Power Optimization</title><categories>cs.NE</categories><journal-ref>Journal of Computing, Vol. 2, Issue 1, January 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reactive power plays an important role in supporting the real power transfer
by maintaining voltage stability and system reliability. It is a critical
element for a transmission operator to ensure the reliability of an electric
system while minimizing the cost associated with it. The traditional objectives
of reactive power dispatch are focused on the technical side of reactive
support such as minimization of transmission losses. Reactive power cost
compensation to a generator is based on the incurred cost of its reactive power
contribution less the cost of its obligation to support the active power
delivery. In this paper an efficient Particle Swarm Optimization (PSO) based
reactive power optimization approach is presented. The optimal reactive power
dispatch problem is a nonlinear optimization problem with several constraints.
The objective of the proposed PSO is to minimize the total support cost from
generators and reactive compensators. It is achieved by maintaining the whole
system power loss as minimum thereby reducing cost allocation. The purpose of
reactive power dispatch is to determine the proper amount and location of
reactive support. Reactive Optimal Power Flow (ROPF) formulation is developed
as an analysis tool and the validity of proposed method is examined using an
IEEE-14 bus system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3493</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3493</id><created>2010-01-20</created><authors><author><keyname>Ojha</keyname><forenames>A. K.</forenames></author><author><keyname>Biswal</keyname><forenames>K. K.</forenames></author></authors><title>Posynomial Geometric Programming Problems with Multiple Parameters</title><categories>cs.DS</categories><journal-ref>Journal of Computing, Vol. 2, Issue 1, January 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Geometric programming problem is a powerful tool for solving some special
type non-linear programming problems. It has a wide range of applications in
optimization and engineering for solving some complex optimization problems.
Many applications of geometric programming are on engineering design problems
where parameters are estimated using geometric programming. When the parameters
in the problems are imprecise, the calculated objective value should be
imprecise as well. In this paper we have developed a method to solve geometric
programming problems where the exponent of the variables in the objective
function, cost coefficients and right hand side are multiple parameters. The
equivalent mathematical programming problems are formulated to find their
corresponding value of the objective function based on the duality theorem. By
applying a variable separable technique the multi-choice mathematical
programming problem is transformed into multiple one level geometric
programming problem which produces multiple objective values that helps
engineers to handle more realistic engineering design problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3494</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3494</id><created>2010-01-20</created><authors><author><keyname>Feizi-Derakhshi</keyname><forenames>Mohammad-Reza</forenames></author><author><keyname>Asil</keyname><forenames>Hasan</forenames></author><author><keyname>Asil</keyname><forenames>Amir</forenames></author></authors><title>Proposing a New Method for Query Processing Adaption in DataBase</title><categories>cs.DB</categories><journal-ref>Journal of Computing, Vol. 2, Issue 1, January 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a multi agent system by compiling two technologies, query
processing optimization and agents which contains features of personalized
queries and adaption with changing of requirements. This system uses a new
algorithm based on modeling of users' long-term requirements and also GA to
gather users' query data. Experimented Result shows more adaption capability
for presented algorithm in comparison with classic algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3495</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3495</id><created>2010-01-20</created><authors><author><keyname>Mates</keyname><forenames>D.</forenames></author><author><keyname>Iancu</keyname><forenames>E.</forenames></author><author><keyname>Bostan</keyname><forenames>I.</forenames></author><author><keyname>Grosu</keyname><forenames>V.</forenames></author></authors><title>Expert System Models in the Companies' Financial and Accounting Domain</title><categories>cs.CE</categories><journal-ref>Journal of Computing, Vol. 2, Issue 1, January 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present paper is based on studying, analyzing and implementing the expert
systems in the financial and accounting domain of the companies, describing the
use method of the informational systems that can be used in the multi-national
companies, public interest institutions, and medium and small dimension
economical entities, in order to optimize the managerial decisions and render
efficient the financial-accounting functionality. The purpose of this paper is
aimed to identifying the economical exigencies of the entities, based on the
already used accounting instruments and the management software that could
consent the control of the economical processes and patrimonial assets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3496</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3496</id><created>2010-01-20</created><authors><author><keyname>Hussein</keyname><forenames>Jamal A.</forenames></author></authors><title>Spatial Domain Watermarking Scheme for Colored Images Based on
  Log-average Luminance</title><categories>cs.GR</categories><journal-ref>Journal of Computing, Vol. 2, Issue 1, January 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a new watermarking scheme is presented based on log-average
luminance. A colored-image is divided into blocks after converting the RGB
colored image to YCbCr color space. A monochrome image of 1024 bytes is used as
the watermark. To embed the watermark, 16 blocks of size 8X8 are selected and
used to embed the watermark image into the original image. The selected blocks
are chosen spirally (beginning form the center of the image) among the blocks
that have log-average luminance higher than or equal the log-average luminance
of the entire image. Each byte of the monochrome watermark is added by updating
a luminance value of a pixel of the image. If the byte of the watermark image
represented white color (255) a value &lt;alpha&gt; is added to the image pixel
luminance value, if it is black (0) the &lt;alpha&gt; is subtracted from the
luminance value. To extract the watermark, the selected blocks are chosen as
the above, if the difference between the luminance value of the watermarked
image pixel and the original image pixel is greater than 0, the watermark pixel
is supposed to be white, otherwise it supposed to be black. Experimental
results show that the proposed scheme is efficient against changing the
watermarked image to grayscale, image cropping, and JPEG compression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3497</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3497</id><created>2010-01-20</created><updated>2010-03-29</updated><authors><author><keyname>Hussain</keyname><forenames>Shahid</forenames></author><author><keyname>Saqib</keyname><forenames>Sheikh Muhammad</forenames></author><author><keyname>Ahmad</keyname><forenames>Bashir</forenames></author><author><keyname>Ahmad</keyname><forenames>Shakeel</forenames></author></authors><title>Mapping of SOA and RUP: DOA as Case Study</title><categories>cs.SE</categories><comments>Journal of Computing, Vol. 2, Issue 1, January 2010,
  https://sites.google.com/site/journalofcomputing/</comments><journal-ref>Journal of Computing, Vol. 2, Issue 1, January 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  SOA (Service Oriented Architecture) is a new trend towards increasing the
profit margins in an organization due to incorporating business services to
business practices. Rational Unified Process (RUP) is a unified method planning
form for large business applications that provides a language for describing
method content and processes. The well defined mapping of SOA and RUP leads to
successful completion of RUP software projects to provide services to their
users. DOA (Digital Office Assistant) is a multi user SOA type application that
provides appropriate viewer for each user to assist him through services. In
this paper authors proposed the mapping strategy of SOA with RUP by considering
DOA as case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3498</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3498</id><created>2010-01-20</created><authors><author><keyname>Anandhavalli</keyname><forenames>M.</forenames></author><author><keyname>Ghose</keyname><forenames>M. K.</forenames></author><author><keyname>Gauthaman</keyname><forenames>K.</forenames></author></authors><title>Interestingness Measure for Mining Spatial Gene Expression Data using
  Association Rule</title><categories>cs.DB q-bio.GN q-bio.QM</categories><journal-ref>Journal of Computing, Vol. 2, Issue 1, January 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The search for interesting association rules is an important topic in
knowledge discovery in spatial gene expression databases. The set of admissible
rules for the selected support and confidence thresholds can easily be
extracted by algorithms based on support and confidence, such as Apriori.
However, they may produce a large number of rules, many of them are
uninteresting. The challenge in association rule mining (ARM) essentially
becomes one of determining which rules are the most interesting. Association
rule interestingness measures are used to help select and rank association rule
patterns. Besides support and confidence, there are other interestingness
measures, which include generality reliability, peculiarity, novelty,
surprisingness, utility, and applicability. In this paper, the application of
the interesting measures entropy and variance for association pattern discovery
from spatial gene expression data has been studied. In this study the fast
mining algorithm has been used which produce candidate itemsets and it spends
less time for calculating k-supports of the itemsets with the Boolean matrix
pruned, and it scans the database only once and needs less memory space.
Experimental results show that using entropy as the measure of interest for the
spatial gene expression data has more diverse and interesting rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3500</identifier>
 <datestamp>2010-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3500</id><created>2010-01-20</created><updated>2010-04-26</updated><authors><author><keyname>Sharma</keyname><forenames>Nitin</forenames></author><author><keyname>Shakya</keyname><forenames>Madhvi</forenames></author></authors><title>Mathematical Modeling to Study the Dynamics of A Diatomic Molecule N2 in
  Water</title><categories>cs.CE physics.comp-ph</categories><comments>https://sites.google.com/site/journalofcomputing</comments><journal-ref>Journal of Computing, Vol. 2, Issue 1, January 2010, 115-120</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present work an attempt has been made to study the dynamics of a
diatomic molecule N2 in water. The proposed model consists of Langevin
stochastic differential equation whose solution is obtained through Euler's
method. The proposed work has been concluded by studying the behavior of
statistical parameters like variance in position, variance in velocity and
covariance between position and velocity. This model incorporates the important
parameters like acceleration, intermolecular force, frictional force and random
force.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3502</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3502</id><created>2010-01-20</created><authors><author><keyname>Alanazi</keyname><forenames>Hamdan. O.</forenames></author><author><keyname>Zaidan</keyname><forenames>B. B</forenames></author><author><keyname>Zaidan</keyname><forenames>A. A</forenames></author></authors><title>3D Skull Recognition Using 3D Matching Technique</title><categories>cs.CV</categories><journal-ref>Journal of Computing, Vol. 2, Issue 1, January 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Biometrics has become a &quot;hot&quot; area. Governments are funding research programs
focused on biometrics. In this paper the problem of person recognition and
verification based on a different biometric application has been addressed. The
system is based on the 3DSkull recognition using 3D matching technique, in fact
this paper present several bio-metric approaches in order of assign the weak
point in term of used the biometric from the authorize person and insure the
person who access the data is the real person. The feature of the simulate
system shows the capability of using 3D matching system as an efficient way to
identify the person through his or her skull by match it with database, this
technique grantee fast processing with optimizing the false positive and
negative as well .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3503</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3503</id><created>2010-01-20</created><authors><author><keyname>Rajendran</keyname><forenames>P.</forenames></author><author><keyname>Madheswaran</keyname><forenames>M.</forenames></author></authors><title>Hybrid Medical Image Classification Using Association Rule Mining with
  Decision Tree Algorithm</title><categories>cs.CV</categories><journal-ref>Journal of Computing, Vol. 2, Issue 1, January 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main focus of image mining in the proposed method is concerned with the
classification of brain tumor in the CT scan brain images. The major steps
involved in the system are: pre-processing, feature extraction, association
rule mining and hybrid classifier. The pre-processing step has been done using
the median filtering process and edge features have been extracted using canny
edge detection technique. The two image mining approaches with a hybrid manner
have been proposed in this paper. The frequent patterns from the CT scan images
are generated by frequent pattern tree (FP-Tree) algorithm that mines the
association rules. The decision tree method has been used to classify the
medical images for diagnosis. This system enhances the classification process
to be more accurate. The hybrid method improves the efficiency of the proposed
method than the traditional image mining methods. The experimental result on
prediagnosed database of brain images showed 97% sensitivity and 95% accuracy
respectively. The physicians can make use of this accurate decision tree
classification phase for classifying the brain images into normal, benign and
malignant for effective medical diagnosis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3504</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3504</id><created>2010-01-20</created><authors><author><keyname>Kadampur</keyname><forenames>Mohammad Ali</forenames></author><author><keyname>N</keyname><forenames>Somayajulu D. V. L.</forenames></author></authors><title>A Noise Addition Scheme in Decision Tree for Privacy Preserving Data
  Mining</title><categories>cs.CR</categories><journal-ref>Journal of Computing, Vol. 2, Issue 1, January 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data mining deals with automatic extraction of previously unknown patterns
from large amounts of data. Organizations all over the world handle large
amounts of data and are dependent on mining gigantic data sets for expansion of
their enterprises. These data sets typically contain sensitive individual
information, which consequently get exposed to the other parties. Though we
cannot deny the benefits of knowledge discovery that comes through data mining,
we should also ensure that data privacy is maintained in the event of data
mining. Privacy preserving data mining is a specialized activity in which the
data privacy is ensured during data mining. Data privacy is as important as the
extracted knowledge and efforts that guarantee data privacy during data mining
are encouraged. In this paper we propose a strategy that protects the data
privacy during decision tree analysis of data mining process. We propose to add
specific noise to the numeric attributes after exploring the decision tree of
the original data. The obfuscated data then is presented to the second party
for decision tree analysis. The decision tree obtained on the original data and
the obfuscated data are similar but by using our method the data proper is not
revealed to the second party during the mining process and hence the privacy
will be preserved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3533</identifier>
 <datestamp>2010-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3533</id><created>2010-01-20</created><updated>2010-02-15</updated><authors><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author><author><keyname>Abhijith</keyname></author><author><keyname>Sooda</keyname><forenames>Kavitha</forenames></author></authors><title>Transformation of Networks through Cognitive Approaches</title><categories>cs.NI</categories><comments>8 pages, 5 figures</comments><journal-ref>Journal of Research &amp; Industry, Volume 1, Issue 1, pp 1-6, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The growth in data traffic and the increased demand for quality of service
had generated a large demand for network systems to be more efficient. The
introduction of improved routing systems to meet the increasing demand and
varied protocols to accommodate various scales of challenges in network
efficiency had further complicated the operations. This means that a better
mode of intelligence has to be infused into networking for smoother operations
and better autonomic features. Cognitive networks are defined and analyzed in
this angle. They are identified to have the potential to deal with the future
user related quality and efficiency of service at optimized levels. The
cognitive elements of a system like perception, learning, planning, reasoning
and decision forming can enable the systems to be more aware of their
environment and offer better services. These approaches are expected to
transform the mode of operation of future networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3539</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3539</id><created>2010-01-20</created><authors><author><keyname>Vaidehi</keyname><forenames>M.</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author></authors><title>Multicore Applications in Real Time Systems</title><categories>cs.SE</categories><comments>6 pages, 4 Figures</comments><journal-ref>Journal of Research &amp; Industry, Volume 1, Issue 1, pp 30-35, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Microprocessor roadmaps clearly show a trend towards multiple core CPUs.
Modern operating systems already make use of these CPU architectures by
distributing tasks between processing cores thereby increasing system
performance. This review article highlights a brief introduction of what a
multicore system is, the various methods adopted to program these systems and
also the industrial application of these high speed systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3550</identifier>
 <datestamp>2010-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3550</id><created>2010-01-20</created><updated>2010-10-15</updated><authors><author><keyname>Fagnani</keyname><forenames>Fabio</forenames></author><author><keyname>Fosson</keyname><forenames>Sophie</forenames></author></authors><title>Deconvolution of linear systems with quantized input: an information
  theoretic viewpoint</title><categories>cs.IT math.DS math.IT</categories><comments>5 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In spite of the huge literature on deconvolution problems, very little is
done for hybrid contexts where signals are quantized. In this paper we
undertake an information theoretic approach to the deconvolution problem of a
simple integrator with quantized binary input and sampled noisy output. We
recast it into a decoding problem and we propose and analyze (theoretically and
numerically) some low complexity on-line algorithms to achieve deconvolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3552</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3552</id><created>2010-01-20</created><authors><author><keyname>Suma</keyname><forenames>V.</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author></authors><title>Effective Defect Prevention Approach in Software Process for Achieving
  Better Quality Levels</title><categories>cs.SE</categories><comments>5 pages, 1 figure</comments><journal-ref>ICSE, Volume 42, pp 258-262, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Defect prevention is the most vital but habitually neglected facet of
software quality assurance in any project. If functional at all stages of
software development, it can condense the time, overheads and wherewithal
entailed to engineer a high quality product. The key challenge of an IT
industry is to engineer a software product with minimum post deployment
defects. This effort is an analysis based on data obtained for five selected
projects from leading software companies of varying software production
competence. The main aim of this paper is to provide information on various
methods and practices supporting defect detection and prevention leading to
thriving software generation. The defect prevention technique unearths 99% of
defects. Inspection is found to be an essential technique in generating ideal
software generation in factories through enhanced methodologies of abetted and
unaided inspection schedules. On an average 13 % to 15% of inspection and 25% -
30% of testing out of whole project effort time is required for 99% - 99.75% of
defect elimination. A comparison of the end results for the five selected
projects between the companies is also brought about throwing light on the
possibility of a particular company to position itself with an appropriate
complementary ratio of inspection testing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3555</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3555</id><created>2010-01-20</created><authors><author><keyname>Selvarani</keyname><forenames>R.</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author><author><keyname>Prasad</keyname><forenames>V. Kamakshi</forenames></author></authors><title>Estimation of Defect proneness Using Design complexity Measurements in
  Object- Oriented Software</title><categories>cs.SE</categories><comments>5 pages, 1 figure</comments><journal-ref>ICCDA, ICSPS, IEEE Computer Society Press, pp 766-770, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software engineering is continuously facing the challenges of growing
complexity of software packages and increased level of data on defects and
drawbacks from software production process. This makes a clarion call for
inventions and methods which can enable a more reusable, reliable, easily
maintainable and high quality software systems with deeper control on software
generation process. Quality and productivity are indeed the two most important
parameters for controlling any industrial process. Implementation of a
successful control system requires some means of measurement. Software metrics
play an important role in the management aspects of the software development
process such as better planning, assessment of improvements, resource
allocation and reduction of unpredictability. The process involving early
detection of potential problems, productivity evaluation and evaluating
external quality factors such as reusability, maintainability, defect proneness
and complexity are of utmost importance. Here we discuss the application of CK
metrics and estimation model to predict the external quality parameters for
optimizing the design process and production process for desired levels of
quality. Estimation of defect-proneness in object-oriented system at design
level is developed using a novel methodology where models of relationship
between CK metrics and defect-proneness index is achieved. A multifunctional
estimation approach captures the correlation between CK metrics and defect
proneness level of software modules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3593</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3593</id><created>2010-01-20</created><updated>2010-11-30</updated><authors><author><keyname>Cheong</keyname><forenames>Otfried</forenames><affiliation>KAIST CS</affiliation></author><author><keyname>Everett</keyname><forenames>Hazel</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Glisse</keyname><forenames>Marc</forenames><affiliation>INRIA Sophia Antipolis / INRIA Saclay - Ile de France</affiliation></author><author><keyname>Gudmundsson</keyname><forenames>Joachim</forenames><affiliation>NICTA</affiliation></author><author><keyname>Hornus</keyname><forenames>Samuel</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Lazard</keyname><forenames>Sylvain</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Lee</keyname><forenames>Mira</forenames><affiliation>KAIST CS</affiliation></author><author><keyname>Na</keyname><forenames>Hyeon-Suk</forenames></author></authors><title>Farthest-Polygon Voronoi Diagrams</title><categories>cs.CG</categories><proxy>ccsd</proxy><journal-ref>Computational Geometry (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a family of k disjoint connected polygonal sites in general position
and of total complexity n, we consider the farthest-site Voronoi diagram of
these sites, where the distance to a site is the distance to a closest point on
it. We show that the complexity of this diagram is O(n), and give an O(n log^3
n) time algorithm to compute it. We also prove a number of structural
properties of this diagram. In particular, a Voronoi region may consist of k-1
connected components, but if one component is bounded, then it is equal to the
entire region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3604</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3604</id><created>2010-01-20</created><authors><author><keyname>Apel</keyname><forenames>Sven</forenames></author><author><keyname>Kaestner</keyname><forenames>Christian</forenames></author><author><keyname>Groesslinger</keyname><forenames>Armin</forenames></author><author><keyname>Lengauer</keyname><forenames>Christian</forenames></author></authors><title>Type-Safe Feature-Oriented Product Lines</title><categories>cs.SE cs.PL</categories><comments>Technical Report of the University of Passau, Germany</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A feature-oriented product line is a family of programs that share a common
set of features. A feature implements a stakeholder's requirement, represents a
design decision and configuration option and, when added to a program, involves
the introduction of new structures, such as classes and methods, and the
refinement of existing ones, such as extending methods. With feature-oriented
decomposition, programs can be generated, solely on the basis of a user's
selection of features, by the composition of the corresponding feature code. A
key challenge of feature-oriented product line engineering is how to guarantee
the correctness of an entire feature-oriented product line, i.e., of all of the
member programs generated from different combinations of features. As the
number of valid feature combinations grows progressively with the number of
features, it is not feasible to check all individual programs. The only
feasible approach is to have a type system check the entire code base of the
feature-oriented product line. We have developed such a type system on the
basis of a formal model of a feature-oriented Java-like language. We
demonstrate that the type system ensures that every valid program of a
feature-oriented product line is well-typed and that the type system is
complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3661</identifier>
 <datestamp>2012-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3661</id><created>2010-01-20</created><updated>2012-11-03</updated><authors><author><keyname>Daniely</keyname><forenames>Amit</forenames></author><author><keyname>Linial</keyname><forenames>Nathan</forenames></author></authors><title>Tight products and Expansion</title><categories>cs.DM</categories><journal-ref>J. Graph Theory, (2012) 69, 426 - 440</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study a new product of graphs called {\em tight product}. A
graph $H$ is said to be a tight product of two (undirected multi) graphs $G_1$
and $G_2$, if $V(H)=V(G_1)\times V(G_2)$ and both projection maps $V(H)\to
V(G_1)$ and $V(H)\to V(G_2)$ are covering maps. It is not a priori clear when
two given graphs have a tight product (in fact, it is $NP$-hard to decide). We
investigate the conditions under which this is possible. This perspective
yields a new characterization of class-1 $(2k+1)$-regular graphs. We also
obtain a new model of random $d$-regular graphs whose second eigenvalue is
almost surely at most $O(d^{3/4})$. This construction resembles random graph
lifts, but requires fewer random bits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3663</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3663</id><created>2010-01-20</created><authors><author><keyname>Zhang</keyname><forenames>Jian</forenames></author><author><keyname>Chen</keyname><forenames>Chaomei</forenames></author></authors><title>Collaboration in an Open Data eScience: A Case Study of Sloan Digital
  Sky Survey</title><categories>cs.DL</categories><comments>iConference 2010</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current science and technology has produced more and more publically
accessible scientific data. However, little is known about how the open data
trend impacts a scientific community, specifically in terms of its
collaboration behaviors. This paper aims to enhance our understanding of the
dynamics of scientific collaboration in the open data eScience environment via
a case study of co-author networks of an active and highly cited open data
project, called Sloan Digital Sky Survey. We visualized the co-authoring
networks and measured their properties over time at three levels: author,
institution, and country levels. We compared these measurements to a random
network model and also compared results across the three levels. The study
found that 1) the collaboration networks of the SDSS community transformed from
random networks to small-world networks; 2) the number of author-level
collaboration instances has not changed much over time, while the number of
collaboration instances at the other two levels has increased over time; 3)
pairwise institutional collaboration become common in recent years. The open
data trend may have both positive and negative impacts on scientific
collaboration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3673</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3673</id><created>2010-01-20</created><authors><author><keyname>Whitbeck</keyname><forenames>John</forenames></author><author><keyname>de Amorim</keyname><forenames>Marcelo Dias</forenames></author><author><keyname>Conan</keyname><forenames>Vania</forenames></author></authors><title>Plausible Mobility: Inferring Movement from Contacts</title><categories>cs.NI</categories><comments>8 pages, 8 figures, 1 table</comments><acm-class>C.2.1; I.6.m</acm-class><journal-ref>In Proceedings: ACM Workshop on Mobile Opportunistic Networking
  (Mobiopp 2010) - Pisa, Italy - February 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the difficult question of inferring plausible node mobility based
only on information from wireless contact traces. Working with mobility
information allows richer protocol simulations, particularly in dense networks,
but requires complex set-ups to measure, whereas contact information is easier
to measure but only allows for simplistic simulation models. In a contact trace
a lot of node movement information is irretrievably lost so the original
positions and velocities are in general out of reach. We propose a fast
heuristic algorithm, inspired by dynamic force-based graph drawing, capable of
inferring a plausible movement from any contact trace, and evaluate it on both
synthetic and real-life contact traces. Our results reveal that (i) the quality
of the inferred mobility is directly linked to the precision of the measured
contact trace, and (ii) the simple addition of appropriate anticipation forces
between nodes leads to an accurate inferred mobility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3689</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3689</id><created>2010-01-20</created><authors><author><keyname>Sardari</keyname><forenames>Mohsen</forenames></author><author><keyname>Hendessi</keyname><forenames>Faramarz</forenames></author><author><keyname>Fekri</keyname><forenames>Faramarz</forenames></author></authors><title>Infocast: A New Paradigm for Collaborative Content Distribution from
  Roadside Units to Vehicular Networks Using Rateless Codes</title><categories>cs.NI</categories><journal-ref>Proc. 6th Annual IEEE Communications Society Conference on Sensor,
  Mesh and Ad Hoc Communications and Networks SECON '09, 2009, 1-9</journal-ref><doi>10.1109/SAHCN.2009.5168939</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the problem of distributing a large amount of bulk
data to a sparse vehicular network from roadside infostations, using efficient
vehicle-to-vehicle collaboration. Due to the highly dynamic nature of the
underlying vehicular network topology, we depart from architectures requiring
centralized coordination, reliable MAC scheduling, or global network state
knowledge, and instead adopt a distributed paradigm with simple protocols. In
other words, we investigate the problem of reliable dissemination from multiple
sources when each node in the network shares a limited amount of its resources
for cooperating with others. By using \emph{rateless} coding at the Road Side
Unit (RSU) and using vehicles as data carriers, we describe an efficient way to
achieve reliable dissemination to all nodes (even disconnected clusters in the
network). In the nutshell, we explore vehicles as mobile storage devices. We
then develop a method to keep the density of the rateless codes packets as a
function of distance from the RSU at the desired level set for the target
decoding distance. We investigate various tradeoffs involving buffer size,
maximum capacity, and the mobility parameter of the vehicles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3697</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3697</id><created>2010-01-20</created><authors><author><keyname>Pinto</keyname><forenames>Pedro C.</forenames></author><author><keyname>Barros</keyname><forenames>Joao</forenames></author><author><keyname>Win</keyname><forenames>Moe Z.</forenames></author></authors><title>Secure Communication in Stochastic Wireless Networks</title><categories>cs.IT cs.CR math.IT math.PR</categories><comments>Submitted for journal publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information-theoretic security -- widely accepted as the strictest notion of
security -- relies on channel coding techniques that exploit the inherent
randomness of the propagation channels to significantly strengthen the security
of digital communications systems. Motivated by recent developments in the
field, this paper aims at a characterization of the fundamental secrecy limits
of wireless networks. Based on a general model in which legitimate nodes and
potential eavesdroppers are randomly scattered in space, the intrinsically
secure communications graph (iS-graph) is defined from the point of view of
information-theoretic security. Conclusive results are provided for the local
connectivity of the Poisson iS-graph, in terms of node degrees and isolation
probabilities. It is shown how the secure connectivity of the network varies
with the wireless propagation effects, the secrecy rate threshold of each link,
and the noise powers of legitimate nodes and eavesdroppers. Sectorized
transmission and eavesdropper neutralization are explored as viable strategies
for improving the secure connectivity. Lastly, the maximum secrecy rate between
a node and each of its neighbours is characterized, and the case of colluding
eavesdroppers is studied. The results help clarify how the spatial density of
eavesdroppers can compromise the intrinsic security of wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3705</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3705</id><created>2010-01-20</created><updated>2011-03-04</updated><authors><author><keyname>Watanabe</keyname><forenames>Shun</forenames></author><author><keyname>Oohama</keyname><forenames>Yasutada</forenames></author></authors><title>Secret Key Agreement from Correlated Gaussian Sources by Rate Limited
  Public Communication</title><categories>cs.IT math.IT</categories><comments>9 pages, no figure, Version 2 is a published version. The results are
  not changed from version 1. Explanations are polished</comments><journal-ref>IEICE Trans. Fundamentals, vol. 93, no. 11, pp. 1976-1983,
  November 2010</journal-ref><doi>10.1587/transfun.E93.A.1976</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the secret key agreement from correlated Gaussian sources in
which the legitimate parties can use the public communication with limited
rate. For the class of protocols with the one-way public communication, we show
a closed form expression of the optimal trade-off between the rate of key
generation and the rate of the public communication. Our results clarify an
essential difference between the key agreement from discrete sources and that
from continuous sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3708</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3708</id><created>2010-01-20</created><updated>2010-01-22</updated><authors><author><keyname>Saffar</keyname><forenames>Hamidreza Ebrahimzadeh</forenames></author><author><keyname>Mitran</keyname><forenames>Patrick</forenames></author></authors><title>Capacity Bounds and Lattice Coding for the Star Relay Network</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to IEEE ISIT, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A half-duplex wireless network with 6 lateral nodes, 3 transmitters and 3
receivers, and a central relay is considered. The transmitters wish to send
information to their corresponding receivers via a two phase communication
protocol. The receivers decode their desired messages by using side information
and the signals received from the relay. We derive an outer bound on the
capacity region of any two phase protocol as well as 3 achievable regions by
employing different relaying strategies. In particular, we combine physical and
network layer coding to take advantage of the interference at the relay, using,
for example, lattice-based codes. We then specialize our results to the
exchange rate. It is shown that for any snr, we can achieve within 0.5 bit of
the upper bound by lattice coding and within 0.34 bit, if we take the best of
the 3 strategies. Also, for high snr, lattice coding is within log(3)/4 ~ 0.4
bit of the upper bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3713</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3713</id><created>2010-01-20</created><authors><author><keyname>Reznik</keyname><forenames>Yuriy A.</forenames></author></authors><title>On Fast Algorithm for Computing Even-Length DCT</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study recursive algorithm for computing DCT of lengths $N=q 2^m$ ($m,q \in
\mathbb{N}$, $q$ is odd) due to C.W.Kok. We show that this algorithm has the
same multiplicative complexity as theoretically achievable by the prime factor
decomposition, when $m \leqslant 2$. We also show that C.W.Kok's factorization
allows a simple conversion to a scaled form. We analyze complexity of such a
scaled factorization, and show that for some lengths it achieves lower
multiplicative complexity than one of known prime factor-based scaled
transforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3714</identifier>
 <datestamp>2010-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3714</id><created>2010-01-20</created><updated>2010-04-24</updated><authors><author><keyname>Yao</keyname><forenames>Hongyi</forenames></author><author><keyname>Silva</keyname><forenames>Danilo</forenames></author><author><keyname>Jaggi</keyname><forenames>Sidharth</forenames></author><author><keyname>Langberg</keyname><forenames>Michael</forenames></author></authors><title>Network Codes Resilient to Jamming and Eavesdropping</title><categories>cs.NI</categories><comments>6 pages, to appear at IEEE NetCod 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of communicating information over a network secretly
and reliably in the presence of a hidden adversary who can eavesdrop and inject
malicious errors. We provide polynomial-time, rate-optimal distributed network
codes for this scenario, improving on the rates achievable in previous work.
Our main contribution shows that as long as the sum of the adversary's jamming
rate Zo and his eavesdropping rate Zi is less than the network capacity C,
(i.e., Zo+Zi&lt;C), our codes can communicate (with vanishingly small error
probability) a single bit correctly and without leaking any information to the
adversary. We then use this to design codes that allow communication at the
optimal source rate of C-Zo-Zi, while keeping the communicated message secret
from the adversary. Interior nodes are oblivious to the presence of adversaries
and perform random linear network coding; only the source and destination need
to be tweaked. In proving our results we correct an error in prior work by a
subset of the authors in this work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3716</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3716</id><created>2010-01-20</created><authors><author><keyname>M.</keyname><forenames>Vaidehi.</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author></authors><title>A Multicore Processor based Real-Time System for Automobile management
  application</title><categories>cs.AR</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose an Intelligent Management System which is capable of
managing the automobile functions using the rigorous real-time principles and a
multicore processor in order to realize higher efficiency and safety for the
vehicle. It depicts how various automobile functionalities can be fine grained
and treated to fit in real time concepts. It also shows how the modern
multicore processors can be of good use in organizing vast amounts of
correlated functions to be executed in real-time with excellent time
commitments. The modeling of the automobile tasks with real time commitments,
organizing appropriate scheduling for various real time tasks and the usage of
a multicore processor enables the system to realize higher efficiency and offer
better safety levels to the vehicle. The industry available real time operating
system is used for scheduling various tasks and jobs on the multicore
processor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3717</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3717</id><created>2010-01-21</created><authors><author><keyname>Muthuramalingam</keyname><forenames>Bama</forenames></author><author><keyname>Bhashyam</keyname><forenames>Srikrishna</forenames></author><author><keyname>Thangaraj</keyname><forenames>Andrew</forenames></author></authors><title>Multistage Relaying Using Interference Networks</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless networks with multiple nodes that relay information from a source to
a destination are expected to be deployed in many applications. Therefore,
understanding their design and performance under practical constraints is
important. In this work, we propose and study three multihopping decode and
forward (MDF) protocols for multistage half-duplex relay networks with no
direct link between the source and destination nodes. In all three protocols,
we assume no cooperation across relay nodes for encoding and decoding.
Numerical evaluation in illustrative example networks and comparison with cheap
relay cut-set bounds for half-duplex networks show that the proposed MDF
protocols approach capacity in some ranges of channel gains. The main idea in
the design of the protocols is the use of coding in interference networks that
are created in different states or modes of a half-duplex network. Our results
suggest that multistage half-duplex relaying with practical constraints on
cooperation is comparable to point-to-point links and full-duplex relay
networks, if there are multiple non-overlapping paths from source to
destination and if suitable coding is employed in interference network states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3718</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3718</id><created>2010-01-20</created><authors><author><keyname>Dappin</keyname><forenames>Satish. G.</forenames></author><author><keyname>Vaidehi</keyname><forenames>M.</forenames></author><author><keyname>Nair</keyname><forenames>G. Nithya</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrsihnan</forenames></author></authors><title>Severity Prediction of Drought in A Large Geographical Area Using
  Distributed Wireless Sensor Networks</title><categories>cs.DC</categories><comments>7 pages, 8 figures</comments><journal-ref>IEEE International Advance Computing Conference, PP 3042-3047,
  2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the severity prediction of drought through the implementation
of modern sensor networks is discussed. We describe how to design a drought
prediction system using wireless sensor networks. This paper will describe a
terrestrial interconnected wireless sensor network paradigm for the prediction
of severity of drought over a vast area of 10,000 sq km. The communication
architecture for sensor network is outlined and the protocols developed for
each layer is explored. The data integration model and sensor data analysis at
the central computer is explained. The advantages and limitations are discussed
along with the use of wireless standards. They are analyzed for its relevance.
Finally a conclusion is presented along with open research issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3720</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3720</id><created>2010-01-21</created><authors><author><keyname>Kim</keyname><forenames>Yi-Reun</forenames></author><author><keyname>Whang</keyname><forenames>Kyu-Young</forenames></author><author><keyname>Song</keyname><forenames>Il-Yeol</forenames></author></authors><title>Page-Differential Logging: An Efficient and DBMS-independent Approach
  for Storing Data into Flash Memory</title><categories>cs.DB</categories><comments>37 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Flash memory is widely used as the secondary storage in lightweight computing
devices due to its outstanding advantages over magnetic disks. Flash memory has
many access characteristics different from those of magnetic disks, and how to
take advantage of them is becoming an important research issue. There are two
existing approaches to storing data into flash memory: page-based and
log-based. The former has good performance for read operations, but poor
performance for write operations. In contrast, the latter has good performance
for write operations when updates are light, but poor performance for read
operations. In this paper, we propose a new method of storing data, called
page-differential logging, for flash-based storage systems that solves the
drawbacks of the two methods. The primary characteristics of our method are:
(1) writing only the difference (which we define as the page-differential)
between the original page in flash memory and the up-to-date page in memory;
(2) computing and writing the page-differential only once at the time the page
needs to be reflected into flash memory. The former contrasts with existing
page-based methods that write the whole page including both changed and
unchanged parts of data or from log-based ones that keep track of the history
of all the changes in a page. Our method allows existing disk-based DBMSs to be
reused as flash-based DBMSs just by modifying the flash memory driver, i.e., it
is DBMS-independent. Experimental results show that the proposed method
improves the I/O performance by 1.2 ~ 6.1 times over existing methods for the
TPC-C data of approximately 1 Gbytes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3725</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3725</id><created>2010-01-21</created><authors><author><keyname>V.</keyname><forenames>Suma</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author></authors><title>Effectiveness Of Defect Prevention In I.T. For Product Development</title><categories>cs.SE</categories><comments>8 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Defect Prevention is the most critical but most neglected component of the
software quality assurance in any project. If applied at all stages of software
development, it can reduce the time, cost and resources required to engineer a
high quality product. Software inspection has proved to be the most effective
and efficient technique enabling defect detection and prevention. Inspections
carried at all phases of software life cycle have proved to be most beneficial
and value added to the attributes of the software. Work is an analysis based on
the data collected for three different projects from a leading product based
company. The purpose of the paper is to show that 55% to 65% of total number of
defects occurs at design phase. Position of this paper also emphasizes the
importance of inspections at all phases of the product development life cycle
in order to achieve the minimal post deployment defects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3727</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3727</id><created>2010-01-21</created><authors><author><keyname>Persya</keyname><forenames>A. Christy</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author></authors><title>Fault Tolerance in Real Time Multiprocessors - Embedded Systems</title><categories>cs.OS</categories><comments>4 pages</comments><journal-ref>Fourth Innovative Conference on Embedded Systems, Mobile
  Communication and Computing, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  All real time tasks which are termed as critical tasks by nature have to
complete its execution before its deadline, even in presence of faults. The
most popularly used real time task assignment algorithms are First Fit (FF),
Best Fit (BF), Bin Packing (BP).The common task scheduling algorithms are Rate
Monotonic (RM), Earliest Deadline First (EDF) etc.All the current approaches
deal with either fault tolerance or criticality in real time. In this paper we
have proposed an integrated approach with a new algorithm, called SASA (Sorting
And Sequential Assignment) which maps the real time task assignment with task
schedule and fault tolerance
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3734</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3734</id><created>2010-01-21</created><authors><author><keyname>Ramachandran</keyname><forenames>Muthu</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrsihnan</forenames></author><author><keyname>Selvarani</keyname><forenames>R.</forenames></author></authors><title>Software Components for Web Services</title><categories>cs.SE</categories><comments>6 pages, 4 figures</comments><journal-ref>Journal of Research &amp; Industry, Volume 1, Issue 1, pp 1-6, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Service-oriented computing has emerged as the new area to address software as
a service. This paper proposes a model for component based development for
service-oriented systems and have created best practice guidelines on software
component design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3735</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3735</id><created>2010-01-21</created><authors><author><keyname>Rai</keyname><forenames>G. N. Harikrishna</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author></authors><title>Gradient Based Seeded Region Grow method for CT Angiographic Image
  Segmentation</title><categories>cs.CV</categories><comments>6 pages, 8 figures</comments><journal-ref>InterJRI Computer Science and Networking, Volume 1, Issue 1, pp
  1-6, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Segmentation of medical images using seeded region growing technique is
increasingly becoming a popular method because of its ability to involve
high-level knowledge of anatomical structures in seed selection process. Region
based segmentation of medical images are widely used in varied clinical
applications like visualization, bone detection, tumor detection and
unsupervised image retrieval in clinical databases. As medical images are
mostly fuzzy in nature, segmenting regions based intensity is the most
challenging task. In this paper, we discuss about popular seeded region grow
methodology used for segmenting anatomical structures in CT Angiography images.
We have proposed a gradient based homogeneity criteria to control the region
grow process while segmenting CTA images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3740</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3740</id><created>2010-01-21</created><authors><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author><author><keyname>Jayalalitha</keyname><forenames>M.</forenames></author><author><keyname>Abhijith</keyname><forenames>S.</forenames></author></authors><title>Cognitive Routing with Stretched Network Awareness through Hidden Markov
  Model Learning at Router Level</title><categories>cs.NI</categories><comments>6 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The routing of packets are generally performed based on the destination
address and forward link channel available from the instantaneous Router
without sufficient cognizance of either the performance of the forward Router
or forward channel characteristics. The lack of awareness of forward channel
property can lead to packet loss or delayed delivery leading to
multipleretransmissions or routing to an underperforming pathway. This paper
describes an application of Cognitive Network to improve the network
performance by implementing a Hidden Markov Model (HMM) algorithm for learning
and predicting the performance of surrounding routers continuously while a
routing demand is initiated. The cognition segment/domain of every router can
gain knowledge about the quality of forward network. The information of the
current network conditions is shared between routers by the Forward Channel
Performance Index FCPI. This enables complete cognition of surroundings and
efficient delivery of messages in various paradigms of performance
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3741</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3741</id><created>2010-01-21</created><authors><author><keyname>Paul</keyname><forenames>Soumitra</forenames></author><author><keyname>Kapoor</keyname><forenames>Kunal</forenames></author><author><keyname>Jasani</keyname><forenames>Devashish</forenames></author><author><keyname>Dudhwewala</keyname><forenames>Rachit</forenames></author><author><keyname>Gowda</keyname><forenames>Vijay Bore</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author></authors><title>Application of Artificial Neural Networks in Aircraft Maintenance,
  Repair and Overhaul Solutions</title><categories>cs.NE</categories><comments>7 pages, 6 figures</comments><journal-ref>International Conference Team Tech pp 42, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reviews application of Artificial Neural Networks in Aircraft
Maintenance, Repair and Overhaul (MRO). MRO solutions are designed to
facilitate the authoring and delivery of maintenance and repair information to
the line maintenance technicians who need to improve aircraft repair turn
around time, optimize the efficiency and consistency of fleet maintenance and
ensure regulatory compliance. The technical complexity of aircraft systems,
especially in avionics, has increased to the point at which it poses a
significant troubleshotting and repair challenge for MRO personnel. As per the
existing scenario, the MRO systems in place are inefficient. In this paper, we
propose the centralization and integration of the MRO database to increase its
efficiency. Moreover the implementation of Artificial Neural Networks in this
system can rid the system of many of its deficiencies. In order to make the
system more efficient we propose to integrate all the modules so as to reduce
the efficacy of repair.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3744</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3744</id><created>2010-01-21</created><authors><author><keyname>Jayarekha</keyname><forenames>P.</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author></authors><title>Multicast Transmission Prefix and Popularity Aware Interval Caching
  Based Admission Control Policy</title><categories>cs.MM</categories><comments>17 pages,</comments><journal-ref>Innovations-2008, pp 15-31, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Admission control is a key component in multimedia servers, which will allow
the resources to be used by the client only when they are available. A problem
faced by numerous content serving machines is overload, when there are too many
clients who need to be served, the server tends to slow down. An admission
control algorithm for a multimedia server is responsible for determining if a
new request can be accepted without violating the QoS requirements of the
existing requests in the system. By caching and streaming only the data in the
interval between two successive requests on the same object, the following
request can be serviced directly from the buffer cache without disk operations
and within the deadline of the request. An admission control strategy based on
Popularity-aware interval caching for Prefix [3] scheme extends the interval
caching by considering different popularity of multimedia objects. The method
of Prefix caching with multicast transmission of popular objects utilizes the
hard disk and network bandwidth efficiently and increases the number of
requests being served.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3745</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3745</id><created>2010-01-21</created><updated>2010-08-12</updated><authors><author><keyname>Medo</keyname><forenames>Matus</forenames></author><author><keyname>Wakeling</keyname><forenames>Joseph Rushton</forenames></author></authors><title>The effect of discrete vs. continuous-valued ratings on reputation and
  ranking systems</title><categories>cs.IR cs.AI cs.DB physics.soc-ph</categories><comments>6 pages, 2 figures</comments><acm-class>H.2.8; K.4.4; H.3.5</acm-class><journal-ref>EPL 91, 48004, 2010</journal-ref><doi>10.1209/0295-5075/91/48004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When users rate objects, a sophisticated algorithm that takes into account
ability or reputation may produce a fairer or more accurate aggregation of
ratings than the straightforward arithmetic average. Recently a number of
authors have proposed different co-determination algorithms where estimates of
user and object reputation are refined iteratively together, permitting
accurate measures of both to be derived directly from the rating data. However,
simulations demonstrating these methods' efficacy assumed a continuum of rating
values, consistent with typical physical modelling practice, whereas in most
actual rating systems only a limited range of discrete values (such as a 5-star
system) is employed. We perform a comparative test of several co-determination
algorithms with different scales of discrete ratings and show that this
seemingly minor modification in fact has a significant impact on algorithms'
performance. Paradoxically, where rating resolution is low, increased noise in
users' ratings may even improve the overall performance of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3748</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3748</id><created>2010-01-21</created><authors><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author><author><keyname>Rao</keyname><forenames>N. Sowjanya</forenames></author><author><keyname>Bukkambudhi</keyname><forenames>Ananda</forenames></author></authors><title>Enhancing Fine Motor Skills of Wards with Special Needs Using Cluster
  Model of Cognition</title><categories>cs.CY</categories><comments>14 pages, 6 figures</comments><journal-ref>International Conference, Team Tech pp 32, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Technology offers great potential to overcome physical barriers of human
race. This paper presents the methods of enhanced learning applicable to
children having special needs using better human-computer interaction. The
Audio-Visual (AV) effects that the graphic tools or animations help in
achieving better learning, understanding, remembering and performance from such
students. The 3L-R Cluster Program Model enable them to look into pictures and
animated objects while listening to the related audio. It also motivates them
to do the FMS development activities like drawing, coloring, tracing etc.,
certain types of games in the clustered model will help the children to improve
concentration, thinking, reasoning, cognitive skills and the eye-to hand
co-ordination. Here we introduced a novel cluster model along with the
methodology described which provides an ample exposure to the effectiveness of
the training. Classify the students with similar problems or disability and the
associated curriculum of modified teaching methodology to meet their special
needs is met through the specialized IT tool which form a part of the cluster
model. It ensures effective learning in wards by enhancing multifaceted
interaction. The main objective of this paper is to support the development of
Fine Motor Skills (FMS) of wards with special needs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3749</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3749</id><created>2010-01-21</created><updated>2010-02-03</updated><authors><author><keyname>Fischer</keyname><forenames>Eldar</forenames></author><author><keyname>Lachish</keyname><forenames>Oded</forenames></author><author><keyname>Yuster</keyname><forenames>Raphael</forenames></author></authors><title>Two-phase algorithms for the parametric shortest path problem</title><categories>cs.CC cs.DS</categories><acm-class>F.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A {\em parametric weighted graph} is a graph whose edges are labeled with
continuous real functions of a single common variable. For any instantiation of
the variable, one obtains a standard edge-weighted graph. Parametric weighted
graph problems are generalizations of weighted graph problems, and arise in
various natural scenarios. Parametric weighted graph algorithms consist of two
phases. A {\em preprocessing phase} whose input is a parametric weighted graph,
and whose output is a data structure, the advice, that is later used by the
{\em instantiation phase}, where a specific value for the variable is given.
The instantiation phase outputs the solution to the (standard) weighted graph
problem that arises from the instantiation. The goal is to have the running
time of the instantiation phase supersede the running time of any algorithm
that solves the weighted graph problem from scratch, by taking advantage of the
advice.
  In this paper we construct several parametric algorithms for the shortest
path problem. For the case of linear function weights we present an algorithm
for the single source shortest path problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3751</identifier>
 <datestamp>2010-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3751</id><created>2010-01-21</created><updated>2010-04-06</updated><authors><author><keyname>Aravindh</keyname><forenames>B. Sri</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author></authors><title>Heat Sink Performance Analysis through Numerical Technique</title><categories>cs.OH</categories><comments>7 pages, 2 figures</comments><journal-ref>IEEE- Symposium, NSSPo8, pp 1-7, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increase in dissipated power per unit area of electronic components sets
higher demands on the performance of the heat sink. Also if we continue at our
current rate of miniaturisation, laptops and other electronic devices can get
heated up tremendously. Hence we require a better heat dissipating system to
overcome the excess heat generating problem of using nanoelectronics, which is
expected to power the next generation of computers. To handle the excessive and
often unpredictable heating up of high performance electronic components like
microprocessors, we need to predict the temperature profile of the heat sink
used. This also helps us to select the best heat sink for the operating power
range of any microprocessor. Understanding the temperature profile of a heat
sink and a microprocessor helps us to handle its temperature efficiently for a
range of loads. In this work, a method to estimate the normal response of a
heat sink to various loads of a microprocessor is explained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3756</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3756</id><created>2010-01-21</created><authors><author><keyname>Persya</keyname><forenames>A. Christy</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author></authors><title>Fault Tolerant Real Time Systems</title><categories>cs.PF</categories><comments>4 pages, 4 figures</comments><journal-ref>International Conference on Next Generation Software Application,
  pp 177-180, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real time systems are systems in which there is a commitment for timely
response by the computer to external stimuli. Real time applications have to
function correctly even in presence of faults. Fault tolerance can be achieved
by either hardware or software or time redundancy. Safety-critical applications
have strict time and cost constraints, which means that not only faults have to
be tolerated but also the constraints should be satisfied. Deadline scheduling
means that the taskwith the earliest required response time is processed. The
most common scheduling algorithms are :Rate Monotonic(RM) and Earliest deadline
first(EDF).This paper deals with the interaction between the fault tolerant
strategy and the EDF real time scheduling strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3760</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3760</id><created>2010-01-21</created><authors><author><keyname>Chen</keyname><forenames>Hongyang</forenames></author><author><keyname>Chan</keyname><forenames>Y. T.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Sezaki</keyname><forenames>Kaoru</forenames></author></authors><title>Range-Free Localization with the Radical Line</title><categories>cs.IT math.IT</categories><comments>Proc. IEEE ICC'10, Cape Town, South Africa, May, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to hardware and computational constraints, wireless sensor networks
(WSNs) normally do not take measurements of time-of-arrival or
time-difference-of-arrival for rangebased localization. Instead, WSNs in some
applications use rangefree localization for simple but less accurate
determination of sensor positions. A well-known algorithm for this purpose is
the centroid algorithm. This paper presents a range-free localization technique
based on the radical line of intersecting circles. This technique provides
greater accuracy than the centroid algorithm, at the expense of a slight
increase in computational load. Simulation results show that for the scenarios
studied, the radical line method can give an approximately 2 to 30% increase in
accuracy over the centroid algorithm, depending on whether or not the anchors
have identical ranges, and on the value of DOI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3765</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3765</id><created>2010-01-21</created><authors><author><keyname>Kokalj-Filipovic</keyname><forenames>Silvija</forenames></author><author><keyname>Spasojevic</keyname><forenames>Predrag</forenames></author><author><keyname>Soljanin</keyname><forenames>Emina</forenames></author></authors><title>Doped Fountain Coding for Minimum Delay Data Collection in Circular
  Networks</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Journal on Selected Areas in Communications (JSAC), Special
  issue on Network Coding for Wireless Communication Networks, Vol. 27, Nr. 5
  (2009), p. 673-684</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies decentralized, Fountain and network-coding based
strategies for facilitating data collection in circular wireless sensor
networks, which rely on the stochastic diversity of data storage. The goal is
to allow for a reduced delay collection by a data collector who accesses the
network at a random position and random time. Data dissemination is performed
by a set of relays which form a circular route to exchange source packets. The
storage nodes within the transmission range of the route's relays linearly
combine and store overheard relay transmissions using random decentralized
strategies. An intelligent data collector first collects a minimum set of coded
packets from a subset of storage nodes in its proximity, which might be
sufficient for recovering the original packets and, by using a message-passing
decoder, attempts recovering all original source packets from this set.
Whenever the decoder stalls, the source packet which restarts decoding is
polled/doped from its original source node. The random-walk-based analysis of
the decoding/doping process furnishes the collection delay analysis with a
prediction on the number of required doped packets. The number of doped packets
can be surprisingly small when employed with an Ideal Soliton code degree
distribution and, hence, the doping strategy may have the least collection
delay when the density of source nodes is sufficiently large. Furthermore, we
demonstrate that network coding makes dissemination more efficient at the
expense of a larger collection delay. Not surprisingly, a circular network
allows for a significantly more (analytically and otherwise) tractable
strategies relative to a network whose model is a random geometric graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3771</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3771</id><created>2010-01-21</created><authors><author><keyname>Gupta</keyname><forenames>Kiran</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author></authors><title>A Study of VLSI Technology, Wafers and Impact on Nanotechnology</title><categories>cs.OH</categories><comments>3 pages, 2 figures</comments><journal-ref>IEEE National Conference on Advanced VLSI/DSP, pp 1-3, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a detailed study of the present VLSI technological
aspects, importance and their replacement or combination with the
Nanotechnology in the VLSI world of silicon semiconductors. Here authors bring
out the nanotechnology in Silicon world which invariably means shrinking
geometry of CMOS devices to nano scale. This also refers to a new world of
nanotechnology where chemists are working in manufacturing of carbon nanotubes
, nano devices of varius materials of nano dimensions without even knowing how
this could change the whole world of Si and CMOS technology and the world we
live in.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3774</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3774</id><created>2010-01-21</created><authors><author><keyname>Dakshayini</keyname><forenames>M.</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishan</forenames></author></authors><title>Cooperative Proxy Servers Architecture for VoD to Achieve High QoS with
  Reduced Transmission Time and Cost</title><categories>cs.MM</categories><comments>12 pages, 6 figures</comments><journal-ref>Innovations-2008, pp 103-114, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  - The aim of this paper is to propose a novel Voice On Demand (VoD)
architecture and implementation of an efficient load sharing algorithm to
achieve Quality of Service (QoS). This scheme reduces the transmission cost
from the Centralized Multimedia Sever (CMS) to Proxy Servers (PS) by sharing
the videos among the proxy servers of the Local Proxy Servers Group [LPSG] and
among the neighboring LPSGs, which are interconnected in a ring fashion. This
results in very low request rejection ratio, reduction in transmission time and
cost, reduction of load on the CMS and high QoS for the users. Simulation
results indicate acceptable initial startup latency, reduced transmission cost
and time, load sharing among the proxy servers, among the LPSGs and between the
CMS and the PS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3777</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3777</id><created>2010-01-21</created><authors><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames><affiliation>SM-IEEE</affiliation></author><author><keyname>Selvarani</keyname><forenames>R.</forenames></author><author><keyname>Vaidehi</keyname><forenames>M.</forenames></author></authors><title>Relaxation Control of Packet Arrival Rate in the Neighborhood of the
  Destination in Concentric Sensor Networks</title><categories>cs.NI</categories><comments>6 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the challenges in the wireless sensor applications which are gaining
much attention is the real-time transmission of continuous data packets across
the network. Though advances in communication in sensor networks are providing
guaranteed quality data packet delivery they still have some drawbacks. One
such drawback is transmission of incessant data packets over high speed
networks. Here in this paper we have designed a concentric sensor network
having buffer just not at the sink but also in selected intermediate nodes to
minimize the packet loss caused due to congestion. This approach results in
haggle congestion and less packet loss in the designed network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3780</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3780</id><created>2010-01-21</created><authors><author><keyname>Huber</keyname><forenames>Michael</forenames></author></authors><title>Combinatorial Bounds and Characterizations of Splitting Authentication
  Codes</title><categories>cs.CR cs.IT math.IT</categories><comments>13 pages; to appear in &quot;Cryptography and Communications&quot;</comments><acm-class>G.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present several generalizations of results for splitting authentication
codes by studying the aspect of multi-fold security. As the two primary
results, we prove a combinatorial lower bound on the number of encoding rules
and a combinatorial characterization of optimal splitting authentication codes
that are multi-fold secure against spoofing attacks. The characterization is
based on a new type of combinatorial designs, which we introduce and for which
basic necessary conditions are given regarding their existence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3781</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3781</id><created>2010-01-21</created><authors><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author><author><keyname>rani</keyname><forenames>R. Selva</forenames></author><author><keyname>Krutthika</keyname><forenames>H. K.</forenames></author></authors><title>An Architectural Approach for Decoding and Distributing Functions in
  FPUs in a Functional Processor System</title><categories>cs.AR</categories><comments>6 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main goal of this research is to develop the concepts of a revolutionary
processor system called Functional Processor System. The fairly novel work
carried out in this proposal concentrates on decoding of function pipelines and
distributing it in FPUs as a part of scheduling approach. As the functional
programs are super-level programs that entails requirements only at functional
level, decoding of functions and distribution of functions in the heterogeneous
functional processor units are a challenge. We explored the possibilities of
segregation of the functions from the application program and distributing the
functions on the relevant FPUs by using address mapping techniques. Here we
pursue the perception of feeding the functions into the processor farm rather
than the processor fetching the instructions or functions and executing it.
This work is carried out at theoretical levels and it requires a long way to go
in the realization of this work in hardware perhaps with a large industrial
team with a pragmatic time frame.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3790</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3790</id><created>2010-01-21</created><updated>2011-02-25</updated><authors><author><keyname>Zaidel</keyname><forenames>Benjamin</forenames></author><author><keyname>Mueller</keyname><forenames>Ralf</forenames></author><author><keyname>Moustakas</keyname><forenames>Aris</forenames></author><author><keyname>de Miguel</keyname><forenames>Rodrigo</forenames></author></authors><title>Vector Precoding for Gaussian MIMO Broadcast Channels: Impact of Replica
  Symmetry Breaking</title><categories>cs.IT math.IT</categories><comments>Comparison with Tomlinson-Harashima precoding added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The so-called &quot;replica method&quot; of statistical physics is employed for the
large system analysis of vector precoding for the Gaussian multiple-input
multiple-output (MIMO) broadcast channel. The transmitter is assumed to
comprise a linear front-end combined with nonlinear precoding, that minimizes
the front-end imposed transmit energy penalty. Focusing on discrete complex
input alphabets, the energy penalty is minimized by relaxing the input alphabet
to a larger alphabet set prior to precoding. For the common discrete
lattice-based relaxation, the problem is found to violate the assumption of
replica symmetry and a replica symmetry breaking ansatz is taken. The limiting
empirical distribution of the precoder's output, as well as the limiting energy
penalty, are derived for one-step replica symmetry breaking. For convex
relaxations, replica symmetry is found to hold and corresponding results are
obtained for comparison. Particularizing to a &quot;zero-forcing&quot; (ZF) linear
front-end, and non-cooperative users, a decoupling result is derived according
to which the channel observed by each of the individual receivers can be
effectively characterized by the Markov chain u-x-y, where u, x, and y are the
channel input, the equivalent precoder output, and the channel output,
respectively. For discrete lattice-based alphabet relaxation, the impact of
replica symmetry breaking is demonstrated for the energy penalty at the
transmitter. An analysis of spectral efficiency is provided to compare discrete
lattice-based relaxations against convex relaxations, as well as linear ZF and
Tomlinson-Harashima precoding (THP). Focusing on quaternary phase shift-keying
(QPSK), significant performance gains of both lattice and convex relaxations
are revealed compared to linear ZF precoding, for medium to high
signal-to-noise ratios (SNRs). THP is shown to be outperformed as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3816</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3816</id><created>2010-01-21</created><updated>2010-01-21</updated><authors><author><keyname>Dube</keyname><forenames>Rakesh</forenames></author></authors><title>The P versus NP Problem</title><categories>cs.CC</categories><comments>Removed by arXiv administration due to plagiarism from Stephen Cook's
  description of the problem for the Clay Mathematics Institute. See
  http://gauss.claymath.org:8888/millennium/P_vs_NP/pvsnp.pdf for the original
  text</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Removed by arXiv administration.
  This article was plagiarized directly from Stephen Cook's description of the
problem for the Clay Mathematics Institute. See
http://gauss.claymath.org:8888/millennium/P_vs_NP/pvsnp.pdf for the original
text.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3824</identifier>
 <datestamp>2010-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3824</id><created>2010-01-21</created><authors><author><keyname>Sacerdoti</keyname><forenames>Federico D.</forenames></author></authors><title>Performance and Fault Tolerance in the StoreTorrent Parallel Filesystem</title><categories>cs.DC</categories><comments>13 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With a goal of supporting the timely and cost-effective analysis of Terabyte
datasets on commodity components, we present and evaluate StoreTorrent, a
simple distributed filesystem with integrated fault tolerance for efficient
handling of small data records. Our contributions include an application-OS
pipelining technique and metadata structure to increase small write and read
performance by a factor of 1-10, and the use of peer-to-peer communication of
replica-location indexes to avoid transferring data during parallel analysis
even in a degraded state. We evaluated StoreTorrent, PVFS, and Gluster
filesystems using 70 storage nodes and 560 parallel clients on an 8-core/node
Ethernet cluster with directly attached SATA disks. StoreTorrent performed
parallel small writes at an aggregate rate of 1.69 GB/s, and supported reads
over the network at 8.47 GB/s. We ported a parallel analysis task and
demonstrate it achieved parallel reads at the full aggregate speed of the
storage node local filesystems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3885</identifier>
 <datestamp>2010-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3885</id><created>2010-01-21</created><authors><author><keyname>Kelly</keyname><forenames>Benjamin G.</forenames></author><author><keyname>Wagner</keyname><forenames>Aaron B.</forenames></author></authors><title>Improved Source Coding Exponents via Witsenhausen's Rate</title><categories>cs.IT math.IT</categories><comments>24 pages, 4 figures. Submitted to IEEE Trans. Info. Theory (Jan 2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a novel upper-bound on Witsenhausen's rate, the rate required in
the zero-error analogue of the Slepian-Wolf problem; our bound is given in
terms of a new information-theoretic functional defined on a certain graph. We
then use the functional to give a single letter lower-bound on the error
exponent for the Slepian-Wolf problem under the vanishing error probability
criterion, where the decoder has full (i.e. unencoded) side information. Our
exponent stems from our new encoding scheme which makes use of source
distribution only through the positions of the zeros in the `channel' matrix
connecting the source with the side information, and in this sense is
`semi-universal'. We demonstrate that our error exponent can beat the
`expurgated' source-coding exponent of Csisz\'{a}r and K\&quot;{o}rner,
achievability of which requires the use of a non-universal maximum-likelihood
decoder. An extension of our scheme to the lossy case (i.e. Wyner-Ziv) is
given. For the case when the side information is a deterministic function of
the source, the exponent of our improved scheme agrees with the sphere-packing
bound exactly (thus determining the reliability function). An application of
our functional to zero-error channel capacity is also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3896</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3896</id><created>2010-01-21</created><updated>2012-02-09</updated><authors><author><keyname>Kakhbod</keyname><forenames>Ali</forenames></author><author><keyname>Teneketzis</keyname><forenames>Demosthenis</forenames></author></authors><title>Games on Social Networks: On a Problem Posed by Goyal</title><categories>cs.GT math.OC</categories><journal-ref>Economic Bulletin (EB). vol 31, no. 3, pp. 2177-2184, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Within the context of games on networks S. Goyal (Goya (2007), pg. 39) posed
the following problem. Under any arbitrary but fixed topology, does there exist
at least one pure Nash equilibrium that exhibits a positive relation between
the cardinality of a player's set of neighbors and its utility payoff? In this
paper we present a class of topologies/games in which pure Nash equilibria with
the above property do not exist.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3908</identifier>
 <datestamp>2010-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3908</id><created>2010-01-22</created><updated>2010-04-21</updated><authors><author><keyname>Ahmadi</keyname><forenames>Hadi</forenames></author><author><keyname>Safavi-Naini</keyname><forenames>Reihaneh</forenames></author></authors><title>Secret Key Establishment over a Pair of Independent Broadcast Channels</title><categories>cs.IT cs.CR math.IT</categories><comments>23 Pages, 4 figures, submitted to the 2010 International Symposium on
  Information Theory and its Applications (ISITA2010)</comments><acm-class>H.1.1; E.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of information-theoretic Secret Key
Establishment (SKE) in the presence of a passive adversary, Eve, when Alice and
Bob are connected by a pair of independent discrete memoryless broadcast
channels in opposite directions. We refer to this setup as 2DMBC. We define the
secret-key capacity in the 2DMBC setup and prove lower and upper bounds on this
capacity. The lower bound is achieved by a two-round SKE protocol that uses a
two-level coding construction. We show that the lower and the upper bounds
coincide in the case of degraded DMBCs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3911</identifier>
 <datestamp>2011-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3911</id><created>2010-01-21</created><updated>2011-10-03</updated><authors><author><keyname>Jeong</keyname><forenames>Seongwook</forenames></author><author><keyname>Moon</keyname><forenames>Jaekyun</forenames></author></authors><title>Computing Lower Bounds on the Information Rate of Intersymbol
  Interference Channels</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author due to its significant
  modification</comments><msc-class>68P30(Primary) 94A15(Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Provable lower bounds are presented for the information rate I(X; X+S+N)
where X is the symbol drawn from a fixed, finite-size alphabet, S a
discrete-valued random variable (RV) and N a Gaussian RV. The information rate
I(X; X+S+N) serves as a tight lower bound for capacity of intersymbol
interference (ISI) channels corrupted by Gaussian noise. The new bounds can be
calculated with a reasonable computational load and provide a similar level of
tightness as the well-known conjectured lower bound by Shamai and Laroia for a
good range of finite-ISI channels of practical interest. The computation of the
presented bounds requires the evaluation of the magnitude sum of the precursor
ISI terms as well as the identification of dominant terms among them seen at
the output of the minimum mean-squared error (MMSE) decision feedback equalizer
(DFE).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3916</identifier>
 <datestamp>2010-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3916</id><created>2010-01-22</created><authors><author><keyname>Zhang</keyname><forenames>Guohua</forenames></author><author><keyname>Wang</keyname><forenames>Xinmei</forenames></author></authors><title>Girth-12 Quasi-Cyclic LDPC Codes with Consecutive Lengths</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method to construct girth-12 (3,L) quasi-cyclic low-density parity-check
(QC-LDPC) codes with all lengths larger than a certain given number is
proposed, via a given girth-12 code subjected to some constraints. The lengths
of these codes can be arbitrary integers of the form LP, provided that P is
larger than a tight lower bound determined by the maximal element within the
exponent matrix of the given girth-12 code. By applying the method to the case
of row-weight six, we obtained a family of girth-12 (3,6) QC-LDPC codes for
arbitrary lengths above 2688, which includes 30 member codes with shorter code
lengths compared with the shortest girth-12 (3,6) QC-LDPC codes reported by
O'Sullivan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3918</identifier>
 <datestamp>2010-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3918</id><created>2010-01-22</created><authors><author><keyname>V</keyname><forenames>Suma</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author></authors><title>Defect Prevention Approaches in Medium Scale it Enterprises</title><categories>cs.SE</categories><comments>5 pages</comments><journal-ref>National Conference on Recent Research Trends in Information
  Technology, pp 134-138, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The software industry is successful, if it can draw the complete attention of
the customers towards it. This is achievable if the organization can produce a
high quality product. To identify a product to be of high quality, it should be
free of defects, should be capable of producing expected results. It should be
delivered in an estimated cost, time and be maintainable with minimum effort.
Defect Prevention is the most critical but often neglected component of the
software quality assurance in any project. If applied at all stages of software
development, it can reduce the time, cost and resources required to engineer a
high quality product.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3919</identifier>
 <datestamp>2010-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3919</id><created>2010-01-22</created><authors><author><keyname>Bharadwaj</keyname><forenames>A. Keshav</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author></authors><title>Mapping General System Characteristics to Non- Functional Requirements</title><categories>cs.SE</categories><comments>5 pages</comments><journal-ref>IEEE International Advance Computing Conference, (IACC), pp
  1821-1825, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Function point analysis (FPA) method is the preferred scheme of
estimation for project managers to determine the size, effort, schedule,
resource loading and other such parameters. The FPA method by International
Function Point Users Group (IFPUG) has captured the critical implementation
features of an application through fourteen general system characteristics.
However, Non- functional requirements (NFRs) such as functionality,
reliability, efficiency, usability, maintainability, portability, etc. have not
been included in the FPA estimation method. This paper discusses some of the
NFRs and tries to determine a degree of influence for each of them. An attempt
to factor the NFRs into estimation has been made. This approach needs to be
validated with data collection and analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3920</identifier>
 <datestamp>2010-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3920</id><created>2010-01-22</created><authors><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author><author><keyname>Sooda</keyname><forenames>Kavitha</forenames></author></authors><title>Comparison of Genetic Algorithm and Simulated Annealing Technique for
  Optimal Path Selection In Network Routing</title><categories>cs.NE cs.NI</categories><comments>6 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the path selection problem from a known sender to the
receiver. The proposed work shows path selection using genetic algorithm(GA)and
simulated annealing (SA) approaches. In genetic algorithm approach, the multi
point crossover and mutation helps in determining the optimal path and also
alternate path if required. The input to both the algorithms is a learnt module
which is a part of the cognitive router that takes care of four QoS
parameters.The aim of the approach is to maximize the bandwidth along the
forward channels and minimize the route length. The population size is
considered as the N nodes participating in the network scenario, which will be
limited to a known size of topology. The simulated results show that, by using
genetic algorithm approach, the probability of shortest path convergence is
higher as the number of iteration goes up whereas in simulated annealing the
number of iterations had no influence to attain better results as it acts on
random principle of selection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3928</identifier>
 <datestamp>2010-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3928</id><created>2010-01-22</created><authors><author><keyname>Razafindradina</keyname><forenames>Henri Bruno Rhb</forenames><affiliation>LASM</affiliation></author><author><keyname>Randriamitantsoa</keyname><forenames>Paul Auguste Rpa</forenames><affiliation>LIISTA</affiliation></author></authors><title>Tatouage Robuste Et Aveugle Dans Le Domaine Des Valeurs Singulieres</title><categories>cs.CR</categories><comments>15 pages</comments><proxy>ccsd hal-00448914</proxy><journal-ref>JMAITS : Journal Marocain de l'Automatique, de l'Informatique et
  du Traitement de Signal (2008) 1-15</journal-ref><doi>10.1978/2808</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital watermarking consists on inserting a mark into an image to protect it
against copies. The heaviness of the extraction procedure with the old methods
urged us to look for a new algorithm in the singular values domain which would
be blind : it does not require the original image to extract the mark. We
propose a new robust method which consists on inserting the bits of the mark
into the singular values matrix. Contrary to most of the watermarking
algorithms, it is blind and the results show that our method is robust against
the JPEG compression, the reduction of colors (GIF) and the histogram
spreading. So, we were able to obtain PSNR = 49,63 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3932</identifier>
 <datestamp>2010-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3932</id><created>2010-01-22</created><authors><author><keyname>Padmini</keyname><forenames>H. A.</forenames></author><author><keyname>Bharadwaj</keyname><forenames>A. Keshav</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author></authors><title>Approaches to Curriculum and Teaching Materials to Bring Out Better
  Skilled Software Engineers-An Indian Perspective</title><categories>cs.CY</categories><comments>7 pages, 2 figures</comments><journal-ref>EDULEARN09 pp 1821-1825, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Development of Curriculum and delivery materials has undergone changes over a
period of time, in undergraduate engineering degree system in Indian
universities. However, there exists a gap between industry expectations in IT
field and skills and knowledge that the graduating engineers possess and this
continues to grow. A similar situation has been seen in the developed countries
like USA, UK and Australia. Several researchers and practitioners have
discussed and tried to come up with innovative approaches to teaching software
engineering and IT as a whole. In India, it is of vital importance that steps
be taken to address this issue seriously. This paper discusses some of the
measures that have been implemented so that this gap is reduced and software
engineers with better skills are produced. Changes to curriculum,
industry-academia collaboration through conferences, sabbaticals etc., industry
internships and live projects for final year students are some of the measures
that have been discussed in this paper. The implementation of these measures
may lead to fulfilling the growing requirement for skilled software engineers
who can handle the industry challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3934</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3934</id><created>2010-01-22</created><updated>2010-10-24</updated><authors><author><keyname>Couillet</keyname><forenames>Romain</forenames></author><author><keyname>Silverstein</keyname><forenames>Jack W.</forenames></author><author><keyname>Bai</keyname><forenames>Zhidong</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Eigen-Inference for Energy Estimation of Multiple Sources</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE Trans. on Information Theory, 17 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new method is introduced to blindly estimate the transmit
power of multiple signal sources in multi-antenna fading channels, when the
number of sensing devices and the number of available samples are sufficiently
large compared to the number of sources. Recent advances in the field of large
dimensional random matrix theory are used that result in a simple and
computationally efficient consistent estimator of the power of each source. A
criterion to determine the minimum number of sensors and the minimum number of
samples required to achieve source separation is then introduced. Simulations
are performed that corroborate the theoretical claims and show that the
proposed power estimator largely outperforms alternative power inference
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3967</identifier>
 <datestamp>2010-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3967</id><created>2010-01-22</created><authors><author><keyname>Colver</keyname><forenames>David</forenames></author></authors><title>Spreadsheet good practice: is there any such thing?</title><categories>cs.HC</categories><comments>9 Pages, 3 Colour Figures. Referenced &amp; Submitted by GJC in Jan 2010</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2004 ISBN 1
  902724 94 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Various techniques for developing spreadsheet models greatly improve the
chance that the end result will not contain basic mechanical errors. However,
for every discipline in which a given technique is useful, there is likely to
be another in which the same technique works badly. As a result, the author
urges that EuSpRIG does not succumb to internal or external pressures to
champion a particular set of &quot;best practices&quot;, because no such set is optimal
in all spreadsheet applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.3974</identifier>
 <datestamp>2010-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.3974</id><created>2010-01-22</created><updated>2010-01-22</updated><authors><author><keyname>Labra&#xf1;a</keyname><forenames>C&#xe9;sar Mena</forenames></author><author><keyname>Schulz</keyname><forenames>Ricardo S&#xe1;nchez</forenames></author><author><keyname>Silva</keyname><forenames>Lautaro Salazar</forenames></author></authors><title>Modelacion y Visualizacion Tridimensional Interactiva de Variables
  Electricas en Celdas de Electro-Obtencion con Electrodos Bipolares</title><categories>cs.GR cs.CE</categories><comments>6 pages, 3 figures, in Spanish. See also arXiv:1001.4002v1 [cs.GR].
  The only change in V2 is the updating of a reference</comments><journal-ref>Anales del XIV Congreso de la Asociacion Chilena de Control
  Automatico, ACCA, 2000, pp. 362-367</journal-ref><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  The use of floating bipolar electrodes in electrowinning cells of copper
constitutes a nonconventional technology that promises economic and operational
impacts. This paper presents a computational tool for the simulation and
analysis of such electrochemical cells. A new model is developed for floating
electrodes and a method of finite difference is used to obtain the
threedimensional distribution of the potential and the field of current density
inside the cell. The analysis of the results is based on a technique for the
interactive visualization of three-dimensional vectorial fields as lines of
flow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4002</identifier>
 <datestamp>2010-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4002</id><created>2010-01-22</created><authors><author><keyname>Labra&#xf1;a</keyname><forenames>C&#xe9;sar Mena</forenames></author></authors><title>Aplicacion Grafica para el estudio de un Modelo de Celda Electrolitica
  usando Tecnicas de Visualizacion de Campos Vectoriales</title><categories>cs.GR cs.CE</categories><comments>Electronic Engineer Thesis, Universidad de Concepcion, 2000, 105
  pages, 22 figures, in Spanish. The main results are also available in
  arXiv:1001.3974v1 [cs.GR]</comments><report-no>000054269</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The use of floating bipolar electrodes in electrowinning cells of copper
constitutes a nonconventional technology that promises economic and operational
impacts. This thesis presents a computational tool for the simulation and
analysis of such electrochemical cells. A new model is developed for floating
electrodes and a method of finite difference is used to obtain the
threedimensional distribution of the potential and the field of current density
inside the cell. The analysis of the results is based on a technique for the
interactive visualization of three-dimensional vectorial fields as lines of
flow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4003</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4003</id><created>2010-01-22</created><authors><author><keyname>Bredereck</keyname><forenames>Robert</forenames></author></authors><title>Fixed-Parameter Algorithms for Computing Kemeny Scores - Theory and
  Practice</title><categories>cs.DS cs.CC</categories><comments>Studienarbeit</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The central problem in this work is to compute a ranking of a set of elements
which is &quot;closest to&quot; a given set of input rankings of the elements. We define
&quot;closest to&quot; in an established way as having the minimum sum of Kendall-Tau
distances to each input ranking. Unfortunately, the resulting problem Kemeny
consensus is NP-hard for instances with n input rankings, n being an even
integer greater than three. Nevertheless this problem plays a central role in
many rank aggregation problems. It was shown that one can compute the
corresponding Kemeny consensus list in f(k) + poly(n) time, being f(k) a
computable function in one of the parameters &quot;score of the consensus&quot;, &quot;maximum
distance between two input rankings&quot;, &quot;number of candidates&quot; and &quot;average
pairwise Kendall-Tau distance&quot; and poly(n) a polynomial in the input size. This
work will demonstrate the practical usefulness of the corresponding algorithms
by applying them to randomly generated and several real-world data. Thus, we
show that these fixed-parameter algorithms are not only of theoretical
interest. In a more theoretical part of this work we will develop an improved
fixed-parameter algorithm for the parameter &quot;score of the consensus&quot; having a
better upper bound for the running time than previous algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4004</identifier>
 <datestamp>2010-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4004</id><created>2010-01-22</created><updated>2010-02-24</updated><authors><author><keyname>Faug&#xe8;re</keyname><forenames>Jean-Charles</forenames></author><author><keyname>Din</keyname><forenames>Mohab Safey El</forenames></author><author><keyname>Spaenlehauer</keyname><forenames>Pierre-Jean</forenames></author></authors><title>Gr\&quot;obner Bases of Bihomogeneous Ideals generated by Polynomials of
  Bidegree (1,1): Algorithms and Complexity</title><categories>cs.SC</categories><comments>31 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solving multihomogeneous systems, as a wide range of structured algebraic
systems occurring frequently in practical problems, is of first importance.
Experimentally, solving these systems with Gr\&quot;obner bases algorithms seems to
be easier than solving homogeneous systems of the same degree. Nevertheless,
the reasons of this behaviour are not clear. In this paper, we focus on
bilinear systems (i.e. bihomogeneous systems where all equations have bidegree
(1,1)). Our goal is to provide a theoretical explanation of the aforementionned
experimental behaviour and to propose new techniques to speed up the Gr\&quot;obner
basis computations by using the multihomogeneous structure of those systems.
The contributions are theoretical and practical. First, we adapt the classical
F5 criterion to avoid reductions to zero which occur when the input is a set of
bilinear polynomials. We also prove an explicit form of the Hilbert series of
bihomogeneous ideals generated by generic bilinear polynomials and give a new
upper bound on the degree of regularity of generic affine bilinear systems.
This leads to new complexity bounds for solving bilinear systems. We propose
also a variant of the F5 Algorithm dedicated to multihomogeneous systems which
exploits a structural property of the Macaulay matrix which occurs on such
inputs. Experimental results show that this variant requires less time and
memory than the classical homogeneous F5 Algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4021</identifier>
 <datestamp>2010-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4021</id><created>2010-01-22</created><authors><author><keyname>Kaminski</keyname><forenames>Mark</forenames></author><author><keyname>Smolka</keyname><forenames>Gert</forenames></author></authors><title>A Minimal Propositional Type Theory</title><categories>cs.LO</categories><comments>11 pages</comments><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Propositional type theory, first studied by Henkin, is the restriction of
simple type theory to a single base type that is interpreted as the set of the
two truth values. We show that two constants (falsity and implication) suffice
for denotational and deductive completeness. Denotational completeness means
that every value of the full set-theoretic type hierarchy can be described by a
closed term. Deductive completeness is shown for a sequent-based proof system
that extends a propositional natural deduction system with lambda conversion
and Boolean replacement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4023</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4023</id><created>2010-01-22</created><authors><author><keyname>Bouche</keyname><forenames>Thierry</forenames><affiliation>IF, CCDNM</affiliation></author></authors><title>Digital Mathematics Libraries: The Good, the Bad, the Ugly</title><categories>cs.DL</categories><proxy>ccsd hal-00449504</proxy><journal-ref>Mathematics in Computer Science 3, 3 (2010) 227-241</journal-ref><doi>10.1007/s11786-010-0029-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The idea of a World digital mathematics library (DML) has been around since
the turn of the 21th century. We feel that it is time to make it a reality,
starting in a modest way from successful bricks that have already been built,
but with an ambitious goal in mind. After a brief historical overview of
publishing mathematics, an estimate of the size and a characterisation of the
bulk of documents to be included in the DML, we turn to proposing a model for a
Reference Digital Mathematics Library--a network of institutions where the
digital documents would be physically archived. This pattern based rather on
the bottom-up strategy seems to be more practicable and consistent with the
digital nature of the DML. After describing the model we summarise what can and
should be done in order to accomplish the vision. The current state of some of
the local libraries that could contribute to the global views are described
with more details.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4072</identifier>
 <datestamp>2010-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4072</id><created>2010-01-22</created><updated>2010-01-22</updated><authors><author><keyname>Ma</keyname><forenames>Rick</forenames></author><author><keyname>Cheng</keyname><forenames>Samuel</forenames></author></authors><title>Hamming Code for Multiple Sources</title><categories>cs.IT math.IT</categories><comments>11 pages, no figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider Slepian-Wolf (SW) coding of multiple sources and extend the
packing bound and the notion of perfect code from conventional channel coding
to SW coding with more than two sources. We then introduce Hamming Codes for
Multiple Sources (HCMSs) as a potential solution of perfect SW coding for
arbitrary number of terminals. Moreover, we study the case with three sources
in detail. We present the necessary conditions of a perfect SW code and show
that there exists infinite number of HCMSs. Moreover, we show that for a
perfect SW code with sufficiently long code length, the compression rates of
different sources can be trade-off flexibly. Finally, we relax the construction
procedure of HCMS and call the resulting code generalized HCMS. We prove that
every perfect SW code for Hamming sources is equivalent to a generalized HCMS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4099</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4099</id><created>2010-01-24</created><authors><author><keyname>Xu</keyname><forenames>Yi-Chun</forenames></author><author><keyname>Dong</keyname><forenames>Fang-Min</forenames></author><author><keyname>Liu</keyname><forenames>Yong</forenames></author><author><keyname>Xiao</keyname><forenames>Ren-Bin</forenames></author><author><keyname>Amos</keyname><forenames>Martyn</forenames></author></authors><title>Ant Colony Algorithm for the Weighted Item Layout Optimization Problem</title><categories>cs.NE cs.CG</categories><comments>Submitted. Replaces version with formatting errors due to PDF
  conversion</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses the problem of placing weighted items in a circular
container in two-dimensional space. This problem is of great practical
significance in various mechanical engineering domains, such as the design of
communication satellites. Two constructive heuristics are proposed, one for
packing circular items and the other for packing rectangular items. These work
by first optimizing object placement order, and then optimizing object
positioning. Based on these heuristics, an ant colony optimization (ACO)
algorithm is described to search first for optimal positioning order, and then
for the optimal layout. We describe the results of numerical experiments, in
which we test two versions of our ACO algorithm alongside local search methods
previously described in the literature. Our results show that the constructive
heuristic-based ACO performs better than existing methods on larger problem
instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4104</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4104</id><created>2010-01-22</created><authors><author><keyname>Colver</keyname><forenames>David</forenames></author></authors><title>Inclusion Analysis</title><categories>cs.SE cs.HC</categories><comments>13 Pages, 10 Tables in Colour</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. 2007 177-189 ISBN
  978-905617-58-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inclusion analysis is the name given by Operis to a black box testing
technique that it has found to make the checking of key financial ratios
calculated by spreadsheet models quicker, easier and more likely to find
omission errors than code inspection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4107</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4107</id><created>2010-01-22</created><authors><author><keyname>Colver</keyname><forenames>David</forenames></author></authors><title>Self-Checks In Spreadsheets: A Survey Of Current Practice</title><categories>cs.SE cs.HC</categories><comments>7 Pages, 1 Table</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 ISBN
  978-905617-69-2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A common application of spreadsheets is the development of models that
deliver projections of the future financial statements of companies established
to pursue ventures that are subject to project financing. A survey of 11 such
spreadsheets prepared by a range of organisations shows that the amount of
self-testing included in such models ranges between one formula of testing for
each three formulae of calculation, down to essentially no self-testing at all.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4108</identifier>
 <datestamp>2010-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4108</id><created>2010-01-22</created><updated>2010-02-24</updated><authors><author><keyname>Lund</keyname><forenames>Ben</forenames></author><author><keyname>Smith</keyname><forenames>Justin W</forenames></author></authors><title>A Multi-Stage CUDA Kernel for Floyd-Warshall</title><categories>cs.DC cs.PF</categories><comments>9 pages, 7 figures, 1 table</comments><acm-class>D.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new implementation of the Floyd-Warshall All-Pairs Shortest
Paths algorithm on CUDA. Our algorithm runs approximately 5 times faster than
the previously best reported algorithm. In order to achieve this speedup, we
applied a new technique to reduce usage of on-chip shared memory and allow the
CUDA scheduler to more effectively hide instruction latency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4110</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4110</id><created>2010-01-22</created><authors><author><keyname>Chandar</keyname><forenames>Venkat</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Wornell</keyname><forenames>Gregory W.</forenames></author></authors><title>A Simple Message-Passing Algorithm for Compressed Sensing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the recovery of a nonnegative vector x from measurements y = Ax,
where A is an m-by-n matrix whos entries are in {0, 1}. We establish that when
A corresponds to the adjacency matrix of a bipartite graph with sufficient
expansion, a simple message-passing algorithm produces an estimate \hat{x} of x
satisfying ||x-\hat{x}||_1 \leq O(n/k) ||x-x(k)||_1, where x(k) is the best
k-sparse approximation of x. The algorithm performs O(n (log(n/k))^2 log(k))
computation in total, and the number of measurements required is m = O(k
log(n/k)). In the special case when x is k-sparse, the algorithm recovers x
exactly in time O(n log(n/k) log(k)). Ultimately, this work is a further step
in the direction of more formally developing the broader role of
message-passing algorithms in solving compressed sensing problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4115</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4115</id><created>2010-01-25</created><updated>2011-01-24</updated><authors><author><keyname>Funk</keyname><forenames>Shelby</forenames></author><author><keyname>Nelis</keyname><forenames>Vincent</forenames></author><author><keyname>Goossens</keyname><forenames>Joel</forenames></author><author><keyname>Milojevic</keyname><forenames>Dragomir</forenames></author><author><keyname>Nelissen</keyname><forenames>Geoffrey</forenames></author></authors><title>On the Design of an Optimal Multiprocessor Real-Time Scheduling
  Algorithm under Practical Considerations (Extended Version)</title><categories>cs.OS cs.DC</categories><comments>This paper has been withdrawn by the authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This research addresses the multiprocessor scheduling problem of hard
real-time systems, and it especially focuses on optimal and global schedulers
when practical constraints are taken into account. First, we propose an
improvement of the optimal algorithm BF. We formally prove that our adaptation
is (i) optimal, i.e., it always generates a feasible schedule as long as such a
schedule exists, and (ii) valid, i.e., it complies with the all the
requirements. We also show that it outperforms BF by providing a computing
complexity of O(n), where n is the number of tasks to be scheduled. Next, we
propose a schedulability analysis which indicates a priori whether the
real-time application can be scheduled by our improvement of BF without missing
any deadline. This analysis is, to the best of our knowledge, the first such
test for multiprocessors that takes into account all the main overheads
generated by the Operating System.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4119</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4119</id><created>2010-01-22</created><updated>2010-02-03</updated><authors><author><keyname>Allamigeon</keyname><forenames>Xavier</forenames></author><author><keyname>Gaubert</keyname><forenames>Stephane</forenames></author><author><keyname>Goubault</keyname><forenames>Eric</forenames></author></authors><title>The tropical double description method</title><categories>cs.CG cs.DM</categories><comments>12 pages, prepared for the Proceedings of the Symposium on
  Theoretical Aspects of Computer Science, 2010, Nancy, France</comments><acm-class>F.2.2; G.2.2</acm-class><doi>10.4230/LIPIcs.STACS.2010.2443</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We develop a tropical analogue of the classical double description method
allowing one to compute an internal representation (in terms of vertices) of a
polyhedron defined externally (by inequalities). The heart of the tropical
algorithm is a characterization of the extreme points of a polyhedron in terms
of a system of constraints which define it. We show that checking the
extremality of a point reduces to checking whether there is only one minimal
strongly connected component in an hypergraph. The latter problem can be solved
in almost linear time, which allows us to eliminate quickly redundant
generators. We report extensive tests (including benchmarks from an application
to static analysis) showing that the method outperforms experimentally the
previous ones by orders of magnitude. The present tools also lead to worst case
bounds which improve the ones provided by previous methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4120</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4120</id><created>2010-01-22</created><authors><author><keyname>Cadambe</keyname><forenames>Viveck R.</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>Sum-Capacity and the Unique Separability of the Parallel Gaussian
  MAC-Z-BC Network</title><categories>cs.IT math.IT</categories><comments>Submitted to ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that the capacity of parallel (e.g., multi-carrier) Gaussian
point-to-point, multiple access and broadcast channels can be achieved by
separate encoding for each subchannel (carrier) subject to a power allocation
across carriers. Recent results have shown that parallel interference channels
are not separable, i.e., joint coding is needed to achieve capacity in general.
This work studies the separability, from a sum-capacity perspective, of single
hop Gaussian interference networks with independent messages and arbitrary
number of transmitters and receivers. The main result is that the only network
that is always (for all values of channel coefficients) separable from a
sum-capacity perspective is the MAC-Z-BC network, i.e., a network where a MAC
component and a BC component are linked by a Z component. The sum capacity of
this network is explicitly characterized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4122</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4122</id><created>2010-01-22</created><authors><author><keyname>Preciado</keyname><forenames>Victor M.</forenames></author><author><keyname>Zavlanos</keyname><forenames>Michael M.</forenames></author><author><keyname>Jadbabaie</keyname><forenames>Ali</forenames></author><author><keyname>Pappas</keyname><forenames>George J.</forenames></author></authors><title>Distributed Control of the Laplacian Spectral Moments of a Network</title><categories>cs.MA cs.CE</categories><comments>8 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well-known that the eigenvalue spectrum of the Laplacian matrix of a
network contains valuable information about the network structure and the
behavior of many dynamical processes run on it. In this paper, we propose a
fully decentralized algorithm that iteratively modifies the structure of a
network of agents in order to control the moments of the Laplacian eigenvalue
spectrum. Although the individual agents have knowledge of their local network
structure only (i.e., myopic information), they are collectively able to
aggregate this local information and decide on what links are most beneficial
to be added or removed at each time step. Our approach relies on gossip
algorithms to distributively compute the spectral moments of the Laplacian
matrix, as well as ensure network connectivity in the presence of link
deletions. We illustrate our approach in nontrivial computer simulations and
show that a good final approximation of the spectral moments of the target
Laplacian matrix is achieved for many cases of interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4129</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4129</id><created>2010-01-22</created><authors><author><keyname>Suma</keyname><forenames>V.</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author></authors><title>Defect Prevention Approaches In Medium Scale It Enterprises</title><categories>cs.SE</categories><comments>5 pages</comments><journal-ref>National Conference on Recent Research Trends in Information
  Technology, pp 134-138, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The software industry is successful, if it can draw the complete attention of
the customers towards it. This is achievable if the organization can produce a
high quality product. To identify a product to be of high quality, it should be
free of defects, should be capable of producing expected results. It should be
delivered in an estimated cost, time and be maintainable with minimum effort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4135</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4135</id><created>2010-01-23</created><authors><author><keyname>Jayarekha</keyname><forenames>P.</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author></authors><title>An Adaptive Dynamic Replacement Approach for a Multicast based
  Popularity Aware Prefix Cache Memory System</title><categories>cs.MM</categories><comments>7 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we have proposed an adaptive dynamic cache replacement
algorithm for a multimedia servers cache system. The goal is to achieve an
effective utilization of the cache memory which stores the prefix of popular
videos. A replacement policy is usually evaluated using hit ratio, the
frequency with which any video is requested. Usually discarding the least
recently used page is the policy of choice in cache management. The adaptive
dynamic replacement approach for prefix cache is a self tuning, low overhead
algorithm that responds online to changing access patterns. It constantly
balances between lru and lfu to improve combined result. It automatically
adapts to evolving workloads. Since in our algorithm we have considered a
prefix caching with multicast transmission of popular objects it utilizes the
hard disk and network bandwidth efficiently and increases the number of
requests being served.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4136</identifier>
 <datestamp>2011-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4136</id><created>2010-01-23</created><authors><author><keyname>Madhuri</keyname><forenames>K. Lakshmi</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author></authors><title>Authentication and Authorization in Server Systems for Bio-Informatics</title><categories>cs.CR cs.IR</categories><journal-ref>International Conference TeamTech, pp 81, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Authentication and authorization are two tightly coupled and interrelated
concepts which are used to keep transactions secure and help in protecting
confidential information. This paper proposes to evaluate the current
techniques used for authentication and authorization also compares them with
the best practices and universally accepted authentication and authorization
methods. Authentication verifies user identity and provides reusable
credentials while authorization services stores information about user access
levels. These mechanisms by which a system checks what level of access a
particular authenticated user should have to view secure resources is
controlled by the system
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4137</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4137</id><created>2010-01-23</created><updated>2010-04-19</updated><authors><author><keyname>Shenvi</keyname><forenames>Sagar</forenames></author><author><keyname>Dey</keyname><forenames>Bikash Kumar</forenames></author></authors><title>On the solvability of 3-source 3-terminal sum-networks</title><categories>cs.IT math.IT</categories><comments>Major revision in the structure of the paper. 24 pages, 15 figures.
  Shorter version accepted to ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a directed acyclic network with three sources and three terminals
such that each source independently generates one symbol from a given field $F$
and each terminal wants to receive the sum (over $F$) of the source symbols.
Each link in the network is considered to be error-free and delay-free and can
carry one symbol from the field in each use. We call such a network a 3-source
3-terminal {\it $(3s/3t)$ sum-network}. In this paper, we give a necessary and
sufficient condition for a $3s/3t$ sum-network to allow all the terminals to
receive the sum of the source symbols over \textit{any} field. Some lemmas
provide interesting simpler sufficient conditions for the same. We show that
linear codes are sufficient for this problem for $3s/3t$ though they are known
to be insufficient for arbitrary number of sources and terminals. We further
show that in most cases, such networks are solvable by simple XOR coding. We
also prove a recent conjecture that if fractional coding is allowed, then the
coding capacity of a $3s/3t$ sum-network is either $0,2/3$ or $\geq 1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4140</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4140</id><created>2010-01-23</created><authors><author><keyname>Kisku</keyname><forenames>Dakshina Ranjan</forenames></author><author><keyname>Mehrotra</keyname><forenames>Hunny</forenames></author><author><keyname>Sing</keyname><forenames>Jamuna Kanta</forenames></author><author><keyname>Gupta</keyname><forenames>Phalguni</forenames></author></authors><title>SVM-based Multiview Face Recognition by Generalization of Discriminant
  Analysis</title><categories>cs.CV cs.LG</categories><comments>6 pages, 3 figures</comments><acm-class>D.2.2; I.2.10</acm-class><journal-ref>International Journal of Computer Systems Science and Engineering
  (formerly International Journal of Intelligent Systems and Technologies),
  vol. 3, no. 3, pp. 174--179, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identity verification of authentic persons by their multiview faces is a real
valued problem in machine vision. Multiview faces are having difficulties due
to non-linear representation in the feature space. This paper illustrates the
usability of the generalization of LDA in the form of canonical covariate for
face recognition to multiview faces. In the proposed work, the Gabor filter
bank is used to extract facial features that characterized by spatial
frequency, spatial locality and orientation. Gabor face representation captures
substantial amount of variations of the face instances that often occurs due to
illumination, pose and facial expression changes. Convolution of Gabor filter
bank to face images of rotated profile views produce Gabor faces with high
dimensional features vectors. Canonical covariate is then used to Gabor faces
to reduce the high dimensional feature spaces into low dimensional subspaces.
Finally, support vector machines are trained with canonical sub-spaces that
contain reduced set of features and perform recognition task. The proposed
system is evaluated with UMIST face database. The experiment results
demonstrate the efficiency and robustness of the proposed system with high
recognition rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4150</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4150</id><created>2010-01-23</created><authors><author><keyname>Dumas</keyname><forenames>Jean-Guillaume</forenames><affiliation>LJK</affiliation></author><author><keyname>Gautier</keyname><forenames>Thierry</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG Laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Roch</keyname><forenames>Jean-Louis</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG Laboratoire d'Informatique de Grenoble</affiliation></author></authors><title>Generic design of Chinese remaindering schemes</title><categories>cs.SC cs.DC</categories><proxy>ccsd hal-00449864</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a generic design for Chinese remainder algorithms. A Chinese
remainder computation consists in reconstructing an integer value from its
residues modulo non coprime integers. We also propose an efficient linear data
structure, a radix ladder, for the intermediate storage and computations. Our
design is structured into three main modules: a black box residue computation
in charge of computing each residue; a Chinese remaindering controller in
charge of launching the computation and of the termination decision; an integer
builder in charge of the reconstruction computation. We then show that this
design enables many different forms of Chinese remaindering (e.g.
deterministic, early terminated, distributed, etc.), easy comparisons between
these forms and e.g. user-transparent parallelism at different parallel grains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4181</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4181</id><created>2010-01-23</created><updated>2011-05-01</updated><authors><author><keyname>Derpich</keyname><forenames>Milan S.</forenames></author><author><keyname>&#xd8;stergaard</keyname><forenames>Jan</forenames></author></authors><title>Improved Upper Bounds to the Causal Quadratic Rate-Distortion Function
  for Gaussian Stationary Sources</title><categories>cs.IT math.IT</categories><comments>47 pages, revised version submitted to IEEE Trans. Information Theory</comments><acm-class>E.4; H.1.1</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We improve the existing achievable rate regions for causal and for zero-delay
source coding of stationary Gaussian sources under an average mean squared
error (MSE) distortion measure. To begin with, we find a closed-form expression
for the information-theoretic causal rate-distortion function (RDF) under such
distortion measure, denoted by $R_{c}^{it}(D)$, for first-order Gauss-Markov
processes. Rc^{it}(D) is a lower bound to the optimal performance theoretically
attainable (OPTA) by any causal source code, namely Rc^{op}(D). We show that,
for Gaussian sources, the latter can also be upper bounded as Rc^{op}(D)\leq
Rc^{it}(D) + 0.5 log_{2}(2\pi e) bits/sample. In order to analyze
$R_{c}^{it}(D)$ for arbitrary zero-mean Gaussian stationary sources, we
introduce \bar{Rc^{it}}(D), the information-theoretic causal RDF when the
reconstruction error is jointly stationary with the source. Based upon
\bar{Rc^{it}}(D), we derive three closed-form upper bounds to the additive rate
loss defined as \bar{Rc^{it}}(D) - R(D), where R(D) denotes Shannon's RDF. Two
of these bounds are strictly smaller than 0.5 bits/sample at all rates. These
bounds differ from one another in their tightness and ease of evaluation; the
tighter the bound, the more involved its evaluation. We then show that, for any
source spectral density and any positive distortion D\leq \sigma_{x}^{2},
\bar{Rc^{it}}(D) can be realized by an AWGN channel surrounded by a unique set
of causal pre-, post-, and feedback filters. We show that finding such filters
constitutes a convex optimization problem. In order to solve the latter, we
propose an iterative optimization procedure that yields the optimal filters and
is guaranteed to converge to \bar{Rc^{it}}(D). Finally, by establishing a
connection to feedback quantization we design a causal and a zero-delay coding
scheme which, for Gaussian sources, achieves...
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4184</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4184</id><created>2010-01-23</created><authors><author><keyname>Ahamed</keyname><forenames>S. S. Riaz</forenames></author></authors><title>Review and Analysis of Local Multipoint Distribution System (LMDS) to
  Deliver Voice, Data, Internet, and Video Services</title><categories>cs.NI</categories><comments>7 Pages</comments><journal-ref>IJEST Volume 1 Issue 1 2009 1-7</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Local multipoint distribution system (LMDS) uses cellular-like network
architecture of microwave radios placed at the client's location and at the
company's base station to deliver fixed services, mainly telephony, video and
Internet access. The use of time-division multiple access (TDMA) and FDMA
(frequency DMA) technology allows multiple customers within a 3-5 mile coverage
radius to share the same radio channel. Customers can receive data rates
between 64kbps to 155Mbps. LMDS was conceived as a broadband, fixed wireless,
point-to-multipoint technology for utilization in the last mile. Throughput
capacity and reliable distance of the link depends on common radio link
constraints and the modulation method used - either phase-shift keying or
amplitude modulation. In general deployment links of up to 5 miles (8 km) from
the base station are possible, but distance is typically limited to about 1.5
miles due to rain fading attenuation constraints. Point-to-point systems are
also capable of using the LMDS frequencies and can reach slightly farther
distances due to increased antenna gain.LMDS uses a scalable architecture
combined with industry standards to ensure service can be expanded as customer
demand increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4185</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4185</id><created>2010-01-23</created><authors><author><keyname>Ahamed</keyname><forenames>S. S. Riaz</forenames></author></authors><title>Technological Strategy of Using Global Positioning System: An Analysis</title><categories>cs.NI</categories><comments>9 Pages</comments><journal-ref>IJEST Volume 1 Issue 1 2009 8-16</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The Global Positioning System (GPS) is a U.S. space-based radionavigation
system that provides reliable positioning, navigation, and timing services to
civilian users on a continuous worldwide basis -- freely available to all. GPS
provides specially coded satellite signals that can be processed in a GPS
receiver, enabling the receiver to compute position, velocity and time.
Basically GPS works by using four GPS satellite signals to compute positions in
three dimensions (and the time offset) in the receiver clock. GPS provides
accurate location and time information for an unlimited number of people in all
weather, day and night, anywhere in the world. Anyone who needs to keep track
of where he or she is, to find his or her way to a specified location, or know
what direction and how fast he or she is going can utilize the benefits of the
global positioning system. Everyday activities such as banking, mobile phone
operations, and even the control of power grids, are facilitated by the
accurate timing provided by GPS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4186</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4186</id><created>2010-01-23</created><authors><author><keyname>J</keyname><forenames>Ravi.</forenames></author><author><keyname>Raja</keyname><forenames>K. B.</forenames></author><author><keyname>R</keyname><forenames>Venugopal. K.</forenames></author></authors><title>Fingerprint Recognition Using Minutia Score Matching</title><categories>cs.CR</categories><comments>8 Pages</comments><journal-ref>IJEST Volume 1 Issue 2 2009 35-42</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The popular Biometric used to authenticate a person is Fingerprint which is
unique and permanent throughout a person's life. A minutia matching is widely
used for fingerprint recognition and can be classified as ridge ending and
ridge bifurcation. In this paper we projected Fingerprint Recognition using
Minutia Score Matching method (FRMSM). For Fingerprint thinning, the Block
Filter is used, which scans the image at the boundary to preserves the quality
of the image and extract the minutiae from the thinned image. The false
matching ratio is better compared to the existing algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4189</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4189</id><created>2010-01-23</created><authors><author><keyname>Kekre</keyname><forenames>H. B.</forenames></author><author><keyname>Sarode</keyname><forenames>Tanuja K.</forenames></author><author><keyname>Gharge</keyname><forenames>Saylee M.</forenames></author></authors><title>Detection and Demarcation of Tumor using Vector Quantization in MRI
  images</title><categories>cs.CV</categories><comments>8 Pages</comments><report-no>IJEST09-01-02-04</report-no><journal-ref>IJEST Volume 1 Issue 2 2009 59-66</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Segmenting a MRI images into homogeneous texture regions representing
disparate tissue types is often a useful preprocessing step in the
computer-assisted detection of breast cancer. That is why we proposed new
algorithm to detect cancer in mammogram breast cancer images. In this paper we
proposed segmentation using vector quantization technique. Here we used Linde
Buzo-Gray algorithm (LBG) for segmentation of MRI images. Initially a codebook
of size 128 was generated for MRI images. These code vectors were further
clustered in 8 clusters using same LBG algorithm. These 8 images were displayed
as a result. This approach does not leads to over segmentation or under
segmentation. For the comparison purpose we displayed results of watershed
segmentation and Entropy using Gray Level Co-occurrence Matrix along with this
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4190</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4190</id><created>2010-01-23</created><authors><author><keyname>Srinivasan</keyname><forenames>A.</forenames></author><author><keyname>Rao</keyname><forenames>K. Srinivasa</forenames></author><author><keyname>Kannan</keyname><forenames>K.</forenames></author><author><keyname>Narasimhan</keyname><forenames>D.</forenames></author></authors><title>Speech Recognition of the letter 'zha' in Tamil Language using HMM</title><categories>cs.SD</categories><comments>6 Pages</comments><report-no>IJEST09-01-02-05</report-no><journal-ref>IJEST Volume 1 Issue 2 2009 67-72</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Speech signals of the letter 'zha' in Tamil language of 3 males and 3 females
were coded using an improved version of Linear Predictive Coding (LPC). The
sampling frequency was at 16 kHz and the bit rate was at 15450 bits per second,
where the original bit rate was at 128000 bits per second with the help of wave
surfer audio tool. The output LPC cepstrum is implemented in first order three
state Hidden Markov Model(HMM) chain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4191</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4191</id><created>2010-01-23</created><authors><author><keyname>Ahamed</keyname><forenames>S. S. Riaz</forenames></author><author><keyname>Mahesh</keyname><forenames>D.</forenames></author></authors><title>Performance Analysis and Special Issues of Broadband Strategies in the
  Computer Communication</title><categories>cs.NI</categories><comments>16 pages</comments><report-no>IJEST09-01-02-06</report-no><journal-ref>IJEST Volume 1 Issue 2 2009 73-89</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Broadband communications consists of the technologies and equipment required
to deliver packet-based digital voice, video, and data services to end users.
Broadband affords end users high-speed, always-on access to the Internet while
affording service providers the ability to offer value-added services to
increase revenues. Due to the growth of the Internet, there has been tremendous
buildout of high-speed, inter-city communications links that connect population
centers and Internet service providers (ISPs) points of presence (PoPs) around
the world. This build out of the backbone infrastructure or core network has
occurred primarily via optical transport technology. Broadband access
technologies are being deployed to address the bandwidth bottleneck for the
&quot;last mile,&quot; the connection of homes and small businesses to this
infrastructure. One important aspect of broadband access to the home is that it
allows people to telecommute effectively by providing a similar environment as
when they are physically present in their office: simultaneous telephone and
computer access, high-speed Internet and intranet access for e-mail, file
sharing, and access to corporate servers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4192</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4192</id><created>2010-01-23</created><authors><author><keyname>Ahamed</keyname><forenames>S. S. Riaz</forenames></author></authors><title>Review and Analysis of The Issues of Unified Modeling Language for
  Visualizing, Specifying, Constructing and Documenting the Artifacts of a
  Software-Intensive System</title><categories>cs.SE</categories><comments>19 Pages</comments><report-no>IJEST09-01-03-02</report-no><journal-ref>IJEST Volume 1 Issue 3 2009 100-118</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The UML allows us to specify models in a precise, complete and unambiguous
manner. In particular, the UML addresses the specification of all important
decisions regarding analysis, design and implementation. Although UML is not a
visual programming language, its models can be directly connected to a vast
variety of programming languages. This enables a dual approach to software
development: the developer has a choice as to the means of input. UML can be
used directly, from which code can be generated; or on the other hand, that
which is best expressed as text can be entered into the program as code. In an
ideal world, the UML tool will be able to reverse-engineer any direct changes
to code and the UML representations will be kept in sync with the code.
However, without human intervention this is not always possible. There are
certain elements of information that are lost when moving from models to code.
Even then, there are certain aspects of programming language code do seem to
preserve more of their semantics and therefore permits automatic
reverse-engineering of code back to a subset of the UML models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4193</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4193</id><created>2010-01-23</created><authors><author><keyname>Ahamed</keyname><forenames>S. S. Riaz</forenames></author></authors><title>Studying the Feasibility and Importance of Software Testing: An Analysis</title><categories>cs.SE</categories><comments>10 Pages</comments><report-no>IJEST09-01-03-03</report-no><journal-ref>IJEST Volume 1 Issue 3 2009 119-128</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Software testing is a critical element of software quality assurance and
represents the ultimate review of specification, design and coding. Software
testing is the process of testing the functionality and correctness of software
by running it. Software testing is usually performed for one of two reasons:
defect detection, and reliability estimation. The problem of applying software
testing to defect detection is that software can only suggest the presence of
flaws, not their absence (unless the testing is exhaustive). The problem of
applying software testing to reliability estimation is that the input
distribution used for selecting test cases may be flawed. The key to software
testing is trying to find the modes of failure - something that requires
exhaustively testing the code on all possible inputs. Software Testing,
depending on the testing method employed, can be implemented at any time in the
development process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4197</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4197</id><created>2010-01-23</created><authors><author><keyname>Nallusamy</keyname><forenames>R.</forenames></author><author><keyname>Duraiswamy</keyname><forenames>K.</forenames></author><author><keyname>Dhanalaksmi</keyname><forenames>R.</forenames></author><author><keyname>Parthiban</keyname><forenames>P.</forenames></author></authors><title>Optimization of Multiple Vehicle Routing Problems using Approximation
  Algorithms</title><categories>cs.DC</categories><comments>7 Pages</comments><report-no>IJEST09-01-03-04</report-no><journal-ref>IJEST Volume 1 Issue 3 2009 129-135</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper deals with generating of an optimized route for multiple Vehicle
routing Problems (mVRP). We used a methodology of clustering the given cities
depending upon the number of vehicles and each cluster is allotted to a
vehicle. k- Means clustering algorithm has been used for easy clustering of the
cities. In this way the mVRP has been converted into VRP which is simple in
computation compared to mVRP. After clustering, an optimized route is generated
for each vehicle in its allotted cluster. Once the clustering had been done and
after the cities were allocated to the various vehicles, each cluster/tour was
taken as an individual Vehicle Routing problem and the steps of Genetic
Algorithm were applied to the cluster and iterated to obtain the most optimal
value of the distance after convergence takes place. After the application of
the various heuristic techniques, it was found that the Genetic algorithm gave
a better result and a more optimal tour for mVRPs in short computational time
than other Algorithms due to the extensive search and constructive nature of
the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4199</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4199</id><created>2010-01-23</created><authors><author><keyname>Kim</keyname><forenames>Dong-Hyun</forenames></author><author><keyname>Jung</keyname><forenames>Woo-Ram</forenames></author><author><keyname>Youn</keyname><forenames>Chan-Hyun</forenames></author></authors><title>Hybrid Workflow Policy Management for Heart Disease Identification</title><categories>cs.OH physics.med-ph</categories><report-no>IJEST09-01-03-07</report-no><journal-ref>IJEST Volume 1 Issue 3 2009 153-159</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  As science technology grows, medical application is becoming more complex to
solve the physiological problems within expected time. Workflow management
systems (WMS) in Grid computing are promising solution to solve the
sophisticated problem such as genomic analysis, drug discovery, disease
identification, etc. Although existing WMS can provide basic management
functionality in Grid environment, consideration of user requirements such as
performance, reliability and interaction with user is missing. In this paper,
we propose hybrid workflow management system for heart disease identification
and discuss how to guarantee different user requirements according to user SLA.
The proposed system is applied to Physio-Grid e-health platform to identify
human heart disease with ECG analysis and Virtual Heart Simulation (VHS)
workflow applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4200</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4200</id><created>2010-01-23</created><authors><author><keyname>Venkateswari</keyname><forenames>P.</forenames></author><author><keyname>Purusothaman</keyname><forenames>Dr. T.</forenames></author></authors><title>Comparative Study of Protocols Used for Establishing VPN</title><categories>cs.NI</categories><comments>6 Pages</comments><report-no>IJEST09-01-03-08</report-no><journal-ref>IJEST Volume 1 Issue 3 2009 160-165</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This is an Internet era. Most of the organizations try to establish their
development centers and branch offices across the World. Employees working from
their homes are also becoming very popular and organizations benefit
financially by utilizing less office space, and reducing total expenses
incurred by having office workers on site. To meet such requirements
organizations develop a need to communicate with these offices over highly
secure, confidential and reliable connections regardless of the location of the
office. Here the VPN plays a vital role in establishing a distributed business
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4220</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4220</id><created>2010-01-23</created><updated>2013-10-01</updated><authors><author><keyname>Ripon</keyname><forenames>Shamim H.</forenames></author></authors><title>Modelling Variability for System Families</title><categories>cs.SE</categories><comments>This paper is withdrawn due to duplicate submission of the same paper</comments><acm-class>D.3.1</acm-class><journal-ref>Malaysian Journal of Computer Science, Vol. 16 No. 1, 2003</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an approach to facilitate the treatment with variabilities in
system families is presented by explicitly modelling variants. The proposed
method of managing variability consists of a variant part, which models
variants and a decision table to depict the customisation decision regarding
each variant. We have found that it is easy to implement and has advantage over
other methods. We present this model as an integral part of modelling system
families.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4231</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4231</id><created>2010-01-24</created><authors><author><keyname>King</keyname><forenames>James</forenames></author><author><keyname>Kirkpatrick</keyname><forenames>David</forenames></author></authors><title>Improved Approximation for Guarding Simple Galleries from the Perimeter</title><categories>cs.CG</categories><comments>16 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide an O(log log OPT)-approximation algorithm for the problem of
guarding a simple polygon with guards on the perimeter. We first design a
polynomial-time algorithm for building epsilon-nets of size O(1/epsilon log log
1/epsilon) for the instances of Hitting Set associated with our guarding
problem. We then apply the technique of Bronnimann and Goodrich to build an
approximation algorithm from this epsilon-net finder. Along with a simple
polygon P, our algorithm takes as input a finite set of potential guard
locations that must include the polygon's vertices. If a finite set of
potential guard locations is not specified, e.g. when guards may be placed
anywhere on the perimeter, we use a known discretization technique at the cost
of making the algorithm's running time potentially linear in the ratio between
the longest and shortest distances between vertices. Our algorithm is the first
to improve upon O(log OPT)-approximation algorithms that use generic net
finders for set systems of finite VC-dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4251</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4251</id><created>2010-01-24</created><authors><author><keyname>Aravantinos</keyname><forenames>Vincent</forenames></author><author><keyname>Caferra</keyname><forenames>Ricardo</forenames></author><author><keyname>Peltier</keyname><forenames>Nicolas</forenames></author></authors><title>A Decidable Class of Nested Iterated Schemata (extended version)</title><categories>cs.LO cs.AI</categories><comments>43 pages, extended version of &quot;A Decidable Class of Nested Iterated
  Schemata&quot;, submitted to IJCAR 2009</comments><acm-class>F.4.1; I.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many problems can be specified by patterns of propositional formulae
depending on a parameter, e.g. the specification of a circuit usually depends
on the number of bits of its input. We define a logic whose formulae, called
&quot;iterated schemata&quot;, allow to express such patterns. Schemata extend
propositional logic with indexed propositions, e.g. P_i, P_i+1, P_1, and with
generalized connectives, e.g. /\i=1..n or i=1..n (called &quot;iterations&quot;) where n
is an (unbound) integer variable called a &quot;parameter&quot;. The expressive power of
iterated schemata is strictly greater than propositional logic: it is even out
of the scope of first-order logic. We define a proof procedure, called DPLL*,
that can prove that a schema is satisfiable for at least one value of its
parameter, in the spirit of the DPLL procedure. However the converse problem,
i.e. proving that a schema is unsatisfiable for every value of the parameter,
is undecidable so DPLL* does not terminate in general. Still, we prove that it
terminates for schemata of a syntactic subclass called &quot;regularly nested&quot;. This
is the first non trivial class for which DPLL* is proved to terminate.
Furthermore the class of regularly nested schemata is the first decidable class
to allow nesting of iterations, i.e. to allow schemata of the form /\i=1..n
(/\j=1..n ...).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4252</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4252</id><created>2010-01-24</created><authors><author><keyname>Avendano</keyname><forenames>Martin</forenames></author><author><keyname>Ibrahim</keyname><forenames>Ashraf</forenames></author><author><keyname>Rojas</keyname><forenames>J. Maurice</forenames></author><author><keyname>Rusek</keyname><forenames>Korben</forenames></author></authors><title>Near NP-Completeness for Detecting p-adic Rational Roots in One Variable</title><categories>math.NT cs.CC math.AG</categories><comments>8 pages in 2 column format, 1 illustration. Submitted to a conference</comments><journal-ref>proceedings of International Symposium on Symbolic and Algebraic
  Computation (ISSAC 2010, July 25-28, 2010, Munchen), pp. 331-338, ACM Press,
  2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that deciding whether a sparse univariate polynomial has a p-adic
rational root can be done in NP for most inputs. We also prove a
polynomial-time upper bound for trinomials with suitably generic p-adic Newton
polygon. We thus improve the best previous complexity upper bound of EXPTIME.
We also prove an unconditional complexity lower bound of NP-hardness with
respect to randomized reductions for general univariate polynomials. The best
previous lower bound assumed an unproved hypothesis on the distribution of
primes in arithmetic progression. We also discuss how our results complement
analogous results over the real numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4255</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4255</id><created>2010-01-24</created><updated>2010-03-29</updated><authors><author><keyname>Meier</keyname><forenames>Arne</forenames></author><author><keyname>Schneider</keyname><forenames>Thomas</forenames></author></authors><title>The Complexity of Satisfiability for Sub-Boolean Fragments of ALC</title><categories>cs.LO cs.CC</categories><comments>17 pages, accepted (in short version) to Description Logic Workshop
  2010</comments><acm-class>I.2.4; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The standard reasoning problem, concept satisfiability, in the basic
description logic ALC is PSPACE-complete, and it is EXPTIME-complete in the
presence of unrestricted axioms. Several fragments of ALC, notably logics in
the FL, EL, and DL-Lite family, have an easier satisfiability problem;
sometimes it is even tractable. All these fragments restrict the use of Boolean
operators in one way or another. We look at systematic and more general
restrictions of the Boolean operators and establish the complexity of the
concept satisfiability problem in the presence of axioms. We separate tractable
from intractable cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4267</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4267</id><created>2010-01-24</created><authors><author><keyname>Viznyuk</keyname><forenames>Sergei</forenames></author></authors><title>Thermodynamic properties of finite binary strings</title><categories>cs.IT math.IT</categories><comments>6 pages, 1 figure, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Thermodynamic properties such as temperature, pressure, and internal energy
have been defined for finite binary strings from equilibrium distribution of a
chosen computable measure. It is demonstrated a binary string can be associated
with one-dimensional gas of quasi-particles of certain mass, momentum, and
energy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4271</identifier>
 <datestamp>2011-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4271</id><created>2010-01-24</created><updated>2011-11-15</updated><authors><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author><author><keyname>Avestimehr</keyname><forenames>A. Salman</forenames></author><author><keyname>Khajehnejad</keyname><forenames>M. Amin</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Divide-and-conquer: Approaching the capacity of the two-pair
  bidirectional Gaussian relay network</title><categories>cs.IT math.IT</categories><comments>IEEE Trans. on Information Theory, accepted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity region of multi-pair bidirectional relay networks, in which a
relay node facilitates the communication between multiple pairs of users, is
studied. This problem is first examined in the context of the linear shift
deterministic channel model. The capacity region of this network when the relay
is operating at either full-duplex mode or half-duplex mode for arbitrary
number of pairs is characterized. It is shown that the cut-set upper-bound is
tight and the capacity region is achieved by a so called divide-and-conquer
relaying strategy. The insights gained from the deterministic network are then
used for the Gaussian bidirectional relay network. The strategy in the
deterministic channel translates to a specific superposition of lattice codes
and random Gaussian codes at the source nodes and successive interference
cancelation at the receiving nodes for the Gaussian network. The achievable
rate of this scheme with two pairs is analyzed and it is shown that for all
channel gains it achieves to within 3 bits/sec/Hz per user of the cut-set
upper-bound. Hence, the capacity region of the two-pair bidirectional Gaussian
relay network to within 3 bits/sec/Hz per user is characterized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4273</identifier>
 <datestamp>2010-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4273</id><created>2010-01-24</created><authors><author><keyname>Jonnalagadda</keyname><forenames>Siddhartha</forenames></author><author><keyname>Gonzalez</keyname><forenames>Graciela</forenames></author></authors><title>Sentence Simplification Aids Protein-Protein Interaction Extraction</title><categories>cs.CL</categories><comments>6 pages, The 3rd International Symposium on Languages in Biology and
  Medicine, Jeju Island, South Korea, November 8-10, 2009</comments><journal-ref>The 3rd International Symposium on Languages in Biology and
  Medicine, Jeju Island, South Korea, November 8-10, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate systems for extracting Protein-Protein Interactions (PPIs)
automatically from biomedical articles can help accelerate biomedical research.
Biomedical Informatics researchers are collaborating to provide metaservices
and advance the state-of-art in PPI extraction. One problem often neglected by
current Natural Language Processing systems is the characteristic complexity of
the sentences in biomedical literature. In this paper, we report on the impact
that automatic simplification of sentences has on the performance of a
state-of-art PPI extraction system, showing a substantial improvement in recall
(8%) when the sentence simplification method is applied, without significant
impact to precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4274</identifier>
 <datestamp>2010-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4274</id><created>2010-01-24</created><updated>2010-03-17</updated><authors><author><keyname>Jonnalagadda</keyname><forenames>Siddhartha</forenames></author><author><keyname>Topham</keyname><forenames>Philip</forenames></author><author><keyname>Gonzalez</keyname><forenames>Graciela</forenames></author></authors><title>ONER: Tool for Organization Named Entity Recognition from Affiliation
  Strings in PubMed Abstracts</title><categories>cs.DL</categories><comments>This paper has been withdrawn; The 3rd International Symposiumon
  Languages in Biology and Medicine, Jeju Island, South Korea, November 8-10,
  2009; http://lbm2009.biopathway.org/download.php?id=304</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatically extracting organization names from the affiliation sentences of
articles related to biomedicine is of great interest to the pharmaceutical
marketing industry, health care funding agencies and public health officials.
It will also be useful for other scientists in normalizing author names,
automatically creating citations, indexing articles and identifying potential
resources or collaborators. Today there are more than 18 million articles
related to biomedical research indexed in PubMed, and information derived from
them could be used effectively to save the great amount of time and resources
spent by government agencies in understanding the scientific landscape,
including key opinion leaders and centers of excellence. Our process for
extracting organization names involves multi-layered rule matching with
multiple dictionaries. The system achieves 99.6% f-measure in extracting
organization names.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4276</identifier>
 <datestamp>2010-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4276</id><created>2010-01-24</created><updated>2010-03-17</updated><authors><author><keyname>Jonnalagadda</keyname><forenames>Siddhartha</forenames></author><author><keyname>Topham</keyname><forenames>Philip</forenames></author><author><keyname>Gonzalez</keyname><forenames>Graciela</forenames></author></authors><title>Towards Automatic Extraction of Social Networks of Organizations in
  PubMed Abstracts</title><categories>cs.DL</categories><comments>This paper has been withdrawn; First International Workshop on Graph
  Techniques for Biomedical Networks in Conjunction with IEEE International
  Conference on Bioinformatics and Biomedicine, Washington D.C., USA, Nov. 1-4,
  2009; http://www.public.asu.edu/~sjonnal3/home/papers/IEEE%20BIBM%202009.pdf</comments><doi>10.1109/BIBMW.2009.5332108</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social Network Analysis (SNA) of organizations can attract great interest
from government agencies and scientists for its ability to boost translational
research and accelerate the process of converting research to care. For SNA of
a particular disease area, we need to identify the key research groups in that
area by mining the affiliation information from PubMed. This not only involves
recognizing the organization names in the affiliation string, but also
resolving ambiguities to identify the article with a unique organization. We
present here a process of normalization that involves clustering based on local
sequence alignment metrics and local learning based on finding connected
components. We demonstrate the application of the method by analyzing
organizations involved in angiogenensis treatment, and demonstrating the
utility of the results for researchers in the pharmaceutical and biotechnology
industries or national funding agencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4277</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4277</id><created>2010-01-24</created><authors><author><keyname>Jonnalagadda</keyname><forenames>Siddhartha</forenames></author><author><keyname>Tari</keyname><forenames>Luis</forenames></author><author><keyname>Hakenberg</keyname><forenames>Jorg</forenames></author><author><keyname>Baral</keyname><forenames>Chitta</forenames></author><author><keyname>Gonzalez</keyname><forenames>Graciela</forenames></author></authors><title>Towards Effective Sentence Simplification for Automatic Processing of
  Biomedical Text</title><categories>cs.CL</categories><comments>4 pages, In Proc. of the NAACL-HLT 2009, Boulder, USA, June</comments><journal-ref>Proc. of the NAACL-HLT 2009, Boulder, USA, June 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The complexity of sentences characteristic to biomedical articles poses a
challenge to natural language parsers, which are typically trained on
large-scale corpora of non-technical text. We propose a text simplification
process, bioSimplify, that seeks to reduce the complexity of sentences in
biomedical abstracts in order to improve the performance of syntactic parsers
on the processed sentences. Syntactic parsing is typically one of the first
steps in a text mining pipeline. Thus, any improvement in performance would
have a ripple effect over all processing steps. We evaluated our method using a
corpus of biomedical sentences annotated with syntactic links. Our empirical
results show an improvement of 2.90% for the Charniak-McClosky parser and of
4.23% for the Link Grammar parser when processing simplified sentences rather
than the original sentences in the corpus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4278</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4278</id><created>2010-01-24</created><updated>2011-07-28</updated><authors><author><keyname>Jafarizadeh</keyname><forenames>Saber</forenames></author><author><keyname>Jamalipour</keyname><forenames>Abbas</forenames></author></authors><title>Weight Optimization for Distributed Average Consensus Algorithm in
  Symmetric, CCS &amp; KCS Star Networks</title><categories>cs.IT cs.DC math.CO math.IT</categories><comments>10 pages, 4 Figures, 5 Tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses weight optimization problem in distributed consensus
averaging algorithm over networks with symmetric star topology. We have
determined optimal weights and convergence rate of the network in terms of its
topological parameters. In addition, two alternative topologies with more rapid
convergence rates have been introduced. The new topologies are Complete-Cored
Symmetric (CCS) star and K-Cored Symmetric (KCS) star topologies. It has been
shown that the optimal weights for the edges of central part in symmetric and
CCS star configurations are independent of their branches. By simulation
optimality of obtained weights under quantization constraints have been
verified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4293</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4293</id><created>2010-01-24</created><authors><author><keyname>Nixon</keyname><forenames>David</forenames></author><author><keyname>O'Hara</keyname><forenames>Mike</forenames></author></authors><title>Spreadsheet Auditing Software</title><categories>cs.SE cs.HC</categories><comments>14 Pages, 5 Figures. All the comparisons are now out of date however
  all the auditing software studied is still available for further historical
  and comparative analysis. Minor Edits and referencing of the original paper
  by GJC in Jan 2010. In memory of Mike O' Hara</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2000 ISBN:1
  86166 158 4</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is now widely accepted that errors in spreadsheets are both common and
potentially dangerous. Further research has taken place to investigate how
frequently these errors occur, what impact they have, how the risk of
spreadsheet errors can be reduced by following spreadsheet design guidelines
and methodologies, and how effective auditing of a spreadsheet is in the
detection of these errors. However, little research exists to establish the
usefulness of software tools in the auditing of spreadsheets. This paper
documents and tests office software tools designed to assist in the audit of
spreadsheets. The test was designed to identify the success of software tools
in detecting different types of errors, to identify how the software tools
assist the auditor and to determine the usefulness of the tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4295</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4295</id><created>2010-01-24</created><authors><author><keyname>Reeves</keyname><forenames>Galen</forenames></author><author><keyname>Gastpar</keyname><forenames>Michael</forenames></author></authors><title>&quot;Compressed&quot; Compressed Sensing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The field of compressed sensing has shown that a sparse but otherwise
arbitrary vector can be recovered exactly from a small number of randomly
constructed linear projections (or samples). The question addressed in this
paper is whether an even smaller number of samples is sufficient when there
exists prior knowledge about the distribution of the unknown vector, or when
only partial recovery is needed. An information-theoretic lower bound with
connections to free probability theory and an upper bound corresponding to a
computationally simple thresholding estimator are derived. It is shown that in
certain cases (e.g. discrete valued vectors or large distortions) the number of
samples can be decreased. Interestingly though, it is also shown that in many
cases no reduction is possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4297</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4297</id><created>2010-01-24</created><authors><author><keyname>Straw</keyname><forenames>Andrew D.</forenames></author><author><keyname>Branson</keyname><forenames>Kristin</forenames></author><author><keyname>Neumann</keyname><forenames>Titus R.</forenames></author><author><keyname>Dickinson</keyname><forenames>Michael H.</forenames></author></authors><title>Multi-camera Realtime 3D Tracking of Multiple Flying Animals</title><categories>cs.CV</categories><comments>pdfTeX using libpoppler 3.141592-1.40.3-2.2 (Web2C 7.5.6), 18 pages
  with 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated tracking of animal movement allows analyses that would not
otherwise be possible by providing great quantities of data. The additional
capability of tracking in realtime - with minimal latency - opens up the
experimental possibility of manipulating sensory feedback, thus allowing
detailed explorations of the neural basis for control of behavior. Here we
describe a new system capable of tracking the position and body orientation of
animals such as flies and birds. The system operates with less than 40 msec
latency and can track multiple animals simultaneously. To achieve these
results, a multi target tracking algorithm was developed based on the Extended
Kalman Filter and the Nearest Neighbor Standard Filter data association
algorithm. In one implementation, an eleven camera system is capable of
tracking three flies simultaneously at 60 frames per second using a gigabit
network of nine standard Intel Pentium 4 and Core 2 Duo computers. This
manuscript presents the rationale and details of the algorithms employed and
shows three implementations of the system. An experiment was performed using
the tracking system to measure the effect of visual contrast on the flight
speed of Drosophila melanogaster. At low contrasts, speed is more variable and
faster on average than at high contrasts. Thus, the system is already a useful
tool to study the neurobiology and behavior of freely flying animals. If
combined with other techniques, such as `virtual reality'-type computer
graphics or genetic manipulation, the tracking system would offer a powerful
new way to investigate the biology of flying animals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4298</identifier>
 <datestamp>2010-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4298</id><created>2010-01-24</created><updated>2010-06-02</updated><authors><author><keyname>Kabashima</keyname><forenames>Yoshiyuki</forenames></author><author><keyname>Wadayama</keyname><forenames>Tadashi</forenames></author><author><keyname>Tanaka</keyname><forenames>Toshiyuki</forenames></author></authors><title>Statistical Mechanical Analysis of a Typical Reconstruction Limit of
  Compressed Sensing</title><categories>cs.IT cond-mat.dis-nn math.IT</categories><comments>5 pages, 2 figures, accepted for presentation in ISIT2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use the replica method of statistical mechanics to examine a typical
performance of correctly reconstructing $N$-dimensional sparse vector
$bx=(x_i)$ from its linear transformation $by=bF bx$ of $P$ dimensions on the
basis of minimization of the $L_p$-norm $||bx||_p= lim_{epsilon to +0}
sum_{i=1}^N |x_i|^{p+epsilon}$. We characterize the reconstruction performance
by the critical relation of the successful reconstruction between the ratio
$alpha=P/N$ and the density $rho$ of non-zero elements in $bx$ in the limit
$P,,N to infty$ while keeping $alpha sim O(1)$ and allowing asymptotically
negligible reconstruction errors. We show that the critical relation
$alpha_c(rho)$ holds universally as long as $bF^{rm T}bF$ can be characterized
asymptotically by a rotationally invariant random matrix ensemble and $bF
bF^{rm T}$ is typically of full rank. This supports the universality of the
critical relation observed by Donoho and Tanner ({em Phil. Trans. R. Soc. A},
vol.~367, pp.~4273--4293, 2009; arXiv: 0807.3590) for various ensembles of
compression matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4299</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4299</id><created>2010-01-24</created><authors><author><keyname>Emmett</keyname><forenames>Hilary L.</forenames></author><author><keyname>Goldman</keyname><forenames>Lawrence I.</forenames></author></authors><title>Identification of Logical Errors through Monte-Carlo Simulation</title><categories>cs.SE</categories><comments>8 Pages, 10 Colour Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2004 ISBN 1
  902724 94 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The primary focus of Monte Carlo simulation is to identify and quantify risk
related to uncertainty and variability in spreadsheet model inputs. The stress
of Monte Carlo simulation often reveals logical errors in the underlying
spreadsheet model that might be overlooked during day-to-day use or traditional
&quot;what-if&quot; testing. This secondary benefit of simulation requires a trained eye
to recognize warning signs of poor model construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4301</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4301</id><created>2010-01-24</created><authors><author><keyname>Jankovic</keyname><forenames>Marko V.</forenames></author></authors><title>Probabilistic Approach to Neural Networks Computation Based on Quantum
  Probability Model Probabilistic Principal Subspace Analysis Example</title><categories>cs.NE cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce elements of probabilistic model that is suitable
for modeling of learning algorithms in biologically plausible artificial neural
networks framework. Model is based on two of the main concepts in quantum
physics - a density matrix and the Born rule. As an example, we will show that
proposed probabilistic interpretation is suitable for modeling of on-line
learning algorithms for PSA, which are preferably realized by a parallel
hardware based on very simple computational units. Proposed concept (model) can
be used in the context of improving algorithm convergence speed, learning
factor choice, or input signal scale robustness. We are going to see how the
Born rule and the Hebbian learning rule are connected
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4305</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4305</id><created>2010-01-24</created><authors><author><keyname>Cao</keyname><forenames>Xiwang</forenames></author><author><keyname>Hu</keyname><forenames>Lei</forenames></author></authors><title>On Exponential Sums, Nowton identities and Dickson Polynomials over
  Finite Fields</title><categories>cs.IT math.IT</categories><comments>18 pages</comments><msc-class>11T23</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\mathbb{F}_{q}$ be a finite field, $\mathbb{F}_{q^s}$ be an extension of
$\mathbb{F}_q$, let $f(x)\in \mathbb{F}_q[x]$ be a polynomial of degree $n$
with $\gcd(n,q)=1$. We present a recursive formula for evaluating the
exponential sum $\sum_{c\in \mathbb{F}_{q^s}}\chi^{(s)}(f(x))$. Let $a$ and $b$
be two elements in $\mathbb{F}_q$ with $a\neq 0$, $u$ be a positive integer. We
obtain an estimate for the exponential sum $\sum_{c\in
\mathbb{F}^*_{q^s}}\chi^{(s)}(ac^u+bc^{-1})$, where $\chi^{(s)}$ is the lifting
of an additive character $\chi$ of $\mathbb{F}_q$. Some properties of the
sequences constructed from these exponential sums are provided also.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4334</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4334</id><created>2010-01-25</created><authors><author><keyname>Kurmaev</keyname><forenames>Oleg F.</forenames></author></authors><title>An Enumerative Method for Encoding Spectrum Shaped Binary Run-Length
  Constrained Sequences</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, 2 tables, submitted to ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method for encoding and decoding spectrum shaped binary run-length
constrained sequences is described. The binary sequences with predefined range
of exponential sums are introduced. On the base of Cover's enumerative scheme,
recurrence relations for calculating the number of these sequences are derived.
Implementation of encoding and decoding procedures is also shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4341</identifier>
 <datestamp>2011-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4341</id><created>2010-01-25</created><authors><author><keyname>Dereniowski</keyname><forenames>Dariusz</forenames></author></authors><title>Connected searching of weighted trees</title><categories>cs.DS cs.DM</categories><report-no>Technical Report no 21/2009, Faculty of Electronics,
  Telecommunications and Informatics, Gdansk University of Technology</report-no><journal-ref>Theoretical Computer Science 412 (2011) 5700-5713</journal-ref><doi>10.1016/j.tcs.2011.06.017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of connected edge searching of weighted
trees. It is shown that there exists a polynomial-time algorithm for finding
optimal connected search strategy for bounded degree trees with arbitrary
weights on the edges and vertices of the tree. The problem is NP-complete for
general node-weighted trees (the weight of each edge is 1).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4361</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4361</id><created>2010-01-25</created><updated>2010-07-07</updated><authors><author><keyname>Takeda</keyname><forenames>Koujin</forenames></author><author><keyname>Kabashima</keyname><forenames>Yoshiyuki</forenames></author></authors><title>Statistical Mechanical Analysis of Compressed Sensing Utilizing
  Correlated Compression Matrix</title><categories>cs.IT cond-mat.dis-nn math.IT</categories><comments>5 pages, 3 figures</comments><journal-ref>ISIT 2010 proceedings pp.1538-1542</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate a reconstruction limit of compressed sensing for a
reconstruction scheme based on the L1-norm minimization utilizing a correlated
compression matrix with a statistical mechanics method. We focus on the
compression matrix modeled as the Kronecker-type random matrix studied in
research on multi-input multi-output wireless communication systems. We found
that strong one-dimensional correlations between expansion bases of original
information slightly degrade reconstruction performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4368</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4368</id><created>2010-01-25</created><authors><author><keyname>Hellsten</keyname><forenames>Iina</forenames></author><author><keyname>Dawson</keyname><forenames>James</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Implicit media frames: Automated analysis of public debate on artificial
  sweeteners</title><categories>cs.IR cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The framing of issues in the mass media plays a crucial role in the public
understanding of science and technology. This article contributes to research
concerned with diachronic analysis of media frames by making an analytical
distinction between implicit and explicit media frames, and by introducing an
automated method for analysing diachronic changes of implicit frames. In
particular, we apply a semantic maps method to a case study on the newspaper
debate about artificial sweeteners, published in The New York Times (NYT)
between 1980 and 2006. Our results show that the analysis of semantic changes
enables us to filter out the dynamics of implicit frames, and to detect
emerging metaphors in public debates. Theoretically, we discuss the relation
between implicit frames in public debates and codification of information in
scientific discourses, and suggest further avenues for research interested in
the automated analysis of frame changes and trends in public debates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4381</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4381</id><created>2010-01-25</created><authors><author><keyname>Zantema</keyname><forenames>Hans</forenames><affiliation>TU Eindhoven</affiliation></author><author><keyname>Raffelsieper</keyname><forenames>Matthias</forenames><affiliation>TU Eindhoven</affiliation></author></authors><title>Stream Productivity by Outermost Termination</title><categories>cs.LO cs.PL</categories><journal-ref>EPTCS 15, 2010, pp. 83-95</journal-ref><doi>10.4204/EPTCS.15.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Streams are infinite sequences over a given data type. A stream specification
is a set of equations intended to define a stream. A core property is
productivity: unfolding the equations produces the intended stream in the
limit. In this paper we show that productivity is equivalent to termination
with respect to the balanced outermost strategy of a TRS obtained by adding an
additional rule. For specifications not involving branching symbols
balancedness is obtained for free, by which tools for proving outermost
termination can be used to prove productivity fully automatically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4382</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4382</id><created>2010-01-25</created><updated>2011-02-17</updated><authors><author><keyname>Zwecher</keyname><forenames>Elchanan</forenames></author><author><keyname>Porrat</keyname><forenames>Dana</forenames></author></authors><title>Training Over Sparse Multipath Channels in the Low SNR Regime</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Training over sparse multipath channels is explored. The energy allocation
and the optimal shape of training signals that enable error free communications
over unknown channels are characterized as a function of the channels'
statistics. The performance of training is evaluated by the reduction of the
mean square error of the channel estimate and by the decrease in the
uncertainty of the channel. A connection between the entropy of the wideband
channel and the required energy for training is shown. In addition, there is a
linkage between the sparsity and the entropy of the channel to the number of
required channel measurements when the training is based on compressed sensing.
The ability to learn the channel from few measurements is connected to the low
entropy of sparse channels that enables training in the low SNR regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4387</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4387</id><created>2010-01-25</created><updated>2010-06-19</updated><authors><author><keyname>Carmi</keyname><forenames>Avishy</forenames></author><author><keyname>Gurfil</keyname><forenames>Pini</forenames></author></authors><title>Convex Feasibility Methods for Compressed Sensing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a computationally-efficient method for recovering sparse signals
from a series of noisy observations, known as the problem of compressed sensing
(CS). CS theory requires solving a convex constrained minimization problem. We
propose to transform this optimization problem into a convex feasibility
problem (CFP), and solve it using subgradient projection methods, which are
iterative, fast, robust and convergent schemes for solving CFPs. As opposed to
some of the recently-introduced CS algorithms, such as Bayesian CS and gradient
projections for sparse reconstruction, which become inefficient as the problem
dimension and sparseness degree increase, the newly-proposed methods exhibit a
marked robustness with respect to these factors. This renders the subgradient
projection methods highly viable for large-scale compressible scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4405</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4405</id><created>2010-01-25</created><authors><author><keyname>McGinnis</keyname><forenames>Jarred</forenames><affiliation>Royal Holloway, University of London</affiliation></author><author><keyname>Stathis</keyname><forenames>Kostas</forenames><affiliation>Royal Holloway, University of London</affiliation></author><author><keyname>Toni</keyname><forenames>Francesca</forenames><affiliation>Imperial College London</affiliation></author></authors><title>A Formal Framework of Virtual Organisations as Agent Societies</title><categories>cs.LO cs.AI cs.MA</categories><journal-ref>EPTCS 16, 2010, pp. 1-14</journal-ref><doi>10.4204/EPTCS.16.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a formal framework that supports a model of agent-based Virtual
Organisations (VOs) for service grids and provides an associated operational
model for the creation of VOs. The framework is intended to be used for
describing different service grid applications based on multiple agents and, as
a result, it abstracts away from any realisation choices of the service grid
application, the agents involved to support the applications and their
interactions. Within the proposed framework VOs are seen as emerging from
societies of agents, where agents are abstractly characterised by goals and
roles they can play within VOs. In turn, VOs are abstractly characterised by
the agents participating in them with specific roles, as well as the workflow
of services and corresponding contracts suitable for achieving the goals of the
participating agents. We illustrate the proposed framework with an earth
observation scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4411</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4411</id><created>2010-01-25</created><authors><author><keyname>Mozolevsky</keyname><forenames>Igor</forenames><affiliation>University of Newcastle</affiliation></author><author><keyname>Fitzgerald</keyname><forenames>John</forenames><affiliation>University of Newcastle</affiliation></author></authors><title>Common Representation of Information Flows for Dynamic Coalitions</title><categories>cs.CR</categories><journal-ref>EPTCS 16, 2010, pp. 15-25</journal-ref><doi>10.4204/EPTCS.16.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a formal foundation for reasoning about access control policies
within a Dynamic Coalition, defining an abstraction over existing access
control models and providing mechanisms for translation of those models into
information-flow domain. The abstracted information-flow domain model, called a
Common Representation, can then be used for defining a way to control the
evolution of Dynamic Coalitions with respect to information flow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4413</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4413</id><created>2010-01-25</created><authors><author><keyname>Bocchi</keyname><forenames>Laura</forenames></author><author><keyname>Fiadeiro</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Rajper</keyname><forenames>Noor</forenames></author><author><keyname>Reiff-Marganiec</keyname><forenames>Stephan</forenames></author></authors><title>Structure and Behaviour of Virtual Organisation Breeding Environments</title><categories>cs.SE cs.MA</categories><journal-ref>EPTCS 16, 2010, pp. 26-40</journal-ref><doi>10.4204/EPTCS.16.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides an outline of a formal approach that we are developing
for modelling Virtual Organisations (VOs) and their Breeding Environments
(VBEs). We propose different levels of representation for the functional
structures and processes that VBEs and VOs involve, which are independent of
the specificities of the infrastructures (organisational and technical) that
support the functioning of VBEs. This allows us to reason about properties of
tasks performed within VBEs and services provided through VOs without
committing to the way in which they are implemented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4419</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4419</id><created>2010-01-25</created><authors><author><keyname>Johnson</keyname><forenames>Peter</forenames></author><author><keyname>Hourizi</keyname><forenames>Rachid</forenames></author><author><keyname>Carrigan</keyname><forenames>Neil</forenames></author><author><keyname>Forbes</keyname><forenames>Nick</forenames></author></authors><title>A Framework to Manage the Complex Organisation of Collaborating: Its
  Application to Autonomous Systems</title><categories>cs.MA</categories><journal-ref>EPTCS 16, 2010, pp. 51-63</journal-ref><doi>10.4204/EPTCS.16.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present an analysis of the complexities of large group
collaboration and its application to develop detailed requirements for
collaboration schema for Autonomous Systems (AS). These requirements flow from
our development of a framework for collaboration that provides a basis for
designing, supporting and managing complex collaborative systems that can be
applied and tested in various real world settings. We present the concepts of
&quot;collaborative flow&quot; and &quot;working as one&quot; as descriptive expressions of what
good collaborative teamwork can be in such scenarios. The paper considers the
application of the framework within different scenarios and discuses the
utility of the framework in modelling and supporting collaboration in complex
organisational structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4420</identifier>
 <datestamp>2011-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4420</id><created>2010-01-25</created><updated>2011-06-09</updated><authors><author><keyname>Clifford</keyname><forenames>Raphael</forenames></author><author><keyname>Jalsenius</keyname><forenames>Markus</forenames></author><author><keyname>Montanaro</keyname><forenames>Ashley</forenames></author><author><keyname>Sach</keyname><forenames>Benjamin</forenames></author></authors><title>The Complexity of Flood Filling Games</title><categories>cs.DS</categories><comments>20 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of the popular one player combinatorial game known as
Flood-It. In this game the player is given an n by n board of tiles where each
tile is allocated one of c colours. The goal is to make the colours of all
tiles equal via the shortest possible sequence of flooding operations. In the
standard version, a flooding operation consists of the player choosing a colour
k, which then changes the colour of all the tiles in the monochromatic region
connected to the top left tile to k. After this operation has been performed,
neighbouring regions which are already of the chosen colour k will then also
become connected, thereby extending the monochromatic region of the board. We
show that finding the minimum number of flooding operations is NP-hard for c&gt;=3
and that this even holds when the player can perform flooding operations from
any position on the board. However, we show that this &quot;free&quot; variant is in P
for c=2. We also prove that for an unbounded number of colours, Flood-It
remains NP-hard for boards of height at least 3, but is in P for boards of
height 2. Next we show how a c-1 approximation and a randomised 2c/3
approximation algorithm can be derived, and that no polynomial time constant
factor, independent of c, approximation algorithm exists unless P=NP. We then
investigate how many moves are required for the &quot;most demanding&quot; n by n boards
(those requiring the most moves) and show that the number grows as fast as
Theta(n*c^0.5). Finally, we consider boards where the colours of the tiles are
chosen at random and show that for c&gt;=2, the number of moves required to flood
the whole board is Omega(n) with high probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4423</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4423</id><created>2010-01-25</created><authors><author><keyname>Mousavi</keyname><forenames>Ali</forenames></author><author><keyname>Pad</keyname><forenames>Pedram</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>A New Decoding Scheme for Errorless Codes for Overloaded CDMA with
  Active User Detection</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, a new class of binary codes for overloaded CDMA systems are
proposed that not only has the ability of errorless communication but also
suitable for detecting active users. These codes are called COWDA [1]. In [1],
a Maximum Likelihood (ML) decoder is proposed for this class of codes. Although
the proposed scheme of coding/decoding show impressive performance, the decoder
can be improved. In this paper by assuming more practical conditions for the
traffic in the system, we suggest an algorithm that increases the performance
of the decoder several orders of magnitude (the Bit-Error-Rate (BER) is divided
by a factor of 400 in some Eb/N0's The algorithm supposes the Poison
distribution for the time of activation/deactivation of the users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4427</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4427</id><created>2010-01-25</created><authors><author><keyname>Bourdier</keyname><forenames>Tony</forenames><affiliation>INRIA Nancy Grand-Est</affiliation></author><author><keyname>Cirstea</keyname><forenames>Horatiu</forenames><affiliation>INRIA Nancy Grand-Est</affiliation></author><author><keyname>Dougherty</keyname><forenames>Daniel</forenames><affiliation>Worcester Polytechnic Institute</affiliation></author><author><keyname>Kirchner</keyname><forenames>H&#xe9;l&#xe8;ne</forenames><affiliation>INRIA Bordeaux Sud-Ouest</affiliation></author></authors><title>Extensional and Intensional Strategies</title><categories>cs.GT cs.LO cs.PL</categories><acm-class>F.3.3; I.2.8</acm-class><journal-ref>EPTCS 15, 2010, pp. 1-19</journal-ref><doi>10.4204/EPTCS.15.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is a contribution to the theoretical foundations of strategies. We
first present a general definition of abstract strategies which is extensional
in the sense that a strategy is defined explicitly as a set of derivations of
an abstract reduction system. We then move to a more intensional definition
supporting the abstract view but more operational in the sense that it
describes a means for determining such a set. We characterize the class of
extensional strategies that can be defined intensionally. We also give some
hints towards a logical characterization of intensional strategies and propose
a few challenging perspectives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4429</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4429</id><created>2010-01-25</created><authors><author><keyname>Bonelli</keyname><forenames>Eduardo</forenames><affiliation>CONICET and Universidad Nacional de Quilmes, Argentina</affiliation></author><author><keyname>Barenbaum</keyname><forenames>Pablo</forenames><affiliation>Universidad de Buenos Aires, Argentina</affiliation></author></authors><title>Superdevelopments for Weak Reduction</title><categories>cs.LO</categories><journal-ref>EPTCS 15, 2010, pp. 20-31</journal-ref><doi>10.4204/EPTCS.15.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study superdevelopments in the weak lambda calculus of Cagman and Hindley,
a confluent variant of the standard weak lambda calculus in which reduction
below lambdas is forbidden. In contrast to developments, a superdevelopment
from a term M allows not only residuals of redexes in M to be reduced but also
some newly created ones. In the lambda calculus there are three ways new
redexes may be created; in the weak lambda calculus a new form of redex
creation is possible. We present labeled and simultaneous reduction
formulations of superdevelopments for the weak lambda calculus and prove them
equivalent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4431</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4431</id><created>2010-01-25</created><updated>2010-06-14</updated><authors><author><keyname>Kim</keyname><forenames>MinJi</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>Algebraic Network Coding Approach to Deterministic Wireless Relay
  Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>9 pages, 12 figures, submitted to Allerton Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The deterministic wireless relay network model, introduced by Avestimehr et
al., has been proposed for approximating Gaussian relay networks. This model,
known as the ADT network model, takes into account the broadcast nature of
wireless medium and interference. Avestimehr et al. showed that the Min-cut
Max-flow theorem holds in the ADT network.
  In this paper, we show that the ADT network model can be described within the
algebraic network coding framework introduced by Koetter and Medard. We prove
that the ADT network problem can be captured by a single matrix, called the
&quot;system matrix&quot;. We show that the min-cut of an ADT network is the rank of the
system matrix; thus, eliminating the need to optimize over exponential number
of cuts between two nodes to compute the min-cut of an ADT network.
  We extend the capacity characterization for ADT networks to a more general
set of connections. Our algebraic approach not only provides the Min-cut
Max-flow theorem for a single unicast/multicast connection, but also extends to
non-multicast connections such as multiple multicast, disjoint multicast, and
two-level multicast. We also provide sufficiency conditions for achievability
in ADT networks for any general connection set. In addition, we show that the
random linear network coding, a randomized distributed algorithm for network
code construction, achieves capacity for the connections listed above.
  Finally, we extend the ADT networks to those with random erasures and cycles
(thus, allowing bi-directional links). Note that ADT network was proposed for
approximating the wireless networks; however, ADT network is acyclic.
Furthermore, ADT network does not model the stochastic nature of the wireless
links. With our algebraic framework, we incorporate both cycles as well as
random failures into ADT network model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4432</identifier>
 <datestamp>2010-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4432</id><created>2010-01-25</created><updated>2010-05-27</updated><authors><author><keyname>Harremo&#xeb;s</keyname><forenames>Peter</forenames></author><author><keyname>Vajda</keyname><forenames>Igor</forenames></author></authors><title>Joint Range of f-divergences</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>Accepted for presentation at ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a general method for evaluation of the joint range of
f-divergences for two different functions f. Via topological arguments we prove
that the joint range for general distributions equals the convex hull of the
joint range achieved by the distributions on a two-element set. The joint range
technique provides important inequalities between different f-divergences with
various applications in information theory and statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4433</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4433</id><created>2010-01-25</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Besselaar</keyname><forenames>Peter Van den</forenames></author></authors><title>Scientometrics and Communication Theory: Towards Theoretically Informed
  Indicators</title><categories>cs.DL physics.soc-ph</categories><journal-ref>Scientometrics 38(1) (1977), 155-174</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A theory of citations should not consider cited and/or citing agents as its
sole subject of study. One is able to study also the dynamics in the networks
of communications. While communicating agents (e.g., authors, laboratories,
journals) can be made comparable in terms of their publication and citation
counts, one would expect the communication networks not to be homogeneous. The
latent structures of the network indicate different codifications that span a
space of possible 'translations'. The various subdynamics can be hypothesized
from an evolutionary perspective. Using the network of aggregated
journal-journal citations in Science &amp; Technology Studies as an empirical case,
the operation of such subdynamics can be demonstrated. Policy implications and
the consequences for a theory-driven type of scientometrics will be elaborated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4434</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4434</id><created>2010-01-25</created><authors><author><keyname>Dundua</keyname><forenames>Besik</forenames><affiliation>RISC, JKU Linz</affiliation></author><author><keyname>Kutsia</keyname><forenames>Temur</forenames><affiliation>RISC, JKU Linz</affiliation></author><author><keyname>Marin</keyname><forenames>Mircea</forenames><affiliation>University of Tsukuba</affiliation></author></authors><title>Strategies in PRholog</title><categories>cs.PL cs.LO cs.SE</categories><journal-ref>EPTCS 15, 2010, pp. 32-43</journal-ref><doi>10.4204/EPTCS.15.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  PRholog is an experimental extension of logic programming with strategic
conditional transformation rules, combining Prolog with Rholog calculus. The
rules perform nondeterministic transformations on hedges. Queries may have
several results that can be explored on backtracking. Strategies provide a
control on rule applications in a declarative way. With strategy combinators,
the user can construct more complex strategies from simpler ones. Matching with
four different kinds of variables provides a flexible mechanism of selecting
(sub)terms during execution. We give an overview on programming with strategies
in PRholog and demonstrate how rewriting strategies can be expressed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4436</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4436</id><created>2010-01-25</created><authors><author><keyname>Gonzalez</keyname><forenames>Ariel</forenames><affiliation>Universidad Nacional de Rio Cuarto, Argentina</affiliation></author><author><keyname>Luna</keyname><forenames>Carlos</forenames><affiliation>Universidad ORT, Uruguay</affiliation></author></authors><title>Specification of Products and Product Lines</title><categories>cs.SE cs.LO</categories><journal-ref>EPTCS 15, 2010, pp. 44-55</journal-ref><doi>10.4204/EPTCS.15.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study of variability in software development has become increasingly
important in recent years. A common mechanism to represent the variability in a
product line is by means of feature models. However, the relationship between
these models and UML design models is not straightforward. UML statecharts are
extended introducing variability in their main components, so that the behavior
of product lines can be specified. The contribution of this work is the
proposal of a rule-based approach that defines a transformation strategy from
extended statecharts to concrete UML statecharts. This is accomplished via the
use of feature models, in order to describe the common and variant components,
in such a way that, starting from different feature configurations and applying
the rule-based method, concrete state machines corresponding to different
products of a line can be obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4437</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4437</id><created>2010-01-25</created><authors><author><keyname>Gramlich</keyname><forenames>Bernhard</forenames><affiliation>Vienna University of Technology</affiliation></author><author><keyname>Schernhammer</keyname><forenames>Felix</forenames><affiliation>Vienna University of Technology</affiliation></author></authors><title>Extending Context-Sensitivity in Term Rewriting</title><categories>cs.LO</categories><acm-class>F.3.1</acm-class><journal-ref>EPTCS 15, 2010, pp. 56-68</journal-ref><doi>10.4204/EPTCS.15.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a generalized version of context-sensitivity in term rewriting
based on the notion of &quot;forbidden patterns&quot;. The basic idea is that a rewrite
step should be forbidden if the redex to be contracted has a certain shape and
appears in a certain context. This shape and context is expressed through
forbidden patterns. In particular we analyze the relationships among this novel
approach and the commonly used notion of context-sensitivity in term rewriting,
as well as the feasibility of rewriting with forbidden patterns from a
computational point of view. The latter feasibility is characterized by
demanding that restricting a rewrite relation yields an improved termination
behaviour while still being powerful enough to compute meaningful results.
Sufficient criteria for both kinds of properties in certain classes of rewrite
systems with forbidden patterns are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4438</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4438</id><created>2010-01-25</created><authors><author><keyname>Ventura</keyname><forenames>Daniel</forenames><affiliation>Universidade de Brasilia</affiliation></author><author><keyname>Ayala-Rinc&#xf3;n</keyname><forenames>Mauricio</forenames><affiliation>Universidade de Brasilia</affiliation></author><author><keyname>Kamareddine</keyname><forenames>Fairouz</forenames><affiliation>Heriot-Watt University, Edinburgh</affiliation></author></authors><title>Principal Typings in a Restricted Intersection Type System for Beta
  Normal Forms with De Bruijn Indices</title><categories>cs.LO cs.PL</categories><journal-ref>EPTCS 15, 2010, pp. 69-82</journal-ref><doi>10.4204/EPTCS.15.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The lambda-calculus with de Bruijn indices assembles each alpha-class of
lambda-terms in a unique term, using indices instead of variable names.
Intersection types provide finitary type polymorphism and can characterise
normalisable lambda-terms through the property that a term is normalisable if
and only if it is typeable. To be closer to computations and to simplify the
formalisation of the atomic operations involved in beta-contractions, several
calculi of explicit substitution were developed mostly with de Bruijn indices.
Versions of explicit substitutions calculi without types and with simple type
systems are well investigated in contrast to versions with more elaborate type
systems such as intersection types. In previous work, we introduced a de Bruijn
version of the lambda-calculus with an intersection type system and proved that
it preserves subject reduction, a basic property of type systems. In this paper
a version with de Bruijn indices of an intersection type system originally
introduced to characterise principal typings for beta-normal forms is
presented. We present the characterisation in this new system and the
corresponding versions for the type inference and the reconstruction of normal
forms from principal typings algorithms. We briefly discuss the failure of the
subject reduction property and some possible solutions for it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4448</identifier>
 <datestamp>2010-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4448</id><created>2010-01-25</created><updated>2010-05-27</updated><authors><author><keyname>van Erven</keyname><forenames>Tim</forenames></author><author><keyname>Harremo&#xeb;s</keyname><forenames>Peter</forenames></author></authors><title>R\'enyi Divergence and Majorization</title><categories>cs.IT math.IT</categories><msc-class>94A17</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  R\'enyi divergence is related to R\'enyi entropy much like information
divergence (also called Kullback-Leibler divergence or relative entropy) is
related to Shannon's entropy, and comes up in many settings. It was introduced
by R\'enyi as a measure of information that satisfies almost the same axioms as
information divergence. We review the most important properties of R\'enyi
divergence, including its relation to some other distances. We show how R\'enyi
divergence appears when the theory of majorization is generalized from the
finite to the continuous setting. Finally, R\'enyi divergence plays a role in
analyzing the number of binary questions required to guess the values of a
sequence of random variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4457</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4457</id><created>2010-01-25</created><authors><author><keyname>Chalopin</keyname><forenames>J&#xe9;r&#xe9;mie</forenames></author><author><keyname>Chepoi</keyname><forenames>Victor</forenames></author><author><keyname>Nisse</keyname><forenames>Nicolas</forenames></author><author><keyname>Vax&#xe8;s</keyname><forenames>Yann</forenames></author></authors><title>Cop and robber games when the robber can hide and ride</title><categories>cs.DM</categories><report-no>INRIA-RR7178</report-no><journal-ref>SIAM J. Discrete Math. 25(2011) 333-359</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the classical cop and robber game, two players, the cop C and the robber
R, move alternatively along edges of a finite graph G. The cop captures the
robber if both players are on the same vertex at the same moment of time. A
graph G is called cop win if the cop always captures the robber after a finite
number of steps. Nowakowski, Winkler (1983) and Quilliot (1983) characterized
the cop-win graphs as graphs admitting a dismantling scheme. In this paper, we
characterize in a similar way the class CW(s,s') of cop-win graphs in the game
in which the cop and the robber move at different speeds s' and s, s'&lt;= s. We
also establish some connections between cop-win graphs for this game with s'&lt;s
and Gromov's hyperbolicity. In the particular case s'=1 and s=2, we prove that
the class of cop-win graphs is exactly the well-known class of dually chordal
graphs. We show that all classes CW(s,1), s&gt;=3, coincide and we provide a
structural characterization of these graphs. We also investigate several
dismantling schemes necessary or sufficient for the cop-win graphs in the game
in which the robber is visible only every k moves for a fixed integer k&gt;1. We
characterize the graphs which are cop-win for any value of k. Finally, we
consider the game where the cop wins if he is at distance at most 1 from the
robber and we characterize via a specific dismantling scheme the bipartite
graphs where a single cop wins in this game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4459</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4459</id><created>2010-01-25</created><authors><author><keyname>Broenink</keyname><forenames>Gerben</forenames></author><author><keyname>Hoepman</keyname><forenames>Jaap-Henk</forenames></author><author><keyname>Hof</keyname><forenames>Christian van 't</forenames></author><author><keyname>van Kranenburg</keyname><forenames>Rob</forenames></author><author><keyname>Smits</keyname><forenames>David</forenames></author><author><keyname>Wisman</keyname><forenames>Tijmen</forenames></author></authors><title>The Privacy Coach: Supporting customer privacy in the Internet of Things</title><categories>cs.CY</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Privacy Coach is an application running on a mobile phone that supports
customers in making privacy decisions when confronted with RFID tags. The
approach we take to increase customer privacy is a radical departure from the
mainstream research efforts that focus on implementing privacy enhancing
technologies on the RFID tags themselves. Instead the Privacy Coach functions
as a mediator between customer privacy preferences and corporate privacy
policies, trying to find a match between the two, and informing the user of the
outcome. In this paper we report on the architecture of the Privacy Coach, and
show how it enables users to make informed privacy decisions in a user-friendly
manner. We also spend considerable time to discuss lessons learnt and to
describe future plans to further improve on the Privacy Coach concept.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4462</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4462</id><created>2010-01-25</created><updated>2010-04-07</updated><authors><author><keyname>Andreev</keyname><forenames>Mikhail</forenames></author><author><keyname>Razenshteyn</keyname><forenames>Ilya</forenames></author><author><keyname>Shen</keyname><forenames>Alexander</forenames></author></authors><title>Not Every Domain of a Plain Decompressor Contains the Domain of a
  Prefix-Free One</title><categories>cs.IT cs.CC math.IT math.LO</categories><msc-class>68Q30</msc-class><acm-class>F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  C.Calude, A.Nies, L.Staiger, and F.Stephan posed the following question about
the relation between plain and prefix Kolmogorov complexities (see their paper
in DLT 2008 conference proceedings): does the domain of every optimal
decompressor contain the domain of some optimal prefix-free decompressor? In
this paper we provide a negative answer to this question.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4472</identifier>
 <datestamp>2013-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4472</id><created>2010-01-25</created><updated>2011-12-22</updated><authors><author><keyname>Bassino</keyname><forenames>Fr&#xe9;d&#xe9;rique</forenames><affiliation>LIPN</affiliation></author><author><keyname>Martino</keyname><forenames>Armando</forenames><affiliation>LIGM</affiliation></author><author><keyname>Nicaud</keyname><forenames>Cyril</forenames><affiliation>LIGM</affiliation></author><author><keyname>Ventura</keyname><forenames>Enric</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Weil</keyname><forenames>Pascal</forenames><affiliation>LaBRI</affiliation></author></authors><title>Statistical properties of subgroups of free groups</title><categories>math.GR cs.DM math.CO</categories><comments>Random Structures and Algorithms (2012) to appear</comments><proxy>ccsd</proxy><journal-ref>Random Structures and Algorithms 42 (2013) 349-373</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The usual way to investigate the statistical properties of finitely generated
subgroups of free groups, and of finite presentations of groups, is based on
the so-called word-based distribution: subgroups are generated (finite
presentations are determined) by randomly chosen k-tuples of reduced words,
whose maximal length is allowed to tend to infinity. In this paper we adopt a
different, though equally natural point of view: we investigate the statistical
properties of the same objects, but with respect to the so-called graph-based
distribution, recently introduced by Bassino, Nicaud and Weil. Here, subgroups
(and finite presentations) are determined by randomly chosen Stallings graphs
whose number of vertices tends to infinity. Our results show that these two
distributions behave quite differently from each other, shedding a new light on
which properties of finitely generated subgroups can be considered frequent or
rare. For example, we show that malnormal subgroups of a free group are
negligible in the graph-based distribution, while they are exponentially
generic in the word-based distribution. Quite surprisingly, a random finite
presentation generically presents the trivial group in this new distribution,
while in the classical one it is known to generically present an infinite
hyperbolic group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4475</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4475</id><created>2010-01-25</created><updated>2011-04-13</updated><authors><author><keyname>Bubeck</keyname><forenames>S&#xe9;bastien</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Munos</keyname><forenames>R&#xe9;mi</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Stoltz</keyname><forenames>Gilles</forenames><affiliation>DMA, GREGH, INRIA Paris - Rocquencourt</affiliation></author><author><keyname>Szepesvari</keyname><forenames>Csaba</forenames></author></authors><title>X-Armed Bandits</title><categories>cs.LG cs.SY math.OC math.ST stat.TH</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a generalization of stochastic bandits where the set of arms,
$\cX$, is allowed to be a generic measurable space and the mean-payoff function
is &quot;locally Lipschitz&quot; with respect to a dissimilarity function that is known
to the decision maker. Under this condition we construct an arm selection
policy, called HOO (hierarchical optimistic optimization), with improved regret
bounds compared to previous results for a large class of problems. In
particular, our results imply that if $\cX$ is the unit hypercube in a
Euclidean space and the mean-payoff function has a finite number of global
maxima around which the behavior of the function is locally continuous with a
known smoothness degree, then the expected regret of HOO is bounded up to a
logarithmic factor by $\sqrt{n}$, i.e., the rate of growth of the regret is
independent of the dimension of the space. We also prove the minimax optimality
of our algorithm when the dissimilarity is a metric. Our basic strategy has
quadratic computational complexity as a function of the number of time steps
and does not rely on the doubling trick. We also introduce a modified strategy,
which relies on the doubling trick but runs in linearithmic time. Both results
are improvements with respect to previous approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4493</identifier>
 <datestamp>2010-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4493</id><created>2010-01-25</created><authors><author><keyname>Angermeier</keyname><forenames>Josef</forenames></author><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author><author><keyname>Kamphans</keyname><forenames>Tom</forenames></author><author><keyname>Schweer</keyname><forenames>Nils</forenames></author><author><keyname>Teich</keyname><forenames>Juergen</forenames></author></authors><title>Maintaining Virtual Areas on FPGAs using Strip Packing with Delays</title><categories>cs.AR cs.DS</categories><comments>9 pages, 10 figures, 1 table, Latex, to appear in 17th Reconfigurable
  Architectures Workshop (RAW 2010)</comments><acm-class>C.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Every year, the computing resources available on dynamically partially
reconfigurable devices increase enormously. In the near future, we expect many
applications to run on a single reconfigurable device. In this paper, we
present a concept for multitasking on dynamically partially reconfigurable
systems called virtual area management. We explain its advantages, show its
challenges, and discuss possible solutions. Furthermore, we investigate one
problem in more detail: Packing modules with time-varying resource requests.
This problem from the reconfigurable computing field results in a completely
new optimization problem not tackled before. ILP-based and heuristic approaches
are compared in an experimental study and the drawbacks and benefits discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4499</identifier>
 <datestamp>2013-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4499</id><created>2010-01-25</created><authors><author><keyname>N&#xe1;n&#xe1;si</keyname><forenames>Michal</forenames></author><author><keyname>Vina&#x159;</keyname><forenames>Tom&#xe1;&#x161;</forenames></author><author><keyname>Brejov&#xe1;</keyname><forenames>Bro&#x148;a</forenames></author></authors><title>The Highest Expected Reward Decoding for HMMs with Application to
  Recombination Detection</title><categories>cs.DS q-bio.GN</categories><doi>10.1007/978-3-642-13509-5_16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hidden Markov models are traditionally decoded by the Viterbi algorithm which
finds the highest probability state path in the model. In recent years, several
limitations of the Viterbi decoding have been demonstrated, and new algorithms
have been developed to address them
\citep{Kall2005,Brejova2007,Gross2007,Brown2010}.
  In this paper, we propose a new efficient highest expected reward decoding
algorithm (HERD) that allows for uncertainty in boundaries of individual
sequence features. We demonstrate usefulness of our approach on jumping HMMs
for recombination detection in viral genomes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4519</identifier>
 <datestamp>2010-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4519</id><created>2010-01-25</created><authors><author><keyname>Pinto</keyname><forenames>Pedro C.</forenames></author><author><keyname>Win</keyname><forenames>Moe Z.</forenames></author></authors><title>Communication in a Poisson Field of Interferers -- Part I: Interference
  Distribution and Error Probability</title><categories>cs.IT cs.NI math.IT</categories><comments>To appear in IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a mathematical model for communication subject to both network
interference and noise. We introduce a framework where the interferers are
scattered according to a spatial Poisson process, and are operating
asynchronously in a wireless environment subject to path loss, shadowing, and
multipath fading. We consider both cases of slow and fast-varying interferer
positions. The paper is comprised of two separate parts. In Part I, we
determine the distribution of the aggregate network interference at the output
of a linear receiver. We characterize the error performance of the link, in
terms of average and outage probabilities. The proposed model is valid for any
linear modulation scheme (e.g., M-ary phase shift keying or M-ary quadrature
amplitude modulation), and captures all the essential physical parameters that
affect network interference. Our work generalizes the conventional analysis of
communication in the presence of additive white Gaussian noise and fast fading,
allowing the traditional results to be extended to include the effect of
network interference. In Part II of the paper, we derive the capacity of the
link when subject to network interference and noise, and characterize the
spectrum of the aggregate interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4520</identifier>
 <datestamp>2010-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4520</id><created>2010-01-25</created><authors><author><keyname>Pinto</keyname><forenames>Pedro C.</forenames></author><author><keyname>Win</keyname><forenames>Moe Z.</forenames></author></authors><title>Communication in a Poisson Field of Interferers -- Part II: Channel
  Capacity and Interference Spectrum</title><categories>cs.IT cs.NI math.IT</categories><comments>To appear in IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Part I of this paper, we presented a mathematical model for communication
subject to both network interference and noise, where the interferers are
scattered according to a spatial Poisson process, and are operating
asynchronously in a wireless environment subject to path loss, shadowing, and
multipath fading. We determined the distribution of the aggregate interference
and the error performance of the link. In this second part, we characterize the
capacity of the link subject to both network interference and noise. Then, we
put forth the concept of spectral outage probability (SOP), a new
characterization of the aggregate radio-frequency emission generated by
communicating nodes in a wireless network. We present some applications of the
SOP, namely the establishment of spectral regulations and the design of covert
military networks. The proposed framework captures all the essential physical
parameters that affect the aggregate network emission, yet is simple enough to
provide insights that may be of value in the design and deployment of wireless
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4521</identifier>
 <datestamp>2011-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4521</id><created>2010-01-25</created><updated>2010-12-08</updated><authors><author><keyname>Agrell</keyname><forenames>Erik</forenames></author><author><keyname>Alvarado</keyname><forenames>Alex</forenames></author></authors><title>On the BICM Capacity</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><journal-ref>IEEE Trans. Inform. Theory, vol. 57, no. 10, pp. 6650-6672, 2011</journal-ref><doi>10.1109/TIT.2011.2162179</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal binary labelings, input distributions, and input alphabets are
analyzed for the so-called bit-interleaved coded modulation (BICM) capacity,
paying special attention to the low signal-to-noise ratio (SNR) regime. For
8-ary pulse amplitude modulation (PAM) and for 0.75 bit/symbol, the folded
binary code results in a higher capacity than the binary reflected gray code
(BRGC) and the natural binary code (NBC). The 1 dB gap between the additive
white Gaussian noise (AWGN) capacity and the BICM capacity with the BRGC can be
almost completely removed if the input symbol distribution is properly
selected. First-order asymptotics of the BICM capacity for arbitrary input
alphabets and distributions, dimensions, mean, variance, and binary labeling
are developed. These asymptotics are used to define first-order optimal (FOO)
constellations for BICM, i.e. constellations that make BICM achieve the Shannon
limit $-1.59 \tr{dB}$. It is shown that the $\Eb/N_0$ required for reliable
transmission at asymptotically low rates in BICM can be as high as infinity,
that for uniform input distributions and 8-PAM there are only 72 classes of
binary labelings with a different first-order asymptotic behavior, and that
this number is reduced to only 26 for 8-ary phase shift keying (PSK). A general
answer to the question of FOO constellations for BICM is also given: using the
Hadamard transform, it is found that for uniform input distributions, a
constellation for BICM is FOO if and only if it is a linear projection of a
hypercube. A constellation based on PAM or quadrature amplitude modulation
input alphabets is FOO if and only if they are labeled by the NBC; if the
constellation is based on PSK input alphabets instead, it can never be FOO if
the input alphabet has more than four points, regardless of the labeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4548</identifier>
 <datestamp>2011-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4548</id><created>2010-01-25</created><updated>2010-12-08</updated><authors><author><keyname>Agrell</keyname><forenames>Erik</forenames></author><author><keyname>Alvarado</keyname><forenames>Alex</forenames></author></authors><title>On the BICM Capacity</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><journal-ref>IEEE Trans. Inform. Theory, vol. 57, no. 10, pp. 6650-6672, 2011</journal-ref><doi>10.1109/TIT.2011.2162179</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal binary labelings, input distributions, and input alphabets are
analyzed for the so-called bit-interleaved coded modulation (BICM) capacity,
paying special attention to the low signal-to-noise ratio (SNR) regime. For
8-ary pulse amplitude modulation (PAM) and for 0.75 bit/symbol, the folded
binary code results in a higher capacity than the binary reflected gray code
(BRGC) and the natural binary code (NBC). The 1 dB gap between the additive
white Gaussian noise (AWGN) capacity and the BICM capacity with the BRGC can be
almost completely removed if the input symbol distribution is properly
selected. First-order asymptotics of the BICM capacity for arbitrary input
alphabets and distributions, dimensions, mean, variance, and binary labeling
are developed. These asymptotics are used to define first-order optimal (FOO)
constellations for BICM, i.e. constellations that make BICM achieve the Shannon
limit $-1.59 \tr{dB}$. It is shown that the $\Eb/N_0$ required for reliable
transmission at asymptotically low rates in BICM can be as high as infinity,
that for uniform input distributions and 8-PAM there are only 72 classes of
binary labelings with a different first-order asymptotic behavior, and that
this number is reduced to only 26 for 8-ary phase shift keying (PSK). A general
answer to the question of FOO constellations for BICM is also given: using the
Hadamard transform, it is found that for uniform input distributions, a
constellation for BICM is FOO if and only if it is a linear projection of a
hypercube. A constellation based on PAM or quadrature amplitude modulation
input alphabets is FOO if and only if they are labeled by the NBC; if the
constellation is based on PSK input alphabets instead, it can never be FOO if
the input alphabet has more than four points, regardless of the labeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4573</identifier>
 <datestamp>2010-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4573</id><created>2010-01-25</created><authors><author><keyname>Fern&#xe1;ndez</keyname><forenames>Maribel</forenames><affiliation>King's College London</affiliation></author></authors><title>Proceedings Ninth International Workshop on Reduction Strategies in
  Rewriting and Programming</title><categories>cs.PL cs.LO cs.SC cs.SE</categories><journal-ref>EPTCS 15, 2010</journal-ref><doi>10.4204/EPTCS.15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains selected papers presented at the 9th International
Workshop on Reduction Strategies in Rewriting and Programming, WRS2009, which
was held in Brasilia on the 28th June 2009, associated to RTA 2009 (the 20th
International Conference on Rewriting Techniques and Applications) at RDP, the
Federated Conference on Rewriting, Deduction and Programming. Reduction
strategies define which (sub)expression(s) should be selected for evaluation
and which rule(s) should be applied. These choices affect fundamental
properties of reductions, such as completeness, laziness and efficiency in
general. The WRS workshops promote research and collaboration in the area of
reduction strategies and their applications in specification and programming,
theorem proving, software engineering, etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4588</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4588</id><created>2010-01-25</created><updated>2011-01-28</updated><authors><author><keyname>Bandemer</keyname><forenames>Bernd</forenames></author><author><keyname>Gamal</keyname><forenames>Abbas El</forenames></author></authors><title>Interference Decoding for Deterministic Channels</title><categories>cs.IT math.IT</categories><comments>17 pages, 7 figures; added new subfigure in Figure 4, included
  discussion about numerical evaluation method, introduction clarified
  (accepted to IEEE Transactions on Information Theory)</comments><journal-ref>IEEE Transactions on Information Theory, vol. 57, no. 5, pp.
  2966-2975, May 2011</journal-ref><doi>10.1109/TIT.2011.2119890</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An inner bound to the capacity region of a class of deterministic
interference channels with three user pairs is presented. The key idea is to
simultaneously decode the combined interference signal and the intended message
at each receiver. It is shown that this interference-decoding inner bound is
tight under certain strong interference conditions. The inner bound is also
shown to strictly contain the inner bound obtained by treating interference as
noise, which includes interference alignment for deterministic channels. The
gain comes from judicious analysis of the number of combined interference
sequences in different regimes of input distributions and message rates.
Finally, the inner bound is generalized to the case where each channel output
is observed through a noisy channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4597</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4597</id><created>2010-01-26</created><updated>2010-09-23</updated><authors><author><keyname>Chen</keyname><forenames>Jiang</forenames></author><author><keyname>Chu</keyname><forenames>Wei</forenames></author><author><keyname>Kou</keyname><forenames>Zhenzhen</forenames></author><author><keyname>Zheng</keyname><forenames>Zhaohui</forenames></author></authors><title>Learning to Blend by Relevance</title><categories>cs.IR</categories><comments>This paper has been withdrawn by the author due to conflict with a
  patent filed by the author</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Emergence of various vertical search engines highlights the fact that a
single ranking technology cannot deal with the complexity and scale of search
problems. For example, technology behind video and image search is very
different from general web search. Their ranking functions share few features.
Question answering websites (e.g., Yahoo! Answer) can make use of text matching
and click features developed for general web, but they have unique page
structures and rich user feedback, e.g., thumbs up and thumbs down ratings in
Yahoo! answer, which greatly benefit their own ranking. Even for those features
shared by answer and general web, the correlation between features and
relevance could be very different. Therefore, dedicated functions are needed in
order to better rank documents within individual domains. These dedicated
functions are defined on distinct feature spaces. However, having one search
box for each domain, is neither efficient nor scalable. Rather than typing the
same query two times into both Yahoo! Search and Yahoo! Answer and retrieving
two ranking lists, we would prefer putting it only once but receiving a
comprehensive list of documents from both domains on the subject. This
situation calls for new technology that blends documents from different sources
into a single ranking list. Despite the content richness of the blended list,
it has to be sorted by relevance none the less. We call such technology
blending, which is the main subject of this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4598</identifier>
 <datestamp>2010-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4598</id><created>2010-01-26</created><updated>2010-10-15</updated><authors><author><keyname>Kakade</keyname><forenames>Sham M.</forenames></author><author><keyname>Lobel</keyname><forenames>Ilan</forenames></author><author><keyname>Nazerzadeh</keyname><forenames>Hamid</forenames></author></authors><title>An Optimal Dynamic Mechanism for Multi-Armed Bandit Processes</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of revenue-optimal dynamic mechanism design in
settings where agents' types evolve over time as a function of their (both
public and private) experience with items that are auctioned repeatedly over an
infinite horizon. A central question here is understanding what natural
restrictions on the environment permit the design of optimal mechanisms (note
that even in the simpler static setting, optimal mechanisms are characterized
only under certain restrictions). We provide a {\em structural
characterization} of a natural &quot;separable: multi-armed bandit environment
(where the evolution and incentive structure of the a-priori type is decoupled
from the subsequent experience in a precise sense) where dynamic optimal
mechanism design is possible. Here, we present the Virtual Index Mechanism, an
optimal dynamic mechanism, which maximizes the (long term) {\em virtual
surplus} using the classical Gittins algorithm. The mechanism optimally
balances exploration and exploitation, taking incentives into account.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4649</identifier>
 <datestamp>2010-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4649</id><created>2010-01-26</created><authors><author><keyname>Caporaso</keyname><forenames>Nicola</forenames></author></authors><title>Is Space a Stronger Resource than Time? Positive Answer for the
  Nondeterministic at-Least-Quadratic Time Case</title><categories>cs.CC</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that all languages accepted in time f(n) &gt;= n^2 can be accepted in
space O(f(n)^{1/2})_and_ in time O(f(n)). The proof is carried out by
simulation, based on the idea of guessing the sequences of internal states of
the simulated TM when entering certain critical cells, whose location is also
guessed. Our method cannot be generalised easily to many-tapes TMs, and in no
case can it be relativised.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4687</identifier>
 <datestamp>2010-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4687</id><created>2010-01-26</created><authors><author><keyname>Bauwens</keyname><forenames>Bruno</forenames></author></authors><title>m-sophistication</title><categories>cs.CC</categories><comments>13 pages, draft</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The m-sophistication of a finite binary string x is introduced as a
generalization of some parameter in the proof that complexity of complexity is
rare. A probabilistic near sufficient statistic of x is given which length is
upper bounded by the m-sophistication of x within small additive terms. This
shows that m-sophistication is lower bounded by coarse sophistication and upper
bounded by sophistication within small additive terms. It is also shown that
m-sophistication and coarse sophistication can not be approximated by an upper
or lower semicomputable function, not even within very large error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4689</identifier>
 <datestamp>2010-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4689</id><created>2010-01-26</created><authors><author><keyname>Ho</keyname><forenames>Zuleita K. M.</forenames></author><author><keyname>Gesbert</keyname><forenames>David</forenames></author></authors><title>Balancing Egoism and Altruism on the Interference Channel: The MIMO case</title><categories>cs.IT math.IT</categories><journal-ref>Proceedings of IEEE ICC 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the so-called MIMO interference channel. This situation
has relevance in applications such as multi-cell coordination in cellular
networks as well as spectrum sharing in cognitive radio networks among others.
We address the design of precoding (i.e. beamforming) vectors at each sender
with the aim of striking a compromise between beamforming gain at the intended
receiver (Egoism) and the mitigation of interference created towards other
receivers (Altruism). Combining egoistic and altruistic beamforming has been
shown previously to be instrumental to optimizing the rates in a MISO
interference channel (i.e. where receivers have no interference canceling
capability) . Here we explore these game-theoretic concepts in the more general
context of MIMO channels and using the framework of Bayesian games, allowing us
to derive (semi-)distributed precoding techniques. We draw parallels with
existing work on the MIMO interference channel, including rate-optimizing and
interference-alignement precoding techniques, showing how such techniques may
be improved and re-interpretated through a common prism based on balancing
egoistic and altruistic beamforming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4694</identifier>
 <datestamp>2010-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4694</id><created>2010-01-26</created><authors><author><keyname>Martina</keyname><forenames>Maurizio</forenames></author><author><keyname>Masera</keyname><forenames>Guido</forenames></author></authors><title>VLSI Architectures for WIMAX Channel Decoders</title><categories>cs.AR</categories><comments>To appear in the book &quot;WIMAX, New Developments&quot;, M. Upena, D. Dalal,
  Y. Kosta (Ed.), ISBN978-953-7619-53-4</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This chapter describes the main architectures proposed in the literature to
implement the channel decoders required by the WiMax standard, namely
convolutional codes, turbo codes (both block and convolutional) and LDPC. Then
it shows a complete design of a convolutional turbo code encoder/decoder system
for WiMax.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4703</identifier>
 <datestamp>2010-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4703</id><created>2010-01-26</created><updated>2010-01-27</updated><authors><author><keyname>Bianchi</keyname><forenames>Pascal</forenames></author><author><keyname>Jakubowicz</keyname><forenames>Jeremie</forenames></author><author><keyname>Roueff</keyname><forenames>Francois</forenames></author></authors><title>Neyman-Pearson Detection of a Gaussian Source using Dumb Wireless
  Sensors</title><categories>cs.IT math.IT</categories><comments>28 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the performance of the Neyman-Pearson detection of a
stationary Gaussian process in noise, using a large wireless sensor network
(WSN). In our model, each sensor compresses its observation sequence using a
linear precoder. The final decision is taken by a fusion center (FC) based on
the compressed information. Two families of precoders are studied: random iid
precoders and orthogonal precoders. We analyse their performance in the regime
where both the number of sensors k and the number of samples n per sensor tend
to infinity at the same rate, that is, k/n tends to c in (0, 1). Contributions
are as follows. 1) Using results of random matrix theory and on large Toeplitz
matrices, it is proved that the miss probability of the Neyman-Pearson detector
converges exponentially to zero, when the above families of precoders are used.
Closed form expressions of the corresponding error exponents are provided. 2)
In particular, we propose a practical orthogonal precoding strategy, the
Principal Frequencies Strategy (PFS), which achieves the best error exponent
among all orthogonal strategies, and which requires very few signaling overhead
between the central processor and the nodes of the network. 3) Moreover, when
the PFS is used, a simplified low-complexity testing procedure can be
implemented at the FC. We show that the proposed suboptimal test enjoys the
same error exponent as the Neyman-Pearson test, which indicates a similar
asymptotic behaviour of the performance. We illustrate our findings by
numerical experiments on some examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4737</identifier>
 <datestamp>2010-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4737</id><created>2010-01-26</created><authors><author><keyname>Maris</keyname><forenames>M.</forenames></author><author><keyname>Tomasi</keyname><forenames>M.</forenames></author><author><keyname>Galeotta</keyname><forenames>S.</forenames></author><author><keyname>Miccolis</keyname><forenames>M.</forenames></author><author><keyname>Hildebrandt</keyname><forenames>S.</forenames></author><author><keyname>Frailis</keyname><forenames>M.</forenames></author><author><keyname>Rohlfs</keyname><forenames>R.</forenames></author><author><keyname>Morisset</keyname><forenames>N.</forenames></author><author><keyname>Zacchei</keyname><forenames>A.</forenames></author><author><keyname>Bersanelli</keyname><forenames>M.</forenames></author><author><keyname>Binko</keyname><forenames>P.</forenames></author><author><keyname>Burigana</keyname><forenames>C.</forenames></author><author><keyname>Butler</keyname><forenames>R. C.</forenames></author><author><keyname>Cuttaia</keyname><forenames>F.</forenames></author><author><keyname>Chulani</keyname><forenames>H.</forenames></author><author><keyname>D'Arcangelo</keyname><forenames>O.</forenames></author><author><keyname>Fogliani</keyname><forenames>S.</forenames></author><author><keyname>Franceschi</keyname><forenames>E.</forenames></author><author><keyname>Gasparo</keyname><forenames>F.</forenames></author><author><keyname>Gomez</keyname><forenames>F.</forenames></author><author><keyname>Gregorio</keyname><forenames>A.</forenames></author><author><keyname>Herreros)</keyname><forenames>J. M.</forenames></author><author><keyname>Leonardi</keyname><forenames>R.</forenames></author><author><keyname>Leutenegger</keyname><forenames>P.</forenames></author><author><keyname>Maggio</keyname><forenames>G.</forenames></author><author><keyname>Maino</keyname><forenames>D.</forenames></author><author><keyname>Malaspina</keyname><forenames>M.</forenames></author><author><keyname>Mandolesi</keyname><forenames>N.</forenames></author><author><keyname>Manzato</keyname><forenames>P.</forenames></author><author><keyname>Meharga</keyname><forenames>M.</forenames></author><author><keyname>Meinhold</keyname><forenames>P.</forenames></author><author><keyname>Mennella</keyname><forenames>A.</forenames></author><author><keyname>Pasian</keyname><forenames>F.</forenames></author><author><keyname>Perrotta</keyname><forenames>F.</forenames></author><author><keyname>Rebolo</keyname><forenames>R.</forenames></author><author><keyname>Turler</keyname><forenames>M.</forenames></author><author><keyname>Zonca</keyname><forenames>A.</forenames></author></authors><title>Optimization of Planck/LFI on--board data handling</title><categories>astro-ph.IM astro-ph.CO cs.IT math.IT</categories><comments>51 pages, 13 fig.s, 3 tables, pdflatex, needs JINST.csl, graphicx,
  txfonts, rotating; Issue 1.0 10 nov 2009; Sub. to JINST 23Jun09, Accepted
  10Nov09, Pub.: 29Dec09; This is a preprint, not the final version</comments><journal-ref>2009 JINST 4 T12018</journal-ref><doi>10.1088/1748-0221/4/12/T12018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To asses stability against 1/f noise, the Low Frequency Instrument (LFI)
onboard the Planck mission will acquire data at a rate much higher than the
data rate allowed by its telemetry bandwith of 35.5 kbps. The data are
processed by an onboard pipeline, followed onground by a reversing step. This
paper illustrates the LFI scientific onboard processing to fit the allowed
datarate. This is a lossy process tuned by using a set of 5 parameters Naver,
r1, r2, q, O for each of the 44 LFI detectors. The paper quantifies the level
of distortion introduced by the onboard processing, EpsilonQ, as a function of
these parameters. It describes the method of optimizing the onboard processing
chain. The tuning procedure is based on a optimization algorithm applied to
unprocessed and uncompressed raw data provided either by simulations, prelaunch
tests or data taken from LFI operating in diagnostic mode. All the needed
optimization steps are performed by an automated tool, OCA2, which ends with
optimized parameters and produces a set of statistical indicators, among them
the compression rate Cr and EpsilonQ. For Planck/LFI the requirements are Cr =
2.4 and EpsilonQ &lt;= 10% of the rms of the instrumental white noise. To speedup
the process an analytical model is developed that is able to extract most of
the relevant information on EpsilonQ and Cr as a function of the signal
statistics and the processing parameters. This model will be of interest for
the instrument data analysis. The method was applied during ground tests when
the instrument was operating in conditions representative of flight. Optimized
parameters were obtained and the performance has been verified, the required
data rate of 35.5 Kbps has been achieved while keeping EpsilonQ at a level of
3.8% of white noise rms well within the requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4738</identifier>
 <datestamp>2010-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4738</id><created>2010-01-26</created><authors><author><keyname>Sbihi</keyname><forenames>Boubker</forenames></author><author><keyname>Kadiri</keyname><forenames>Kamal Eddine El</forenames></author></authors><title>Towards a participatory E-learning 2.0 A new E-learning focused on
  learners and validation of the content</title><categories>cs.CY</categories><comments>7 Pages IEEE format, International Journal on Computer Science and
  Engineering, IJCSE 2010, ISSN 0975-3397, Impact Factor 0.583</comments><report-no>IJCSE02-01-01-01</report-no><journal-ref>International Journal on Computer Science and Engineering, IJCSE,
  Vol. 2, No. 1 January 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our aim is to propose a collaborative methodological approach centred on
learners and based on the Web 2.0 tools in order to make E-learning 2.0. It is
based on a process consisting of four iterative steps which are: grouping,
collaborating, validating and publishing content. In this context, learners
will be the creators of the content of assigned courses in a virtual meeting
through the chat. These contents will be validated after a pedagogical
monitoring by the instructor through the class's blog and merged into a single
course content published on a class wiki. Social interaction and sharing of
files on the web will be the responsibility of social networks. The rest of the
web 2.0 tools such as RSS feeds, tags, podcasts and video casts will be used as
complementary tools in order to improve the quality of training. This
methodological approach will allow E-learning 2.0 by ensuring a better
interactivity, collaboration, sharing and an optimal exploitation of
collaborative intelligence in the classroom.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4739</identifier>
 <datestamp>2010-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4739</id><created>2010-01-26</created><authors><author><keyname>Rahman</keyname><forenames>Md Saifur</forenames></author><author><keyname>Wagner</keyname><forenames>Aaron B.</forenames></author></authors><title>Rate Region of the Gaussian Scalar-Help-Vector Source-Coding Problem</title><categories>cs.IT math.IT</categories><comments>36 pages, 2 figures, submitted to IEEE transactions on IT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We determine the rate region of the Gaussian scalar-help-vector source-coding
problem under a covariance matrix distortion constraint. The rate region is
achieved by a Gaussian achievable scheme. We introduce a novel outer bounding
technique to establish the converse of the main result. Our approach is based
on lower bounding the problem with a potentially reduced dimensional problem by
projecting the main source and imposing the distortion constraint in certain
directions determined by the optimal Gaussian scheme. We also prove several
properties that the optimal solution to the point-to-point rate-distortion
problem for a vector Gaussian source under a covariance matrix distortion
constraint satisfies. These properties play an important role in our converse
proof. We further establish an outer bound to the rate region of the more
general problem in which there are distortion constraints on both the sources.
The outer bound is partially tight in general. We also study its tightness in
some nontrivial cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4753</identifier>
 <datestamp>2010-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4753</id><created>2010-01-26</created><authors><author><keyname>M</keyname><forenames>Shyam</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author></authors><title>Obstacle Constrained Total Area Coverage in Wireless Sensor Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the accomplishment of total area coverage of an
arbitrary region using sensors with a finite sensing radius of rs. For a given
region, we aim to obtain a deterministic placement of sensors which, apart from
ensuring that the entire region comes under the purview of at least a single
sensor, minimises the number of sensors utilised. We begin by considering
regions devoid of obstacles and thus having every location amenable for
placement. Herein, we formalise the popular notion that sensors at the centres
of the hexagons of a hexagonal tessellation provide the most optimal placement.
We then move on to regions which may comprise obstacles of arbitrary size at
arbitrary locations. We recognise two distinct classes of obstacles, namely
transparent and opaque obstacles, which are distinguished by their ability (or
the lack of it) to permit sensing radiation through them. In the real world,
transparent obstacles model lakes, ponds and swamps, while the opaque ones
stand for, inter alia, hills, trees and walls.We propose a polynomial-time
algorithm for achieving optimal placement in the aforesaid scenarios and we
prove its convergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4764</identifier>
 <datestamp>2010-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4764</id><created>2010-01-26</created><authors><author><keyname>Apfelbaum</keyname><forenames>Roel</forenames></author><author><keyname>Sharir</keyname><forenames>Micha</forenames></author></authors><title>An Improved Bound on the Number of Unit Area Triangles</title><categories>cs.CG</categories><comments>12 pages, 2 figures, appeared in the 25th Annual Symposium on
  Computational Geometry (2009), submitted to &quot;Discrete and Computational
  Geometry&quot;</comments><journal-ref>Proceedings of the 25th annual symposium on Computational geometry
  (2009) 135--140</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the number of unit-area triangles determined by a set of $n$
points in the plane is $O(n^{9/4+\epsilon})$, for any $\epsilon&gt;0$, improving
the recent bound $O(n^{44/19})$ of Dumitrescu et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4829</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4829</id><created>2010-01-26</created><updated>2010-02-03</updated><authors><author><keyname>Babai</keyname><forenames>Laszlo</forenames></author><author><keyname>Banerjee</keyname><forenames>Anandam</forenames></author><author><keyname>Kulkarni</keyname><forenames>Raghav</forenames></author><author><keyname>Naik</keyname><forenames>Vipul</forenames></author></authors><title>Evasiveness and the Distribution of Prime Numbers</title><categories>cs.CC cs.DM</categories><comments>12 pages (conference version for STACS 2010)</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We confirm the eventual evasiveness of several classes of monotone graph
properties under widely accepted number theoretic hypotheses. In particular we
show that Chowla's conjecture on Dirichlet primes implies that (a) for any
graph $H$, &quot;forbidden subgraph $H$&quot; is eventually evasive and (b) all
nontrivial monotone properties of graphs with $\le n^{3/2-\epsilon}$ edges are
eventually evasive. ($n$ is the number of vertices.)
  While Chowla's conjecture is not known to follow from the Extended Riemann
Hypothesis (ERH, the Riemann Hypothesis for Dirichlet's $L$ functions), we show
(b) with the bound $O(n^{5/4-\epsilon})$ under ERH.
  We also prove unconditional results: (a$'$) for any graph $H$, the query
complexity of &quot;forbidden subgraph $H$&quot; is $\binom{n}{2} - O(1)$; (b$'$) for
some constant $c&gt;0$, all nontrivial monotone properties of graphs with $\le
cn\log n+O(1)$ edges are eventually evasive.
  Even these weaker, unconditional results rely on deep results from number
theory such as Vinogradov's theorem on the Goldbach conjecture.
  Our technical contribution consists in connecting the topological framework
of Kahn, Saks, and Sturtevant (1984), as further developed by Chakrabarti,
Khot, and Shi (2002), with a deeper analysis of the orbital structure of
permutation groups and their connection to the distribution of prime numbers.
Our unconditional results include stronger versions and generalizations of some
result of Chakrabarti et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4880</identifier>
 <datestamp>2010-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4880</id><created>2010-01-27</created><authors><author><keyname>Nguyen</keyname><forenames>Benjamin</forenames></author><author><keyname>Zoupanos</keyname><forenames>Spyros</forenames></author></authors><title>The WebContent XML Store</title><categories>cs.DB</categories><comments>Must be compiled with pdflatex</comments><acm-class>H.3.2; H.3.3</acm-class><journal-ref>RFIA 2010 Workshop &quot;Sources Ouvertes et Services&quot;</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we describe the XML storage system used in the WebContent
project. We begin by advocating the use of an XML database in order to store
WebContent documents, and we present two different ways of storing and querying
these documents : the use of a centralized XML database and the use of a P2P
XML database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4887</identifier>
 <datestamp>2010-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4887</id><created>2010-01-27</created><authors><author><keyname>Chatterji</keyname><forenames>Samaresh</forenames></author><author><keyname>Gandhi</keyname><forenames>Ratnik</forenames></author></authors><title>Some Algebraic Properties of a Subclass of Finite Normal Form Games</title><categories>cs.GT cs.SC</categories><comments>18 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of computing all Nash equilibria of a subclass of finite
normal form games. With algebraic characterization of the games, we present a
method for computing all its Nash equilibria. Further, we present a method for
deciding membership to the class of games with its related results. An
appendix, containing an example to show working of each of the presented
methods, concludes the work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4892</identifier>
 <datestamp>2010-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4892</id><created>2010-01-27</created><authors><author><keyname>Bedini</keyname><forenames>Ivan</forenames></author><author><keyname>Nguyen</keyname><forenames>Benjamin</forenames></author><author><keyname>Gardarin</keyname><forenames>Georges</forenames></author></authors><title>Janus: Automatic Ontology Builder from XSD Files</title><categories>cs.DB cs.AI</categories><acm-class>D.3.3</acm-class><journal-ref>Proceedings of the World Wide Web Conference (WWW), Beijin, China,
  April 2008 (Developper Track), 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The construction of a reference ontology for a large domain still remains an
hard human task. The process is sometimes assisted by software tools that
facilitate the information extraction from a textual corpus. Despite of the
great use of XML Schema files on the internet and especially in the B2B domain,
tools that offer a complete semantic analysis of XML schemas are really rare.
In this paper we introduce Janus, a tool for automatically building a reference
knowledge base starting from XML Schema files. Janus also provides different
useful views to simplify B2B application integration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4898</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4898</id><created>2010-01-27</created><updated>2011-11-09</updated><authors><author><keyname>Boldo</keyname><forenames>Sylvie</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author><author><keyname>Cl&#xe9;ment</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Filli&#xe2;tre</keyname><forenames>Jean-Christophe</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author><author><keyname>Mayero</keyname><forenames>Micaela</forenames><affiliation>LIPN, INRIA Rh&#xf4;ne-Alpes / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme</affiliation></author><author><keyname>Melquiond</keyname><forenames>Guillaume</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author><author><keyname>Weis</keyname><forenames>Pierre</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Formal Proof of a Wave Equation Resolution Scheme: the Method Error</title><categories>cs.LO math.NA</categories><comments>This paper has been withdrawn by the authors. Please refere to
  arXiv:1005.0824</comments><proxy>ccsd inria-00450789</proxy><report-no>RR-7181</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Popular finite difference numerical schemes for the resolution of the
one-dimensional acoustic wave equation are well-known to be convergent. We
present a comprehensive formalization of the simplest one and formally prove
its convergence in Coq. The main difficulties lie in the proper definition of
asymptotic behaviors and the implicit way they are handled in the mathematical
pen-and-paper proofs. To our knowledge, this is the first time such kind of
mathematical proof is machine-checked.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4901</identifier>
 <datestamp>2010-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4901</id><created>2010-01-27</created><authors><author><keyname>Bedini</keyname><forenames>Ivan</forenames></author><author><keyname>Gardarin</keyname><forenames>Georges</forenames></author><author><keyname>Nguyen</keyname><forenames>Benjamin</forenames></author></authors><title>Deriving Ontologies from XML Schema</title><categories>cs.PL cs.DB</categories><acm-class>D.3.3</acm-class><journal-ref>Entrepots de Donnees et Analyse en Ligne (EDA) Conference, Invited
  Paper, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a method and a tool for deriving a skeleton of an
ontology from XML schema files. We first recall what an is ontology and its
relationships with XML schemas. Next, we focus on ontology building methodology
and associated tool requirements. Then, we introduce Janus, a tool for building
an ontology from various XML schemas in a given domain. We summarize the main
features of Janus and illustrate its functionalities through a simple example.
Finally, we compare our approach to other existing ontology building tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4919</identifier>
 <datestamp>2010-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4919</id><created>2010-01-27</created><authors><author><keyname>Hinrichs</keyname><forenames>Aicke</forenames></author><author><keyname>Vyb&#xed;ral</keyname><forenames>Jan</forenames></author></authors><title>Johnson-Lindenstrauss lemma for circulant matrices</title><categories>math.FA cs.IT math.IT</categories><msc-class>52C99; 68Q01</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove a variant of a Johnson-Lindenstrauss lemma for matrices with
circulant structure. This approach allows to minimise the randomness used, is
easy to implement and provides good running times. The price to be paid is the
higher dimension of the target space $k=O(\epsilon^{-2}\log^3n)$ instead of the
classical bound $k=O(\epsilon^{-2}\log n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4939</identifier>
 <datestamp>2010-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4939</id><created>2010-01-27</created><authors><author><keyname>Desmedt</keyname><forenames>Yvo</forenames></author><author><keyname>Elkind</keyname><forenames>Edith</forenames></author></authors><title>Equilibria of Plurality Voting with Abstentions</title><categories>cs.GT</categories><comments>Submitted to ACM EC'10</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the traditional voting manipulation literature, it is assumed that a group
of manipulators jointly misrepresent their preferences to get a certain
candidate elected, while the remaining voters are truthful. In this paper, we
depart from this assumption, and consider the setting where all voters are
strategic. In this case, the election can be viewed as a game, and the election
outcomes correspond to Nash equilibria of this game. We use this framework to
analyze two variants of Plurality voting, namely, simultaneous voting, where
all voters submit their ballots at the same time, and sequential voting, where
the voters express their preferences one by one. For simultaneous voting, we
characterize the preference profiles that admit a pure Nash equilibrium, but
show that it is computationally hard to check if a given profile fits our
criterion. For sequential voting, we provide a complete analysis of the setting
with two candidates, and show that for three or more candidates the equilibria
of sequential voting may behave in a counterintuitive manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4981</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4981</id><created>2010-01-27</created><authors><author><keyname>Zhang</keyname><forenames>Guangcai</forenames></author><author><keyname>Xu</keyname><forenames>Aiguo</forenames></author><author><keyname>Lu</keyname><forenames>Guo</forenames></author><author><keyname>Mo</keyname><forenames>Zeyao</forenames></author></authors><title>Cluster Identification and Characterization of Physical Fields</title><categories>cond-mat.stat-mech cs.CG</categories><comments>PDF file, Science in China G (in press)</comments><journal-ref>Sci China Phys Mech Astron September (2010) Vol. 53 No. 9
  1610-1618</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The description of complex configuration is a difficult issue. We present a
powerful technique for cluster identification and characterization. The scheme
is designed to treat with and analyze the experimental and/or simulation data
from various methods. Main steps are as follows. We first divide the space
using face or volume elements from discrete points. Then, combine the elements
with the same and/or similar properties to construct clusters with special
physical characterizations. In the algorithm, we adopt administrative structure
of hierarchy-tree for spatial bodies such as points, lines, faces, blocks, and
clusters. Two fast search algorithms with the complexity are realized. The
establishing of the hierarchy-tree and the fast searching of spatial bodies are
general, which are independent of spatial dimensions. Therefore, it is easy to
extend the skill to other fields. As a verification and validation, we treated
with and analyzed some two-dimensional and three-dimensional random data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4987</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4987</id><created>2010-01-27</created><updated>2010-02-03</updated><authors><author><keyname>Dyer</keyname><forenames>Martin E.</forenames></author><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author><author><keyname>Jalsenius</keyname><forenames>Markus</forenames></author><author><keyname>Richerby</keyname><forenames>David</forenames></author></authors><title>The Complexity of Approximating Bounded-Degree Boolean #CSP (Extended
  Abstract)</title><categories>cs.CC</categories><comments>12-page conference version for STACS 2010</comments><acm-class>F.2.2; G.2.1</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The degree of a CSP instance is the maximum number of times that a variable
may appear in the scope of constraints. We consider the approximate counting
problem for Boolean CSPs with bounded-degree instances, for constraint
languages containing the two unary constant relations {0} and {1}. When the
maximum degree is at least 25 we obtain a complete classification of the
complexity of this problem. It is exactly solvable in polynomial-time if every
relation in the constraint language is affine. It is equivalent to the problem
of approximately counting independent sets in bipartite graphs if every
relation can be expressed as conjunctions of {0}, {1} and binary implication.
Otherwise, there is no FPRAS unless NP=RP. For lower degree bounds, additional
cases arise in which the complexity is related to the complexity of
approximately counting independent sets in hypergraphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.4992</identifier>
 <datestamp>2010-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.4992</id><created>2010-01-27</created><updated>2010-01-28</updated><authors><author><keyname>Bringer</keyname><forenames>Julien</forenames></author><author><keyname>Chabanne</keyname><forenames>Herv&#xe9;</forenames></author><author><keyname>Cohen</keyname><forenames>G&#xe9;rard</forenames></author><author><keyname>Kindarji</keyname><forenames>Bruno</forenames></author></authors><title>RFID Key Establishment Against Active Adversaries</title><categories>cs.CR</categories><comments>This work was presented at the First IEEE Workshop on Information
  Forensics and Security (WIFS'09) (update including minor remarks and
  references to match the presented version)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method to strengthen a very low cost solution for key agreement
with a RFID device.
  Starting from a work which exploits the inherent noise on the communication
link to establish a key by public discussion, we show how to protect this
agreement against active adversaries. For that purpose, we unravel integrity
$(I)$-codes suggested by Cagalj et al.
  No preliminary key distribution is required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5007</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5007</id><created>2010-01-27</created><updated>2010-01-27</updated><authors><author><keyname>Gariel</keyname><forenames>Maxime</forenames></author><author><keyname>Srivastava</keyname><forenames>Ashok N.</forenames></author><author><keyname>Feron</keyname><forenames>Eric</forenames></author></authors><title>Trajectory Clustering and an Application to Airspace Monitoring</title><categories>cs.LG</categories><comments>15 pages, 20 figures</comments><doi>10.1016/j.eij.2011.02.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a framework aimed at monitoring the behavior of aircraft
in a given airspace. Nominal trajectories are determined and learned using data
driven methods. Standard procedures are used by air traffic controllers (ATC)
to guide aircraft, ensure the safety of the airspace, and to maximize the
runway occupancy. Even though standard procedures are used by ATC, the control
of the aircraft remains with the pilots, leading to a large variability in the
flight patterns observed. Two methods to identify typical operations and their
variability from recorded radar tracks are presented. This knowledge base is
then used to monitor the conformance of current operations against operations
previously identified as standard. A tool called AirTrajectoryMiner is
presented, aiming at monitoring the instantaneous health of the airspace, in
real time. The airspace is &quot;healthy&quot; when all aircraft are flying according to
the nominal procedures. A measure of complexity is introduced, measuring the
conformance of current flight to nominal flight patterns. When an aircraft does
not conform, the complexity increases as more attention from ATC is required to
ensure a safe separation between aircraft.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5016</identifier>
 <datestamp>2010-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5016</id><created>2010-01-27</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Persson</keyname><forenames>Olle</forenames></author></authors><title>Mapping the Geography of Science: Distribution Patterns and Networks of
  Relations among Cities and Institutes</title><categories>cs.DL cs.IR physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using Google Earth, Google Maps and/or network visualization programs such as
Pajek, one can overlay the network of relations among addresses in scientific
publications on the geographic map. We discuss the pros en cons of the various
options, and provide software (freeware) for bridging existing gaps between the
Science Citation Indices and Scopus, on the one side, and these various
visualization tools, on the other. At the level of city names, the global map
can be drawn reliably on the basis of the available address information. At the
level of the names of organizations and institutes, there are problems of
unification both in the ISI-databases and Scopus. Pajek enables us to combine
the visualization with statistical analysis, whereas the Google Maps and its
derivates provide superior tools at the Internet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5018</identifier>
 <datestamp>2010-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5018</id><created>2010-01-27</created><authors><author><keyname>Dolfsma</keyname><forenames>Wilfred</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>The Citation Field of Evolutionary Economics</title><categories>cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Evolutionary economics has developed into an academic field of its own,
institutionalized around, amongst others, the Journal of Evolutionary Economics
(JEE). This paper analyzes the way and extent to which evolutionary economics
has become an interdisciplinary journal, as its aim was: a journal that is
indispensable in the exchange of expert knowledge on topics and using
approaches that relate naturally with it. Analyzing citation data for the
relevant academic field for the Journal of Evolutionary Economics, we use
insights from scientometrics and social network analysis to find that, indeed,
the JEE is a central player in this interdisciplinary field aiming mostly at
understanding technological and regional dynamics. It does not, however, link
firmly with the natural sciences (including biology) nor to management
sciences, entrepreneurship, and organization studies. Another journal that
could be perceived to have evolutionary acumen, the Journal of Economic Issues,
does relate to heterodox economics journals and is relatively more involved in
discussing issues of firm and industry organization. The JEE seems most keen to
develop theoretical insights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5019</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5019</id><created>2010-01-27</created><updated>2011-06-23</updated><authors><author><keyname>Kreutzer</keyname><forenames>Stephan</forenames></author><author><keyname>Tazari</keyname><forenames>Siamak</forenames></author></authors><title>Lower Bounds for the Complexity of Monadic Second-Order Logic</title><categories>cs.LO cs.CC cs.DM cs.DS</categories><comments>Preliminary version appeared in proceedings of the 25th IEEE
  symposium on Logic in Computer Science (LICS'10), Edinburgh, Scotland, UK,
  pp. 189-198, 2010</comments><acm-class>F.4.1; F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Courcelle's famous theorem from 1990 states that any property of graphs
definable in monadic second-order logic (MSO) can be decided in linear time on
any class of graphs of bounded treewidth, or in other words, MSO is
fixed-parameter tractable in linear time on any such class of graphs. From a
logical perspective, Courcelle's theorem establishes a sufficient condition, or
an upper bound, for tractability of MSO-model checking.
  Whereas such upper bounds on the complexity of logics have received
significant attention in the literature, almost nothing is known about
corresponding lower bounds. In this paper we establish a strong lower bound for
the complexity of monadic second-order logic. In particular, we show that if C
is any class of graphs which is closed under taking subgraphs and whose
treewidth is not bounded by a polylogarithmic function (in fact, $\log^c n$ for
some small c suffices) then MSO-model checking is intractable on C (under a
suitable assumption from complexity theory).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5047</identifier>
 <datestamp>2012-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5047</id><created>2010-01-27</created><authors><author><keyname>Chambart</keyname><forenames>Pierre</forenames></author><author><keyname>Schnoebelen</keyname><forenames>Philippe</forenames></author></authors><title>Toward a Compositional Theory of Leftist Grammars and Transformations</title><categories>cs.FL</categories><comments>Full version of the FOSSACS 2010 paper</comments><journal-ref>Proc. FoSSaCS'10, LNCS 6014, pages 237-251. Springer, 2010</journal-ref><doi>10.1007/978-3-642-12032-9_17</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Leftist grammars [Motwani et al., STOC 2000] are special semi-Thue systems
where symbols can only insert or erase to their left. We develop a theory of
leftist grammars seen as word transformers as a tool toward rigorous analyses
of their computational power. Our main contributions in this first paper are
(1) constructions proving that leftist transformations are closed under
compositions and transitive closures, and (2) a proof that bounded reachability
is NP-complete even for leftist grammars with acyclic rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5050</identifier>
 <datestamp>2010-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5050</id><created>2010-01-27</created><authors><author><keyname>Haidar</keyname><forenames>Ali N.</forenames><affiliation>University College London</affiliation></author><author><keyname>Coveney</keyname><forenames>P. V.</forenames><affiliation>University College London</affiliation></author><author><keyname>Abdallah</keyname><forenames>Ali E.</forenames><affiliation>London South Bank University</affiliation></author><author><keyname>Ryan</keyname><forenames>P. Y. A</forenames><affiliation>University of Luxembourg</affiliation></author><author><keyname>Beckles</keyname><forenames>B.</forenames><affiliation>University of Cambridge Computing Service</affiliation></author><author><keyname>Brooke</keyname><forenames>J. M.</forenames><affiliation>University of Manchester</affiliation></author><author><keyname>Jones</keyname><forenames>M . A. S.</forenames><affiliation>University of Manchester</affiliation></author></authors><title>Formal Modelling of a Usable Identity Management Solution for Virtual
  Organisations</title><categories>cs.SE cs.CR cs.CY</categories><journal-ref>EPTCS 16, 2010, pp. 41-50</journal-ref><doi>10.4204/EPTCS.16.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper attempts to accurately model security requirements for
computational grid environments with particular focus on authentication. We
introduce the Audited Credential Delegation (ACD) architecture as a solution to
some of the virtual organisations identity management usability problems. The
approach uses two complementary models: one is state based, described in Z
notation, and the other is event-based, expressed in the Process Algebra of
Hoare's Communicating Sequential Processes (CSP). The former will be used to
capture the state of the WS and to model back-end operations on it whereas the
latter will be used to model behavior, and in particular, front-end
interactions and communications. The modelling helps to clearly and precisely
understand functional and security requirements and provide a basis for
verifying that the system meets its intended requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5056</identifier>
 <datestamp>2011-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5056</id><created>2010-01-28</created><authors><author><keyname>Lee</keyname><forenames>Jon</forenames></author><author><keyname>Onn</keyname><forenames>Shmuel</forenames></author><author><keyname>Weismantel</keyname><forenames>Robert</forenames></author></authors><title>Intractability of approximate multi-dimensional nonlinear optimization
  on independence systems</title><categories>math.OC cs.CC cs.DM math.CO</categories><msc-class>05A, 15A, 51M, 52A, 52B, 52C, 62H, 68Q, 68R, 68U, 68W, 90B, 90C</msc-class><journal-ref>Discrete Mathematics, 311:780--783, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider optimization of nonlinear objective functions that balance $d$
linear criteria over $n$-element independence systems presented by
linear-optimization oracles. For $d=1$, we have previously shown that an
$r$-best approximate solution can be found in polynomial time. Here, using an
extended Erd\H{o}s-Ko-Rado theorem of Frankl, we show that for $d=2$, finding a
$\rho n$-best solution requires exponential time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5073</identifier>
 <datestamp>2010-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5073</id><created>2010-01-27</created><authors><author><keyname>Mohimani</keyname><forenames>Hosein</forenames></author><author><keyname>Babaie-Zadeh</keyname><forenames>Massoud</forenames></author><author><keyname>Gorodnitsky</keyname><forenames>Irina</forenames></author><author><keyname>Jutten</keyname><forenames>Christian</forenames></author></authors><title>Sparse Recovery using Smoothed $\ell^0$ (SL0): Convergence Analysis</title><categories>cs.IT math.IT</categories><comments>Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding the sparse solution of an underdetermined system of linear equations
has many applications, especially, it is used in Compressed Sensing (CS),
Sparse Component Analysis (SCA), and sparse decomposition of signals on
overcomplete dictionaries. We have recently proposed a fast algorithm, called
Smoothed $\ell^0$ (SL0), for this task. Contrary to many other sparse recovery
algorithms, SL0 is not based on minimizing the $\ell^1$ norm, but it tries to
directly minimize the $\ell^0$ norm of the solution. The basic idea of SL0 is
optimizing a sequence of certain (continuous) cost functions approximating the
$\ell^0$ norm of a vector. However, in previous papers, we did not provide a
complete convergence proof for SL0. In this paper, we study the convergence
properties of SL0, and show that under a certain sparsity constraint in terms
of Asymmetric Restricted Isometry Property (ARIP), and with a certain choice of
parameters, the convergence of SL0 to the sparsest solution is guaranteed.
Moreover, we study the complexity of SL0, and we show that whenever the
dimension of the dictionary grows, the complexity of SL0 increases with the
same order as Matching Pursuit (MP), which is one of the fastest existing
sparse recovery methods, while contrary to MP, its convergence to the sparsest
solution is guaranteed under certain conditions which are satisfied through the
choice of parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5074</identifier>
 <datestamp>2010-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5074</id><created>2010-01-27</created><authors><author><keyname>Borges-Quintana</keyname><forenames>M.</forenames></author><author><keyname>Borges-Trenard</keyname><forenames>M. A.</forenames></author><author><keyname>Martinez-Moro</keyname><forenames>E.</forenames></author></authors><title>Computing coset leaders of binary codes</title><categories>cs.IT math.IT</categories><comments>Submitted to Designs, Codes and Cryptography</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm for computing the set of all coset leaders of a
binary code $\mathcal C \subset \mathbb{F}_2^n$. The method is adapted from
some of the techniques related to the computation of Gr\&quot;obner representations
associated with codes. The algorithm provides a Gr\&quot;obner representation of the
binary code and the set of coset leaders $\mathrm{CL}(\mathcal C)$. Its
efficiency stands of the fact that its complexity is linear on the number of
elements of $\mathrm{CL}(\mathcal C)$, which is smaller than exhaustive search
in $\mathbb{F}_2^n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5076</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5076</id><created>2010-01-27</created><updated>2010-02-16</updated><authors><author><keyname>Feldman</keyname><forenames>Jon</forenames></author><author><keyname>Henzinger</keyname><forenames>Monika</forenames></author><author><keyname>Korula</keyname><forenames>Nitish</forenames></author><author><keyname>Mirrokni</keyname><forenames>Vahab S.</forenames></author><author><keyname>Stein</keyname><forenames>Cliff</forenames></author></authors><title>Online Stochastic Packing Applied to Display Ad Allocation</title><categories>cs.DS</categories><comments>19 pages, 3 figures, 3 tables. The new version generalizes results to
  a broader class of packing problems, and gives additional applications</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by online ad allocation, we study online stochastic packing linear
programs from theoretical and practical standpoints. We first present a
near-optimal online algorithm for a general class of packing linear programs
which model various online resource allocation problems including online
variants of routing, ad allocations, generalized assignment, and combinatorial
auctions. As our main theoretical result, we prove that a simple primal-dual
training-based algorithm achieves a (1 - o(1))-approximation guarantee in the
random order stochastic model. This is a significant improvement over
logarithmic or constant-factor approximations for the adversarial variants of
the same problems (e.g. factor 1 - 1/e for online ad allocation, and \log m for
online routing). We then focus on the online display ad allocation problem and
study the efficiency and fairness of various training-based and online
allocation algorithms on data sets collected from real-life display ad
allocation system. Our experimental evaluation confirms the effectiveness of
training-based primal-dual algorithms on real data sets, and also indicate an
intrinsic trade-off between fairness and efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5079</identifier>
 <datestamp>2010-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5079</id><created>2010-01-27</created><authors><author><keyname>Deift</keyname><forenames>Percy</forenames></author><author><keyname>G&#xfc;nt&#xfc;rk</keyname><forenames>C. Sinan</forenames></author><author><keyname>Krahmer</keyname><forenames>Felix</forenames></author></authors><title>An Optimal Family of Exponentially Accurate One-Bit Sigma-Delta
  Quantization Schemes</title><categories>cs.IT math.CA math.IT</categories><comments>35 pages, 3 figures</comments><msc-class>94A17; 94A14; 94A12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sigma-Delta modulation is a popular method for analog-to-digital conversion
of bandlimited signals that employs coarse quantization coupled with
oversampling. The standard mathematical model for the error analysis of the
method measures the performance of a given scheme by the rate at which the
associated reconstruction error decays as a function of the oversampling ratio
$\lambda$. It was recently shown that exponential accuracy of the form
$O(2^{-r\lambda})$ can be achieved by appropriate one-bit Sigma-Delta
modulation schemes. By general information-entropy arguments $r$ must be less
than 1. The current best known value for $r$ is approximately 0.088. The
schemes that were designed to achieve this accuracy employ the &quot;greedy&quot;
quantization rule coupled with feedback filters that fall into a class we call
&quot;minimally supported&quot;. In this paper, we study the minimization problem that
corresponds to optimizing the error decay rate for this class of feedback
filters. We solve a relaxed version of this problem exactly and provide
explicit asymptotics of the solutions. From these relaxed solutions, we find
asymptotically optimal solutions of the original problem, which improve the
best known exponential error decay rate to $r \approx 0.102$. Our method draws
from the theory of orthogonal polynomials; in particular, it relates the
optimal filters to the zero sets of Chebyshev polynomials of the second kind.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5100</identifier>
 <datestamp>2010-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5100</id><created>2010-01-27</created><authors><author><keyname>Cao</keyname><forenames>Xiwang</forenames></author><author><keyname>Hu</keyname><forenames>Lei</forenames></author></authors><title>On Exponential Sums, Nowton identities and Dickson Polynomials over
  Finite Fields</title><categories>cs.IT math.IT</categories><comments>18 pages</comments><msc-class>11T23</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\mathbb{F}_{q}$ be a finite field, $\mathbb{F}_{q^s}$ be an extension of
$\mathbb{F}_q$, let $f(x)\in \mathbb{F}_q[x]$ be a polynomial of degree $n$
with $\gcd(n,q)=1$. We present a recursive formula for evaluating the
exponential sum $\sum_{c\in \mathbb{F}_{q^s}}\chi^{(s)}(f(x))$. Let $a$ and $b$
be two elements in $\mathbb{F}_q$ with $a\neq 0$, $u$ be a positive integer. We
obtain an estimate for the exponential sum $\sum_{c\in
\mathbb{F}^*_{q^s}}\chi^{(s)}(ac^u+bc^{-1})$, where $\chi^{(s)}$ is the lifting
of an additive character $\chi$ of $\mathbb{F}_q$. Some properties of the
sequences constructed from these exponential sums are provided also.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5113</identifier>
 <datestamp>2010-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5113</id><created>2010-01-28</created><updated>2010-04-27</updated><authors><author><keyname>Chilappagari</keyname><forenames>Shashi Kiran</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author><author><keyname>Vasic</keyname><forenames>Bane</forenames></author></authors><title>Worst Configurations (Instantons) for Compressed Sensing over Reals: a
  Channel Coding Approach</title><categories>cs.IT math.IT</categories><comments>Accepted to be presented at the IEEE International Symposium on
  Information Theory (ISIT 2010). 5 pages, 2 Figures. Minor edits from previous
  version. Added a new reference.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the Linear Programming (LP) solution of the Compressed Sensing
(CS) problem over reals, also known as the Basis Pursuit (BasP) algorithm. The
BasP allows interpretation as a channel-coding problem, and it guarantees
error-free reconstruction with a properly chosen measurement matrix and
sufficiently sparse error vectors. In this manuscript, we examine how the BasP
performs on a given measurement matrix and develop an algorithm to discover the
sparsest vectors for which the BasP fails. The resulting algorithm is a
generalization of our previous results on finding the most probable
error-patterns degrading performance of a finite size Low-Density Parity-Check
(LDPC) code in the error-floor regime. The BasP fails when its output is
different from the actual error-pattern. We design a CS-Instanton Search
Algorithm (ISA) generating a sparse vector, called a CS-instanton, such that
the BasP fails on the CS-instanton, while the BasP recovery is successful for
any modification of the CS-instanton replacing a nonzero element by zero. We
also prove that, given a sufficiently dense random input for the error-vector,
the CS-ISA converges to an instanton in a small finite number of steps. The
performance of the CS-ISA is illustrated on a randomly generated $120\times
512$ matrix. For this example, the CS-ISA outputs the shortest instanton (error
vector) pattern of length 11.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5130</identifier>
 <datestamp>2010-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5130</id><created>2010-01-28</created><authors><author><keyname>Wan</keyname><forenames>Xiang</forenames></author><author><keyname>Yang</keyname><forenames>Can</forenames></author><author><keyname>Yang</keyname><forenames>Qiang</forenames></author><author><keyname>Xue</keyname><forenames>Hong</forenames></author><author><keyname>Fan</keyname><forenames>Xiaodan</forenames></author><author><keyname>Tang</keyname><forenames>Nelson L. S.</forenames></author><author><keyname>Yu</keyname><forenames>Weichuan</forenames></author></authors><title>BOOST: A fast approach to detecting gene-gene interactions in
  genome-wide case-control studies</title><categories>q-bio.GN cs.CE q-bio.QM</categories><comments>Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gene-gene interactions have long been recognized to be fundamentally
important to understand genetic causes of complex disease traits. At present,
identifying gene-gene interactions from genome-wide case-control studies is
computationally and methodologically challenging. In this paper, we introduce a
simple but powerful method, named `BOolean Operation based Screening and
Testing'(BOOST). To discover unknown gene-gene interactions that underlie
complex diseases, BOOST allows examining all pairwise interactions in
genome-wide case-control studies in a remarkably fast manner. We have carried
out interaction analyses on seven data sets from the Wellcome Trust Case
Control Consortium (WTCCC). Each analysis took less than 60 hours on a standard
3.0 GHz desktop with 4G memory running Windows XP system. The interaction
patterns identified from the type 1 diabetes data set display significant
difference from those identified from the rheumatoid arthritis data set, while
both data sets share a very similar hit region in the WTCCC report. BOOST has
also identified many undiscovered interactions between genes in the major
histocompatibility complex (MHC) region in the type 1 diabetes data set. In the
coming era of large-scale interaction mapping in genome-wide case-control
studies, our method can serve as a computationally and statistically useful
tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5134</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5134</id><created>2010-01-28</created><updated>2010-04-09</updated><authors><author><keyname>Kuznetsov</keyname><forenames>Petr</forenames></author><author><keyname>Schmid</keyname><forenames>Stefan</forenames></author></authors><title>Towards Network Games with Social Preferences</title><categories>cs.DC cs.GT</categories><comments>12 pages</comments><acm-class>C.2.4; F.1.1</acm-class><doi>10.1007/978-3-642-13284-1_3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many distributed systems can be modeled as network games: a collection of
selfish players that communicate in order to maximize their individual
utilities. The performance of such games can be evaluated through the costs of
the system equilibria: the system states in which no player can increase her
utility by unilaterally changing her behavior. However, assuming that all
players are selfish and in particular that all players have the same utility
function may not always be appropriate. Hence, several extensions to
incorporate also altruistic and malicious behavior in addition to selfishness
have been proposed over the last years. In this paper, we seek to go one step
further and study arbitrary relationships between participants. In particular,
we introduce the notion of the social range matrix and explore the effects of
the social range matrix on the equilibria in a network game. In order to derive
concrete results, we propose a simplistic network creation game that captures
the effect of social relationships among players.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5135</identifier>
 <datestamp>2010-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5135</id><created>2010-01-28</created><authors><author><keyname>Efraim</keyname><forenames>Hadar</forenames></author><author><keyname>Yacov</keyname><forenames>Nadav</forenames></author><author><keyname>Shental</keyname><forenames>Ori</forenames></author><author><keyname>Kanter</keyname><forenames>Ido</forenames></author></authors><title>An efficient CDMA decoder for correlated information sources</title><categories>cs.IT cond-mat.stat-mech math.IT</categories><comments>11 pages</comments><journal-ref>J. Stat. Mech. (2009) P07039</journal-ref><doi>10.1088/1742-5468/2009/07/P07039</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the detection of correlated information sources in the ubiquitous
Code-Division Multiple-Access (CDMA) scheme. We propose a message-passing based
scheme for detecting correlated sources directly, with no need for source
coding. The detection is done simultaneously over a block of transmitted binary
symbols (word). Simulation results are provided demonstrating a substantial
improvement in bit-error-rate in comparison with the unmodified detector and
the alternative of source compression. The robustness of the error-performance
improvement is shown under practical model settings, including wrong estimation
of the generating Markov transition matrix and finite-length spreading codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5178</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5178</id><created>2010-01-28</created><updated>2010-10-18</updated><authors><author><keyname>Gadouleau</keyname><forenames>Maximilien</forenames></author><author><keyname>Goupil</keyname><forenames>Alban</forenames></author></authors><title>A Matroid Framework for Noncoherent Random Network Communications</title><categories>cs.IT cs.NI math.CO math.IT</categories><comments>31 pages, 3 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Models for noncoherent error control in random linear network coding (RLNC)
and store and forward (SAF) have been recently proposed. In this paper, we
model different types of random network communications as the transmission of
flats of matroids. This novel framework encompasses RLNC and SAF and allows us
to introduce a novel protocol, referred to as random affine network coding
(RANC), based on affine combinations of packets. Although the models previously
proposed for RLNC and SAF only consider error control, using our framework, we
first evaluate and compare the performance of different network protocols in
the error-free case. We define and determine the rate, average delay, and
throughput of such protocols, and we also investigate the possibilities of
partial decoding before the entire message is received. We thus show that RANC
outperforms RLNC in terms of data rate and throughput thanks to a more
efficient encoding of messages into packets. Second, we model the possible
alterations of a message by the network as an operator channel, which
generalizes the channels proposed for RLNC and SAF. Error control is thus
reduced to a coding-theoretic problem on flats of a matroid, where two distinct
metrics can be used for error correction. We study the maximum cardinality of
codes on flats in general, and codes for error correction in RANC in
particular. We finally design a class of nearly optimal codes for RANC based on
rank metric codes for which we propose a low-complexity decoding algorithm. The
gain of RANC over RLNC is thus preserved with no additional cost in terms of
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5183</identifier>
 <datestamp>2012-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5183</id><created>2010-01-28</created><updated>2012-04-03</updated><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Doyen</keyname><forenames>Laurent</forenames></author></authors><title>Energy Parity Games</title><categories>cs.LO cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy parity games are infinite two-player turn-based games played on
weighted graphs. The objective of the game combines a (qualitative) parity
condition with the (quantitative) requirement that the sum of the weights
(i.e., the level of energy in the game) must remain positive. Beside their own
interest in the design and synthesis of resource-constrained omega-regular
specifications, energy parity games provide one of the simplest model of games
with combined qualitative and quantitative objective. Our main results are as
follows: (a) exponential memory is necessary and sufficient for winning
strategies in energy parity games; (b) the problem of deciding the winner in
energy parity games can be solved in NP \cap coNP; and (c) we give an algorithm
to solve energy parity by reduction to energy games. We also show that the
problem of deciding the winner in energy parity games is polynomially
equivalent to the problem of deciding the winner in mean-payoff parity games,
while optimal strategies may require infinite memory in mean-payoff parity
games. As a consequence we obtain a conceptually simple algorithm to solve
mean-payoff parity games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5194</identifier>
 <datestamp>2010-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5194</id><created>2010-01-28</created><authors><author><keyname>Dramitinos</keyname><forenames>Emmanouil</forenames><affiliation>NES</affiliation></author><author><keyname>Lassous</keyname><forenames>Isabelle Guerin</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme</affiliation></author></authors><title>Auction-based Bandwidth Allocation Mechanisms for Wireless Future
  Internet</title><categories>cs.NI</categories><proxy>ccsd inria-00450922</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important aspect of the Future Internet is the efficient utilization of
(wireless) network resources. In order for the - demanding in terms of QoS -
Future Internet services to be provided, the current trend is evolving towards
an &quot;integrated&quot; wireless network access model that enables users to enjoy
mobility, seamless access and high quality of service in an all-IP network on
an &quot;Anytime, Anywhere&quot; basis. The term &quot;integrated&quot; is used to denote that the
Future Internet wireless &quot;last mile&quot; is expected to comprise multiple
heterogeneous geographically coexisting wireless networks, each having
different capacity and coverage radius. The efficient management of the
wireless access network resources is crucial due to their scarcity that renders
wireless access a potential bottleneck for the provision of high quality
services. In this paper we propose an auction mechanism for allocating the
bandwidth of such a network so that efficiency is attained, i.e. social welfare
is maximized. In particular, we propose an incentive-compatible, efficient
auction-based mechanism of low computational complexity. We define a repeated
game to address user utilities and incentives issues. Subsequently, we extend
this mechanism so that it can also accommodate multicast sessions. We also
analyze the computational complexity and message overhead of the proposed
mechanism. We then show how user bids can be replaced from weights generated by
the network and transform the auction to a cooperative mechanism capable of
prioritizing certain classes of services and emulating DiffServ and time-of-day
pricing schemes. The theoretical analysis is complemented by simulations that
assess the proposed mechanisms properties and performance. We finally provide
some concluding remarks and directions for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5196</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5196</id><created>2010-01-28</created><authors><author><keyname>Sun</keyname><forenames>Jie</forenames></author><author><keyname>ben-Avraham</keyname><forenames>Daniel</forenames></author></authors><title>Greedy Connectivity of Geographically Embedded Graphs</title><categories>cond-mat.stat-mech cs.NI physics.soc-ph</categories><doi>10.1103/PhysRevE.82.016109</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a measure of {\em greedy connectivity} for geographical networks
(graphs embedded in space) and where the search for connecting paths relies
only on local information, such as a node's location and that of its neighbors.
Constraints of this type are common in everyday life applications. Greedy
connectivity accounts also for imperfect transmission across established links
and is larger the higher the proportion of nodes that can be reached from other
nodes with a high probability. Greedy connectivity can be used as a criterion
for optimal network design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5207</identifier>
 <datestamp>2010-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5207</id><created>2010-01-28</created><authors><author><keyname>Maynard</keyname><forenames>C. M.</forenames></author></authors><title>International Lattice Data Grid: Turn on, plug in,and download</title><categories>hep-lat cs.DL</categories><comments>8 pages, 1 figure</comments><journal-ref>PoS(LAT2009)020</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the beginning there was the internet, then came the world wide web, and
now there is the grid. In the future perhaps there will be the cloud. In the
age of persistent, pervasive, and pandemic networks I review how the lattice
QCD community embraced the open source paradigm for both code and data whilst
adopting the emerging grid technologies, and why having your data persistently
accessible via standardized protocols and services might be a good idea.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5244</identifier>
 <datestamp>2010-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5244</id><created>2010-01-28</created><updated>2010-07-26</updated><authors><author><keyname>Gershenson</keyname><forenames>Carlos</forenames></author></authors><title>Computing Networks: A General Framework to Contrast Neural and Swarm
  Cognitions</title><categories>cs.NE cs.AI nlin.AO</categories><comments>18 pages, 5 figures</comments><report-no>C3 Report No. 2010.01</report-no><acm-class>F.1.1; I.2.0; H.1.1</acm-class><journal-ref>Paladyn, Journal of Behavioral Robotics 1(2): 147-153, 2010</journal-ref><doi>10.2478/s13230-010-0015-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the Computing Networks (CNs) framework. CNs are used to
generalize neural and swarm architectures. Artificial neural networks, ant
colony optimization, particle swarm optimization, and realistic biological
models are used as examples of instantiations of CNs. The description of these
architectures as CNs allows their comparison. Their differences and
similarities allow the identification of properties that enable neural and
swarm architectures to perform complex computations and exhibit complex
cognitive abilities. In this context, the most relevant characteristics of CNs
are the existence multiple dynamical and functional scales. The relationship
between multiple dynamical and functional scales with adaptation, cognition (of
brains and swarms) and computation is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5272</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5272</id><created>2010-01-28</created><authors><author><keyname>Harvey</keyname><forenames>David</forenames><affiliation>New York University</affiliation></author><author><keyname>Roche</keyname><forenames>Daniel S.</forenames><affiliation>University of Waterloo</affiliation></author></authors><title>An in-place truncated Fourier transform and applications to polynomial
  multiplication</title><categories>cs.DS cs.MS cs.SC</categories><comments>5 pages, 1 figure, pdflatex</comments><acm-class>F.2.1; G.4; I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The truncated Fourier transform (TFT) was introduced by van der Hoeven in
2004 as a means of smoothing the &quot;jumps&quot; in running time of the ordinary FFT
algorithm that occur at power-of-two input sizes. However, the TFT still
introduces these jumps in memory usage. We describe in-place variants of the
forward and inverse TFT algorithms, achieving time complexity O(n log n) with
only O(1) auxiliary space. As an application, we extend the second author's
results on space-restricted FFT-based polynomial multiplication to polynomials
of arbitrary degree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5275</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5275</id><created>2010-01-28</created><authors><author><keyname>Khalil</keyname><forenames>Khaled M.</forenames></author><author><keyname>Abdel-Aziz</keyname><forenames>M.</forenames></author><author><keyname>Nazmy</keyname><forenames>Taymour T.</forenames></author><author><keyname>Salem</keyname><forenames>Abdel-Badeeh M.</forenames></author></authors><title>An Agent-Based Modeling for Pandemic Influenza in Egypt</title><categories>cs.MA cs.CY</categories><comments>9 pages, 9 figure, 2 tables, sent to INFOS2010 conference (waiting
  for acceptance)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pandemic influenza has great potential to cause large and rapid increases in
deaths and serious illness. The objective of this paper is to develop an
agent-based model to simulate the spread of pandemic influenza (novel H1N1) in
Egypt. The proposed multi-agent model is based on the modeling of individuals'
interactions in a space time context. The proposed model involves different
types of parameters such as: social agent attributes, distribution of Egypt
population, and patterns of agents' interactions. Analysis of modeling results
leads to understanding the characteristics of the modeled pandemic,
transmission patterns, and the conditions under which an outbreak might occur.
In addition, the proposed model is used to measure the effectiveness of
different control strategies to intervene the pandemic spread.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5307</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5307</id><created>2010-01-28</created><authors><author><keyname>Kobayashi</keyname><forenames>Hirotada</forenames></author><author><keyname>Matsumoto</keyname><forenames>Keiji</forenames></author><author><keyname>Tani</keyname><forenames>Seiichiro</forenames></author></authors><title>Computing on Anonymous Quantum Network</title><categories>quant-ph cs.CC cs.CR</categories><comments>25 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers distributed computing on an anonymous quantum network, a
network in which no party has a unique identifier and quantum communication and
computation are available. It is proved that the leader election problem can
exactly (i.e., without error in bounded time) be solved with at most the same
complexity up to a constant factor as that of exactly computing symmetric
functions (without intermediate measurements for a distributed and superposed
input), if the number of parties is given to every party. A corollary of this
result is a more efficient quantum leader election algorithm than existing
ones: the new quantum algorithm runs in O(n) rounds with bit complexity
O(mn^2), on an anonymous quantum network with n parties and m communication
links. Another corollary is the first quantum algorithm that exactly computes
any computable Boolean function with round complexity O(n) and with smaller bit
complexity than that of existing classical algorithms in the worst case over
all (computable) Boolean functions and network topologies. More generally, any
n-qubit state can be shared with that complexity on an anonymous quantum
network with n parties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5310</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5310</id><created>2010-01-28</created><authors><author><keyname>Bryans</keyname><forenames>Jeremy</forenames></author><author><keyname>Fitzgerald</keyname><forenames>John</forenames></author></authors><title>Proceedings Second Workshop on Formal Aspects of Virtual Organisations</title><categories>cs.SE</categories><journal-ref>EPTCS 16, 2010</journal-ref><doi>10.4204/EPTCS.16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  FAVO2009 was the second workshop on Formal Aspects of Virtual Organisations.
The purpose of the FAVO workshops is to encourage an active community of
researchers and practitioners using formal methods in the research and
development of Virtual Organisations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5311</identifier>
 <datestamp>2010-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5311</id><created>2010-01-29</created><updated>2010-05-27</updated><authors><author><keyname>Haupt</keyname><forenames>Jarvis</forenames></author><author><keyname>Castro</keyname><forenames>Rui</forenames></author><author><keyname>Nowak</keyname><forenames>Robert</forenames></author></authors><title>Distilled Sensing: Adaptive Sampling for Sparse Detection and Estimation</title><categories>math.ST cs.IT math.IT stat.ML stat.TH</categories><comments>23 pages, 2 figures. Revision includes minor clarifications, along
  with more illustrative experimental results (cf. Figure 2)</comments><report-no>Rice University ECE Technical Report TREE1001</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adaptive sampling results in dramatic improvements in the recovery of sparse
signals in white Gaussian noise. A sequential adaptive sampling-and-refinement
procedure called Distilled Sensing (DS) is proposed and analyzed. DS is a form
of multi-stage experimental design and testing. Because of the adaptive nature
of the data collection, DS can detect and localize far weaker signals than
possible from non-adaptive measurements. In particular, reliable detection and
localization (support estimation) using non-adaptive samples is possible only
if the signal amplitudes grow logarithmically with the problem dimension. Here
it is shown that using adaptive sampling, reliable detection is possible
provided the amplitude exceeds a constant, and localization is possible when
the amplitude exceeds any arbitrarily slowly growing function of the dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5319</identifier>
 <datestamp>2013-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5319</id><created>2010-01-28</created><updated>2013-01-22</updated><authors><author><keyname>Ramamoorthy</keyname><forenames>Aditya</forenames></author><author><keyname>Langberg</keyname><forenames>Michael</forenames></author></authors><title>Communicating the sum of sources over a network</title><categories>cs.IT cs.NI math.IT</categories><comments>12 pages, IEEE JSAC: Special Issue on In-network
  Computation:Exploring the Fundamental Limits (to appear)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the network communication scenario, over directed acyclic
networks with unit capacity edges in which a number of sources $s_i$ each
holding independent unit-entropy information $X_i$ wish to communicate the sum
$\sum{X_i}$ to a set of terminals $t_j$. We show that in the case in which
there are only two sources or only two terminals, communication is possible if
and only if each source terminal pair $s_i/t_j$ is connected by at least a
single path. For the more general communication problem in which there are
three sources and three terminals, we prove that a single path connecting the
source terminal pairs does not suffice to communicate $\sum{X_i}$. We then
present an efficient encoding scheme which enables the communication of
$\sum{X_i}$ for the three sources, three terminals case, given that each source
terminal pair is connected by {\em two} edge disjoint paths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5334</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5334</id><created>2010-01-29</created><authors><author><keyname>Saritha</keyname><forenames>B. S.</forenames></author><author><keyname>Hemanth</keyname><forenames>S.</forenames></author></authors><title>An Efficient Hidden Markov Model for Offline Handwritten Numeral
  Recognition</title><categories>cs.NI</categories><comments>6pages, 5 figures</comments><journal-ref>InterJRI Computer Science and Networking, Volume 1, pp 7-12, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditionally, the performance of ocr algorithms and systems is based on the
recognition of isolated characters. When a system classifies an individual
character, its output is typically a character label or a reject marker that
corresponds to an unrecognized character. By comparing output labels with the
correct labels, the number of correct recognition, substitution errors
misrecognized characters, and rejects unrecognized characters are determined.
Nowadays, although recognition of printed isolated characters is performed with
high accuracy, recognition of handwritten characters still remains an open
problem in the research arena. The ability to identify machine printed
characters in an automated or a semi automated manner has obvious applications
in numerous fields. Since creating an algorithm with a one hundred percent
correct recognition rate is quite probably impossible in our world of noise and
different font styles, it is important to design character recognition
algorithms with these failures in mind so that when mistakes are inevitably
made, they will at least be understandable and predictable to the person
working with the
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5336</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5336</id><created>2010-01-29</created><authors><author><keyname>Huang</keyname><forenames>Chuan</forenames></author><author><keyname>Jiang</keyname><forenames>Jinhua</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Asymptotic Capacity of Large Fading Relay Networks with Random Node
  Failures</title><categories>cs.IT math.IT</categories><comments>24 pages, 5 figures, submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To understand the network response to large-scale physical attacks, we
investigate the asymptotic capacity of a half-duplex fading relay network with
random node failures when the number of relays $N$ is infinitely large. In this
paper, a simplified independent attack model is assumed where each relay node
fails with a certain probability. The noncoherent relaying scheme is
considered, which corresponds to the case of zero forward-link channel state
information (CSI) at the relays. Accordingly, the whole relay network can be
shown equivalent to a Rayleigh fading channel, where we derive the
$\epsilon$-outage capacity upper bound according to the multiple access (MAC)
cut-set, and the $\epsilon$-outage achievable rates for both the
amplify-and-forward (AF) and decode-and-forward (DF) strategies. Furthermore,
we show that the DF strategy is asymptotically optimal as the outage
probability $\epsilon$ goes to zero, with the AF strategy strictly suboptimal
over all signal to noise ratio (SNR) regimes. Regarding the rate loss due to
random attacks, the AF strategy suffers a less portion of rate loss than the DF
strategy in the high SNR regime, while the DF strategy demonstrates more robust
performance in the low SNR regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5339</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5339</id><created>2010-01-29</created><authors><author><keyname>Shet</keyname><forenames>N. S. V.</forenames></author><author><keyname>Chandrasekaran</keyname><forenames>K.</forenames></author><author><keyname>Shet</keyname><forenames>K. C.</forenames></author></authors><title>Implementation of Connectivity and Handover through Wireless Sensor Node
  based Techniques</title><categories>cs.NI</categories><comments>5 pages, 8 figures</comments><journal-ref>InterJRI Computer Science and Networking, Volume 1, pp 13-17, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a scheme for handoff and connectivity, based on wireless sensor
nodetechniques is proposed. Scenes are created in Qualnet and simulated for a
simple case. Results are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5348</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5348</id><created>2010-01-29</created><authors><author><keyname>Satapathy</keyname><forenames>Suresh Chandra</forenames></author><author><keyname>Pradhan</keyname><forenames>Gunanidhi</forenames></author><author><keyname>Pattnaik</keyname><forenames>Sabyasachi</forenames></author><author><keyname>Murthy</keyname><forenames>J. V. R.</forenames></author><author><keyname>Reddy</keyname><forenames>P. V. G. D. Prasad</forenames></author></authors><title>Performance Comparisons of PSO based Clustering</title><categories>cs.NE cs.LG</categories><comments>6 pages 2 figures</comments><journal-ref>InterJRI Computer Science and Networking, Volume 1, pp18-23, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we have investigated the performance of PSO Particle Swarm
Optimization based clustering on few real world data sets and one artificial
data set. The performances are measured by two metric namely quantization error
and inter-cluster distance. The K means clustering algorithm is first
implemented for all data sets, the results of which form the basis of
comparison of PSO based approaches. We have explored different variants of PSO
such as gbest, lbest ring, lbest vonneumann and Hybrid PSO for comparison
purposes. The results reveal that PSO based clustering algorithms perform
better compared to K means in all data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5352</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5352</id><created>2010-01-29</created><authors><author><keyname>Indira</keyname><forenames>K.</forenames></author><author><keyname>Selvi</keyname><forenames>S. Sethu</forenames></author></authors><title>Kannada Character Recognition System A Review</title><categories>cs.CV</categories><comments>12 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intensive research has been done on optical character recognition ocr and a
large number of articles have been published on this topic during the last few
decades. Many commercial OCR systems are now available in the market, but most
of these systems work for Roman, Chinese, Japanese and Arabic characters. There
are no sufficient number of works on Indian language character recognition
especially Kannada script among 12 major scripts in India. This paper presents
a review of existing work on printed Kannada script and their results. The
characteristics of Kannada script and Kannada Character Recognition System kcr
are discussed in detail. Finally fusion at the classifier level is proposed to
increase the recognition accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5358</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5358</id><created>2010-01-29</created><authors><author><keyname>Rao</keyname><forenames>P. V. R. R. Bhogendra</forenames></author><author><keyname>Prasad</keyname><forenames>V. Kamakshi</forenames></author></authors><title>Design of Run time Architectures for Real time UML Models an Actor
  Centric Approach</title><categories>cs.SE</categories><comments>6 pages, 3 figurs</comments><journal-ref>InterJRI Computer Science and Networking, Volume 1, pp 43-48,,
  2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although a lot of research has taken place in Object Oriented Design of
software for Real Time systems and mapping of design models to implementation
models, these methodologies are applicable to systems which are less complex
and small in source code size. However, in practice, the size of the software
for real time applications is growing. The run time architecture of real time
applications is becoming increasingly complex. In this paper, we present a
generic approach for mapping the design models to run time architectures
resulting in combination of processes and threads. This method is applied in
development of a communication subsystem of C4I complex and shall be presented
as a case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5359</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5359</id><created>2010-01-29</created><authors><author><keyname>Rathinavel</keyname><forenames>S.</forenames></author><author><keyname>Arumugam</keyname><forenames>S.</forenames></author></authors><title>Threshold Based Indexing of Commercial Shoe Print to Create Reference
  and Recovery Images</title><categories>cs.CV</categories><comments>4 pages, 8 figures</comments><journal-ref>InterJRI Computer Science and Networking, Volume 1, pp 49-52, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the important evidence in a crime scene that is normally overlooked
but very important evidence is shoe print as the criminal is normally unaware
of the mask for this. In this paper we use image processing technique to
process reference shoe images to make it index-able for a search from the
database the shoe print impressions available in the commercial market. This is
achieved first by converting the commercially available image through the
process of converting them to gray scale then apply image enhancement and
restoration techniques and finally do image segmentation to store the segmented
parameter as index in the database storage. We use histogram method for image
enhancement, inverse filtering for image restoration and threshold method for
indexing. We use global threshold as index of the shoe print. The paper
describes this method and simulation results are included to validate the
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5364</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5364</id><created>2010-01-29</created><authors><author><keyname>Goldberger</keyname><forenames>Jacobb</forenames></author><author><keyname>Leshem</keyname><forenames>Amir</forenames></author></authors><title>MIMO Detection for High-Order QAM Based on a Gaussian Tree Approximation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new detection algorithm for MIMO communication systems
employing high order QAM constellations. The factor graph that corresponds to
this problem is very loopy; in fact, it is a complete graph. Hence, a
straightforward application of the Belief Propagation (BP) algorithm yields
very poor results. Our algorithm is based on an optimal tree approximation of
the Gaussian density of the unconstrained linear system. The finite-set
constraint is then applied to obtain a loop-free discrete distribution. It is
shown that even though the approximation is not directly applied to the exact
discrete distribution, applying the BP algorithm to the loop-free factor graph
outperforms current methods in terms of both performance and complexity. The
improved performance of the proposed algorithm is demonstrated on the problem
of MIMO detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5404</identifier>
 <datestamp>2011-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5404</id><created>2010-01-29</created><updated>2011-06-08</updated><authors><author><keyname>Avanzini</keyname><forenames>Martin</forenames></author><author><keyname>Moser</keyname><forenames>Georg</forenames></author></authors><title>Efficient Implementation of Rewriting Revisited Technical Report</title><categories>cs.CC cs.LO</categories><comments>Submitted to RTA 2010</comments><acm-class>F.1.2; F.1.3; F.4.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Recently, many techniques have been introduced that allow the (automated)
classification of the runtime complexity of term rewrite systems (TRSs for
short). In earlier work, the authors have shown that for confluent TRSs,
innermost polynomial runtime complexity induces polytime computability of the
functions defined.
  In this paper, we generalise the above result to full rewriting. Following
our previous work, we exploit graph rewriting. We give a new proof of the
adequacy of graph rewriting for full rewriting that allows for a precise
control of the resources copied. In sum we completely describe an
implementation of rewriting on a Turing machine (TM for short). We show that
the runtime complexity of the TRS and the runtime complexity of the TM is
polynomially related. Our result strengthens the evidence that the complexity
of a rewrite system is truthfully represented through the length of
derivations. Moreover our result allows the classification of non-deterministic
polytime-computation based on runtime complexity analysis of rewrite systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5420</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5420</id><created>2010-01-29</created><authors><author><keyname>Hanan</keyname><forenames>William</forenames></author><author><keyname>Mehta</keyname><forenames>Dhagash</forenames></author><author><keyname>Moroz</keyname><forenames>Guillaume</forenames></author><author><keyname>Pouryahya</keyname><forenames>Sepanda</forenames></author></authors><title>Stability and Bifurcation Analysis of Coupled Fitzhugh-Nagumo
  Oscillators</title><categories>q-bio.NC cs.SC nlin.CD q-bio.QM</categories><comments>&quot;Extended abstract&quot; published in the Joint Conference of ASCM2009 and
  MACIS2009, Japan, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neurons are the central biological objects in understanding how the brain
works. The famous Hodgkin-Huxley model, which describes how action potentials
of a neuron are initiated and propagated, consists of four coupled nonlinear
differential equations. Because these equations are difficult to deal with,
there also exist several simplified models, of which many exhibit
polynomial-like non-linearity. Examples of such models are the Fitzhugh-Nagumo
(FHN) model, the Hindmarsh-Rose (HR) model, the Morris-Lecar (ML) model and the
Izhikevich model. In this work, we first prescribe the biologically relevant
parameter ranges for the FHN model and subsequently study the dynamical
behaviour of coupled neurons on small networks of two or three nodes. To do
this, we use a computational real algebraic geometry method called the
Discriminant Variety (DV) method to perform the stability and bifurcation
analysis of these small networks. A time series analysis of the FHN model can
be found elsewhere in related work[15].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5421</identifier>
 <datestamp>2014-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5421</id><created>2010-01-29</created><authors><author><keyname>Hochreiter</keyname><forenames>Ronald</forenames></author></authors><title>A note on evolutionary stochastic portfolio optimization and
  probabilistic constraints</title><categories>q-fin.PM cs.CE cs.NE</categories><journal-ref>Proceedings of MENDEL 2010: 1-6. 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we extend an evolutionary stochastic portfolio optimization
framework to include probabilistic constraints. Both the stochastic
programming-based modeling environment as well as the evolutionary optimization
environment are ideally suited for an integration of various types of
probabilistic constraints. We show an approach on how to integrate these
constraints. Numerical results using recent financial data substantiate the
applicability of the presented approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5454</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5454</id><created>2010-01-29</created><updated>2010-06-19</updated><authors><author><keyname>Chernyak</keyname><forenames>Vladimir Y.</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author><author><keyname>Goldberg</keyname><forenames>David A.</forenames></author><author><keyname>Turitsyn</keyname><forenames>Konstantin</forenames></author></authors><title>Non-Equilibrium Statistical Physics of Currents in Queuing Networks</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.IT math.IT math.PR</categories><comments>26 pages, 5 figures</comments><report-no>LA-UR 10-00419</report-no><doi>10.1007/s10955-010-0018-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a stable open queuing network as a steady non-equilibrium system
of interacting particles. The network is completely specified by its underlying
graphical structure, type of interaction at each node, and the Markovian
transition rates between nodes. For such systems, we ask the question ``What is
the most likely way for large currents to accumulate over time in a network
?'', where time is large compared to the system correlation time scale. We
identify two interesting regimes. In the first regime, in which the
accumulation of currents over time exceeds the expected value by a small to
moderate amount (moderate large deviation), we find that the large-deviation
distribution of currents is universal (independent of the interaction details),
and there is no long-time and averaged over time accumulation of particles
(condensation) at any nodes. In the second regime, in which the accumulation of
currents over time exceeds the expected value by a large amount (severe large
deviation), we find that the large-deviation current distribution is sensitive
to interaction details, and there is a long-time accumulation of particles
(condensation) at some nodes. The transition between the two regimes can be
described as a dynamical second order phase transition. We illustrate these
ideas using the simple, yet non-trivial, example of a single node with
feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5460</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5460</id><created>2010-01-29</created><authors><author><keyname>Morozov</keyname><forenames>Oleksii</forenames></author><author><keyname>Hunziker</keyname><forenames>Patrick</forenames></author></authors><title>Solving Tensor Structured Problems with Computational Tensor Algebra</title><categories>cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since its introduction by Gauss, Matrix Algebra has facilitated understanding
of scientific problems, hiding distracting details and finding more elegant and
efficient ways of computational solving. Today's largest problems, which often
originate from multidimensional data, might profit from even higher levels of
abstraction. We developed a framework for solving tensor structured problems
with tensor algebra that unifies concepts from tensor analysis, multilinear
algebra and multidimensional signal processing. In contrast to the conventional
matrix approach, it allows the formulation of multidimensional problems, in a
multidimensional way, preserving structure and data coherence; and the
implementation of automated optimizations of solving algorithms, based on the
commutativity of all tensor operations. Its ability to handle large scientific
tasks is showcased by a real-world, 4D medical imaging problem, with more than
30 million unknown parameters solved on a current, inexpensive hardware. This
significantly surpassed the best published matrix-based approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5470</identifier>
 <datestamp>2010-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5470</id><created>2010-01-29</created><updated>2010-08-20</updated><authors><author><keyname>Delacourt</keyname><forenames>Martin</forenames><affiliation>LIF</affiliation></author><author><keyname>Poupet</keyname><forenames>Victor</forenames><affiliation>LIF</affiliation></author><author><keyname>Sablik</keyname><forenames>Mathieu</forenames><affiliation>LATP</affiliation></author><author><keyname>Theyssier</keyname><forenames>Guillaume</forenames><affiliation>LAMA</affiliation></author></authors><title>Directional Dynamics along Arbitrary Curves in Cellular Automata</title><categories>cs.DM</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies directional dynamics in cellular automata, a formalism
previously introduced by the third author. The central idea is to study the
dynamical behaviour of a cellular automaton through the conjoint action of its
global rule (temporal action) and the shift map (spacial action): qualitative
behaviours inherited from topological dynamics (equicontinuity, sensitivity,
expansivity) are thus considered along arbitrary curves in space-time. The main
contributions of the paper concern equicontinuous dynamics which can be
connected to the notion of consequences of a word. We show that there is a
cellular automaton with an equicontinuous dynamics along a parabola, but which
is sensitive along any linear direction. We also show that real numbers that
occur as the slope of a limit linear direction with equicontinuous dynamics in
some cellular automaton are exactly the computably enumerable numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1001.5471</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1001.5471</id><created>2010-01-29</created><updated>2010-09-24</updated><authors><author><keyname>Delorme</keyname><forenames>Marianne</forenames><affiliation>LIP</affiliation></author><author><keyname>Mazoyer</keyname><forenames>Jacques</forenames><affiliation>LIP</affiliation></author><author><keyname>Ollinger</keyname><forenames>Nicolas</forenames><affiliation>LIF</affiliation></author><author><keyname>Theyssier</keyname><forenames>Guillaume</forenames><affiliation>LAMA</affiliation></author></authors><title>Bulking II: Classifications of Cellular Automata</title><categories>cs.FL</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is the second part of a series of two papers dealing with bulking:
a way to define quasi-order on cellular automata by comparing space-time
diagrams up to rescaling. In the present paper, we introduce three notions of
simulation between cellular automata and study the quasi-order structures
induced by these simulation relations on the whole set of cellular automata.
Various aspects of these quasi-orders are considered (induced equivalence
relations, maximum elements, induced orders, etc) providing several formal
tools allowing to classify cellular automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0007</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0007</id><created>2010-01-29</created><authors><author><keyname>Saucan</keyname><forenames>Emil</forenames></author></authors><title>Curvature based triangulation of metric measure spaces</title><categories>math.DG cs.IT math.CV math.IT</categories><comments>24 pages, submitted for publication</comments><msc-class>53C23, 53B20, 60D05, Secondary: 30C65</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that a Ricci curvature based method of triangulation of compact
Riemannian manifolds, due to Grove and Petersen, extends to the context of
weighted Riemannian manifolds and more general metric measure spaces. In both
cases the role of the lower bound on Ricci curvature is replaced by the
curvature-dimension condition ${\rm CD}(K,N)$. We show also that for weighted
Riemannian manifolds the triangulation can be improved to become a thick one
and that, in consequence, such manifolds admit weight-sensitive
quasimeromorphic mappings. An application of this last result to information
manifolds is considered.
  Further more, we extend to weak ${\rm CD}(K,N)$ spaces the results of Kanai
regarding the discretization of manifolds, and show that the volume growth of
such a space is the same as that of any of its discretizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0012</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0012</id><created>2010-01-29</created><authors><author><keyname>Carette</keyname><forenames>Jacques</forenames></author><author><keyname>Davenport</keyname><forenames>James H.</forenames></author></authors><title>The Power of Vocabulary: The Case of Cyclotomic Polynomials</title><categories>cs.SC cs.DS cs.MS math.AC</categories><comments>7 pages. Submitted to ISSAC 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We observe that the vocabulary used to construct the &quot;answer&quot; to problems in
computer algebra can have a dramatic effect on the computational complexity of
solving that problem. We recall a formalization of this observation and explain
the classic example of sparse polynomial arithmetic. For this case, we show
that it is possible to extend the vocabulary so as reap the benefits of
conciseness whilst avoiding the obvious pitfall of repeating the problem
statement as the &quot;solution&quot;.
  It is possible to extend the vocabulary either by irreducible cyclotomics or
by $x^n-1$: we look at the options and suggest that the pragmatist might opt
for both.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0019</identifier>
 <datestamp>2012-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0019</id><created>2010-01-29</created><updated>2012-03-27</updated><authors><author><keyname>Lu</keyname><forenames>Wei</forenames></author><author><keyname>Vaswani</keyname><forenames>Namrata</forenames></author></authors><title>Regularized Modified BPDN for Noisy Sparse Reconstruction with Partial
  Erroneous Support and Signal Value Knowledge</title><categories>cs.IT math.IT</categories><comments>30 pages, 5 figures</comments><journal-ref>IEEE transaction on Signal Processing, January 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of sparse reconstruction from noisy undersampled
measurements when the following two things are available. (1) We are given
partial, and partly erroneous, knowledge of the signal's support, denoted by
$T$. (2) We are also given an erroneous estimate of the signal values on $T$,
denoted by $(\hat{\mu})_T$. In practice, both these may be available from
available prior knowledge. Alternatively, in recursive reconstruction
applications, like real-time dynamic MRI, one can use the support estimate and
the signal value estimate from the previous time instant as $T$ and
$(\hat{\mu})_T$. In this work, we introduce regularized modified-BPDN
(reg-mod-BPDN) and obtain computable bounds on its reconstruction error.
Reg-mod-BPDN tries to find the signal that is sparsest outside the set $T$,
while being &quot;close enough&quot; to $(\hat{\mu})_T$ on $T$ and while satisfying the
data constraint. Corresponding results for modified-BPDN and BPDN follow as
direct corollaries. A second key contribution is an approach to obtain
computable error bounds that hold without any sufficient conditions. This makes
it easy to compare the bounds for the various approaches. Empirical
reconstruction error comparisons with many existing approaches are also
provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0026</identifier>
 <datestamp>2010-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0026</id><created>2010-02-01</created><updated>2010-07-05</updated><authors><author><keyname>Rif&#xe0;-Pous</keyname><forenames>H.</forenames></author><author><keyname>Rif&#xe0;</keyname><forenames>J.</forenames></author><author><keyname>Ronquillo</keyname><forenames>L.</forenames></author></authors><title>Perfect Z2Z4-linear codes in Steganography</title><categories>cs.IT cs.CR math.IT</categories><comments>5 pages, revised version</comments><acm-class>H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Steganography is an information hiding application which aims to hide secret
data imperceptibly into a commonly used media. Unfortunately, the theoretical
hiding asymptotical capacity of steganographic systems is not attained by
algorithms developed so far. In this paper, we describe a novel coding method
based on Z2Z4-linear codes that conforms to +/-1-steganography, that is secret
data is embedded into a cover message by distorting each symbol by one unit at
most. This method solves some problems encountered by the most efficient
methods known today, based on ternary Hamming codes. Finally, the performance
of this new technique is compared with that of the mentioned methods and with
the well-known theoretical upper bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0035</identifier>
 <datestamp>2011-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0035</id><created>2010-01-29</created><updated>2011-01-25</updated><authors><author><keyname>Stein</keyname><forenames>Noah D.</forenames></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames></author><author><keyname>Parrilo</keyname><forenames>Pablo A.</forenames></author></authors><title>Structure of Extreme Correlated Equilibria: a Zero-Sum Example and its
  Implications</title><categories>cs.GT</categories><journal-ref>International Journal of Game Theory, Volume 40, Number 4,
  749-767, 2011</journal-ref><doi>10.1007/s00182-010-0267-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We exhibit the rich structure of the set of correlated equilibria by
analyzing the simplest of polynomial games: the mixed extension of matching
pennies. We show that while the correlated equilibrium set is convex and
compact, the structure of its extreme points can be quite complicated. In
finite games the ratio of extreme correlated to extreme Nash equilibria can be
greater than exponential in the size of the strategy spaces. In polynomial
games there can exist extreme correlated equilibria which are not finitely
supported; we construct a large family of examples using techniques from
ergodic theory. We show that in general the set of correlated equilibrium
distributions of a polynomial game cannot be described by conditions on
finitely many moments (means, covariances, etc.), in marked contrast to the set
of Nash equilibria which is always expressible in terms of finitely many
moments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0043</identifier>
 <datestamp>2010-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0043</id><created>2010-01-30</created><updated>2010-06-04</updated><authors><author><keyname>Nguyen</keyname><forenames>Phong S.</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna R.</forenames></author></authors><title>A Rate-Distortion Exponent Approach to Multiple Decoding Attempts for
  Reed-Solomon Codes</title><categories>cs.IT math.IT</categories><comments>accepted for presentation at 2010 IEEE International Symposium on
  Information Theory (ISIT 2010), Austin TX, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithms based on multiple decoding attempts of Reed-Solomon (RS) codes
have recently attracted new attention. Choosing decoding candidates based on
rate-distortion (R-D) theory, as proposed previously by the authors, currently
provides the best performance-versus-complexity trade-off. In this paper, an
analysis based on the rate-distortion exponent (RDE) is used to directly
minimize the exponential decay rate of the error probability. This enables
rigorous bounds on the error probability for finite-length RS codes and leads
to modest performance gains. As a byproduct, a numerical method is derived that
computes the rate-distortion exponent for independent non-identical sources.
Analytical results are given for errors/erasures decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0046</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0046</id><created>2010-01-30</created><updated>2010-06-01</updated><authors><author><keyname>Bodini</keyname><forenames>Olivier</forenames><affiliation>LIP6</affiliation></author><author><keyname>Ponty</keyname><forenames>Yann</forenames><affiliation>LIX</affiliation></author></authors><title>Multi-dimensional Boltzmann Sampling of Languages</title><categories>cs.DS</categories><comments>12pp</comments><proxy>ccsd</proxy><journal-ref>AOFA'10, Vienne : Autriche (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the uniform random generation of words from a
context-free language (over an alphabet of size $k$), while constraining every
letter to a targeted frequency of occurrence. Our approach consists in a
multidimensional extension of Boltzmann samplers \cite{Duchon2004}. We show
that, under mostly \emph{strong-connectivity} hypotheses, our samplers return a
word of size in $[(1-\varepsilon)n, (1+\varepsilon)n]$ and exact frequency in
$\mathcal{O}(n^{1+k/2})$ expected time. Moreover, if we accept tolerance
intervals of width in $\Omega(\sqrt{n})$ for the number of occurrences of each
letters, our samplers perform an approximate-size generation of words in
expected $\mathcal{O}(n)$ time. We illustrate these techniques on the
generation of Tetris tessellations with uniform statistics in the different
types of tetraminoes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0049</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0049</id><created>2010-01-30</created><authors><author><keyname>Rajesh</keyname><forenames>A. M.</forenames></author><author><keyname>Bharath</keyname><forenames>K. N.</forenames></author></authors><title>Solar Still Coupled With Solar Collector and Storage Tank</title><categories>cs.OH</categories><comments>11 pages, 14 figures</comments><journal-ref>InterJRI Science and Technology, Volume 1, pp 62-72, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acute shortage of good, clean drinking water is a major problem for most
developing countries of the world. In most cases, ponds, streams, wells and
rivers are often polluted that they are unsafe for direct use as drinking water
&gt;.Often water sources are brackish and or contain harmful bacteria. Therefore
cannot be used for drinking .In addition there are many coastal locations where
sea water is abundant but potable water is not available. Solar distillation is
one of the important methods of utilizing solar energy for the supply of
potable water to small communities where natural supply of fresh water is
inadequate or of poor quality .In this direction an experimental performance
analysis was carried out on a single basin still compared with FPC coupled one.
Test were carried out for different water samples namely borewell water, sea
water, river water for a water depth of 20 mm
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0063</identifier>
 <datestamp>2010-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0063</id><created>2010-01-30</created><updated>2010-03-03</updated><authors><author><keyname>Safilian</keyname><forenames>Ali Akbar</forenames></author><author><keyname>Didehvar</keyname><forenames>Farzad</forenames></author></authors><title>Enumeration Order Reducibility</title><categories>cs.FL cs.CC</categories><comments>This paper is the second version of our work on Enumeration Orders</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we define a new reducibility based on the enumeration orders
of r.e. sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0097</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0097</id><created>2010-01-30</created><updated>2012-02-09</updated><authors><author><keyname>Kakhbod</keyname><forenames>Ali</forenames></author><author><keyname>Zadimoghaddam</keyname><forenames>Morteza</forenames></author></authors><title>On the Construction of Prefix-Free and Fix-Free Codes with Specified
  Codeword Compositions</title><categories>cs.IT math.IT</categories><journal-ref>Discrete Applied Mathematics (DAM). vol. 159, no. 18, pp
  2269-2275, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the construction of prefix-free and fix-free codes with
specified codeword compositions. We present a polynomial time algorithm which
constructs a fix-free code with the same codeword compositions as a given code
for a special class of codes called distinct codes. We consider the
construction of optimal fix-free codes which minimizes the average codeword
cost for general letter costs with uniform distribution of the codewords and
present an approximation algorithm to find a near optimal fix-free code with a
given constant cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0102</identifier>
 <datestamp>2015-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0102</id><created>2010-01-30</created><updated>2015-10-02</updated><authors><author><keyname>Smarandache</keyname><forenames>Florentin</forenames></author></authors><title>$\alpha$-Discounting Multi-Criteria Decision Making ($\alpha$-D MCDM)</title><categories>cs.AI</categories><comments>62 pages</comments><acm-class>I.2.3</acm-class><journal-ref>Proceedings of Fusion 2010 International Conference, Edinburgh,
  Scotland, 26-29 July, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this book we introduce a new procedure called \alpha-Discounting Method
for Multi-Criteria Decision Making (\alpha-D MCDM), which is as an alternative
and extension of Saaty Analytical Hierarchy Process (AHP). It works for any
number of preferences that can be transformed into a system of homogeneous
linear equations. A degree of consistency (and implicitly a degree of
inconsistency) of a decision-making problem are defined. \alpha-D MCDM is
afterwards generalized to a set of preferences that can be transformed into a
system of linear and or non-linear homogeneous and or non-homogeneous equations
and or inequalities. The general idea of \alpha-D MCDM is to assign non-null
positive parameters \alpha_1, \alpha_2, and so on \alpha_p to the coefficients
in the right-hand side of each preference that diminish or increase them in
order to transform the above linear homogeneous system of equations which has
only the null-solution, into a system having a particular non-null solution.
After finding the general solution of this system, the principles used to
assign particular values to all parameters \alpha is the second important part
of \alpha-D, yet to be deeper investigated in the future. In the current book
we propose the Fairness Principle, i.e. each coefficient should be discounted
with the same percentage (we think this is fair: not making any favoritism or
unfairness to any coefficient), but the reader can propose other principles.
For consistent decision-making problems with pairwise comparisons,
\alpha-Discounting Method together with the Fairness Principle give the same
result as AHP. But for weak inconsistent decision-making problem,
\alpha-Discounting together with the Fairness Principle give a different result
from AHP. Many consistent, weak inconsistent, and strong inconsistent examples
are given in this book.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0108</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0108</id><created>2010-01-31</created><authors><author><keyname>Kubanek</keyname><forenames>Petr</forenames></author></authors><title>Genetic algorithm for robotic telescope scheduling</title><categories>cs.AI astro-ph.IM</categories><comments>38 pages; master thesis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work was inspired by author experiences with a telescope scheduling.
Author long time goal is to develop and further extend software for an
autonomous observatory. The software shall provide users with all the
facilities they need to take scientific images of the night sky, cooperate with
other autonomous observatories, and possibly more. This works shows how genetic
algorithm can be used for scheduling of a single observatory, as well as
network of observatories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0110</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0110</id><created>2010-02-01</created><authors><author><keyname>Jung</keyname><forenames>Alexander</forenames></author><author><keyname>Ben-Haim</keyname><forenames>Zvika</forenames></author><author><keyname>Hlawatsch</keyname><forenames>Franz</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>On Unbiased Estimation of Sparse Vectors Corrupted by Gaussian Noise</title><categories>cs.IT math.IT</categories><comments>4 pages, 2 figures. To appear in ICASSP 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the estimation of a sparse parameter vector from measurements
corrupted by white Gaussian noise. Our focus is on unbiased estimation as a
setting under which the difficulty of the problem can be quantified
analytically. We show that there are infinitely many unbiased estimators but
none of them has uniformly minimum mean-squared error. We then provide lower
and upper bounds on the Barankin bound, which describes the performance
achievable by unbiased estimators. These bounds are used to predict the
threshold region of practical estimators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0123</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0123</id><created>2010-01-31</created><authors><author><keyname>Kim</keyname><forenames>Sang Joon</forenames></author><author><keyname>Smida</keyname><forenames>Besma</forenames></author><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author></authors><title>Achievable rate regions and outer bounds for a multi-pair bi-directional
  relay network</title><categories>cs.IT math.IT</categories><comments>61 pages, 12 figures, will be submitted to IEEE info theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a bi-directional relay channel, a pair of nodes wish to exchange
independent messages over a shared wireless half-duplex channel with the help
of relays. Recent work has mostly considered information theoretic limits of
the bi-directional relay channel with two terminal nodes (or end users) and one
relay. In this work we consider bi-directional relaying with one base station,
multiple terminal nodes and one relay, all of which operate in half-duplex
modes. We assume that each terminal node communicates with the base-station in
a bi-directional fashion through the relay and do not place any restrictions on
the channels between the users, relays and base-stations; that is, each node
has a direct link with every other node.
  Our contributions are three-fold: 1) the introduction of four new temporal
protocols which fully exploit the two-way nature of the data and outperform
simple routing or multi-hop communication schemes by carefully combining
network coding, random binning and user cooperation which exploit over-heard
and own-message side information, 2) derivations of inner and outer bounds on
the capacity region of the discrete-memoryless multi-pair two-way network, and
3) a numerical evaluation of the obtained achievable rate regions and outer
bounds in Gaussian noise which illustrate the performance of the proposed
protocols compared to simpler schemes, to each other, to the outer bounds,
which highlight the relative gains achieved by network coding, random binning
and compress-and-forward-type cooperation between terminal nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0125</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0125</id><created>2010-01-31</created><authors><author><keyname>&#xc5;strand</keyname><forenames>Matti</forenames></author><author><keyname>Polishchuk</keyname><forenames>Valentin</forenames></author><author><keyname>Rybicki</keyname><forenames>Joel</forenames></author><author><keyname>Suomela</keyname><forenames>Jukka</forenames></author><author><keyname>Uitto</keyname><forenames>Jara</forenames></author></authors><title>Local algorithms in (weakly) coloured graphs</title><categories>cs.DC</categories><comments>14 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A local algorithm is a distributed algorithm that completes after a constant
number of synchronous communication rounds. We present local approximation
algorithms for the minimum dominating set problem and the maximum matching
problem in 2-coloured and weakly 2-coloured graphs. In a weakly 2-coloured
graph, both problems admit a local algorithm with the approximation factor
$(\Delta+1)/2$, where $\Delta$ is the maximum degree of the graph. We also give
a matching lower bound proving that there is no local algorithm with a better
approximation factor for either of these problems. Furthermore, we show that
the stronger assumption of a 2-colouring does not help in the case of the
dominating set problem, but there is a local approximation scheme for the
maximum matching problem in 2-coloured graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0134</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0134</id><created>2010-01-31</created><authors><author><keyname>Kotthoff</keyname><forenames>Lars</forenames></author></authors><title>Constraint solvers: An empirical evaluation of design decisions</title><categories>cs.AI cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an evaluation of the design decisions made in four
state-of-the-art constraint solvers; Choco, ECLiPSe, Gecode, and Minion. To
assess the impact of design decisions, instances of the five problem classes
n-Queens, Golomb Ruler, Magic Square, Social Golfers, and Balanced Incomplete
Block Design are modelled and solved with each solver. The results of the
experiments are not meant to give an indication of the performance of a solver,
but rather investigate what influence the choice of algorithms and data
structures has.
  The analysis of the impact of the design decisions focuses on the different
ways of memory management, behaviour with increasing problem size, and
specialised algorithms for specific types of variables. It also briefly
considers other, less significant decisions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0136</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0136</id><created>2010-01-31</created><authors><author><keyname>Kotthoff</keyname><forenames>Lars</forenames></author></authors><title>Dominion -- A constraint solver generator</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a design for a system to generate constraint solvers that
are specialised for specific problem models. It describes the design in detail
and gives preliminary experimental results showing the feasibility and
effectiveness of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0139</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0139</id><created>2010-01-31</created><authors><author><keyname>Hiremath</keyname><forenames>P. S</forenames></author><author><keyname>Algur</keyname><forenames>Siddu P.</forenames></author></authors><title>Extraction of Flat and Nested Data Records from Web Pages</title><categories>cs.DB</categories><comments>10 Pages IEEE format, International Journal on Computer Science and
  Engineering, IJCSE 2010, ISSN 0975-3397, Impact Factor 0.583</comments><report-no>IJEST10-02-01-07</report-no><journal-ref>International Journal on Computer Science and Engineering, IJCSE,
  Vol. 2, No. 1 January 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of identification and extraction of flat and
nested data records from a given web page. With the explosive growth of
information sources available on the World Wide Web, it has become increasingly
difficult to identify the relevant pieces of information, since web pages are
often cluttered with irrelevant content like advertisements, navigation-panels,
copyright notices etc., surrounding the main content of the web page. Hence, it
is useful to mine such data regions and data records in order to extract
information from such web pages to provide value-added services. Currently
available automatic techniques to mine data regions and data records from web
pages are still unsatisfactory because of their poor performance. In this paper
a novel method to identify and extract the flat and nested data records from
the web pages automatically is proposed. It comprises of two steps : (1)
Identification and Extraction of the data regions based on visual clues
information. (2) Identification and extraction of flat and nested data records
from the data region of a web page automatically. For step1, a novel and more
effective method is proposed, which finds the data regions formed by all types
of tags using visual clues. For step2, a more effective and efficient method
namely, Visual Clue based Extraction of web Data (VCED), is proposed, which
extracts each record from the data region and identifies it whether it is a
flat or nested data record based on visual clue information the area covered by
and the number of data items present in each record. Our experimental results
show that the proposed technique is effective and better than existing
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0145</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0145</id><created>2010-01-31</created><updated>2010-02-08</updated><authors><author><keyname>Saxena</keyname><forenames>Nitin</forenames></author><author><keyname>Seshadhri</keyname><forenames>C.</forenames></author></authors><title>From Sylvester-Gallai Configurations to Rank Bounds: Improved Black-box
  Identity Test for Depth-3 Circuits</title><categories>cs.CC cs.DM</categories><comments>33 pages, 1 table, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of identity testing for depth-3 circuits of top fanin k
and degree d. We give a new structure theorem for such identities. A direct
application of our theorem improves the known deterministic d^{k^k}-time
black-box identity test over rationals (Kayal-Saraf, FOCS 2009) to one that
takes d^{k^2}-time. Our structure theorem essentially says that the number of
independent variables in a real depth-3 identity is very small. This theorem
settles affirmatively the stronger rank conjectures posed by Dvir-Shpilka (STOC
2005) and Kayal-Saraf (FOCS 2009). Our techniques provide a unified framework
that actually beats all known rank bounds and hence gives the best running time
(for every field) for black-box identity tests.
  Our main theorem (almost optimally) pins down the relation between higher
dimensional Sylvester-Gallai theorems and the rank of depth-3 identities in a
very transparent manner. The existence of this was hinted at by Dvir-Shpilka
(STOC 2005), but first proven, for reals, by Kayal-Saraf (FOCS 2009). We
introduce the concept of Sylvester-Gallai rank bounds for any field, and show
the intimate connection between this and depth-3 identity rank bounds. We also
prove the first ever theorem about high dimensional Sylvester-Gallai
configurations over any field. Our proofs and techniques are very different
from previous results and devise a very interesting ensemble of combinatorics
and algebra. The latter concepts are ideal theoretic and involve a new Chinese
remainder theorem. Our proof methods explain the structure of any depth-3
identity C: there is a nucleus of C that forms a low rank identity, while the
remainder is a high dimensional Sylvester-Gallai configuration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0154</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0154</id><created>2010-01-31</created><authors><author><keyname>Humbert</keyname><forenames>Pierre</forenames><affiliation>LORIA</affiliation></author></authors><title>Usages et conception des TIC : Proposition d'un mod\`ele d'aide \`a la
  repr\'esentation de probl\`eme de conception</title><categories>cs.SE</categories><proxy>ccsd hal-00440806</proxy><journal-ref>Colloque International Enjeux et Usages des TIC : Strat\'egies du
  changement dans les syst\`emes et les territoires, Bordeaux : France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers economic intelligence contribution to exploit individual
and collective images of change, in ICT design decision-making. Technical
devices meeting with real use situations often gives the opportunity to emerge
mental images, that a innovation process, through its unprecedented nature, can
not anticipate. Although methodologies exists for quality and design project
management, the survey we conduct among small ICT publishers, show how they are
not very suitable for small firms. This elements taken into account, we try to
build a proposition of exploration ? analyze ? sum up process, adapted to this
type of actors decisional process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0155</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0155</id><created>2010-01-31</created><authors><author><keyname>Weibel</keyname><forenames>Christophe</forenames></author></authors><title>Maximal f-vectors of Minkowski sums of large numbers of polytopes</title><categories>cs.CG</categories><comments>15 pages, 2 figures, submitted to Symposium on Computational Geometry</comments><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that in the Minkowski sum of $r$ polytopes in dimension $d$, with
$r&lt;d$, the number of vertices of the sum can potentially be as high as the
product of the number of vertices in each summand. However, the number of
vertices for sums of more polytopes was unknown so far. In this paper, we study
sums of polytopes in general orientations, and show a linear relation between
the number of faces of a sum of $r$ polytopes in dimension $d$, with $r\geq d$,
and the number of faces in the sums of less than $d$ of the summand polytopes.
We deduce from this exact formula a tight bound on the maximum possible number
of vertices of the Minkowski sum of any number of polytopes in any dimension.
In particular, the linear relation implies that a sum of $r$ polytopes in
dimension $d$ has a number of vertices in $O(n^{d-1})$ of the total number of
vertices in the summands, even when $r\geq d$. This bound is tight, in the
sense that some sums do have that many vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0169</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0169</id><created>2010-01-31</created><authors><author><keyname>Preciado</keyname><forenames>Victor M.</forenames></author><author><keyname>Jadbabaie</keyname><forenames>Ali</forenames></author></authors><title>Moment-Based Analysis of Synchronization in Small-World Networks of
  Oscillators</title><categories>cs.MA cs.CE cs.DM nlin.AO</categories><comments>6 pages, 4 figures</comments><journal-ref>IEEE Conference of Decision and Control, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate synchronization in a small-world network of
coupled nonlinear oscillators. This network is constructed by introducing
random shortcuts in a nearest-neighbors ring. The local stability of the
synchronous state is closely related with the support of the eigenvalue
distribution of the Laplacian matrix of the network. We introduce, for the
first time, analytical expressions for the first three moments of the
eigenvalue distribution of the Laplacian matrix as a function of the
probability of shortcuts and the connectivity of the underlying
nearest-neighbor coupled ring. We apply these expressions to estimate the
spectral support of the Laplacian matrix in order to predict synchronization in
small-world networks. We verify the efficiency of our predictions with
numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0170</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0170</id><created>2010-01-31</created><updated>2010-02-02</updated><authors><author><keyname>Preciado</keyname><forenames>Victor M.</forenames></author><author><keyname>Jadbabaie</keyname><forenames>Ali</forenames></author></authors><title>Spectral Analysis of Virus Spreading in Random Geometric Networks</title><categories>cs.MA cs.CE cs.DM nlin.AO</categories><comments>6 pages, 5 figures</comments><journal-ref>IEEE Conference on Decision and Control, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the dynamics of a viral spreading process in random
geometric graphs (RGG). The spreading of the viral process we consider in this
paper is closely related with the eigenvalues of the adjacency matrix of the
graph. We deduce new explicit expressions for all the moments of the eigenvalue
distribution of the adjacency matrix as a function of the spatial density of
nodes and the radius of connection. We apply these expressions to study the
behavior of the viral infection in an RGG. Based on our results, we deduce an
analytical condition that can be used to design RGG's in order to tame an
initial viral infection. Numerical simulations are in accordance with our
analytical predictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0172</identifier>
 <datestamp>2010-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0172</id><created>2010-01-31</created><updated>2010-04-15</updated><authors><author><keyname>Gor&#xe9;</keyname><forenames>Rajeev</forenames></author><author><keyname>Widmann</keyname><forenames>Florian</forenames></author></authors><title>Optimal and Cut-free Tableaux for Propositional Dynamic Logic with
  Converse</title><categories>cs.LO</categories><comments>30 pages, minor improvements, some typos, change of title</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an optimal (EXPTIME), sound and complete tableau-based algorithm for
deciding satisfiability for propositional dynamic logic with converse (CPDL)
which does not require the use of analytic cut. Our main contribution is a
sound methodto combine our previous optimal method for tracking least
fix-points in PDL with our previous optimal method for handling converse in the
description logic ALCI. The extension is non-trivial as the two methods cannot
be combined naively. We give sufficient details to enable an implementation by
others. Our OCaml implementation seems to be the first theorem prover for CPDL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0177</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0177</id><created>2010-01-31</created><authors><author><keyname>Padhy</keyname><forenames>C. N.</forenames></author><author><keyname>Panda</keyname><forenames>R. R.</forenames></author></authors><title>Logical Evaluation of Consciousness: For Incorporating Consciousness
  into Machine Architecture</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine Consciousness is the study of consciousness in a biological,
philosophical, mathematical and physical perspective and designing a model that
can fit into a programmable system architecture. Prime objective of the study
is to make the system architecture behave consciously like a biological model
does. Present work has developed a feasible definition of consciousness, that
characterizes consciousness with four parameters i.e., parasitic, symbiotic,
self referral and reproduction. Present work has also developed a biologically
inspired consciousness architecture that has following layers: quantum layer,
cellular layer, organ layer and behavioral layer and traced the characteristics
of consciousness at each layer. Finally, the work has estimated physical and
algorithmic architecture to devise a system that can behave consciously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0179</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0179</id><created>2010-01-31</created><updated>2010-09-12</updated><authors><author><keyname>Norton</keyname><forenames>Graham H.</forenames></author></authors><title>B\'{e}zout Identities Associated to a Finite Sequence</title><categories>cs.IT cs.SC math.IT</categories><comments>Major revision, based on recursive index function and minimal
  polynomial theorem of 1001.1597. Improved notation. Contains new identities
  and applications. References expanded</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider finite sequences $s\in D^n$ where $D$ is a commutative, unital,
integral domain. We prove three sets of identities (possibly with repetitions),
each involving $2n$ polynomials associated to $s$. The right-hand side of these
identities is a recursively-defined (non-zero) 'product-of-discrepancies'.
There are implied iterative algorithms (of quadratic complexity) for the
left-hand side coefficients; when the ground domain is factorial, the
identities are in effect B\'ezout identities.
  We give a number of applications: an algorithm to compute B\'ezout
coefficients over a field; the outputs of the Berlekamp-Massey algorithm;
sequences with perfect linear complexity profile; annihilating polynomials
which do not vanish at zero and have minimal degree: we simplify and extend an
algorithm of Salagean to sequences over $D$. In the Appendix, we give a new
proof of a theorem of Imamura and Yoshida on the linear complexity of reverse
sequences, initially proved using Hankel matrices over a field and now valid
for sequences over a factorial domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0182</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0182</id><created>2010-02-01</created><authors><author><keyname>G&#xfc;nt&#xfc;rk</keyname><forenames>S.</forenames></author><author><keyname>Powell</keyname><forenames>A.</forenames></author><author><keyname>Saab</keyname><forenames>R.</forenames></author><author><keyname>Y&#x131;lmaz</keyname><forenames>&#xd6;.</forenames></author></authors><title>Sobolev Duals for Random Frames and Sigma-Delta Quantization of
  Compressed Sensing Measurements</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantization of compressed sensing measurements is typically justified by the
robust recovery results of Cand\`es, Romberg and Tao, and of Donoho. These
results guarantee that if a uniform quantizer of step size $\delta$ is used to
quantize $m$ measurements $y = \Phi x$ of a $k$-sparse signal $x \in \R^N$,
where $\Phi$ satisfies the restricted isometry property, then the approximate
recovery $x^#$ via $\ell_1$-minimization is within $O(\delta)$ of $x$. The
simplest and commonly assumed approach is to quantize each measurement
independently. In this paper, we show that if instead an $r$th order
$\Sigma\Delta$ quantization scheme with the same output alphabet is used to
quantize $y$, then there is an alternative recovery method via Sobolev dual
frames which guarantees a reduction of the approximation error by a factor of
$(m/k)^{(r-1/2)\alpha}$ for any $0 &lt; \alpha &lt; 1$, if $m \gtrsim_r k (\log
N)^{1/(1-\alpha)}$. The result holds with high probability on the initial draw
of the measurement matrix $\Phi$ from the Gaussian distribution, and uniformly
for all $k$-sparse signals $x$ that satisfy a mild size condition on their
supports.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0184</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0184</id><created>2010-02-01</created><authors><author><keyname>Diamant</keyname><forenames>Emanuel</forenames></author></authors><title>Some considerations on how the human brain must be arranged in order to
  make its replication in a thinking machine possible</title><categories>cs.AI q-bio.NC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the most of my life, I have earned my living as a computer vision
professional busy with image processing tasks and problems. In the computer
vision community there is a widespread belief that artificial vision systems
faithfully replicate human vision abilities or at least very closely mimic
them. It was a great surprise to me when one day I have realized that computer
and human vision have next to nothing in common. The former is occupied with
extensive data processing, carrying out massive pixel-based calculations, while
the latter is busy with meaningful information processing, concerned with smart
objects-based manipulations. And the gap between the two is insurmountable. To
resolve this confusion, I had had to return and revaluate first the vision
phenomenon itself, define more carefully what visual information is and how to
treat it properly. In this work I have not been, as it is usually accepted,
biologically inspired . On the contrary, I have drawn my inspirations from a
pure mathematical theory, the Kolmogorov s complexity theory. The results of my
work have been already published elsewhere. So the objective of this paper is
to try and apply the insights gained in course of this my enterprise to a more
general case of information processing in human brain and the challenging issue
of human intelligence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0205</identifier>
 <datestamp>2010-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0205</id><created>2010-02-01</created><updated>2010-02-23</updated><authors><author><keyname>Li</keyname><forenames>Hua-Chieh</forenames></author><author><keyname>Chen</keyname><forenames>Ming-Yang</forenames></author><author><keyname>Cioffi</keyname><forenames>John M.</forenames></author></authors><title>On the Generality of $1+\mathbf{i}$ as a Non-Norm Element</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Informaion Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Full-rate space-time block codes with nonvanishing determinants have been
extensively designed with cyclic division algebras. For these designs, smaller
pairwise error probabilities of maximum likelihood detections require larger
normalized diversity products, which can be obtained by choosing integer
non-norm elements with smaller absolute values. All known methods have
constructed $1+\bi$ and $2+\bi$ to be integer non-norm elements with the
smallest absolute values over QAM for the number of transmit antennas $n$:
$\{n:5\leq n\leq 40,8\nmid n\}$ and $\{n:5\leq n\leq 40,8\mid n\}$,
respectively. Via explicit constructions, this paper proves that $1+\bi$ is an
integer non-norm element with the smallest absolute value over QAM for every
$n\geq 5$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0214</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0214</id><created>2010-02-01</created><authors><author><keyname>Samper</keyname><forenames>Serge</forenames><affiliation>SYMME</affiliation></author><author><keyname>Adragna</keyname><forenames>Pierre-Antoine</forenames><affiliation>SYMME</affiliation></author><author><keyname>Favreliere</keyname><forenames>Hugues</forenames><affiliation>SYMME</affiliation></author><author><keyname>Pillet</keyname><forenames>Maurice</forenames><affiliation>SYMME</affiliation></author></authors><title>Modeling of 2D and 3D Assemblies Taking Into Account Form Errors of
  Plane Surfaces</title><categories>cs.OH</categories><proxy>ccsd hal-00451883</proxy><journal-ref>Journal of Computing and Information Science in Engineering 9, 4
  (2009) 041005</journal-ref><doi>10.1115/1.3249575</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The tolerancing process links the virtual and the real worlds. From the
former, tolerances define a variational geometrical language (geometric
parameters). From the latter, there are values limiting those parameters. The
beginning of a tolerancing process is in this duality. As high precision
assemblies cannot be analyzed with the assumption that form errors are
negligible, we propose to apply this process to assemblies with form errors
through a new way of allowing to parameterize forms and solve their assemblies.
The assembly process is calculated through a method of allowing to solve the 3D
assemblies of pairs of surfaces having form errors using a static equilibrium.
We have built a geometrical model based on the modal shapes of the ideal
surface. We compute for the completely deterministic contact points between
this pair of shapes according to a given assembly process. The solution gives
an accurate evaluation of the assembly performance. Then we compare the results
with or without taking into account the form errors. When we analyze a batch of
assemblies, the problem is to compute for the nonconformity rate of a pilot
production according to the functional requirements. We input probable errors
of surfaces (position, orientation, and form) in our calculus and we evaluate
the quality of the results compared with the functional requirements. The pilot
production then can or cannot be validated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0215</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0215</id><created>2010-02-01</created><authors><author><keyname>Bessagnet</keyname><forenames>Marie-No&#xeb;lle</forenames><affiliation>LIUPPA</affiliation></author><author><keyname>Kergosien</keyname><forenames>Eric</forenames><affiliation>LIUPPA</affiliation></author><author><keyname>Gaio</keyname><forenames>Mauro</forenames><affiliation>LIUPPA</affiliation></author></authors><title>Extraction de termes, reconnaissance et labellisation de relations dans
  un th\'esaurus</title><categories>cs.IR</categories><proxy>ccsd hal-00451960</proxy><journal-ref>CIDE'12: 12e Colloque International sur le Document Electronique,
  Montr\'eal : Canada (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Within the documentary system domain, the integration of thesauri for
indexing and retrieval information steps is usual. In libraries, documents own
rich descriptive information made by librarians, under descriptive notice based
on Rameau thesaurus. We exploit two kinds of information in order to create a
first semantic structure. A step of conceptualization allows us to define the
various modules used to automatically build the semantic structure of the
indexation work. Our current work focuses on an approach that aims to define an
ontology based on a thesaurus. We hope to integrate new knowledge
characterizing the territory of our structure (adding &quot;toponyms&quot; and links
between concepts) thanks to a geographic information system (GIS).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0217</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0217</id><created>2010-02-01</created><authors><author><keyname>Zweig</keyname><forenames>K. A.</forenames></author><author><keyname>Palla</keyname><forenames>G.</forenames></author><author><keyname>Vicsek</keyname><forenames>T.</forenames></author></authors><title>What makes a phase transition? Analysis of the random satisfiability
  problem</title><categories>physics.data-an cs.CC physics.comp-ph</categories><journal-ref>Physica A 389, 1501-1511 (2010)</journal-ref><doi>10.1016/j.physa.2009.12.051</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the last 30 years it was found that many combinatorial systems undergo
phase transitions. One of the most important examples of these can be found
among the random k-satisfiability problems (often referred to as k-SAT), asking
whether there exists an assignment of Boolean values satisfying a Boolean
formula composed of clauses with k random variables each. The random 3-SAT
problem is reported to show various phase transitions at different critical
values of the ratio of the number of clauses to the number of variables. The
most famous of these occurs when the probability of finding a satisfiable
instance suddenly drops from 1 to 0. This transition is associated with a rise
in the hardness of the problem, but until now the correlation between any of
the proposed phase transitions and the hardness is not totally clear. In this
paper we will first show numerically that the number of solutions universally
follows a lognormal distribution, thereby explaining the puzzling question of
why the number of solutions is still exponential at the critical point.
Moreover we provide evidence that the hardness of the closely related problem
of counting the total number of solutions does not show any phase
transition-like behavior. This raises the question of whether the probability
of finding a satisfiable instance is really an order parameter of a phase
transition or whether it is more likely to just show a simple sharp threshold
phenomenon. More generally, this paper aims at starting a discussion where a
simple sharp threshold phenomenon turns into a genuine phase transition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0235</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0235</id><created>2010-02-01</created><updated>2010-06-02</updated><authors><author><keyname>Aldridge</keyname><forenames>Matthew</forenames></author><author><keyname>Johnson</keyname><forenames>Oliver</forenames></author><author><keyname>Piechocki</keyname><forenames>Robert</forenames></author></authors><title>Asymptotic Sum-Capacity of Random Gaussian Interference Networks Using
  Interference Alignment</title><categories>cs.IT math.IT</categories><comments>5 pages; to appear at ISIT 2010</comments><acm-class>E.4</acm-class><journal-ref>2010 IEEE International Symposium on Information Theory, Austin,
  Texas, June 2010, pages 410-414</journal-ref><doi>10.1109/ISIT.2010.5513390</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a dense n-user Gaussian interference network formed by paired
transmitters and receivers placed independently at random in Euclidean space.
Under natural conditions on the node position distributions and signal
attenuation, we prove convergence in probability of the average per-user
capacity C_Sigma/n to 1/2 E log(1 + 2SNR).
  The achievability result follows directly from results based on an
interference alignment scheme presented in recent work of Nazer et al. Our main
contribution comes through the converse result, motivated by ideas of
`bottleneck links' developed in recent work of Jafar. An information theoretic
argument gives a capacity bound on such bottleneck links, and probabilistic
counting arguments show there are sufficiently many such links to tightly bound
the sum-capacity of the whole network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0239</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0239</id><created>2010-02-01</created><authors><author><keyname>Kergosien</keyname><forenames>Eric</forenames><affiliation>LIUPPA</affiliation></author><author><keyname>Kamel</keyname><forenames>Mouna</forenames><affiliation>IRIT</affiliation></author><author><keyname>Sallaberry</keyname><forenames>Christian</forenames><affiliation>LIUPPA</affiliation></author><author><keyname>Bessagnet</keyname><forenames>Marie-No&#xeb;lle</forenames><affiliation>LIUPPA</affiliation></author><author><keyname>Gilles</keyname><forenames>Nathalie Aussenac-</forenames><affiliation>IRIT</affiliation></author><author><keyname>Gaio</keyname><forenames>Mauro</forenames><affiliation>LIUPPA</affiliation></author></authors><title>Construction et enrichissement automatique d'ontologie \`a partir de
  ressources externes</title><categories>cs.IR</categories><proxy>ccsd hal-00451980</proxy><journal-ref>JFO'09: 3es Journ\'ees Francophones sur les Ontologies, Poitiers :
  France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic construction of ontologies from text is generally based on
retrieving text content. For a much more rich ontology we extend these
approaches by taking into account the document structure and some external
resources (like thesaurus of indexing terms of near domain). In this paper we
describe how these external resources are at first analyzed and then exploited.
This method has been applied on a geographical domain and the benefit has been
evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0251</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0251</id><created>2010-02-01</created><authors><author><keyname>Favreliere</keyname><forenames>Hugues</forenames><affiliation>SYMME</affiliation></author><author><keyname>Samper</keyname><forenames>Serge</forenames><affiliation>SYMME</affiliation></author><author><keyname>Adragna</keyname><forenames>Pierre-Antoine</forenames><affiliation>SYMME</affiliation></author></authors><title>Caract\'erisation des d\'efauts d'une surface sph\'erique par
  d\'ecomposition modale</title><categories>cs.OH</categories><proxy>ccsd hal-00452064</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The [ISO 1101] standard specifies the form errors with geometrical tolerances
using the zone concept.To complete this concept, we present a generic method
which adapts to any geometry and allows to describe any kind of errors. Thus,we
can dissociate the part errors according to reference categories: position,
orientation,form, waviness and roughnesses. Starting from a cloud of poinds
representing the error measurement, the &quot;modal&quot; method decompose, like Fourier
series,this error in a sum of sorted errors according to the ircomplexity
degree (a number of &quot;wavinesses&quot;). In addition, we propose to show, on a simple
example, that according to error complexity to be characterized, an
interpolation by the modal method allows to optimize the measuring strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0253</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0253</id><created>2010-02-01</created><authors><author><keyname>Adragna</keyname><forenames>Pierre-Antoine</forenames><affiliation>SYMME</affiliation></author><author><keyname>Samper</keyname><forenames>Serge</forenames><affiliation>SYMME</affiliation></author><author><keyname>Pillet</keyname><forenames>Maurice</forenames><affiliation>SYMME</affiliation></author></authors><title>A proposition of 3D inertial tolerancing to consider the statistical
  combination of the location and orientation deviations</title><categories>cs.OH</categories><proxy>ccsd hal-00452096</proxy><journal-ref>International Journal of Product Development 10, 1-2 (2010)
  26-45(20)</journal-ref><doi>10.1504/IJPD.2010.029985</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tolerancing of assembly mechanisms is a major interest in the product life
cycle. One can distinguish several models with growing complexity, from
1-dimensional (1D) to 3-dimensional (3D) (including form deviations), and two
main tolerancing assumptions, the worst case and the statistical hypothesis.
This paper presents an approach to 3D statistical tolerancing using a new
acceptance criterion. Our approach is based on the 1D inertial acceptance
criterion that is extended to 3D and form acceptance. The modal
characterisation is used to describe the form deviation of a geometry as the
combination of elementary deviations (location, orientation and form). The
proposed 3D statistical tolerancing is applied on a simple mechanism with lever
arm. It is also compared to the traditional worst-case tolerancing using a
tolerance zone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0262</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0262</id><created>2010-02-01</created><authors><author><keyname>Ledoux</keyname><forenames>Y.</forenames><affiliation>TREFLE</affiliation></author><author><keyname>Favreliere</keyname><forenames>H.</forenames><affiliation>SYMME</affiliation></author><author><keyname>Samper</keyname><forenames>Serge</forenames><affiliation>SYMME</affiliation></author></authors><title>Optimization of a Classical Stamping Progression by Modal Correction of
  Anisotropy Ears</title><categories>cs.OH</categories><proxy>ccsd hal-00452113</proxy><journal-ref>Journal of Manufacturing Science and Engineering 129, 6 (2007)
  1101-1108</journal-ref><doi>10.1115/1.2769730</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work is a development from the Inetforsmep European project. We proposed
to realize a global optimization of a deep drawing industrial progression (made
of several stages) for a cup manufacture. The objectives of the process were
the thickness decrease and the geometrical parameters (especially the height).
This paper improves on this previous work in the aim of mastering the contour
error. From the optimal configuration, we expect to cut down the amount of the
needed material and the number of forming operations. Our action is focused on
the appearance of unexpected undulations (ears) located on the rim of the cups
during forming due to a nonuniform crystallographic texture. Those undulations
can cause a significant amount of scraps, productivity loss, and cost during
manufacture. In this paper, this phenomenon causes the use of four forming
operations for the cup manufacture. The aim is to cut down from four to two
forming stages by defining an optimal blank (size and shape). The advantage is
to reduce the cost of the tool manufacturing and to minimize the needed
material (by suppressing the part flange). The chosen approach consists in
defining a particular description of the ears' part by modal decomposition and
then simulating several blank shapes and sizes generated by discrete cosine
transformation (DCT). The use of a numerical simulation for the forming
operation and the design of an experiment technique allow mathematical links
between the ears' formation and the DCT coefficients. An optimization is then
possible by using mathematical links. This original approach leads the ears'
amplitude to be reduced by a factor of 10, with only 15 numerical experiments.
Moreover, we have limited the number of forming stages from 4 to 2 with a
minimal material use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0270</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0270</id><created>2010-02-01</created><authors><author><keyname>Adragna</keyname><forenames>Pierre-Antoine</forenames><affiliation>SYMME</affiliation></author><author><keyname>Pillet</keyname><forenames>Maurice</forenames><affiliation>SYMME</affiliation></author><author><keyname>Formosa</keyname><forenames>Fabien</forenames><affiliation>SYMME</affiliation></author><author><keyname>Samper</keyname><forenames>Serge</forenames><affiliation>SYMME</affiliation></author></authors><title>Inertial tolerancing and capability indices in an assembly production</title><categories>cs.OH</categories><proxy>ccsd hal-00452137</proxy><journal-ref>Revue Internationale d Ingenierie Numerique 2, 1-2 (2006) 71-88</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional tolerancing considers the conformity of a batch when the batch
satisfies the specifications. The characteristic is considered for itself and
not according to its incidence in the assembly. Inertial tolerancing proposes
another alternative of tolerancing in order to guarantee the final assembly
characteristic. The inertia I2 = \sqrt{\delta^2 + \sigma^2} is not toleranced
by a tolerance interval but by a scalar representing the maximum inertia that
the characteristic should not exceed. We detail how to calculate the inertial
tolerances according to two cases, one aims to guarantee an inertia of the
assembly characteristic the other a tolerance interval on the assembly
characteristic by a Cpk capability index, in the particular but common case of
uniform tolerances or more general with non uniform tolerances. An example will
be detailed to show the results of the different tolerancing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0276</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0276</id><created>2010-02-01</created><authors><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Dendritic Cells for SYN Scan Detection</title><categories>cs.AI cs.CR cs.NE</categories><comments>8 Pages, 9 Figures, Genetic and Evolutionary Computation Conference
  (GECCO 2007)</comments><journal-ref>Proceedings of the Genetic and Evolutionary Computation Conference
  (GECCO 2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificial immune systems have previously been applied to the problem of
intrusion detection. The aim of this research is to develop an intrusion
detection system based on the function of Dendritic Cells (DCs). DCs are
antigen presenting cells and key to activation of the human immune system,
behaviour which has been abstracted to form the Dendritic Cell Algorithm (DCA).
In algorithmic terms, individual DCs perform multi-sensor data fusion,
asynchronously correlating the the fused data signals with a secondary data
stream. Aggregate output of a population of cells, is analysed and forms the
basis of an anomaly detection system. In this paper the DCA is applied to the
detection of outgoing port scans using TCP SYN packets. Results show that
detection can be achieved with the DCA, yet some false positives can be
encountered when simultaneously scanning and using other network services.
Suggestions are made for using adaptive signals to alleviate this uncovered
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0286</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0286</id><created>2010-02-01</created><updated>2010-02-23</updated><authors><author><keyname>Crowston</keyname><forenames>R.</forenames></author><author><keyname>Gutin</keyname><forenames>G.</forenames></author><author><keyname>Jones</keyname><forenames>M.</forenames></author><author><keyname>Kim</keyname><forenames>E. J.</forenames></author><author><keyname>Ruzsa</keyname><forenames>I. Z.</forenames></author></authors><title>Systems of Linear Equations over $\mathbb{F}_2$ and Problems
  Parameterized Above Average</title><categories>cs.DM cs.DS</categories><doi>10.1007/978-3-642-13731-0_17</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the problem Max Lin, we are given a system $Az=b$ of $m$ linear equations
with $n$ variables over $\mathbb{F}_2$ in which each equation is assigned a
positive weight and we wish to find an assignment of values to the variables
that maximizes the excess, which is the total weight of satisfied equations
minus the total weight of falsified equations. Using an algebraic approach, we
obtain a lower bound for the maximum excess.
  Max Lin Above Average (Max Lin AA) is a parameterized version of Max Lin
introduced by Mahajan et al. (Proc. IWPEC'06 and J. Comput. Syst. Sci. 75,
2009). In Max Lin AA all weights are integral and we are to decide whether the
maximum excess is at least $k$, where $k$ is the parameter.
  It is not hard to see that we may assume that no two equations in $Az=b$ have
the same left-hand side and $n={\rm rank A}$. Using our maximum excess results,
we prove that, under these assumptions, Max Lin AA is fixed-parameter tractable
for a wide special case: $m\le 2^{p(n)}$ for an arbitrary fixed function
$p(n)=o(n)$.
  Max $r$-Lin AA is a special case of Max Lin AA, where each equation has at
most $r$ variables. In Max Exact $r$-SAT AA we are given a multiset of $m$
clauses on $n$ variables such that each clause has $r$ variables and asked
whether there is a truth assignment to the $n$ variables that satisfies at
least $(1-2^{-r})m + k2^{-r}$ clauses. Using our maximum excess results, we
prove that for each fixed $r\ge 2$, Max $r$-Lin AA and Max Exact $r$-SAT AA can
be solved in time $2^{O(k \log k)}+m^{O(1)}.$ This improves
$2^{O(k^2)}+m^{O(1)}$-time algorithms for the two problems obtained by Gutin et
al. (IWPEC 2009) and Alon et al. (SODA 2010), respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0295</identifier>
 <datestamp>2015-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0295</id><created>2010-02-01</created><authors><author><keyname>Rif&#xe0;</keyname><forenames>Josep</forenames></author><author><keyname>Zinoviev</keyname><forenames>Victor</forenames></author></authors><title>On lifting perfect codes</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider completely regular codes, obtained from perfect
(Hamming) codes by lifting the ground field. More exactly, for a given perfect
code C of length n=(q^m-1)/(q-1) over F_q with a parity check matrix H_m, we
define a new code C_{(m,r)} of length n over F_{q^r}, r &gt; 1, with this parity
check matrix H_m. The resulting code C_{(m,r)} is completely regular with
covering radius R = min{r,m}. We compute the intersection numbers of such codes
and, finally, we prove that Hamming codes are the only codes that, after
lifting the ground field, result in completely regular codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0298</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0298</id><created>2010-02-01</created><authors><author><keyname>Kannan</keyname><forenames>Jayanthkumar</forenames></author><author><keyname>Maniatis</keyname><forenames>Petros</forenames></author><author><keyname>Chun</keyname><forenames>Byung-Gon</forenames></author></authors><title>A Data Capsule Framework For Web Services: Providing Flexible Data
  Access Control To Users</title><categories>cs.CR cs.OS</categories><acm-class>D.4.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the notion of a secure data capsule, which refers to an
encapsulation of sensitive user information (such as a credit card number)
along with code that implements an interface suitable for the use of such
information (such as charging for purchases) by a service (such as an online
merchant). In our capsule framework, users provide their data in the form of
such capsules to web services rather than raw data. Capsules can be deployed in
a variety of ways, either on a trusted third party or the user's own computer
or at the service itself, through the use of a variety of hardware or software
modules, such as a virtual machine monitor or trusted platform module: the only
requirement is that the deployment mechanism must ensure that the user's data
is only accessed via the interface sanctioned by the user. The framework
further allows an user to specify policies regarding which services or machines
may host her capsule, what parties are allowed to access the interface, and
with what parameters. The combination of interface restrictions and policy
control lets us bound the impact of an attacker who compromises the service to
gain access to the user's capsule or a malicious insider at the service itself.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0378</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0378</id><created>2010-02-01</created><updated>2010-02-08</updated><authors><author><keyname>Niu</keyname><forenames>Jinzhong</forenames></author><author><keyname>Cai</keyname><forenames>Kai</forenames></author><author><keyname>Parsons</keyname><forenames>Simon</forenames></author></authors><title>A Grey-Box Approach to Automated Mechanism Design</title><categories>cs.GT cs.AI cs.MA</categories><comments>18 pages, 2 figures, 2 tables, and 1 algorithm. Extended abstract to
  appear in the proceedings of AAMAS'2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Auctions play an important role in electronic commerce, and have been used to
solve problems in distributed computing. Automated approaches to designing
effective auction mechanisms are helpful in reducing the burden of traditional
game theoretic, analytic approaches and in searching through the large space of
possible auction mechanisms. This paper presents an approach to automated
mechanism design (AMD) in the domain of double auctions. We describe a novel
parametrized space of double auctions, and then introduce an evolutionary
search method that searches this space of parameters. The approach evaluates
auction mechanisms using the framework of the TAC Market Design Game and
relates the performance of the markets in that game to their constituent parts
using reinforcement learning. Experiments show that the strongest mechanisms we
found using this approach not only win the Market Design Game against known,
strong opponents, but also exhibit desirable economic properties when they run
in isolation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0382</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0382</id><created>2010-02-01</created><authors><author><keyname>Kisku</keyname><forenames>Dakshina Ranjan</forenames></author><author><keyname>Tistarelli</keyname><forenames>Massimo</forenames></author><author><keyname>Sing</keyname><forenames>Jamuna Kanta</forenames></author><author><keyname>Gupta</keyname><forenames>Phalguni</forenames></author></authors><title>Face Recognition by Fusion of Local and Global Matching Scores using DS
  Theory: An Evaluation with Uni-classifier and Multi-classifier Paradigm</title><categories>cs.CV cs.AI</categories><comments>7 pages, 6 figures, IEEE Computer Vision and Pattern Recognition
  Workshop on Biometrics</comments><acm-class>D.2.2; I.2.10</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Faces are highly deformable objects which may easily change their appearance
over time. Not all face areas are subject to the same variability. Therefore
decoupling the information from independent areas of the face is of paramount
importance to improve the robustness of any face recognition technique. This
paper presents a robust face recognition technique based on the extraction and
matching of SIFT features related to independent face areas. Both a global and
local (as recognition from parts) matching strategy is proposed. The local
strategy is based on matching individual salient facial SIFT features as
connected to facial landmarks such as the eyes and the mouth. As for the global
matching strategy, all SIFT features are combined together to form a single
feature. In order to reduce the identification errors, the Dempster-Shafer
decision theory is applied to fuse the two matching techniques. The proposed
algorithms are evaluated with the ORL and the IITK face databases. The
experimental results demonstrate the effectiveness and potential of the
proposed face recognition techniques also in the case of partially occluded
faces or with missing information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0383</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0383</id><created>2010-02-01</created><authors><author><keyname>Mehrotra</keyname><forenames>Hunny</forenames></author><author><keyname>Kisku</keyname><forenames>Dakshina Ranjan</forenames></author><author><keyname>Radhika</keyname><forenames>V. Bhawani</forenames></author><author><keyname>Majhi</keyname><forenames>Banshidhar</forenames></author><author><keyname>Gupta</keyname><forenames>Phalguni</forenames></author></authors><title>Feature Level Clustering of Large Biometric Database</title><categories>cs.CV cs.DB cs.LG</categories><comments>4 pages, 2 figures, IAPR International Conference on Machine Vision
  Applications, 2009</comments><acm-class>D.2.2; I.2.10</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an efficient technique for partitioning large biometric
database during identification. In this technique feature vector which
comprises of global and local descriptors extracted from offline signature are
used by fuzzy clustering technique to partition the database. As biometric
features posses no natural order of sorting, thus it is difficult to index them
alphabetically or numerically. Hence, some supervised criteria is required to
partition the search space. At the time of identification the fuzziness
criterion is introduced to find the nearest clusters for declaring the identity
of query sample. The system is tested using bin-miss rate and performs better
in comparison to traditional k-means approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0406</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0406</id><created>2010-02-02</created><authors><author><keyname>Studer</keyname><forenames>Christoph</forenames></author><author><keyname>Wenk</keyname><forenames>Markus</forenames></author><author><keyname>Burg</keyname><forenames>Andreas</forenames></author></authors><title>MIMO Transmission with Residual Transmit-RF Impairments</title><categories>cs.IT math.IT</categories><comments>to be presented at the International ITG Workshop on Smart Antennas -
  WSA 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Physical transceiver implementations for multiple-input multiple-output
(MIMO) wireless communication systems suffer from transmit-RF (Tx-RF)
impairments. In this paper, we study the effect on channel capacity and
error-rate performance of residual Tx-RF impairments that defy proper
compensation. In particular, we demonstrate that such residual distortions
severely degrade the performance of (near-)optimum MIMO detection algorithms.
To mitigate this performance loss, we propose an efficient algorithm, which is
based on an i.i.d. Gaussian model for the distortion caused by these
impairments. In order to validate this model, we provide measurement results
based on a 4-stream Tx-RF chain implementation for MIMO orthogonal
frequency-division multiplexing (OFDM).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0411</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0411</id><created>2010-02-02</created><authors><author><keyname>Kisku</keyname><forenames>Dakshina Ranjan</forenames></author><author><keyname>Rattani</keyname><forenames>Ajita</forenames></author><author><keyname>Grosso</keyname><forenames>Enrico</forenames></author><author><keyname>Tistarelli</keyname><forenames>Massimo</forenames></author></authors><title>Face Identification by SIFT-based Complete Graph Topology</title><categories>cs.CV cs.AI</categories><comments>6 pages, 7 figures, AutoId 2007</comments><acm-class>D.2.2; I.2.10</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper presents a new face identification system based on Graph Matching
Technique on SIFT features extracted from face images. Although SIFT features
have been successfully used for general object detection and recognition, only
recently they were applied to face recognition. This paper further investigates
the performance of identification techniques based on Graph matching topology
drawn on SIFT features which are invariant to rotation, scaling and
translation. Face projections on images, represented by a graph, can be matched
onto new images by maximizing a similarity function taking into account spatial
distortions and the similarities of the local features. Two graph based
matching techniques have been investigated to deal with false pair assignment
and reducing the number of features to find the optimal feature set between
database and query face SIFT features. The experimental results, performed on
the BANCA database, demonstrate the effectiveness of the proposed system for
automatic face identification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0412</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0412</id><created>2010-02-02</created><authors><author><keyname>Kisku</keyname><forenames>Dakshina Ranjan</forenames></author><author><keyname>Mehrotra</keyname><forenames>Hunny</forenames></author><author><keyname>Gupta</keyname><forenames>Phalguni</forenames></author><author><keyname>Sing</keyname><forenames>Jamuna Kanta</forenames></author></authors><title>SIFT-based Ear Recognition by Fusion of Detected Keypoints from Color
  Similarity Slice Regions</title><categories>cs.CV cs.AI</categories><comments>6 pages, 4 figures, ACTEA 2009</comments><acm-class>D.2.2; I.2.10</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Ear biometric is considered as one of the most reliable and invariant
biometrics characteristics in line with iris and fingerprint characteristics.
In many cases, ear biometrics can be compared with face biometrics regarding
many physiological and texture characteristics. In this paper, a robust and
efficient ear recognition system is presented, which uses Scale Invariant
Feature Transform (SIFT) as feature descriptor for structural representation of
ear images. In order to make it more robust to user authentication, only the
regions having color probabilities in a certain ranges are considered for
invariant SIFT feature extraction, where the K-L divergence is used for keeping
color consistency. Ear skin color model is formed by Gaussian mixture model and
clustering the ear color pattern using vector quantization. Finally, K-L
divergence is applied to the GMM framework for recording the color similarity
in the specified ranges by comparing color similarity between a pair of
reference model and probe ear images. After segmentation of ear images in some
color slice regions, SIFT keypoints are extracted and an augmented vector of
extracted SIFT features are created for matching, which is accomplished between
a pair of reference model and probe ear images. The proposed technique has been
tested on the IITK Ear database and the experimental results show improvements
in recognition accuracy while invariant features are extracted from color slice
regions to maintain the robustness of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0414</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0414</id><created>2010-02-02</created><authors><author><keyname>Kisku</keyname><forenames>Dakshina Ranjan</forenames></author><author><keyname>Gupta</keyname><forenames>Phalguni</forenames></author><author><keyname>Sing</keyname><forenames>Jamuna Kanta</forenames></author></authors><title>Feature Level Fusion of Biometrics Cues: Human Identification with
  Doddingtons Caricature</title><categories>cs.CV cs.AI</categories><comments>8 pages, 3 figures</comments><acm-class>D.2.2; I.2.10</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper presents a multimodal biometric system of fingerprint and ear
biometrics. Scale Invariant Feature Transform (SIFT) descriptor based feature
sets extracted from fingerprint and ear are fused. The fused set is encoded by
K-medoids partitioning approach with less number of feature points in the set.
K-medoids partition the whole dataset into clusters to minimize the error
between data points belonging to the clusters and its center. Reduced feature
set is used to match between two biometric sets. Matching scores are generated
using wolf-lamb user-dependent feature weighting scheme introduced by
Doddington. The technique is tested to exhibit its robust performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0416</identifier>
 <datestamp>2010-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0416</id><created>2010-02-02</created><authors><author><keyname>Kisku</keyname><forenames>Dakshina Ranjan</forenames></author><author><keyname>Gupta</keyname><forenames>Phalguni</forenames></author><author><keyname>Sing</keyname><forenames>Jamuna Kanta</forenames></author></authors><title>Fusion of Multiple Matchers using SVM for Offline Signature
  Identification</title><categories>cs.CV cs.LG</categories><comments>8 pages, 2 figures</comments><acm-class>D.2.2; I.2.10</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper uses Support Vector Machines (SVM) to fuse multiple classifiers
for an offline signature system. From the signature images, global and local
features are extracted and the signatures are verified with the help of
Gaussian empirical rule, Euclidean and Mahalanobis distance based classifiers.
SVM is used to fuse matching scores of these matchers. Finally, recognition of
query signatures is done by comparing it with all signatures of the database.
The proposed system is tested on a signature database contains 5400 offline
signatures of 600 individuals and the results are found to be promising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0424</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0424</id><created>2010-02-02</created><updated>2010-10-03</updated><authors><author><keyname>Peters</keyname><forenames>Steven W.</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Cooperative Algorithms for MIMO Interference Channels</title><categories>cs.IT math.IT</categories><comments>13 pages, to appear in IEEE Transactions on Vehicular Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference alignment is a transmission technique for exploiting all
available degrees of freedom in the interference channel with an arbitrary
number of users. Most prior work on interference alignment, however, neglects
interference from other nodes in the network not participating in the alignment
operation. This paper proposes three generalizations of interference alignment
for the multiple-antenna interference channel with multiple users that account
for colored noise, which models uncoordinated interference. First, a minimum
interference-plus-noise leakage algorithm is presented, and shown to be
equivalent to previous subspace methods when noise is spatially white or
negligible. A joint minimum mean squared error design is then proposed that
jointly optimizes the transmit precoders and receive spatial filters, whereas
previous designs neglect the receive spatial filter. This algorithm is shown to
be a generalization of previous joint MMSE designs for other system
configurations such as the broadcast channel. Finally, a maximum
signal-to-interference-plus-noise ratio algorithm is developed that is proven
to converge, unlike previous maximum SINR algorithms. The latter two designs
are shown to have increased complexity due to non-orthogonal precoders, more
required iterations, or more channel state knowledge than the min INL or
subspace methods. The sum throughput performance of these algorithms is
simulated in the context of a network with uncoordinated co-channel interferers
not participating in the alignment protocol. It is found that a network with
cochannel interference can benefit from employing precoders designed to
consider that interference, but in some cases, ignoring the co-channel
interference is advantageous.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0432</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0432</id><created>2010-02-02</created><authors><author><keyname>Wilson</keyname><forenames>William O.</forenames></author><author><keyname>Feyereisl</keyname><forenames>Jan</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Detecting Motifs in System Call Sequences</title><categories>cs.AI cs.CR cs.NE</categories><comments>16 pages, 3 tables, 1 figure, 8th International Workshop on
  Information Security Applications (WISA2007), Lecture Notes in Computer
  Science, Jeju, Korea</comments><journal-ref>Proceedings of the 8th International Workshop on Information
  Security Applications (WISA2007), Lecture Notes in Computer Science, Jeju,
  Korea</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The search for patterns or motifs in data represents an area of key interest
to many researchers. In this paper we present the Motif Tracking Algorithm, a
novel immune inspired pattern identification tool that is able to identify
unknown motifs which repeat within time series data. The power of the algorithm
is derived from its use of a small number of parameters with minimal
assumptions. The algorithm searches from a completely neutral perspective that
is independent of the data being analysed, and the underlying motifs. In this
paper the motif tracking algorithm is applied to the search for patterns within
sequences of low level system calls between the Linux kernel and the operating
system's user space. The MTA is able to compress data found in large system
call data sets to a limited number of motifs which summarise that data. The
motifs provide a resource from which a profile of executed processes can be
built. The potential for these profiles and new implications for security
research are highlighted. A higher level call system language for measuring
similarity between patterns of such calls is also suggested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0449</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0449</id><created>2010-02-02</created><updated>2010-07-08</updated><authors><author><keyname>Zhu</keyname><forenames>Ping</forenames></author><author><keyname>Wen</keyname><forenames>Qiaoyan</forenames></author></authors><title>Some improved results on communication between information systems</title><categories>cs.AI</categories><comments>12 pages</comments><journal-ref>Information Sciences, 180(18): 3521-3531, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To study the communication between information systems, Wang et al. [C. Wang,
C. Wu, D. Chen, Q. Hu, and C. Wu, Communicating between information systems,
Information Sciences 178 (2008) 3228-3239] proposed two concepts of type-1 and
type-2 consistent functions. Some properties of such functions and induced
relation mappings have been investigated there. In this paper, we provide an
improvement of the aforementioned work by disclosing the symmetric relationship
between type-1 and type-2 consistent functions. We present more properties of
consistent functions and induced relation mappings and improve upon several
deficient assertions in the original work. In particular, we unify and extend
type-1 and type-2 consistent functions into the so-called
neighborhood-consistent functions. This provides a convenient means for
studying the communication between information systems based on various
neighborhoods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0478</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0478</id><created>2010-02-02</created><authors><author><keyname>Piton</keyname><forenames>Odile</forenames><affiliation>SAMM</affiliation></author><author><keyname>Pignot</keyname><forenames>H&#xe9;l&#xe8;ne</forenames></author></authors><title>\'Etude et traitement automatique de l'anglais du XVIIe si\`ecle :
  outils morphosyntaxiques et dictionnaires</title><categories>cs.CL</categories><proxy>ccsd hal-00452430</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we record the main linguistic differences or singularities
of 17th century English, analyse them morphologically and syntactically and
propose equivalent forms in contemporary English. We show how 17th century
texts may be transcribed into modern English, combining the use of electronic
dictionaries with rules of transcription implemented as transducers. Apr\`es
avoir expos\'e la constitution du corpus, nous recensons les principales
diff\'erences ou particularit\'es linguistiques de la langue anglaise du XVIIe
si\`ecle, les analysons du point de vue morphologique et syntaxique et
proposons des \'equivalents en anglais contemporain (AC). Nous montrons comment
nous pouvons effectuer une transcription automatique de textes anglais du XVIIe
si\`ecle en anglais moderne, en combinant l'utilisation de dictionnaires
\'electroniques avec des r\`egles de transcriptions impl\'ement\'ees sous forme
de transducteurs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0479</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0479</id><created>2010-02-02</created><authors><author><keyname>Piton</keyname><forenames>Odile</forenames><affiliation>SAMM</affiliation></author><author><keyname>Pignot</keyname><forenames>H&#xe9;l&#xe8;ne</forenames><affiliation>SAMM</affiliation></author></authors><title>&quot;Mind your p's and q's&quot;: or the peregrinations of an apostrophe in 17th
  Century English</title><categories>cs.CL</categories><proxy>ccsd hal-00452436</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  If the use of the apostrophe in contemporary English often marks the Saxon
genitive, it may also indicate the omission of one or more let-ters. Some
writers (wrongly?) use it to mark the plural in symbols or abbreviations,
visual-ised thanks to the isolation of the morpheme &quot;s&quot;. This punctuation mark
was imported from the Continent in the 16th century. During the 19th century
its use was standardised. However the rules of its usage still seem problematic
to many, including literate speakers of English. &quot;All too often, the apostrophe
is misplaced&quot;, or &quot;errant apostrophes are springing up every-where&quot; is a
complaint that Internet users fre-quently come across when visiting grammar
websites. Many of them detail its various uses and misuses, and attempt to
correct the most common mistakes about it, especially its mis-use in the
plural, called greengrocers' apostro-phes and humorously misspelled
&quot;greengro-cers apostrophe's&quot;. While studying English travel accounts published
in the seventeenth century, we noticed that the different uses of this symbol
may accompany various models of metaplasms. We were able to highlight the
linguistic variations of some lexemes, and trace the origin of modern grammar
rules gov-erning its usage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0481</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0481</id><created>2010-02-02</created><updated>2010-05-31</updated><authors><author><keyname>Hamadou</keyname><forenames>Abdelmajid Ben</forenames><affiliation>MIRACL</affiliation></author><author><keyname>Piton</keyname><forenames>Odile</forenames><affiliation>MIRACL</affiliation></author><author><keyname>Fehri</keyname><forenames>H&#xe9;la</forenames><affiliation>MIRACL</affiliation></author></authors><title>Recognition and translation Arabic-French of Named Entities: case of the
  Sport places</title><categories>cs.CL</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recognition of Arabic Named Entities (NE) is a problem in different
domains of Natural Language Processing (NLP) like automatic translation.
Indeed, NE translation allows the access to multilingual in-formation. This
translation doesn't always lead to expected result especially when NE contains
a person name. For this reason and in order to ameliorate translation, we can
transliterate some part of NE. In this context, we propose a method that
integrates translation and transliteration together. We used the linguis-tic
NooJ platform that is based on local grammars and transducers. In this paper,
we focus on sport domain. We will firstly suggest a refinement of the
typological model presented at the MUC Conferences we will describe the
integration of an Arabic transliteration module into translation system.
Finally, we will detail our method and give the results of the evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0484</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0484</id><created>2010-02-02</created><authors><author><keyname>Jarry</keyname><forenames>Aubin</forenames></author><author><keyname>Leone</keyname><forenames>Pierre</forenames></author><author><keyname>Rolim</keyname><forenames>Jose</forenames></author></authors><title>VRAC: Theory #1</title><categories>cs.NI cs.DC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to make full use of geographic routing techniques developed for
sensor networks, nodes must be localized. However, traditional localization and
virtual localization techniques are dependent either on expensive and sometimes
unavailable hardware (e.g. GPS) or on sophisticated localization calculus (e.g.
triangulation) which are both error-prone and with a costly overhead.
  Instead of actually localizing nodes in the physical two-dimensional
Euclidean space, we use directly the raw distance to a set of anchors to
produce multi-dimensional coordinates. We prove that the image of the physical
two-dimensional Euclidean space is a two-dimensional surface, and we show that
it is possible to adapt geographic routing strategies on this surface, simply,
efficiently and successfully.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0485</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0485</id><created>2010-02-02</created><authors><author><keyname>Piton</keyname><forenames>Odile</forenames></author><author><keyname>Lagji</keyname><forenames>Klara</forenames></author></authors><title>Morphological study of Albanian words, and processing with NooJ</title><categories>cs.CL</categories><proxy>ccsd hal-00452458</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are developing electronic dictionaries and transducers for the automatic
processing of the Albanian Language. We will analyze the words inside a linear
segment of text. We will also study the relationship between units of sense and
units of form. The composition of words takes different forms in Albanian. We
have found that morphemes are frequently concatenated or simply juxtaposed or
contracted. The inflected grammar of NooJ allows constructing the dictionaries
of flexed forms (declensions or conjugations). The diversity of word structures
requires tools to identify words created by simple concatenation, or to treat
contractions. The morphological tools of NooJ allow us to create grammatical
tools to represent and treat these phenomena. But certain problems exceed the
morphological analysis and must be represented by syntactical grammars.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0507</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0507</id><created>2010-02-02</created><authors><author><keyname>Lecointre</keyname><forenames>Aubin</forenames><affiliation>LAAS</affiliation></author><author><keyname>Dragomirescu</keyname><forenames>Daniela</forenames><affiliation>LAAS</affiliation></author><author><keyname>Dubuc</keyname><forenames>David</forenames><affiliation>LAAS</affiliation></author><author><keyname>Katia</keyname><forenames>Grenier</forenames><affiliation>LAAS</affiliation></author><author><keyname>Patrick</keyname><forenames>Pons</forenames><affiliation>LAAS</affiliation></author><author><keyname>Aubert</keyname><forenames>Herv&#xe9;</forenames><affiliation>LAAS</affiliation></author><author><keyname>Muller</keyname><forenames>A.</forenames><affiliation>LAAS</affiliation></author><author><keyname>Berthou</keyname><forenames>Pascal</forenames><affiliation>LAAS</affiliation></author><author><keyname>Gayraud</keyname><forenames>Thierry</forenames><affiliation>LAAS</affiliation></author><author><keyname>Plana</keyname><forenames>Robert</forenames><affiliation>LAAS</affiliation></author></authors><title>Miniaturized wireless sensor network</title><categories>cs.NI</categories><proxy>ccsd hal-00452543</proxy><journal-ref>IEEE International Conference of Semiconductors, CAS2006 Romania
  (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses an overview of the wireless sensor networks. It is shown
that MEMS/NEMS technologies and SIP concept are well suited for advanced
architectures. It is also shown analog architectures have to be compatible with
digital signal techniques to develop smart network of microsystem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0508</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0508</id><created>2010-02-02</created><authors><author><keyname>Lecointre</keyname><forenames>Aubin</forenames><affiliation>LAAS</affiliation></author><author><keyname>Dragomirescu</keyname><forenames>Daniela</forenames><affiliation>LAAS</affiliation></author><author><keyname>Plana</keyname><forenames>Robert</forenames><affiliation>LAAS</affiliation></author></authors><title>Software defined radio layer for IR-UWB systems in Wireless Sensor
  Network Context</title><categories>cs.NI</categories><proxy>ccsd hal-00452547</proxy><journal-ref>50th IEEE International Midwest Symposium on Circuits and Systems
  (MWSCAS 2007) Canada (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the radio interface problematic for MANET (Mobile Ad-hoc
NETwork) applications. Here we propose to study the radio reconfigurability in
order to provide a unique physical layer which is able to deal with all MANET
applications. For implementing this reconfigurable physical layer, we propose
to use Impulse Radio Ultra WideBand (IRUWB). This paper presents also our two
level design approach for obtaining our reconfigurable IR-UWB receiver on FPGA
(Field Programmable Gate Array).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0509</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0509</id><created>2010-02-02</created><authors><author><keyname>Lecointre</keyname><forenames>Aubin</forenames><affiliation>LAAS</affiliation></author><author><keyname>Dragomirescu</keyname><forenames>Daniela</forenames><affiliation>LAAS</affiliation></author><author><keyname>Plana</keyname><forenames>Robert</forenames><affiliation>LAAS</affiliation></author></authors><title>Study of Reconfigurable Mostly Digital Radio for Manet</title><categories>cs.NI</categories><proxy>ccsd hal-00452553</proxy><journal-ref>30th IEEE International Semiconductor Conference, IEEE CAS 2007
  Romania (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the radio reconfigurability thanks to IRUWB mostly digital
architecture for MANET context. This particular context implies some
constraints on the radio interface such as low cost, low power, small
dimensions and simplicity. Here, we propose an implementation of dynamic
reconfigurable receiver on ASIC, and FPGA, after having explained the
advantages of mostly digital radio for reconfigurability. In this paper, by
studying our prototypes, we could prove that reconfigurability is on the
contrary with MANET constraints needs. The proposed solution allows data rate,
radio range, energy and spectrum occupation reconfigurability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0511</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0511</id><created>2010-02-02</created><authors><author><keyname>Dragomirescu</keyname><forenames>Daniela</forenames><affiliation>LAAS</affiliation></author><author><keyname>Lecointre</keyname><forenames>Aubin</forenames><affiliation>LAAS</affiliation></author><author><keyname>Plana</keyname><forenames>Robert</forenames><affiliation>LAAS</affiliation></author></authors><title>SOPC Co-Design Platform for UWB Systems in Wireless Sensor Network
  Context</title><categories>cs.NI</categories><proxy>ccsd hal-00452568</proxy><journal-ref>Third International Conference on Systems ICONS Mexico (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents our approach of the radio interface problematic for
Wireless Sensor Network. We introduce the WSN context and constraints
associated. We propose an IR-UWB solution and illustrate why it could be a
viable solution for WSN. A high level modelling and simulation platform for
IR-UWB radio interface is proposed on Matlab. It allows us to determine
according to BER versus Eb/N0 criteria and the WSN constraints what kind of
design is more adequate. Moreover, a co-design co-simulation platform Matlab
VHDL is proposed here. Using this platform we designed IR-UWB transceiver
having reconfigurable capabilities, such as data rate reconfiguration, time
hopping code, spectrum occupation and radio range reconfiguration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0532</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0532</id><created>2010-02-02</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>What Can Heterogeneity Add to the Scientometric Map? Steps towards
  algorithmic historiography</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Actor Network represents heterogeneous entities as actants (Callon et
al., 1983; 1986). Although computer programs for the visualization of social
networks increasingly allow us to represent heterogeneity in a network using
different shapes and colors for the visualization, hitherto this possibility
has scarcely been exploited (Mogoutov et al., 2008). In this contribution to
the Festschrift, I study the question of what heterogeneity can add
specifically to the visualization of a network. How does an integrated network
improve on the one-dimensional ones (such as co-word and co-author maps)? The
oeuvre of Michel Callon is used as the case materials, that is, his 65 papers
which can be retrieved from the (Social) Science Citation Index since 1975.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0561</identifier>
 <datestamp>2010-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0561</id><created>2010-02-02</created><authors><author><keyname>Adamic</keyname><forenames>Lada A.</forenames></author><author><keyname>Wei</keyname><forenames>Xiao</forenames></author><author><keyname>Yang</keyname><forenames>Jiang</forenames></author><author><keyname>Gerrish</keyname><forenames>Sean</forenames></author><author><keyname>Nam</keyname><forenames>Kevin K.</forenames></author><author><keyname>Clarkson</keyname><forenames>Gavin S.</forenames></author></authors><title>Individual focus and knowledge contribution</title><categories>cs.CY</categories><comments>10 pages, 4 figures</comments><acm-class>H.2.8; H.3.5; K.4.3</acm-class><journal-ref>First Monday 15(3), 1 March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Before contributing new knowledge, individuals must attain requisite
background knowledge or skills through schooling, training, practice, and
experience. Given limited time, individuals often choose either to focus on few
areas, where they build deep expertise, or to delve less deeply and distribute
their attention and efforts across several areas. In this paper we measure the
relationship between the narrowness of focus and the quality of contribution
across a range of both traditional and recent knowledge sharing media,
including scholarly articles, patents, Wikipedia, and online question and
answer forums. Across all systems, we observe a small but significant positive
correlation between focus and quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0562</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0562</id><created>2010-02-02</created><authors><author><keyname>Hoffmann</keyname><forenames>Michael</forenames></author><author><keyname>Matou&#x161;ek</keyname><forenames>Ji&#x159;&#xed;</forenames></author><author><keyname>Okamoto</keyname><forenames>Yoshio</forenames></author><author><keyname>Zumstein</keyname><forenames>Philipp</forenames></author></authors><title>Minimum and maximum against k lies</title><categories>cs.DS cs.CC cs.GT</categories><comments>11 pages, 3 figures</comments><acm-class>F.2.2; F.1.2; G.2.1</acm-class><doi>10.1007/978-3-642-13731-0_14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A neat 1972 result of Pohl asserts that [3n/2]-2 comparisons are sufficient,
and also necessary in the worst case, for finding both the minimum and the
maximum of an n-element totally ordered set. The set is accessed via an oracle
for pairwise comparisons. More recently, the problem has been studied in the
context of the Renyi-Ulam liar games, where the oracle may give up to k false
answers. For large k, an upper bound due to Aigner shows that (k+O(\sqrt{k}))n
comparisons suffice. We improve on this by providing an algorithm with at most
(k+1+C)n+O(k^3) comparisons for some constant C. The known lower bounds are of
the form (k+1+c_k)n-D, for some constant D, where c_0=0.5, c_1=23/32=0.71875,
and c_k=\Omega(2^{-5k/4}) as k goes to infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0570</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0570</id><created>2010-02-02</created><authors><author><keyname>Berthe</keyname><forenames>Abdoulaye</forenames><affiliation>LAAS</affiliation></author><author><keyname>Lecointre</keyname><forenames>Aubin</forenames><affiliation>LAAS</affiliation></author><author><keyname>Dragomirescu</keyname><forenames>Daniela</forenames><affiliation>LAAS</affiliation></author><author><keyname>Plana</keyname><forenames>Robert</forenames><affiliation>LAAS</affiliation></author></authors><title>Simulation Platform for Wireless Sensor Networks Based on Impulse Radio
  Ultra Wide Band</title><categories>cs.NI</categories><proxy>ccsd hal-00452624</proxy><journal-ref>The Eighth International Conference on Networks, ICN Mexico (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Impulse Radio Ultra Wide Band (IR-UWB) is a promising technology to address
Wireless Sensor Network (WSN) constraints. However, existing network simulation
tools do not provide a complete WSN simulation architecture, with the IR-UWB
specificities at the PHYsical (PHY) and the Medium Access Control (MAC) layers.
In this paper, we propose a WSN simulation architecture based on the IR-UWB
technique. At the PHY layer, we take into account the pulse collision by
dealing with the pulse propagation delay. We also modelled MAC protocols
specific to IRUWB, for WSN applications. To completely fit the WSN simulation
requirements, we propose a generic and reusable sensor and sensing channel
model. Most of the WSN application performances can be evaluated thanks to the
proposed simulation architecture. The proposed models are implemented on a
scalable and well known network simulator: Global Mobile Information System
Simulator (GloMoSim). However, they can be reused for all other packet based
simulation platforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0573</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0573</id><created>2010-02-02</created><authors><author><keyname>Berthe</keyname><forenames>Abdoulaye</forenames><affiliation>LAAS</affiliation></author><author><keyname>Lecointre</keyname><forenames>Aubin</forenames><affiliation>LAAS</affiliation></author><author><keyname>Dragomirescu</keyname><forenames>Daniela</forenames><affiliation>LAAS</affiliation></author><author><keyname>Plana</keyname><forenames>Robert</forenames><affiliation>LAAS</affiliation></author></authors><title>Medium Access Control for Wireless Sensor Networks based on Impulse
  Radio Ultra Wideband</title><categories>cs.NI</categories><proxy>ccsd hal-00452626</proxy><journal-ref>International Conference on Electronics Computers and Artificial
  Intelligence, ECAI Romania (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a detailed performance evaluation of distributed Medium
Access Control (MAC) protocols for Wireless Sensor Networks based on Impulse
Radio Ultra Wideband (IR-UWB) Physical layer (PHY). Two main classes of Medium
Access Control protocol have been considered: Slotted and UnSlotted with
reliability. The reliability is based on Automatic Repeat ReQuest (ARQ). The
performance evaluation is performed using a complete Wireless Sensor Networks
(WSN) simulator built on the Global Mobile Information System Simulator
(GloMoSim). The optimal operating parameters are first discussed for IR-UWB in
terms of slot size, retransmission delay and the number of retransmission, then
a comparison between IR-UWB and other transmission techniques in terms of
reliability latency and power efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0574</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0574</id><created>2010-02-02</created><authors><author><keyname>Lecointre</keyname><forenames>Aubin</forenames><affiliation>LAAS</affiliation></author><author><keyname>Dragomirescu</keyname><forenames>Daniela</forenames><affiliation>LAAS</affiliation></author><author><keyname>Plana</keyname><forenames>Robert</forenames><affiliation>LAAS</affiliation></author></authors><title>Channel Capacity Limitations versus Hardware Implementation for UWB
  Impulse Radio Communications</title><categories>cs.NI</categories><proxy>ccsd hal-00452693</proxy><journal-ref>Romanian Journal of Information Science and Technology (2009)
  339-353</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Starting from the Shannon channel capacity, we propose an IR-UWB channel
capacity based on the delay spread for multipath time variant channels. This
IR-UWB channel capacity is obtained from the no ISI (Inter Symbol Interference)
assumption and for binary modulations. The impact of the kind of implementation
is considered on the IR-UWB channel capacity. This study is lead for mixed and
mostly digital implementation. The key parameters and theirs impacts on the
channel capacity are exposed in each case: the data converters for mostly
digital implementations and the pulse generator capabilities for mixed
implementations. Finally, these two implementations are compared from a data
rate point of view. Their behaviors regarding an increase of the operating
frequency are also studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0575</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0575</id><created>2010-02-02</created><authors><author><keyname>Lecointre</keyname><forenames>Aubin</forenames><affiliation>LAAS</affiliation></author><author><keyname>Berthe</keyname><forenames>Abdoulaye</forenames><affiliation>LAAS</affiliation></author><author><keyname>Dragomirescu</keyname><forenames>Daniela</forenames><affiliation>LAAS</affiliation></author><author><keyname>Plana</keyname><forenames>Robert</forenames><affiliation>LAAS</affiliation></author></authors><title>Performance Evaluation of Impluse Radio Ultra Wide Band Wireless Sensor
  Networks</title><categories>cs.NI</categories><proxy>ccsd hal-00452646</proxy><journal-ref>IEEE International Military Communications Conference, IEEE MILCOM
  United States (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a performance evaluation of Wireless Sensor Networks
(WSN) based on Impulse Radio Ultra Wideband (IR-UWB) over a new simulation
platform developed for this purpose. The simulation platform is built on an
existing network simulator: Global Mobile Information System Simulator
(GloMoSim). It mainly focuses on the accurately modeling of IR-UWB PHYsical
(PHY) and Medium Access Control (MAC) layer. Pulse collision is modeled
according to the used time hopping sequence (THS) and the pulse propagation
delay in order to increase the simulation fidelity. It also includes a
detection and identification application based on a new sensing channel and new
sensor device models. The proposed architecture is generic so it can be reused
for any simulation platform. The performance evaluation is based on one of the
typical WSN applications: local area protection, where sensor nodes are densely
scattered in an access regulated area in order to detect, identify and report
non authorized accesses to a base station for analysis. Two networks topologies
using different protocol stacks are investigated. Their performance evaluation
is presented in terms of reliability and latency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0576</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0576</id><created>2010-02-02</created><authors><author><keyname>Lecointre</keyname><forenames>Aubin</forenames><affiliation>LAAS</affiliation></author><author><keyname>Dragomirescu</keyname><forenames>Daniela</forenames><affiliation>LAAS</affiliation></author><author><keyname>Plana</keyname><forenames>Robert</forenames><affiliation>LAAS</affiliation></author></authors><title>New methodology to design advanced MR-IRUWB communication system</title><categories>cs.NI</categories><proxy>ccsd hal-00452691</proxy><journal-ref>Electronics Letters / IEE Electronics Letters (2008) 1412-1413</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new model is proposed giving the channel capability of a MB-IR-UWB system
versus the number of subband and the duty cycle. The architecture simulated
shows data rate ranging from 1.434 Gbits/s to 0.9 Gbits/s for 16 to 10 subbands
and duty cycle ranging from 20% to 12%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0577</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0577</id><created>2010-02-02</created><authors><author><keyname>Van</keyname><forenames>Tien Nguyen</forenames><affiliation>LIUPPA</affiliation></author><author><keyname>Gaio</keyname><forenames>Mauro</forenames><affiliation>LIUPPA</affiliation></author><author><keyname>Sallaberry</keyname><forenames>Christian</forenames><affiliation>LIUPPA</affiliation></author></authors><title>Recherche de relations spatio-temporelles : une m\'ethode bas\'ee sur
  l'analyse de corpus textuels</title><categories>cs.IR</categories><proxy>ccsd hal-00452005</proxy><journal-ref>TIA'09WS: Acquisition et mod\'elisation de relations
  s\'emantiques, Toulouse : France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a work package realized for the G\'eOnto project. A new
method is proposed for an enrichment of a first geographical ontology developed
beforehand. This method relies on text analysis by lexico-syntactic patterns.
  From the retrieve of n-ary relations the method automatically detect those
involved in a spatial and/or temporal relation in a context of a description of
journeys.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0580</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0580</id><created>2010-02-02</created><authors><author><keyname>Spoerhase</keyname><forenames>Joachim</forenames></author></authors><title>An Optimal Algorithm for the Indirect Covering Subtree Problem</title><categories>cs.DS cs.DM</categories><comments>10 pages, 1 figure</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the indirect covering subtree problem (Kim et al., 1996). The
input is an edge weighted tree graph along with customers located at the nodes.
Each customer is associated with a radius and a penalty. The goal is to locate
a tree-shaped facility such that the sum of setup and penalty cost is
minimized. The setup cost equals the sum of edge lengths taken by the facility
and the penalty cost is the sum of penalties of all customers whose distance to
the facility exceeds their radius. The indirect covering subtree problem
generalizes the single maximum coverage location problem on trees where the
facility is a node rather than a subtree. Indirect covering subtree can be
solved in $O(n\log^2 n)$ time (Kim et al., 1996). A slightly faster algorithm
for single maximum coverage location with a running time of
$O(n\log^2n/\log\log n)$ has been provided (Spoerhase and Wirth, 2009). We
achieve time $O(n\log n)$ for indirect covering subtree thereby providing the
fastest known algorithm for both problems. Our result implies also faster
algorithms for competitive location problems such as $(1,X)$-medianoid and
$(1,p)$-centroid on trees. We complement our result by a lower bound of
$\Omega(n\log n)$ for single maximum coverage location and $(1,X)$-medianoid on
a real-number RAM model showing that our algorithm is optimal in running time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0644</identifier>
 <datestamp>2010-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0644</id><created>2010-02-03</created><authors><author><keyname>Siddique</keyname><forenames>Atiur Rahman</forenames></author><author><keyname>Kamruzzaman</keyname><forenames>Joarder</forenames></author></authors><title>Performance Analysis of m-retry BEB based DCF under Unsaturated Traffic
  Condition</title><categories>cs.NI</categories><comments>Draft for IEEE WCNC 2010, 6 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The IEEE 802.11 standard offers a cheap and promising solution for small
scale wireless networks. Due to the self configuring nature, WLANs do not
require large scale infrastructure deployment, and are scalable and easily
maintainable which incited its popularity in both literature and industry. In
real environment, these networks operate mostly under unsaturated condition. We
investigate performance of such a network with m-retry limit BEB based DCF. We
consider imperfect channel with provision for power capture. Our method employs
a Markov model and represents the most common performance measures in terms of
network parameters making the model and mathematical analysis useful in network
design and planning. We also explore the effects of packet error, network size,
initial contention window, and retry limit on overall performance of WLANs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0672</identifier>
 <datestamp>2010-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0672</id><created>2010-02-03</created><updated>2010-12-16</updated><authors><author><keyname>Foucart</keyname><forenames>Simon</forenames></author><author><keyname>Pajor</keyname><forenames>Alain</forenames></author><author><keyname>Rauhut</keyname><forenames>Holger</forenames></author><author><keyname>Ullrich</keyname><forenames>Tino</forenames></author></authors><title>The Gelfand widths of $\ell_p$-balls for $0&lt;p\leq 1$</title><categories>math.FA cs.IT math.IT</categories><comments>15 pages</comments><msc-class>41A46, 46B09</msc-class><journal-ref>Journal of Complexity 26 (2010) 629-640</journal-ref><doi>10.1016/j.jco.2010.04.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide sharp lower and upper bounds for the Gelfand widths of
$\ell_p$-balls in the $N$-dimensional $\ell_q^N$-space for $0&lt;p\leq 1$ and $p&lt;q
\leq 2$. Such estimates are highly relevant to the novel theory of compressive
sensing, and our proofs rely on methods from this area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0678</identifier>
 <datestamp>2010-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0678</id><created>2010-02-03</created><authors><author><keyname>Faatz</keyname><forenames>Andreas</forenames></author><author><keyname>Zinnen</keyname><forenames>Andreas</forenames></author></authors><title>FORMT: Form-based Mutation Testing of Logical Specifications</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The draft paper defines a system, which is capable of maintaining bases of
test cases for logical specifications. The specifications, which are subject to
this system are transformed from their original shape in first-order logic to
form-based expressions as originally introduced in logics of George
Spencer-Brown. The innovation comes from the operations the system provides
when injecting faults - so-called mutations - to the specifications. The system
presented here applies to logical specifications from areas as different as
programming, ontologies or hardware specifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0680</identifier>
 <datestamp>2010-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0680</id><created>2010-02-03</created><authors><author><keyname>Binia</keyname><forenames>Jacob</forenames></author></authors><title>Some Relations between Divergence Derivatives and Estimation in Gaussian
  channels</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The minimum mean square error of the estimation of a non Gaussian signal
where observed from an additive white Gaussian noise channel's output, is
analyzed. First, a quite general time-continuous channel model is assumed for
which the behavior of the non-Gaussianess of the channel's output for small
signal to noise ratio q, is proved. Then, It is assumed that the channel
input's signal is composed of a (normalized) sum of N narrowband, mutually
independent waves. It is shown that if N goes to infinity, then for any fixed q
(no mater how big) both CMMSE and MMSE converge to the signal energy at a rate
which is proportional to the inverse of N. Finally, a known result for the MMSE
in the one-dimensional case, for small q, is used to show that all the first
four terms in the Taylor expansion of the non-Gaussianess of the channel's
output equal to zero.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0682</identifier>
 <datestamp>2010-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0682</id><created>2010-02-03</created><authors><author><keyname>Lecointre</keyname><forenames>Aubin</forenames><affiliation>LAAS</affiliation></author><author><keyname>Dragomirescu</keyname><forenames>Daniela</forenames><affiliation>LAAS</affiliation></author><author><keyname>Plana</keyname><forenames>Robert</forenames><affiliation>LAAS</affiliation></author></authors><title>IR-UWB Channel Capacity for Analog and Mostly Digital Implementation</title><categories>cs.NI</categories><proxy>ccsd hal-00452612</proxy><journal-ref>IEEE International Semiconductor Conference, IEEE CAS Romania
  (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The impact of the type of implementation is considered on the IR-UWB channel
capacity. This study is lead for analog and mostly digital implementation. Key
parameters and theirs impacts on the channel capacity are exposed in each case:
data converters for mostly digital implementations and pulse generators
capabilities for analog implementations. These two implementations are compared
from a data rate point of view. Their behaviors regarding an increase of the
operating frequency are also studied
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0696</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0696</id><created>2010-02-03</created><authors><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Twycross</keyname><forenames>Jamie</forenames></author></authors><title>Detecting Danger: Applying a Novel Immunological Concept to Intrusion
  Detection Systems</title><categories>cs.AI cs.CR cs.NE</categories><comments>3 pages, The 6th International Conference in Adaptive Computing in
  Design and Manufacture (ACDM2004), Bristol, UK</comments><journal-ref>Proceedings of The 6th International Conference in Adaptive
  Computing in Design and Manufacture (ACDM2004), Bristol, UK</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years computer systems have become increasingly complex and
consequently the challenge of protecting these systems has become increasingly
difficult. Various techniques have been implemented to counteract the misuse of
computer systems in the form of firewalls, anti-virus software and intrusion
detection systems. The complexity of networks and dynamic nature of computer
systems leaves current methods with significant room for improvement. Computer
scientists have recently drawn inspiration from mechanisms found in biological
systems and, in the context of computer security, have focused on the human
immune system (HIS). The human immune system provides a high level of
protection from constant attacks. By examining the precise mechanisms of the
human immune system, it is hoped the paradigm will improve the performance of
real intrusion detection systems. This paper presents an introduction to recent
developments in the field of immunology. It discusses the incorporation of a
novel immunological paradigm, Danger Theory, and how this concept is inspiring
artificial immune systems (AIS). Applications within the context of computer
security are outlined drawing direct reference to the underlying principles of
Danger Theory and finally, the current state of intrusion detection systems is
discussed and improvements suggested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0705</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0705</id><created>2010-02-03</created><authors><author><keyname>Nilsen</keyname><forenames>Jon K.</forenames></author><author><keyname>Cai</keyname><forenames>Xing</forenames></author><author><keyname>Hoyland</keyname><forenames>Bjorn</forenames></author><author><keyname>Langtangen</keyname><forenames>Hans Petter</forenames></author></authors><title>Simplifying Parallelization of Scientific Codes by a Function-Centric
  Approach in Python</title><categories>cs.DC cs.PL</categories><comments>29 pages, submitted to Computational Science and Discovery</comments><doi>10.1088/1749-4699/3/1/015003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this paper is to show how existing scientific software can be
parallelized using a separate thin layer of Python code where all parallel
communication is implemented. We provide specific examples on such layers of
code, and these examples may act as templates for parallelizing a wide set of
serial scientific codes. The use of Python for parallelization is motivated by
the fact that the language is well suited for reusing existing serial codes
programmed in other languages. The extreme flexibility of Python with regard to
handling functions makes it very easy to wrap up decomposed computational tasks
of a serial scientific application as Python functions. Many
parallelization-specific components can be implemented as generic Python
functions, which may take as input those functions that perform concrete
computational tasks. The overall programming effort needed by this
parallelization approach is rather limited, and the resulting parallel Python
scripts have a compact and clean structure. The usefulness of the
parallelization approach is exemplified by three different classes of
applications in natural and social sciences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0709</identifier>
 <datestamp>2010-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0709</id><created>2010-02-03</created><authors><author><keyname>Zhdanov</keyname><forenames>Fedor</forenames></author><author><keyname>Chernov</keyname><forenames>Alexey</forenames></author><author><keyname>Kalnishkan</keyname><forenames>Yuri</forenames></author></authors><title>Aggregating Algorithm competing with Banach lattices</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper deals with on-line regression settings with signals belonging to a
Banach lattice. Our algorithms work in a semi-online setting where all the
inputs are known in advance and outcomes are unknown and given step by step. We
apply the Aggregating Algorithm to construct a prediction method whose
cumulative loss over all the input vectors is comparable with the cumulative
loss of any linear functional on the Banach lattice. As a by-product we get an
algorithm that takes signals from an arbitrary domain. Its cumulative loss is
comparable with the cumulative loss of any predictor function from Besov and
Triebel-Lizorkin spaces. We describe several applications of our setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0712</identifier>
 <datestamp>2010-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0712</id><created>2010-02-03</created><authors><author><keyname>Nilsen</keyname><forenames>Jon K.</forenames></author><author><keyname>Toor</keyname><forenames>Salman</forenames></author><author><keyname>Nagy</keyname><forenames>Zsombor</forenames></author><author><keyname>Mohn</keyname><forenames>Bjarte</forenames></author><author><keyname>Read</keyname><forenames>Alex L.</forenames></author></authors><title>Performance and Stability of the Chelonia Storage Cloud</title><categories>cs.DC cs.SE</categories><comments>29 pages, 10 figures, submitted to Future Generation Computing
  Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present the Chelonia storage cloud middleware. It was
designed to fill the requirements gap between those of large, sophisticated
scientific collaborations which have adopted the grid paradigm for their
distributed storage needs, and of corporate business communities which are
gravitating towards the cloud paradigm. The similarities to and differences
between Chelonia and several well-known grid- and cloud-based storage solutions
are commented. The design of Chelonia has been chosen to optimize high
reliability and scalability of an integrated system of heterogeneous,
geographically dispersed storage sites and the ability to easily expand the
system dynamically. The architecture and implementation in term of web-services
running inside the Advanced Resource Connector Hosting Environment Dameon (ARC
HED) are described. We present results of tests in both local-area and
wide-area networks that demonstrate the fault-tolerance, stability and
scalability of Chelonia.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0722</identifier>
 <datestamp>2010-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0722</id><created>2010-02-03</created><updated>2010-03-15</updated><authors><author><keyname>Jafarizadeh</keyname><forenames>Saber</forenames></author></authors><title>Fastest Distributed Consensus on Path Network</title><categories>cs.IT cs.DC math.CO math.IT</categories><comments>4 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Providing an analytical solution for the problem of finding Fastest
Distributed Consensus (FDC) is one of the challenging problems in the field of
sensor networks. Most of the methods proposed so far deal with the FDC
averaging algorithm problem by numerical convex optimization methods and in
general no closed-form solution for finding FDC has been offered up to now
except in [3] where the conjectured answer for path has been proved. Here in
this work we present an analytical solution for the problem of Fastest
Distributed Consensus for the Path network using semidefinite programming
particularly solving the slackness conditions, where the optimal weights are
obtained by inductive comparing of the characteristic polynomials initiated by
slackness conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0739</identifier>
 <datestamp>2010-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0739</id><created>2010-02-03</created><authors><author><keyname>Van Hoeij</keyname><forenames>Mark</forenames><affiliation>FSU</affiliation></author><author><keyname>Novocin</keyname><forenames>Andrew</forenames><affiliation>LIP</affiliation></author></authors><title>Gradual sub-lattice reduction and a new complexity for factoring
  polynomials</title><categories>cs.SC cs.CC</categories><proxy>ccsd ensl-00452881</proxy><journal-ref>in Gradual sub-lattice reduction and a new complexity for
  factoring polynomials - LATIN 2010, Oaxaca : Mexico (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a lattice algorithm specifically designed for some classical
applications of lattice reduction. The applications are for lattice bases with
a generalized knapsack-type structure, where the target vectors are boundably
short. For such applications, the complexity of the algorithm improves
traditional lattice reduction by replacing some dependence on the bit-length of
the input vectors by some dependence on the bound for the output vectors. If
the bit-length of the target vectors is unrelated to the bit-length of the
input, then our algorithm is only linear in the bit-length of the input
entries, which is an improvement over the quadratic complexity floating-point
LLL algorithms. To illustrate the usefulness of this algorithm we show that a
direct application to factoring univariate polynomials over the integers leads
to the first complexity bound improvement since 1984. A second application is
algebraic number reconstruction, where a new complexity bound is obtained as
well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0745</identifier>
 <datestamp>2010-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0745</id><created>2010-02-03</created><authors><author><keyname>Omran</keyname><forenames>Mahamed G. H.</forenames></author><author><keyname>al-Adwani</keyname><forenames>Faisal</forenames></author></authors><title>Using CODEQ to Train Feed-forward Neural Networks</title><categories>cs.NE cs.AI</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  CODEQ is a new, population-based meta-heuristic algorithm that is a hybrid of
concepts from chaotic search, opposition-based learning, differential evolution
and quantum mechanics. CODEQ has successfully been used to solve different
types of problems (e.g. constrained, integer-programming, engineering) with
excellent results. In this paper, CODEQ is used to train feed-forward neural
networks. The proposed method is compared with particle swarm optimization and
differential evolution algorithms on three data sets with encouraging results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0747</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0747</id><created>2010-02-03</created><updated>2010-04-18</updated><authors><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author><author><keyname>Tamuz</keyname><forenames>Omer</forenames></author></authors><title>Efficient Bayesian Learning in Social Networks with Gaussian Estimators</title><categories>stat.AP cs.LG stat.ML</categories><comments>10 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a Bayesian model of iterative learning on social networks that is
computationally tractable; the agents of this model are fully rational, and
their calculations can be performed with modest computational resources for
large networks. Furthermore, learning is efficient, in the sense that the
process results in an information-theoretically optimal belief. This result
extends Condorcet's Jury Theorem to general social networks, preserving
rationality, computational feasibility and efficient learning. The model
consists of a group of agents who belong to a social network, so that a pair of
agents can observe each other's actions only if they are neighbors. We assume
that the network is connected and that the agents have full knowledge of the
structure of the network, so that they know the members of the network and
their social connections. The agents try to estimate some state of the world S
(say, the price of oil a year from today). Each agent has a private
measurement: an independently acquired piece of information regarding S. This
is modeled, for agent v, by a number S_v picked from a Gaussian distribution
with mean S and standard deviation one. Accordingly, agent v's prior belief
regarding S is a normal distribution with mean S_v and standard deviation one.
The agents start acting iteratively. At each iteration, each agent takes the
optimal action given its current belief. This action reveals its mean estimate
of S to its neighbors. Then, observing its neighbors' actions, each agent
updates its belief, using Bayes' Law. We show that this process is efficient:
all the agents converge to the belief that they would have, had they access to
all the private measurements. Additionally, and in contrast to other iterative
Bayesian models on networks, it is computationally efficient, so that each
agent's calculation can be easily carried out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0757</identifier>
 <datestamp>2010-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0757</id><created>2010-02-03</created><authors><author><keyname>Gr&#xfc;nwald</keyname><forenames>Peter</forenames></author><author><keyname>Kot&#x142;owski</keyname><forenames>Wojciech</forenames></author></authors><title>Prequential Plug-In Codes that Achieve Optimal Redundancy Rates even if
  the Model is Wrong</title><categories>cs.IT cs.LG math.IT math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyse the prequential plug-in codes relative to one-parameter
exponential families M. We show that if data are sampled i.i.d. from some
distribution outside M, then the redundancy of any plug-in prequential code
grows at rate larger than 1/2 ln(n) in the worst case. This means that plug-in
codes, such as the Rissanen-Dawid ML code, may behave inferior to other
important universal codes such as the 2-part MDL, Shtarkov and Bayes codes, for
which the redundancy is always 1/2 ln(n) + O(1). However, we also show that a
slight modification of the ML plug-in code, &quot;almost&quot; in the model, does achieve
the optimal redundancy even if the the true distribution is outside M.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0773</identifier>
 <datestamp>2010-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0773</id><created>2010-02-03</created><authors><author><keyname>Wegmann</keyname><forenames>Steven</forenames></author></authors><title>Approximations to the MMI criterion and their effect on lattice-based
  MMI</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximum mutual information (MMI) is a model selection criterion used for
hidden Markov model (HMM) parameter estimation that was developed more than
twenty years ago as a discriminative alternative to the maximum likelihood
criterion for HMM-based speech recognition. It has been shown in the speech
recognition literature that parameter estimation using the current MMI
paradigm, lattice-based MMI, consistently outperforms maximum likelihood
estimation, but this is at the expense of undesirable convergence properties.
In particular, recognition performance is sensitive to the number of times that
the iterative MMI estimation algorithm, extended Baum-Welch, is performed. In
fact, too many iterations of extended Baum-Welch will lead to degraded
performance, despite the fact that the MMI criterion improves at each
iteration. This phenomenon is at variance with the analogous behavior of
maximum likelihood estimation -- at least for the HMMs used in speech
recognition -- and it has previously been attributed to `over fitting'. In this
paper, we present an analysis of lattice-based MMI that demonstrates, first of
all, that the asymptotic behavior of lattice-based MMI is much worse than was
previously understood, i.e. it does not appear to converge at all, and, second
of all, that this is not due to `over fitting'. Instead, we demonstrate that
the `over fitting' phenomenon is the result of standard methodology that
exacerbates the poor behavior of two key approximations in the lattice-based
MMI machinery. We also demonstrate that if we modify the standard methodology
to improve the validity of these approximations, then the convergence
properties of lattice-based MMI become benign without sacrificing improvements
to recognition accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0777</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0777</id><created>2010-02-03</created><updated>2010-08-07</updated><authors><author><keyname>Abbe</keyname><forenames>Emmanuel</forenames></author><author><keyname>Telatar</keyname><forenames>Emre</forenames></author></authors><title>Polar Codes for the m-User MAC</title><categories>cs.IT cs.DM math.CO math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, polar codes for the $m$-user multiple access channel (MAC)
with binary inputs are constructed. It is shown that Ar{\i}kan's polarization
technique applied individually to each user transforms independent uses of a
$m$-user binary input MAC into successive uses of extremal MACs. This
transformation has a number of desirable properties: (i) the `uniform sum rate'
of the original MAC is preserved, (ii) the extremal MACs have uniform rate
regions that are not only polymatroids but matroids and thus (iii) their
uniform sum rate can be reached by each user transmitting either uncoded or
fixed bits; in this sense they are easy to communicate over. A polar code can
then be constructed with an encoding and decoding complexity of $O(n \log n)$
(where $n$ is the block length), a block error probability of $o(\exp(- n^{1/2
- \e}))$, and capable of achieving the uniform sum rate of any binary input MAC
with arbitrary many users. An application of this polar code construction to
communicating on the AWGN channel is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0783</identifier>
 <datestamp>2012-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0783</id><created>2010-02-03</created><updated>2011-03-03</updated><authors><author><keyname>Mkrtchyan</keyname><forenames>Vahan V.</forenames></author><author><keyname>Steffen</keyname><forenames>Eckhard</forenames></author></authors><title>Maximum $\Delta$-edge-colorable subgraphs of class II graphs</title><categories>cs.DM</categories><comments>13 pages, 2 figures, the proof of the Lemma 1 is corrected</comments><journal-ref>Journal of Graph Theory 70/4, 2012, pp. 473-482</journal-ref><doi>10.1002/jgt.20629</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph $G$ is class II, if its chromatic index is at least $\Delta+1$. Let
$H$ be a maximum $\Delta$-edge-colorable subgraph of $G$. The paper proves best
possible lower bounds for $\frac{|E(H)|}{|E(G)|}$, and structural properties of
maximum $\Delta$-edge-colorable subgraphs. It is shown that every set of
vertex-disjoint cycles of a class II graph with $\Delta\geq3$ can be extended
to a maximum $\Delta$-edge-colorable subgraph. Simple graphs have a maximum
$\Delta$-edge-colorable subgraph such that the complement is a matching.
Furthermore, a maximum $\Delta$-edge-colorable subgraph of a simple graph is
always class I.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0852</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0852</id><created>2010-02-03</created><updated>2011-01-21</updated><authors><author><keyname>Balzano</keyname><forenames>Laura</forenames></author><author><keyname>Recht</keyname><forenames>Bejamin</forenames></author><author><keyname>Nowak</keyname><forenames>Robert</forenames></author></authors><title>High-Dimensional Matched Subspace Detection When Data are Missing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of deciding whether a highly incomplete signal lies
within a given subspace. This problem, Matched Subspace Detection, is a
classical, well-studied problem when the signal is completely observed. High-
dimensional testing problems in which it may be prohibitive or impossible to
obtain a complete observation motivate this work. The signal is represented as
a vector in R^n, but we only observe m &lt;&lt; n of its elements. We show that
reliable detection is possible, under mild incoherence conditions, as long as m
is slightly greater than the dimension of the subspace in question.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0855</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0855</id><created>2010-02-03</created><authors><author><keyname>Baccelli</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Blaszczyszyn</keyname><forenames>Bartek</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>A New Phase Transition for Local Delays in MANETs</title><categories>cs.NI math.PR</categories><comments>accepted for IEEE Infocom 2010</comments><proxy>ccsd inria-00435237</proxy><doi>10.1109/INFCOM.2010.5462132</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider Mobile Ad-hoc Network (MANET) with transmitters located according
to a Poisson point in the Euclidean plane, slotted Aloha Medium Access (MAC)
protocol and the so-called outage scenario, where a successful transmission
requires a Signal-to-Interference-and-Noise (SINR) larger than some threshold.
We analyze the local delays in such a network, namely the number of times slots
required for nodes to transmit a packet to their prescribed next-hop receivers.
The analysis depends very much on the receiver scenario and on the variability
of the fading. In most cases, each node has finite-mean geometric random delay
and thus a positive next hop throughput. However, the spatial (or large
population) averaging of these individual finite mean-delays leads to infinite
values in several practical cases, including the Rayleigh fading and positive
thermal noise case. In some cases it exhibits an interesting phase transition
phenomenon where the spatial average is finite when certain model parameters
are below a threshold and infinite above. We call this phenomenon, contention
phase transition. We argue that the spatial average of the mean local delays is
infinite primarily because of the outage logic, where one transmits full
packets at time slots when the receiver is covered at the required SINR and
where one wastes all the other time slots. This results in the &quot;RESTART&quot;
mechanism, which in turn explains why we have infinite spatial average.
Adaptive coding offers a nice way of breaking the outage/RESTART logic. We show
examples where the average delays are finite in the adaptive coding case,
whereas they are infinite in the outage case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0865</identifier>
 <datestamp>2010-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0865</id><created>2010-02-03</created><authors><author><keyname>Wolinsky</keyname><forenames>David Isaac</forenames></author><author><keyname>Juste</keyname><forenames>Pierre St.</forenames></author><author><keyname>Boykin</keyname><forenames>P. Oscar</forenames></author><author><keyname>Figueiredo</keyname><forenames>Renato</forenames></author></authors><title>Towards Social Profile Based Overlays</title><categories>cs.DC cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online social networking has quickly become one of the most common activities
of Internet users. As social networks evolve, they encourage users to share
more information, requiring the users, in turn, to place more trust into social
networks. Peer-to-peer (P2P) overlays provide an environment that can return
ownership of information, trust, and control to the users, away from
centralized third-party social networks.
  In this paper, we present a novel concept, social profile overlays, which
enable users to share their profile only with trusted peers in a scalable,
reliable, and private manner. Each user's profile consists of a unique private,
secure overlay, where members of that overlay have a friendship with the
overlay owner. Profile data is made available without regard to the online
state of the profile owner through the use of the profile overlay's distributed
data store. Privacy and security are enforced through the use of a public key
infrastructure (PKI), where the role of certificate authority (CA) is handled
by the overlay owner and each member of the overlay has a CA-signed
certificate. All members of the social network join a common public or
directory overlay facilitating friend discovery and bootstrap connections into
profile overlays. We define interfaces and present tools that can be used to
implement this system, as well as explore some of the challenges related to it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0874</identifier>
 <datestamp>2010-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0874</id><created>2010-02-03</created><authors><author><keyname>Grossi</keyname><forenames>Roberto</forenames></author><author><keyname>Pietracaprina</keyname><forenames>Andrea</forenames></author><author><keyname>Pisanti</keyname><forenames>Nadia</forenames></author><author><keyname>Pucci</keyname><forenames>Geppino</forenames></author><author><keyname>Upfal</keyname><forenames>Eli</forenames></author><author><keyname>Vandin</keyname><forenames>Fabio</forenames></author></authors><title>MADMX: A Novel Strategy for Maximal Dense Motif Extraction</title><categories>cs.DS</categories><comments>A preliminary version of this work was presented in WABI 2009. 10
  pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop, analyze and experiment with a new tool, called MADMX, which
extracts frequent motifs, possibly including don't care characters, from
biological sequences. We introduce density, a simple and flexible measure for
bounding the number of don't cares in a motif, defined as the ratio of solid
(i.e., different from don't care) characters to the total length of the motif.
By extracting only maximal dense motifs, MADMX reduces the output size and
improves performance, while enhancing the quality of the discoveries. The
efficiency of our approach relies on a newly defined combining operation,
dubbed fusion, which allows for the construction of maximal dense motifs in a
bottom-up fashion, while avoiding the generation of nonmaximal ones. We provide
experimental evidence of the efficiency and the quality of the motifs returned
by MADMX
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0878</identifier>
 <datestamp>2010-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0878</id><created>2010-02-03</created><authors><author><keyname>Redner</keyname><forenames>S.</forenames></author></authors><title>On the meaning of the h-index</title><categories>physics.data-an cs.DL physics.soc-ph</categories><comments>3 pages, 2 figures, 2 tables, revtex4 format</comments><journal-ref>J. Stat. Mech. L03005 (2010)</journal-ref><doi>10.1088/1742-5468/2010/03/L03005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The h-index -- the value for which an individual has published at least h
papers with at least h citations -- has become a popular metric to assess the
citation impact of scientists. As already noted in the original work of Hirsch
and as evidenced from data of a representative sample of physicists, sqrt{c}
scales as h, where c is the total number citations to an individual. Thus
sqrt{c} appears to be equivalent to the h index. As a further check of this
equivalence, the distribution of the ratio s=sqrt{c}/2h for this sample is
sharply peaked about 1. The outliers in this distribution reveal fundamentally
different types of individual publication records.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0904</identifier>
 <datestamp>2010-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0904</id><created>2010-02-04</created><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author></authors><title>On Event Structure in the Torn Dress</title><categories>cs.CL</categories><comments>17 pages; a 2003 report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using Pustejovsky's &quot;The Syntax of Event Structure&quot; and Fong's &quot;On Mending a
Torn Dress&quot; we give a glimpse of a Pustejovsky-like analysis to some example
sentences in Fong. We attempt to give a framework for semantics to the noun
phrases and adverbs as appropriate as well as the lexical entries for all words
in the examples and critique both papers in light of our findings and
difficulties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0908</identifier>
 <datestamp>2011-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0908</id><created>2010-02-04</created><authors><author><keyname>Zhu</keyname><forenames>Ping</forenames></author><author><keyname>Wen</keyname><forenames>Qiaoyan</forenames></author></authors><title>Homomorphisms between fuzzy information systems revisited</title><categories>cs.AI</categories><comments>10 pages</comments><journal-ref>Applied Mathematics Letters, 24(9): 1548-1553, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Wang et al. discussed the properties of fuzzy information systems
under homomorphisms in the paper [C. Wang, D. Chen, L. Zhu, Homomorphisms
between fuzzy information systems, Applied Mathematics Letters 22 (2009)
1045-1050], where homomorphisms are based upon the concepts of consistent
functions and fuzzy relation mappings. In this paper, we classify consistent
functions as predecessor-consistent and successor-consistent, and then proceed
to present more properties of consistent functions. In addition, we improve
some characterizations of fuzzy relation mappings provided by Wang et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0930</identifier>
 <datestamp>2010-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0930</id><created>2010-02-04</created><authors><author><keyname>L&#xf3;pez</keyname><forenames>Hugo A.</forenames><affiliation>IT University of Copenhagen</affiliation></author><author><keyname>Olarte</keyname><forenames>Carlos</forenames><affiliation>&#xc9;cole Polytechnique - Universidad Javeriana Cali</affiliation></author><author><keyname>P&#xe9;rez</keyname><forenames>Jorge A.</forenames><affiliation>University of Bologna</affiliation></author></authors><title>Towards a Unified Framework for Declarative Structured Communications</title><categories>cs.PL cs.LO</categories><acm-class>F.3.1; F.3.2; C.2.4</acm-class><journal-ref>EPTCS 17, 2010, pp. 1-15</journal-ref><doi>10.4204/EPTCS.17.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a unified framework for the declarative analysis of structured
communications. By relying on a (timed) concurrent constraint programming
language, we show that in addition to the usual operational techniques from
process calculi, the analysis of structured communications can elegantly
exploit logic-based reasoning techniques. We introduce a declarative
interpretation of the language for structured communications proposed by Honda,
Vasconcelos, and Kubo. Distinguishing features of our approach are: the
possibility of including partial information (constraints) in the session
model; the use of explicit time for reasoning about session duration and
expiration; a tight correspondence with logic, which formally relates session
execution and linear-time temporal logic formulas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0933</identifier>
 <datestamp>2010-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0933</id><created>2010-02-04</created><authors><author><keyname>Bejleri</keyname><forenames>Andi</forenames><affiliation>Imperial College</affiliation></author><author><keyname>Hu</keyname><forenames>Raymond</forenames><affiliation>Imperial College</affiliation></author><author><keyname>Yoshida</keyname><forenames>Nobuko</forenames><affiliation>Imperial College</affiliation></author></authors><title>Session-Based Programming for Parallel Algorithms: Expressiveness and
  Performance</title><categories>cs.PL cs.DC</categories><journal-ref>EPTCS 17, 2010, pp. 17-29</journal-ref><doi>10.4204/EPTCS.17.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates session programming and typing of benchmark examples
to compare productivity, safety and performance with other communications
programming languages. Parallel algorithms are used to examine the above
aspects due to their extensive use of message passing for interaction, and
their increasing prominence in algorithmic research with the rising
availability of hardware resources such as multicore machines and clusters. We
contribute new benchmark results for SJ, an extension of Java for type-safe,
binary session programming, against MPJ Express, a Java messaging system based
on the MPI standard. In conclusion, we observe that (1) despite rich libraries
and functionality, MPI remains a low-level API, and can suffer from commonly
perceived disadvantages of explicit message passing such as deadlocks and
unexpected message types, and (2) the benefits of high-level session
abstraction, which has significant impact on program structure to improve
readability and reliability, and session type-safety can greatly facilitate the
task of communications programming whilst retaining competitive performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0935</identifier>
 <datestamp>2010-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0935</id><created>2010-02-04</created><authors><author><keyname>Carbone</keyname><forenames>Marco</forenames><affiliation>IT University of Copenhagen</affiliation></author><author><keyname>Guttman</keyname><forenames>Joshua</forenames><affiliation>Worcester Polytechnic Institute</affiliation></author></authors><title>Execution Models for Choreographies and Cryptoprotocols</title><categories>cs.LO cs.CR</categories><journal-ref>EPTCS 17, 2010, pp. 31-41</journal-ref><doi>10.4204/EPTCS.17.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A choreography describes a transaction in which several principals interact.
Since choreographies frequently describe business processes affecting
substantial assets, we need a security infrastructure in order to implement
them safely. As part of a line of work devoted to generating cryptoprotocols
from choreographies, we focus here on the execution models suited to the two
levels.
  We give a strand-style semantics for choreographies, and propose a special
execution model in which choreography-level messages are faithfully delivered
exactly once. We adapt this model to handle multiparty protocols in which some
participants may be compromised.
  At level of cryptoprotocols, we use the standard Dolev-Yao execution model,
with one alteration. Since many implementations use a &quot;nonce cache&quot; to discard
multiply delivered messages, we provide a semantics for at-most-once delivery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0936</identifier>
 <datestamp>2010-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0936</id><created>2010-02-04</created><authors><author><keyname>Kehrt</keyname><forenames>Matthew</forenames><affiliation>University of Washington</affiliation></author><author><keyname>Effinger-Dean</keyname><forenames>Laura</forenames><affiliation>University of Washington</affiliation></author><author><keyname>Schmitz</keyname><forenames>Michael</forenames><affiliation>University of Washington</affiliation></author><author><keyname>Grossman</keyname><forenames>Dan</forenames><affiliation>University of Washington</affiliation></author></authors><title>Programming Idioms for Transactional Events</title><categories>cs.PL cs.DC</categories><acm-class>D.3.3; D.1.3</acm-class><journal-ref>EPTCS 17, 2010, pp. 43-48</journal-ref><doi>10.4204/EPTCS.17.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transactional events (TE) are an extension of Concurrent ML (CML), a
programming model for synchronous message-passing. Prior work has focused on
TE's formal semantics and its implementation. This paper considers programming
idioms, particularly those that vary unexpectedly from the corresponding CML
idioms. First, we solve a subtle problem with client-server protocols in TE.
Second, we argue that CML's wrap and guard primitives do not translate well to
TE, and we suggest useful workarounds. Finally, we discuss how to rewrite CML
protocols that use abort actions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0937</identifier>
 <datestamp>2010-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0937</id><created>2010-02-04</created><authors><author><keyname>Martins</keyname><forenames>Francisco</forenames><affiliation>University of Lisbon</affiliation></author><author><keyname>Lopes</keyname><forenames>Lu&#xed;s</forenames><affiliation>University of Porto</affiliation></author><author><keyname>Barros</keyname><forenames>Jo&#xe3;o</forenames><affiliation>University of Porto</affiliation></author></authors><title>Towards the Safe Programming of Wireless Sensor Networks</title><categories>cs.PL cs.NI</categories><journal-ref>EPTCS 17, 2010, pp. 49-62</journal-ref><doi>10.4204/EPTCS.17.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensor networks are rather challenging to deploy, program, and debug. Current
programming languages for these platforms suffer from a significant semantic
gap between their specifications and underlying implementations. This fact
precludes the development of (type-)safe applications, which would potentially
simplify the task of programming and debugging deployed networks. In this paper
we define a core calculus for programming sensor networks and propose to use it
as an assembly language for developing type-safe, high-level programming
languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0939</identifier>
 <datestamp>2010-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0939</id><created>2010-02-04</created><authors><author><keyname>Marr</keyname><forenames>Stefan</forenames><affiliation>Vrije Universiteit Brussel</affiliation></author><author><keyname>Haupt</keyname><forenames>Michael</forenames><affiliation>Hasso Plattner Institute, University of Potsdam</affiliation></author><author><keyname>Timbermont</keyname><forenames>Stijn</forenames><affiliation>Vrije Universiteit Brussel</affiliation></author><author><keyname>Adams</keyname><forenames>Bram</forenames><affiliation>Queen's University</affiliation></author><author><keyname>D'Hondt</keyname><forenames>Theo</forenames><affiliation>Vrije Universiteit Brussel</affiliation></author><author><keyname>Costanza</keyname><forenames>Pascal</forenames><affiliation>Vrije Universiteit Brussel</affiliation></author><author><keyname>De Meuter</keyname><forenames>Wolfgang</forenames><affiliation>Vrije Universiteit Brussel</affiliation></author></authors><title>Virtual Machine Support for Many-Core Architectures: Decoupling Abstract
  from Concrete Concurrency Models</title><categories>cs.DC cs.AR cs.PL cs.SE</categories><acm-class>D.3.4; D.1.3</acm-class><journal-ref>EPTCS 17, 2010, pp. 63-77</journal-ref><doi>10.4204/EPTCS.17.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The upcoming many-core architectures require software developers to exploit
concurrency to utilize available computational power. Today's high-level
language virtual machines (VMs), which are a cornerstone of software
development, do not provide sufficient abstraction for concurrency concepts. We
analyze concrete and abstract concurrency models and identify the challenges
they impose for VMs. To provide sufficient concurrency support in VMs, we
propose to integrate concurrency operations into VM instruction sets.
  Since there will always be VMs optimized for special purposes, our goal is to
develop a methodology to design instruction sets with concurrency support.
Therefore, we also propose a list of trade-offs that have to be investigated to
advise the design of such instruction sets.
  As a first experiment, we implemented one instruction set extension for
shared memory and one for non-shared memory concurrency. From our experimental
results, we derived a list of requirements for a full-grown experimental
environment for further research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0940</identifier>
 <datestamp>2010-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0940</id><created>2010-02-04</created><authors><author><keyname>Gerakios</keyname><forenames>Prodromos</forenames><affiliation>National Technical University of Athens</affiliation></author><author><keyname>Papaspyrou</keyname><forenames>Nikolaos</forenames><affiliation>National Technical University of Athens</affiliation></author><author><keyname>Sagonas</keyname><forenames>Konstantinos</forenames><affiliation>National Technical University of Athens</affiliation></author></authors><title>A Concurrent Language with a Uniform Treatment of Regions and Locks</title><categories>cs.PL cs.DC</categories><journal-ref>EPTCS 17, 2010, pp. 79-93</journal-ref><doi>10.4204/EPTCS.17.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A challenge for programming language research is to design and implement
multi-threaded low-level languages providing static guarantees for memory
safety and freedom from data races. Towards this goal, we present a concurrent
language employing safe region-based memory management and hierarchical locking
of regions. Both regions and locks are treated uniformly, and the language
supports ownership transfer, early deallocation of regions and early release of
locks in a safe manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0942</identifier>
 <datestamp>2010-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0942</id><created>2010-02-04</created><updated>2010-02-05</updated><authors><author><keyname>Vasconcelos</keyname><forenames>Vasco T.</forenames><affiliation>University of Lisbon</affiliation></author><author><keyname>Martins</keyname><forenames>Francisco</forenames><affiliation>University of Lisbon</affiliation></author><author><keyname>Cogumbreiro</keyname><forenames>Tiago</forenames><affiliation>University of Lisbon</affiliation></author></authors><title>Type Inference for Deadlock Detection in a Multithreaded Polymorphic
  Typed Assembly Language</title><categories>cs.PL</categories><journal-ref>EPTCS 17, 2010, pp. 95-109</journal-ref><doi>10.4204/EPTCS.17.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We previously developed a polymorphic type system and a type checker for a
multithreaded lock-based polymorphic typed assembly language (MIL) that ensures
that well-typed programs do not encounter race conditions. This paper extends
such work by taking into consideration deadlocks. The extended type system
verifies that locks are acquired in the proper order. Towards this end we
require a language with annotations that specify the locking order. Rather than
asking the programmer (or the compiler's backend) to specifically annotate each
newly introduced lock, we present an algorithm to infer the annotations. The
result is a type checker whose input language is non-decorated as before, but
that further checks that programs are exempt from deadlocks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0963</identifier>
 <datestamp>2010-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0963</id><created>2010-02-04</created><authors><author><keyname>Jeung</keyname><forenames>Hoyoung</forenames></author><author><keyname>Yiu</keyname><forenames>Man Lung</forenames></author><author><keyname>Zhou</keyname><forenames>Xiaofang</forenames></author><author><keyname>Jensen</keyname><forenames>Christian S.</forenames></author><author><keyname>Shen</keyname><forenames>Heng Tao</forenames></author></authors><title>Discovery of Convoys in Trajectory Databases</title><categories>cs.DB cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As mobile devices with positioning capabilities continue to proliferate, data
management for so-called trajectory databases that capture the historical
movements of populations of moving objects becomes important. This paper
considers the querying of such databases for convoys, a convoy being a group of
objects that have traveled together for some time. More specifically, this
paper formalizes the concept of a convoy query using density-based notions, in
order to capture groups of arbitrary extents and shapes. Convoy discovery is
relevant for real-life applications in throughput planning of trucks and
carpooling of vehicles. Although there has been extensive research on
trajectories in the literature, none of this can be applied to retrieve
correctly exact convoy result sets. Motivated by this, we develop three
efficient algorithms for convoy discovery that adopt the well-known
filter-refinement framework. In the filter step, we apply line-simplification
techniques on the trajectories and establish distance bounds between the
simplified trajectories. This permits efficient convoy discovery over the
simplified trajectories without missing any actual convoys. In the refinement
step, the candidate convoys are further processed to obtain the actual convoys.
Our comprehensive empirical study offers insight into the properties of the
paper's proposals and demonstrates that the proposals are effective and
efficient on real-world trajectory data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0968</identifier>
 <datestamp>2015-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0968</id><created>2010-02-04</created><authors><author><keyname>Russo</keyname><forenames>Ciro</forenames></author></authors><title>Quantale Modules and their Operators, with Applications</title><categories>math.LO cs.IT math.IT</categories><msc-class>06F07</msc-class><journal-ref>J Logic Computation (2010), 20(4): 917-946</journal-ref><doi>10.1093/logcom/exn088</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The central topic of this work is the categories of modules over unital
quantales. The main categorical properties are established and a special class
of operators, called Q-module transforms, is defined. Such operators - that
turn out to be precisely the homomorphisms between free objects in those
categories - find concrete applications in two different branches of image
processing, namely fuzzy image compression and mathematical morphology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0971</identifier>
 <datestamp>2010-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0971</id><created>2010-02-04</created><authors><author><keyname>Nguyen</keyname><forenames>Benjamin</forenames><affiliation>PRISM</affiliation></author><author><keyname>Dudouet</keyname><forenames>Fran&#xe7;ois-Xavier</forenames><affiliation>LASP, IRISES</affiliation></author><author><keyname>Colazzo</keyname><forenames>Dario</forenames><affiliation>LRI</affiliation></author><author><keyname>Vion</keyname><forenames>Antoine</forenames><affiliation>LEST</affiliation></author><author><keyname>Manolescu</keyname><forenames>Ioana</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Senellart</keyname><forenames>Pierre</forenames></author></authors><title>The WebStand Project</title><categories>cs.DB</categories><proxy>ccsd hal-00453346</proxy><journal-ref>WebSci'09: Society On-Line Conference, Greece (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present the state of advancement of the French ANR WebStand
project. The objective of this project is to construct a customizable XML based
warehouse platform to acquire, transform, analyze, store, query and export data
from the web, in particular mailing lists, with the final intension of using
this data to perform sociological studies focused on social groups of World
Wide Web, with a specific emphasis on the temporal aspects of this data. We are
currently using this system to analyze the standardization process of the W3C,
through its social network of standard setters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0982</identifier>
 <datestamp>2010-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0982</id><created>2010-02-04</created><authors><author><keyname>Russo</keyname><forenames>Ciro</forenames></author></authors><title>A Unified Algebraic Framework for Fuzzy Image Compression and
  Mathematical Morphology</title><categories>cs.IT math.IT</categories><msc-class>68U10</msc-class><journal-ref>V. Di Gesu', S.K. Pal, and A. Petrosino Eds.: WILF 2009, LNAI
  5571, pp. 205-212, Springer-Verlag 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we show how certain techniques of image processing, having
different scopes, can be joined together under a common &quot;algebraic roof&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.0986</identifier>
 <datestamp>2012-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.0986</id><created>2010-02-04</created><updated>2012-06-30</updated><authors><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author><author><keyname>Jerrum</keyname><forenames>Mark</forenames></author></authors><title>Approximating the partition function of the ferromagnetic Potts model</title><categories>cs.CC math.CO</categories><comments>Minor corrections</comments><acm-class>F.2.2; F.1.3; G.2.2</acm-class><journal-ref>JACM 59(5) Article 25 October 2012</journal-ref><doi>10.1145/2371656.2371660</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide evidence that it is computationally difficult to approximate the
partition function of the ferromagnetic q-state Potts model when q&gt;2.
Specifically we show that the partition function is hard for the complexity
class #RHPi_1 under approximation-preserving reducibility. Thus, it is as hard
to approximate the partition function as it is to find approximate solutions to
a wide range of counting problems, including that of determining the number of
independent sets in a bipartite graph. Our proof exploits the first order phase
transition of the &quot;random cluster&quot; model, which is a probability distribution
on graphs that is closely related to the q-state Potts model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1005</identifier>
 <datestamp>2010-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1005</id><created>2010-02-04</created><authors><author><keyname>Waignier</keyname><forenames>Guillaume</forenames><affiliation>LIFL, INRIA Lille - Nord Europe</affiliation></author><author><keyname>Duguep&#xe9;roux</keyname><forenames>Est&#xe9;ban</forenames><affiliation>LIFL, INRIA Lille - Nord Europe</affiliation></author><author><keyname>Meur</keyname><forenames>Anne-Fran&#xe7;oise Le</forenames><affiliation>LIFL, INRIA Lille - Nord Europe</affiliation></author><author><keyname>Duchien</keyname><forenames>Laurence</forenames><affiliation>LIFL, INRIA Lille - Nord Europe</affiliation></author></authors><title>A Framework for Agile Development of Component-Based Applications</title><categories>cs.SE</categories><proxy>ccsd inria-00442154</proxy><journal-ref>The 8th BElgian-NEtherlands software eVOLution seminar (BENEVOL
  2009), Louvain-la-Neuve : Belgium (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Agile development processes and component-based software architectures are
two software engineering approaches that contribute to enable the rapid
building and evolution of applications. Nevertheless, few approaches have
proposed a framework to combine agile and component-based development, allowing
an application to be tested throughout the entire development cycle. To address
this problematic, we have built CALICO, a model-based framework that allows
applications to be safely developed in an iterative and incremental manner. The
CALICO approach relies on the synchronization of a model view, which specifies
the application properties, and a runtime view, which contains the application
in its execution context. Tests on the application specifications that require
values only known at runtime, are automatically integrated by CALICO into the
running application, and the captured needed values are reified at execution
time to resume the tests and inform the architect of potential problems. Any
modification at the model level that does not introduce new errors is
automatically propagated to the running system, allowing the safe evolution of
the application. In this paper, we illustrate the CALICO development process
with a concrete example and provide information on the current implementation
of our framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1016</identifier>
 <datestamp>2010-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1016</id><created>2010-02-04</created><authors><author><keyname>Clementi</keyname><forenames>Andrea</forenames></author><author><keyname>Monti</keyname><forenames>Angelo</forenames></author><author><keyname>Silvestri</keyname><forenames>Riccardo</forenames></author></authors><title>Modelling Mobility: A Discrete Revolution</title><categories>cs.DM</categories><comments>34 pages, 4 figures, submitted paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new approach to model and analyze \emph{Mobility}. It is fully
based on discrete mathematics and yields a class of mobility models, called the
\emph{Markov Trace} Model. This model can be seen as the discrete version of
the \emph{Random Trip} Model including all variants of the \emph{Random
Way-Point} Model \cite{L06}.
  We derive fundamental properties and \emph{explicit} analytical formulas for
the \emph{stationary distributions} yielded by the Markov Trace Model. Such
results can be exploited to compute formulas and properties for concrete cases
of the Markov Trace Model by just applying counting arguments.
  We apply the above general results to the discrete version of the
\emph{Manhattan Random Way-Point} over a square of bounded size.
  We get formulas for the total stationary distribution and for two important
\emph{conditional} ones: the agent spatial and destination distributions. Our
method makes the analysis of complex mobile systems a feasible task.
  As a further evidence of this important fact, we first model a complex
vehicular-mobile system over a set of crossing streets. Several concrete issues
are implemented such as parking zones, traffic lights, and variable vehicle
speeds. By using a \emph{modular} version of the Markov Trace Model, we get
explicit formulas for the stationary distributions yielded by this
vehicular-mobile model as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1021</identifier>
 <datestamp>2010-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1021</id><created>2010-02-04</created><authors><author><keyname>Geisberger</keyname><forenames>Robert</forenames></author></authors><title>Heuristic Contraction Hierarchies with Approximation Guarantee</title><categories>cs.DS</categories><comments>7 pages, technical report</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new heuristic point-to-point routing algorithm based on
contraction hierarchies (CH). Given an epsilon &gt;= 0, we can prove that the
length of the path computed by our algorithm is at most (1+epsilon) times the
length of the optimal (shortest) path. CH is based on node contraction:
removing nodes from a network and adding shortcut edges to preserve shortest
path distances. Our algorithm tries to avoid shortcuts even when a replacement
path is epsilon times longer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1060</identifier>
 <datestamp>2010-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1060</id><created>2010-02-04</created><authors><author><keyname>da Silva</keyname><forenames>Roberto</forenames></author><author><keyname>de Oliveira</keyname><forenames>Jose Palazzo</forenames></author><author><keyname>de Lima</keyname><forenames>Jose Valdeni</forenames></author><author><keyname>Moreira</keyname><forenames>Viviane</forenames></author></authors><title>Statistics for Ranking Program Committees and Editorial Boards</title><categories>cs.IT cs.IR math.IT physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ranking groups of researchers is important in several contexts and can serve
many purposes such as the fair distribution of grants based on the scientist's
publication output, concession of research projects, classification of journal
editorial boards and many other applications in a social context. In this
paper, we propose a method for measuring the performance of groups of
researchers. The proposed method is called alpha-index and it is based on two
parameters: (i) the homogeneity of the h-indexes of the researchers in the
group; and (ii) the h-group, which is an extension of the h-index for groups.
Our method integrates the concepts of homogeneity and absolute value of the
h-index into a single measure which is appropriate for the evaluation of
groups. We report on experiments that assess computer science conferences based
on the h-indexes of their program committee members. Our results are similar to
a manual classification scheme adopted by a research agency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1092</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1092</id><created>2010-02-04</created><authors><author><keyname>Bose</keyname><forenames>Prosenjit</forenames></author><author><keyname>Devroye</keyname><forenames>Luc</forenames></author><author><keyname>Douieb</keyname><forenames>Karim</forenames></author><author><keyname>Dujmovic</keyname><forenames>Vida</forenames></author><author><keyname>King</keyname><forenames>James</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author></authors><title>Odds-On Trees</title><categories>cs.CG cs.DS</categories><comments>19 pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let R^d -&gt; A be a query problem over R^d for which there exists a data
structure S that can compute P(q) in O(log n) time for any query point q in
R^d. Let D be a probability measure over R^d representing a distribution of
queries. We describe a data structure called the odds-on tree, of size
O(n^\epsilon) that can be used as a filter that quickly computes P(q) for some
query values q in R^d and relies on S for the remaining queries. With an
odds-on tree, the expected query time for a point drawn according to D is
O(H*+1), where H* is a lower-bound on the expected cost of any linear decision
tree that solves P.
  Odds-on trees have a number of applications, including distribution-sensitive
data structures for point location in 2-d, point-in-polytope testing in d
dimensions, ray shooting in simple polygons, ray shooting in polytopes,
nearest-neighbour queries in R^d, point-location in arrangements of hyperplanes
in R^d, and many other geometric searching problems that can be solved in the
linear-decision tree model. A standard lifting technique extends these results
to algebraic decision trees of constant degree. A slightly different version of
odds-on trees yields similar results for orthogonal searching problems that can
be solved in the comparison tree model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1095</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1095</id><created>2010-02-04</created><authors><author><keyname>Rudzicz</keyname><forenames>Frank</forenames></author><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author></authors><title>Towards a Heuristic Categorization of Prepositional Phrases in English
  with WordNet</title><categories>cs.CL</categories><comments>8 pages; 4 tables; 1 figure; a year 2003 report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document discusses an approach and its rudimentary realization towards
automatic classification of PPs; the topic, that has not received as much
attention in NLP as NPs and VPs. The approach is a rule-based heuristics
outlined in several levels of our research. There are 7 semantic categories of
PPs considered in this document that we are able to classify from an annotated
corpus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1099</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1099</id><created>2010-02-04</created><authors><author><keyname>Chatzigiannakis</keyname><forenames>Ioannis</forenames></author><author><keyname>Mylonas</keyname><forenames>Georgios</forenames></author><author><keyname>Akribopoulos</keyname><forenames>Orestis</forenames></author><author><keyname>Logaras</keyname><forenames>Marios</forenames></author><author><keyname>Kokkinos</keyname><forenames>Panagiotis</forenames></author><author><keyname>Spirakis</keyname><forenames>Paul</forenames></author></authors><title>The &quot;Hot Potato&quot; Case: Challenges in Multiplayer Pervasive Games Based
  on Ad hoc Mobile Sensor Networks and the Experimental Evaluation of a
  Prototype Game</title><categories>cs.HC cs.DC cs.MA cs.NI cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we discuss multiplayer pervasive games that rely on the use of
ad hoc mobile sensor networks. The unique feature in such games is that players
interact with each other and their surrounding environment by using movement
and presence as a means of performing game-related actions, utilizing sensor
devices. We discuss the fundamental issues and challenges related to these type
of games and the scenarios associated with them. We also present and evaluate
an example of such a game, called the &quot;Hot Potato&quot;, developed using the Sun
SPOT hardware platform. We provide a set of experimental results, so as to both
evaluate our implementation and also to identify issues that arise in pervasive
games which utilize sensor network nodes, which show that there is great
potential in this type of games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1104</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1104</id><created>2010-02-04</created><authors><author><keyname>Kirsch</keyname><forenames>Adam</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Pietracaprina</keyname><forenames>Andrea</forenames></author><author><keyname>Pucci</keyname><forenames>Geppino</forenames></author><author><keyname>Upfal</keyname><forenames>Eli</forenames></author><author><keyname>Vandin</keyname><forenames>Fabio</forenames></author></authors><title>An Efficient Rigorous Approach for Identifying Statistically Significant
  Frequent Itemsets</title><categories>cs.DB cs.DS</categories><comments>A preliminary version of this work was presented in ACM PODS 2009. 20
  pages, 0 figures</comments><acm-class>H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As advances in technology allow for the collection, storage, and analysis of
vast amounts of data, the task of screening and assessing the significance of
discovered patterns is becoming a major challenge in data mining applications.
In this work, we address significance in the context of frequent itemset
mining. Specifically, we develop a novel methodology to identify a meaningful
support threshold s* for a dataset, such that the number of itemsets with
support at least s* represents a substantial deviation from what would be
expected in a random dataset with the same number of transactions and the same
individual item frequencies. These itemsets can then be flagged as
statistically significant with a small false discovery rate. We present
extensive experimental results to substantiate the effectiveness of our
methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1143</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1143</id><created>2010-02-05</created><updated>2010-02-08</updated><authors><author><keyname>Mahmood</keyname><forenames>Nadeem</forenames></author><author><keyname>Burney</keyname><forenames>Aqil</forenames></author><author><keyname>Ahsan</keyname><forenames>Kamran</forenames></author></authors><title>A Logical Temporal Relational Data Model</title><categories>cs.DB</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/A-Logical-Temporal-Relational-Data-Model.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/A-Logical-Temporal-Relational-Data-Model.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time is one of the most difficult aspects to handle in real world
applications such as database systems. Relational database management systems
proposed by Codd offer very little built-in query language support for temporal
data management. The model itself incorporates neither the concept of time nor
any theory of temporal semantics. Many temporal extensions of the relational
model have been proposed and some of them are also implemented. This paper
offers a brief introduction to temporal database research. We propose a
conceptual model for handling time varying attributes in the relational
database model with minimal temporal attributes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1144</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1144</id><created>2010-02-05</created><authors><author><keyname>Ramaswami</keyname><forenames>M.</forenames></author><author><keyname>Bhaskaran</keyname><forenames>R.</forenames></author></authors><title>A CHAID Based Performance Prediction Model in Educational Data Mining</title><categories>cs.LG</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/A-CHAID-Based-Performance-Prediction-Model-in-Educational-Data-Mining.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/A-CHAID-Based-Performance-Prediction-Model-in-Educational-Data-Mining.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance in higher secondary school education in India is a turning
point in the academic lives of all students. As this academic performance is
influenced by many factors, it is essential to develop predictive data mining
model for students' performance so as to identify the slow learners and study
the influence of the dominant factors on their academic performance. In the
present investigation, a survey cum experimental methodology was adopted to
generate a database and it was constructed from a primary and a secondary
source. While the primary data was collected from the regular students, the
secondary data was gathered from the school and office of the Chief Educational
Officer (CEO). A total of 1000 datasets of the year 2006 from five different
schools in three different districts of Tamilnadu were collected. The raw data
was preprocessed in terms of filling up missing values, transforming values in
one form into another and relevant attribute/ variable selection. As a result,
we had 772 student records, which were used for CHAID prediction model
construction. A set of prediction rules were extracted from CHIAD prediction
model and the efficiency of the generated CHIAD prediction model was found. The
accuracy of the present model was compared with other model and it has been
found to be satisfactory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1146</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1146</id><created>2010-02-05</created><authors><author><keyname>Hossen</keyname><forenames>Md. Sakhawat</forenames></author><author><keyname>Kabir</keyname><forenames>A. F. M. Sultanul</forenames></author><author><keyname>Khan</keyname><forenames>Razib Hayat</forenames></author><author><keyname>Azfar</keyname><forenames>Abdullah</forenames></author></authors><title>Interconnection between 802.15.4 Devices and IPv6: Implications and
  Existing Approaches</title><categories>cs.NI</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/Interconnection-between-802.15.4-Devices-and-IPv6-Implications-and-Existing-Approaches.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/Interconnection-between-802.15.4-Devices-and-IPv6-Implications-and-Existing-Approaches.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing role of home automation in routine life and the rising demand
for sensor networks enhanced wireless personal area networks (WPANs)
development, pervasiveness of wireless &amp; wired network, and research. Soon
arose the need of implementing the Internet Protocol in these devices in order
to WPAN standards, raising the way for questions on how to provide seamless
communication between wired and wireless technologies. After a quick overview
of the Low-rate WPAN standard (IEEE 802.15.4) and the Zigbee stack, this paper
focuses on understanding the implications when interconnecting low powered IEEE
802.15.4 devices and a wired IPv6 domain. Subsequently the focus will be on
existing approaches to connect LoWPAN devices to the internet and on how these
approaches try to solve these challenges, concluding with a critical analysis
of interoperability problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1148</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1148</id><created>2010-02-05</created><authors><author><keyname>Al-amri</keyname><forenames>Salem Saleh</forenames></author><author><keyname>Kalyankar</keyname><forenames>N. V.</forenames></author><author><keyname>Khamitkar</keyname><forenames>S. D.</forenames></author></authors><title>A Comparative Study of Removal Noise from Remote Sensing Image</title><categories>cs.CV</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/A-Comparative-Study-of-Removal-Noise-from-Remote-Sensing-Image.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/A-Comparative-Study-of-Removal-Noise-from-Remote-Sensing-Image.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper attempts to undertake the study of three types of noise such as
Salt and Pepper (SPN), Random variation Impulse Noise (RVIN), Speckle (SPKN).
Different noise densities have been removed between 10% to 60% by using five
types of filters as Mean Filter (MF), Adaptive Wiener Filter (AWF), Gaussian
Filter (GF), Standard Median Filter (SMF) and Adaptive Median Filter (AMF). The
same is applied to the Saturn remote sensing image and they are compared with
one another. The comparative study is conducted with the help of Mean Square
Errors (MSE) and Peak-Signal to Noise Ratio (PSNR). So as to choose the base
method for removal of noise from remote sensing image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1149</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1149</id><created>2010-02-05</created><authors><author><keyname>Vijayalakshmi</keyname><forenames>S. R.</forenames></author><author><keyname>Padmavathi</keyname><forenames>G.</forenames></author></authors><title>A Performance Study of GA and LSH in Multiprocessor Job Scheduling</title><categories>cs.PF</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/A-Performance-Study-of-GA-and-LSH-in-Multiprocessor-Job-Scheduling.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/A-Performance-Study-of-GA-and-LSH-in-Multiprocessor-Job-Scheduling.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiprocessor task scheduling is an important and computationally difficult
problem. This paper proposes a comparison study of genetic algorithm and list
scheduling algorithm. Both algorithms are naturally parallelizable but have
heavy data dependencies. Based on experimental results, this paper presents a
detailed analysis of the scalability, advantages and disadvantages of each
algorithm. Multiprocessors have emerged as a powerful computing means for
running real-time applications, especially where a uni-processor system would
not be sufficient enough to execute all the tasks. The high performance and
reliability of multiprocessors have made them a powerful computing resource.
Such computing environment requires an efficient algorithm to determine when
and on which processor a given task should execute. In multiprocessor systems,
an efficient scheduling of a parallel program onto the processors that
minimizes the entire execution time is vital for achieving a high performance.
This scheduling problem is known to be NP- Hard. In multiprocessor scheduling
problem, a given program is to be scheduled in a given multiprocessor system
such that the program's execution time is minimized. The last job must be
completed as early as possible. Genetic algorithm (GA) is one of the widely
used techniques for constrained optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1150</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1150</id><created>2010-02-05</created><authors><author><keyname>Esmaeili</keyname><forenames>Mahdi</forenames></author><author><keyname>Gabor</keyname><forenames>Fazekas</forenames></author></authors><title>Finding Sequential Patterns from Large Sequence Data</title><categories>cs.DB</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/Finding-Sequential-Patterns-from-Large-Sequence-Data.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/Finding-Sequential-Patterns-from-Large-Sequence-Data.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data mining is the task of discovering interesting patterns from large
amounts of data. There are many data mining tasks, such as classification,
clustering, association rule mining, and sequential pattern mining. Sequential
pattern mining finds sets of data items that occur together frequently in some
sequences. Sequential pattern mining, which extracts frequent subsequences from
a sequence database, has attracted a great deal of interest during the recent
data mining research because it is the basis of many applications, such as: web
user analysis, stock trend prediction, DNA sequence analysis, finding language
or linguistic patterns from natural language texts, and using the history of
symptoms to predict certain kind of disease. The diversity of the applications
may not be possible to apply a single sequential pattern model to all these
problems. Each application may require a unique model and solution. A number of
research projects were established in recent years to develop meaningful
sequential pattern models and efficient algorithms for mining these patterns.
In this paper, we theoretically provided a brief overview three types of
sequential patterns model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1151</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1151</id><created>2010-02-05</created><authors><author><keyname>Sharma</keyname><forenames>Manju</forenames></author><author><keyname>Awasthi</keyname><forenames>Lalit</forenames></author></authors><title>Realistic Approach towards Quantitative Analysis and Simulation of
  EEHC-Based Routing for Wireless Sensor Networks</title><categories>cs.NI</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/Realistic-Approach-towards-Quantitative-Analysis-and-Simulation-of-EEHC-Based-Routing-for-Wireless-Sensor-Networks.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/Realistic-Approach-towards-Quantitative-Analysis-and-Simulation-of-EEHC-Based-Routing-for-Wireless-Sensor-Networks.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the realistic approach towards the quantitative analysis
and simulation of Energy Efficient Hierarchical Cluster (EEHC)-based routing
for wireless sensor networks. Here the efforts have been done to combine
analytical hardware model with the modified EEHC-based routing model. The
dependence of various performance metrics like: optimum number of clusters,
Energy Consumption, and Energy consumed per round etc. based on analytical
hardware sensor model and EEHC model has been presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1152</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1152</id><created>2010-02-05</created><authors><author><keyname>Natarajan</keyname><forenames>Mahalakshmi Chidambara</forenames></author><author><keyname>Muthiah</keyname><forenames>Ramaswamy</forenames></author><author><keyname>Nachiappan</keyname><forenames>Alamelu</forenames></author></authors><title>Performance Investigation of Virtual Private Networks with Different
  Bandwidth Allocations</title><categories>cs.NI</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/Performance-Investigation-of-Virtual-Private-Networks-with-Different-Bandwidth-Allocations.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/Performance-Investigation-of-Virtual-Private-Networks-with-Different-Bandwidth-Allocations.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Virtual Private Network (VPN) provides private network connections over a
publicly accessible shared network. The effective allocation of bandwidth for
VPNs assumes significance in the present scenario due to varied traffic. Each
VPN endpoint specifies bounds on the total amount of traffic that it is likely
to send or receive at any time. The network provider tailors the VPN so that
there is sufficient bandwidth for any traffic matrix that is consistent with
these bounds. The approach incorporates the use of Ad-hoc On demand Distance
Vector (AODV) protocol, with a view to accomplish an enhancement in the
performance of the mobile networks. The NS2 based simulation results are
evaluated in terms of its metrics for different bandwidth allocations, besides
analyzing its performance in the event of exigencies such as link failures. The
results highlight the suitability of the proposed strategy in the context of
real time applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1154</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1154</id><created>2010-02-05</created><authors><author><keyname>Sebai</keyname><forenames>Dorsaf</forenames></author><author><keyname>Jemai</keyname><forenames>Abderrazak</forenames></author><author><keyname>Bennour</keyname><forenames>Imed</forenames></author></authors><title>Performance Analysis of Software to Hardware Task Migration in Codesign</title><categories>cs.PF</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/Performance-Analysis-of-Software-to-Hardware-Task-Migration-in-Codesign.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/Performance-Analysis-of-Software-to-Hardware-Task-Migration-in-Codesign.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The complexity of multimedia applications in terms of intensity of
computation and heterogeneity of treated data led the designers to embark them
on multiprocessor systems on chip. The complexity of these systems on one hand
and the expectations of the consumers on the other hand complicate the
designers job to conceive and supply strong and successful systems in the
shortest deadlines. They have to explore the different solutions of the design
space and estimate their performances in order to deduce the solution that
respects their design constraints. In this context, we propose the modeling of
one of the design space possible solutions: the software to hardware task
migration. This modeling exploits the synchronous dataflow graphs to take into
account the different migration impacts and estimate their performances in
terms of throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1156</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1156</id><created>2010-02-05</created><authors><author><keyname>Reddy</keyname><forenames>M. Babu</forenames></author><author><keyname>Reddy</keyname><forenames>L. S. S.</forenames></author></authors><title>Dimensionality Reduction: An Empirical Study on the Usability of IFE-CF
  (Independent Feature Elimination- by C-Correlation and F-Correlation)
  Measures</title><categories>cs.LG</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010, http://ijcsi.org</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/Dimensionality-Reduction-An-Empirical-Study-on-the-Usability-of-IFE-CF-(Independent-Feature-Elimination-by-C-Correlation-and-F-Correlation)-Measures.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent increase in dimensionality of data has thrown a great challenge to
the existing dimensionality reduction methods in terms of their effectiveness.
Dimensionality reduction has emerged as one of the significant preprocessing
steps in machine learning applications and has been effective in removing
inappropriate data, increasing learning accuracy, and improving
comprehensibility. Feature redundancy exercises great influence on the
performance of classification process. Towards the better classification
performance, this paper addresses the usefulness of truncating the highly
correlated and redundant attributes. Here, an effort has been made to verify
the utility of dimensionality reduction by applying LVQ (Learning Vector
Quantization) method on two Benchmark datasets of 'Pima Indian Diabetic
patients' and 'Lung cancer patients'.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1157</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1157</id><created>2010-02-05</created><authors><author><keyname>Prakash</keyname><forenames>K. Soorya</forenames></author><author><keyname>Nazirudeen</keyname><forenames>S. S. Mohamed</forenames></author><author><keyname>Raj</keyname><forenames>M. Joseph Malvin</forenames></author></authors><title>Establishment of Relationships between Material Design and Product
  Design Domains by Hybrid FEM-ANN Technique</title><categories>cs.AI</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/Establishment-of-Relationships-between-Material-Design-and-Product-Design-Domains-by-Hybrid-FEM-ANN-Technique.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 1, January 2010,
  http://ijcsi.org/articles/Establishment-of-Relationships-between-Material-Design-and-Product-Design-Domains-by-Hybrid-FEM-ANN-Technique.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, research on AI based modeling technique to optimize
development of new alloys with necessitated improvements in properties and
chemical mixture over existing alloys as per functional requirements of product
is done. The current research work novels AI in lieu of predictions to
establish association between material and product customary. Advanced
computational simulation techniques like CFD, FEA interrogations are made
viable to authenticate product dynamics in context to experimental
investigations. Accordingly, the current research is focused towards binding
relationships between material design and product design domains. The input to
feed forward back propagation prediction network model constitutes of material
design features. Parameters relevant to product design strategies are furnished
as target outputs. The outcomes of ANN shows good sign of correlation between
material and product design domains. The study enriches a new path to
illustrate material factors at the time of new product development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1159</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1159</id><created>2010-02-05</created><authors><author><keyname>Cohen</keyname><forenames>Yuval</forenames></author></authors><title>Mining The Successful Binary Combinations: Methodology and A Simple Case
  Study</title><categories>cs.DB</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Mining-The-Successful-Binary-Combinations-Methodology-and-A-Simple-Case-Study.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Mining-The-Successful-Binary-Combinations-Methodology-and-A-Simple-Case-Study.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The importance of finding the characteristics leading to either a success or
a failure is one of the driving forces of data mining. The various application
areas of finding success/failure factors cover vast variety of areas such as
credit risk evaluation and granting loans, micro array analysis, health factors
and health risk factors, and parameter combination leading to a product
success. This paper presents a new approach for making inferences about
dichotomous data. The objective is to determine rules that lead to a certain
result. The method consists of four phases: in the first phase, the data is
processed into a binary format of a truth table, in the second phase; rules are
found by utilizing an algorithm that minimizes Boolean functions. In the third
phase the rules are checked and filtered. In the fourth phase, simple rules
that involve one to two features are revealed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1160</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1160</id><created>2010-02-05</created><authors><author><keyname>Hasib</keyname><forenames>Abdullah Al</forenames></author><author><keyname>Azfar</keyname><forenames>Abdullah</forenames></author><author><keyname>Morshed</keyname><forenames>Md. Sarwar</forenames></author></authors><title>Towards Public Key Infrastructure less authentication in Session
  Initiation Protocol</title><categories>cs.CR</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Towards-Public-Key-Infrastructure-less-authentication-in-Session-Initiation-Protocol.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Towards-Public-Key-Infrastructure-less-authentication-in-Session-Initiation-Protocol.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Session Initiation Protocol (SIP) has become the most predominant
protocol for Voice over Internet Protocol (VoIP) signaling. Security of SIP is
an important consideration for VoIP communication as the traffic is transmitted
over the insecure IP network. And the authentication process in SIP ranges from
pre-shared secret based solutions to Public Key Infrastructure (PKI) based
solution. However, due to the limitations in PKI based solutions, some PKI less
authentications mechanisms are proposed. This paper aims to present an overview
of different authentication methods used in or together with SIP. We start by
highlighting the security issues in SIP in the context of VoIP communication.
Then we illustrate the current activities regarding the SIP authentication
mechanisms including the recent developments in the research community and
standardization efforts within the Internet Engineering Task Force (IETF).
Finally we analyze the security aspects of these approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1162</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1162</id><created>2010-02-05</created><authors><author><keyname>Upadhayaya</keyname><forenames>Shuchita</forenames></author><author><keyname>Gandhi</keyname><forenames>Charu</forenames></author></authors><title>Node Disjoint Multipath Routing Considering Link and Node Stability
  protocol: A characteristic Evaluation</title><categories>cs.NI</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Node-Disjoint-Multipath-Routing-Considering-Link-and-Node-Stability-protocol-A-characteristic-Evaluation.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Node-Disjoint-Multipath-Routing-Considering-Link-and-Node-Stability-protocol-A-characteristic-Evaluation.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile Ad hoc Networks are highly dynamic networks. Quality of Service (QoS)
routing in such networks is usually limited by the network breakage due to
either node mobility or energy depletion of the mobile nodes. Also, to fulfill
certain quality parameters, presence of multiple node-disjoint paths becomes
essential. Such paths aid in the optimal traffic distribution and reliability
in case of path breakages. Thus, to cater various challenges in QoS routing in
Mobile Add hoc Networks, a Node Disjoint Multipath Routing Considering Link and
Node Stability (NDMLNR) protocol has been proposed by the authors. The metric
used to select the paths takes into account the stability of the nodes and the
corresponding links. This paper studies various challenges in the QoS routing
and presents the characteristic evaluation of NDMLNR w.r.t various existing
protocols in this area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1163</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1163</id><created>2010-02-05</created><authors><author><keyname>Aboud</keyname><forenames>Sattar J</forenames></author></authors><title>Efficient Password-Typed Key Agreement Scheme</title><categories>cs.CR</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Efficient-Password-Typed-Key-Agreement-Scheme.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Efficient-Password-Typed-Key-Agreement-Scheme.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we will study Lee, Kim and Yoo, a verifier password typed key
agreement scheme and demonstrate that the scheme is not secure. Then, the
authors will propose an enhanced verifier typed key agreement scheme relied on
Lee, Kim and Yoo scheme and demonstrate that the propose scheme resists against
password guessing attack and stolen verifier attack. The authors are claimed
that the proposed scheme is more secure and efficient compare with Lee, Kim and
Yoo.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1164</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1164</id><created>2010-02-05</created><authors><author><keyname>Ojha</keyname><forenames>A. K.</forenames></author><author><keyname>Mallick</keyname><forenames>Dushmanta</forenames></author><author><keyname>Mallick</keyname><forenames>C.</forenames></author></authors><title>Existence and Global Logarithmic Stability of Impulsive Neural Networks
  with Time Delay</title><categories>cs.NE</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Existence-and-Global-Logarithmic-Stability-of-Impulsive-Neural-Networks-with-Time-Delay.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Existence-and-Global-Logarithmic-Stability-of-Impulsive-Neural-Networks-with-Time-Delay.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stability and convergence of the neural networks are the fundamental
characteristics in the Hopfield type networks. Since time delay is ubiquitous
in most physical and biological systems, more attention is being made for the
delayed neural networks. The inclusion of time delay into a neural model is
natural due to the finite transmission time of the interactions. The stability
analysis of the neural networks depends on the Lyapunov function and hence it
must be constructed for the given system. In this paper we have made an attempt
to establish the logarithmic stability of the impulsive delayed neural networks
by constructing suitable Lyapunov function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1166</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1166</id><created>2010-02-05</created><authors><author><keyname>nair</keyname><forenames>T. R. GopalaKrishnan</forenames></author><author><keyname>Jayarekha</keyname><forenames>P.</forenames></author></authors><title>A Strategy to enable Prefix of Multicast VoD through dynamic buffer
  allocation</title><categories>cs.MM</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/A-Strategy-to-enable-Prefix-of-Multicast-VoD-through-dynamic-buffer-allocation.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/A-Strategy-to-enable-Prefix-of-Multicast-VoD-through-dynamic-buffer-allocation.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we have proposed a dynamic buffer allocation algorithm for the
prefix, based on the popularity of the videos. More cache blocks are allocated
for most popular videos and a few cache blocks are allocated for less popular
videos. Buffer utilization is also maximized irrespective of the load on the
Video-on-Demand system. Overload can lead the server getting slowed down. By
storing the first few seconds of popular video clips, a multimedia local server
can shield the users from the delay, throughput, and loss properties of the
path between the local server and the central server. The key idea of
controlled multicast is used to allow clients to share a segment of a video
stream even when the requests arrive at different times. This dynamic buffer
allocation algorithm is simulated and its performance is evaluated based on the
buffer utilization by multimedia servers and average buffer allocation for the
most popular videos. Our simulation results shows efficient utilization of
network bandwidth and reduced hard disk utilization hence resulting in increase
in the number of requests being served.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1167</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1167</id><created>2010-02-05</created><authors><author><keyname>Ojha</keyname><forenames>A. K.</forenames></author><author><keyname>Das</keyname><forenames>A. K.</forenames></author></authors><title>Geometric Programming Problem with Co-Efficients and Exponents
  Associated with Binary Numbers</title><categories>cs.NA</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Geometric-Programming-Problem-with-Co-Efficients-and-Exponents-Associated-with-Binary-Numbers.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Geometric-Programming-Problem-with-Co-Efficients-and-Exponents-Associated-with-Binary-Numbers.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Geometric programming (GP) provides a power tool for solving a variety of
optimization problems. In the real world, many applications of geometric
programming (GP) are engineering design problems in which some of the problem
parameters are estimating of actual values. This paper develops a solution
procedure to solve nonlinear programming problems using GP technique by
splitting the cost coefficients, constraint coefficients and exponents with the
help of binary numbers. The equivalent mathematical programming problems are
formulated to find their corresponding value of the objective function based on
the duality theorem. The ability of calculating the cost coefficients,
constraint coefficients and exponents developed in this paper might help lead
to more realistic modeling efforts in engineering design areas. Standard
nonlinear programming software has been used to solve the proposed optimization
problem. Two numerical examples are presented to illustrate the method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1168</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1168</id><created>2010-02-05</created><authors><author><keyname>Benboubker</keyname><forenames>F.</forenames></author><author><keyname>Abdi</keyname><forenames>F.</forenames></author><author><keyname>Ahaitouf</keyname><forenames>A.</forenames></author></authors><title>Shape-Adaptive Motion Estimation Algorithm for MPEG-4 Video Coding</title><categories>cs.MM</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Shape-Adaptive-Motion-Estimation-Algorithm-for-MPEG-4-Video-Coding.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Shape-Adaptive-Motion-Estimation-Algorithm-for-MPEG-4-Video-Coding.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a gradient based motion estimation algorithm based on
shape-motion prediction, which takes advantage of the correlation between
neighboring Binary Alpha Blocks (BABs), to match with the Mpeg-4 shape coding
case and speed up the estimation process. The PSNR and computation time
achieved by the proposed algorithm seem to be better than those obtained by
most popular motion estimation techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1169</identifier>
 <datestamp>2010-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1169</id><created>2010-02-05</created><updated>2010-03-16</updated><authors><author><keyname>Kamalesh</keyname><forenames>V. N</forenames></author><author><keyname>Srivatsa</keyname><forenames>S. K.</forenames></author></authors><title>Adjacency Matrix based method to compute the node connectivity of a
  Computer Communication Network</title><categories>cs.NI</categories><comments>Paper has been withdrawn due to non-compliance with IJCSI terms and
  conditions.</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Adjacency-Matrix-based-method-to-compute-the-node-connectivity-of-a-Computer-Communication-Network.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Paper has been withdrawn due to non-compliance with IJCSI terms and
conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1174</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1174</id><created>2010-02-05</created><authors><author><keyname>Navale</keyname><forenames>Geeta S.</forenames></author><author><keyname>Joshi</keyname><forenames>Swati S.</forenames></author><author><keyname>Deshmukh</keyname><forenames>Aaradhana A.</forenames></author></authors><title>M-Banking Security - a futuristic improved security approach</title><categories>cs.CR</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/M-Banking-Security-a-futuristic-improved-security-approach.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/M-Banking-Security-a-futuristic-improved-security-approach.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In last few decades large technology development raised various new needs.
Financial sector has also no exception. People are approaching all over the
world to fulfill there dreams. Any sector needs to understand changing need of
customer. In order to satisfy financial need for customer banks are taking help
of new technology such as internet. Only problem remain is of security. The aim
of this work is to provide a secure environment in terms of security for
transaction by various ways. In order to improve security we are making use of
&quot;Steganography&quot; technique in the way never used before. Task of enhancing
security include construction of formula for both data encryption and also for
hiding pattern. Server should not process any fake request hence concept of
custom &quot;Session id&quot; and &quot;Request id&quot; is introduced. Implementation of such a
security constraints in banking sector not only help to serve customer in
better way but also make customer confident and satisfy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1176</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1176</id><created>2010-02-05</created><authors><author><keyname>Kadri</keyname><forenames>Boufeldja</forenames></author><author><keyname>Boussahla</keyname><forenames>Miloud</forenames></author><author><keyname>Bendimerad</keyname><forenames>Fethi Tarik</forenames></author></authors><title>Phase-Only Planar Antenna Array Synthesis with Fuzzy Genetic Algorithms</title><categories>cs.NE</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Phase-Only-Planar-Antenna-Array-Synthesis-with-Fuzzy-Genetic-Algorithms.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Phase-Only-Planar-Antenna-Array-Synthesis-with-Fuzzy-Genetic-Algorithms.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a new method for the synthesis of planar antenna arrays
using fuzzy genetic algorithms (FGAs) by optimizing phase excitation
coefficients to best meet a desired radiation pattern. We present the
application of a rigorous optimization technique based on fuzzy genetic
algorithms (FGAs), the optimizing algorithm is obtained by adjusting control
parameters of a standard version of genetic algorithm (SGAs) using a fuzzy
controller (FLC) depending on the best individual fitness and the population
diversity measurements (PDM). The presented optimization algorithms were
previously checked on specific mathematical test function and show their
superior capabilities with respect to the standard version (SGAs). A planar
array with rectangular cells using a probe feed is considered. Included example
using FGA demonstrates the good agreement between the desired and calculated
radiation patterns than those obtained by a SGA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1178</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1178</id><created>2010-02-05</created><authors><author><keyname>Guezouri</keyname><forenames>Mustapha</forenames></author><author><keyname>Blaha</keyname><forenames>Ahmed</forenames></author><author><keyname>Keche</keyname><forenames>Mokhtar</forenames></author></authors><title>Adaptation of TURN protocol to SIP protocol</title><categories>cs.NI</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Adaptation-of-TURN-protocol-to-SIP-protocol.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Adaptation-of-TURN-protocol-to-SIP-protocol.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today, SIP is a protocol par Excellence in the field of communication over
Internet. But, the fact that it belongs to the application layer constitutes a
weakness vis-a-vis the NAT traversal. This weakness is due to the way in which
the server replies to the requests of clients on the one hand. On the other, it
is caused by the dynamic allocation of UDP ports for emission and reception of
packets RTP/RTCP. The TURN Protocol may face this weakness. However, its use
requires a certain number of exchanges between the clients and a TURN server
before establishing the multimedia sessions and this increase the latent time.
In this article, we propose to adapt TURN protocol for applications based on
SIP protocol such as telephony over Internet, conference video, etc. This
adaptation optimises the establishment of multimedia sessions by integrating a
manager of TCP connections and multimedia flow controller into SIP Proxy
server.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1179</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1179</id><created>2010-02-05</created><authors><author><keyname>Ahsan</keyname><forenames>Kamran</forenames></author><author><keyname>Shah</keyname><forenames>Hanifa</forenames></author><author><keyname>Kingston</keyname><forenames>Paul</forenames></author></authors><title>RFID Applications: An Introductory and Exploratory Study</title><categories>cs.NI</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010,
  http://ijcsi.org/articles/RFID-Applications-An-Introductory-and-Exploratory-Study.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010,
  http://ijcsi.org/articles/RFID-Applications-An-Introductory-and-Exploratory-Study.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  RFID is not a new technology and has passed through many decades of use in
military, airline, library, security, healthcare, sports, animal farms and
other areas. Industries use RFID for various applications such as
personal/vehicle access control, departmental store security, equipment
tracking, baggage, fast food establishments, logistics, etc. The enhancement in
RFID technology has brought advantages that are related to resource
optimization, increased efficiency within business processes, and enhanced
customer care, overall improvements in business operations and healthcare. Our
research is part of a big project; its aim is to produce a model for mobile
technology implementation of hospital patients' movement process. However, the
focus of this paper is to explore the main RFID components, i.e. the tag,
antenna and reader. The results of the investigations conducted on the three
RFID components will be used to develop our research model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1181</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1181</id><created>2010-02-05</created><authors><author><keyname>Kao</keyname><forenames>Fu-Chien</forenames></author><author><keyname>Wang</keyname><forenames>Siang-Ru</forenames></author><author><keyname>Huang</keyname><forenames>Ting-Hao</forenames></author></authors><title>The Design of Circuit-Measuring Collaborative Learning System with
  Embedded Broker</title><categories>cs.CY</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010,
  http://ijcsi.org/articles/The-Design-of-Circuit-Measuring-Collaborative-Learning-System-with-Embedded-Broker.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010,
  http://ijcsi.org/articles/The-Design-of-Circuit-Measuring-Collaborative-Learning-System-with-Embedded-Broker.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the academic community has been giving much attention to
Cooperative Learning System, a group learning method combined with pedagogy and
social psychology. It allows group members to gain knowledge through
collaborations and interactions. Nowadays, most Internet cooperative learning
systems are designed to provide students mainly with a convenient online
environment to study theoretical courses but rarely with an online environment
to operate practical instruments. Hence, this paper designed a 3D online
cooperative learning system for operating virtual instruments with
circuit-measuring function. By integrating with Virtual Reality, Remote Control
Parameter Transmission and embedded system techniques, this system gives
learners not only a cooperative learning environment via networking to jointly
operate the 3D virtual instruments (for example, multi-meters, power supplies
and oscilloscopes) but also the functions of instant messages and 3D puzzles to
interact with one another. Therefore, learners can effectively improve learning
interests and results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1183</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1183</id><created>2010-02-05</created><updated>2010-06-08</updated><authors><author><keyname>Gerin</keyname><forenames>Lucas</forenames><affiliation>MODAL'X</affiliation></author></authors><title>Random sampling of lattice paths with constraints, via transportation</title><categories>math.PR cs.DS</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss a Monte Carlo Markov Chain (MCMC) procedure for the random
sampling of some one-dimensional lattice paths with constraints, for various
constraints. We show that an approach inspired by optimal transport allows us
to bound efficiently the mixing time of the associated Markov chain. The
algorithm is robust and easy to implement, and samples an &quot;almost&quot; uniform path
of length $n$ in $n^{3+\eps}$ steps. This bound makes use of a certain
contraction property of the Markov chain, and is also used to derive a bound
for the running time of Propp-Wilson's CFTP algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1184</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1184</id><created>2010-02-05</created><authors><author><keyname>Shivakumar</keyname><forenames>R.</forenames></author><author><keyname>Lakshmipathi</keyname><forenames>R.</forenames></author></authors><title>Implementation of an Innovative Bio Inspired GA and PSO Algorithm for
  Controller design considering Steam GT Dynamics</title><categories>cs.NE</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010,
  http://ijcsi.org/articles/Implementation-of-an-Innovative-Bio-Inspired-GA-and-PSO-Algorithm-for-Controller-design-considering-Steam-GT-Dynamics.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010,
  http://ijcsi.org/articles/Implementation-of-an-Innovative-Bio-Inspired-GA-and-PSO-Algorithm-for-Controller-design-considering-Steam-GT-Dynamics.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Application of Bio Inspired Algorithms to complicated Power System
Stability Problems has recently attracted the researchers in the field of
Artificial Intelligence. Low frequency oscillations after a disturbance in a
Power system, if not sufficiently damped, can drive the system unstable. This
paper provides a systematic procedure to damp the low frequency oscillations
based on Bio Inspired Genetic (GA) and Particle Swarm Optimization (PSO)
algorithms. The proposed controller design is based on formulating a System
Damping ratio enhancement based Optimization criterion to compute the optimal
controller parameters for better stability. The Novel and contrasting feature
of this work is the mathematical modeling and simulation of the Synchronous
generator model including the Steam Governor Turbine (GT) dynamics. To show the
robustness of the proposed controller, Non linear Time domain simulations have
been carried out under various system operating conditions. Also, a detailed
Comparative study has been done to show the superiority of the Bio inspired
algorithm based controllers over the Conventional Lead lag controller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1185</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1185</id><created>2010-02-05</created><authors><author><keyname>Saxena</keyname><forenames>Kanak</forenames></author><author><keyname>Shukla</keyname><forenames>Rahul</forenames></author></authors><title>Significant Interval and Frequent Pattern Discovery in Web Log Data</title><categories>cs.DB</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010,
  http://ijcsi.org/articles/Significant-Interval-and-Frequent-Pattern-Discovery-in-Web-Log-Data.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010,
  http://ijcsi.org/articles/Significant-Interval-and-Frequent-Pattern-Discovery-in-Web-Log-Data.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a considerable body of work on sequence mining of Web Log Data. We
are using One Pass frequent Episode discovery (or FED) algorithm, takes a
different approach than the traditional apriori class of pattern detection
algorithms. In this approach significant intervals for each Website are
computed first (independently) and these interval used for detecting frequent
patterns/Episode and then the Analysis is performed on Significant Intervals
and frequent patterns That can be used to forecast the user's behavior using
previous trends and this can be also used for advertising purpose. This type of
applications predicts the Website interest. In this approach, time-series data
are folded over a periodicity (day, week, etc.) Which are used to form the
Interval? Significant intervals are discovered from these time points that
satisfy the criteria of minimum confidence and maximum interval length
specified by the user.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1186</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1186</id><created>2010-02-05</created><authors><author><keyname>Prasanth</keyname><forenames>K.</forenames></author><author><keyname>Duraiswamy</keyname><forenames>K.</forenames></author><author><keyname>Jayasudha</keyname><forenames>K.</forenames></author><author><keyname>Chandrasekar</keyname><forenames>C.</forenames></author></authors><title>Efficient Packet Forwarding Approach in Vehicular Ad Hoc Networks Using
  EBGR Algorithm</title><categories>cs.NI</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010,
  http://ijcsi.org/articles/Efficient-Packet-Forwarding-Approach-in-Vehicular-Ad-Hoc-Networks-Using-EBGR-Algorithm.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010,
  http://ijcsi.org/articles/Efficient-Packet-Forwarding-Approach-in-Vehicular-Ad-Hoc-Networks-Using-EBGR-Algorithm.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  VANETs (Vehicular Ad hoc Networks) are highly mobile wireless ad hoc networks
and will play an important role in public safety communications and commercial
applications. Routing of data in VANETs is a challenging task due to rapidly
changing topology and high speed mobility of vehicles. Conventional routing
protocols in MANETs (Mobile Ad hoc Networks) are unable to fully address the
unique characteristics in vehicular networks. In this paper, we propose EBGR
(Edge Node Based Greedy Routing), a reliable greedy position based routing
approach to forward packets to the node present in the edge of the transmission
range of source/forwarding node as most suitable next hop, with consideration
of nodes moving in the direction of the destination. We propose Revival
Mobility model (RMM) to evaluate the performance of our routing technique. This
paper presents a detailed description of our approach and simulation results
show that packet delivery ratio is improved considerably compared to other
routing techniques of VANET.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1188</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1188</id><created>2010-02-05</created><authors><author><keyname>Rao</keyname><forenames>Akepogu Anand</forenames></author><author><keyname>Madhavi</keyname><forenames>Karanam</forenames></author></authors><title>Framework for Visualizing Model-Driven Software Evolution and its
  Application</title><categories>cs.SE</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010,
  http://ijcsi.org/articles/Framework-for-Visualizing-Model-Driven-Software-Evolution-and-its-Application.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010,
  http://ijcsi.org/articles/Framework-for-Visualizing-Model-Driven-Software-Evolution-and-its-Application.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software Visualization encompasses the development and evaluation of methods
for graphically representing different aspects of methods of software,
including its structure, execution and evolution. Creating visualizations helps
the user to better understand complex phenomena. It is also found by the
software engineering community that visualization is essential and important.
In order to visualize the evolution of the models in Model-Driven Software
Evolution, authors have proposed a framework which consists of 7 key areas
(views) and 22 key features for the assessment of Model Driven Software
Evolution process and addresses a number of stakeholder concerns. The framework
is derived by the application of the Goal Question Metric Paradigm. This paper
aims to describe an application of the framework by considering different
visualization tools/CASE tools which are used to visualize the models in
different views and to capture the information of models during their
evolution. Comparison of such tools is also possible by using the framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1191</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1191</id><created>2010-02-05</created><authors><author><keyname>Al-Ani</keyname><forenames>Muzhir</forenames></author><author><keyname>Al-Shayea</keyname><forenames>Qeethara</forenames></author></authors><title>Unidirectional Error Correcting Codes for Memory Systems: A Comparative
  Study</title><categories>cs.IT math.IT</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010,
  http://ijcsi.org/articles/Unidirectional-Error-Correcting-Codes-for-Memory-Systems-A-Comparative-Study.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010,
  http://ijcsi.org/articles/Unidirectional-Error-Correcting-Codes-for-Memory-Systems-A-Comparative-Study.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to achieve fault tolerance, highly reliable system often require the
ability to detect errors as soon as they occur and prevent the speared of
erroneous information throughout the system. Thus, the need for codes capable
of detecting and correcting byte errors are extremely important since many
memory systems use b-bit-per-chip organization. Redundancy on the chip must be
put to make fault-tolerant design available. This paper examined several
methods of computer memory systems, and then a proposed technique is designed
to choose a suitable method depending on the organization of memory systems.
The constructed codes require a minimum number of check bits with respect to
codes used previously, then it is optimized to fit the organization of memory
systems according to the requirements for data and byte lengths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1193</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1193</id><created>2010-02-05</created><authors><author><keyname>Sharma</keyname><forenames>Dhirendra</forenames></author><author><keyname>Singh</keyname><forenames>Vikram</forenames></author></authors><title>ICT in Universities of the Western Himalayan Region of India II: A
  Comparative SWOT Analysis</title><categories>cs.OH</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010,
  http://ijcsi.org/articles/ICT-in-Universities-of-the-Western-Himalayan-Region-of-India-II-A-Comparative-SWOT-Analysis.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010,
  http://ijcsi.org/articles/ICT-in-Universities-of-the-Western-Himalayan-Region-of-India-II-A-Comparative-SWOT-Analysis.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study presents a comparative SWOT analysis to comprehend the pattern of
development of ICT within six universities of western Himalayan region of
India. With the objective of achieving quality and excellence in higher
education system in the region, this study provides a basis to decision makers
to exploit opportunities and minimize the external threats. The SWOT analysis
of different universities, placed under three categories, has been undertaken
within the four-tier framework used earlier by the authors. Guided by the
initiatives of National Mission on Education through ICT (NMEICT) for SWOT
analysis, findings of this paper reveal, relative consistency of these three
categories of universities, with the earlier study. A few suggestions, as
opportunities, with an emphasis on problem solving orientation in higher
education, have been made to strengthen the leadership of universities in the
field of ICT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1195</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1195</id><created>2010-02-05</created><authors><author><keyname>Nair</keyname><forenames>T. R. GopalaKrishnan</forenames></author><author><keyname>Dakshayini</keyname><forenames>M.</forenames></author></authors><title>Stochastic Model Based Proxy Servers Architecture for VoD to Achieve
  Reduced Client Waiting Time</title><categories>cs.MM</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010,
  http://ijcsi.org/articles/Stochastic-Model-Based-Proxy-Servers-Architecture-for-VoD-to-Achieve-Reduced-Client-Waiting-Time.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010,
  http://ijcsi.org/articles/Stochastic-Model-Based-Proxy-Servers-Architecture-for-VoD-to-Achieve-Reduced-Client-Waiting-Time.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a video on demand system, the main video repository may be far away from
the user and generally has limited streaming capacities. Since a high quality
video's size is huge, it requires high bandwidth for streaming over the
internet. In order to achieve a higher video hit ratio, reduced client waiting
time, distributed server's architecture can be used, in which multiple local
servers are placed close to clients and, based on their regional demands video
contents are cached dynamically from the main server. As the cost of proxy
server is decreasing and demand for reduced waiting time is increasing day by
day, newer architectures are explored, innovative schemes are arrived at. In
this paper we present novel 3 layer architecture, includes main multimedia
server, a Tracker and Proxy servers. This architecture targets to optimize the
client waiting time. We also propose an efficient prefix caching and load
sharing algorithm at the proxy server to allocate the cache according to
regional popularity of the video. The simulation results demonstrate that it
achieves significantly lower client's waiting time, when compared to the other
existing algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1198</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1198</id><created>2010-02-05</created><authors><author><keyname>Sandanalakshmi</keyname><forenames>R.</forenames></author><author><keyname>Athilakshmi</keyname></author><author><keyname>Manivannan</keyname><forenames>K.</forenames></author></authors><title>Modified EESM Based Link Adaptation Algorithm for Multimedia
  Transmission in Multicarrier Systems</title><categories>cs.OH</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010,
  http://ijcsi.org/articles/Modified-EESM-Based-Link-Adaptation-Algorithm-for-Multimedia-Transmission-in-Multicarrier-Systems.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010,
  http://ijcsi.org/articles/Modified-EESM-Based-Link-Adaptation-Algorithm-for-Multimedia-Transmission-in-Multicarrier-Systems.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The previous link adaptation algorithms on ofdm based systems use equal
modulation order for all sub carrier index within a block. For multimedia
transmission using ofdm as the modulation technique, unequal constellation is
used within one ofdm subcarrier block, a set of subcarriers for audio and
another set for video transmissions. A generic model has been shown for such a
transmission and link adaptation algorithm has been proposed using EESM
(Effective Exponential SNR mapping) method as basic method. Mathematical model
has been derived for the channel based on bivariate Gaussian distribution in
which the amplitude varies two dimensionally in the same envelope. From the
Moment generating function of bivariate distribution, Probability of error has
been theoretically derived. Results have been shown for BER performance of an
ofdm system using unequal constellation. BER performances have been shown for
different values of correlation parameter and fading figure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1199</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1199</id><created>2010-02-05</created><authors><author><keyname>Raamesh</keyname><forenames>Lilly</forenames></author><author><keyname>Uma</keyname><forenames>G. V.</forenames></author></authors><title>Reliable Mining of Automatically Generated Test Cases from Software
  Requirements Specification (SRS)</title><categories>cs.SE</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010, http://ijcsi.org/issues.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010, http://ijcsi.org/issues.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Writing requirements is a two-way process. In this paper we use to classify
Functional Requirements (FR) and Non Functional Requirements (NFR) statements
from Software Requirements Specification (SRS) documents. This is
systematically transformed into state charts considering all relevant
information. The current paper outlines how test cases can be automatically
generated from these state charts. The application of the states yields the
different test cases as solutions to a planning problem. The test cases can be
used for automated or manual software testing on system level. And also the
paper presents a method for reduction of test suite by using mining methods
thereby facilitating the mining and knowledge extraction from test cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1200</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1200</id><created>2010-02-05</created><authors><author><keyname>Al-Hammadi</keyname><forenames>Yousof</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Detecting Bots Based on Keylogging Activities</title><categories>cs.CR cs.AI cs.NE</categories><comments>7 pages, 7 figures, 3rd International Conference on Availability,
  Reliability and Security (ARES2008)</comments><journal-ref>Proceedings of the 3rd International Conference on Availability,
  Reliability and Security (ARES2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A bot is a piece of software that is usually installed on an infected machine
without the user's knowledge. A bot is controlled remotely by the attacker
under a Command and Control structure. Recent statistics show that bots
represent one of the fastest growing threats to our network by performing
malicious activities such as email spamming or keylogging. However, few bot
detection techniques have been developed to date. In this paper, we investigate
a behavioural algorithm to detect a single bot that uses keylogging activity.
Our approach involves the use of function calls analysis for the detection of
the bot with a keylogging component. Correlation of the frequency of a
specified time-window is performed to enhance he detection scheme. We perform a
range of experiments with the spybot. Our results show that there is a high
correlation between some function calls executed by this bot which indicates
abnormal activity in our system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1201</identifier>
 <datestamp>2010-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1201</id><created>2010-02-05</created><authors><author><keyname>Phulari</keyname><forenames>S. S.</forenames></author><author><keyname>Khamitkar</keyname><forenames>S. D.</forenames></author><author><keyname>Deshmukh</keyname><forenames>N. K.</forenames></author><author><keyname>Bhalchandra</keyname><forenames>P. U.</forenames></author><author><keyname>Lokhande</keyname><forenames>S. N.</forenames></author><author><keyname>Shinde</keyname><forenames>A. R.</forenames></author></authors><title>Understanding Formulation of Social Capital in Online Social Network
  Sites (SNS)</title><categories>cs.OH</categories><comments>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010, http://ijcsi.org/issues.php</comments><journal-ref>International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 3, January 2010, http://ijcsi.org/issues.php</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online communities are the gatherings of like-minded people, brought together
in cyberspace by shared interests. The shared interest has hidden social
capital aspects and can be of bridging or bonding type. Creating such
communities is not a big challenge but sustaining member's participation is.
This study examines the formation and maintenance of social capital in social
network sites. In addition to assessing bonding and bridging social capital, we
explore a dimension of social capital that assesses one's ability to stay
connected with members of a previously inhabited community, which we call
maintained social capital. Such dimension is enacted here in terms of
Hypothesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1285</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1285</id><created>2010-02-05</created><authors><author><keyname>Bagci</keyname><forenames>Ulas</forenames></author><author><keyname>Udupa</keyname><forenames>Jayaram K.</forenames></author><author><keyname>Bai</keyname><forenames>Li</forenames></author></authors><title>The Influence of Intensity Standardization on Medical Image Registration</title><categories>cs.CV</categories><comments>SPIE Medical Imaging 2010 conference paper, and the complete version
  of this paper was published in Elsevier Pattern Recognition Letters, volume
  31, 2010</comments><doi>10.1117/12.843969</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acquisition-to-acquisition signal intensity variations (non-standardness) are
inherent in MR images. Standardization is a post processing method for
correcting inter-subject intensity variations through transforming all images
from the given image gray scale into a standard gray scale wherein similar
intensities achieve similar tissue meanings. The lack of a standard image
intensity scale in MRI leads to many difficulties in tissue characterizability,
image display, and analysis, including image segmentation. This phenomenon has
been documented well; however, effects of standardization on medical image
registration have not been studied yet. In this paper, we investigate the
influence of intensity standardization in registration tasks with systematic
and analytic evaluations involving clinical MR images. We conducted nearly
20,000 clinical MR image registration experiments and evaluated the quality of
registrations both quantitatively and qualitatively. The evaluations show that
intensity variations between images degrades the accuracy of registration
performance. The results imply that the accuracy of image registration not only
depends on spatial and geometric similarity but also on the similarity of the
intensity values for the same tissues in different images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1288</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1288</id><created>2010-02-05</created><authors><author><keyname>Bagci</keyname><forenames>Ulas</forenames></author><author><keyname>Udupa</keyname><forenames>Jayaram K.</forenames></author><author><keyname>Chen</keyname><forenames>Xinjian</forenames></author></authors><title>Ball-Scale Based Hierarchical Multi-Object Recognition in 3D Medical
  Images</title><categories>cs.CV</categories><comments>This paper was published and presented in SPIE Medical Imaging 2010</comments><doi>10.1117/12.839920</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates, using prior shape models and the concept of ball
scale (b-scale), ways of automatically recognizing objects in 3D images without
performing elaborate searches or optimization. That is, the goal is to place
the model in a single shot close to the right pose (position, orientation, and
scale) in a given image so that the model boundaries fall in the close vicinity
of object boundaries in the image. This is achieved via the following set of
key ideas: (a) A semi-automatic way of constructing a multi-object shape model
assembly. (b) A novel strategy of encoding, via b-scale, the pose relationship
between objects in the training images and their intensity patterns captured in
b-scale images. (c) A hierarchical mechanism of positioning the model, in a
one-shot way, in a given image from a knowledge of the learnt pose relationship
and the b-scale image of the given image to be segmented. The evaluation
results on a set of 20 routine clinical abdominal female and male CT data sets
indicate the following: (1) Incorporating a large number of objects improves
the recognition accuracy dramatically. (2) The recognition algorithm can be
thought as a hierarchical framework such that quick replacement of the model
assembly is defined as coarse recognition and delineation itself is known as
finest recognition. (3) Scale yields useful information about the relationship
between the model assembly and any given image such that the recognition
results in a placement of the model close to the actual pose without doing any
elaborate searches or optimization. (4) Effective object recognition can make
delineation most accurate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1290</identifier>
 <datestamp>2010-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1290</id><created>2010-02-05</created><updated>2010-04-23</updated><authors><author><keyname>Rathi</keyname><forenames>Vishwambhar</forenames></author><author><keyname>Aurell</keyname><forenames>Erik</forenames></author><author><keyname>Rasmussen</keyname><forenames>Lars</forenames></author><author><keyname>Skoglund</keyname><forenames>Mikael</forenames></author></authors><title>Bounds on Threshold of Regular Random $k$-SAT</title><categories>cs.IT cs.CC math.CO math.IT</categories><comments>Accepted to SAT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the regular model of formula generation in conjunctive normal
form (CNF) introduced by Boufkhad et. al. We derive an upper bound on the
satisfiability threshold and NAE-satisfiability threshold for regular random
$k$-SAT for any $k \geq 3$. We show that these bounds matches with the
corresponding bound for the uniform model of formula generation.
  We derive lower bound on the threshold by applying the second moment method
to the number of satisfying assignments. For large $k$, we note that the
obtained lower bounds on the threshold of a regular random formula converges to
the lower bound obtained for the uniform model. Thus, we answer the question
posed in \cite{AcM06} regarding the performance of the second moment method for
regular random formulas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1292</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1292</id><created>2010-02-05</created><updated>2010-02-05</updated><authors><author><keyname>Nor</keyname><forenames>Igor</forenames></author><author><keyname>Hermelin</keyname><forenames>Danny</forenames></author><author><keyname>Charlat</keyname><forenames>Sylvain</forenames></author><author><keyname>Engelstadter</keyname><forenames>Jan</forenames></author><author><keyname>Reuter</keyname><forenames>Max</forenames></author><author><keyname>Duron</keyname><forenames>Olivier</forenames></author><author><keyname>Sagot</keyname><forenames>Marie-France</forenames></author></authors><title>Mod/Resc Parsimony Inference</title><categories>cs.DS</categories><comments>11 pages, 3 figures</comments><doi>10.1007/978-3-642-13509-5_19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address in this paper a new computational biology problem that aims at
understanding a mechanism that could potentially be used to genetically
manipulate natural insect populations infected by inherited, intra-cellular
parasitic bacteria. In this problem, that we denote by \textsc{Mod/Resc
Parsimony Inference}, we are given a boolean matrix and the goal is to find two
other boolean matrices with a minimum number of columns such that an
appropriately defined operation on these matrices gives back the input. We show
that this is formally equivalent to the \textsc{Bipartite Biclique Edge Cover}
problem and derive some complexity results for our problem using this
equivalence. We provide a new, fixed-parameter tractability approach for
solving both that slightly improves upon a previously published algorithm for
the \textsc{Bipartite Biclique Edge Cover}. Finally, we present experimental
results where we applied some of our techniques to a real-life data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1300</identifier>
 <datestamp>2011-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1300</id><created>2010-02-05</created><updated>2011-01-20</updated><authors><author><keyname>Agarwal</keyname><forenames>Mukul</forenames></author><author><keyname>Mitter</keyname><forenames>Sanjoy</forenames></author></authors><title>Architecture for communication with a fidelity criterion in unknown
  networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that in order to communicate independent sources (this is the
unicast problem) between various users over an unknown medium to within various
distortion levels, it is sufficient to consider source-channel separation based
architectures: architectures which first compress the sources to within the
corresponding distortion levels followed by reliable communication over the
unknown medium. We are reducing the problem of universal rate-distortion
communication of independent sources over a network to the universal reliable
communication problem over networks. This is a reductionist view. We are not
solving the reliable communication problem in networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1313</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1313</id><created>2010-02-05</created><authors><author><keyname>Amariucai</keyname><forenames>George T.</forenames></author><author><keyname>Wei</keyname><forenames>Shuangqing</forenames></author></authors><title>Half-Duplex Active Eavesdropping in Fast Fading Channels: A Block-Markov
  Wyner Secrecy Encoding Scheme</title><categories>cs.IT cs.CR math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the problem of half-duplex active eavesdropping in
fast fading channels. The active eavesdropper is a more powerful adversary than
the classical eavesdropper. It can choose between two functional modes:
eavesdropping the transmission between the legitimate parties (Ex mode), and
jamming it (Jx mode) -- the active eavesdropper cannot function in full duplex
mode. We consider a conservative scenario, when the active eavesdropper can
choose its strategy based on the legitimate transmitter-receiver pair's
strategy -- and thus the transmitter and legitimate receiver have to plan for
the worst. We show that conventional physical-layer secrecy approaches perform
poorly (if at all), and we introduce a novel encoding scheme, based on very
limited and unsecured feedback -- the Block-Markov Wyner (BMW) encoding scheme
-- which outperforms any schemes currently available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1335</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1335</id><created>2010-02-06</created><authors><author><keyname>Venkatramanan</keyname><forenames>Srinivasan</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author></authors><title>New Insights from an Analysis of Social Influence Networks under the
  Linear Threshold Model</title><categories>cs.OH physics.soc-ph</categories><comments>13 pages, 6 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the spread of influence in a social network based on the Linear
Threshold model. We derive an analytical expression for evaluating the expected
size of the eventual influenced set for a given initial set, using the
probability of activation for each node in the social network. We then provide
an equivalent interpretation for the influence spread, in terms of acyclic path
probabilities in the Markov chain obtained by reversing the edges in the social
network influence graph. We use some properties of such acyclic path
probabilities to provide an alternate proof for the submodularity of the
influence function. We illustrate the usefulness of the analytical expression
in estimating the most influential set, in special cases such as the
UILT(Uniform Influence Linear Threshold), USLT(Uniform Susceptance Linear
Threshold) and node-degree based influence models. We show that the PageRank
heuristic is either provably optimal or performs very well in the above models,
and explore its limitations in more general cases. Finally, based on the
insights obtained from the analytical expressions, we provide an efficient
algorithm which approximates the greedy algorithm for the influence
maximization problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1337</identifier>
 <datestamp>2011-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1337</id><created>2010-02-05</created><updated>2011-10-18</updated><authors><author><keyname>Lee</keyname><forenames>Si-Hyeon</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author></authors><title>Capacity Scaling of Wireless Ad Hoc Networks: Shannon Meets Maxwell</title><categories>cs.IT math.IT</categories><comments>14 pages, 4 figures. Accepted for publication in IEEE Transactions on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we characterize the information-theoretic capacity scaling of
wireless ad hoc networks with $n$ randomly distributed nodes. By using an exact
channel model from Maxwell's equations, we successfully resolve the conflict in
the literature between the linear capacity scaling by \&quot;{O}zg\&quot;{u}r et al. and
the degrees of freedom limit given as the ratio of the network diameter and the
wavelength $\lambda$ by Franceschetti et al. In dense networks where the
network area is fixed, the capacity scaling is given as the minimum of $n$ and
the degrees of freedom limit $\lambda^{-1}$ to within an arbitrarily small
exponent. In extended networks where the network area is linear in $n$, the
capacity scaling is given as the minimum of $n$ and the degrees of freedom
limit $\sqrt{n}\lambda^{-1}$ to within an arbitrarily small exponent. Hence, we
recover the linear capacity scaling by \&quot;{O}zg\&quot;{u}r et al. if
$\lambda=O(n^{-1})$ in dense networks and if $\lambda=O(n^{-1/2})$ in extended
networks. Otherwise, the capacity scaling is given as the degrees of freedom
limit characterized by Franceschetti et al. For achievability, a modified
hierarchical cooperation is proposed based on a lower bound on the capacity of
multiple-input multiple-output channel between two node clusters using our
channel model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1347</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1347</id><created>2010-02-05</created><authors><author><keyname>Sankar</keyname><forenames>Lalitha</forenames></author><author><keyname>Rajagopalan</keyname><forenames>S. Raj</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Utility and Privacy of Data Sources: Can Shannon Help Conceal and Reveal
  Information?</title><categories>cs.IT math.IT</categories><comments>presented at the 4th Information Theory and Applications Workshop, La
  Jolla, CA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of private information &quot;leakage&quot; (inadvertently or by malicious
design) from the myriad large centralized searchable data repositories drives
the need for an analytical framework that quantifies unequivocally how safe
private data can be (privacy) while still providing useful benefit (utility) to
multiple legitimate information consumers. Rate distortion theory is shown to
be a natural choice to develop such a framework which includes the following:
modeling of data sources, developing application independent utility and
privacy metrics, quantifying utility-privacy tradeoffs irrespective of the type
of data sources or the methods of providing privacy, developing a
side-information model for dealing with questions of external knowledge, and
studying a successive disclosure problem for multiple query data sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1363</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1363</id><created>2010-02-06</created><authors><author><keyname>Jiang</keyname><forenames>Albert Xin</forenames></author><author><keyname>Safari</keyname><forenames>MohammadAli</forenames></author></authors><title>Pure Nash Equilibria: Complete Characterization of Hard and Easy
  Graphical Games</title><categories>cs.GT cs.CC</categories><comments>8 pages. To appear in AAMAS 2010</comments><acm-class>J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the computational complexity of pure Nash equilibria in graphical
games. It is known that the problem is NP-complete in general, but tractable
(i.e., in P) for special classes of graphs such as those with bounded
treewidth. It is then natural to ask: is it possible to characterize all
tractable classes of graphs for this problem? In this work, we provide such a
characterization for the case of bounded in-degree graphs, thereby resolving
the gap between existing hardness and tractability results. In particular, we
analyze the complexity of PUREGG(C, -), the problem of deciding the existence
of pure Nash equilibria in graphical games whose underlying graphs are
restricted to class C. We prove that, under reasonable complexity theoretic
assumptions, for every recursively enumerable class C of directed graphs with
bounded in-degree, PUREGG(C, -) is in polynomial time if and only if the
reduced graphs (the graphs resulting from iterated removal of sinks) of C have
bounded treewidth. We also give a characterization for PURECHG(C,-), the
problem of deciding the existence of pure Nash equilibria in colored
hypergraphical games, a game representation that can express the additional
structure that some of the players have identical local utility functions. We
show that the tractable classes of bounded-arity colored hypergraphical games
are precisely those whose reduced graphs have bounded treewidth modulo
homomorphic equivalence. Our proofs make novel use of Grohe's characterization
of the complexity of homomorphism problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1406</identifier>
 <datestamp>2010-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1406</id><created>2010-02-06</created><updated>2010-06-02</updated><authors><author><keyname>Li</keyname><forenames>Yao</forenames></author><author><keyname>Soljanin</keyname><forenames>Emina</forenames></author><author><keyname>Spasojevic</keyname><forenames>Predrag</forenames></author></authors><title>Collecting Coded Coupons over Generations</title><categories>cs.IT math.IT</categories><comments>accepted by ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To reduce computational complexity and delay in randomized network coded
content distribution (and for some other practical reasons), coding is not
performed simultaneously over all content blocks but over much smaller subsets
known as generations. A penalty is throughput reduction. We model coding over
generations as the coupon collector's brotherhood problem. This model enables
us to theoretically compute the expected number of coded packets needed for
successful decoding of the entire content, as well as a bound on the
probability of decoding failure, and further, to quantify the tradeoff between
computational complexity and throughput. Interestingly, with a moderate
increase in the generation size, throughput quickly approaches link capacity.
As an additional contribution, we derive new results for the generalized
collector's brotherhood problem which can also be used for further study of
many other aspects of coding over generations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1407</identifier>
 <datestamp>2010-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1407</id><created>2010-02-06</created><updated>2010-05-01</updated><authors><author><keyname>Li</keyname><forenames>Yao</forenames></author><author><keyname>Soljanin</keyname><forenames>Emina</forenames></author><author><keyname>Spasojevic</keyname><forenames>Predrag</forenames></author></authors><title>Collecting Coded Coupons over Overlapping Generations</title><categories>cs.IT math.IT</categories><comments>Accepted by NetCod 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coding over subsets (known as generations) rather than over all content
blocks in P2P distribution networks and other applications is necessary for a
number of practical reasons such as computational complexity. A penalty for
coding only within generations is an overall throughput reduction. It has been
previously shown that allowing contiguous generations to overlap in a
head-to-toe manner improves the throughput. We here propose and study a scheme,
referred to as the {\it random annex code}, that creates shared packets between
any two generations at random rather than only the neighboring ones. By
optimizing very few design parameters, we obtain a simple scheme that
outperforms both the non-overlapping and the head-to-toe overlapping schemes of
comparable computational complexity, both in the expected throughput and in the
rate of convergence of the probability of decoding failure to zero. We provide
a practical algorithm for accurate analysis of the expected throughput of the
random annex code for finite-length information. This algorithm enables us to
quantify the throughput vs.computational complexity tradeoff, which is
necessary for optimal selection of the scheme parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1408</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1408</id><created>2010-02-06</created><authors><author><keyname>Beresford</keyname><forenames>Alastair R.</forenames><affiliation>University of Cambridge</affiliation></author><author><keyname>Gay</keyname><forenames>Simon</forenames><affiliation>University of Glasgow</affiliation></author></authors><title>Proceedings Second International Workshop on Programming Language
  Approaches to Concurrency and Communication-cEntric Software</title><categories>cs.PL cs.DC</categories><acm-class>D.1.3; C.2.4; D.3.0</acm-class><journal-ref>EPTCS 17, 2010</journal-ref><doi>10.4204/EPTCS.17</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Second International Workshop on Programming Language Approaches to
Concurrency and Communication-cEntric Software (PLACES) was co-located with
ETAPS 2009 in the city of York, England. The workshop took place on Sunday 22nd
March 2009. The workshop focused on the challenges raised by the changing
landscape of computer software. Traditionally, most software was written for a
single computer with one CPU. However applications on the web today are built
using numerous interacting services deployed on across many machines; soon
off-the-shelf CPUs will host thousands of cores, and sensor networks will be
composed from a large number of processing units. Many normal applications will
soon need to make effective use of thousands of computing nodes. At some level
of granularity, computation in such systems will be inherently concurrent and
communication-centred.
  The development of effective programming methodologies for the coming
computing paradigm demands exploration and understanding of a wide variety of
ideas and techniques. This workshop offered a forum where researchers from
different fields could exchange new ideas on one of the central challenges for
programming in the near future, the development of programming methodologies
and infrastructures where concurrency and distribution are the norm rather than
a marginal concern.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1422</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1422</id><created>2010-02-06</created><authors><author><keyname>van Emden</keyname><forenames>M. H.</forenames></author></authors><title>Integrating Interval Constraints into Logic Programming</title><categories>cs.PL cs.LO cs.NA</categories><comments>21 pages, 2 tables, no figures</comments><report-no>DCS-133-IR</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The CLP scheme uses Horn clauses and SLD resolution to generate multiple
constraint satisfaction problems (CSPs). The possible CSPs include rational
trees (giving Prolog) and numerical algorithms for solving linear equations and
linear programs (giving CLP(R)). In this paper we develop a form of CSP for
interval constraints. In this way one obtains a logic semantics for the
efficient floating-point hardware that is available on most computers.
  The need for the method arises because in the practice of scheduling and
engineering design it is not enough to solve a single CSP. Ideally one should
be able to consider thousands of CSPs and efficiently solve them or show them
to be unsolvable. This is what CLP/NCSP, the new subscheme of CLP described in
this paper is designed to do.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1436</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1436</id><created>2010-02-07</created><authors><author><keyname>Schwartz</keyname><forenames>Moshe</forenames></author></authors><title>Constant-Weight Gray Codes for Local Rank Modulation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the local rank-modulation scheme in which a sliding window going
over a sequence of real-valued variables induces a sequence of permutations.
The local rank-modulation, as a generalization of the rank-modulation scheme,
has been recently suggested as a way of storing information in flash memory.
  We study constant-weight Gray codes for the local rank-modulation scheme in
order to simulate conventional multi-level flash cells while retaining the
benefits of rank modulation. We provide necessary conditions for the existence
of cyclic and cyclic optimal Gray codes. We then specifically study codes of
weight 2 and upper bound their efficiency, thus proving that there are no such
asymptotically-optimal cyclic codes. In contrast, we study codes of weight 3
and efficiently construct codes which are asymptotically-optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1443</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1443</id><created>2010-02-07</created><authors><author><keyname>Filiot</keyname><forenames>Emmanuel</forenames></author><author><keyname>Raskin</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author><author><keyname>Reynier</keyname><forenames>Pierre-Alain</forenames></author><author><keyname>Servais</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Talbot</keyname><forenames>Jean-Marc</forenames></author></authors><title>On Functionality of Visibly Pushdown Transducers</title><categories>cs.FL</categories><comments>20 pages</comments><doi>10.1007/978-3-642-15155-2_32</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visibly pushdown transducers form a subclass of pushdown transducers that
(strictly) extends finite state transducers with a stack. Like visibly pushdown
automata, the input symbols determine the stack operations. In this paper, we
prove that functionality is decidable in PSpace for visibly pushdown
transducers. The proof is done via a pumping argument: if a word with two
outputs has a sufficiently large nesting depth, there exists a nested word with
two outputs whose nesting depth is strictly smaller. The proof uses technics of
word combinatorics. As a consequence of decidability of functionality, we also
show that equivalence of functional visibly pushdown transducers is
Exptime-Complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1446</identifier>
 <datestamp>2011-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1446</id><created>2010-02-07</created><authors><author><keyname>Amblard</keyname><forenames>P. O.</forenames></author><author><keyname>Michel</keyname><forenames>O. J. J.</forenames></author></authors><title>On directed information theory and Granger causality graphs</title><categories>cs.IT math.IT</categories><comments>accepted for publications, Journal of Computational Neuroscience</comments><journal-ref>J. Comput. Neurosci. (2010), 30:7-16</journal-ref><doi>10.1007/s10827-010-0231-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Directed information theory deals with communication channels with feedback.
When applied to networks, a natural extension based on causal conditioning is
needed. We show here that measures built from directed information theory in
networks can be used to assess Granger causality graphs of stochastic
processes. We show that directed information theory includes measures such as
the transfer entropy, and that it is the adequate information theoretic
framework needed for neuroscience applications, such as connectivity inference
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1447</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1447</id><created>2010-02-07</created><authors><author><keyname>Naeiny</keyname><forenames>Mahmoud Ferdosizadeh</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>PAPR reduction of space-time and space-frequency coded OFDM systems
  using active constellation extension</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Active Constellation Extension (ACE) is one of techniques introduced for Peak
to Average Power Ratio (PAPR) reduction for OFDM systems. In this technique,
the constellation points are extended such that the PAPR is minimized but the
minimum distance of the constellation points does not decrease. In this paper,
an iterative ACE method is extended to spatially encoded OFDM systems. The
proposed methods are such that the PAPR is reduced simultaneously at all
antennas, while the spatial encoding relationships still hold. It will be shown
that the original ACE method can be employed before Space Time Block Coding
(STBC). But in case of Space Frequency Block Coding (SFBC), two modified
techniques have been proposed. In the first method, the OFDM frame is separated
by several subframes and the ACE method is applied to these subframes
independently to reduce their corresponding PAPRs. Then the low PAPR subframes
are recombined based on SFBC relationships to yield the transmitted signals
from different antennas. In the second method, for each iteration, the ACE is
applied to the antenna with the maximum PAPR, and the signals of the other
antennas are generated from that of this antenna. Simulation results show that
both algorithms converge, but the second method outperforms the first one when
the number of antennas is increased.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1456</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1456</id><created>2010-02-07</created><updated>2010-04-15</updated><authors><author><keyname>Filiot</keyname><forenames>Emmanuel</forenames></author><author><keyname>Gall</keyname><forenames>Tristan Le</forenames></author><author><keyname>Raskin</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author></authors><title>Iterated Regret Minimization in Game Graphs</title><categories>cs.GT</categories><comments>19 pages. Bug in introductive example fixed.</comments><doi>10.1007/978-3-642-15155-2_31</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Iterated regret minimization has been introduced recently by J.Y. Halpern and
R. Pass in classical strategic games. For many games of interest, this new
solution concept provides solutions that are judged more reasonable than
solutions offered by traditional game concepts -- such as Nash equilibrium --.
Although computing iterated regret on explicit matrix game is conceptually and
computationally easy, nothing is known about computing the iterated regret on
games whose matrices are defined implicitly using game tree, game DAG or, more
generally game graphs. In this paper, we investigate iterated regret
minimization for infinite duration two-player quantitative non-zero sum games
played on graphs.
  We consider reachability objectives that are not necessarily antagonist.
Edges are weighted by integers -- one for each player --, and the payoffs are
defined by the sum of the weights along the paths. Depending on the class of
graphs, we give either polynomial or pseudo-polynomial time algorithms to
compute a strategy that minimizes the regret for a fixed player. We finally
give algorithms to compute the strategies of the two players that minimize the
iterated regret for trees, and for graphs with strictly positive weights only.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1464</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1464</id><created>2010-02-07</created><updated>2010-02-12</updated><authors><author><keyname>To</keyname><forenames>Anthony Widjaja</forenames></author></authors><title>Parikh Images of Regular Languages: Complexity and Applications</title><categories>cs.LO cs.FL</categories><comments>Full version of submission to LICS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the Parikh image of the language of an NFA with n states over an
alphabet of size k can be described as a finite union of linear sets with at
most k generators and total size 2^{O(k^2 log n)}, i.e., polynomial for all
fixed k &gt;= 1. Previously, it was not known whether the number of generators
could be made independent of n, and best upper bounds on the total size were
exponential in n. Furthermore, we give an algorithm for performing such a
translation in time 2^{O(k^2 log(kn))}. Our proof exploits a previously unknown
connection to the theory of convex sets, and establishes a normal form theorem
for semilinear sets, which is of independent interests. To complement these
results, we show that our upper bounds are tight and that the results cannot be
extended to context-free languages. We give four applications: (1) a new
polynomial fragment of integer programming, (2) precise complexity of
membership for Parikh images of NFAs, (3) an answer to an open question about
polynomial PAC-learnability of semilinear sets, and (4) an optimal algorithm
for LTL model checking over discrete-timed reversal-bounded counter systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1465</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1465</id><created>2010-02-07</created><authors><author><keyname>Rouayheb</keyname><forenames>Salim El</forenames></author><author><keyname>Sprintson</keyname><forenames>Alex</forenames></author><author><keyname>Sadeghi</keyname><forenames>Parastoo</forenames></author></authors><title>On Coding for Cooperative Data Exchange</title><categories>cs.IT math.IT</categories><comments>Appeared in the proceedings of the 2010 IEEE Information Theory
  Workshop (ITW 2010, Cairo)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of data exchange by a group of closely-located
wireless nodes. In this problem each node holds a set of packets and needs to
obtain all the packets held by other nodes. Each of the nodes can broadcast the
packets in its possession (or a combination thereof) via a noiseless broadcast
channel of capacity one packet per channel use. The goal is to minimize the
total number of transmissions needed to satisfy the demands of all the nodes,
assuming that they can cooperate with each other and are fully aware of the
packet sets available to other nodes. This problem arises in several practical
settings, such as peer-to-peer systems and wireless data broadcast. In this
paper, we establish upper and lower bounds on the optimal number of
transmissions and present an efficient algorithm with provable performance
guarantees. The effectiveness of our algorithms is established through
numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1480</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1480</id><created>2010-02-07</created><authors><author><keyname>Ortega</keyname><forenames>Pedro A.</forenames></author><author><keyname>Braun</keyname><forenames>Daniel A.</forenames></author></authors><title>A Minimum Relative Entropy Controller for Undiscounted Markov Decision
  Processes</title><categories>cs.AI cs.LG cs.RO</categories><comments>8 pages, 3 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adaptive control problems are notoriously difficult to solve even in the
presence of plant-specific controllers. One way to by-pass the intractable
computation of the optimal policy is to restate the adaptive control as the
minimization of the relative entropy of a controller that ignores the true
plant dynamics from an informed controller. The solution is given by the
Bayesian control rule-a set of equations characterizing a stochastic adaptive
controller for the class of possible plant dynamics. Here, the Bayesian control
rule is applied to derive BCR-MDP, a controller to solve undiscounted Markov
decision processes with finite state and action spaces and unknown dynamics. In
particular, we derive a non-parametric conjugate prior distribution over the
policy space that encapsulates the agent's whole relevant history and we
present a Gibbs sampler to draw random policies from this distribution.
Preliminary results show that BCR-MDP successfully avoids sub-optimal limit
cycles due to its built-in mechanism to balance exploration versus
exploitation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1496</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1496</id><created>2010-02-07</created><authors><author><keyname>Jansen</keyname><forenames>Maurice</forenames></author><author><keyname>Qiao</keyname><forenames>Youming</forenames></author><author><keyname>Sarma</keyname><forenames>Jayalal</forenames></author></authors><title>Deterministic Black-Box Identity Testing $\pi$-Ordered Algebraic
  Branching Programs</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study algebraic branching programs (ABPs) with restrictions
on the order and the number of reads of variables in the program. Given a
permutation $\pi$ of $n$ variables, for a $\pi$-ordered ABP ($\pi$-OABP), for
any directed path $p$ from source to sink, a variable can appear at most once
on $p$, and the order in which variables appear on $p$ must respect $\pi$. An
ABP $A$ is said to be of read $r$, if any variable appears at most $r$ times in
$A$. Our main result pertains to the identity testing problem. Over any field
$F$ and in the black-box model, i.e. given only query access to the polynomial,
we have the following result: read $r$ $\pi$-OABP computable polynomials can be
tested in $\DTIME[2^{O(r\log r \cdot \log^2 n \log\log n)}]$.
  Our next set of results investigates the computational limitations of OABPs.
It is shown that any OABP computing the determinant or permanent requires size
$\Omega(2^n/n)$ and read $\Omega(2^n/n^2)$. We give a multilinear polynomial
$p$ in $2n+1$ variables over some specifically selected field $G$, such that
any OABP computing $p$ must read some variable at least $2^n$ times. We show
that the elementary symmetric polynomial of degree $r$ in $n$ variables can be
computed by a size $O(rn)$ read $r$ OABP, but not by a read $(r-1)$ OABP, for
any $0 &lt; 2r-1 \leq n$. Finally, we give an example of a polynomial $p$ and two
variables orders $\pi \neq \pi'$, such that $p$ can be computed by a read-once
$\pi$-OABP, but where any $\pi'$-OABP computing $p$ must read some variable at
least $2^n$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1530</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1530</id><created>2010-02-08</created><updated>2010-02-09</updated><authors><author><keyname>Vaze</keyname><forenames>Chinmay S.</forenames></author><author><keyname>Varanasi</keyname><forenames>Mahesh K.</forenames></author></authors><title>The Degrees of Freedom Region of the MIMO Cognitive Interference Channel
  with No CSIT</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author(s) for revision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1531</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1531</id><created>2010-02-08</created><updated>2010-02-18</updated><authors><author><keyname>Vaze</keyname><forenames>Chinmay S.</forenames></author><author><keyname>Varanasi</keyname><forenames>Mahesh K.</forenames></author></authors><title>A Large-System Analysis of the Imperfect-CSIT Gaussian Broadcast Channel
  with a DPC-based Transmission Strategy</title><categories>cs.IT math.IT</categories><comments>Submitted to ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Gaussian broadcast channel (GBC) with $K$ transmit antennas and $K$
single-antenna users is considered for the case in which the channel state
information is obtained at the transmitter via a finite-rate feedback link of
capacity $r$ bits per user. The throughput (i.e., the sum-rate normalized by
$K$) of the GBC is analyzed in the limit as $K \to \infty$ with $\frac{r}{K}
\to \bar{r}$. Considering the transmission strategy of zeroforcing dirty paper
coding (ZFDPC), a closed-form expression for the asymptotic throughput is
derived. It is observed that, even under the finite-rate feedback setting,
ZFDPC achieves a significantly higher throughput than zeroforcing beamforming.
Using the asymptotic throughput expression, the problem of obtaining the number
of users to be selected in order to maximize the throughput is solved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1532</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1532</id><created>2010-02-08</created><updated>2010-02-09</updated><authors><author><keyname>Vaze</keyname><forenames>Chinmay S.</forenames></author><author><keyname>Varanasi</keyname><forenames>Mahesh K.</forenames></author></authors><title>On the scaling of feedback bits to achieve the full multiplexing gain
  over the Gaussian broadcast channel using DPC</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author(s) for revision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1549</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1549</id><created>2010-02-08</created><authors><author><keyname>Breslav</keyname><forenames>Andrey</forenames></author></authors><title>Extensible type checker for parser generation</title><categories>cs.PL cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parser generators generate translators from language specifications. In many
cases, such specifications contain semantic actions written in the same
language as the generated code. Since these actions are subject to little
static checking, they are usually a source of errors which are discovered only
when generated code is compiled.
  In this paper we propose a parser generator front-end which statically checks
semantic actions for typing errors and prevents such errors from appearing in
generated code. The type checking procedure is extensible to support many
implementation languages. An extension for Java is presented along with an
extension for declarative type system descriptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1559</identifier>
 <datestamp>2011-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1559</id><created>2010-02-08</created><updated>2011-01-11</updated><authors><author><keyname>Takahashi</keyname><forenames>Hayato</forenames></author></authors><title>Computational limits to nonparametric estimation for ergodic processes</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE trans IT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new negative result for nonparametric estimation of binary ergodic
processes is shown. I The problem of estimation of distribution with any degree
of accuracy is studied. Then it is shown that for any countable class of
estimators there is a zero-entropy binary ergodic process that is inconsistent
with the class of estimators. Our result is different from other negative
results for universal forecasting scheme of ergodic processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1581</identifier>
 <datestamp>2010-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1581</id><created>2010-02-08</created><updated>2010-03-03</updated><authors><author><keyname>Leith</keyname><forenames>Douglas J.</forenames></author><author><keyname>Cao</keyname><forenames>Qizhi</forenames></author><author><keyname>Subramanian</keyname><forenames>Vijay G.</forenames></author></authors><title>Max-min Fairness in 802.11 Mesh Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we build upon the recent observation that the 802.11 rate
region is log-convex and, for the first time, characterise max-min fair rate
allocations for a large class of 802.11 wireless mesh networks. By exploiting
features of the 802.11e/n MAC, in particular TXOP packet bursting, we are able
to use this characterisation to establish a straightforward, practically
implementable approach for achieving max-min throughput fairness. We
demonstrate that this approach can be readily extended to encompass time-based
fairness in multi-rate 802.11 mesh networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1584</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1584</id><created>2010-02-08</created><authors><author><keyname>Tadrous</keyname><forenames>John</forenames></author><author><keyname>Sultan</keyname><forenames>Ahmed</forenames></author><author><keyname>Nafie</keyname><forenames>Mohammed</forenames></author><author><keyname>El-Keyi</keyname><forenames>Amr</forenames></author></authors><title>Power Control for Maximum Throughput in Spectrum Underlay Cognitive
  Radio Networks</title><categories>cs.IT cs.NI math.IT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate power allocation for users in a spectrum underlay cognitive
network. Our objective is to find a power control scheme that allocates
transmit power for both primary and secondary users so that the overall network
throughput is maximized while maintaining the quality of service (QoS) of the
primary users greater than a certain minimum limit. Since an optimum solution
to our problem is computationally intractable, as the optimization problem is
non-convex, we propose an iterative algorithm based on sequential geometric
programming, that is proved to converge to at least a local optimum solution.
We use the proposed algorithm to show how a spectrum underlay network would
achieve higher throughput with secondary users operation than with primary
users operating alone. Also, we show via simulations that the loss in primary
throughput due to the admission of the secondary users is accompanied by a
reduction in the total primary transmit power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1606</identifier>
 <datestamp>2014-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1606</id><created>2010-02-08</created><updated>2014-03-18</updated><authors><author><keyname>Dinur</keyname><forenames>Irit</forenames></author><author><keyname>Meir</keyname><forenames>Or</forenames></author></authors><title>Derandomized Parallel Repetition via Structured PCPs</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A PCP is a proof system for NP in which the proof can be checked by a
probabilistic verifier. The verifier is only allowed to read a very small
portion of the proof, and in return is allowed to err with some bounded
probability. The probability that the verifier accepts a false proof is called
the soundness error, and is an important parameter of a PCP system that one
seeks to minimize. Constructing PCPs with sub-constant soundness error and, at
the same time, a minimal number of queries into the proof (namely two) is
especially important due to applications for inapproximability.
  In this work we construct such PCP verifiers, i.e., PCPs that make only two
queries and have sub-constant soundness error. Our construction can be viewed
as a combinatorial alternative to the &quot;manifold vs. point&quot; construction, which
is the only construction in the literature for this parameter range. The
&quot;manifold vs. point&quot; PCP is based on a low degree test, while our construction
is based on a direct product test. We also extend our construction to yield a
decodable PCP (dPCP) with the same parameters. By plugging in this dPCP into
the scheme of Dinur and Harsha (FOCS 2009) one gets an alternative construction
of the result of Moshkovitz and Raz (FOCS 2008), namely: a construction of
two-query PCPs with small soundness error and small alphabet size.
  Our construction of a PCP is based on extending the derandomized direct
product test of Impagliazzo, Kabanets and Wigderson (STOC 09) to a derandomized
parallel repetition theorem. More accurately, our PCP construction is obtained
in two steps. We first prove a derandomized parallel repetition theorem for
specially structured PCPs. Then, we show that any PCP can be transformed into
one that has the required structure, by embedding it on a de-Bruijn graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1624</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1624</id><created>2010-02-08</created><updated>2010-02-10</updated><authors><author><keyname>Bloom</keyname><forenames>Stephen L.</forenames></author><author><keyname>Esik</keyname><forenames>Zoltan</forenames></author></authors><title>Algebraic Linear Orderings</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algebraic linear ordering is a component of the initial solution of a
first-order recursion scheme over the continuous categorical algebra of
countable linear orderings equipped with the sum operation and the constant 1.
Due to a general Mezei-Wright type result, algebraic linear orderings are
exactly those isomorphic to the linear ordering of the leaves of an algebraic
tree. Using Courcelle's characterization of algebraic trees, we obtain the fact
that a linear ordering is algebraic if and only if it can be represented as the
lexicographic ordering of a deterministic context-free language. When the
algebraic linear ordering is a well-ordering, its order type is an algebraic
ordinal. We prove that the Hausdorff rank of any scattered algebraic linear
ordering is less than $\omega^\omega$. It follows that the algebraic ordinals
are exactly those less than $\omega^{\omega^\omega}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1629</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1629</id><created>2010-02-08</created><authors><author><keyname>Blaszczyszyn</keyname><forenames>Bartek</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Muhlethaler</keyname><forenames>Paul</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Stochastic Analysis of Non-slotted Aloha in Wireless Ad-Hoc Networks</title><categories>cs.NI math.PR</categories><comments>accepted for IEEE Infocom 2010</comments><proxy>ccsd inria-00435236</proxy><doi>10.1109/INFCOM.2010.5462086</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose two analytically tractable stochastic models of
non-slotted Aloha for Mobile Ad-hoc NETworks (MANETs): one model assumes a
static pattern of nodes while the other assumes that the pattern of nodes
varies over time. Both models feature transmitters randomly located in the
Euclidean plane, according to a Poisson point process with the receivers
randomly located at a fixed distance from the emitters. We concentrate on the
so-called outage scenario, where a successful transmission requires a
Signal-to-Interference-and-Noise Ratio (SINR) larger than a given threshold.
With Rayleigh fading and the SINR averaged over the duration of the packet
transmission, both models lead to closed form expressions for the probability
of successful transmission. We show an excellent matching of these results with
simulations. Using our models we compare the performances of non-slotted Aloha
to previously studied slotted Aloha. We observe that when the path loss is not
very strong both models, when appropriately optimized, exhibit similar
performance. For stronger path loss non-slotted Aloha performs worse than
slotted Aloha, however when the path loss exponent is equal to 4 its density of
successfully received packets is still 75% of that in the slotted scheme. This
is still much more than the 50% predicted by the well-known analysis where
simultaneous transmissions are never successful. Moreover, in any path loss
scenario, both schemes exhibit the same energy efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1636</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1636</id><created>2010-02-08</created><updated>2010-04-16</updated><authors><author><keyname>Hugel</keyname><forenames>Thomas</forenames></author><author><keyname>Boufkhad</keyname><forenames>Yacine</forenames></author></authors><title>Non Uniform Selection of Solutions for Upper Bounding the 3-SAT
  Threshold</title><categories>cs.DM</categories><comments>28 pages; presentation improved</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new insight into the upper bounding of the 3-SAT threshold by the
first moment method. The best criteria developed so far to select the solutions
to be counted discriminate among neighboring solutions on the basis of uniform
information about each individual free variable. What we mean by uniform
information, is information which does not depend on the solution: e.g. the
number of positive/negative occurrences of the considered variable. What is new
in our approach is that we use non uniform information about variables. Thus we
are able to make a more precise tuning, resulting in a slight improvement on
upper bounding the 3-SAT threshold for various models of formulas defined by
their distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1678</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1678</id><created>2010-02-08</created><authors><author><keyname>Rahayu</keyname><forenames>S. Siti</forenames></author><author><keyname>Robiah</keyname><forenames>Y.</forenames></author><author><keyname>Shahrin</keyname><forenames>S.</forenames></author><author><keyname>Zaki</keyname><forenames>Mohd M.</forenames></author><author><keyname>Irda</keyname><forenames>R.</forenames></author><author><keyname>Faizal</keyname><forenames>M. A.</forenames></author></authors><title>Scenario Based Worm Trace Pattern Identification Technique</title><categories>cs.CR</categories><comments>9 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Computer Science ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 1-9, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The number of malware variants is growing tremendously and the study of
malware attacks on the Internet is still a demanding research domain. In this
research, various logs from different OSI layer are explore to identify the
traces leave on the attacker and victim logs, and the attack worm trace pattern
are establish in order to reveal true attacker or victim. For the purpose of
this paper, it will only concentrate on cybercrime that caused by malware
network intrusion and used the traditional worm namely blaster worm variants.
This research creates the concept of trace pattern by fusing the attackers and
victims perspective. Therefore, the objective of this paper is to propose on
attackers, victims and multistep, attacker or victim, trace patterns by
combining both perspectives. These three proposed worm trace patterns can be
extended into research areas in alert correlation and computer forensic
investigation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1679</identifier>
 <datestamp>2011-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1679</id><created>2010-02-08</created><updated>2010-11-05</updated><authors><author><keyname>Alekseyev</keyname><forenames>Max A.</forenames></author></authors><title>On the intersections of Fibonacci, Pell, and Lucas numbers</title><categories>math.NT cs.DM cs.DS</categories><journal-ref>INTEGERS 11(3), 2011, pp. 239-259</journal-ref><doi>10.1515/INTEG.2011.021</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe how to compute the intersection of two Lucas sequences of the
forms $\{U_n(P,\pm 1) \}_{n=0}^{\infty}$ or $\{V_n(P,\pm 1) \}_{n=0}^{\infty}$
with $P\in\mathbb{Z}$ that includes sequences of Fibonacci, Pell, Lucas, and
Lucas-Pell numbers. We prove that such an intersection is finite except for the
case $U_n(1,-1)$ and $U_n(3,1)$ and the case of two $V$-sequences when the
product of their discriminants is a perfect square. Moreover, the intersection
in these cases also forms a Lucas sequence. Our approach relies on solving
homogeneous quadratic Diophantine equations and Thue equations. In particular,
we prove that 0, 1, 2, and 5 are the only numbers that are both Fibonacci and
Pell, and list similar results for many other pairs of Lucas sequences. We
further extend our results to Lucas sequences with arbitrary initial terms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1681</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1681</id><created>2010-02-08</created><authors><author><keyname>Baadache</keyname><forenames>Abderrahmane</forenames></author><author><keyname>Belmehdi</keyname><forenames>Ali</forenames></author></authors><title>Avoiding Black Hole and Cooperative Black Hole Attacks in Wireless Ad
  hoc Networks</title><categories>cs.CR</categories><comments>7 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Computer Science ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 10-16, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In wireless ad hoc networks, the absence of any control on packets
forwarding, make these networks vulnerable by various deny of service attacks
(DoS). A node, in wireless ad hoc network, counts always on intermediate nodes
to send these packets to a given destination node. An intermediate node, which
takes part in packets forwarding, may behave maliciously and drop packets which
goes through it, instead of forwarding them to the following node. Such
behavior is called black hole attack. In this paper, after having specified the
black hole attack, a secure mechanism, which consists in checking the good
forwarding of packets by an intermediate node, was proposed. The proposed
solution avoids the black hole and the cooperative black hole attacks.
Evaluation metrics were considered in simulation to show the effectiveness of
the suggested solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1683</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1683</id><created>2010-02-08</created><authors><author><keyname>Ramesh</keyname><forenames>K.</forenames></author><author><keyname>Ayyar</keyname><forenames>K.</forenames></author><author><keyname>Nirmalkumar</keyname><forenames>A.</forenames></author><author><keyname>Gurusamy</keyname><forenames>G.</forenames></author></authors><title>Design of Current Controller for Two Quadrant DC Motor Drive by Using
  Model Order Reduction Technique</title><categories>cs.OH</categories><comments>8 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Computer Science Volume 7 ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 17-24, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, design of current controller for a two quadrant DC motor drive
was proposed with the help of model order reduction technique. The calculation
of current controller gain with some approximations in the conventional design
process is replaced by proposed model order reduction method. The model order
reduction technique proposed in this paper gives the better controller gain
value for the DC motor drive. The proposed model order reduction method is a
mixed method, where the numerator polynomial of reduced order model is obtained
by using stability equation method and the denominator polynomial is obtained
by using some approximation technique preceded in this paper. The designed
controllers responses were simulated with the help of MATLAB to show the
validity of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1687</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1687</id><created>2010-02-08</created><authors><author><keyname>S</keyname><forenames>Mahendra kumar.</forenames></author><author><keyname>K</keyname><forenames>Senthil Prakash.</forenames></author></authors><title>Wireless Congestion Control Protocol For Multihop Ad Hoc Networks</title><categories>cs.NI</categories><comments>7 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Computer Science Volume 7 ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 25-31, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The traditional TCP congestion control mechanism encounters a number of new
problems and suffers a poor performance when the IEEE 802.11 MAC protocol is
used in multihop ad hoc networks. Many of the problems result from medium
contention at the MAC layer. In this paper, I first illustrate that severe
medium contention and congestion are intimately coupled, and TCP s congestion
control algorithm becomes too coarse in its granularity, causing throughput
instability and excessively long delay. Further, we illustrate TCP s severe
unfairness problem due to the medium contention and the tradeoff between
aggregate throughput and fairness. Then, based on the novel use of channel
busyness ratio, a more accurate metric to characterize the network utilization
and congestion status, I propose a new wireless congestion control protocol
(WCCP) to efficiently and fairly support the transport service in multihop ad
hoc networks. In this protocol, each forwarding node along a traffic flow
exercises the internode and intranode fair resource allocation and determines
the MAC layer feedback accordingly. The endtoend feedback, which is ultimately
determined by the bottleneck node along the flow, is carried back to the source
to control its sending rate. Extensive simulations show that WCCP significantly
outperforms traditional TCP in terms of channel utilization, delay, and
fairness, and eliminates the starvation problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1689</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1689</id><created>2010-02-08</created><authors><author><keyname>Kumar</keyname><forenames>Ponnusamy</forenames></author><author><keyname>Krishnan</keyname><forenames>A.</forenames></author></authors><title>Saturation Throughput Analysis of IEEE 802.11b Wireless Local Area
  Networks under High Interference Considering Capture Effects</title><categories>cs.NI</categories><comments>8 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Computer Science Volume 7 ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 32-39, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed contention based Medium Access Control (MAC) protocols are the
fundamental components for IEEE 802.11 based Wireless Local Area Networks
(WLANs). Contention windows (CW) change dynamically to adapt to the current
contention level, Upon each packet collision, a station doubles its CW to
reduce further collision of packets. IEEE 802.11 Distributed Coordination
Function (DCF) suffers from a common problem in erroneous channel. They cannot
distinguish noise lost packets from collision lost packets. In both situations
a station does not receive its ACK and doubles the CW to reduce further packet
collisions. This increases backoff overhead unnecessarily in addition to the
noise lost packets, reduces the throughput significantly. Furthermore, the
aggregate throughput of a practical WLAN strongly depends on the channel
conditions. In real radio environment, the received signal power at the access
point from a station is subjected to deterministic path loss, shadowing and
fast multipath fading. In this paper, we propose a new saturation throughput
analysis for IEEE 802.11 DCF considering erroneous channel and capture effects.
To alleviate the low performance of IEEE 802.11 DCF, we introduce a mechanism
that greatly outperforms under noisy environment with low network traffic and
compare their performances to the existing standards. We extend the
multidimensional Markov chain model initially proposed by Bianchi(3) to
characterize the behavior of DCF in order to account both real channel
conditions and capture effects, especially in a high interference radio
environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1691</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1691</id><created>2010-02-08</created><authors><author><keyname>Debnath</keyname><forenames>Sumon Kumar</forenames></author><author><keyname>Ahmed</keyname><forenames>Foez</forenames></author><author><keyname>Islam</keyname><forenames>Nayeema</forenames></author></authors><title>Performance Evaluation of Unicast and Broadcast Mobile Ad hoc Network
  Routing Protocols</title><categories>cs.NI cs.PF</categories><comments>7 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Computer Science Volume 7 ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 40-46, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient routing mechanism is a challenging issue for group oriented
computing in Mobile Ad Hoc Networks (MANETs). The ability of MANETs to support
adequate Quality of Service (QoS) for group communication is limited by the
ability of the underlying ad-hoc routing protocols to provide consistent
behavior despite the dynamic properties of mobile computing devices. In MANET
QoS requirements can be quantified in terms of Packet Delivery Ratio (PDR),
Data Latency, Packet Loss Probability, Routing Overhead, Medium Access Control
(MAC) Overhead and Data Throughput etc. This paper presents an in depth study
of one to many and many to many communications in MANETs and provides a
comparative performance evaluation of unicast and broadcast routing protocols.
Dynamic Source Routing protocol (DSR) is used as unicast protocol and BCAST is
used to represent broadcast protocol. The performance differentials are
analyzed using ns2 network simulator varying multicast group size (number of
data senders and data receivers). Both protocols are simulated with identical
traffic loads and mobility models. Simulation result shows that BCAST performs
better than DSR in most cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1692</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1692</id><created>2010-02-08</created><authors><author><keyname>Feng</keyname><forenames>Yaping</forenames></author><author><keyname>Lee</keyname><forenames>Lee Sub</forenames></author></authors><title>The Importance Analysis of Use Case Map with Markov Chains</title><categories>cs.SE</categories><comments>8 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Computer Science Volume 7 ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 55-62, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  UCMs (Use Case Maps) model describes functional requirements and high-level
designs with causal paths superimposed on a structure of components. It could
provide useful resources for software acceptance testing. However until now
statistical testing technologies for large scale software is not considered yet
in UCMs model. Thus if one applies UCMs model to a large scale software using
traditional coverage based exhaustive tasting, then it requires too much costs
for the quality assurance. Therefore this paper proposes an importance analysis
of UCMs model with Markov chains. With this approach not only highly frequently
used usage scenarios but also important objects such as components,
responsibilities, stubs and plugins can also be identified from UCMs
specifications. Therefore careful analysis, design, implementation and
efficient testing could be possible with the importance of scenarios and
objects during the full software life cycle. Consequently product reliability
can be obtained with low costs. This paper includes an importance analysis
method that identifies important scenarios and objects and a case study to
illustrate the applicability of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1718</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1718</id><created>2010-02-08</created><authors><author><keyname>Burkov</keyname><forenames>Andriy</forenames></author><author><keyname>Chaib-draa</keyname><forenames>Brahim</forenames></author></authors><title>An Approximate Subgame-Perfect Equilibrium Computation Technique for
  Repeated Games</title><categories>cs.GT</categories><comments>26 pages, 13 figures, 1 table</comments><acm-class>I.2.11; I.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a technique for approximating, up to any precision, the
set of subgame-perfect equilibria (SPE) in discounted repeated games. The
process starts with a single hypercube approximation of the set of SPE. Then
the initial hypercube is gradually partitioned on to a set of smaller adjacent
hypercubes, while those hypercubes that cannot contain any point belonging to
the set of SPE are simultaneously withdrawn.
  Whether a given hypercube can contain an equilibrium point is verified by an
appropriate mathematical program. Three different formulations of the algorithm
for both approximately computing the set of SPE payoffs and extracting players'
strategies are then proposed: the first two that do not assume the presence of
an external coordination between players, and the third one that assumes a
certain level of coordination during game play for convexifying the set of
continuation payoffs after any repeated game history.
  A special attention is paid to the question of extracting players' strategies
and their representability in form of finite automata, an important feature for
artificial agent systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1727</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1727</id><created>2010-02-08</created><updated>2010-06-21</updated><authors><author><keyname>Li</keyname><forenames>Shujun</forenames></author><author><keyname>Ahmad</keyname><forenames>Junaid Jameel</forenames></author><author><keyname>Saupe</keyname><forenames>Dietmar</forenames></author><author><keyname>Kuo</keyname><forenames>C. -C. Jay</forenames></author></authors><title>An Improved DC Recovery Method from AC Coefficients of DCT-Transformed
  Images</title><categories>cs.MM cs.CV</categories><comments>6 pages, 6 figures, ICIP 2010</comments><acm-class>I.4.2; E.3</acm-class><journal-ref>Proceedings of 2010 17th IEEE International Conference on Image
  Processing (ICIP 2010), pages 2085-2088, IEEE, 2010</journal-ref><doi>10.1109/ICIP.2010.5653467</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the work of Uehara et al. [1], an improved method to recover DC
coefficients from AC coefficients of DCT-transformed images is investigated in
this work, which finds applications in cryptanalysis of selective multimedia
encryption. The proposed under/over-flow rate minimization (FRM) method employs
an optimization process to get a statistically more accurate estimation of
unknown DC coefficients, thus achieving a better recovery performance. It was
shown by experimental results based on 200 test images that the proposed DC
recovery method significantly improves the quality of most recovered images in
terms of the PSNR values and several state-of-the-art objective image quality
assessment (IQA) metrics such as SSIM and MS-SSIM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1744</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1744</id><created>2010-02-08</created><authors><author><keyname>Oneto</keyname><forenames>Anna</forenames></author><author><keyname>Tamone</keyname><forenames>Grazia</forenames></author></authors><title>On some invariants in numerical semigroups and estimations of the order
  bound</title><categories>cs.IT cs.DM math.AC math.IT</categories><msc-class>13F</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study suitable parameters and relations in a numerical semigroup S. When S
is the Weierstrass semigroup at a rational point P of a projective curve C, we
evaluate the Feng-Rao order bound of the associated family of Goppa codes.
Further we conjecture that the order bound is always greater than a fixed value
easily deduced from the parameters of the semigroup: we also prove this
inequality in several cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1751</identifier>
 <datestamp>2010-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1751</id><created>2010-02-09</created><updated>2010-09-07</updated><authors><author><keyname>Ribeiro</keyname><forenames>Bruno</forenames></author><author><keyname>Towsley</keyname><forenames>Don</forenames></author></authors><title>Estimating and Sampling Graphs with Multidimensional Random Walks</title><categories>cs.DS cs.NI</categories><report-no>UMass Amherst Technical Report UM-CS-2010-011 (extended)</report-no><acm-class>G.3</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Estimating characteristics of large graphs via sampling is a vital part of
the study of complex networks. Current sampling methods such as (independent)
random vertex and random walks are useful but have drawbacks. Random vertex
sampling may require too many resources (time, bandwidth, or money). Random
walks, which normally require fewer resources per sample, can suffer from large
estimation errors in the presence of disconnected or loosely connected graphs.
In this work we propose a new $m$-dimensional random walk that uses $m$
dependent random walkers. We show that the proposed sampling method, which we
call Frontier sampling, exhibits all of the nice sampling properties of a
regular random walk. At the same time, our simulations over large real world
graphs show that, in the presence of disconnected or loosely connected
components, Frontier sampling exhibits lower estimation errors than regular
random walks. We also show that Frontier sampling is more suitable than random
vertex sampling to sample the tail of the degree distribution of the graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1773</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1773</id><created>2010-02-08</created><authors><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Cuspidal and Noncuspidal Robot Manipulators</title><categories>cs.RO</categories><proxy>ccsd hal-00454562</proxy><journal-ref>Robotica 25, 6 (2007) 717-724</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article synthezises the most important results on the kinematics of
cuspidal manipulators i.e. nonredundant manipulators that can change posture
without meeting a singularity. The characteristic surfaces, the uniqueness
domains and the regions of feasible paths in the workspace are defined. Then,
several sufficient geometric conditions for a manipulator to be noncuspidal are
enumerated and a general necessary and sufficient condition for a manipulator
to be cuspidal is provided. An explicit DH-parameter-based condition for an
orthogonal manipulator to be cuspidal is derived. The full classification of 3R
orthogonal manipulators is provided and all types of cuspidal and noncuspidal
orthogonal manipulators are enumerated. Finally, some facts about cuspidal and
noncuspidal 6R manipulators are reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1774</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1774</id><created>2010-02-08</created><authors><author><keyname>Innocenti</keyname><forenames>Carlo</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Position Analysis of the RRP-3(SS) Multi-Loop Spatial Structure</title><categories>cs.RO</categories><proxy>ccsd hal-00454563</proxy><journal-ref>Journal of Mechanical Design 128, 1 (2006) 272-278</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents the position analysis of a spatial structure composed of
two platforms mutually connected by one RRP and three SS serial kinematic
chains, where R, P, and S stand for revolute, prismatic, and spherical
kinematic pair respectively. A set of three compatibility equations is laid
down that, following algebraic elimination, results in a 28th-order univariate
algebraic equation, which in turn provides the addressed problem with 28
solutions in the complex domain. Among the applications of the results
presented in this paper is the solution to the forward kinematics of the
Tricept, a well-known in-parallel-actuated spatial manipulator. Numerical
examples show adoption of the proposed method in dealing with two case studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1781</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1781</id><created>2010-02-09</created><updated>2011-06-02</updated><authors><author><keyname>Ardestanizadeh</keyname><forenames>Ehsan</forenames></author><author><keyname>Wigger</keyname><forenames>Michele A.</forenames></author><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author><author><keyname>Javidi</keyname><forenames>Tara</forenames></author></authors><title>Linear Sum Capacity for Gaussian Multiple Access Channels with Feedback</title><categories>cs.IT math.IT</categories><comments>Submitted to Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity region of the N-sender Gaussian multiple access channel with
feedback is not known in general. This paper studies the class of
linear-feedback codes that includes (nonlinear) nonfeedback codes at one
extreme and the linear-feedback codes by Schalkwijk and Kailath, Ozarow, and
Kramer at the other extreme. The linear-feedback sum-capacity C_L(N,P) under
symmetric power constraints P is characterized, the maximum sum-rate achieved
by linear-feedback codes when each sender has the equal block power constraint
P. In particular, it is shown that Kramer's code achieves this linear-feedback
sum-capacity. The proof involves the dependence balance condition introduced by
Hekstra and Willems and extended by Kramer and Gastpar, and the analysis of the
resulting nonconvex optimization problem via a Lagrange dual formulation.
Finally, an observation is presented based on the properties of the conditional
maximal correlation---an extension of the Hirschfeld--Gebelein--Renyi maximal
correlation---which reinforces the conjecture that Kramer's code achieves not
only the linear-feedback sum-capacity, but also the sum-capacity itself (the
maximum sum-rate achieved by arbitrary feedback codes).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1782</identifier>
 <datestamp>2010-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1782</id><created>2010-02-09</created><updated>2010-05-12</updated><authors><author><keyname>Golovin</keyname><forenames>Daniel</forenames></author><author><keyname>Faulkner</keyname><forenames>Matthew</forenames></author><author><keyname>Krause</keyname><forenames>Andreas</forenames></author></authors><title>Online Distributed Sensor Selection</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A key problem in sensor networks is to decide which sensors to query when, in
order to obtain the most useful information (e.g., for performing accurate
prediction), subject to constraints (e.g., on power and bandwidth). In many
applications the utility function is not known a priori, must be learned from
data, and can even change over time. Furthermore for large sensor networks
solving a centralized optimization problem to select sensors is not feasible,
and thus we seek a fully distributed solution. In this paper, we present
Distributed Online Greedy (DOG), an efficient, distributed algorithm for
repeatedly selecting sensors online, only receiving feedback about the utility
of the selected sensors. We prove very strong theoretical no-regret guarantees
that apply whenever the (unknown) utility function satisfies a natural
diminishing returns property called submodularity. Our algorithm has extremely
low communication requirements, and scales well to large sensor deployments. We
extend DOG to allow observation-dependent sensor selection. We empirically
demonstrate the effectiveness of our algorithm on several real-world sensing
tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1796</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1796</id><created>2010-02-09</created><authors><author><keyname>Kolano</keyname><forenames>Paul Z.</forenames></author><author><keyname>Furia</keyname><forenames>Carlo A.</forenames></author><author><keyname>Kemmerer</keyname><forenames>Richard A.</forenames></author><author><keyname>Mandrioli</keyname><forenames>Dino</forenames></author></authors><title>Refinement and Verification of Real-Time Systems</title><categories>cs.LO</categories><comments>59 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses highly general mechanisms for specifying the refinement
of a real-time system as a collection of lower level parallel components that
preserve the timing and functional requirements of the upper level
specification. These mechanisms are discussed in the context of ASTRAL, which
is a formal specification language for real-time systems. Refinement is
accomplished by mapping all of the elements of an upper level specification
into lower level elements that may be split among several parallel components.
In addition, actions that can occur in the upper level are mapped to actions of
components operating at the lower level. This allows several types of
implementation strategies to be specified in a natural way, while the price for
generality (in terms of complexity) is paid only when necessary. The refinement
mechanisms are first illustrated using a simple digital circuit; then, through
a highly complex phone system; finally, design guidelines gleaned from these
specifications are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1828</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1828</id><created>2010-02-09</created><authors><author><keyname>Mir</keyname><forenames>Arnau</forenames></author><author><keyname>Rossello</keyname><forenames>Francesc</forenames></author></authors><title>The median of the distance between two leaves in a phylogenetic tree</title><categories>cs.DM</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish a limit formula for the median of the distance between two
leaves in a fully resolved unrooted phylogenetic tree with n leaves. More
precisely, we prove that this median is equal, in the limit, to the square root
of 4*ln(2)*n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1833</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1833</id><created>2010-02-09</created><authors><author><keyname>L&#xf3;pez-Fraguas</keyname><forenames>F. J.</forenames></author><author><keyname>Rodr&#xed;guez-Hortal&#xe1;</keyname><forenames>J.</forenames></author></authors><title>The Full Abstraction Problem for Higher Order Functional-Logic Programs</title><categories>cs.LO cs.PL</categories><journal-ref>WLPE 2009 Proceedings</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Developing suitable formal semantics can be of great help in the
understanding, design and implementation of a programming language, and act as
a guide for software development tools like analyzers or partial evaluators. In
this sense, full abstraction is a highly desirable property, indicating a
perfect correspondence between the semantics and the observable behavior of
program pieces. In this work we address the question of full abstraction for
the family of modern functional logic languages, in which functions can be
higher order and non-deterministic, and where the semantics adopted for
non-determinism is \emph{call-time choice}. We show that, with respect to
natural notions of \emph{observation}, any semantics based on
\emph{extensional} functions is necessarily unsound; in contrast, we show that
the higher order version of \emph{CRWL}, a well-known existing semantic
framework for functional logic programming, based on an \emph{intensional} view
of functions, turns out to be fully abstract and compositional.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1834</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1834</id><created>2010-02-09</created><authors><author><keyname>Eleryan</keyname><forenames>Ahmed</forenames></author><author><keyname>Elsabagh</keyname><forenames>Mohamed</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author></authors><title>AROMA: Automatic Generation of Radio Maps for Localization Systems</title><categories>cs.NI</categories><comments>14 pages, 17 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  WLAN localization has become an active research field recently. Due to the
wide WLAN deployment, WLAN localization provides ubiquitous coverage and adds
to the value of the wireless network by providing the location of its users
without using any additional hardware. However, WLAN localization systems
usually require constructing a radio map, which is a major barrier of WLAN
localization systems' deployment. The radio map stores information about the
signal strength from different signal strength streams at selected locations in
the site of interest. Typical construction of a radio map involves measurements
and calibrations making it a tedious and time-consuming operation. In this
paper, we present the AROMA system that automatically constructs accurate
active and passive radio maps for both device-based and device-free WLAN
localization systems. AROMA has three main goals: high accuracy, low
computational requirements, and minimum user overhead. To achieve high
accuracy, AROMA uses 3D ray tracing enhanced with the uniform theory of
diffraction (UTD) to model the electric field behavior and the human shadowing
effect. AROMA also automates a number of routine tasks, such as importing
building models and automatic sampling of the area of interest, to reduce the
user's overhead. Finally, AROMA uses a number of optimization techniques to
reduce the computational requirements. We present our system architecture and
describe the details of its different components that allow AROMA to achieve
its goals. We evaluate AROMA in two different testbeds. Our experiments show
that the predicted signal strength differs from the measurements by a maximum
average absolute error of 3.18 dBm achieving a maximum localization error of
2.44m for both the device-based and device-free cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1836</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1836</id><created>2010-02-09</created><authors><author><keyname>Bueno</keyname><forenames>F.</forenames></author><author><keyname>Navas</keyname><forenames>J.</forenames></author><author><keyname>Hermenegildo</keyname><forenames>M.</forenames></author></authors><title>Towards Parameterized Regular Type Inference Using Set Constraints</title><categories>cs.LO cs.PL</categories><journal-ref>WLPE 2009 Proceedings</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method for inferring \emph{parameterized regular types} for
logic programs as solutions for systems of constraints over sets of finite
ground Herbrand terms (set constraint systems). Such parameterized regular
types generalize \emph{parametric} regular types by extending the scope of the
parameters in the type definitions so that such parameters can relate the types
of different predicates. We propose a number of enhancements to the procedure
for solving the constraint systems that improve the precision of the type
descriptions inferred. The resulting algorithm, together with a procedure to
establish a set constraint system from a logic program, yields a program
analysis that infers tighter safe approximations of the success types of the
program than previous comparable work, offering a new and useful efficiency vs.
precision trade-off. This is supported by experimental results, which show the
feasibility of our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1843</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1843</id><created>2010-02-09</created><authors><author><keyname>Haverkort</keyname><forenames>Herman</forenames></author></authors><title>Recursive tilings and space-filling curves with little fragmentation</title><categories>cs.CG</categories><comments>Manuscript accompanying abstract in EuroCG 2010, including full
  proofs, 20 figures, references, discussion etc</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper defines the Arrwwid number of a recursive tiling (or space-filling
curve) as the smallest number w such that any ball Q can be covered by w tiles
(or curve sections) with total volume O(vol(Q)). Recursive tilings and
space-filling curves with low Arrwwid numbers can be applied to optimise disk,
memory or server access patterns when processing sets of points in
d-dimensional space. This paper presents recursive tilings and space-filling
curves with optimal Arrwwid numbers. For d &gt;= 3, we see that regular cube
tilings and space-filling curves cannot have optimal Arrwwid number, and we see
how to construct alternatives with better Arrwwid numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1874</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1874</id><created>2010-02-09</created><authors><author><keyname>Nandeppanavar</keyname><forenames>A. S.</forenames></author><author><keyname>Birje</keyname><forenames>M. N.</forenames></author><author><keyname>Manvi</keyname><forenames>S. S.</forenames></author><author><keyname>Shridhar</keyname></author></authors><title>Mobility Impact on Performance of Mobile Grids</title><categories>cs.NI</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 106-111, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless mobile grids are one of the emerging grid types, which help to pool
the resources of several willing and cooperative mobile devices to resolve a
computationally intensive task. The mobile grids exhibit stronger challenges
like mobility management of devices, providing transparent access to grid
resources, task management and handling of limited resources so that resources
are shared efficiently. Task execution on these devices should not be affected
by their mobility. The proposed work presents performance evaluation of
wireless mobile grid using normal walk mobility model. The normal walk model
represents daily motion of users and the direction of motion is mostly
symmetric in a real life environment, thus it is effective in location updating
of a mobile station and in turn helps task distribution among these available
mobile stations. Some of the performance parameters such as Task Execution
Time, task failure rate, communication overhead on Brokering Server and
Monitoring Cost are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1880</identifier>
 <datestamp>2012-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1880</id><created>2010-02-09</created><updated>2012-02-24</updated><authors><author><keyname>Guillemot</keyname><forenames>Sylvain</forenames></author><author><keyname>Sikora</keyname><forenames>Florian</forenames></author></authors><title>Finding and counting vertex-colored subtrees</title><categories>cs.CC</categories><comments>Conference version in International Symposium on Mathematical
  Foundations of Computer Science (MFCS), Brno : Czech Republic (2010) Journal
  Version in Algorithmica</comments><proxy>ccsd</proxy><doi>10.1007/s00453-011-9600-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problems studied in this article originate from the Graph Motif problem
introduced by Lacroix et al. in the context of biological networks. The problem
is to decide if a vertex-colored graph has a connected subgraph whose colors
equal a given multiset of colors $M$. It is a graph pattern-matching problem
variant, where the structure of the occurrence of the pattern is not of
interest but the only requirement is the connectedness. Using an algebraic
framework recently introduced by Koutis et al., we obtain new FPT algorithms
for Graph Motif and variants, with improved running times. We also obtain
results on the counting versions of this problem, proving that the counting
problem is FPT if M is a set, but becomes W[1]-hard if M is a multiset with two
colors. Finally, we present an experimental evaluation of this approach on real
datasets, showing that its performance compares favorably with existing
software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1881</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1881</id><created>2010-02-09</created><authors><author><keyname>Zhang</keyname><forenames>Linlin</forenames><affiliation>LAHC</affiliation></author><author><keyname>Fresse</keyname><forenames>Virginie</forenames><affiliation>LAHC</affiliation></author><author><keyname>Khalid</keyname><forenames>Mohammed</forenames><affiliation>RCIM</affiliation></author><author><keyname>Houzet</keyname><forenames>Dominique</forenames><affiliation>GIPSA-lab</affiliation></author><author><keyname>Legrand</keyname><forenames>Anne-Claire</forenames><affiliation>LAHC</affiliation></author></authors><title>Evaluation and Design Space Exploration of a Time-Division Multiplexed
  NoC on FPGA for Image Analysis Applications</title><categories>cs.AR</categories><proxy>ccsd hal-00455123</proxy><journal-ref>Eurasip Journal on Embedded Systems 2010 (2010) 542035</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to present an adaptable Fat Tree NoC architecture
for Field Programmable Gate Array (FPGA) designed for image analysis
applications. Traditional NoCs (Network on Chip) are not optimal for dataflow
applications with large amount of data. On the opposite, point to point
communications are designed from the algorithm requirements but they are
expensives in terms of resource and wire. We propose a dedicated communication
architecture for image analysis algorithms. This communication mechanism is a
generic NoC infrastructure dedicated to dataflow image processing applications,
mixing circuit-switching and packet-switching communications. The complete
architecture integrates two dedicated communication architectures and reusable
IP blocks. Communications are based on the NoC concept to support the high
bandwidth required for a large number and type of data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1887</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1887</id><created>2010-02-09</created><updated>2010-12-17</updated><authors><author><keyname>Najman</keyname><forenames>Laurent</forenames></author></authors><title>On the equivalence between hierarchical segmentations and ultrametric
  watersheds</title><categories>cs.DM</categories><comments>19 pages, double-column</comments><proxy>ccsd</proxy><journal-ref>Journal of Mathematical Imaging and Vision 40, 3 (2011) 231-247</journal-ref><doi>10.1007/s10851-011-0259-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study hierarchical segmentation in the framework of edge-weighted graphs.
We define ultrametric watersheds as topological watersheds null on the minima.
We prove that there exists a bijection between the set of ultrametric
watersheds and the set of hierarchical segmentations. We end this paper by
showing how to use the proposed framework in practice in the example of
constrained connectivity; in particular it allows to compute such a hierarchy
following a classical watershed-based morphological scheme, which provides an
efficient algorithm to compute the whole hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1896</identifier>
 <datestamp>2010-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1896</id><created>2010-02-09</created><updated>2010-03-18</updated><authors><author><keyname>Gargiulo</keyname><forenames>F.</forenames></author><author><keyname>Huet</keyname><forenames>S.</forenames></author></authors><title>When group level is different from the population level: an adaptive
  network with the Deffuant model</title><categories>physics.soc-ph cs.MA</categories><comments>7 pages, 5 figures, Proc of 5th Int. Workshop on Emergent
  Intelligence on networked Agents, Toronto 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a model coupling the classical opinion dynamics of the bounded
confidence model, proposed by Deffuant et al., with an adaptive network forming
a community or group structure. At each step, an individual can decide if it
changes groups or interact on its opinion with one of its internal or external
neighbour. If it decides to look at the group level, it changes groups if its
opinion is far from the average of its group from more than a threshold. If it
is the case, it joins the group which has proportionally the closest average
opinion from its. If it decides to interact with one of its neighbour, it
becomes closer in opinion to it when its opinion and the one of the
selected-to-interact neighbour are less distant from the threshold. From the
study of this coupled model, we discover some surprising behaviours compared to
the known behaviour of the Deffuant bounded confidence model(BC): The coupled
model exhibits a total consensus for an threshold value lower than the BC
model; the distribution of sizes of the groups changes: some groups become
larger while other decrease in size, sometimes until containing only one
individual; from the point of view of the groups, the consensus remains for a
large set of threshold values while, looking at the population level, there are
a lot of opinion clusters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1897</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1897</id><created>2010-02-09</created><authors><author><keyname>Chatzidiamantis</keyname><forenames>Nestor D.</forenames></author><author><keyname>Lioumpas</keyname><forenames>Athanasios S.</forenames></author><author><keyname>Karagiannidis</keyname><forenames>George K.</forenames></author><author><keyname>Arnon</keyname><forenames>Shlomi</forenames></author></authors><title>Adaptive Subcarrier PSK Intensity Modulation in Free Space Optical
  Systems</title><categories>cs.NI</categories><comments>Submitted To IEEE Transactions On Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an adaptive transmission technique for free space optical (FSO)
systems, operating in atmospheric turbulence and employing subcarrier phase
shift keying (S-PSK) intensity modulation. Exploiting the constant envelope
characteristics of S-PSK, the proposed technique offers efficient utilization
of the FSO channel capacity by adapting the modulation order of S-PSK,
according to the instantaneous state of turbulence induced fading and a
pre-defined bit error rate (BER) requirement. Novel expressions for the
spectral efficiency and average BER of the proposed adaptive FSO system are
presented and performance investigations under various turbulence conditions
and target BER requirements are carried out. Numerical results indicate that
significant spectral efficiency gains are offered without increasing the
transmitted average optical power or sacrificing BER requirements, in
moderate-to-strong turbulence conditions. Furthermore, the proposed variable
rate transmission technique is applied to multiple input multiple output (MIMO)
FSO systems, providing additional improvement in the achieved spectral
efficiency as the number of the transmit and/or receive apertures increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1916</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1916</id><created>2010-02-09</created><authors><author><keyname>Prabhakaran</keyname><forenames>Vinod</forenames></author><author><keyname>Prabhakaran</keyname><forenames>Manoj</forenames></author></authors><title>Assisted Common Information with Applications to Secure Two-Party
  Computation</title><categories>cs.IT cs.CR math.IT</categories><comments>submitted to IEEE International Symposium on Information Theory 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secure multi-party computation is a central problem in modern cryptography.
An important sub-class of this are problems of the following form: Alice and
Bob desire to produce sample(s) of a pair of jointly distributed random
variables. Each party must learn nothing more about the other party's output
than what its own output reveals. To aid in this, they have available a set up
- correlated random variables whose distribution is different from the desired
distribution - as well as unlimited noiseless communication. In this paper we
present an upperbound on how efficiently a given set up can be used to produce
samples from a desired distribution.
  The key tool we develop is a generalization of the concept of common
information of two dependent random variables [Gacs-Korner, 1973]. Our
generalization - a three-dimensional region - remedies some of the limitations
of the original definition which captured only a limited form of dependence. It
also includes as a special case Wyner's common information [Wyner, 1975]. To
derive the cryptographic bounds, we rely on a monotonicity property of this
region: the region of the &quot;views&quot; of Alice and Bob engaged in any protocol can
only monotonically expand and not shrink. Thus, by comparing the regions for
the target random variables and the given random variables, we obtain our
upperbound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1919</identifier>
 <datestamp>2010-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1919</id><created>2010-02-09</created><updated>2010-03-16</updated><authors><author><keyname>Sinthupoun</keyname><forenames>Somnuk</forenames></author><author><keyname>Sornil</keyname><forenames>Ohm</forenames></author></authors><title>Thai Rhetorical Structure Analysis</title><categories>cs.CL</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 95-105, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rhetorical structure analysis (RSA) explores discourse relations among
elementary discourse units (EDUs) in a text. It is very useful in many text
processing tasks employing relationships among EDUs such as text understanding,
summarization, and question-answering. Thai language with its distinctive
linguistic characteristics requires a unique technique. This article proposes
an approach for Thai rhetorical structure analysis. First, EDUs are segmented
by two hidden Markov models derived from syntactic rules. A rhetorical
structure tree is constructed from a clustering technique with its similarity
measure derived from Thai semantic rules. Then, a decision tree whose features
derived from the semantic rules is used to determine discourse relations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1928</identifier>
 <datestamp>2010-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1928</id><created>2010-02-09</created><updated>2010-04-23</updated><authors><author><keyname>Fici</keyname><forenames>Gabriele</forenames></author><author><keyname>Pribavkina</keyname><forenames>Elena V.</forenames></author><author><keyname>Sakarovitch</keyname><forenames>Jacques</forenames></author></authors><title>On the Minimal Uncompletable Word Problem</title><categories>cs.FL</categories><comments>5 pages; added references, corrected typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let S be a finite set of words over an alphabet Sigma. The set S is said to
be complete if every word w over the alphabet Sigma is a factor of some element
of S*, i.e. w belongs to Fact(S*). Otherwise if S is not complete, we are
interested in finding bounds on the minimal length of words in Sigma* which are
not elements of Fact(S*) in terms of the maximal length of words in S.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1936</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1936</id><created>2010-02-09</created><authors><author><keyname>Chen</keyname><forenames>Chaomei</forenames></author><author><keyname>Zhang</keyname><forenames>Jian</forenames></author><author><keyname>Vogeley</keyname><forenames>Michael S.</forenames></author></authors><title>Making Sense of the Evolution of a Scientific Domain: A Visual Analytic
  Study of the Sloan Digital Sky Survey Research</title><categories>cs.GL</categories><comments>15 pages, 12 figures, 4 tables</comments><doi>10.1007/s11192-009-0123-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new visual analytic approach to the study of scientific
discoveries and knowledge diffusion. Our approach enhances contemporary
co-citation network analysis by enabling analysts to identify co-citation
clusters of cited references intuitively, synthesize thematic contexts in which
these clusters are cited, and trace how research focus evolves over time. The
new approach integrates and streamlines a few previously isolated techniques
such as spectral clustering and feature selection algorithms. The integrative
procedure is expected to empower and strengthen analytical and sense making
capabilities of scientists, learners, and researchers to understand the
dynamics of the evolution of scientific domains in a wide range of scientific
fields, science studies, and science policy evaluation and planning. We
demonstrate the potential of our approach through a visual analysis of the
evolution of astronomical research associated with the Sloan Digital Sky Survey
(SDSS) using bibliographic data between 1994 and 2008. In addition, we also
demonstrate that the approach can be consistently applied to a set of
heterogeneous data sources such as e-prints on arXiv, publications on ADS, and
NSF awards related to the same topic of SDSS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1937</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1937</id><created>2010-02-09</created><authors><author><keyname>Fasy</keyname><forenames>Brittany Terese</forenames></author></authors><title>Persistence Diagrams and the Heat Equation Homotopy</title><categories>cs.CG</categories><comments>27 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Persistence homology is a tool used to measure topological features that are
present in data sets and functions. Persistence pairs births and deaths of
these features as we iterate through the sublevel sets of the data or function
of interest. I am concerned with using persistence to characterize the
difference between two functions f, g : M -&gt; R, where M is a topological space.
Furthermore, I formulate a homotopy from g to f by applying the heat equation
to the difference function g-f. By stacking the persistence diagrams associated
with this homotopy, we create a vineyard of curves that connect the points in
the diagram for f with the points in the diagram for g. I look at the diagrams
where M is a square, a sphere, a torus, and a Klein bottle. Looking at these
four topologies, we notice trends (and differences) as the persistence diagrams
change with respect to time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1950</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1950</id><created>2010-02-09</created><authors><author><keyname>Syed</keyname><affiliation>Shawon</affiliation></author><author><keyname>Rahman</keyname><forenames>M.</forenames></author><author><keyname>Donahue</keyname><forenames>Shannon E.</forenames></author></authors><title>Convergence of Corporate and Information Security</title><categories>cs.CR</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 63-68, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As physical and information security boundaries have become increasingly
blurry many organizations are experiencing challenges with how to effectively
and efficiently manage security within the corporate. There is no current
standard or best practice offered by the security community regarding
convergence; however many organizations such as the Alliance for Enterprise
Security Risk Management (AESRM) offer some excellent suggestions for
integrating a converged security program. This paper reports on how
organizations have traditionally managed asset protection, why that is changing
and how to establish convergence to optimize security value to the business
within an enterprise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1951</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1951</id><created>2010-02-09</created><authors><author><keyname>H.</keyname><forenames>Mr. Kondekar V.</forenames></author><author><keyname>S.</keyname><forenames>Mr. Kolkure V.</forenames></author><author><keyname>N</keyname><forenames>Prof. Kore S.</forenames></author></authors><title>Image Retrieval Techniques based on Image Features, A State of Art
  approach for CBIR</title><categories>cs.MM cs.IR</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 69-76, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this Paper is to describe our research on different feature
extraction and matching techniques in designing a Content Based Image Retrieval
(CBIR) system. Due to the enormous increase in image database sizes, as well as
its vast deployment in various applications, the need for CBIR development
arose. Firstly, this paper outlines a description of the primitive feature
extraction techniques like, texture, colour, and shape. Once these features are
extracted and used as the basis for a similarity check between images, the
various matching techniques are discussed. Furthermore, the results of its
performance are illustrated by a detailed example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1953</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1953</id><created>2010-02-09</created><authors><author><keyname>Shashikumar</keyname><forenames>Dr. R.</forenames></author><author><keyname>Kumar</keyname><forenames>C. N. Vijay</forenames></author><author><keyname>Nagendrakumar</keyname><forenames>M.</forenames></author><author><keyname>Hemanthkumar</keyname><forenames>C. S.</forenames></author></authors><title>Ahb Compatible DDR Sdram Controller Ip Core for Arm Based Soc</title><categories>cs.AR cs.PF</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 77-85, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  DDR SDRAM is similar in function to the regular SDRAM but doubles the
bandwidth of the memory by transferring data on both edges of the clock cycles.
DDR SDRAM most commonly used in various embedded application like networking,
image or video processing, Laptops ete. Now a days many applications needs more
and more cheap and fast memory. Especially in the field of signal processing,
requires significant amount of memory. The most used type of dynamic memory for
that purpose is DDR SDRAM. For FPGA design the IC manufacturers are providing
commercial memory controller IP cores working only on their products. Main
disadvantage is the lack of memory access optimization for random memory access
patterns. The data path part of those controllers can be used free of charge.
This work propose an architecture of a DDR SDRAM controller, which takes
advantage of those available and well tested data paths and can be used for any
FPGA device or ASIC design.(5). In most of the SOC design, DDR SDRAM is
commonly used. ARM processor is widely used in SOCs; so that we focused to
implement AHB compatible DDR SDRAM controller suitable for ARM based SOC
design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1954</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1954</id><created>2010-02-09</created><authors><author><keyname>Zerrouki</keyname><forenames>Hadj</forenames></author><author><keyname>Feham</keyname><forenames>Mohamed</forenames></author></authors><title>High Throughput of WiMAX MIMO OFDM Including Adaptive Modulation and
  Coding</title><categories>cs.NI</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 86-91, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  WiMAX technology is based on the IEEE 802.16 specification of which IEEE
802.16-2004 and 802.16e amendment are Physical (PHY) layer specifications. IEEE
802.16-2004 currently supports several multiple-antenna options including
Space-Time Codes (STC), Multiple-Input Multiple-Output (MIMO) antenna systems
and Adaptive Antenna Systems (AAS). The most recent WiMAX standard (802.16e)
supports broadband applications to mobile terminals and laptops. Using Adaptive
Modulation and Coding (AMC) we analyze the performance of OFDM physical layer
in WiMAX based on the simulation results of Bit Error Rate (BER), and data
throughput. The performance analysis of OFDM PHY is done. In this paper, an
extension to the basic SISO mode, a number of 2 by 2 MIMO extensions are
analysed under different combinations of digital modulation (QPSK, 16QAM and
64QAM) and Convolutional Code (CC) with half, two-third and three quarter rated
codes. The intent of this paper is to provide an idea of the benefits of
multiple antenna systems over single antenna systems in WiMAX type deployments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1955</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1955</id><created>2010-02-09</created><authors><author><keyname>Guatam</keyname><forenames>K. K.</forenames></author><author><keyname>Rai</keyname><forenames>Anurag</forenames></author></authors><title>Performance Modeling and Evaluation of Traffic management for Mobile
  Networks by SINR Prediction</title><categories>cs.NI</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 92-94, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the recent years a considerable amount of effort has been devoted
towards the performance evaluation and prediction of Mobile Networks.
Performance modeling and evaluation of mobile networks are very important in
view of their ever expending usage and the multiplicity of their component
parts together with the complexity of their functioning. The present paper
addresses current issues in traffic management and congestion control by
(signal to interference plus noise ratio) SINR prediction congestion control,
routing and optimization of cellular mobile networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.1985</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.1985</id><created>2010-02-09</created><authors><author><keyname>Chen</keyname><forenames>Chaomei</forenames></author><author><keyname>Ibekwe-SanJuan</keyname><forenames>Fidelia</forenames></author><author><keyname>Hou</keyname><forenames>Jianhua</forenames></author></authors><title>The Structure and Dynamics of Co-Citation Clusters: A
  Multiple-Perspective Co-Citation Analysis</title><categories>cs.CY</categories><comments>33 pages, 11 figures, 10 tables. To appear in the Journal of the
  American Society for Information Science and Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A multiple-perspective co-citation analysis method is introduced for
characterizing and interpreting the structure and dynamics of co-citation
clusters. The method facilitates analytic and sense making tasks by integrating
network visualization, spectral clustering, automatic cluster labeling, and
text summarization. Co-citation networks are decomposed into co-citation
clusters. The interpretation of these clusters is augmented by automatic
cluster labeling and summarization. The method focuses on the interrelations
between a co-citation cluster's members and their citers. The generic method is
applied to a three-part analysis of the field of Information Science as defined
by 12 journals published between 1996 and 2008: 1) a comparative author
co-citation analysis (ACA), 2) a progressive ACA of a time series of
co-citation networks, and 3) a progressive document co-citation analysis (DCA).
Results show that the multiple-perspective method increases the
interpretability and accountability of both ACA and DCA networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2012</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2012</id><created>2010-02-09</created><authors><author><keyname>Alves</keyname><forenames>Nuno</forenames></author></authors><title>Implementing Genetic Algorithms on Arduino Micro-Controllers</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since their conception in 1975, Genetic Algorithms have been an extremely
popular approach to find exact or approximate solutions to optimization and
search problems. Over the last years there has been an enhanced interest in the
field with related techniques, such as grammatical evolution, being developed.
Unfortunately, work on developing genetic optimizations for low-end embedded
architectures hasn't embraced the same enthusiasm. This short paper tackles
that situation by demonstrating how genetic algorithms can be implemented in
Arduino Duemilanove, a 16 MHz open-source micro-controller, with limited
computation power and storage resources. As part of this short paper, the
libraries used in this implementation are released into the public domain under
a GPL license.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2034</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2034</id><created>2010-02-10</created><authors><author><keyname>Roche</keyname><forenames>Christophe</forenames><affiliation>LISTIC</affiliation></author></authors><title>Dire n'est pas concevoir</title><categories>cs.AI cs.CL</categories><comments>12 pages</comments><proxy>ccsd hal-00455253</proxy><journal-ref>Ing\'enierie des Connaissances, Grenoble : France (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The conceptual modelling built from text is rarely an ontology. As a matter
of fact, such a conceptualization is corpus-dependent and does not offer the
main properties we expect from ontology. Furthermore, ontology extracted from
text in general does not match ontology defined by expert using a formal
language. It is not surprising since ontology is an extra-linguistic
conceptualization whereas knowledge extracted from text is the concern of
textual linguistics. Incompleteness of text and using rhetorical figures, like
ellipsis, modify the perception of the conceptualization we may have.
Ontological knowledge, which is necessary for text understanding, is not in
general embedded into documents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2044</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2044</id><created>2010-02-10</created><authors><author><keyname>Rubinstein</keyname><forenames>Benjamin I. P.</forenames></author><author><keyname>Simma</keyname><forenames>Aleksandr</forenames></author></authors><title>On the Stability of Empirical Risk Minimization in the Presence of
  Multiple Risk Minimizers</title><categories>cs.LG</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently Kutin and Niyogi investigated several notions of algorithmic
stability--a property of a learning map conceptually similar to
continuity--showing that training-stability is sufficient for consistency of
Empirical Risk Minimization while distribution-free CV-stability is necessary
and sufficient for having finite VC-dimension. This paper concerns a phase
transition in the training stability of ERM, conjectured by the same authors.
Kutin and Niyogi proved that ERM on finite hypothesis spaces containing a
unique risk minimizer has training stability that scales exponentially with
sample size, and conjectured that the existence of multiple risk minimizers
prevents even super-quadratic convergence. We prove this result for the
strictly weaker notion of CV-stability, positively resolving the conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2050</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2050</id><created>2010-02-10</created><authors><author><keyname>Fan</keyname><forenames>Mingyu</forenames></author><author><keyname>Gu</keyname><forenames>Nannan</forenames></author><author><keyname>Qiao</keyname><forenames>Hong</forenames></author><author><keyname>Zhang</keyname><forenames>Bo</forenames></author></authors><title>Intrinsic dimension estimation of data by principal component analysis</title><categories>cs.CV cs.LG</categories><comments>8 pages, submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimating intrinsic dimensionality of data is a classic problem in pattern
recognition and statistics. Principal Component Analysis (PCA) is a powerful
tool in discovering dimensionality of data sets with a linear structure; it,
however, becomes ineffective when data have a nonlinear structure. In this
paper, we propose a new PCA-based method to estimate intrinsic dimension of
data with nonlinear structures. Our method works by first finding a minimal
cover of the data set, then performing PCA locally on each subset in the cover
and finally giving the estimation result by checking up the data variance on
all small neighborhood regions. The proposed method utilizes the whole data set
to estimate its intrinsic dimension and is convenient for incremental learning.
In addition, our new PCA procedure can filter out noise in data and converge to
a stable estimation with the neighborhood region size increasing. Experiments
on synthetic and real world data sets show effectiveness of the proposed
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2084</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2084</id><created>2010-02-10</created><authors><author><keyname>Gamzu</keyname><forenames>Iftah</forenames></author><author><keyname>Segev</keyname><forenames>Danny</forenames></author></authors><title>A Sublogarithmic Approximation for Highway and Tollbooth Pricing</title><categories>cs.DS cs.GT</categories><comments>14 pages, 3 figure</comments><acm-class>F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An instance of the tollbooth problem consists of an undirected network and a
collection of single-minded customers, each of which is interested in
purchasing a fixed path subject to an individual budget constraint. The
objective is to assign a per-unit price to each edge in a way that maximizes
the collective revenue obtained from all customers. The revenue generated by
any customer is equal to the overall price of the edges in her desired path,
when this cost falls within her budget; otherwise, that customer will not
purchase any edge.
  Our main result is a deterministic algorithm for the tollbooth problem on
trees whose approximation ratio is O(log m / log log m), where m denotes the
number of edges in the underlying graph. This finding improves on the currently
best performance guarantees for trees, due to Elbassioni et al. (SAGT '09), as
well as for paths (commonly known as the highway problem), due to Balcan and
Blum (EC '06). An additional interesting consequence is a computational
separation between tollbooth pricing on trees and the original prototype
problem of single-minded unlimited supply pricing, under a plausible hardness
hypothesis due to Demaine et al. (SODA '06).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2134</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2134</id><created>2010-02-10</created><authors><author><keyname>Nayak</keyname><forenames>S. K.</forenames></author><author><keyname>Thorat</keyname><forenames>S. B.</forenames></author><author><keyname>Kalyankar</keyname><forenames>N. V.</forenames></author></authors><title>Reaching the Unreached A Role of ICT in Sustainable Rural Development</title><categories>cs.CY</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 220-224, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have seen in last few decades that the progress of information technology
with leaps and bounds, which have completely changed the way of life in the
developed nations. While internet has changed the established working practice
and opened new vistas and provided a platform to connect, this gives the
opportunity for collaborative work space that goes beyond the global boundary.
ICT promises a fundamental change in all aspects of our lives, including
knowledge dissemination, social interaction, economic and business practices,
political engagement, media, education, health, leisure and
entertainment...This paper introduces the application of ICT for rural
development. The paper aims at improving the delivery of information to rural
masses such as, technology information, marketing information, and information
advice. This paper focuses digital divide and poverty eradication, good
governance and the significance of internet for rural development. The paper
concludes that ICTs offer the developing country, the opportunity to look ahead
several stages of rural development by the use of internet. Effective use of
ICT can demolish geographical boundaries and can bring rural communities closer
to global economic systems and be of meaningful help to the underprivileged.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2147</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2147</id><created>2010-02-10</created><authors><author><keyname>Grandoni</keyname><forenames>Fabrizio</forenames></author><author><keyname>Zenklusen</keyname><forenames>Rico</forenames></author></authors><title>Optimization with More than One Budget</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A natural way to deal with multiple, partially conflicting objectives is
turning all the objectives but one into budget constraints. Some classical
polynomial-time optimization problems, such as spanning tree and forest,
shortest path, (perfect) matching, independent set (basis) in a matroid or in
the intersection of two matroids, become NP-hard even with one budget
constraint. Still, for most of these problems deterministic and randomized
polynomial-time approximation schemes are known. In the case of two or more
budgets, typically only multi-criteria approximation schemes are available,
which return slightly infeasible solutions. Not much is known however for the
case of strict budget constraints: filling this gap is the main goal of this
paper.
  We show that shortest path, perfect matching, and spanning tree (and hence
matroid basis and matroid intersection basis) are inapproximable already with
two budget constraints. For the remaining problems, whose set of solutions
forms an independence system, we present deterministic and randomized
polynomial-time approximation schemes for a constant number k of budget
constraints. Our results are based on a variety of techniques:
  1. We present a simple and powerful mechanism to transform multi-criteria
approximation schemes into pure approximation schemes.
  2. We show that points in low dimensional faces of any matroid polytope are
almost integral, an interesting result on its own. This gives a deterministic
approximation scheme for k-budgeted matroid independent set.
  3. We present a deterministic approximation scheme for 2-budgeted matching.
The backbone of this result is a purely topological property of curves in R^2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2164</identifier>
 <datestamp>2012-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2164</id><created>2010-02-10</created><authors><author><keyname>Yazdani</keyname><forenames>Raman</forenames></author><author><keyname>Ardakani</keyname><forenames>Masoud</forenames></author></authors><title>Efficient LLR Calculation for Non-Binary Modulations over Fading
  Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Communications</comments><doi>10.1109/TCOMM.2011.022811.090261</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Log-likelihood ratio (LLR) computation for non-binary modulations over fading
channels is complicated. A measure of LLR accuracy on asymmetric binary
channels is introduced to facilitate good LLR approximations for non-binary
modulations. Considering piecewise linear LLR approximations, we prove
convexity of optimizing the coefficients according to this measure. For the
optimized approximate LLRs, we report negligible performance losses compared to
true LLRs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2166</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2166</id><created>2010-02-10</created><authors><author><keyname>Poinsot</keyname><forenames>Laurent</forenames><affiliation>LIPN</affiliation></author><author><keyname>Duchamp</keyname><forenames>G&#xe9;rard</forenames><affiliation>LIPN</affiliation></author><author><keyname>Tollu</keyname><forenames>Christophe</forenames><affiliation>LIPN</affiliation></author></authors><title>Partial monoids: associativity and confluence</title><categories>cs.DM</categories><proxy>ccsd hal-00455588</proxy><journal-ref>Journal of Pure and Applied Mathematics 3, 2 (2010) 265-285</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A partial monoid $P$ is a set with a partial multiplication $\times$ (and
total identity $1_P$) which satisfies some associativity axiom. The partial
monoid $P$ may be embedded in a free monoid $P^*$ and the product $\star$ is
simulated by a string rewriting system on $P^*$ that consists in evaluating the
concatenation of two letters as a product in $P$, when it is defined, and a
letter $1_P$ as the empty word $\epsilon$. In this paper we study the profound
relations between confluence for such a system and associativity of the
multiplication. Moreover we develop a reduction strategy to ensure confluence
and which allows us to define a multiplication on normal forms associative up
to a given congruence of $P^*$. Finally we show that this operation is
associative if, and only if, the rewriting system under consideration is
confluent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2171</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2171</id><created>2010-02-10</created><authors><author><keyname>Wiesinger</keyname><forenames>J.</forenames></author><author><keyname>Sornette</keyname><forenames>D.</forenames></author><author><keyname>Satinover</keyname><forenames>J.</forenames></author></authors><title>Reverse Engineering Financial Markets with Majority and Minority Games
  using Genetic Algorithms</title><categories>q-fin.TR cs.LG cs.MA</categories><comments>14 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using virtual stock markets with artificial interacting software investors,
aka agent-based models (ABMs), we present a method to reverse engineer
real-world financial time series. We model financial markets as made of a large
number of interacting boundedly rational agents. By optimizing the similarity
between the actual data and that generated by the reconstructed virtual stock
market, we obtain parameters and strategies, which reveal some of the inner
workings of the target stock market. We validate our approach by out-of-sample
predictions of directional moves of the Nasdaq Composite Index.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2182</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2182</id><created>2010-02-10</created><authors><author><keyname>Balakumaran</keyname><forenames>T.</forenames></author><author><keyname>Vennila</keyname><forenames>I. L. A.</forenames></author><author><keyname>Shankar</keyname><forenames>C. Gowri</forenames></author></authors><title>Detection of Microcalcification in Mammograms Using Wavelet Transform
  and Fuzzy Shell Clustering</title><categories>cs.CV</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 121-125, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Microcalcifications in mammogram have been mainly targeted as a reliable
earliest sign of breast cancer and their early detection is vital to improve
its prognosis. Since their size is very small and may be easily overlooked by
the examining radiologist, computer-based detection output can assist the
radiologist to improve the diagnostic accuracy. In this paper, we have proposed
an algorithm for detecting microcalcification in mammogram. The proposed
microcalcification detection algorithm involves mammogram quality enhancement
using multirresolution analysis based on the dyadic wavelet transform and
microcalcification detection by fuzzy shell clustering. It may be possible to
detect nodular components such as microcalcification accurately by introducing
shape information. The effectiveness of the proposed algorithm for
microcalcification detection is confirmed by experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2184</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2184</id><created>2010-02-10</created><authors><author><keyname>Ashok</keyname><forenames>V.</forenames></author><author><keyname>Balakumaran</keyname><forenames>T.</forenames></author><author><keyname>Gowrishankar</keyname><forenames>C.</forenames></author><author><keyname>Vennila</keyname><forenames>I. L. A.</forenames></author><author><keyname>kumar</keyname><forenames>A. Nirmal</forenames></author></authors><title>The Fast Haar Wavelet Transform for Signal &amp; Image Processing</title><categories>cs.MM cs.CV</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 126-130, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method for the design of Fast Haar wavelet for signal processing and image
processing has been proposed. In the proposed work, the analysis bank and
synthesis bank of Haar wavelet is modified by using polyphase structure.
Finally, the Fast Haar wavelet was designed and it satisfies alias free and
perfect reconstruction condition. Computational time and computational
complexity is reduced in Fast Haar wavelet transform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2186</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2186</id><created>2010-02-10</created><authors><author><keyname>Guatam</keyname><forenames>K. K.</forenames></author><author><keyname>Rai</keyname><forenames>Anurag</forenames></author></authors><title>A Survivability Strategy in Route Optimization Mobile Network by Memetic
  Algorithm</title><categories>cs.NI</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 131-134, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capability to provide network service even under a significant network
system element disruption is the backbone for the survival of route optimize of
mobile network Technology in today s world. Keeping this view in mind, the
present paper highlights a new method based on memetic algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2187</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2187</id><created>2010-02-10</created><authors><author><keyname>Alim</keyname><forenames>M. A.</forenames></author><author><keyname>Rahman</keyname><forenames>M. M.</forenames></author><author><keyname>Hossain</keyname><forenames>M. M.</forenames></author><author><keyname>Nahid</keyname><forenames>A. Al</forenames></author></authors><title>Analysis of Large Scale Propagation Models for Mobile Communications in
  Urban Area</title><categories>cs.NI</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 135-139, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel properties influence the development of wireless communication
systems. Unlike wired channels that are stationary and predictable, radio
channels are extremely random and dont offer easy analysis. A Radio Propagation
Model (RPM), also known as the Radio Wave Propagation Model (RWPM), is an
empirical mathematical formulation for the characterization of radio wave
propagation as a function of frequency. In mobile radio systems, path loss
models are necessary for proper planning, interference estimations, frequency
assignments and cell parameters which are the basic for network planning
process as well as Location Based Services (LBS) techniques. Propagation models
that predict the mean signal strength for an arbitrary transmitter receiver (T
R) separation distance which is useful in estimating the radio coverage area of
a transmitter are called large scale propagation models, since they
characterize signal strength over large TR separation distances. In this paper,
the large scale propagation performance of Okumura, Hata, and Lee models has
been compared varying Mobile Station (MS) antenna height, Transmitter Receiver
(TR) distance and Base Station (BS) antenna height, considering the system to
operate at 900 MHz. Through the MATLAB simulation it is turned out that the
Okumura model shows the better performance than that of the other large scale
propagation models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2189</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2189</id><created>2010-02-10</created><authors><author><keyname>Ahmed</keyname><forenames>Foez</forenames></author><author><keyname>Pradhan</keyname><forenames>Sateesh Kumar</forenames></author><author><keyname>Islam</keyname><forenames>Nayeema</forenames></author><author><keyname>Debnath</keyname><forenames>Sumon Kumar</forenames></author></authors><title>Performance Evaluation of TCP over Mobile Ad hoc Networks</title><categories>cs.NI</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 140-146, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the proliferation of mobile computing devices, the demand for continuous
network connectivity regardless of physical location has spurred interest in
the use of mobile ad hoc networks. Since Transmission Control Protocol (TCP) is
the standard network protocol for communication in the internet, any wireless
network with Internet service need to be compatible with TCP. TCP is tuned to
perform well in traditional wired networks, where packet losses occur mostly
because of congestion. However, TCP connections in Ad-hoc mobile networks are
plagued by problems such as high bit error rates, frequent route changes,
multipath routing and temporary network partitions. The throughput of TCP over
such connection is not satisfactory, because TCP misinterprets the packet loss
or delay as congestion and invokes congestion control and avoidance algorithm.
In this research, the performance of TCP in Adhoc mobile network with high Bit
Error rate (BER) and mobility is studied and investigated. Simulation model is
implemented and experiments are performed using the Network Simulatior 2 (NS2).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2191</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2191</id><created>2010-02-10</created><authors><author><keyname>Sumathi</keyname><forenames>S.</forenames></author><author><keyname>Srivatsa</keyname><forenames>S. K.</forenames></author><author><keyname>Maheswari</keyname><forenames>M. Uma</forenames></author></authors><title>Vision Based Game Development Using Human Computer Interaction</title><categories>cs.HC cs.CV cs.MM</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 147-153, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Human Computer Interface (HCI) System for playing games is designed here
for more natural communication with the machines. The system presented here is
a vision-based system for detection of long voluntary eye blinks and
interpretation of blink patterns for communication between man and machine.
This system replaces the mouse with the human face as a new way to interact
with the computer. Facial features (nose tip and eyes) are detected and tracked
in realtime to use their actions as mouse events. The coordinates and movement
of the nose tip in the live video feed are translated to become the coordinates
and movement of the mouse pointer on the application. The left or right eye
blinks fire left or right mouse click events. The system works with inexpensive
USB cameras and runs at a frame rate of 30 frames per second.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2193</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2193</id><created>2010-02-10</created><authors><author><keyname>Amr</keyname><forenames>Ismail I.</forenames></author><author><keyname>Amin</keyname><forenames>Mohamed</forenames></author><author><keyname>Kafrawy</keyname><forenames>Passent El</forenames></author><author><keyname>Sauber</keyname><forenames>Amr M.</forenames></author></authors><title>Using Statistical Moment Invariants and Entropy in Image Retrieval</title><categories>cs.MM cs.IR</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 160-164, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although content-based image retrieval (CBIR) is not a new subject, it keeps
attracting more and more attention, as the amount of images grow tremendously
due to internet, inexpensive hardware and automation of image acquisition. One
of the applications of CBIR is fetching images from a database. This paper
presents a new method for automatic image retrieval using moment invariants and
image entropy, our technique could be used to find semi or perfect matches
based on query by example manner, experimental results demonstrate that the
purposed technique is scalable and efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2194</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2194</id><created>2010-02-10</created><authors><author><keyname>Nandi</keyname><forenames>Bhaskar</forenames></author><author><keyname>Barman</keyname><forenames>Subhabrata</forenames></author><author><keyname>Paul</keyname><forenames>Soumen</forenames></author></authors><title>Genetic Algorithm Based Optimization of Clustering in Ad Hoc Networks</title><categories>cs.NI</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 165-169, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we have to concentrate on implementation of Weighted
Clustering Algorithm with the help of Genetic Algorithm (GA).Here we have
developed new algorithm for the implementation of GA-based approach with the
help of Weighted Clustering Algorithm (WCA) (4). ClusterHead chosen is a
important thing for clustering in adhoc networks. So, we have shown the
optimization technique for the minimization of ClusterHeads(CH) based on some
parameter such as degree difference, Battery power (Pv), degree of mobility,
and sum of the distances of a node in adhoc networks. ClusterHeads selection of
adhoc networks is an important thing for clustering. Here, we have discussed
the performance comparison between deterministic approach and GA based
approach. In this performance comparison, we have seen that GA does not always
give the good result compare to deterministic WCA algorithm. Here we have seen
connectivity (connectivity can be measured by the probability that a node is
reachable to any other node.) is better than the deterministic WCA algorithm
(4).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2195</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2195</id><created>2010-02-10</created><authors><author><keyname>Narmadha</keyname><forenames>S.</forenames></author><author><keyname>Selladurai</keyname><forenames>Dr. V.</forenames></author><author><keyname>Sathish</keyname><forenames>G.</forenames></author></authors><title>Multi Product Inventory Optimization using Uniform Crossover Genetic
  Algorithm</title><categories>cs.NE</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 170-179, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inventory management is considered to be an important field in Supply Chain
Management because the cost of inventories in a supply chain accounts for about
30 percent of the value of the product. The service provided to the customer
eventually gets enhanced once the efficient and effective management of
inventory is carried out all through the supply chain. The precise estimation
of optimal inventory is essential since shortage of inventory yields to lost
sales, while excess of inventory may result in pointless storage costs. Thus
the determination of the inventory to be held at various levels in a supply
chain becomes inevitable so as to ensure minimal cost for the supply chain. The
minimization of the total supply chain cost can only be achieved when
optimization of the base stock level is carried out at each member of the
supply chain. This paper deals with the problem of determination of base stock
levels in a ten member serial supply chain with multiple products produced by
factories using Uniform Crossover Genetic Algorithms. The complexity of the
problem increases when more distribution centers and agents and multiple
products were involved. These considerations leading to very complex inventory
management process has been resolved in this work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2196</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2196</id><created>2010-02-10</created><authors><author><keyname>Narmadha</keyname><forenames>S.</forenames></author><author><keyname>Selladurai</keyname><forenames>Dr. V.</forenames></author><author><keyname>Sathish</keyname><forenames>G.</forenames></author></authors><title>Efficient Inventory Optimization of Multi Product, Multiple Suppliers
  with Lead Time using PSO</title><categories>cs.NE</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 180-189, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With information revolution, increased globalization and competition, supply
chain has become longer and more complicated than ever before. These
developments bring supply chain management to the forefront of the managements
attention. Inventories are very important in a supply chain. The total
investment in inventories is enormous, and the management of inventory is
crucial to avoid shortages or delivery delays for the customers and serious
drain on a companys financial resources. The supply chain cost increases
because of the influence of lead times for supplying the stocks as well as the
raw materials. Practically, the lead times will not be same through out all the
periods. Maintaining abundant stocks in order to avoid the impact of high lead
time increases the holding cost. Similarly, maintaining fewer stocks because of
ballpark lead time may lead to shortage of stocks. This also happens in the
case of lead time involved in supplying raw materials. A better optimization
methodology that utilizes the Particle Swarm Optimization algorithm, one of the
best optimization algorithms, is proposed to overcome the impasse in
maintaining the optimal stock levels in each member of the supply chain. Taking
into account the stock levels thus obtained from the proposed methodology, an
appropriate stock levels to be maintained in the approaching periods that will
minimize the supply chain inventory cost can be arrived at.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2197</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2197</id><created>2010-02-10</created><authors><author><keyname>Jeevarathinam</keyname><forenames>Mrs. R.</forenames></author><author><keyname>Thanamani</keyname><forenames>Dr. Antony Selvadoss</forenames></author></authors><title>Test Case Generation using Mutation Operators and Fault Classification</title><categories>cs.SE</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 190-195, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software testing is the important phase of software development process. But,
this phase can be easily missed by software developers because of their limited
time to complete the project. Since, software developers finish their software
nearer to the delivery time; they dont get enough time to test their program by
creating effective test cases. . One of the major difficulties in software
testing is the generation of test cases that satisfy the given adequacy
criterion Moreover, creating manual test cases is a tedious work for software
developers in the final rush hours. A new approach which generates test cases
can help the software developers to create test cases from software
specifications in early stage of software development (before coding) and as
well as from program execution traces from after software development (after
coding). Heuristic techniques can be applied for creating quality test cases.
Mutation testing is a technique for testing software units that has great
potential for improving the quality of testing, and to assure the high
reliability of software. In this paper, a mutation testing based test cases
generation technique has been proposed to generate test cases from program
execution trace, so that the test cases can be generated after coding. The
paper details about the mutation testing implementation to generate test cases.
The proposed algorithm has been demonstrated for an example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2199</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2199</id><created>2010-02-10</created><authors><author><keyname>Angayarkkani</keyname><forenames>K.</forenames></author><author><keyname>Radhakrishnan</keyname><forenames>N.</forenames></author></authors><title>An Intelligent System For Effective Forest Fire Detection Using Spatial
  Data</title><categories>cs.OH</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 202-208, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The explosive growth of spatial data and extensive utilization of spatial
databases emphasize the necessity for the automated discovery of spatial
knowledge. In modern times, spatial data mining has emerged as an area of
voluminous research. Forest fires are a chief environmental concern, causing
economical and ecological damage while endangering human lives across the
world. The fast or early detection of forest fires is a vital element for
controlling such phenomenon. The application of remote sensing is at present a
significant method for forest fires monitoring, particularly in vast and remote
areas. Different methods have been presented by researchers for forest fire
detection. The motivation behind this research is to obtain beneficial
information from images in the forest spatial data and use the same in the
determination of regions at the risk of fires by utilizing Image Processing and
Artificial Intelligence techniques. This paper presents an intelligent system
to detect the presence of forest fires in the forest spatial data using
Artificial Neural Networks. The digital images in the forest spatial data are
converted from RGB to XYZ color space and then segmented by employing
anisotropic diffusion to identify the fire regions. Subsequently, Radial Basis
Function Neural Network is employed in the design of the intelligent system,
which is trained with the color space values of the segmented fire regions.
Extensive experimental assessments on publicly available spatial data
illustrated the efficiency of the proposed system in effectively detecting
forest fires.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2202</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2202</id><created>2010-02-10</created><authors><author><keyname>Pillai</keyname><forenames>Ramesh Kumar Gopala</forenames></author><author><keyname>P</keyname><forenames>Dr. Ramakanth Kumar .</forenames></author></authors><title>Modeling of Human Criminal Behavior using Probabilistic Networks</title><categories>cs.AI</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 216-219, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Currently, criminals profile (CP) is obtained from investigators or forensic
psychologists interpretation, linking crime scene characteristics and an
offenders behavior to his or her characteristics and psychological profile.
This paper seeks an efficient and systematic discovery of nonobvious and
valuable patterns between variables from a large database of solved cases via a
probabilistic network (PN) modeling approach. The PN structure can be used to
extract behavioral patterns and to gain insight into what factors influence
these behaviors. Thus, when a new case is being investigated and the profile
variables are unknown because the offender has yet to be identified, the
observed crime scene variables are used to infer the unknown variables based on
their connections in the structure and the corresponding numerical
(probabilistic) weights. The objective is to produce a more systematic and
empirical approach to profiling, and to use the resulting PN model as a
decision tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2203</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2203</id><created>2010-02-10</created><authors><author><keyname>Kwon</keyname><forenames>Keehang</forenames></author><author><keyname>Ha</keyname><forenames>Hong Pyo</forenames></author><author><keyname>Kim</keyname><forenames>Jiseung</forenames></author></authors><title>A proof Procedure for Testing Membership in Regular Expressions</title><categories>cs.FL</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 225-227, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an algorithm that test membership for regular expressions and show
that the algorithm is correct. This algorithm is written in the style of a
sequent proof system. The advantage of this algorithm over traditional ones is
that the complex conversion process from regular expressions to finite automata
is not needed. As a consequence, our algorithm is simple and extends easily to
various extensions to regular expressions such as timed regular expressions or
regular languages with the intersection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2222</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2222</id><created>2010-02-11</created><authors><author><keyname>Alhaj</keyname><forenames>Mosleh M. Abu</forenames></author><author><keyname>Halaiyqah</keyname><forenames>M.</forenames></author><author><keyname>Hashem</keyname><forenames>Muhannad A. Abu</forenames></author><author><keyname>Hnaif</keyname><forenames>Adnan A.</forenames></author><author><keyname>Abouabdalla</keyname><forenames>O.</forenames></author><author><keyname>Manasrah</keyname><forenames>Ahmed M.</forenames></author></authors><title>An innovative platform to improve the performance of exact string
  matching algorithms</title><categories>cs.DC cs.DS</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 280-283, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Exact String Matching is an essential issue in many computer science
applications. Unfortunately, the performance of Exact String Matching
algorithms, namely, executing time, does not address the needs of these
applications. This paper proposes a general platform for improving the existing
Exact String Matching algorithms executing time, called the PXSMAlg platform.
The function of this platform is to parallelize the Exact String Matching
algorithms using the MPI model over the Master or Slaves paradigms. The PXSMAlg
platform parallelization process is done by dividing the Text into several
parts and working on these parts simultaneously. This improves the executing
time of the Exact String Matching algorithms. We have simulated the PXSMAlg
platform in order to show its competence, through applying the Quick Search
algorithm on the PXSMAlg platform. The simulation result showed significant
improvement in the Quick Search executing time, and therefore extreme
competence in the PXSMAlg platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2236</identifier>
 <datestamp>2014-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2236</id><created>2010-02-10</created><updated>2010-03-26</updated><authors><author><keyname>Ghorbal</keyname><forenames>Khalil</forenames></author><author><keyname>Goubault</keyname><forenames>Eric</forenames></author><author><keyname>Putot</keyname><forenames>Sylvie</forenames></author></authors><title>A Logical Product Approach to Zonotope Intersection</title><categories>cs.LO cs.NA</categories><doi>10.1007/978-3-642-14295-6_22</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define and study a new abstract domain which is a fine-grained combination
of zonotopes with polyhedric domains such as the interval, octagon, linear
templates or polyhedron domain. While abstract transfer functions are still
rather inexpensive and accurate even for interpreting non-linear computations,
we are able to also interpret tests (i.e. intersections) efficiently. This
fixes a known drawback of zonotopic methods, as used for reachability analysis
for hybrid sys- tems as well as for invariant generation in abstract
interpretation: intersection of zonotopes are not always zonotopes, and there
is not even a best zonotopic over-approximation of the intersection. We
describe some examples and an im- plementation of our method in the APRON
library, and discuss some further in- teresting combinations of zonotopes with
non-linear or non-convex domains such as quadratic templates and maxplus
polyhedra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2240</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2240</id><created>2010-02-10</created><authors><author><keyname>Suzuki</keyname><forenames>Joe</forenames></author></authors><title>A Generalization of the Chow-Liu Algorithm and its Application to
  Statistical Learning</title><categories>cs.IT cs.AI cs.LG math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the Chow-Liu algorithm for general random variables while the
previous versions only considered finite cases. In particular, this paper
applies the generalization to Suzuki's learning algorithm that generates from
data forests rather than trees based on the minimum description length by
balancing the fitness of the data to the forest and the simplicity of the
forest. As a result, we successfully obtain an algorithm when both of the
Gaussian and finite random variables are present.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2244</identifier>
 <datestamp>2013-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2244</id><created>2010-02-10</created><updated>2013-01-17</updated><authors><author><keyname>Cheraghchi</keyname><forenames>Mahdi</forenames></author></authors><title>Improved Constructions for Non-adaptive Threshold Group Testing</title><categories>cs.DM cs.IT math.IT</categories><comments>Revised draft of the full version. Contains various edits and a new
  lower bounds section. Preliminary version appeared in Proceedings of the 37th
  International Colloquium on Automata, Languages and Programming (ICALP), 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The basic goal in combinatorial group testing is to identify a set of up to
$d$ defective items within a large population of size $n \gg d$ using a pooling
strategy. Namely, the items can be grouped together in pools, and a single
measurement would reveal whether there are one or more defectives in the pool.
The threshold model is a generalization of this idea where a measurement
returns positive if the number of defectives in the pool reaches a fixed
threshold $u &gt; 0$, negative if this number is no more than a fixed lower
threshold $\ell &lt; u$, and may behave arbitrarily otherwise. We study
non-adaptive threshold group testing (in a possibly noisy setting) and show
that, for this problem, $O(d^{g+2} (\log d) \log(n/d))$ measurements (where $g
:= u-\ell-1$ and $u$ is any fixed constant) suffice to identify the defectives,
and also present almost matching lower bounds. This significantly improves the
previously known (non-constructive) upper bound $O(d^{u+1} \log(n/d))$.
Moreover, we obtain a framework for explicit construction of measurement
schemes using lossless condensers. The number of measurements resulting from
this scheme is ideally bounded by $O(d^{g+3} (\log d) \log n)$. Using
state-of-the-art constructions of lossless condensers, however, we obtain
explicit testing schemes with $O(d^{g+3} (\log d) qpoly(\log n))$ and
$O(d^{g+3+\beta} poly(\log n))$ measurements, for arbitrary constant $\beta &gt;
0$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2259</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2259</id><created>2010-02-10</created><updated>2010-08-08</updated><authors><author><keyname>Bansal</keyname><forenames>Nikhil</forenames></author></authors><title>Constructive Algorithms for Discrepancy Minimization</title><categories>cs.DS cs.DM math.CO</categories><comments>Fixed a previous erroneous claim about a logarithmic approximation
  for hereditary discrepancy. Other minor updates</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set system (V,S), V={1,...,n} and S={S1,...,Sm}, the minimum
discrepancy problem is to find a 2-coloring of V, such that each set is colored
as evenly as possible. In this paper we give the first polynomial time
algorithms for discrepancy minimization that achieve bounds similar to those
known existentially using the so-called Entropy Method. We also give a first
approximation-like result for discrepancy. The main idea in our algorithms is
to produce a coloring over time by letting the color of the elements perform a
random walk (with tiny increments) starting from 0 until they reach $-1$ or
$+1$. At each time step the random hops for various elements are correlated
using the solution to a semidefinite program, where this program is determined
by the current state and the entropy method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2271</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2271</id><created>2010-02-10</created><authors><author><keyname>Abbe</keyname><forenames>Emmanuel</forenames></author><author><keyname>Zheng</keyname><forenames>Lizhong</forenames></author></authors><title>A Coordinate System for Gaussian Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies network information theory problems where the external
noise is Gaussian distributed. In particular, the Gaussian broadcast channel
with coherent fading and the Gaussian interference channel are investigated. It
is shown that in these problems, non-Gaussian code ensembles can achieve higher
rates than the Gaussian ones. It is also shown that the strong Shamai-Laroia
conjecture on the Gaussian ISI channel does not hold. In order to analyze
non-Gaussian code ensembles over Gaussian networks, a geometrical tool using
the Hermite polynomials is proposed. This tool provides a coordinate system to
analyze a class of non-Gaussian input distributions that are invariant over
Gaussian networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2283</identifier>
 <datestamp>2011-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2283</id><created>2010-02-11</created><updated>2011-02-10</updated><authors><author><keyname>Lu</keyname><forenames>Jie</forenames></author><author><keyname>Tang</keyname><forenames>Choon Yik</forenames></author><author><keyname>Regier</keyname><forenames>Paul R.</forenames></author><author><keyname>Bow</keyname><forenames>Travis D.</forenames></author></authors><title>Gossip Algorithms for Convex Consensus Optimization over Networks</title><categories>math.OC cs.DC cs.SY</categories><comments>15 pages</comments><msc-class>93A14</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many applications, nodes in a network desire not only a consensus, but an
optimal one. To date, a family of subgradient algorithms have been proposed to
solve this problem under general convexity assumptions. This paper shows that,
for the scalar case and by assuming a bit more, novel non-gradient-based
algorithms with appealing features can be constructed. Specifically, we develop
Pairwise Equalizing (PE) and Pairwise Bisectioning (PB), two gossip algorithms
that solve unconstrained, separable, convex consensus optimization problems
over undirected networks with time-varying topologies, where each local
function is strictly convex, continuously differentiable, and has a minimizer.
We show that PE and PB are easy to implement, bypass limitations of the
subgradient algorithms, and produce switched, nonlinear, networked dynamical
systems that admit a common Lyapunov function and asymptotically converge.
Moreover, PE generalizes the well-known Pairwise Averaging and Randomized
Gossip Algorithm, while PB relaxes a requirement of PE, allowing nodes to never
share their local functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2284</identifier>
 <datestamp>2010-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2284</id><created>2010-02-11</created><updated>2010-05-13</updated><authors><author><keyname>Maymin</keyname><forenames>Philip</forenames></author></authors><title>Markets are efficient if and only if P = NP</title><categories>q-fin.GN cs.CC</categories><comments>33 pages; extended literature review and some additions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I prove that if markets are weak-form efficient, meaning current prices fully
reflect all information available in past prices, then P = NP, meaning every
computational problem whose solution can be verified in polynomial time can
also be solved in polynomial time. I also prove the converse by showing how we
can &quot;program&quot; the market to solve NP-complete problems. Since P probably does
not equal NP, markets are probably not efficient. Specifically, markets become
increasingly inefficient as the time series lengthens or becomes more frequent.
An illustration by way of partitioning the excess returns to momentum
strategies based on data availability confirms this prediction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2293</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2293</id><created>2010-02-11</created><updated>2010-04-14</updated><authors><author><keyname>Yang</keyname><forenames>Shenghao</forenames></author><author><keyname>Ho</keyname><forenames>Siu-Wai</forenames></author><author><keyname>Meng</keyname><forenames>Jin</forenames></author><author><keyname>Yang</keyname><forenames>En-hui</forenames></author><author><keyname>Yeung</keyname><forenames>Raymond W.</forenames></author></authors><title>On Linear Operator Channels over Finite Fields</title><categories>cs.IT math.IT</categories><comments>53 pages, 3 figures, submitted to IEEE Transaction on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by linear network coding, communication channels perform linear
operation over finite fields, namely linear operator channels (LOCs), are
studied in this paper. For such a channel, its output vector is a linear
transform of its input vector, and the transformation matrix is randomly and
independently generated. The transformation matrix is assumed to remain
constant for every T input vectors and to be unknown to both the transmitter
and the receiver. There are NO constraints on the distribution of the
transformation matrix and the field size.
  Specifically, the optimality of subspace coding over LOCs is investigated. A
lower bound on the maximum achievable rate of subspace coding is obtained and
it is shown to be tight for some cases. The maximum achievable rate of
constant-dimensional subspace coding is characterized and the loss of rate
incurred by using constant-dimensional subspace coding is insignificant.
  The maximum achievable rate of channel training is close to the lower bound
on the maximum achievable rate of subspace coding. Two coding approaches based
on channel training are proposed and their performances are evaluated. Our
first approach makes use of rank-metric codes and its optimality depends on the
existence of maximum rank distance codes. Our second approach applies linear
coding and it can achieve the maximum achievable rate of channel training. Our
code designs require only the knowledge of the expectation of the rank of the
transformation matrix. The second scheme can also be realized ratelessly
without a priori knowledge of the channel statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2294</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2294</id><created>2010-02-11</created><authors><author><keyname>Seigneur</keyname><forenames>Jean-Marc</forenames></author><author><keyname>Titi</keyname><forenames>Xavier</forenames></author></authors><title>Reputation-based Telecommunication Network Selection</title><categories>cs.NI cs.CR</categories><comments>Published in the Proceedings of the 2009 IADIS e-Society
  International Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, mobile users can switch between different available networks, for
example, nearby WiFi networks or their standard mobile operator network. Soon
it will be extended to other operators. However, unless telecommunication
operators can directly benefit from allowing a user to switch to another
operator, operators have an incentive to keep their network quality of service
confidential to avoid that their users decide to switch to another network. In
contrast, in a user-centric way, the users should be allowed to share their
observations regarding the networks that they have used. In this paper, we
present our work in progress towards attack-resistant sharing of quality of
service information and network provider reputation among mobile users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2297</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2297</id><created>2010-02-11</created><authors><author><keyname>Seigneur</keyname><forenames>Jean-Marc</forenames></author></authors><title>Local ePolitics Reputation Case Study</title><categories>cs.CY</categories><comments>Published in the Proceedings of the IADIS 2009 e-Society
  International Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  More and more people rely on Web information and with the advance of Web 2.0
technologies they can increasingly easily participate to the creation of this
information. Country-level politicians could not ignore this trend and have
started to use the Web to promote them or to demote their opponents. This paper
presents how candidates to a French mayor local election and with less budget
have engineered their Web campaign and online reputation. After presenting the
settings of the local election, the Web tools used by the different candidates
and the local journalists are detailed. These tools are evaluated from a
security point of view and the legal issues that they have created are
underlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2321</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2321</id><created>2010-02-11</created><authors><author><keyname>Pujari</keyname><forenames>Bhalchandra S.</forenames></author></authors><title>Exploiting Grids for applications in Condensed Matter Physics</title><categories>cond-mat.mes-hall cond-mat.other cs.CE physics.comp-ph</categories><journal-ref>ICTP Lecture Notes Series, Volume 24 (ISBN 92-95003-42-X) -
  November 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Grids - the collection of heterogeneous computers spread across the globe -
present a new paradigm for the large scale problems in variety of fields. We
discuss two representative cases in the area of condensed matter physics
outlining the widespread applications of the Grids. Both the problems involve
calculations based on commonly used Density Functional Theory and hence can be
considered to be of general interest. We demonstrate the suitability of Grids
for the problems discussed and provide a general algorithm to implement and
manage such large scale problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2334</identifier>
 <datestamp>2013-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2334</id><created>2010-02-11</created><updated>2013-11-28</updated><authors><author><keyname>Singer</keyname><forenames>Yaron</forenames></author></authors><title>Budget Feasible Mechanisms</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a novel class of mechanism design problems in which the outcomes are
constrained by the payments. This basic class of mechanism design problems
captures many common economic situations, and yet it has not been studied, to
our knowledge, in the past. We focus on the case of procurement auctions in
which sellers have private costs, and the auctioneer aims to maximize a utility
function on subsets of items, under the constraint that the sum of the payments
provided by the mechanism does not exceed a given budget. Standard mechanism
design ideas such as the VCG mechanism and its variants are not applicable
here. We show that, for general functions, the budget constraint can render
mechanisms arbitrarily bad in terms of the utility of the buyer. However, our
main result shows that for the important class of submodular functions, a
bounded approximation ratio is achievable. Better approximation results are
obtained for subclasses of the submodular functions. We explore the space of
budget feasible mechanisms in other domains and give a characterization under
more restricted conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2353</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2353</id><created>2010-02-11</created><authors><author><keyname>Haddadi</keyname><forenames>Hamed</forenames></author></authors><title>Fighting Online Click-Fraud Using Bluff Ads</title><categories>cs.CR</categories><comments>Draft</comments><acm-class>J.4</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Online advertising is currently the greatest source of revenue for many
Internet giants. The increased number of specialized websites and modern
profiling techniques, have all contributed to an explosion of the income of ad
brokers from online advertising. The single biggest threat to this growth, is
however, click-fraud. Trained botnets and even individuals are hired by
click-fraud specialists in order to maximize the revenue of certain users from
the ads they publish on their websites, or to launch an attack between
competing businesses.
  In this note we wish to raise the awareness of the networking research
community on potential research areas within this emerging field. As an example
strategy, we present Bluff ads; a class of ads that join forces in order to
increase the effort level for click-fraud spammers. Bluff ads are either
targeted ads, with irrelevant display text, or highly relevant display text,
with irrelevant targeting information. They act as a litmus test for the
legitimacy of the individual clicking on the ads. Together with standard
threshold-based methods, fake ads help to decrease click-fraud levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2384</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2384</id><created>2010-02-11</created><authors><author><keyname>Antunes</keyname><forenames>Nelson</forenames></author><author><keyname>Fricker</keyname><forenames>Christine</forenames></author><author><keyname>Robert</keyname><forenames>Philippe</forenames></author><author><keyname>Roberts</keyname><forenames>James</forenames></author></authors><title>Upstream traffic capacity of a WDM EPON under online GATE-driven
  scheduling</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Passive optical networks are increasingly used for access to the Internet and
it is important to understand the performance of future long-reach,
multi-channel variants. In this paper we discuss requirements on the dynamic
bandwidth allocation (DBA) algorithm used to manage the upstream resource in a
WDM EPON and propose a simple novel DBA algorithm that is considerably more
efficient than classical approaches. We demonstrate that the algorithm emulates
a multi-server polling system and derive capacity formulas that are valid for
general traffic processes. We evaluate delay performance by simulation
demonstrating the superiority of the proposed scheduler. The proposed scheduler
offers considerable flexibility and is particularly efficient in long-reach
access networks where propagation times are high.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2385</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2385</id><created>2010-02-11</created><updated>2010-03-27</updated><authors><author><keyname>Antunes</keyname><forenames>Nelson</forenames></author><author><keyname>Fricker</keyname><forenames>Christine</forenames></author><author><keyname>Robert</keyname><forenames>Philippe</forenames></author><author><keyname>Roberts</keyname><forenames>James</forenames></author></authors><title>Traffic Capacity of Large WDM Passive Optical Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As passive optical networks (PON) are increasingly deployed to provide high
speed Internet access, it is important to understand their fundamental traffic
capacity limits. The paper discusses performance models applicable to
wavelength division multiplexing (WDM) EPONs and GPONs under the assumption
that users access the fibre via optical network units equipped with tunable
transmitters. The considered stochastic models are based on multiserver polling
systems for which explicit analytical results are not known. A large system
asymptotic, mean-field approximation, is used to derive closed form solutions
of these complex systems. Convergence of the mean field dynamics is proved in
the case of a simple network configuration. Simulation results show that, for a
realistic sized PON, the mean field approximation is accurate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2403</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2403</id><created>2010-02-11</created><authors><author><keyname>Qamar</keyname><forenames>Shamimul</forenames></author><author><keyname>Manoj</keyname><forenames>Kumar</forenames></author></authors><title>Impact of Random Loss on TCP Performance in Mobile Ad hoc Networks (IEEE
  802.11), A Simulation-Based Analysis</title><categories>cs.NI</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 228-233, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Initially TCP was designed with the notion in mind that wired networks are
generally reliable and any segment loss in a transmission is due to congestion
in the network rather than an unreliable medium (The assumptions is that the
packet loss caused by damage is much less than 1 percent) . This notion doesnt
hold in wireless parts of the network. Wireless links are highly unreliable and
they lose segments all the time due to a number of factors. Very few papers are
available which uses TCP for MANET. In this paper, an attempt have been made to
justify the use of TCP variants (Tahoe and Reno) for loss of packet due to
random noise introduces in the MANET. For the present analysis the simulation
has been carried out for TCP variants (Tahoe and Reno) by introduces 0, 10, 20
and 30 percent noise. The comparison of TCP variants is made by running
simulation for 0, 10, 20 and 30 percent of data packet loss due to noise in the
transmission link and the effect of throughput and congestion window has been
examined. During the simulation we have observed that throughput has been
decreased when a drop of multiple segments happens, further we have observed in
the case of TCP variant (Reno) throughput is better at 1 percent (Figure 5)
which implies a network with short burst of error and low BER, causing only one
segment to be lost. When multiple segments are lost due to error prone nature
of link, Tahoe perform better than Reno (Figure 13), that gives a significant
saving of time (64.28 percent) in comparison with Reno (Table 4). Several
simulations have been run with ns 2 simulator in order to acquire a better
understanding of these TCP variants and the way they perform their function. We
conclude with a discussion of whether these TCP versions can be used in Mobile
Ad hoc Network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2408</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2408</id><created>2010-02-11</created><authors><author><keyname>Jayanthi</keyname><forenames>D.</forenames></author><author><keyname>Devi</keyname><forenames>N.</forenames></author><author><keyname>SwarnaParvathi</keyname><forenames>S.</forenames></author></authors><title>Automatic diagnosis of retinal diseases from color retinal images</title><categories>cs.CV</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 234-238, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Teleophthalmology holds a great potential to improve the quality, access, and
affordability in health care. For patients, it can reduce the need for travel
and provide the access to a superspecialist. Ophthalmology lends itself easily
to telemedicine as it is a largely image based diagnosis. The main goal of the
proposed system is to diagnose the type of disease in the retina and to
automatically detect and segment retinal diseases without human supervision or
interaction. The proposed system will diagnose the disease present in the
retina using a neural network based classifier.The extent of the disease spread
in the retina can be identified by extracting the textural features of the
retina. This system will diagnose the following type of diseases: Diabetic
Retinopathy and Drusen.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2409</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2409</id><created>2010-02-11</created><authors><author><keyname>Sheikh</keyname><forenames>Rashid</forenames></author><author><keyname>Kumar</keyname><forenames>Beerendra</forenames></author><author><keyname>Mishra</keyname><forenames>Durgesh Kumar</forenames></author></authors><title>Changing Neighbors k Secure Sum Protocol for Secure Multi Party
  Computation</title><categories>cs.CR</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 239-243, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secure sum computation of private data inputs is an important component of
Secure Multi party Computation (SMC).In this paper we provide a protocol to
compute the sum of individual data inputs with zero probability of data
leakage. In our proposed protocol we break input of each party into number of
segments and change the arrangement of the parties such that in each round of
the computation the neighbors are changed. In this protocol it becomes
impossible for semi honest parties to know the private data of some other
party.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2412</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2412</id><created>2010-02-11</created><authors><author><keyname>Priyam</keyname><forenames>Amrita</forenames></author><author><keyname>Karan</keyname><forenames>B. M.</forenames></author><author><keyname>Sahoo</keyname><forenames>G.</forenames></author></authors><title>A Probabilistic Model For Sequence Analysis</title><categories>q-bio.QM cs.CE</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 244-247, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a probabilistic approach for DNA sequence analysis. A DNA
sequence consists of an arrangement of the four nucleotides A, C, T and G and
different representation schemes are presented according to a probability
measure associated with them. There are different ways that probability can be
associated with the DNA sequence: one way is when the probability of an
occurrence of a letter does not depend on the previous one (termed as
unsuccessive probability) and in another scheme the probability of occurrence
of a letter depends on its previous letter (termed as successive probability).
Further, based on these probability measures graphical representations of the
schemes are also presented. Using the diagram probability measure one can
easily calculate an associated probability measure which can serve as a
parameter to check how close is a new sequence to already existing ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2414</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2414</id><created>2010-02-11</created><authors><author><keyname>Dhanalakshmi</keyname><forenames>R.</forenames></author><author><keyname>Thaiyalnayaki</keyname><forenames>K.</forenames></author></authors><title>Dual Watermarking Scheme with Encryption</title><categories>cs.MM cs.CR</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 248-253, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital Watermarking is used for copyright protection and authentication. In
the proposed system, a Dual Watermarking Scheme based on DWT SVD with chaos
encryption algorithm, will be developed to improve the robustness and
protection along with security. DWT and SVD have been used as a mathematical
tool to embed watermark in the image. Two watermarks are embedded in the host
image. The secondary is embedded into primary watermark and the resultant
watermarked image is encrypted using chaos based logistic map. This provides an
efficient and secure way for image encryption and transmission. The watermarked
image is decrypted and a reliable watermark extraction scheme is developed for
the extraction of the primary as well as secondary watermark from the distorted
image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2415</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2415</id><created>2010-02-11</created><authors><author><keyname>Suri</keyname><forenames>P. K.</forenames></author><author><keyname>Singh</keyname><forenames>Gurdev</forenames></author></authors><title>Effort minimization in UI development by reusing existing DGML based UI
  design for qualitative software development</title><categories>cs.HC</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 254-261, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the methodology for achieving the user interface design
reusability of a qualitative software system and effort minimization by
applying the inference on the stored design documents. The pictorial design
documents are stored in a special format in the form of keyword text [DGML tag
based design]. The design document storage mechanism will expose the keywords
per design stored. This methodology is having an inference engine. Inference
mechanism search for the requirements and find the match for them in the
available design repository. A match found will success in reusing it after
checking the quality parameters of the found design module in the result set.
DGML notations produces qualitative designs which helps in minimizing the
efforts of software development life cycle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2416</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2416</id><created>2010-02-11</created><authors><author><keyname>Islam</keyname><forenames>Rafiqul</forenames></author><author><keyname>Naji</keyname><forenames>A. W.</forenames></author><author><keyname>Zaidan</keyname><forenames>A. A.</forenames></author><author><keyname>Zaidan</keyname><forenames>B. B.</forenames></author></authors><title>New System for Secure Cover File of Hidden Data in the Image Page within
  Executable File Using Statistical Steganography Techniques</title><categories>cs.CR cs.MM</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 273-279, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Previously traditional methods were sufficient to protect the information,
since it is simplicity in the past does not need complicated methods but with
the progress of information technology, it become easy to attack systems, and
detection of encryption methods became necessary to find ways parallel with the
differing methods used by hackers, so the embedding methods could be under
surveillance from system managers in an organization that requires the high
level of security. This fact requires researches on new hiding methods and
cover objects which hidden information is embedded in. It is the result from
the researches to embed information in executable files, but when will use the
executable file for cover they have many challenges must be taken into
consideration which is any changes made to the file will be firstly detected by
untie viruses, secondly the functionality of the file is not still functioning.
In this paper, a new information hiding system is presented. The aim of the
proposed system is to hide information (data file) within image page of
execution file (EXEfile) to make sure changes made to the file will not be
detected by universe and the functionality of the exe.file is still functioning
after hiding process. Meanwhile, since the cover file might be used to identify
hiding information, the proposed system considers overcoming this dilemma by
using the execution file as a cover file.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2418</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2418</id><created>2010-02-11</created><authors><author><keyname>Ramesh</keyname><forenames>S. M.</forenames></author><author><keyname>Shanmugam</keyname><forenames>A.</forenames></author></authors><title>Medical Image Compression using Wavelet Decomposition for Prediction
  Method</title><categories>cs.CV</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 262-265, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper offers a simple and lossless compression method for compression
of medical images. Method is based on wavelet decomposition of the medical
images followed by the correlation analysis of coefficients. The correlation
analyses are the basis of prediction equation for each sub band. Predictor
variable selection is performed through coefficient graphic method to avoid
multicollinearity problem and to achieve high prediction accuracy and
compression rate. The method is applied on MRI and CT images. Results show that
the proposed approach gives a high compression rate for MRI and CT images
comparing with state of the art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2420</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2420</id><created>2010-02-11</created><authors><author><keyname>Ezhumalai</keyname><forenames>P.</forenames></author><author><keyname>Manojkumar</keyname><forenames>S.</forenames></author><author><keyname>Arun</keyname><forenames>C.</forenames></author><author><keyname>Sakthivel</keyname><forenames>P.</forenames></author><author><keyname>Sridharan</keyname><forenames>D.</forenames></author></authors><title>High Performance Hybrid Two Layer Router Architecture for FPGAs Using
  Network On Chip</title><categories>cs.NI</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 266-272, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Networks on Chip is a recent solution paradigm adopted to increase the
performance of Multicore designs. The key idea is to interconnect various
computation modules (IP cores) in a network fashion and transport packets
simultaneously across them, thereby gaining performance. In addition to
improving performance by having multiple packets in flight, NoCs also present a
host of other advantages including scalability, power efficiency, and component
reuse through modular design. This work focuses on design and development of
high performance communication architectures for FPGAs using NoCs Once
completely developed, the above methodology could be used to augment the
current FPGA design flow for implementing multicore SoC applications. We design
and implement an NoC framework for FPGAs, MultiClock OnChip Network for
Reconfigurable Systems (MoCReS). We propose a novel microarchitecture for a
hybrid two layer router that supports both packetswitched communications,
across its local and directional ports, as well as, time multiplexed
circuitswitched communications among the multiple IP cores directly connected
to it. Results from place and route VHDL models of the advanced router
architecture show an average improvement of 20.4 percent in NoC bandwidth
(maximum of 24 percent compared to a traditional NoC). We parameterize the
hybrid router model over the number of ports, channel width and bRAM depth and
develop a library of network components (MoClib Library). For your paper to be
published in the conference proceedings, you must use this document as both an
instruction set and as a template into which you can type your own text. If
your paper does not conform to the required format, you will be asked to fix
it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2423</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2423</id><created>2010-02-11</created><authors><author><keyname>Singh</keyname><forenames>Jatinder</forenames></author><author><keyname>Gupta</keyname><forenames>Savita</forenames></author><author><keyname>Kaur</keyname><forenames>Lakhwinder</forenames></author></authors><title>A MAC Layer Based Defense Architecture for Reduction of Quality (RoQ)
  Attacks in Wireless LAN</title><categories>cs.CR cs.NI</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 284-291, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently an alternative of DDoS attacks called shrew attacks or Reduction of
Quality (RoQ) has been identified which is very much difficult to detect. The
RoQ attacks can use source and destination IP address spoofing, and they do not
have distinct periodicity, and may not filter the attack packets precisely. In
this paper, we propose to design the MAC layer based defense architecture for
RoQ attacks in Wireless LAN which includes the detection and response stages.
The attackers are detected by checking the RTS CTS packets from the MAC layer
and the corresponding attack flows are blocked or rejected. By our simulation
results, we show that our proposed technique achieves reduces the attack
throughput there by increasing the received bandwidth and reducing the packet
loss of legitimate users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2425</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2425</id><created>2010-02-11</created><authors><author><keyname>Oyelade</keyname><forenames>O. J.</forenames></author><author><keyname>Oladipupo</keyname><forenames>O. O.</forenames></author><author><keyname>Obagbuwa</keyname><forenames>I. C.</forenames></author></authors><title>Application of k Means Clustering algorithm for prediction of Students
  Academic Performance</title><categories>cs.LG cs.CY</categories><comments>IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 1947 5500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 292-295, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to monitor the progress of students academic performance is a
critical issue to the academic community of higher learning. A system for
analyzing students results based on cluster analysis and uses standard
statistical algorithms to arrange their scores data according to the level of
their performance is described. In this paper, we also implemented k mean
clustering algorithm for analyzing students result data. The model was combined
with the deterministic model to analyze the students results of a private
Institution in Nigeria which is a good benchmark to monitor the progression of
academic performance of students in higher Institution for the purpose of
making an effective decision by the academic planners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2439</identifier>
 <datestamp>2010-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2439</id><created>2010-02-11</created><authors><author><keyname>Shipman</keyname><forenames>Jeffery L.</forenames></author><author><keyname>Klein</keyname><forenames>Martin</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author></authors><title>Using Web Page Titles to Rediscover Lost Web Pages</title><categories>cs.IR</categories><comments>49 pages, 18 figures, CS project report</comments><acm-class>H.3.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Titles are denoted by the TITLE element within a web page. We queried the
title against the the Yahoo search engine to determine the page's status
(found, not found). We conducted several tests based on elements of the title.
These tests were used to discern whether we could predict a pages status based
on the title. Our results increase our ability to determine bad titles but not
our ability to determine good titles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2440</identifier>
 <datestamp>2014-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2440</id><created>2010-02-11</created><updated>2012-03-08</updated><authors><author><keyname>Ambuehl</keyname><forenames>Christoph</forenames></author><author><keyname>Gaertner</keyname><forenames>Bernd</forenames></author><author><keyname>von Stengel</keyname><forenames>Bernhard</forenames></author></authors><title>Optimal Lower Bounds for Projective List Update Algorithms</title><categories>cs.CC cs.DS</categories><comments>Version 3 same as version 2, but date in LaTeX \today macro replaced
  by March 8, 2012</comments><msc-class>68W27, 68W40, 68P05, 68P10</msc-class><acm-class>F.1.2</acm-class><journal-ref>ACM Transactions on Algorithms (TALG) Volume 9, Issue 4, September
  2013, Article 31, 18 pages</journal-ref><doi>10.1145/2500120</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The list update problem is a classical online problem, with an optimal
competitive ratio that is still open, known to be somewhere between 1.5 and
1.6. An algorithm with competitive ratio 1.6, the smallest known to date, is
COMB, a randomized combination of BIT and the TIMESTAMP algorithm TS. This and
almost all other list update algorithms, like MTF, are projective in the sense
that they can be defined by looking only at any pair of list items at a time.
Projectivity (also known as &quot;list factoring&quot;) simplifies both the description
of the algorithm and its analysis, and so far seems to be the only way to
define a good online algorithm for lists of arbitrary length. In this paper we
characterize all projective list update algorithms and show that their
competitive ratio is never smaller than 1.6 in the partial cost model.
Therefore, COMB is a best possible projective algorithm in this model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2450</identifier>
 <datestamp>2010-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2450</id><created>2010-02-11</created><authors><author><keyname>de Lara</keyname><forenames>Alejandro Chinea Manrique</forenames></author></authors><title>Modeling the Probability of Failure on LDAP Binding Operations in
  Iplanet Web Proxy 3.6 Server</title><categories>cs.PF cs.DB</categories><comments>11 pages, 3 figures, Published in Sun MicroSystems Laboratories April
  2002</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is devoted to the theoretical analysis of a problem derived from
interaction between two Iplanet products: Web Proxy Server and the Directory
Server. In particular, a probabilistic and stochastic-approximation model is
proposed to minimize the occurrence of LDAP connection failures in Iplanet Web
Proxy 3.6 Server. The proposed model serves not only to provide a
parameterization of the aforementioned phenomena, but also to provide
meaningful insights illustrating and supporting these theoretical results. In
addition, we shall also address practical considerations when estimating the
parameters of the proposed model from experimental data. Finally, we shall
provide some interesting results from real-world data collected from our
customers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2456</identifier>
 <datestamp>2010-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2456</id><created>2010-02-11</created><authors><author><keyname>Guenda</keyname><forenames>Kenza</forenames></author></authors><title>The Permutation Groups and the Equivalence of Cyclic and Quasi-Cyclic
  Codes</title><categories>cs.IT math.GR math.IT</categories><msc-class>20B05; 94B15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give the class of finite groups which arise as the permutation groups of
cyclic codes over finite fields. Furthermore, we extend the results of Brand
and Huffman et al. and we find the properties of the set of permutations by
which two cyclic codes of length p^r can be equivalent. We also find the set of
permutations by which two quasi-cyclic codes can be equivalent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2477</identifier>
 <datestamp>2010-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2477</id><created>2010-02-12</created><updated>2010-03-31</updated><authors><author><keyname>Sundararajan</keyname><forenames>Mukund</forenames></author><author><keyname>Yan</keyname><forenames>Qiqi</forenames></author></authors><title>Robust Mechanisms for Risk-Averse Sellers</title><categories>cs.GT</categories><acm-class>J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The existing literature on optimal auctions focuses on optimizing the
expected revenue of the seller, and is appropriate for risk-neutral sellers. In
this paper, we identify good mechanisms for risk-averse sellers. As is standard
in the economics literature, we model the risk-aversion of a seller by endowing
the seller with a monotone concave utility function. We then seek robust
mechanisms that are approximately optimal for all sellers, no matter what their
levels of risk-aversion are. We have two main results for multi-unit auctions
with unit-demand bidders whose valuations are drawn i.i.d. from a regular
distribution. First, we identify a posted-price mechanism called the Hedge
mechanism, which gives a universal constant factor approximation; we also show
for the unlimited supply case that this mechanism is in a sense the best
possible. Second, we show that the VCG mechanism gives a universal constant
factor approximation when the number of bidders is even only a small multiple
of the number of items. Along the way we point out that Myerson's
characterization of the optimal mechanisms fails to extend to
utility-maximization for risk-averse sellers, and establish interesting
properties of regular distributions and monotone hazard rate distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2488</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2488</id><created>2010-02-12</created><updated>2011-06-21</updated><authors><author><keyname>Beigi</keyname><forenames>Salman</forenames></author></authors><title>Entanglement-assisted zero-error capacity is upper bounded by the Lovasz
  theta function</title><categories>quant-ph cs.IT math.IT</categories><comments>4 pages, matches published version</comments><journal-ref>Phys. Rev. A 82, 010303(R) (2010)</journal-ref><doi>10.1103/PhysRevA.82.010303</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The zero-error capacity of a classical channel is expressed in terms of the
independence number of some graph and its tensor powers. This quantity is hard
to compute even for small graphs such as the cycle of length seven, so upper
bounds such as the Lovasz theta function play an important role in zero-error
communication. In this paper, we show that the Lovasz theta function is an
upper bound on the zero-error capacity even in the presence of entanglement
between the sender and receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2514</identifier>
 <datestamp>2013-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2514</id><created>2010-02-12</created><updated>2010-03-11</updated><authors><author><keyname>Duan</keyname><forenames>Runyao</forenames></author><author><keyname>Severini</keyname><forenames>Simone</forenames></author><author><keyname>Winter</keyname><forenames>Andreas</forenames></author></authors><title>Zero-error communication via quantum channels, non-commutative graphs
  and a quantum Lovasz theta function</title><categories>quant-ph cs.IT math.IT math.OA</categories><comments>24 pages: v2 has added discussion and more details in section 7.</comments><journal-ref>IEEE Trans. Inf. Theory 59(2):1164-1174, 2013</journal-ref><doi>10.1109/TIT.2012.2221677</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the quantum channel version of Shannon's zero-error capacity
problem. Motivated by recent progress on this question, we propose to consider
a certain operator space as the quantum generalisation of the adjacency matrix,
in terms of which the plain, quantum and entanglement-assisted capacity can be
formulated, and for which we show some new basic properties.
  Most importantly, we define a quantum version of Lovasz' famous theta
function, as the norm-completion (or stabilisation) of a &quot;naive&quot; generalisation
of theta. We go on to show that this function upper bounds the number of
entanglement-assisted zero-error messages, that it is given by a semidefinite
programme, whose dual we write down explicitly, and that it is multiplicative
with respect to the natural (strong) graph product.
  We explore various other properties of the new quantity, which reduces to
Lovasz' original theta in the classical case, give several applications, and
propose to study the operator spaces associated to channels as &quot;non-commutative
graphs&quot;, using the language of Hilbert modules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2523</identifier>
 <datestamp>2010-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2523</id><created>2010-02-12</created><authors><author><keyname>Rattani</keyname><forenames>Ajita</forenames></author><author><keyname>Kisku</keyname><forenames>Dakshina Ranjan</forenames></author><author><keyname>Bicego</keyname><forenames>Manuele</forenames></author><author><keyname>Tistarelli</keyname><forenames>Massimo</forenames></author></authors><title>Feature Level Fusion of Face and Fingerprint Biometrics</title><categories>cs.CV cs.AI</categories><comments>6 pages, 7 figures, conference</comments><acm-class>D.2.2; I.2.10</acm-class><journal-ref>BTAS 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to study the fusion at feature extraction level for
face and fingerprint biometrics. The proposed approach is based on the fusion
of the two traits by extracting independent feature pointsets from the two
modalities, and making the two pointsets compatible for concatenation.
Moreover, to handle the problem of curse of dimensionality, the feature
pointsets are properly reduced in dimension. Different feature reduction
techniques are implemented, prior and after the feature pointsets fusion, and
the results are duly recorded. The fused feature pointset for the database and
the query face and fingerprint images are matched using techniques based on
either the point pattern matching, or the Delaunay triangulation. Comparative
experiments are conducted on chimeric and real databases, to assess the actual
advantage of the fusion performed at the feature extraction level, in
comparison to the matching score level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2527</identifier>
 <datestamp>2010-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2527</id><created>2010-02-12</created><authors><author><keyname>Jagadeesan</keyname><forenames>A.</forenames></author><author><keyname>Duraiswamy</keyname><forenames>K.</forenames></author></authors><title>Secured Cryptographic Key Generation From Multimodal Biometrics Feature
  Level Fusion Of Fingerprint And Iris</title><categories>cs.CR</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Journal of Computer Science, ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 296-305, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human users have a tough time remembering long cryptographic keys. Hence,
researchers, for so long, have been examining ways to utilize biometric
features of the user instead of a memorable password or passphrase, in an
effort to generate strong and repeatable cryptographic keys. Our objective is
to incorporate the volatility of the users biometric features into the
generated key, so as to make the key unguessable to an attacker lacking
significant knowledge of the users biometrics. We go one step further trying to
incorporate multiple biometric modalities into cryptographic key generation so
as to provide better security. In this article, we propose an efficient
approach based on multimodal biometrics (Iris and fingerprint) for generation
of secure cryptographic key. The proposed approach is composed of three modules
namely, 1) Feature extraction, 2) Multimodal biometric template generation and
3) Cryptographic key generation. Initially, the features, minutiae points and
texture properties are extracted from the fingerprint and iris images
respectively. Subsequently, the extracted features are fused together at the
feature level to construct the multibiometric template. Finally, a 256bit
secure cryptographic key is generated from the multibiometric template. For
experimentation, we have employed the fingerprint images obtained from publicly
available sources and the iris images from CASIA Iris Database. The
experimental results demonstrate the effectiveness of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2557</identifier>
 <datestamp>2010-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2557</id><created>2010-02-12</created><authors><author><keyname>Brazdil</keyname><forenames>Tomas</forenames></author><author><keyname>Jancar</keyname><forenames>Petr</forenames></author><author><keyname>Kucera</keyname><forenames>Antonin</forenames></author></authors><title>Reachability Games on Extended Vector Addition Systems with States</title><categories>cs.GT</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two-player turn-based games with zero-reachability and
zero-safety objectives generated by extended vector addition systems with
states. Although the problem of deciding the winner in such games is
undecidable in general, we identify several decidable and even tractable
subcases of this problem obtained by restricting the number of counters and/or
the sets of target configurations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2578</identifier>
 <datestamp>2010-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2578</id><created>2010-02-12</created><authors><author><keyname>Endrullis</keyname><forenames>Joerg</forenames></author><author><keyname>Hendriks</keyname><forenames>Dimitri</forenames></author><author><keyname>Klop</keyname><forenames>Jan Willem</forenames></author></authors><title>Modular Construction of Fixed Point Combinators and Clocked Boehm Trees</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fixed point combinators (and their generalization: looping combinators) are
classic notions belonging to the heart of lambda-calculus and logic. We start
with an exploration of the structure of fixed point combinators (fpc's), vastly
generalizing the well-known fact that if Y is an fpc, Y(SI) is again an fpc,
generating the Boehm sequence of fpc's. Using the infinitary lambda-calculus we
devise infinitely many other generation schemes for fpc's. In this way we find
schemes and building blocks to construct new fpc's in a modular way.
  Having created a plethora of new fixed point combinators, the task is to
prove that they are indeed new. That is, we have to prove their
beta-inconvertibility. Known techniques via Boehm Trees do not apply, because
all fpc's have the same Boehm Tree (BT). Therefore, we employ `clocked BT's',
with annotations that convey information of the tempo in which the data in the
BT are produced. BT's are thus enriched with an intrinsic clock behaviour,
leading to a refined discrimination method for lambda-terms. The corresponding
equality is strictly intermediate between beta-convertibility and BT-equality,
the equality in the classical models of lambda-calculus. An analogous approach
pertains to Levy-Longo Berarducci trees. Finally, we increase the
discrimination power by a precision of the clock notion that we call `atomic
clock'.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2580</identifier>
 <datestamp>2011-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2580</id><created>2010-02-12</created><updated>2011-08-12</updated><authors><author><keyname>Gray</keyname><forenames>Chris</forenames></author><author><keyname>Kammer</keyname><forenames>Frank</forenames></author><author><keyname>Loffler</keyname><forenames>Maarten</forenames></author><author><keyname>Silveira</keyname><forenames>Rodrigo I.</forenames></author></authors><title>Removing Local Extrema from Imprecise Terrains</title><categories>cs.CG cs.DS</categories><comments>21 pages, revised version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider imprecise terrains, that is, triangulated terrains
with a vertical error interval in the vertices. In particular, we study the
problem of removing as many local extrema (minima and maxima) as possible from
the terrain. We show that removing only minima or only maxima can be done
optimally in O(n log n) time, for a terrain with n vertices. Interestingly,
however, removing both the minima and maxima simultaneously is NP-hard, and is
even hard to approximate within a factor of O(log log n) unless P=NP. Moreover,
we show that even a simplified version of the problem where vertices can have
only two different heights is already NP-hard, a result we obtain by proving
hardness of a special case of 2-Disjoint Connected Subgraphs, a problem that
has lately received considerable attention from the graph-algorithms community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2586</identifier>
 <datestamp>2010-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2586</id><created>2010-02-12</created><updated>2010-04-28</updated><authors><author><keyname>Gleichman</keyname><forenames>Sivan</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Blind Compressed Sensing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fundamental principle underlying compressed sensing is that a signal,
which is sparse under some basis representation, can be recovered from a small
number of linear measurements. However, prior knowledge of the sparsity basis
is essential for the recovery process. This work introduces the concept of
blind compressed sensing, which avoids the need to know the sparsity basis in
both the sampling and the recovery process. We suggest three possible
constraints on the sparsity basis that can be added to the problem in order to
make its solution unique. For each constraint we prove conditions for
uniqueness, and suggest a simple method to retrieve the solution. Under the
uniqueness conditions, and as long as the signals are sparse enough, we
demonstrate through simulations that without knowing the sparsity basis our
methods can achieve results similar to those of standard compressed sensing,
which relay on prior knowledge of the sparsity basis. This offers a general
sampling and reconstruction system that fits all sparse signals, regardless of
the sparsity basis, under the conditions and constraints presented in this
work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2594</identifier>
 <datestamp>2010-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2594</id><created>2010-02-12</created><authors><author><keyname>De Feo</keyname><forenames>Luca</forenames></author><author><keyname>Schost</keyname><forenames>&#xc9;ric</forenames></author></authors><title>Fast Arithmetics in Artin-Schreier Towers over Finite Fields</title><categories>cs.SC cs.MS</categories><comments>28 pages, 4 figures, 3 tables, uses mathdots.sty, yjsco.sty Submitted
  to J. Symb. Comput</comments><acm-class>I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An Artin-Schreier tower over the finite field F_p is a tower of field
extensions generated by polynomials of the form X^p - X - a. Following Cantor
and Couveignes, we give algorithms with quasi-linear time complexity for
arithmetic operations in such towers. As an application, we present an
implementation of Couveignes' algorithm for computing isogenies between
elliptic curves using the p-torsion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2625</identifier>
 <datestamp>2010-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2625</id><created>2010-02-12</created><authors><author><keyname>Kasa</keyname><forenames>Zoltan</forenames></author></authors><title>Generating and ranking of Dyck words</title><categories>cs.DM</categories><acm-class>G.2.1</acm-class><journal-ref>Acta Universitatis Sapientiae, Informatica, 1, 1 (2009) 109-118</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new algorithm to generate all Dyck words is presented, which is used in
ranking and unranking Dyck words. We emphasize the importance of using Dyck
words in encoding objects related to Catalan numbers. As a consequence of
formulas used in the ranking algorithm we can obtain a recursive formula for
the nth Catalan number.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2654</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2654</id><created>2010-02-12</created><authors><author><keyname>Norman</keyname><forenames>Evgeny D.</forenames></author></authors><title>Assessment Of The Wind Farm Impact On The Radar</title><categories>cs.CV cs.MS</categories><comments>Master's Thesis, 62 pages, LaTeX. Submitted to ENSIETA &amp; Thales Air
  Systems. Paris area, 2009</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This study shows the means to evaluate the wind farm impact on the radar. It
proposes the set of tools, which can be used to realise this objective. The big
part of report covers the study of complex pattern propagation factor as the
critical issue of the Advanced Propagation Model (APM). Finally, the reader can
find here the implementation of this algorithm - the real scenario in Inverness
airport (the United Kingdom), where the ATC radar STAR 2000, developed by
Thales Air Systems, operates in the presence of several wind farms. Basically,
the project is based on terms of the department &quot;Strategy Technology &amp;
Innovation&quot;, where it has been done. Also you can find here how the radar
industry can act with the problem engendered by wind farms. The current
strategies in this area are presented, such as a wind turbine production,
improvements of air traffic handling procedures and the collaboration between
developers of radars and wind turbines. The possible strategy for Thales as a
main pioneer was given as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2655</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2655</id><created>2010-02-12</created><updated>2010-10-24</updated><authors><author><keyname>Liu</keyname><forenames>Chun-Hung</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Multicast Outage Probability and Transmission Capacity of Multihop
  Wireless Networks</title><categories>cs.IT math.IT</categories><comments>31 pages, 6 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multicast transmission, wherein the same packet must be delivered to multiple
receivers, is an important aspect of sensor and tactical networks and has
several distinctive traits as opposed to more commonly studied unicast
networks. Specially, these include (i) identical packets must be delivered
successfully to several nodes, (ii) outage at any receiver requires the packet
to be retransmitted at least to that receiver, and (iii) the multicast rate is
dominated by the receiver with the weakest link in order to minimize outage and
retransmission. A first contribution of this paper is the development of a
tractable multicast model and throughput metric that captures each of these key
traits in a multicast wireless network. We utilize a Poisson cluster process
(PCP) consisting of a distinct Poisson point process (PPP) for the transmitters
and receivers, and then define the multicast transmission capacity (MTC) as the
maximum achievable multicast rate per transmission attempt times the maximum
intensity of multicast clusters under decoding delay and multicast outage
constraints. A multicast cluster is a contiguous area over which a packet is
multicasted, and to reduce outage it can be tessellated into $v$ smaller
regions of multicast. The second contribution of the paper is the analysis of
several key aspects of this model, for which we develop the following main
result. Assuming $\tau/v$ transmission attempts are allowed for each
tessellated region in a multicast cluster, we show that the MTC is $\Theta(\rho
k^{x}\log(k)v^{y})$ where $\rho$, $x$ and $y$ are functions of $\tau$ and $v$
depending on the network size and intensity, and $k$ is the average number of
the intended receivers in a cluster. We derive $\{\rho, x, y\}$ for a number of
regimes of interest, and also show that an appropriate number of
retransmissions can significantly enhance the MTC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2677</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2677</id><created>2010-02-12</created><authors><author><keyname>Subramanian</keyname><forenames>Sushil</forenames></author></authors><title>Compressed Sensing for Sparse Underwater Channel Estimation: Some
  Practical Considerations</title><categories>stat.AP cs.IT math.IT</categories><comments>10 pages, 6 figures, 17 references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the use of a structured thresholding algorithm for sparse
underwater channel estimation using compressed sensing. This method shows some
improvements over standard algorithms for sparse channel estimation such as
matching pursuit, iterative detection and least squares.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2686</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2686</id><created>2010-02-13</created><authors><author><keyname>Prakasha</keyname><forenames>S.</forenames></author><author><keyname>Selvarani</keyname><forenames>R.</forenames></author></authors><title>Performance Analysis of View Maintenance Techniques for DW</title><categories>cs.SE</categories><comments>6 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Data Warehouse stores integrated information as materialized views over
data from one or more remote sources. These materialized views must be
maintained in response to actual relation updates in the remote sources. The
data warehouse view maintenance techniques are classified into four major
categories self maintainable recomputation, not self maintainable
recomputation, self maintainable incremental maintenance, and not self
maintainable incremental maintenance. This paper provides a comprehensive
comparison of the techniques in these four categories in terms of the data
warehouse space usage and number of rows accessed in order to propagate an
update from a remote data source to a target materialized view in the data
warehouse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2687</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2687</id><created>2010-02-13</created><authors><author><keyname>Pushpavathi</keyname><forenames>T. P.</forenames></author><author><keyname>Kumar</keyname><forenames>N. R. Shashi</forenames></author><author><keyname>Selvarani</keyname><forenames>R.</forenames></author></authors><title>IT in Power Sector A KPCL Implementation</title><categories>cs.OH</categories><comments>6 pages, 2 figures</comments><journal-ref>National Symposium on Scenario of Scientific and IT in Power
  Electronic Systems, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate the extent of Information Technology penetration
in Power sector, taking KPCL, Karnataka Power Corporation Ltd., a premier power
generating, a state owned public sector organization as an example. Any
organization to flourish, adoption of Information Technology is inevitable in
the days of fast changing technological advancements. It is not merely the
investment on IT which helps but adoption of right IT solutions and the optimum
use of the same does matter and becomes most critical. A strong infrastructure
coupled with modern technical and management concepts has helped KPCL to meet
the challenges of the rising energy demands of Karnataka.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2720</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2720</id><created>2010-02-15</created><authors><author><keyname>Wang</keyname><forenames>Chenwei</forenames></author><author><keyname>Gou</keyname><forenames>Tiangao</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>Aiming Perfectly in the Dark - Blind Interference Alignment through
  Staggered Antenna Switching</title><categories>cs.IT math.IT</categories><comments>27 pages, 15 figures</comments><journal-ref>IEEE Transactions on Signal Processing, Vol. 59, No. 6, Pages:
  2734-2744, June 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a blind interference alignment scheme for the vector broadcast
channel where the transmitter is equipped with M antennas and there are K
receivers, each equipped with a reconfigurable antenna capable of switching
among M preset modes. Without any knowledge of the channel coefficient values
at the transmitters and with only mild assumptions on the channel coherence
structure we show that MK/M+K-1 degrees of freedom are achievable. The key to
the blind interference alignment scheme is the ability of the receivers to
switch between reconfigurable antenna modes to create short term channel
fluctuation patterns that are exploited by the transmitter. The achievable
scheme does not require cooperation between transmit antennas and is therefore
applicable to the MxK X network as well. Only finite symbol extensions are
used, and no channel knowledge at the receivers is required to null the
interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2721</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2721</id><created>2010-02-13</created><authors><author><keyname>Kasa</keyname><forenames>Zoltan</forenames></author></authors><title>On the d-complexity of strings</title><categories>cs.DM</categories><acm-class>G.2.1</acm-class><journal-ref>Pure Math. Appl., 9, 1-2 (1998) pp. 119-128</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the complexity of strings, which play an important role
in biology (nucleotid sequences), information theory and computer science. The
d-complexity of a string is defined as the number of its distinct d-substrings
given in Definition 1. The case d=1 is studied in detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2722</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2722</id><created>2010-02-13</created><updated>2010-07-02</updated><authors><author><keyname>Aldinucci</keyname><forenames>Marco</forenames></author><author><keyname>Tuosto</keyname><forenames>Emilio</forenames></author></authors><title>Toward a Formal Semantics for Autonomic Components</title><categories>cs.DC cs.SE</categories><comments>11 pages + cover page</comments><report-no>TR-08-08</report-no><acm-class>D.1.3; F.1.1; D.2.2; D.2.3</acm-class><journal-ref>In From Grids To Service and Pervasive Computing (Proc. of the
  CoreGRID Symposium 2008), CoreGRID, pages 31-45, Las Palmas, Spain, Aug.
  2008. Springer</journal-ref><doi>10.1007/978-0-387-09455-7_3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomic management can improve the QoS provided by parallel/ distributed
applications. Within the CoreGRID Component Model, the autonomic management is
tailored to the automatic - monitoring-driven - alteration of the component
assembly and, therefore, is defined as the effect of (distributed) management
code. This work yields a semantics based on hypergraph rewriting suitable to
model the dynamic evolution and non-functional aspects of Service Oriented
Architectures and component-based autonomic applications. In this regard, our
main goal is to provide a formal description of adaptation operations that are
typically only informally specified. We contend that our approach makes easier
to raise the level of abstraction of management code in autonomic and adaptive
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2723</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2723</id><created>2010-02-13</created><authors><author><keyname>Anisiu</keyname><forenames>M-C.</forenames></author><author><keyname>Anisiu</keyname><forenames>V.</forenames></author><author><keyname>Kasa</keyname><forenames>Z.</forenames></author></authors><title>Properties of palindromes in finite words</title><categories>cs.DM</categories><acm-class>G.2.1</acm-class><journal-ref>Pure Math. Appl. 17, 3-4 (2006) pp. 183-195</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method which displays all palindromes of a given length from De
Bruijn words of a certain order, and also a recursive one which constructs all
palindromes of length $n+1$ from the set of palindromes of length $n$. We show
that the palindrome complexity function, which counts the number of palindromes
of each length contained in a given word, has a different shape compared with
the usual (subword) complexity function. We give upper bounds for the average
number of palindromes contained in all words of length $n$, and obtain exact
formulae for the number of palindromes of length 1 and 2 contained in all words
of length $n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2724</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2724</id><created>2010-02-13</created><authors><author><keyname>Anisiu</keyname><forenames>M-C.</forenames></author><author><keyname>Blazsik</keyname><forenames>Z.</forenames></author><author><keyname>Kasa</keyname><forenames>Z.</forenames></author></authors><title>Maximal Complexity of Finite Words</title><categories>cs.DM</categories><acm-class>G.2.1</acm-class><journal-ref>Pure Math. Appl., 13, 1-2 (2002) pp. 39-48</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The subword complexity of a finite word $w$ of length $N$ is a function which
associates to each $n\le N$ the number of all distinct subwords of $w$ having
the length $n$. We define the \emph{maximal complexity} C(w) as the maximum of
the subword complexity for $n \in \{1,2,..., N \}$, and the \emph{global
maximal complexity} K(N) as the maximum of C(w) for all words $w$ of a fixed
length $N$ over a finite alphabet. By R(N) we will denote the set of the values
$i$ for which there exits a word of length $N$ having K(N) subwords of length
$i$.
  M(N) represents the number of words of length $N$ whose maximal complexity is
equal to the global maximal complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2746</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2746</id><created>2010-02-13</created><authors><author><keyname>Doty</keyname><forenames>David</forenames></author><author><keyname>Kari</keyname><forenames>Lila</forenames></author><author><keyname>Masson</keyname><forenames>Benoit</forenames></author></authors><title>Negative Interactions in Irreversible Self-Assembly</title><categories>cs.DS cs.CC</categories><acm-class>F.1.1; F.1.1; F.1.m; F.m; J.2</acm-class><doi>10.1007/978-3-642-18305-8_4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores the use of negative (i.e., repulsive) interaction the
abstract Tile Assembly Model defined by Winfree. Winfree postulated negative
interactions to be physically plausible in his Ph.D. thesis, and Reif, Sahu,
and Yin explored their power in the context of reversible attachment
operations. We explore the power of negative interactions with irreversible
attachments, and we achieve two main results. Our first result is an
impossibility theorem: after t steps of assembly, Omega(t) tiles will be
forever bound to an assembly, unable to detach. Thus negative glue strengths do
not afford unlimited power to reuse tiles. Our second result is a positive one:
we construct a set of tiles that can simulate a Turing machine with space bound
s and time bound t, while ensuring that no intermediate assembly grows larger
than O(s), rather than O(s * t) as required by the standard Turing machine
simulation with tiles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2755</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2755</id><created>2010-02-14</created><authors><author><keyname>Kisku</keyname><forenames>Dakshina Ranjan</forenames></author><author><keyname>Sing</keyname><forenames>Jamuna Kanta</forenames></author><author><keyname>Gupta</keyname><forenames>Phalguni</forenames></author></authors><title>Multibiometrics Belief Fusion</title><categories>cs.CV cs.AI</categories><comments>4 pages, 3 figures</comments><acm-class>D.2.2; I.2.10</acm-class><journal-ref>ICMV 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a multimodal biometric system through Gaussian Mixture
Model (GMM) for face and ear biometrics with belief fusion of the estimated
scores characterized by Gabor responses and the proposed fusion is accomplished
by Dempster-Shafer (DS) decision theory. Face and ear images are convolved with
Gabor wavelet filters to extracts spatially enhanced Gabor facial features and
Gabor ear features. Further, GMM is applied to the high-dimensional Gabor face
and Gabor ear responses separately for quantitive measurements. Expectation
Maximization (EM) algorithm is used to estimate density parameters in GMM. This
produces two sets of feature vectors which are then fused using Dempster-Shafer
theory. Experiments are conducted on multimodal database containing face and
ear images of 400 individuals. It is found that use of Gabor wavelet filters
along with GMM and DS theory can provide robust and efficient multimodal fusion
strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2769</identifier>
 <datestamp>2010-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2769</id><created>2010-02-14</created><authors><author><keyname>Opthof</keyname><forenames>Tobias</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Caveats for the journal and field normalizations in the CWTS (&quot;Leiden&quot;)
  evaluations of research performance</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Center for Science and Technology Studies at Leiden University advocates
the use of specific normalizations for assessing research performance with
reference to a world average. The Journal Citation Score (JCS) and Field
Citation Score (FCS) are averaged for the research group or individual
researcher under study, and then these values are used as denominators of the
(mean) Citations per publication (CPP). Thus, this normalization is based on
dividing two averages. This procedure only generates a legitimate indicator in
the case of underlying normal distributions. Given the skewed distributions
under study, one should average the observed versus expected values which are
to be divided first for each publication. We show the effects of the Leiden
normalization for a recent evaluation where we happened to have access to the
underlying data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2780</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2780</id><created>2010-02-14</created><authors><author><keyname>Salakhutdinov</keyname><forenames>Ruslan</forenames></author><author><keyname>Srebro</keyname><forenames>Nathan</forenames></author></authors><title>Collaborative Filtering in a Non-Uniform World: Learning with the
  Weighted Trace Norm</title><categories>cs.LG</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that matrix completion with trace-norm regularization can be
significantly hurt when entries of the matrix are sampled non-uniformly. We
introduce a weighted version of the trace-norm regularizer that works well also
with non-uniform sampling. Our experimental results demonstrate that the
weighted trace-norm regularization indeed yields significant gains on the
(highly non-uniformly sampled) Netflix dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2798</identifier>
 <datestamp>2010-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2798</id><created>2010-02-14</created><updated>2010-02-24</updated><authors><author><keyname>Formato</keyname><forenames>Richard A.</forenames></author></authors><title>Comparative Results: Group Search Optimizer and Central Force
  Optimization</title><categories>cs.OH</categories><comments>Includes detailed numerical results and source code in appendices.
  Update 02-24-10: Replaces Fig. A2(b) for improved visualization; corrects
  minor typos (note that trajectory plots were removed to meet file size
  restrictions - see Ver. 1 for complete set)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note compares the performance of two multidimensional search and
optimization algorithms: Group Search Optimizer and Central Force Optimization.
GSO is a new state-of-the-art algorithm that has gained some notoriety,
consequently providing an excellent yardstick for measuring the performance of
other algorithms. CFO is a novel deterministic metaheuristic that has performed
well against GSO in previous tests. The CFO implementation reported here
includes architectural improvements in errant probe retrieval and decision
space adaptation that result in even better performance. Detailed results are
provided for the twenty-three function benchmark suite used to evaluate GSO.
CFO performs better than or essentially as well as GSO on twenty functions and
nearly as well on one of the remaining three. Includes update 24 February 2010.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2800</identifier>
 <datestamp>2012-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2800</id><created>2010-02-14</created><updated>2010-09-28</updated><authors><author><keyname>Brattka</keyname><forenames>Vasco</forenames></author><author><keyname>de Brecht</keyname><forenames>Matthew</forenames></author><author><keyname>Pauly</keyname><forenames>Arno</forenames></author></authors><title>Closed Choice and a Uniform Low Basis Theorem</title><categories>math.LO cs.LO</categories><journal-ref>Annals of Pure and Applied Logic 163:8 (2012) 986--1008</journal-ref><doi>10.1016/j.apal.2011.12.020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study closed choice principles for different spaces. Given information
about what does not constitute a solution, closed choice determines a solution.
We show that with closed choice one can characterize several models of
hypercomputation in a uniform framework using Weihrauch reducibility. The
classes of functions which are reducible to closed choice of the singleton
space, of the natural numbers, of Cantor space and of Baire space correspond to
the class of computable functions, of functions computable with finitely many
mind changes, of weakly computable functions and of effectively Borel
measurable functions, respectively. We also prove that all these classes
correspond to classes of non-deterministically computable functions with the
respective spaces as advice spaces. Moreover, we prove that closed choice on
Euclidean space can be considered as &quot;locally compact choice&quot; and it is
obtained as product of closed choice on the natural numbers and on Cantor
space. We also prove a Quotient Theorem for compact choice which shows that
single-valued functions can be &quot;divided&quot; by compact choice in a certain sense.
Another result is the Independent Choice Theorem, which provides a uniform
proof that many choice principles are closed under composition. Finally, we
also study the related class of low computable functions, which contains the
class of weakly computable functions as well as the class of functions
computable with finitely many mind changes. As one main result we prove a
uniform version of the Low Basis Theorem that states that closed choice on
Cantor space (and the Euclidean space) is low computable. We close with some
related observations on the Turing jump operation and its initial topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2813</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2813</id><created>2010-02-14</created><updated>2010-04-05</updated><authors><author><keyname>Jose</keyname><forenames>Jubin</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Distributed Rate Allocation for Wireless Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>39 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a distributed algorithm for rate allocation in wireless
networks that achieves the same throughput region as optimal centralized
algorithms. This cross-layer algorithm jointly performs medium access control
(MAC) and physical-layer rate adaptation. The paper establishes that this
algorithm is throughput-optimal for general rate regions. In contrast to on-off
scheduling, rate allocation enables optimal utilization of physical-layer
schemes by scheduling multiple rate levels. The algorithm is based on local
queue-length information, and thus the algorithm is of significant practical
value. The algorithm requires that each link can determine the global
feasibility of increasing its current data-rate. In many classes of networks,
any one link's data-rate primarily impacts its neighbors and this impact decays
with distance. Hence, local exchanges can provide the information needed to
determine feasibility. Along these lines, the paper discusses the potential use
of existing physical-layer control messages to determine feasibility. This can
be considered as a technique analogous to carrier sensing in CSMA (Carrier
Sense Multiple Access) networks. An important application of this algorithm is
in multiple-band multiple-radio throughput-optimal distributed scheduling for
white-space networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2827</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2827</id><created>2010-02-15</created><updated>2011-06-28</updated><authors><author><keyname>Lochin</keyname><forenames>Emmanuel</forenames></author><author><keyname>Perennou</keyname><forenames>Tanguy</forenames></author><author><keyname>Dairaine</keyname><forenames>Laurent</forenames></author></authors><title>When Should I Use Network Emulation?</title><categories>cs.NI</categories><acm-class>C.4</acm-class><doi>10.1007/s12243-011-0268-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design and development of a complex system requires an adequate
methodology and efficient instrumental support in order to early detect and
correct anomalies in the functional and non-functional properties of the tested
protocols. Among the various tools used to provide experimental support for
such developments, network emulation relies on real-time production of
impairments on real traffic according to a communication model, either
realistically or not.
  This paper aims at simply presenting to newcomers in network emulation
(students, engineers, ...) basic principles and practices illustrated with a
few commonly used tools. The motivation behind is to fill a gap in terms of
introductory and pragmatic papers in this domain.
  The study particularly considers centralized approaches, allowing cheap and
easy implementation in the context of research labs or industrial developments.
In addition, an architectural model for emulation systems is proposed, defining
three complementary levels, namely hardware, impairment and model levels. With
the help of this architectural framework, various existing tools are situated
and described. Various approaches for modeling the emulation actions are
studied, such as impairment-based scenarios and virtual architectures,
real-time discrete simulation and trace-based systems. Those modeling
approaches are described and compared in terms of services and we study their
ability to respond to various designer needs to assess when emulation is
needed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2829</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2829</id><created>2010-02-15</created><authors><author><keyname>Kumar</keyname><forenames>NR Shashi</forenames></author><author><keyname>Pushpavathi</keyname><forenames>TP</forenames></author><author><keyname>Selvarani</keyname><forenames>R</forenames></author></authors><title>Dynamic Cognitive Process Application of Blooms Taxonomy for Complex
  Software Design in the Cognitive Domain</title><categories>cs.SE</categories><comments>13 pages, 6 figures</comments><journal-ref>Awarded as the Best paper, International Conference, Team Tech,
  IISc., pp 101, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software design in Software Engineering is a critical and dynamic cognitive
process. Accurate and flawless system design will lead to fast coding and early
completion of a software project. Blooms taxonomy classifies cognitive domain
into six dynamic levels such as Knowledge at base level to Comprehension,
Application, Analysis, Synthesis and Evaluation at the highest level in the
order of increasing complexity. A case study indicated in this paper is a gira
system, which is a gprs based Intranet Remote Administration which monitors and
controls the intranet from a mobile device. This paper investigates from this
case study that the System Design stage in Software Engineering uses all the
six levels of Blooms Taxonomy. The application of the highest levels of Blooms
Taxonomy such as Synthesis and Evaluation in the design of gira indicates that
Software Design in Software Development Life Cycle is a complex and critical
cognitive process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2858</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2858</id><created>2010-02-15</created><updated>2010-08-14</updated><authors><author><keyname>Franceschet</keyname><forenames>Massimo</forenames></author></authors><title>PageRank: Standing on the shoulders of giants</title><categories>cs.IR cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  PageRank is a Web page ranking technique that has been a fundamental
ingredient in the development and success of the Google search engine. The
method is still one of the many signals that Google uses to determine which
pages are most important. The main idea behind PageRank is to determine the
importance of a Web page in terms of the importance assigned to the pages
hyperlinking to it. In fact, this thesis is not new, and has been previously
successfully exploited in different contexts. We review the PageRank method and
link it to some renowned previous techniques that we have found in the fields
of Web information retrieval, bibliometrics, sociometry, and econometrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2864</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2864</id><created>2010-02-15</created><authors><author><keyname>Aceto</keyname><forenames>Luca</forenames><affiliation>Reykjavik University</affiliation></author><author><keyname>Cimini</keyname><forenames>Matteo</forenames><affiliation>Reykjavik University</affiliation></author><author><keyname>Ingolfsdottir</keyname><forenames>Anna</forenames><affiliation>Reykjavik University</affiliation></author></authors><title>A Bisimulation-based Method for Proving the Validity of Equations in
  GSOS Languages</title><categories>cs.LO</categories><journal-ref>EPTCS 18, 2010, pp. 1-16</journal-ref><doi>10.4204/EPTCS.18.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a bisimulation-based method for establishing the
soundness of equations between terms constructed using operations whose
semantics is specified by rules in the GSOS format of Bloom, Istrail and Meyer.
The method is inspired by de Simone's FH-bisimilarity and uses transition rules
as schematic transitions in a bisimulation-like relation between open terms.
The soundness of the method is proven and examples showing its applicability
are provided. The proposed bisimulation-based proof method is incomplete, but
the article offers some completeness results for restricted classes of GSOS
specifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2867</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2867</id><created>2010-02-15</created><authors><author><keyname>Johansson</keyname><forenames>Magnus</forenames><affiliation>Uppsala University</affiliation></author><author><keyname>Victor</keyname><forenames>Bj&#xf6;rn</forenames><affiliation>Uppsala University</affiliation></author><author><keyname>Parrow</keyname><forenames>Joachim</forenames><affiliation>Uppsala University</affiliation></author></authors><title>A Fully Abstract Symbolic Semantics for Psi-Calculi</title><categories>cs.LO</categories><journal-ref>EPTCS 18, 2010, pp. 17-31</journal-ref><doi>10.4204/EPTCS.18.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a symbolic transition system and bisimulation equivalence for
psi-calculi, and show that it is fully abstract with respect to bisimulation
congruence in the non-symbolic semantics.
  A psi-calculus is an extension of the pi-calculus with nominal data types for
data structures and for logical assertions representing facts about data. These
can be transmitted between processes and their names can be statically scoped
using the standard pi-calculus mechanism to allow for scope migrations.
Psi-calculi can be more general than other proposed extensions of the
pi-calculus such as the applied pi-calculus, the spi-calculus, the fusion
calculus, or the concurrent constraint pi-calculus.
  Symbolic semantics are necessary for an efficient implementation of the
calculus in automated tools exploring state spaces, and the full abstraction
property means the semantics of a process does not change from the original.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2868</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2868</id><created>2010-02-15</created><authors><author><keyname>Mousavi</keyname><forenames>MohammadReza</forenames><affiliation>Eindhoven University of Technology</affiliation></author></authors><title>Causality in the Semantics of Esterel: Revisited</title><categories>cs.LO cs.PL</categories><journal-ref>EPTCS 18, 2010, pp. 32-45</journal-ref><doi>10.4204/EPTCS.18.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We re-examine the challenges concerning causality in the semantics of Esterel
and show that they pertain to the known issues in the semantics of Structured
Operational Semantics with negative premises. We show that the solutions
offered for the semantics of SOS also provide answers to the semantic
challenges of Esterel and that they satisfy the intuitive requirements set by
the language designers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2869</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2869</id><created>2010-02-15</created><authors><author><keyname>Bonchi</keyname><forenames>Filippo</forenames><affiliation>CWI Amsterdam</affiliation></author><author><keyname>Gadducci</keyname><forenames>Fabio</forenames><affiliation>Universit&#xe0; di Pisa</affiliation></author><author><keyname>Monreale</keyname><forenames>Giacoma Valentina</forenames><affiliation>Universit&#xe0; di Pisa</affiliation></author></authors><title>On Barbs and Labels in Reactive Systems</title><categories>cs.LO</categories><journal-ref>EPTCS 18, 2010, pp. 46-61</journal-ref><doi>10.4204/EPTCS.18.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reactive systems (RSs) represent a meta-framework aimed at deriving
behavioral congruences for those computational formalisms whose operational
semantics is provided by reduction rules. RSs proved a flexible specification
device, yet so far most of the efforts dealing with their behavioural semantics
focused on idem pushouts (IPOs) and saturated (also known as dynamic)
bisimulations. In this paper we introduce a novel, intermediate behavioural
equivalence: L-bisimilarity, which is able to recast both its IPO and saturated
counterparts. The equivalence is parametric with respect to a set L of RSs
labels, and it is shown that under mild conditions on L it is indeed a
congruence. Furthermore, L-bisimilarity can also recast the notion of barbed
semantics for RSs, proposed by the same authors in a previous paper. In order
to provide a suitable test-bed, we instantiate our proposal by addressing the
semantics of (asynchronous) CCS and of the calculus of mobile ambients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2871</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2871</id><created>2010-02-15</created><authors><author><keyname>Phillips</keyname><forenames>Iain</forenames><affiliation>Imperial College London</affiliation></author><author><keyname>Ulidowski</keyname><forenames>Irek</forenames><affiliation>University of Leicester</affiliation></author></authors><title>Reverse Bisimulations on Stable Configuration Structures</title><categories>cs.LO</categories><journal-ref>EPTCS 18, 2010, pp. 62-76</journal-ref><doi>10.4204/EPTCS.18.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The relationships between various equivalences on configuration structures,
including interleaving bisimulation (IB), step bisimulation (SB) and hereditary
history-preserving (HH) bisimulation, have been investigated by van Glabbeek
and Goltz (and later Fecher). Since HH bisimulation may be characterised by the
use of reverse as well as forward transitions, it is of interest to investigate
forms of IB and SB where both forward and reverse transitions are allowed. We
give various characterisations of reverse SB, showing that forward steps do not
add extra power. We strengthen Bednarczyk's result that, in the absence of
auto-concurrency, reverse IB is as strong as HH bisimulation, by showing that
we need only exclude auto-concurrent events at the same depth in the
configuration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2872</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2872</id><created>2010-02-15</created><authors><author><keyname>Dowek</keyname><forenames>Gilles</forenames><affiliation>&#xc9;cole Polytechnique and INRIA</affiliation></author><author><keyname>Mu&#xf1;oz</keyname><forenames>C&#xe9;sar</forenames><affiliation>National Institute of Aerospace</affiliation></author><author><keyname>Rocha</keyname><forenames>Camilo</forenames><affiliation>University of Illinois</affiliation></author></authors><title>Rewriting Logic Semantics of a Plan Execution Language</title><categories>cs.PL cs.LO</categories><journal-ref>EPTCS 18, 2010, pp. 77-91</journal-ref><doi>10.4204/EPTCS.18.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Plan Execution Interchange Language (PLEXIL) is a synchronous language
developed by NASA to support autonomous spacecraft operations. In this paper,
we propose a rewriting logic semantics of PLEXIL in Maude, a high-performance
logical engine. The rewriting logic semantics is by itself a formal interpreter
of the language and can be used as a semantic benchmark for the implementation
of PLEXIL executives. The implementation in Maude has the additional benefit of
making available to PLEXIL designers and developers all the formal analysis and
verification tools provided by Maude. The formalization of the PLEXIL semantics
in rewriting logic poses an interesting challenge due to the synchronous nature
of the language and the prioritized rules defining its semantics. To overcome
this difficulty, we propose a general procedure for simulating synchronous set
relations in rewriting logic that is sound and, for deterministic relations,
complete. We also report on two issues at the design level of the original
PLEXIL semantics that were identified with the help of the executable
specification in Maude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2873</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2873</id><created>2010-02-15</created><authors><author><keyname>Reniers</keyname><forenames>Michel A.</forenames><affiliation>Eindhoven University of Technology</affiliation></author><author><keyname>Willemse</keyname><forenames>Tim A. C.</forenames><affiliation>Eindhoven University of Technology</affiliation></author></authors><title>Analysis of Boolean Equation Systems through Structure Graphs</title><categories>cs.LO cs.FL</categories><journal-ref>EPTCS 18, 2010, pp. 92-107</journal-ref><doi>10.4204/EPTCS.18.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyse the problem of solving Boolean equation systems through the use of
structure graphs. The latter are obtained through an elegant set of
Plotkin-style deduction rules. Our main contribution is that we show that
equation systems with bisimilar structure graphs have the same solution. We
show that our work conservatively extends earlier work, conducted by Keiren and
Willemse, in which dependency graphs were used to analyse a subclass of Boolean
equation systems, viz., equation systems in standard recursive form. We
illustrate our approach by a small example, demonstrating the effect of
simplifying an equation system through minimisation of its structure graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2897</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2897</id><created>2010-02-15</created><authors><author><keyname>Chenouard</keyname><forenames>Raphael</forenames><affiliation>LINA</affiliation></author><author><keyname>Granvilliers</keyname><forenames>Laurent</forenames><affiliation>LINA</affiliation></author><author><keyname>Soto</keyname><forenames>Ricardo</forenames><affiliation>LINA</affiliation></author></authors><title>Model-Driven Constraint Programming</title><categories>cs.AI</categories><proxy>ccsd hal-00456549</proxy><journal-ref>International Conference on Principles and Practice of Declarative
  Programming, Valence : Spain (2008)</journal-ref><doi>10.1145/1389449.1389479</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constraint programming can definitely be seen as a model-driven paradigm. The
users write programs for modeling problems. These programs are mapped to
executable models to calculate the solutions. This paper focuses on efficient
model management (definition and transformation). From this point of view, we
propose to revisit the design of constraint-programming systems. A model-driven
architecture is introduced to map solving-independent constraint models to
solving-dependent decision models. Several important questions are examined,
such as the need for a visual highlevel modeling language, and the quality of
metamodeling techniques to implement the transformations. A main result is the
s-COMMA platform that efficiently implements the chain from modeling to solving
constraint problems
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2928</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2928</id><created>2010-02-15</created><updated>2011-05-10</updated><authors><author><keyname>Ensslin</keyname><forenames>Torsten</forenames></author><author><keyname>Frommert</keyname><forenames>Mona</forenames></author></authors><title>Reconstruction of signals with unknown spectra in information field
  theory with parameter uncertainty</title><categories>astro-ph.IM astro-ph.CO cs.IT math.IT physics.data-an stat.ME</categories><comments>21 pages, 5 figures, accepted by PRD</comments><journal-ref>Phys.Rev.D83:105014,2011</journal-ref><doi>10.1103/PhysRevD.83.105014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The optimal reconstruction of cosmic metric perturbations and other signals
requires knowledge of their power spectra and other parameters. If these are
not known a priori, they have to be measured simultaneously from the same data
used for the signal reconstruction. We formulate the general problem of signal
inference in the presence of unknown parameters within the framework of
information field theory. We develop a generic parameter uncertainty
renormalized estimation (PURE) technique and address the problem of
reconstructing Gaussian signals with unknown power-spectrum with five different
approaches: (i) separate maximum-a-posteriori power spectrum measurement and
subsequent reconstruction, (ii) maximum-a-posteriori power reconstruction with
marginalized power-spectrum, (iii) maximizing the joint posterior of signal and
spectrum, (iv) guessing the spectrum from the variance in the Wiener filter
map, and (v) renormalization flow analysis of the field theoretical problem
providing the PURE filter. In all cases, the reconstruction can be described or
approximated as Wiener filter operations with assumed signal spectra derived
from the data according to the same recipe, but with differing coefficients.
All of these filters, except the renormalized one, exhibit a perception
threshold in case of a Jeffreys prior for the unknown spectrum. Data modes,
with variance below this threshold do not affect the signal reconstruction at
all. Filter (iv) seems to be similar to the so called Karhune-Loeve and
Feldman-Kaiser-Peacock estimators for galaxy power spectra used in cosmology,
which therefore should also exhibit a marginal perception threshold if
correctly implemented. We present statistical performance tests and show that
the PURE filter is superior to the others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2954</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2954</id><created>2010-02-15</created><authors><author><keyname>Nguyen</keyname><forenames>Phuong</forenames></author><author><keyname>Cook</keyname><forenames>Stephen</forenames></author></authors><title>The Complexity of Proving the Discrete Jordan Curve Theorem</title><categories>cs.LO cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Jordan Curve Theorem (JCT) states that a simple closed curve divides the
plane into exactly two connected regions. We formalize and prove the theorem in
the context of grid graphs, under different input settings, in theories of
bounded arithmetic that correspond to small complexity classes. The theory
$V^0(2)$ (corresponding to $AC^0(2)$) proves that any set of edges that form
disjoint cycles divides the grid into at least two regions. The theory $V^0$
(corresponding to $AC^0$) proves that any sequence of edges that form a simple
closed curve divides the grid into exactly two regions. As a consequence, the
Hex tautologies and the st-connectivity tautologies have polynomial size
$AC^0(2)$-Frege-proofs, which improves results of Buss which only apply to the
stronger proof system $TC^0$-Frege.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2959</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2959</id><created>2010-02-15</created><authors><author><keyname>Saucan</keyname><forenames>Emil</forenames></author><author><keyname>Appleboim</keyname><forenames>Eli</forenames></author><author><keyname>Zeevi</keyname><forenames>Yehoshua Y.</forenames></author></authors><title>Geometric approach to sampling and communication</title><categories>cs.IT cs.CV math.DG math.IT</categories><comments>19 pages, submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Relationships that exist between the classical, Shannon-type, and
geometric-based approaches to sampling are investigated. Some aspects of coding
and communication through a Gaussian channel are considered. In particular, a
constructive method to determine the quantizing dimension in Zador's theorem is
provided. A geometric version of Shannon's Second Theorem is introduced.
Applications to Pulse Code Modulation and Vector Quantization of Images are
addressed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2964</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2964</id><created>2010-02-15</created><authors><author><keyname>Xia</keyname><forenames>Ping</forenames></author><author><keyname>Chandrasekhar</keyname><forenames>Vikram</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Open vs Closed Access Femtocells in the Uplink</title><categories>cs.IT math.IT</categories><comments>21 pages, 8 figures, 2 tables, submitted to IEEE Trans. on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Femtocells are assuming an increasingly important role in the coverage and
capacity of cellular networks. In contrast to existing cellular systems,
femtocells are end-user deployed and controlled, randomly located, and rely on
third party backhaul (e.g. DSL or cable modem). Femtocells can be configured to
be either open access or closed access. Open access allows an arbitrary nearby
cellular user to use the femtocell, whereas closed access restricts the use of
the femtocell to users explicitly approved by the owner. Seemingly, the network
operator would prefer an open access deployment since this provides an
inexpensive way to expand their network capabilities, whereas the femtocell
owner would prefer closed access, in order to keep the femtocell's capacity and
backhaul to himself. We show mathematically and through simulations that the
reality is more complicated for both parties, and that the best approach
depends heavily on whether the multiple access scheme is orthogonal (TDMA or
OFDMA, per subband) or non-orthogonal (CDMA). In a TDMA/OFDMA network,
closed-access is typically preferable at high user densities, whereas in CDMA,
open access can provide gains of more than 200% for the home user by reducing
the near-far problem experienced by the femtocell. The results of this paper
suggest that the interests of the femtocell owner and the network operator are
more compatible than typically believed, and that CDMA femtocells should be
configured for open access whereas OFDMA or TDMA femtocells should adapt to the
cellular user density.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2966</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2966</id><created>2010-02-15</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author><author><keyname>Ashikhmin</keyname><forenames>Alexei</forenames></author></authors><title>Nonbinary Quantum Cyclic and Subsystem Codes Over
  Asymmetrically-decohered Quantum Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum computers theoretically are able to solve certain problems more
quickly than any deterministic or probabilistic computers. A quantum computer
exploits the rules of quantum mechanics to speed up computations. However, one
has to mitigate the resulting noise and decoherence effects to avoid
computational errors in order to successfully build quantum computers.
  In this paper, we construct asymmetric quantum codes to protect quantum
information over asymmetric quantum channels, $\Pr Z \geq \Pr X$. Two generic
methods are presented to derive asymmetric quantum cyclic codes using the
generator polynomials and defining sets of classical cyclic codes.
Consequently, the methods allow us to construct several families of quantum
BCH, RS, and RM codes over asymmetric quantum channels. Finally, the methods
are used to construct families of asymmetric subsystem codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2970</identifier>
 <datestamp>2011-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2970</id><created>2010-02-15</created><authors><author><keyname>van Dam</keyname><forenames>Wim</forenames></author><author><keyname>Yuan</keyname><forenames>Qingqing</forenames></author></authors><title>Quantum Online Memory Checking</title><categories>quant-ph cs.CC</categories><comments>12 pages; Theory of Quantum Computation, Communication, and
  Cryptography: Fourth Workshop, TQC 2009</comments><journal-ref>Lecture Notes in Computer Science 5906 (2009), 10-19</journal-ref><doi>10.1007/978-3-642-10698-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of memory checking considers storing files on an unreliable
public server whose memory can be modified by a malicious party. The main task
is to design an online memory checker with the capability to verify that the
information on the server has not been corrupted. To store n bits of public
information, the memory checker has s private reliable bits for verification
purpose; while to retrieve each bit of public information the checker
communicates t bits with the public memory. Earlier work showed that, for
classical memory checkers, the lower bound s*t \in Omega(n) holds. In this
article we study quantum memory checkers that have s private qubits and that
are allowed to quantum query the public memory using t qubits. We prove an
exponential improvement over the classical setting by showing the existence of
a quantum checker that, using quantum fingerprints, requires only s \in O(log
n) qubits of local memory and t \in O(polylog n) qubits of communication with
the public memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2971</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2971</id><created>2010-02-15</created><authors><author><keyname>Ahmed</keyname><forenames>Ebad</forenames></author><author><keyname>Wagner</keyname><forenames>Aaron B.</forenames></author></authors><title>Erasure Multiple Descriptions</title><categories>cs.IT math.IT</categories><comments>48 pages, 2 figures, submitted to IEEE Trans. Inf. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a binary erasure version of the n-channel multiple descriptions
problem with symmetric descriptions, i.e., the rates of the n descriptions are
the same and the distortion constraint depends only on the number of messages
received. We consider the case where there is no excess rate for every k out of
n descriptions. Our goal is to characterize the achievable distortions D_1,
D_2,...,D_n. We measure the fidelity of reconstruction using two distortion
criteria: an average-case distortion criterion, under which distortion is
measured by taking the average of the per-letter distortion over all source
sequences, and a worst-case distortion criterion, under which distortion is
measured by taking the maximum of the per-letter distortion over all source
sequences. We present achievability schemes, based on random binning for
average-case distortion and systematic MDS (maximum distance separable) codes
for worst-case distortion, and prove optimality results for the corresponding
achievable distortion regions. We then use the binary erasure multiple
descriptions setup to propose a layered coding framework for multiple
descriptions, which we then apply to vector Gaussian multiple descriptions and
prove its optimality for symmetric scalar Gaussian multiple descriptions with
two levels of receivers and no excess rate for the central receiver. We also
prove a new outer bound for the general multi-terminal source coding problem
and use it to prove an optimality result for the robust binary erasure CEO
problem. For the latter, we provide a tight lower bound on the distortion for
\ell messages for any coding scheme that achieves the minimum achievable
distortion for k messages where k is less than or equal to \ell.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2975</identifier>
 <datestamp>2010-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2975</id><created>2010-02-15</created><authors><author><keyname>Del Genio</keyname><forenames>Charo I.</forenames></author><author><keyname>Kim</keyname><forenames>Hyunju</forenames></author><author><keyname>Toroczkai</keyname><forenames>Zoltan</forenames></author><author><keyname>Bassler</keyname><forenames>Kevin E.</forenames></author></authors><title>Efficient and exact sampling of simple graphs with given arbitrary
  degree sequence</title><categories>physics.soc-ph cond-mat.stat-mech cs.DS</categories><comments>8 pages, 3 figures</comments><journal-ref>PLoS ONE 5(4), e10012 (2010).</journal-ref><doi>10.1371/journal.pone.0010012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Uniform sampling from graphical realizations of a given degree sequence is a
fundamental component in simulation-based measurements of network observables,
with applications ranging from epidemics, through social networks to Internet
modeling. Existing graph sampling methods are either link-swap based
(Markov-Chain Monte Carlo algorithms) or stub-matching based (the Configuration
Model). Both types are ill-controlled, with typically unknown mixing times for
link-swap methods and uncontrolled rejections for the Configuration Model. Here
we propose an efficient, polynomial time algorithm that generates statistically
independent graph samples with a given, arbitrary, degree sequence. The
algorithm provides a weight associated with each sample, allowing the
observable to be measured either uniformly over the graph ensemble, or,
alternatively, with a desired distribution. Unlike other algorithms, this
method always produces a sample, without back-tracking or rejections. Using a
central limit theorem-based reasoning, we argue, that for large N, and for
degree sequences admitting many realizations, the sample weights are expected
to have a lognormal distribution. As examples, we apply our algorithm to
generate networks with degree sequences drawn from power-law distributions and
from binomial distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.2978</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.2978</id><created>2010-02-15</created><authors><author><keyname>Klin</keyname><forenames>Bartek</forenames><affiliation>University of Cambridge, Warsaw University</affiliation></author><author><keyname>Soboci&#x144;ski</keyname><forenames>Pawe&#x142;</forenames><affiliation>University of Southampton</affiliation></author></authors><title>Proceedings Sixth Workshop on Structural Operational Semantics</title><categories>cs.LO cs.PL</categories><journal-ref>EPTCS 18, 2010</journal-ref><doi>10.4204/EPTCS.18</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of SOS 2009, the Sixth Workshop on
Structural Operational Semantics held on the 31st of August 2009 in Bologna,
Italy as a affiliated workshop of CONCUR 2009, the 20th International
Conference on Concurrency Theory.
  Structural operational semantics (SOS) is a technique for defining
operational semantics for programming and specification languages. The workshop
is forum for researchers, students and practitioners interested in new
developments and directions for future investigations in the area of SOS. One
of the specific goals of the workshop is to provide a meeting point for the
concurrency and programming language communities. Another goal is the
dissemination of the theory and practice of SOS amongst postgraduate students
and young researchers worldwide.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3008</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3008</id><created>2010-02-16</created><authors><author><keyname>Kotnala</keyname><forenames>Abhishek</forenames></author><author><keyname>Selvarani</keyname><forenames>R.</forenames></author></authors><title>Cognitive Process of Comprehension in Requirement Analysis in IT
  Applications</title><categories>cs.SE</categories><comments>4 pages, 1 figure</comments><journal-ref>International Conference, TeamTech, IISc., pp 42, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Requirement Analysis is an important phase in software development which
deals with understanding the customers requirements. It includes the collection
of information from the customer, which is regarding the customers requirements
and what he expects from the software which is to be developed. By doing so,
you can have a better understanding of what the customer actually needs and
hence can deliver the output as per the customers requirements. Studies are
being carried out to bring about improvements in the process of requirement
analysis so that errors in software development could be minimized and hence
improved and reliable products could be delivered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3011</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3011</id><created>2010-02-16</created><authors><author><keyname>Pushpavathi</keyname><forenames>T. P.</forenames></author><author><keyname>Selvarani</keyname><forenames>R</forenames></author><author><keyname>Kumar</keyname><forenames>N. R. Shashi</forenames></author></authors><title>GPRS Video Streaming Surveillance System GVSS</title><categories>cs.CR</categories><comments>5 pages, 4 figures</comments><journal-ref>Journal of Research and Industry, Volume 1, pp 40-44, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Future security measures will create comfortable living environments that are
embedded with a wide range of intelligent functionalities including home
computing, entertainment, health care and security. These place stringent
requirements on the home networking architecture which integrates various
existing technologies for monitoring and control for future high security
needs. This paper discusses the design and implementation of a gvss gprs Video
Streaming Surveillance System system, which integrates various existing
technologies for providing security for smart home environments. This system
provides security for office, home and other buildings where high security is
required.This allows the mobile user to track the activities from a particular
location. The system will send snapshots of the video and stores them in
different formats. It is also possible to display the time with the image when
it was captured in the gprs enabled mobiles. This system is implemented using
J2me Technology
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3015</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3015</id><created>2010-02-16</created><authors><author><keyname>R.</keyname><forenames>Shashi Kumar N.</forenames></author><author><keyname>Selvarani</keyname><forenames>R.</forenames></author><author><keyname>P</keyname><forenames>Pushpavathi T.</forenames></author></authors><title>GPRS Based Intranet Remote Administration GIRA</title><categories>cs.SE</categories><comments>4 pages, 2 figures</comments><journal-ref>Journal of Research and Industry, Volume 1, pp 36-39, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a world of increasing mobility, there is a growing need for people to
communicate with each other and have timely access to information regardless of
the location of the individuals or the information. With the advent of moblle
technology, the way of communication has changed. The gira system is basically
a mobile phone technology service. In this paper we discuss about a novel local
area network control system called gprs based Intranet Remote Administration
gira. This system finds application in a mobile handset. With this system, a
network administrator will have an effective remote control over the network.
gira system is developed using gprs, gcf Generic Connection Framework of j2me,
sockets and rmi technologies
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3023</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3023</id><created>2010-02-16</created><authors><author><keyname>Chenouard</keyname><forenames>Raphael</forenames><affiliation>LINA</affiliation></author><author><keyname>Granvilliers</keyname><forenames>Laurent</forenames><affiliation>LINA</affiliation></author><author><keyname>Soto</keyname><forenames>Ricardo</forenames><affiliation>LINA</affiliation></author></authors><title>Rewriting Constraint Models with Metamodels</title><categories>cs.AI</categories><proxy>ccsd hal-00456824</proxy><journal-ref>The eight symposium on abstraction, reformulation, and
  approximation, Lake Arrowhead : United States (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important challenge in constraint programming is to rewrite constraint
models into executable programs calculat- ing the solutions. This phase of
constraint processing may require translations between constraint programming
lan- guages, transformations of constraint representations, model
optimizations, and tuning of solving strategies. In this paper, we introduce a
pivot metamodel describing the common fea- tures of constraint models including
different kinds of con- straints, statements like conditionals and loops, and
other first-class elements like object classes and predicates. This metamodel
is general enough to cope with the constructions of many languages, from
object-oriented modeling languages to logic languages, but it is independent
from them. The rewriting operations manipulate metamodel instances apart from
languages. As a consequence, the rewriting operations apply whatever languages
are selected and they are able to manage model semantic information. A bridge
is created between the metamodel space and languages using parsing techniques.
Tools from the software engineering world can be useful to implement this
framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3024</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3024</id><created>2010-02-16</created><authors><author><keyname>Bachoc</keyname><forenames>Christine</forenames><affiliation>IMB</affiliation></author><author><keyname>Zemor</keyname><forenames>Gilles</forenames><affiliation>IMB</affiliation></author></authors><title>Bounds for binary codes relative to pseudo-distances of k points</title><categories>cs.IT math.IT</categories><proxy>ccsd hal-00456568</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply Schrijver's semidefinite programming method to obtain improved upper
bounds on generalized distances and list decoding radii of binary codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3031</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3031</id><created>2010-02-16</created><authors><author><keyname>Selvarani</keyname><forenames>R.</forenames></author><author><keyname>Banu</keyname><forenames>Wahida</forenames></author><author><keyname>Prasad</keyname><forenames>Kamakshi</forenames></author></authors><title>Quantifying the Deign Quality of Object Oriented System The metric based
  rules and heuristic</title><categories>cs.SE</categories><comments>8 pages, 2 figures</comments><journal-ref>National Conference on Advanced Software Engineering, pp 54-62,
  2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design structure of OO software has decisive impact on its quality. The
design must be strongly correlated with quality characteristics like
analyzability, changeability, stability and testability, which are important
for maintaining the system. But due to the diversity and complexity of the
design properties of OO system e.g. Polymorphism, encapsulation, coupling it
becomes cumbersome.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3047</identifier>
 <datestamp>2010-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3047</id><created>2010-02-16</created><updated>2010-04-28</updated><authors><author><keyname>Fawaz</keyname><forenames>Nadia</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>On the Non-Coherent Wideband Multipath Fading Relay Channel</title><categories>cs.IT math.IT</categories><comments>8 pages, 4 figures, longer version (including proof) of the paper in
  Proc. of IEEE ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the multipath fading relay channel in the limit of a large
bandwidth, and in the non-coherent setting, where the channel state is unknown
to all terminals, including the relay and the destination. We propose a
hypergraph model of the wideband multipath fading relay channel, and show that
its min-cut is achieved by a non-coherent peaky frequency binning scheme. The
so-obtained lower bound on the capacity of the wideband multipath fading relay
channel turns out to coincide with the block-Markov lower bound on the capacity
of the wideband frequency-division Gaussian (FD-AWGN) relay channel. In certain
cases, this achievable rate also meets the cut-set upper-bound, and thus
reaches the capacity of the non-coherent wideband multipath fading relay
channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3065</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3065</id><created>2010-02-16</created><authors><author><keyname>Ozgur</keyname><forenames>Ayfer</forenames></author><author><keyname>Leveque</keyname><forenames>Olivier</forenames></author><author><keyname>Tse</keyname><forenames>David</forenames></author></authors><title>Linear Capacity Scaling in Wireless Networks: Beyond Physical Limits?</title><categories>cs.IT math.IT</categories><comments>10 pages, 5 figures, in Proc. of IEEE Information Theory and
  Applications Workshop, Feb. 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the role of cooperation in wireless networks subject to a
spatial degrees of freedom limitation. To address the worst case scenario, we
consider a free-space line-of-sight type environment with no scattering and no
fading. We identify three qualitatively different operating regimes that are
determined by how the area of the network A, normalized with respect to the
wavelength lambda, compares to the number of users n. In networks with
sqrt{A}/lambda &lt; sqrt{n}, the limitation in spatial degrees of freedom does not
allow to achieve a capacity scaling better than sqrt{n} and this performance
can be readily achieved by multi-hopping. This result has been recently shown
by Franceschetti et al. However, for networks with sqrt{A}/lambda &gt; sqrt{n},
the number of available degrees of freedom is min(n, sqrt{A}/lambda), larger
that what can be achieved by multi-hopping. We show that the optimal capacity
scaling in this regime is achieved by hierarchical cooperation. In particular,
in networks with sqrt{A}/lambda&gt; n, hierarchical cooperation can achieve linear
scaling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3074</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3074</id><created>2010-02-16</created><authors><author><keyname>Sale</keyname><forenames>Arthur</forenames></author><author><keyname>Couture</keyname><forenames>Marc</forenames></author><author><keyname>Rodrigues</keyname><forenames>Eloy</forenames></author><author><keyname>Carr</keyname><forenames>Leslie</forenames></author><author><keyname>Harnad</keyname><forenames>Stevan</forenames></author></authors><title>Open Access Mandates and the &quot;Fair Dealing&quot; Button</title><categories>cs.DL</categories><comments>12 pages, 5 figures, 32 references. To appear in &quot;Dynamic Fair
  Dealing: Creating Canadian Culture Online&quot; (Rosemary J. Coombe &amp; Darren
  Wershler, Eds.)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe the &quot;Fair Dealing Button,&quot; a feature designed for authors who
have deposited their papers in an Open Access Institutional Repository but have
deposited them as &quot;Closed Access&quot; (meaning only the metadata are visible and
retrievable, not the full eprint) rather than Open Access. The Button allows
individual users to request and authors to provide a single eprint via
semi-automated email. The purpose of the Button is to tide over research usage
needs during any publisher embargo on Open Access and, more importantly, to
make it possible for institutions to adopt the
&quot;Immediate-Deposit/Optional-Access&quot; Mandate, without exceptions or opt-outs,
instead of a mandate that allows delayed deposit or deposit waivers, depending
on publisher permissions or embargoes (or no mandate at all). This is only
&quot;Almost-Open Access,&quot; but in facilitating exception-free immediate-deposit
mandates it will accelerate the advent of universal Open Access.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3077</identifier>
 <datestamp>2010-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3077</id><created>2010-02-16</created><updated>2010-05-31</updated><authors><author><keyname>Mezzarobba</keyname><forenames>Marc</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>NumGfun: a Package for Numerical and Analytic Computation with D-finite
  Functions</title><categories>cs.SC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article describes the implementation in the software package NumGfun of
classical algorithms that operate on solutions of linear differential equations
or recurrence relations with polynomial coefficients, including what seems to
be the first general implementation of the fast high-precision numerical
evaluation algorithms of Chudnovsky &amp; Chudnovsky. In some cases, our
descriptions contain improvements over existing algorithms. We also provide
references to relevant ideas not currently used in NumGfun.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3078</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3078</id><created>2010-02-16</created><authors><author><keyname>Chenouard</keyname><forenames>Raphael</forenames><affiliation>LINA</affiliation></author><author><keyname>Granvilliers</keyname><forenames>Laurent</forenames><affiliation>LINA</affiliation></author><author><keyname>Soto</keyname><forenames>Ricardo</forenames><affiliation>LINA</affiliation></author></authors><title>Using ATL to define advanced and flexible constraint model
  transformations</title><categories>cs.AI</categories><proxy>ccsd hal-00456940</proxy><journal-ref>MtATL2009, Nantes : France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transforming constraint models is an important task in re- cent constraint
programming systems. User-understandable models are defined during the modeling
phase but rewriting or tuning them is manda- tory to get solving-efficient
models. We propose a new architecture al- lowing to define bridges between any
(modeling or solver) languages and to implement model optimizations. This
architecture follows a model- driven approach where the constraint modeling
process is seen as a set of model transformations. Among others, an interesting
feature is the def- inition of transformations as concept-oriented rules, i.e.
based on types of model elements where the types are organized into a hierarchy
called a metamodel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3083</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3083</id><created>2010-02-16</created><authors><author><keyname>Guo</keyname><forenames>Hai-Feng</forenames></author><author><keyname>Zheng</keyname><forenames>Wen</forenames></author><author><keyname>Subramaniam</keyname><forenames>Mahadevan</forenames></author></authors><title>L2C2: Logic-based LSC Consistency Checking</title><categories>cs.LO</categories><comments>To be included in the on-line proceedings of WLPE'2009</comments><journal-ref>WLPE 2009 proceedings</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Live sequence charts (LSCs) have been proposed as an inter-object
scenario-based specification and visual programming language for reactive
systems. In this paper, we introduce a logic-based framework to check the
consistency of an LSC specification. An LSC simulator has been implemented in
logic programming, utilizing a memoized depth-first search strategy, to show
how a reactive system in LSCs would response to a set of external event
sequences. A formal notation is defined to specify external event sequences,
extending the regular expression with a parallel operator and a testing
control. The parallel operator allows interleaved parallel external events to
be tested in LSCs simultaneously; while the testing control provides users to a
new approach to specify and test certain temporal properties (e.g., CTL
formula) in a form of LSC. Our framework further provides either a state
transition graph or a failure trace to justify the consistency checking
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3084</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3084</id><created>2010-02-16</created><updated>2010-04-16</updated><authors><author><keyname>Coffman</keyname><forenames>Ed</forenames></author><author><keyname>Robert</keyname><forenames>Philippe</forenames></author><author><keyname>Simatos</keyname><forenames>Florian</forenames></author><author><keyname>Tarumi</keyname><forenames>Shuzo</forenames></author><author><keyname>Zussman</keyname><forenames>Gil</forenames></author></authors><title>Channel Fragmentation in Dynamic Spectrum Access Systems - a Theoretical
  Study</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic Spectrum Access systems exploit temporarily available spectrum
(`white spaces') and can spread transmissions over a number of non-contiguous
sub-channels. Such methods are highly beneficial in terms of spectrum
utilization. However, excessive fragmentation degrades performance and hence
off-sets the benefits. Thus, there is a need to study these processes so as to
determine how to ensure acceptable levels of fragmentation. Hence, we present
experimental and analytical results derived from a mathematical model. We model
a system operating at capacity serving requests for bandwidth by assigning a
collection of gaps (sub-channels) with no limitations on the fragment size. Our
main theoretical result shows that even if fragments can be arbitrarily small,
the system does not degrade with time. Namely, the average total number of
fragments remains bounded. Within the very difficult class of dynamic
fragmentation models (including models of storage fragmentation), this result
appears to be the first of its kind. Extensive experimental results describe
behavior, at times unexpected, of fragmentation under different algorithms. Our
model also applies to dynamic linked-list storage allocation, and provides a
novel analysis in that domain. We prove that, interestingly, the 50% rule of
the classical (non-fragmented) allocation model carries over to our model.
Overall, the paper provides insights into the potential behavior of practical
fragmentation algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3086</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3086</id><created>2010-02-16</created><authors><author><keyname>Ortega</keyname><forenames>Pedro A.</forenames></author><author><keyname>Braun</keyname><forenames>Daniel A.</forenames></author></authors><title>Convergence of Bayesian Control Rule</title><categories>cs.AI cs.LG</categories><comments>8 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, new approaches to adaptive control have sought to reformulate the
problem as a minimization of a relative entropy criterion to obtain tractable
solutions. In particular, it has been shown that minimizing the expected
deviation from the causal input-output dependencies of the true plant leads to
a new promising stochastic control rule called the Bayesian control rule. This
work proves the convergence of the Bayesian control rule under two sufficient
assumptions: boundedness, which is an ergodicity condition; and consistency,
which is an instantiation of the sure-thing principle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3102</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3102</id><created>2010-02-16</created><updated>2010-08-10</updated><authors><author><keyname>Chakraborty</keyname><forenames>Tanmoy</forenames></author><author><keyname>Even-Dar</keyname><forenames>Eyal</forenames></author><author><keyname>Guha</keyname><forenames>Sudipto</forenames></author><author><keyname>Mansour</keyname><forenames>Yishay</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author></authors><title>Selective Call Out and Real Time Bidding</title><categories>cs.GT cs.DS</categories><comments>24 pages, 10 figures</comments><acm-class>F.2.2; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ads on the Internet are increasingly sold via ad exchanges such as
RightMedia, AdECN and Doubleclick Ad Exchange. These exchanges allow real-time
bidding, that is, each time the publisher contacts the exchange, the exchange
``calls out'' to solicit bids from ad networks. This aspect of soliciting bids
introduces a novel aspect, in contrast to existing literature. This suggests
developing a joint optimization framework which optimizes over the allocation
and well as solicitation. We model this selective call out as an online
recurrent Bayesian decision framework with bandwidth type constraints. We
obtain natural algorithms with bounded performance guarantees for several
natural optimization criteria. We show that these results hold under different
call out constraint models, and different arrival processes. Interestingly, the
paper shows that under MHR assumptions, the expected revenue of generalized
second price auction with reserve is constant factor of the expected welfare.
Also the analysis herein allow us prove adaptivity gap type results for the
adwords problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3117</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3117</id><created>2010-02-16</created><updated>2011-04-11</updated><authors><author><keyname>Halabi</keyname><forenames>Nissim</forenames></author><author><keyname>Even</keyname><forenames>Guy</forenames></author></authors><title>LP Decoding of Regular LDPC Codes in Memoryless Channels</title><categories>cs.IT math.IT</categories><comments>Extended abstract submitted to ISIT 2010. Submitted to IEEE
  Transactions on Information Theory, March, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study error bounds for linear programming decoding of regular LDPC codes.
For memoryless binary-input output-symmetric channels, we prove bounds on the
word error probability that are inverse doubly-exponential in the girth of the
factor graph. For memoryless binary-input AWGN channel, we prove lower bounds
on the threshold for regular LDPC codes whose factor graphs have logarithmic
girth under LP-decoding. Specifically, we prove a lower bound of $\sigma=0.735$
(upper bound of $\frac{Eb}{N_0}=2.67$dB) on the threshold of $(3,6)$-regular
LDPC codes whose factor graphs have logarithmic girth.
  Our proof is an extension of a recent paper of Arora, Daskalakis, and Steurer
[STOC 2009] who presented a novel probabilistic analysis of LP decoding over a
binary symmetric channel. Their analysis is based on the primal LP
representation and has an explicit connection to message passing algorithms. We
extend this analysis to any MBIOS channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3131</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3131</id><created>2010-02-16</created><updated>2011-02-07</updated><authors><author><keyname>de Carvalho</keyname><forenames>Daniel</forenames></author><author><keyname>de Falco</keyname><forenames>Lorenzo Tortora</forenames></author></authors><title>The relational model is injective for Multiplicative Exponential Linear
  Logic (without weakenings)</title><categories>cs.LO</categories><comments>36 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that for Multiplicative Exponential Linear Logic (without weakenings)
the syntactical equivalence relation on proofs induced by cut-elimination
coincides with the semantic equivalence relation on proofs induced by the
multiset based relational model: one says that the interpretation in the model
(or the semantics) is injective. We actually prove a stronger result: two
cut-free proofs of the full multiplicative and exponential fragment of linear
logic whose interpretations coincide in the multiset based relational model are
the same &quot;up to the connections between the doors of exponential boxes&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3171</identifier>
 <datestamp>2012-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3171</id><created>2010-02-17</created><updated>2012-03-16</updated><authors><author><keyname>Toorani</keyname><forenames>M.</forenames></author><author><keyname>Beheshti</keyname><forenames>A. A.</forenames></author></authors><title>SSMS - A Secure SMS Messaging Protocol for the M-payment Systems</title><categories>cs.CR cs.NI</categories><comments>6 Pages, 5 Figures</comments><msc-class>94Axx</msc-class><acm-class>E.3; K.6.5; C.2; D.4.6; H.4.3; K.4.4; C.1.3</acm-class><journal-ref>Proceedings of the 13th IEEE Symposium on Computers and
  Communications (ISCC'08), pp.700-705, July 2008</journal-ref><doi>10.1109/ISCC.2008.4625610</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The GSM network with the greatest worldwide number of users, succumbs to
several security vulnerabilities. The short message service (SMS) is one of its
superior and well-tried services with a global availability in the GSM
networks. The main contribution of this paper is to introduce a new secure
application layer protocol, called SSMS, to efficiently embed the desired
security attributes in the SMS messages to be used as a secure bearer in the
m-payment systems. SSMS efficiently embeds the confidentiality, integrity,
authentication, and non-repudiation in the SMS messages. It provides an
elliptic curve-based public key solution that uses public keys for the secret
key establishment of a symmetric encryption. It also provides the attributes of
public verification and forward secrecy. It efficiently makes the SMS messaging
suitable for the m-payment applications where the security is the great
concern.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3174</identifier>
 <datestamp>2012-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3174</id><created>2010-02-17</created><updated>2012-03-16</updated><authors><author><keyname>Amirani</keyname><forenames>M. C.</forenames></author><author><keyname>Toorani</keyname><forenames>M.</forenames></author><author><keyname>Beheshti</keyname><forenames>A. A.</forenames></author></authors><title>A new approach to content-based file type detection</title><categories>cs.LG cs.AI</categories><comments>6 Pages, 5 Figure, 2 Tables</comments><msc-class>94Axx</msc-class><acm-class>H.3.2; I.5.1; I.2.6; E.5; I.7; C.2; F.1; D.4.3</acm-class><journal-ref>Proceedings of the 13th IEEE Symposium on Computers and
  Communications (ISCC'08), pp.1103-1108, July 2008</journal-ref><doi>10.1109/ISCC.2008.4625611</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  File type identification and file type clustering may be difficult tasks that
have an increasingly importance in the field of computer and network security.
Classical methods of file type detection including considering file extensions
and magic bytes can be easily spoofed. Content-based file type detection is a
newer way that is taken into account recently. In this paper, a new
content-based method for the purpose of file type detection and file type
clustering is proposed that is based on the PCA and neural networks. The
proposed method has a good accuracy and is fast enough.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3175</identifier>
 <datestamp>2012-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3175</id><created>2010-02-17</created><updated>2012-03-16</updated><authors><author><keyname>Toorani</keyname><forenames>M.</forenames></author><author><keyname>Beheshti</keyname><forenames>A. A.</forenames></author></authors><title>Solutions to the GSM Security Weaknesses</title><categories>cs.CR cs.NI</categories><comments>6 Pages, 2 Figures</comments><msc-class>94Axx</msc-class><acm-class>C.1.3; C.2; D.4.6; K.6.5; K.6.m; E.3</acm-class><journal-ref>Proceedings of the 2nd International Conference on Next Generation
  Mobile Applications, Services, and Technologies (NGMAST'08), pp.576-581,
  Cardiff, UK, Sep. 2008</journal-ref><doi>10.1109/NGMAST.2008.88</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the mobile industry has experienced an extreme increment in number
of its users. The GSM network with the greatest worldwide number of users
succumbs to several security vulnerabilities. Although some of its security
problems are addressed in its upper generations, there are still many operators
using 2G systems. This paper briefly presents the most important security flaws
of the GSM network and its transport channels. It also provides some practical
solutions to improve the security of currently available 2G systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3176</identifier>
 <datestamp>2012-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3176</id><created>2010-02-17</created><updated>2012-03-16</updated><authors><author><keyname>Toorani</keyname><forenames>M.</forenames></author></authors><title>SMEmail - A New Protocol for the Secure E-mail in Mobile Environments</title><categories>cs.CR cs.NI</categories><comments>6 Pages, 5 Figures</comments><msc-class>94Axx</msc-class><acm-class>E.3; K.6.5; C.2; D.4.6; H.4.3; K.6.m</acm-class><journal-ref>Proceedings of the Australian Telecommunications Networks and
  Applications Conference (ATNAC'08), pp.39-44, Adelaide, Australia, Dec. 2008</journal-ref><doi>10.1109/ATNAC.2008.4783292</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The electronic mail plays an unavoidable role in the humankind
communications. With the great interest for the connection via mobile
platforms, and the growing number of vulnerabilities and attacks, it is
essential to provide suitable security solutions regarding the limitations of
resource restricted platforms. Although some solutions such as PGP and S/MIME
are currently available for the secure e-mail over the Internet, they are based
on traditional public key cryptography that involves huge computational costs.
In this paper, a new secure application-layer protocol, called SMEmail, is
introduced that provides several security attributes such as confidentiality,
integrity, authentication, non-repudiation, and forward secrecy of message
confidentiality for the electronic mails. SMEmail offers an elliptic
curve-based public key solution that uses public keys for the secure key
establishment of a symmetric encryption, and is so suitable for the resource
restricted platforms such as mobile phones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3180</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3180</id><created>2010-02-16</created><authors><author><keyname>Caruso</keyname><forenames>Fabrizio</forenames></author></authors><title>Factorization of Non-Commutative Polynomials</title><categories>cs.MS cs.SC</categories><comments>7 pages</comments><acm-class>F.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an algorithm for the factorization of non-commutative polynomials
over a field. The first sketch of this algorithm appeared in an unpublished
manuscript (literally hand written notes) by James H. Davenport more than 20
years ago. This version of the algorithm contains some improvements with
respect to the original sketch. An improved version of the algorithm has been
fully implemented in the Axiom computer algebra system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3183</identifier>
 <datestamp>2013-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3183</id><created>2010-02-16</created><updated>2013-11-24</updated><authors><author><keyname>Feldman</keyname><forenames>Vitaly</forenames></author></authors><title>A Complete Characterization of Statistical Query Learning with
  Applications to Evolvability</title><categories>cs.CC cs.LG</categories><comments>Simplified Lemma 3.8 and it's applications</comments><journal-ref>Proceedings of the 44th IEEE Symposium on Foundations of Computer
  Science, pp 375-384, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statistical query (SQ) learning model of Kearns (1993) is a natural
restriction of the PAC learning model in which a learning algorithm is allowed
to obtain estimates of statistical properties of the examples but cannot see
the examples themselves. We describe a new and simple characterization of the
query complexity of learning in the SQ learning model. Unlike the previously
known bounds on SQ learning our characterization preserves the accuracy and the
efficiency of learning. The preservation of accuracy implies that that our
characterization gives the first characterization of SQ learning in the
agnostic learning framework. The preservation of efficiency is achieved using a
new boosting technique and allows us to derive a new approach to the design of
evolutionary algorithms in Valiant's (2006) model of evolvability. We use this
approach to demonstrate the existence of a large class of monotone evolutionary
learning algorithms based on square loss performance estimation. These results
differ significantly from the few known evolutionary algorithms and give
evidence that evolvability in Valiant's model is a more versatile phenomenon
than there had been previous reason to suspect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3187</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3187</id><created>2010-02-16</created><updated>2010-02-18</updated><authors><author><keyname>Hassani</keyname><forenames>S. Hamed</forenames></author><author><keyname>Alishahi</keyname><forenames>Kasra</forenames></author><author><keyname>Urbanke</keyname><forenames>Rudiger</forenames></author></authors><title>On the scaling of Polar Codes: II. The behavior of un-polarized channels</title><categories>cs.IT math.IT</categories><comments>Submitted to ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide upper and lower bounds on the escape rate of the Bhattacharyya
process corresponding to polar codes and transmission over the the binary
erasure channel. More precisely, we bound the exponent of the number of
sub-channels whose Bhattacharyya constant falls in a fixed interval $[a,b]$.
Mathematically this can be stated as bounding the limit $\lim_{n \to \infty}
\frac{1}{n} \ln \mathbb{P}(Z_n \in [a,b])$, where $Z_n$ is the Bhattacharyya
process. The quantity $\mathbb{P}(Z_n \in [a,b])$ represents the fraction of
sub-channels that are still un-polarized at time $n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3188</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3188</id><created>2010-02-16</created><updated>2010-03-11</updated><authors><author><keyname>Lim</keyname><forenames>Sung Hoon</forenames></author><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author><author><keyname>Gamal</keyname><forenames>Abbas El</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author></authors><title>Noisy Network Coding</title><categories>cs.IT math.IT</categories><comments>33 pages, 4 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A noisy network coding scheme for sending multiple sources over a general
noisy network is presented. For multi-source multicast networks, the scheme
naturally extends both network coding over noiseless networks by Ahlswede, Cai,
Li, and Yeung, and compress-forward coding for the relay channel by Cover and
El Gamal to general discrete memoryless and Gaussian networks. The scheme also
recovers as special cases the results on coding for wireless relay networks and
deterministic networks by Avestimehr, Diggavi, and Tse, and coding for wireless
erasure networks by Dana, Gowaikar, Palanki, Hassibi, and Effros. The scheme
involves message repetition coding, relay signal compression, and simultaneous
decoding. Unlike previous compress--forward schemes, where independent messages
are sent over multiple blocks, the same message is sent multiple times using
independent codebooks as in the network coding scheme for cyclic networks.
Furthermore, the relays do not use Wyner--Ziv binning as in previous
compress-forward schemes, and each decoder performs simultaneous joint
typicality decoding on the received signals from all the blocks without
explicitly decoding the compression indices. A consequence of this new scheme
is that achievability is proved simply and more generally without resorting to
time expansion to extend results for acyclic networks to networks with cycles.
The noisy network coding scheme is then extended to general multi-source
networks by combining it with decoding techniques for interference channels.
For the Gaussian multicast network, noisy network coding improves the
previously established gap to the cutset bound. We also demonstrate through two
popular AWGN network examples that noisy network coding can outperform
conventional compress-forward, amplify-forward, and hash-forward schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3190</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3190</id><created>2010-02-16</created><authors><author><keyname>Zhu</keyname><forenames>Quanyan</forenames></author><author><keyname>Fung</keyname><forenames>Carol J.</forenames></author><author><keyname>Boutaba</keyname><forenames>Raouf</forenames></author><author><keyname>Basar</keyname><forenames>Tamer</forenames></author></authors><title>A Distributed Sequential Algorithm for Collaborative Intrusion Detection
  Networks</title><categories>cs.CR cs.NI</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Collaborative intrusion detection networks are often used to gain better
detection accuracy and cost efficiency as compared to a single host-based
intrusion detection system (IDS). Through cooperation, it is possible for a
local IDS to detect new attacks that may be known to other experienced
acquaintances. In this paper, we present a sequential hypothesis testing method
for feedback aggregation for each individual IDS in the net- work. Our
simulation results corroborate our theoretical results and demonstrate the
properties of cost efficiency and accuracy compared to other heuristic methods.
The analytical result on the lower-bound of the average number of acquaintances
for consultation is essential for the design and configuration of IDSs in a
collaborative environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3192</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3192</id><created>2010-02-16</created><authors><author><keyname>Zhang</keyname><forenames>Lili</forenames></author><author><keyname>Jiang</keyname><forenames>Jinhua</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea J.</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Study of Gaussian Relay Channels with Correlated Noises</title><categories>cs.IT math.IT</categories><comments>24 pages, 7 figures, submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider full-duplex and half-duplex Gaussian relay
channels where the noises at the relay and destination are arbitrarily
correlated. We first derive the capacity upper bound and the achievable rates
with three existing schemes: Decode-and-Forward (DF), Compress-and-Forward
(CF), and Amplify-and-Forward (AF). We present two capacity results under
specific noise correlation coefficients, one being achieved by DF and the other
being achieved by direct link transmission (or a special case of CF). The
channel for the former capacity result is equivalent to the traditional
Gaussian degraded relay channel and the latter corresponds to the Gaussian
reversely-degraded relay channel. For CF and AF schemes, we show that their
achievable rates are strictly decreasing functions over the negative
correlation coefficient. Through numerical comparisons under different channel
settings, we observe that although DF completely disregards the noise
correlation while the other two can potentially exploit such extra information,
none of the three relay schemes always outperforms the others over different
correlation coefficients. Moreover, the exploitation of noise correlation by CF
and AF accrues more benefit when the source-relay link is weak. This paper also
considers the optimal power allocation problem under the correlated-noise
channel setting. With individual power constraints at the relay and the source,
it is shown that the relay should use all its available power to maximize the
achievable rates under any correlation coefficient. With a total power
constraint across the source and the relay, the achievable rates are proved to
be concave functions over the power allocation factor for AF and CF under
full-duplex mode, where the closed-form power allocation strategy is derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3195</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3195</id><created>2010-02-16</created><authors><author><keyname>Hossain</keyname><forenames>M. Shahriar</forenames></author><author><keyname>Narayan</keyname><forenames>Michael</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>Naren</forenames></author></authors><title>Efficiently Discovering Hammock Paths from Induced Similarity Networks</title><categories>cs.AI cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Similarity networks are important abstractions in many information management
applications such as recommender systems, corpora analysis, and medical
informatics. For instance, by inducing similarity networks between movies rated
similarly by users, or between documents containing common terms, and or
between clinical trials involving the same themes, we can aim to find the
global structure of connectivities underlying the data, and use the network as
a basis to make connections between seemingly disparate entities. In the above
applications, composing similarities between objects of interest finds uses in
serendipitous recommendation, in storytelling, and in clinical diagnosis,
respectively. We present an algorithmic framework for traversing similarity
paths using the notion of `hammock' paths which are generalization of
traditional paths. Our framework is exploratory in nature so that, given
starting and ending objects of interest, it explores candidate objects for path
following, and heuristics to admissibly estimate the potential for paths to
lead to a desired destination. We present three diverse applications: exploring
movie similarities in the Netflix dataset, exploring abstract similarities
across the PubMed corpus, and exploring description similarities in a database
of clinical trials. Experimental results demonstrate the potential of our
approach for unstructured knowledge discovery in similarity networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3222</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3222</id><created>2010-02-17</created><authors><author><keyname>Keiren</keyname><forenames>Jeroen</forenames></author><author><keyname>Reniers</keyname><forenames>Michel A.</forenames></author><author><keyname>Willemse</keyname><forenames>Tim A. C.</forenames></author></authors><title>Structural Analysis of Boolean Equation Systems</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyse the problem of solving Boolean equation systems through the use of
structure graphs. The latter are obtained through an elegant set of
Plotkin-style deduction rules. Our main contribution is that we show that
equation systems with bisimilar structure graphs have the same solution. We
show that our work conservatively extends earlier work, conducted by Keiren and
Willemse, in which dependency graphs were used to analyse a subclass of Boolean
equation systems, viz., equation systems in standard recursive form. We
illustrate our approach by a small example, demonstrating the effect of
simplifying an equation system through minimisation of its structure graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3229</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3229</id><created>2010-02-17</created><updated>2011-08-30</updated><authors><author><keyname>Sridharan</keyname><forenames>Arun</forenames></author><author><keyname>Koksal</keyname><forenames>C. Emre</forenames></author><author><keyname>Uysal-Biyikoglu</keyname><forenames>Elif</forenames></author></authors><title>A Greedy link scheduler for Wireless Networks having Gaussian Broadcast
  and Multiple Access Channels</title><categories>cs.NI</categories><comments>Accepted for publication in IEEE/ACM Transactions on Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information theoretic Broadcast Channels (BC) and Multiple Access Channels
(MAC) enable a single node to transmit data simultaneously to multiple nodes,
and multiple nodes to transmit data simultaneously to a single node
respectively. In this paper, we address the problem of link scheduling in
multihop wireless networks containing nodes with BC and MAC capabilities. We
first propose an interference model that extends protocol interference models,
originally designed for point to point channels, to include the possibility of
BC and MAC. Due to the high complexity of optimal link schedulers, we introduce
the Multiuser Greedy Maximum Weight algorithm for link scheduling in multihop
wireless networks containing BCs and MACs. Given a network graph, we develop
new local pooling conditions and show that the performance of our algorithm can
be fully characterized using the associated parameter, the multiuser local
pooling factor. We provide examples of some network graphs, on which we apply
local pooling conditions and derive the multiuser local pooling factor. We
prove optimality of our algorithm in tree networks and show that the
exploitation of BCs and MACs improve the throughput performance considerably in
multihop wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3234</identifier>
 <datestamp>2011-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3234</id><created>2010-02-17</created><updated>2011-09-29</updated><authors><author><keyname>Vallet</keyname><forenames>Pascal</forenames></author><author><keyname>Loubaton</keyname><forenames>Philippe</forenames></author><author><keyname>Mestre</keyname><forenames>Xavier</forenames></author></authors><title>Improved subspace estimation for multivariate observations of high
  dimension: the deterministic signals case</title><categories>cs.IT math.IT</categories><comments>New version with minor corrections. The present paper is an extended
  version of a paper (same title) to appear in IEEE Trans. on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of subspace estimation in situations where the number
of available snapshots and the observation dimension are comparable in
magnitude. In this context, traditional subspace methods tend to fail because
the eigenvectors of the sample correlation matrix are heavily biased with
respect to the true ones. It has recently been suggested that this situation
(where the sample size is small compared to the observation dimension) can be
very accurately modeled by considering the asymptotic regime where the
observation dimension $M$ and the number of snapshots $N$ converge to $+\infty$
at the same rate. Using large random matrix theory results, it can be shown
that traditional subspace estimates are not consistent in this asymptotic
regime. Furthermore, new consistent subspace estimate can be proposed, which
outperform the standard subspace methods for realistic values of $M$ and $N$.
The work carried out so far in this area has always been based on the
assumption that the observations are random, independent and identically
distributed in the time domain. The goal of this paper is to propose new
consistent subspace estimators for the case where the source signals are
modelled as unknown deterministic signals. In practice, this allows to use the
proposed approach regardless of the statistical properties of the source
signals. In order to construct the proposed estimators, new technical results
concerning the almost sure location of the eigenvalues of sample covariance
matrices of Information plus Noise complex Gaussian models are established.
These results are believed to be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3238</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3238</id><created>2010-02-17</created><updated>2010-02-18</updated><authors><author><keyname>Piwowarski</keyname><forenames>Benjamin</forenames></author><author><keyname>Frommholz</keyname><forenames>Ingo</forenames></author><author><keyname>Lalmas</keyname><forenames>Mounia</forenames></author><author><keyname>van Rijsbergen</keyname><forenames>Keith</forenames></author></authors><title>Exploring a Multidimensional Representation of Documents and Queries
  (extended version)</title><categories>cs.IR</categories><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Information Retrieval (IR), whether implicitly or explicitly, queries and
documents are often represented as vectors. However, it may be more beneficial
to consider documents and/or queries as multidimensional objects. Our belief is
this would allow building &quot;truly&quot; interactive IR systems, i.e., where
interaction is fully incorporated in the IR framework.
  The probabilistic formalism of quantum physics represents events and
densities as multidimensional objects. This paper presents our first step
towards building an interactive IR framework upon this formalism, by stating
how the first interaction of the retrieval process, when the user types a
query, can be formalised. Our framework depends on a number of parameters
affecting the final document ranking. In this paper we experimentally
investigate the effect of these parameters, showing that the proposed
representation of documents and queries as multidimensional objects can compete
with standard approaches, with the additional prospect to be applied to
interactive retrieval.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3239</identifier>
 <datestamp>2014-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3239</id><created>2010-02-17</created><updated>2012-12-01</updated><authors><author><keyname>Ruozzi</keyname><forenames>Nicholas</forenames></author><author><keyname>Tatikonda</keyname><forenames>Sekhar</forenames></author></authors><title>Message-Passing Algorithms: Reparameterizations and Splittings</title><categories>cs.IT cs.AI math.IT</categories><comments>A complete rework and expansion of the previous versions</comments><journal-ref>Information Theory, IEEE Transactions on , vol.59, no.9,
  pp.5860,5881, Sept. 2013</journal-ref><doi>10.1109/TIT.2013.2259576</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The max-product algorithm, a local message-passing scheme that attempts to
compute the most probable assignment (MAP) of a given probability distribution,
has been successfully employed as a method of approximate inference for
applications arising in coding theory, computer vision, and machine learning.
However, the max-product algorithm is not guaranteed to converge to the MAP
assignment, and if it does, is not guaranteed to recover the MAP assignment.
  Alternative convergent message-passing schemes have been proposed to overcome
these difficulties. This work provides a systematic study of such
message-passing algorithms that extends the known results by exhibiting new
sufficient conditions for convergence to local and/or global optima, providing
a combinatorial characterization of these optima based on graph covers, and
describing a new convergent and correct message-passing algorithm whose
derivation unifies many of the known convergent message-passing algorithms.
  While convergent and correct message-passing algorithms represent a step
forward in the analysis of max-product style message-passing algorithms, the
conditions needed to guarantee convergence to a global optimum can be too
restrictive in both theory and practice. This limitation of convergent and
correct message-passing schemes is characterized by graph covers and
illustrated by example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3258</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3258</id><created>2010-02-17</created><authors><author><keyname>Chevallereau</keyname><forenames>Christine</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Grizzle</keyname><forenames>Jessy W.</forenames><affiliation>EECS</affiliation></author><author><keyname>Shih</keyname><forenames>Ching-Long</forenames><affiliation>EE-506</affiliation></author></authors><title>Asymptotically Stable Walking of a Five-Link Underactuated 3D Bipedal
  Robot</title><categories>cs.RO</categories><proxy>ccsd hal-00456192</proxy><journal-ref>IEEE Transactions on Robotics 25, 1 (2009) 37-50</journal-ref><doi>10.1109/TRO.2008.2010366</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents three feedback controllers that achieve an asymptotically
stable, periodic, and fast walking gait for a 3D (spatial) bipedal robot
consisting of a torso, two legs, and passive (unactuated) point feet. The
contact between the robot and the walking surface is assumed to inhibit yaw
rotation. The studied robot has 8 DOF in the single support phase and 6
actuators. The interest of studying robots with point feet is that the robot's
natural dynamics must be explicitly taken into account to achieve balance while
walking. We use an extension of the method of virtual constraints and hybrid
zero dynamics, in order to simultaneously compute a periodic orbit and an
autonomous feedback controller that realizes the orbit. This method allows the
computations to be carried out on a 2-DOF subsystem of the 8-DOF robot model.
The stability of the walking gait under closed-loop control is evaluated with
the linearization of the restricted Poincar\'e map of the hybrid zero dynamics.
Three strategies are explored. The first strategy consists of imposing a
stability condition during the search of a periodic gait by optimization. The
second strategy uses an event-based controller. In the third approach, the
effect of output selection is discussed and a pertinent choice of outputs is
proposed, leading to stabilization without the use of a supplemental
event-based controller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3282</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3282</id><created>2010-02-17</created><updated>2010-06-21</updated><authors><author><keyname>Qiu</keyname><forenames>Tian</forenames></author><author><keyname>Hadzibeganovic</keyname><forenames>Tarik</forenames></author><author><keyname>Chen</keyname><forenames>Guang</forenames></author><author><keyname>Zhong</keyname><forenames>Li-Xin</forenames></author><author><keyname>Wu</keyname><forenames>Xiao-Run</forenames></author></authors><title>Cooperation in the snowdrift game on directed small-world networks under
  self-questioning and noisy conditions</title><categories>physics.soc-ph cs.GT physics.comp-ph q-bio.PE</categories><comments>7 pages, 6 figures, 1 table</comments><doi>10.1016/j.cpc.2010.08.018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperation in the evolutionary snowdrift game with a self-questioning
updating mechanism is studied on annealed and quenched small-world networks
with directed couplings. Around the payoff parameter value $r=0.5$, we find a
size-invariant symmetrical cooperation effect. While generally suppressing
cooperation for $r&gt;0.5$ payoffs, rewired networks facilitated cooperative
behavior for $r&lt;0.5$. Fair amounts of noise were found to break the observed
symmetry and further weaken cooperation at relatively large values of $r$.
However, in the absence of noise, the self-questioning mechanism recovers
symmetrical behavior and elevates altruism even under large-reward conditions.
Our results suggest that an updating mechanism of this type is necessary to
stabilize cooperation in a spatially structured environment which is otherwise
detrimental to cooperative behavior, especially at high cost-to-benefit ratios.
Additionally, we employ component and local stability analyses to better
understand the nature of the manifested dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3299</identifier>
 <datestamp>2012-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3299</id><created>2010-02-17</created><updated>2012-03-16</updated><authors><author><keyname>Toorani</keyname><forenames>M.</forenames></author><author><keyname>Beheshti</keyname><forenames>A. A.</forenames></author></authors><title>LPKI - A Lightweight Public Key Infrastructure for the Mobile
  Environments</title><categories>cs.CR</categories><comments>6 Pages, 6 Figures</comments><msc-class>94Axx</msc-class><acm-class>E.3; K.6.5; C.2; D.4.6; H.4.3; K.4.4; C.1.3; K.6.m</acm-class><journal-ref>Proceedings of the 11th IEEE International Conference on
  Communication Systems (IEEE ICCS'08), pp.162-166, Guangzhou, China, Nov. 2008</journal-ref><doi>10.1109/ICCS.2008.4737164</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The non-repudiation as an essential requirement of many applications can be
provided by the asymmetric key model. With the evolution of new applications
such as mobile commerce, it is essential to provide secure and efficient
solutions for the mobile environments. The traditional public key cryptography
involves huge computational costs and is not so suitable for the
resource-constrained platforms. The elliptic curve-based approaches as the
newer solutions require certain considerations that are not taken into account
in the traditional public key infrastructures. The main contribution of this
paper is to introduce a Lightweight Public Key Infrastructure (LPKI) for the
constrained platforms such as mobile phones. It takes advantages of elliptic
curve cryptography and signcryption to decrease the computational costs and
communication overheads, and adapting to the constraints. All the computational
costs of required validations can be eliminated from end-entities by
introduction of a validation authority to the introduced infrastructure and
delegating validations to such a component. LPKI is so suitable for mobile
environments and for applications such as mobile commerce where the security is
the great concern.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3303</identifier>
 <datestamp>2012-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3303</id><created>2010-02-17</created><updated>2012-03-16</updated><authors><author><keyname>Toorani</keyname><forenames>M.</forenames></author><author><keyname>Beheshti</keyname><forenames>A. A.</forenames></author></authors><title>Cryptanalysis of an Efficient Signcryption Scheme with Forward Secrecy
  Based on Elliptic Curve</title><categories>cs.CR</categories><comments>5 Pages, 2 Figures</comments><msc-class>94A60</msc-class><acm-class>E.3; K.6.5; D.4.6; K.6.m</acm-class><journal-ref>Proceedings of 2008 International Conference on Computer and
  Electrical Engineering (ICCEE'08), pp.428-432, Dec. 2008</journal-ref><doi>10.1109/ICCEE.2008.147</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The signcryption is a relatively new cryptographic technique that is supposed
to fulfill the functionalities of encryption and digital signature in a single
logical step. Several signcryption schemes are proposed throughout the years,
each of them having its own problems and limitations. In this paper, the
security of a recent signcryption scheme, i.e. Hwang et al.'s scheme is
analyzed, and it is proved that it involves several security flaws and
shortcomings. Several devastating attacks are also introduced to the mentioned
scheme whereby it fails all the desired and essential security attributes of a
signcryption scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3307</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3307</id><created>2010-02-17</created><authors><author><keyname>Watanabe</keyname><forenames>Yusuke</forenames></author><author><keyname>Fukumizu</keyname><forenames>Kenji</forenames></author></authors><title>Graph Zeta Function in the Bethe Free Energy and Loopy Belief
  Propagation</title><categories>cs.AI cs.DM math-ph math.MP</categories><comments>19 pages, Annual Conference on Neural Information Processing Systems
  (NIPS 2009), together with the supplementary material</comments><journal-ref>Advances in Neural Information Processing Systems 22, pages
  2017-2025</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new approach to the analysis of Loopy Belief Propagation (LBP)
by establishing a formula that connects the Hessian of the Bethe free energy
with the edge zeta function. The formula has a number of theoretical
implications on LBP. It is applied to give a sufficient condition that the
Hessian of the Bethe free energy is positive definite, which shows
non-convexity for graphs with multiple cycles. The formula clarifies the
relation between the local stability of a fixed point of LBP and local minima
of the Bethe free energy. We also propose a new approach to the uniqueness of
LBP fixed point, and show various conditions of uniqueness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3312</identifier>
 <datestamp>2011-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3312</id><created>2010-02-17</created><updated>2011-04-27</updated><authors><author><keyname>Murugesan</keyname><forenames>Sugumar</forenames></author><author><keyname>Schniter</keyname><forenames>Philip</forenames></author><author><keyname>Shroff</keyname><forenames>Ness B.</forenames></author></authors><title>Multiuser Scheduling in a Markov-modeled Downlink using Randomly Delayed
  ARQ Feedback</title><categories>cs.IT cs.SY math.IT math.OC</categories><comments>Contains 22 pages, 6 figures and 8 tables; revised version including
  additional analytical and numerical results; work submitted, Feb 2010, to
  IEEE Transactions on Information Theory, revised April 2011; authors can be
  reached at sugumar.murugesan@asu.edu/schniter@ece.osu.edu/shroff@ece.osu.edu</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We focus on the downlink of a cellular system, which corresponds to the bulk
of the data transfer in such wireless systems. We address the problem of
opportunistic multiuser scheduling under imperfect channel state information,
by exploiting the memory inherent in the channel. In our setting, the channel
between the base station and each user is modeled by a two-state Markov chain
and the scheduled user sends back an ARQ feedback signal that arrives at the
scheduler with a random delay that is i.i.d across users and time. The
scheduler indirectly estimates the channel via accumulated delayed-ARQ feedback
and uses this information to make scheduling decisions. We formulate a
throughput maximization problem as a partially observable Markov decision
process (POMDP). For the case of two users in the system, we show that a greedy
policy is sum throughput optimal for any distribution on the ARQ feedback
delay. For the case of more than two users, we prove that the greedy policy is
suboptimal and demonstrate, via numerical studies, that it has near optimal
performance. We show that the greedy policy can be implemented by a simple
algorithm that does not require the statistics of the underlying Markov channel
or the ARQ feedback delay, thus making it robust against errors in system
parameter estimation. Establishing an equivalence between the two-user system
and a genie-aided system, we obtain a simple closed form expression for the sum
capacity of the Markov-modeled downlink. We further derive inner and outer
bounds on the capacity region of the Markov-modeled downlink and tighten these
bounds for special cases of the system parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3316</identifier>
 <datestamp>2012-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3316</id><created>2010-02-17</created><updated>2012-03-16</updated><authors><author><keyname>Toorani</keyname><forenames>M.</forenames></author><author><keyname>Beheshti</keyname><forenames>A. A.</forenames></author></authors><title>A Directly Public Verifiable Signcryption Scheme based on Elliptic
  Curves</title><categories>cs.CR</categories><comments>4 Pages, 2 Figures, 2 Tables</comments><msc-class>94Axx</msc-class><acm-class>E.3; K.6.5; D.4.6; K.6.m</acm-class><journal-ref>Proceedings of the 14th IEEE Symposium on Computers and
  Communications (ISCC'09), pp.713-716, July 2009</journal-ref><doi>10.1109/ISCC.2009.5202242</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A directly public verifiable signcryption scheme is introduced in this paper
that provides the security attributes of message confidentiality,
authentication, integrity, non-repudiation, unforgeability, and forward secrecy
of message confidentiality. It provides the attribute of direct public
verifiability so anyone can verify the signcryption without any need for any
secret information from the corresponding participants. The proposed scheme is
based on elliptic curve cryptography and is so suitable for environments with
resource constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3317</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3317</id><created>2010-02-17</created><updated>2010-02-23</updated><authors><author><keyname>Sinha</keyname><forenames>Nirmalendu Bikas</forenames></author><author><keyname>Chakraborty</keyname><forenames>S.</forenames></author><author><keyname>Sutradhar</keyname><forenames>P. K.</forenames></author><author><keyname>Bera</keyname><forenames>R.</forenames></author><author><keyname>Mitra</keyname><forenames>M.</forenames></author></authors><title>Optimization of MIMO detectors: Unleashing the multiplexing gain</title><categories>cs.NI</categories><comments>Journal of Telecommunications,Volume 1, Issue 1, pp1-5, February 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple Input Multiple Output (MIMO) systems have recently emerged as a key
technology in wireless communication systems for increasing both data rates and
system performance. There are many schemes that can be applied to MIMO systems
such as space time block codes, space time trellis codes, and the Vertical Bell
Labs Space-Time Architecture (V-BLAST). This paper proposes a novel signal
detector scheme called MIMO detectors to enhance the performance in MIMO
channels. We study the general MIMO system, the general V-BLAST architecture
with Maximum Likelihood (ML), Zero- Forcing (ZF), Minimum Mean- Square Error
(MMSE), and Ordered Successive Interference Cancellation (SIC) detectors and
simulate this structure in Rayleigh fading channel. Also compares the
performances of MIMO system with different modulation techniques in Fading and
AWGN channels. Base on frame error rates and bit error rates, we compare the
performance and the computational complexity of these schemes with other
existence model.Simulations shown that V-BLAST implements a detection
technique, i.e. SIC receiver, based on ZF or MMSE combined with symbol
cancellation and optimal ordering to improve the performance with lower
complexity, although ML receiver appears to have the best SER performance-BLAST
achieves symbol error rates close to the ML scheme while retaining the
lowcomplexity nature of the V-BLAST.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3320</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3320</id><created>2010-02-17</created><authors><author><keyname>Suleesathira</keyname><forenames>Raungrong</forenames></author></authors><title>Co-channel Interference Cancellation for Space-Time Coded OFDM Systems
  Using Adaptive Beamforming and Null Deepening</title><categories>cs.CL</categories><comments>Journal of Telecommunications,Volume 1, Issue 1, pp6-13, February
  2010</comments><journal-ref>Raungrong Suleesathira, &quot;Co-channel Interference Cancellation for
  Space-Time Coded OFDM Systems Using Adaptive Beamforming and Null Deepening&quot;,
  Journal of Telecommunications, Volume 1, Issue 1, pp6-13, February 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Combined with space-time coding, the orthogonal frequency division
multiplexing (OFDM) system explores space diversity. It is a potential scheme
to offer spectral efficiency and robust high data rate transmissions over
frequency-selective fading channel. However, space-time coding impairs the
system ability to suppress interferences as the signals transmitted from two
transmit antennas are superposed and interfered at the receiver antennas. In
this paper, we developed an adaptive beamforming based on least mean squared
error algorithm and null deepening to combat co-channel interference (CCI) for
the space-time coded OFDM (STC-OFDM) system. To illustrate the performance of
the presented approach, it is compared to the null steering beamformer which
requires a prior knowledge of directions of arrival (DOAs). The structure of
space-time decoders are preserved although there is the use of beamformers
before decoding. By incorporating the proposed beamformer as a CCI canceller in
the STC-OFDM systems, the performance improvement is achieved as shown in the
simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3322</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3322</id><created>2010-02-17</created><authors><author><keyname>Alhabeeb</keyname><forenames>M. A.</forenames></author><author><keyname>Almuhaideb</keyname><forenames>A. M</forenames></author><author><keyname>Le</keyname><forenames>P. D</forenames></author></authors><title>Holistic Approach for Critical System Security: Flooding Prevention and
  Malicious Packet Stopping</title><categories>cs.NI</categories><comments>Journal of Telecommunications,Volume 1, Issue 1, pp14-24, February
  2010</comments><journal-ref>M.A. Alhabeeb, A.M Almuhaideb and P.D Le, &quot;Holistic Approach for
  Critical System Security: Flooding Prevention and Malicious Packet Stopping&quot;,
  Journal of Telecommunications, Volume 1, Issue 1, pp14-24, February 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Denial of service attacks (DoS) can cause significant financial damages.
Flooding and Malicious packets are two kinds of DoS attacks. This paper
presents a new security approach which stops malicious packets and prevents
flooding in the critical systems. New concepts of packet stamp a
dynamic-multi-communication-point mechanism has been identified for this
proposed approach to make the prevention of flooding attacks easier and the
performing of malicious packet attacks harder. In addition, dynamic key
encryption technique has been adapted as a part of the proposed approach to
enhance its functionality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3326</identifier>
 <datestamp>2010-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3326</id><created>2010-02-17</created><authors><author><keyname>Verkhovsky</keyname><forenames>Boris S.</forenames></author></authors><title>Design of Optimal Topology of Satellite-Based Terrestrial Communication
  Networks</title><categories>cs.NI cs.CG</categories><comments>Journal of Telecommunications,Volume 1, Issue 1, pp25-35, February
  2010</comments><journal-ref>Boris S. Verkhovsky, &quot;Design of Optimal Topology of
  Satellite-Based Terrestrial Communication Networks&quot;, Journal of
  Telecommunications, Volume 1, Issue 1, pp25-35, February 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Topological design of terrestrial networks for communication via satellites
is studied in the paper. Quantitative model of the network cost-analysis
minimizing the total transmission and switching cost is described. Several
algorithms solving combinatorial problem of the optimal topology design based
on binary partitioning, a minimax parametric search and dynamic programming are
developed by the author and demonstrated with a numeric example. Analysis of
average complexity of the minimax parametric search algorithm is also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3328</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3328</id><created>2010-02-17</created><authors><author><keyname>Hossain</keyname><forenames>Md. M.</forenames></author><author><keyname>Hossain</keyname><forenames>J.</forenames></author></authors><title>Error Performance Analysis to Increase Capacity of A Cellular System
  Using SDMA</title><categories>cs.NI</categories><comments>Journal of Telecommunications,Volume 1, Issue 1, pp36-39, February
  2010</comments><journal-ref>Md. M. Hossain and J.Hossain, &quot;Error Performance Analysis to
  Increase Capacity of A Cellular System Using SDMA&quot;, Journal of
  Telecommunications, Volume 1, Issue 1, pp36-39, February 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the biggest drawbacks of the wireless environment is the limited
bandwidth. However, the users sharing this limited bandwidth have been
increasing considerably.Space Division Multiple Access (SDMA) is a new
technology by which the capacity of existing mobile communication systems can
economically be increased. This paper has been presented how the capacity can
be enhanced by using SDMA with smart antennas in mobile communications system.
Based on Adaptive Antenna Array (AAA) technology the spatial dimension of the
existing system is exploited by means of forming independent radio beams in
each of the original channels. This paper analyses the comparison of average
Bit Error Rate (BER) of SDMA and CDMA technique and the different ways in which
SDMA can be introduced to increase the capacity of a cellular system. The
probability of error is found for a standard omni directional base station
antenna, and another set of curves is found for flat top beam having a
directivity of 5.1dB. It is assumed that k separate flat top beams can be
formed by base station and pointed each of the k users within the cell of
interest. Noticing that for an average probability of error greater than 0.1 in
a propagation path loss environment of n=4, the flat top beam will support 200
users, whereas the omni-directional antenna will support only 50 users. This
increase the number of user is roughly equal to the directivity offered by the
flat top beam system, and illustrates the promise SDMA offers for improving
capacity in wireless system. Here multipath fading is not considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3329</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3329</id><created>2010-02-17</created><authors><author><keyname>Tarighi</keyname><forenames>M.</forenames></author><author><keyname>Motamedi</keyname><forenames>S. A.</forenames></author><author><keyname>Sharifian</keyname><forenames>S.</forenames></author></authors><title>A new model for virtual machine migration in virtualized cluster server
  based on Fuzzy Decision Making</title><categories>cs.OS cs.NI</categories><comments>Journal of Telecommunications,Volume 1, Issue 1, pp40-51, February
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show that performance of the virtualized cluster servers
could be improved through intelligent decision over migration time of Virtual
Machines across heterogeneous physical nodes of a cluster server. The cluster
serves a variety range of services from Web Service to File Service. Some of
them are CPU-Intensive while others are RAM-Intensive and so on. Virtualization
has many advantages such as less hardware cost, cooling cost, more
manageability. One of the key benefits is better load balancing by using of VM
migration between hosts. To migrate, we must know which virtual machine needs
to be migrated and when this relocation has to be done and, moreover, which
host must be destined. To relocate VMs from overloaded servers to underloaded
ones, we need to sort nodes from the highest volume to the lowest. There are
some models to finding the most overloaded node, but they have some
shortcomings. The focus of this paper is to present a new method to migrate VMs
between cluster nodes using TOPSIS algorithm - one of the most efficient Multi
Criteria Decision Making techniques- to make more effective decision over whole
active servers of the Cluster and find the most loaded serversTo evaluate the
performance improvement resulted from this model, we used cluster Response time
and Unbalanced Factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3330</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3330</id><created>2010-02-17</created><updated>2010-02-17</updated><authors><author><keyname>Ripon</keyname><forenames>Shamim H.</forenames></author><author><keyname>Butler</keyname><forenames>Michael</forenames></author></authors><title>Deriving Relationship Between Semantic Models - An Approach for cCSP</title><categories>cs.LO cs.SE</categories><comments>8 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500</comments><report-no>Computer Science Volume 7 ISSN 19475500</report-no><acm-class>F.4.1; F.3.2</acm-class><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 47-54, January 2010, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Formal semantics offers a complete and rigorous definition of a language. It
is important to define different semantic models for a language and different
models serve different purposes. Building equivalence between different
semantic models of a language strengthen its formal foundation. This paper
shows the derivation of denotational semantics from operational semantics of
the language cCSP. The aim is to show the correspondence between operational
and trace semantics. We extract traces from operational rules and use induction
over traces to show the correspondence between the two semantics of cCSP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3332</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3332</id><created>2010-02-17</created><authors><author><keyname>Parmar</keyname><forenames>Sargam</forenames></author><author><keyname>Unhelkar</keyname><forenames>Bhuvan</forenames></author></authors><title>Performance Comparisions of ICA Algorithms to DS-CDMA Detection</title><categories>cs.NI</categories><comments>Journal of Telecommunications,Volume 1, Issue 1, pp52-56, February
  2010</comments><journal-ref>M.Tarighi, S. Parmar and B. Unhelkar, &quot;Performance Comparisions of
  ICA Algorithms to DS-CDMA Detection&quot;, Journal of Telecommunications, Volume
  1, Issue 1, pp52-56, February 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Commercial cellular networks, like the systems based on DS-CDMA, face many
types of interferences such as multi-user interference inside each sector in a
cell to interoperate interference. Independent Component Analysis (ICA) has
been used as an advanced preprocessing tool for blind suppression of
interfering signals in DS-CDMA communication systems. The role of ICA is to
provide an interference-mitigated signal to the conventional detection. This
paper evaluates the performance of some major ICA algorithms like Cardoso's
joint approximate diagonalization of eigen matrices (JADE), Hyvarinen's fixed
point algorithm and Comon's algorithm to solve the symbol estimation problem of
the multi users in a DSCDMA communication system. The main focus is on blind
separation of convolved CDMA mixture and the improvement of the downlink symbol
estimation. The results of numerical experiment are compared with those
obtained by the Single User Detection (SUD) receiver, ICA detector and combined
SUD-ICA detector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3333</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3333</id><created>2010-02-17</created><authors><author><keyname>Laisuzzaman</keyname><forenames>Ijaj Md.</forenames></author><author><keyname>Imran</keyname><forenames>Nahid</forenames></author><author><keyname>Nahid</keyname><forenames>Abdullah Al</forenames></author><author><keyname>Ziaul</keyname><forenames>Md.</forenames></author><author><keyname>Alim</keyname><forenames>Md. Abdul</forenames></author></authors><title>The Framework for Implementing ECommerce: The Role of Bank and Telecom
  in Bangladesh</title><categories>cs.CY</categories><comments>Journal of Telecommunications,Volume 1, Issue 1, pp57-62, February
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we describe an effective framework for adapting electronic
commerce or e-commerce services in developing countries like Bangladesh. The
internet has opened up a new horizon for commerce, namely electronic commerce
(e-commerce). It entails the use of the internet in the marketing,
identification, payment and delivery of goods and services. At present internet
facilities are available in Bangladesh. Slowly, but steadily these facilities
are holding a strong position in every aspects of our life. E-commerce is one
of those sectors which need more attention if we want to be a part of global
business. Bangladesh is far-far away to adapt the main stream of e-commerce
application. Though government is shouting to take the challenges of
e-commerce, but they do not take the right step, that is why e-commerce dose
not make any real contribution in our socio-economic life. Here we propose a
model which may develop the e-commerce infrastructure of Bangladesh.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3337</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3337</id><created>2010-02-17</created><authors><author><keyname>De</keyname><forenames>Asok</forenames></author><author><keyname>Raghava</keyname><forenames>N. S.</forenames></author><author><keyname>Malhotra</keyname><forenames>Sagar</forenames></author><author><keyname>Arora</keyname><forenames>Pushkar</forenames></author><author><keyname>Bazaz</keyname><forenames>Rishik</forenames></author></authors><title>Effect of different substrates on Compact stacked square Microstrip
  Antenna</title><categories>cs.OH</categories><comments>Journal of Telecommunications,Volume 1, Issue 1, pp63-65, February
  2010</comments><journal-ref>A. De, N. S. Raghava, S. Malhotra, P. Arora and R. Bazaz, &quot;Effect
  of different substrates on Compact stacked square Microstrip Antenna&quot;,
  Journal of Telecommunications, Volume 1, Issue 1, pp63-65, February 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Selection of the most suitable substrate for a Microstrip antenna is a matter
of prime importance. This is because many limitations of the microstrip antenna
such as high return loss, low gain and low efficiency can be overcome by
selecting an appropriate substrate for fabrication of the antenna, without
shifting the resonant frequency significantly. The substate properties such as
its dielectric constant, loss tangent have a pronounced effect on the antenna
characteristics. Some of the critical properties that are to be taken care of
while selecting a dielectric are homogeneity, moisture absorption and adhesion
of metal- foil cladding. In this paper a comprehensive study of the effect of
variation of substrate material on the antenna properties has been presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3339</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3339</id><created>2010-02-17</created><authors><author><keyname>Song</keyname><forenames>Ha-ryong</forenames></author><author><keyname>Shin</keyname><forenames>Vladimir</forenames></author></authors><title>Limited Memory Prediction for Linear Systems with Different types of
  Observation</title><categories>cs.OH</categories><comments>Journal of Telecommunications,Volume 1, Issue 1, pp66-71, February
  2010</comments><journal-ref>Ha-ryong Song and V. Shin, &quot;Limited Memory Prediction for Linear
  Systems with Different types of Observation&quot;, Journal of Telecommunications,
  Volume 1, Issue 1, pp66-71, February 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with distributed limited memory prediction for
continuous-time linear stochastic systems with multiple sensors. A distributed
fusion with the weighted sum structure is applied to the optimal local limited
memory predictors. The distributed prediction algorithm represents the optimal
linear fusion by weighting matrices under the minimum mean square criterion.
The algorithm has the parallel structure and allows parallel processing of
observations making it reliable since the rest faultless sensors can continue
to the fusion estimation if some sensors occur faulty. The derivation of
equations for error cross-covariances between the local predictors is the key
of this paper. Example demonstrates effectiveness of the distributed limited
memory predictor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3340</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3340</id><created>2010-02-17</created><authors><author><keyname>Singh</keyname><forenames>S. N.</forenames></author><author><keyname>Singh</keyname><forenames>A. K.</forenames></author></authors><title>FPGA Based Sinusoidal Pulse Width Modulated Waveform Generation for
  Solar (PV) Rural Home Power Inverter</title><categories>cs.OH</categories><comments>Journal of Telecommunications,Volume 1, Issue 1, pp72-79, February
  2010</comments><journal-ref>S. N. Singh and A. K. Singh, &quot;FPGA Based Sinusoidal Pulse Width
  Modulated Waveform Generation for Solar (PV) Rural Home Power Inverter&quot;,
  Journal of Telecommunications, Volume 1, Issue 1, pp72-79, February 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increasing concern about global environmental protection and energy
demand due to rapid growth of population in developing countries and the
diminishing trend of resources of conventional grid supply, the need to produce
freely available pollution free natural energy such as solar/wind energy has
been drawing increasing interest in every corner of the world. In an effort to
utilize these energies effectively through Power converter, a great deal of
research is being carried out by different researchers / scientist and
engineers at different places in the world to meet the increasing demand of
load. The study presents methodology to integrate solar (PV) energy (which is
freely available in every corner of the world) with grid source and supplement
the existing grid power in rural houses during its cut off or restricted supply
period. In order to get consistency in supply a DG is also added as a standby
source in the proposed integration of network. The software using novel Direct
PWM modulation strategy and its soft control features extend the flexibility to
control converter (inverter) parameters like voltage, frequency, number of
samples of PWM pulses constituting sine-wave without changing any hardware
configuration in the circuit. The system simulation of PWM Pulse generation has
been done on a XILINX based FPGA Spartan 3E board using VHDL code. The test on
simulation of PWM generation program after synthesis and compilation were
recorded and verified on a prototype sample.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3342</identifier>
 <datestamp>2010-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3342</id><created>2010-02-17</created><authors><author><keyname>Georgeot</keyname><forenames>B.</forenames></author><author><keyname>Giraud</keyname><forenames>O.</forenames></author><author><keyname>Shepelyansky</keyname><forenames>D. L.</forenames></author></authors><title>Spectral properties of the Google matrix of the World Wide Web and other
  directed networks</title><categories>cs.IR</categories><comments>8 pages, 12 figures, research done at
  http://www.quantware.ups-tlse.fr</comments><journal-ref>Phys. Rev. E 81, 056109 (2010)</journal-ref><doi>10.1103/PhysRevE.81.056109</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study numerically the spectrum and eigenstate properties of the Google
matrix of various examples of directed networks such as vocabulary networks of
dictionaries and university World Wide Web networks. The spectra have gapless
structure in the vicinity of the maximal eigenvalue for Google damping
parameter $\alpha$ equal to unity. The vocabulary networks have relatively
homogeneous spectral density, while university networks have pronounced
spectral structures which change from one university to another, reflecting
specific properties of the networks. We also determine specific properties of
eigenstates of the Google matrix, including the PageRank. The fidelity of the
PageRank is proposed as a new characterization of its stability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3344</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3344</id><created>2010-02-17</created><authors><author><keyname>Avanaki</keyname><forenames>Alireza</forenames></author></authors><title>Iterative exact global histogram specification and SSIM gradient ascent:
  a proof of convergence, step size and parameter selection</title><categories>cs.CV cs.MM</categories><comments>Supplement to published work, on SSIM-optimized exact global
  histogram specification; please see arXiv:0901.0065</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The SSIM-optimized exact global histogram specification (EGHS) is shown to
converge in the sense that the first order approximation of the result's
quality (i.e., its structural similarity with input) does not decrease in an
iteration, when the step size is small. Each iteration is composed of SSIM
gradient ascent and basic EGHS with the specified target histogram. Selection
of step size and other parameters is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3345</identifier>
 <datestamp>2010-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3345</id><created>2010-02-17</created><updated>2010-05-20</updated><authors><author><keyname>Guillory</keyname><forenames>Andrew</forenames></author><author><keyname>Bilmes</keyname><forenames>Jeff</forenames></author></authors><title>Interactive Submodular Set Cover</title><categories>cs.LG</categories><comments>15 pages, 1 figure</comments><report-no>UWEETR-2010-0001</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a natural generalization of submodular set cover and exact
active learning with a finite hypothesis class (query learning). We call this
new problem interactive submodular set cover. Applications include advertising
in social networks with hidden information. We give an approximation guarantee
for a novel greedy algorithm and give a hardness of approximation result which
matches up to constant factors. We also discuss negative results for simpler
approaches and present encouraging early experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3356</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3356</id><created>2010-02-17</created><authors><author><keyname>Marsch</keyname><forenames>Patrick</forenames></author><author><keyname>Fettweis</keyname><forenames>Gerhard</forenames></author></authors><title>Uplink CoMP under a Constrained Backhaul and Imperfect Channel Knowledge</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communications in February
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coordinated Multi-Point (CoMP) is known to be a key technology for next
generation mobile communications systems, as it allows to overcome the burden
of inter-cell interference. Especially in the uplink, it is likely that
interference exploitation schemes will be used in the near future, as they can
be used with legacy terminals and require no or little changes in
standardization. Major drawbacks, however, are the extent of additional
backhaul infrastructure needed, and the sensitivity to imperfect channel
knowledge. This paper jointly addresses both issues in a new framework
incorporating a multitude of proposed theoretical uplink CoMP concepts, which
are then put into perspective with practical CoMP algorithms. This
comprehensive analysis provides new insight into the potential usage of uplink
CoMP in next generation wireless communications systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3409</identifier>
 <datestamp>2010-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3409</id><created>2010-02-17</created><authors><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>Aryabhata's Mathematics</title><categories>cs.CR math.HO</categories><comments>Keynote Lecture at RSA Conference, San Jose, February 13-17, 2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents certains aspects of the mathematics of Aryabhata that are
of interest to the cryptography community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3438</identifier>
 <datestamp>2010-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3438</id><created>2010-02-18</created><updated>2010-05-31</updated><authors><author><keyname>Krivine</keyname><forenames>Jean-Louis</forenames><affiliation>PPS</affiliation></author></authors><title>Alg\`ebres de r\'ealisabilit\'e: un programme pour bien ordonner R</title><categories>cs.LO math.LO</categories><comments>45 pages</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a method to transform into programs, classical proofs using a well
ordering of the reals. The technics uses a generalization of Cohen's forcing
and the theory of classical realizability introduced by the author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3449</identifier>
 <datestamp>2011-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3449</id><created>2010-02-18</created><updated>2011-07-06</updated><authors><author><keyname>Xie</keyname><forenames>Bike</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author><author><keyname>Wesel</keyname><forenames>Richard D.</forenames></author></authors><title>Minimizing weighted sum download time for one-to-many file transfer in
  peer-to-peer networks</title><categories>cs.IT cs.NI math.IT math.OC</categories><comments>67 pages, 21 figures</comments><msc-class>68M10, 90B18</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of transferring a file from one source node
to multiple receivers in a peer-to-peer (P2P) network. The objective is to
minimize the weighted sum download time (WSDT) for the one-to-many file
transfer. Previous work has shown that, given an order at which the receivers
finish downloading, the minimum WSD can be solved in polynomial time by convex
optimization, and can be achieved by linear network coding, assuming that node
uplinks are the only bottleneck in the network. This paper, however, considers
heterogeneous peers with both uplink and downlink bandwidth constraints
specified. The static scenario is a file-transfer scheme in which the network
resource allocation remains static until all receivers finish downloading. This
paper first shows that the static scenario may be optimized in polynomial time
by convex optimization, and the associated optimal static WSD can be achieved
by linear network coding. This paper then presented a lower bound to the
minimum WSDT that is easily computed and turns out to be tight across a wide
range of parameterizations of the problem. This paper also proposes a static
routing-based scheme and a static rateless-coding-based scheme which have
almost-optimal empirical performances. The dynamic scenario is a file-transfer
scheme which can re-allocate the network resource during the file transfer.
This paper proposes a dynamic rateless-coding-based scheme, which provides
significantly smaller WSDT than the optimal static scenario does.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3453</identifier>
 <datestamp>2010-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3453</id><created>2010-02-18</created><authors><author><keyname>Vercelli</keyname><forenames>Luca</forenames></author></authors><title>On the complexity of stratified logics</title><categories>cs.CC</categories><comments>PhD thesis. about 180 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our primary motivation is the comparison of two different traditions used in
ICC to characterize the class FPTIME of the polynomial time computable
functions. On one side, FPTIME can be captured by Intuitionistic Light Affine
Logic (ILAL), a logic derived from Linear Logic, characterized by the
structural invariant Stratification. On the other side, FPTIME can be captured
by Safe Recursion on Notation (SRN), an algebra of functions based on
Predicative Recursion, a restriction of the standard recursion schema used to
defiine primitive recursive functions. Stratifiication and Predicative
Recursion seem to share common underlying principles, whose study is the main
subject of this work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3474</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3474</id><created>2010-02-18</created><updated>2011-05-23</updated><authors><author><keyname>Auletta</keyname><forenames>Vincenzo</forenames></author><author><keyname>Ferraioli</keyname><forenames>Diodato</forenames></author><author><keyname>Pasquale</keyname><forenames>Francesco</forenames></author><author><keyname>Persiano</keyname><forenames>Giuseppe</forenames></author></authors><title>Mixing Time and Stationary Expected Social Welfare of Logit Dynamics</title><categories>cs.GT cs.DM</categories><comments>28 pages</comments><doi>10.1007/978-3-642-16170-4_6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study &quot;logit dynamics&quot; [Blume, Games and Economic Behavior, 1993] for
strategic games. This dynamics works as follows: at every stage of the game a
player is selected uniformly at random and she plays according to a &quot;noisy&quot;
best-response where the noise level is tuned by a parameter $\beta$. Such a
dynamics defines a family of ergodic Markov chains, indexed by $\beta$, over
the set of strategy profiles. We believe that the stationary distribution of
these Markov chains gives a meaningful description of the long-term behavior
for systems whose agents are not completely rational.
  Our aim is twofold: On the one hand, we are interested in evaluating the
performance of the game at equilibrium, i.e. the expected social welfare when
the strategy profiles are random according to the stationary distribution. On
the other hand, we want to estimate how long it takes, for a system starting at
an arbitrary profile and running the logit dynamics, to get close to its
stationary distribution; i.e., the &quot;mixing time&quot; of the chain.
  In this paper we study the stationary expected social welfare for the
3-player CK game, for 2-player coordination games, and for two simple
$n$-player games. For all these games, we also give almost tight upper and
lower bounds on the mixing time of logit dynamics. Our results show two
different behaviors: in some games the mixing time depends exponentially on
$\beta$, while for other games it can be upper bounded by a function
independent of $\beta$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3475</identifier>
 <datestamp>2010-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3475</id><created>2010-02-18</created><authors><author><keyname>Balanoiu</keyname><forenames>Paul</forenames></author></authors><title>Enhancing Privacy for Biometric Identification Cards</title><categories>cs.CR</categories><comments>8 Pages, 7 figures</comments><acm-class>C.1.3; C.2; D.4.6; K.6.5; K.6.m</acm-class><journal-ref>Informatica Economica, Vol.13, No.1, pp.100-107, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most developed countries have started the implementation of biometric
electronic identification cards, especially passports. The European Union and
the United States of America struggle to introduce and standardize these
electronic documents. Due to the personal nature of the biometric elements used
for the generation of these cards, privacy issues were raised on both sides of
the Atlantic Ocean, leading to civilian protests and concerns. The lack of
transparency from the public authorities responsible with the implementation of
such identification systems, and the poor technological approaches chosen by
these authorities, are the main reasons for the negative popularity of the new
identification methods. The following article shows an approach that provides
all the benefits of modern technological advances in the fields of biometrics
and cryptography, without sacrificing the privacy of those that will be the
beneficiaries of the new system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3492</identifier>
 <datestamp>2010-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3492</id><created>2010-02-18</created><authors><author><keyname>Khajeh-Hosseini</keyname><forenames>Ali</forenames></author><author><keyname>Greenwood</keyname><forenames>David</forenames></author><author><keyname>Sommerville</keyname><forenames>Ian</forenames></author></authors><title>Cloud Migration: A Case Study of Migrating an Enterprise IT System to
  IaaS</title><categories>cs.DC</categories><comments>Submitted to IEEE CLOUD 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This case study illustrates the potential benefits and risks associated with
the migration of an IT system in the oil &amp; gas industry from an in-house data
center to Amazon EC2 from a broad variety of stakeholder perspectives across
the enterprise, thus transcending the typical, yet narrow, financial and
technical analysis offered by providers. Our results show that the system
infrastructure in the case study would have cost 37% less over 5 years on EC2,
and using cloud computing could have potentially eliminated 21% of the support
calls for this system. These findings seem significant enough to call for a
migration of the system to the cloud but our stakeholder impact analysis
revealed that there are significant risks associated with this. Whilst the
benefits of using the cloud are attractive, we argue that it is important that
enterprise decision-makers consider the overall organizational implications of
the changes brought about with cloud computing to avoid implementing local
optimizations at the cost of organization-wide performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3493</identifier>
 <datestamp>2011-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3493</id><created>2010-02-18</created><updated>2011-07-12</updated><authors><author><keyname>Hajek</keyname><forenames>Bruce</forenames></author><author><keyname>Zhu</keyname><forenames>Ji</forenames></author></authors><title>The Missing Piece Syndrome in Peer-to-Peer Communication</title><categories>cs.PF cs.IT math.IT</categories><comments>14 pages, 3 figures in 5 files. An earlier version appeared in the
  2010 IEEE International Symposium on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Typical protocols for peer-to-peer file sharing over the Internet divide
files to be shared into pieces. New peers strive to obtain a complete
collection of pieces from other peers and from a seed. In this paper we
investigate a problem that can occur if the seeding rate is not large enough.
The problem is that, even if the statistics of the system are symmetric in the
pieces, there can be symmetry breaking, with one piece becoming very rare. If
peers depart after obtaining a complete collection, they can tend to leave
before helping other peers receive the rare piece. Assuming that peers arrive
with no pieces, there is a single seed, random peer contacts are made, random
useful pieces are downloaded, and peers depart upon receiving the complete
file, the system is stable if the seeding rate (in pieces per time unit) is
greater than the arrival rate, and is unstable if the seeding rate is less than
the arrival rate. The result persists for any piece selection policy that
selects from among useful pieces, such as rarest first, and it persists with
the use of network coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3511</identifier>
 <datestamp>2010-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3511</id><created>2010-02-18</created><authors><author><keyname>Karpinski</keyname><forenames>Marek</forenames></author><author><keyname>Munro</keyname><forenames>J. Ian</forenames></author><author><keyname>Nekrich</keyname><forenames>Yakov</forenames></author></authors><title>Range Reporting for Moving Points on a Grid</title><categories>cs.DS cs.CG</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe a new data structure that supports orthogonal range
reporting queries on a set of points that move along linear trajectories on a
$U\times U$ grid. The assumption that points lie on a $U\times U$ grid enables
us to significantly decrease the query time in comparison to the standard
kinetic model. Our data structure answers queries in $O(\sqrt{\log U/\log \log
U}+k)$ time, where $k$ denotes the number of points in the answer. The above
improves over the $\Omega(\log n)$ lower bound that is valid in the
infinite-precision kinetic model. The methods used in this paper could be also
of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3518</identifier>
 <datestamp>2010-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3518</id><created>2010-02-18</created><authors><author><keyname>Fountoulakis</keyname><forenames>Nikolaos</forenames></author><author><keyname>Panagiotou</keyname><forenames>Konstantinos</forenames></author></authors><title>Rumor Spreading on Random Regular Graphs and Expanders</title><categories>math.CO cs.DS math.PR</categories><comments>18 pages</comments><msc-class>05C80; 60C05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Broadcasting algorithms are important building blocks of distributed systems.
In this work we investigate the typical performance of the classical and
well-studied push model. Assume that initially one node in a given network
holds some piece of information. In each round, every one of the informed nodes
chooses independently a neighbor uniformly at random and transmits the message
to it.
  In this paper we consider random networks where each vertex has degree d,
which is at least 3, i.e., the underlying graph is drawn uniformly at random
from the set of all d-regular graphs with n vertices. We show that with
probability 1 - o(1) the push model broadcasts the message to all nodes within
(1 + o(1))C_d ln n rounds, where C_d = 1/ ln(2(1-1/d)) - 1/(d ln(1 - 1/d)). In
particular, we can characterize precisely the effect of the node degree to the
typical broadcast time of the push model. Moreover, we consider pseudo-random
regular networks, where we assume that the degree of each node is very large.
There we show that the broadcast time is (1+o(1))C ln n with probability 1 -
o(1), where C= 1/ ln 2 + 1, is the limit of C_d as d grows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3521</identifier>
 <datestamp>2010-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3521</id><created>2010-02-18</created><authors><author><keyname>Mori</keyname><forenames>Ryuhei</forenames></author></authors><title>Properties and Construction of Polar Codes</title><categories>cs.IT math.IT</categories><comments>Master thesis. The supervisor is Toshiyuki Tanaka. 24 pages, 3
  figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Ar{\i}kan introduced the method of channel polarization on which
one can construct efficient capacity-achieving codes, called polar codes, for
any binary discrete memoryless channel. In the thesis, we show that decoding
algorithm of polar codes, called successive cancellation decoding, can be
regarded as belief propagation decoding, which has been used for decoding of
low-density parity-check codes, on a tree graph. On the basis of the
observation, we show an efficient construction method of polar codes using
density evolution, which has been used for evaluation of the error probability
of belief propagation decoding on a tree graph. We further show that channel
polarization phenomenon and polar codes can be generalized to non-binary
discrete memoryless channels. Asymptotic performances of non-binary polar
codes, which use non-binary matrices called the Reed-Solomon matrices, are
better than asymptotic performances of the best explicitly known binary polar
code. We also find that the Reed-Solomon matrices are considered to be natural
generalization of the original binary channel polarization introduced by
Ar{\i}kan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3534</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3534</id><created>2010-02-18</created><updated>2010-12-29</updated><authors><author><keyname>Holenstein</keyname><forenames>Thomas</forenames></author><author><keyname>Schoenebeck</keyname><forenames>Grant</forenames></author></authors><title>General Hardness Amplification of Predicates and Puzzles</title><categories>cs.CR cs.CC</categories><comments>Revision 2: Added references, minor changes, slight improvements in
  presentation of some proof sketches</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give new proofs for the hardness amplification of efficiently samplable
predicates and of weakly verifiable puzzles which generalize to new settings.
More concretely, in the first part of the paper, we give a new proof of Yao's
XOR-Lemma that additionally applies to related theorems in the cryptographic
setting. Our proof seems simpler than previous ones, yet immediately
generalizes to statements similar in spirit such as the extraction lemma used
to obtain pseudo-random generators from one-way functions [Hastad, Impagliazzo,
Levin, Luby, SIAM J. on Comp. 1999].
  In the second part of the paper, we give a new proof of hardness
amplification for weakly verifiable puzzles, which is more general than
previous ones in that it gives the right bound even for an arbitrary monotone
function applied to the checking circuit of the underlying puzzle.
  Both our proofs are applicable in many settings of interactive cryptographic
protocols because they satisfy a property that we call &quot;non-rewinding&quot;. In
particular, we show that any weak cryptographic protocol whose security is
given by the unpredictability of single bits can be strengthened with a natural
information theoretic protocol. As an example, we show how these theorems solve
the main open question from [Halevi and Rabin, TCC2008] concerning bit
commitment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3541</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3541</id><created>2010-02-18</created><updated>2010-08-02</updated><authors><author><keyname>Newman</keyname><forenames>Ilan</forenames></author><author><keyname>Rabinovich</keyname><forenames>Yuri</forenames></author></authors><title>Finite Volume Spaces and Sparsification</title><categories>cs.DS cs.DM</categories><comments>previous revision was the wrong file: the new revision: changed
  (extended considerably) the treatment of finite volumes (see revised
  abstract). Inserted new applications for the sparsification techniques</comments><acm-class>G.2.0; G.2.1; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce and study finite $d$-volumes - the high dimensional
generalization of finite metric spaces. Having developed a suitable
combinatorial machinery, we define $\ell_1$-volumes and show that they contain
Euclidean volumes and hypertree volumes. We show that they can approximate any
$d$-volume with $O(n^d)$ multiplicative distortion. On the other hand, contrary
to Bourgain's theorem for $d=1$, there exists a $2$-volume that on $n$ vertices
that cannot be approximated by any $\ell_1$-volume with distortion smaller than
$\tilde{\Omega}(n^{1/5})$.
  We further address the problem of $\ell_1$-dimension reduction in the context
of $\ell_1$ volumes, and show that this phenomenon does occur, although not to
the same striking degree as it does for Euclidean metrics and volumes. In
particular, we show that any $\ell_1$ metric on $n$ points can be $(1+
\epsilon)$-approximated by a sum of $O(n/\epsilon^2)$ cut metrics, improving
over the best previously known bound of $O(n \log n)$ due to Schechtman.
  In order to deal with dimension reduction, we extend the techniques and ideas
introduced by Karger and Bencz{\'u}r, and Spielman et al.~in the context of
graph Sparsification, and develop general methods with a wide range of
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3567</identifier>
 <datestamp>2012-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3567</id><created>2010-02-18</created><updated>2012-03-16</updated><authors><author><keyname>Toorani</keyname><forenames>M.</forenames></author><author><keyname>Falahati</keyname><forenames>A.</forenames></author></authors><title>A Secure Variant of the Hill Cipher</title><categories>cs.CR</categories><comments>4 Pages, 4 Figures</comments><msc-class>94A60</msc-class><acm-class>E.3; K.6.5; D.4.6; K.6.m</acm-class><journal-ref>Proceedings of the 14th IEEE Symposium on Computers and
  Communications (ISCC'09), pp.313-316, July 2009</journal-ref><doi>10.1109/ISCC.2009.5202241</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Hill cipher is a classical symmetric encryption algorithm that succumbs
to the know-plaintext attack. Although its vulnerability to cryptanalysis has
rendered it unusable in practice, it still serves an important pedagogical role
in cryptology and linear algebra. In this paper, a variant of the Hill cipher
is introduced that makes the Hill cipher secure while it retains the
efficiency. The proposed scheme includes a ciphering core for which a
cryptographic protocol is introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3583</identifier>
 <datestamp>2012-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3583</id><created>2010-02-18</created><updated>2011-07-25</updated><authors><author><keyname>Kopeck&#xe1;</keyname><forenames>Eva</forenames></author><author><keyname>Reem</keyname><forenames>Daniel</forenames></author><author><keyname>Reich</keyname><forenames>Simeon</forenames></author></authors><title>Zone diagrams in compact subsets of uniformly convex normed spaces</title><categories>math.FA cs.CG math.GN</categories><comments>18 pages, 6 figures; Israel Journal of Mathematics, to appear; slight
  weakening of the main theorem by adding the emanation property assumption to
  this theorem and to some of the auxiliary claims (no change in the proofs);
  added a discussion about the emanation property; a few additions and
  modifications; the figures were slightly improved; added references and
  thanks</comments><msc-class>46B20, 47H10, 54B20, 54F15, 68U05</msc-class><journal-ref>Israel Journal of Mathematics, 188 (2012), 1-23</journal-ref><doi>10.1007/s11856-011-0094-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A zone diagram is a relatively new concept which has emerged in computational
geometry and is related to Voronoi diagrams. Formally, it is a fixed point of a
certain mapping, and neither its uniqueness nor its existence are obvious in
advance. It has been studied by several authors, starting with T. Asano, J.
Matousek and T. Tokuyama, who considered the Euclidean plane with singleton
sites, and proved the existence and uniqueness of zone diagrams there. In the
present paper we prove the existence of zone diagrams with respect to finitely
many pairwise disjoint compact sites contained in a compact and convex subset
of a uniformly convex normed space, provided that either the sites or the
convex subset satisfy a certain mild condition. The proof is based on the
Schauder fixed point theorem, the Curtis-Schori theorem regarding the Hilbert
cube, and on recent results concerning the characterization of Voronoi cells as
a collection of line segments and their geometric stability with respect to
small changes of the corresponding sites. Along the way we obtain the
continuity of the Dom mapping as well as interesting and apparently new
properties of Voronoi cells.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3602</identifier>
 <datestamp>2011-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3602</id><created>2010-02-18</created><updated>2011-08-03</updated><authors><author><keyname>Bao</keyname><forenames>Xingkai</forenames><affiliation>Tiffany</affiliation></author><author><keyname>Li</keyname><forenames>Jing</forenames><affiliation>Tiffany</affiliation></author></authors><title>Mobile Wireless Localization through Cooperation</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers N mobile nodes that move together in the vicinity of
each other, whose initial poses as well as subsequent movements must be
accurately tracked in real time with the assist of M(&gt;=3) reference nodes. By
engaging the neighboring mobile nodes in a simple but effective cooperation,
and by exploiting both the time-of-arrival (TOA) information (between mobile
nodes and reference nodes) and the received-signal-strength (RSS) information
(between mobile nodes), an effective new localization strategy, termed
cooperative TOA and RSS (COTAR), is developed. An optimal maximum likelihood
detector is first formulated, followed by the derivation of a low-complexity
iterative approach that can practically achieve the Cramer-Rao lower bound.
Instead of using simplified channel models as in many previous studies, a
sophisticated and realistic channel model is used, which can effectively
account for the critical fact that the direct path is not necessarily the
strongest path. Extensive simulations are conducted in static and mobile
settings, and various practical issues and system parameters are evaluated. It
is shown that COTAR significantly outperforms the existing strategies,
achieving a localization accuracy of only a few tenths of a meter in clear
environments and a couple of meters in heavily obstructed environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3629</identifier>
 <datestamp>2010-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3629</id><created>2010-02-18</created><authors><author><keyname>Bao</keyname><forenames>Xingkai</forenames><affiliation>Tiffany</affiliation></author><author><keyname>Li</keyname><forenames>Jing</forenames><affiliation>Tiffany</affiliation></author></authors><title>Generalized Adaptive Network Coded Cooperation (GANCC): A Unified
  Framework for Network Coding and Channel Coding</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers distributed coding for multi-source single-sink data
collection wireless networks. A unified framework for network coding and
channel coding, termed &quot;generalized adaptive network coded cooperation&quot;
(GANCC), is proposed. Key ingredients of GANCC include: matching code graphs
with the dynamic network graphs on-the-fly, and integrating channel coding with
network coding through circulant low-density parity-check codes. Several code
constructing methods and several families of sparse-graph codes are proposed,
and information theoretical analysis is performed. It is shown that GANCC is
simple to operate, adaptive in real time, distributed in nature, and capable of
providing remarkable coding gains even with a very limited number of
cooperating users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3664</identifier>
 <datestamp>2010-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3664</id><created>2010-02-18</created><authors><author><keyname>Drucker</keyname><forenames>Andrew</forenames></author></authors><title>A PCP Characterization of AM</title><categories>cs.CC</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a 2-round stochastic constraint-satisfaction problem, and show
that its approximation version is complete for (the promise version of) the
complexity class AM. This gives a `PCP characterization' of AM analogous to the
PCP Theorem for NP. Similar characterizations have been given for higher levels
of the Polynomial Hierarchy, and for PSPACE; however, we suggest that the
result for AM might be of particular significance for attempts to derandomize
this class.
  To test this notion, we pose some `Randomized Optimization Hypotheses'
related to our stochastic CSPs that (in light of our result) would imply
collapse results for AM. Unfortunately, the hypotheses appear over-strong, and
we present evidence against them. In the process we show that, if some language
in NP is hard-on-average against circuits of size 2^{Omega(n)}, then there
exist hard-on-average optimization problems of a particularly elegant form.
  All our proofs use a powerful form of PCPs known as Probabilistically
Checkable Proofs of Proximity, and demonstrate their versatility. We also use
known results on randomness-efficient soundness- and hardness-amplification. In
particular, we make essential use of the Impagliazzo-Wigderson generator; our
analysis relies on a recent Chernoff-type theorem for expander walks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3671</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3671</id><created>2010-02-19</created><updated>2010-07-28</updated><authors><author><keyname>Pathak</keyname><forenames>Manas A.</forenames></author><author><keyname>Raj</keyname><forenames>Bhiksha</forenames></author></authors><title>Privacy-Preserving Protocols for Eigenvector Computation</title><categories>cs.CR cs.DB</categories><comments>14 pages</comments><journal-ref>Proceedings of ECML/PKDD Workshop on Privacy and Security issues
  in Data Mining and Machine Learning, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a protocol for computing the principal eigenvector
of a collection of data matrices belonging to multiple semi-honest parties with
privacy constraints. Our proposed protocol is based on secure multi-party
computation with a semi-honest arbitrator who deals with data encrypted by the
other parties using an additive homomorphic cryptosystem. We augment the
protocol with randomization and obfuscation to make it difficult for any party
to estimate properties of the data belonging to other parties from the
intermediate steps. The previous approaches towards this problem were based on
expensive QR decomposition of correlation matrices, we present an efficient
algorithm using the power iteration method. We analyze the protocol for
correctness, security, and efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3711</identifier>
 <datestamp>2010-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3711</id><created>2010-02-19</created><authors><author><keyname>Jureta</keyname><forenames>Ivan</forenames></author><author><keyname>Siena</keyname><forenames>Alberto</forenames></author><author><keyname>Mylopoulos</keyname><forenames>John</forenames></author><author><keyname>Perini</keyname><forenames>Anna</forenames></author><author><keyname>Susi</keyname><forenames>Angelo</forenames></author></authors><title>Theory of Regulatory Compliance for Requirements Engineering</title><categories>cs.SE</categories><comments>16 pages</comments><acm-class>D.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regulatory compliance is increasingly being addressed in the practice of
requirements engineering as a main stream concern. This paper points out a gap
in the theoretical foundations of regulatory compliance, and presents a theory
that states (i) what it means for requirements to be compliant, (ii) the
compliance problem, i.e., the problem that the engineer should resolve in order
to verify whether requirements are compliant, and (iii) testable hypotheses
(predictions) about how compliance of requirements is verified. The theory is
instantiated by presenting a requirements engineering framework that implements
its principles, and is exemplified on a real-world case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3724</identifier>
 <datestamp>2010-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3724</id><created>2010-02-19</created><updated>2010-02-22</updated><authors><author><keyname>Nasso</keyname><forenames>Sara</forenames><affiliation>Department of Information Engineering, University of Padova</affiliation></author><author><keyname>Silvestri</keyname><forenames>Francesco</forenames><affiliation>Department of Information Engineering, University of Padova</affiliation></author><author><keyname>Tisiot</keyname><forenames>Francesco</forenames><affiliation>Department of Information Engineering, University of Padova</affiliation></author><author><keyname>Di Camillo</keyname><forenames>Barbara</forenames><affiliation>Department of Information Engineering, University of Padova</affiliation></author><author><keyname>Pietracaprina</keyname><forenames>Andrea</forenames><affiliation>Department of Information Engineering, University of Padova</affiliation></author><author><keyname>Toffolo</keyname><forenames>Gianna Maria</forenames><affiliation>Department of Information Engineering, University of Padova</affiliation></author></authors><title>An Optimized Data Structure for High Throughput 3D Proteomics Data:
  mzRTree</title><categories>cs.CE cs.DS q-bio.QM</categories><comments>Paper details: 10 pages, 7 figures, 2 tables. To be published in
  Journal of Proteomics. Source code available at
  http://www.dei.unipd.it/mzrtree</comments><acm-class>J.3; E.2</acm-class><journal-ref>Journal of Proteomics 73(6) (2010) 1176-1182</journal-ref><doi>10.1016/j.jprot.2010.02.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As an emerging field, MS-based proteomics still requires software tools for
efficiently storing and accessing experimental data. In this work, we focus on
the management of LC-MS data, which are typically made available in standard
XML-based portable formats. The structures that are currently employed to
manage these data can be highly inefficient, especially when dealing with
high-throughput profile data. LC-MS datasets are usually accessed through 2D
range queries. Optimizing this type of operation could dramatically reduce the
complexity of data analysis. We propose a novel data structure for LC-MS
datasets, called mzRTree, which embodies a scalable index based on the R-tree
data structure. mzRTree can be efficiently created from the XML-based data
formats and it is suitable for handling very large datasets. We experimentally
show that, on all range queries, mzRTree outperforms other known structures
used for LC-MS data, even on those queries these structures are optimized for.
Besides, mzRTree is also more space efficient. As a result, mzRTree reduces
data analysis computational costs for very large profile datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3757</identifier>
 <datestamp>2010-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3757</id><created>2010-02-19</created><authors><author><keyname>Clementi</keyname><forenames>Andrea</forenames></author><author><keyname>Monti</keyname><forenames>Angelo</forenames></author><author><keyname>Silvestri</keyname><forenames>Riccardo</forenames></author></authors><title>Fast Flooding over Manhattan</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a Mobile Ad-hoc NETwork (MANET) formed by n agents that move at
speed V according to the Manhattan Random-Way Point model over a square region
of side length L. The resulting stationary (agent) spatial probability
distribution is far to be uniform: the average density over the &quot;central zone&quot;
is asymptotically higher than that over the &quot;suburb&quot;. Agents exchange data iff
they are at distance at most R within each other.
  We study the flooding time of this MANET: the number of time steps required
to broadcast a message from one source agent to all agents of the network in
the stationary phase. We prove the first asymptotical upper bound on the
flooding time. This bound holds with high probability, it is a decreasing
function of R and V, and it is tight for a wide and relevant range of the
network parameters (i.e. L, R and V).
  A consequence of our result is that flooding over the sparse and
highly-disconnected suburb can be as fast as flooding over the dense and
connected central zone. Rather surprisingly, this property holds even when R is
exponentially below the connectivity threshold of the MANET and the speed V is
very low.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3763</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3763</id><created>2010-02-19</created><updated>2010-09-06</updated><authors><author><keyname>Li</keyname><forenames>Jian</forenames></author><author><keyname>Mestre</keyname><forenames>Juli&#xe1;n</forenames></author></authors><title>Improved bounds for stochastic matching</title><categories>cs.DS cs.DM</categories><comments>This paper has been withdrawn due to new merged paper arXiv:1008.5356</comments><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This results in this paper have been merged with the result in
arXiv:1003.0167. The authors would like to withdraw this version. Please see
arXiv:1008.5356 for the merged version.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3769</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3769</id><created>2010-02-19</created><updated>2011-04-11</updated><authors><author><keyname>Kari</keyname><forenames>Lila</forenames></author><author><keyname>Masson</keyname><forenames>Beno&#xee;t</forenames></author></authors><title>Polyominoes Simulating Arbitrary-Neighborhood Zippers and Tilings</title><categories>cs.CC</categories><comments>Submitted to Theoretical Computer Science</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides a bridge between the classical tiling theory and the
complex neighborhood self-assembling situations that exist in practice. The
neighborhood of a position in the plane is the set of coordinates which are
considered adjacent to it. This includes classical neighborhoods of size four,
as well as arbitrarily complex neighborhoods. A generalized tile system
consists of a set of tiles, a neighborhood, and a relation which dictates which
are the &quot;admissible&quot; neighboring tiles of a given tile. Thus, in correctly
formed assemblies, tiles are assigned positions of the plane in accordance to
this relation. We prove that any validly tiled path defined in a given but
arbitrary neighborhood (a zipper) can be simulated by a simple &quot;ribbon&quot; of
microtiles. A ribbon is a special kind of polyomino, consisting of a
non-self-crossing sequence of tiles on the plane, in which successive tiles
stick along their adjacent edge. Finally, we extend this construction to the
case of traditional tilings, proving that we can simulate
arbitrary-neighborhood tilings by simple-neighborhood tilings, while preserving
some of their essential properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3770</identifier>
 <datestamp>2014-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3770</id><created>2010-02-19</created><authors><author><keyname>Arias</keyname><forenames>Antonia Perez</forenames></author><author><keyname>Hanebeck</keyname><forenames>Uwe D.</forenames></author><author><keyname>Ehrhardt</keyname><forenames>Peter</forenames></author><author><keyname>Hengst</keyname><forenames>Stefan</forenames></author><author><keyname>Kretz</keyname><forenames>Tobias</forenames></author><author><keyname>Vortisch</keyname><forenames>Peter</forenames></author></authors><title>Extended Range Telepresence for Evacuation Training in Pedestrian
  Simulations</title><categories>cs.HC cs.MA</categories><comments>Contribution to Pedestrian and Evacuation Dynamics 2010 (PED2010)
  conference</comments><doi>10.1007/978-1-4419-9725-8_18</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this contribution, we propose a new framework to evaluate pedestrian
simula-tions by using Extended Range Telepresence. Telepresence is used as a
virtual reality walking simulator, which provides the user with a realistic
impression of being present and walking in a virtual environment that is much
larger than the real physical environment, in which the user actually walks.
The validation of the simulation is performed by comparing motion data of the
telepresent user with simulated data at some points of the simulation. The use
of haptic feedback from the simulation makes the framework suitable for
training in emergency situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3814</identifier>
 <datestamp>2010-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3814</id><created>2010-02-19</created><authors><author><keyname>Grabisch</keyname><forenames>Michel</forenames><affiliation>CES</affiliation></author></authors><title>The lattice of embedded subsets</title><categories>cs.DM cs.GT</categories><proxy>ccsd hal-00457827</proxy><journal-ref>Discrete Applied Mathematics 158 (2010) 479-488</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In cooperative game theory, games in partition function form are real-valued
function on the set of so-called embedded coalitions, that is, pairs $(S,\pi)$
where $S$ is a subset (coalition) of the set $N$ of players, and $\pi$ is a
partition of $N$ containing $S$. Despite the fact that many studies have been
devoted to such games, surprisingly nobody clearly defined a structure (i.e.,
an order) on embedded coalitions, resulting in scattered and divergent works,
lacking unification and proper analysis. The aim of the paper is to fill this
gap, thus to study the structure of embedded coalitions (called here embedded
subsets), and the properties of games in partition function form.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3864</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3864</id><created>2010-02-20</created><authors><author><keyname>Harsha</keyname><forenames>Prahladh</forenames></author><author><keyname>Charikar</keyname><forenames>Moses</forenames></author><author><keyname>Andrews</keyname><forenames>Matthew</forenames></author><author><keyname>Arora</keyname><forenames>Sanjeev</forenames></author><author><keyname>Khot</keyname><forenames>Subhash</forenames></author><author><keyname>Moshkovitz</keyname><forenames>Dana</forenames></author><author><keyname>Zhang</keyname><forenames>Lisa</forenames></author><author><keyname>Aazami</keyname><forenames>Ashkan</forenames></author><author><keyname>Desai</keyname><forenames>Dev</forenames></author><author><keyname>Gorodezky</keyname><forenames>Igor</forenames></author><author><keyname>Jagannathan</keyname><forenames>Geetha</forenames></author><author><keyname>Kulikov</keyname><forenames>Alexander S.</forenames></author><author><keyname>Mir</keyname><forenames>Darakhshan J.</forenames></author><author><keyname>Newman</keyname><forenames>Alantha</forenames></author><author><keyname>Nikolov</keyname><forenames>Aleksandar</forenames></author><author><keyname>Pritchard</keyname><forenames>David</forenames></author><author><keyname>Spencer</keyname><forenames>Gwen</forenames></author></authors><title>Limits of Approximation Algorithms: PCPs and Unique Games (DIMACS
  Tutorial Lecture Notes)</title><categories>cs.CC cs.DS</categories><comments>74 pages, lecture notes</comments><report-no>DIMACS Technical Report 2010-02</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  These are the lecture notes for the DIMACS Tutorial &quot;Limits of Approximation
Algorithms: PCPs and Unique Games&quot; held at the DIMACS Center, CoRE Building,
Rutgers University on 20-21 July, 2009. This tutorial was jointly sponsored by
the DIMACS Special Focus on Hardness of Approximation, the DIMACS Special Focus
on Algorithmic Foundations of the Internet, and the Center for Computational
Intractability with support from the National Security Agency and the National
Science Foundation.
  The speakers at the tutorial were Matthew Andrews, Sanjeev Arora, Moses
Charikar, Prahladh Harsha, Subhash Khot, Dana Moshkovitz and Lisa Zhang. The
sribes were Ashkan Aazami, Dev Desai, Igor Gorodezky, Geetha Jagannathan,
Alexander S. Kulikov, Darakhshan J. Mir, Alantha Newman, Aleksandar Nikolov,
David Pritchard and Gwen Spencer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3866</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3866</id><created>2010-02-20</created><updated>2011-03-04</updated><authors><author><keyname>Bassino</keyname><forenames>Fr&#xe9;d&#xe9;rique</forenames><affiliation>LIPN</affiliation></author><author><keyname>Bouvel</keyname><forenames>Mathilde</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Pierrot</keyname><forenames>Adeline</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Rossin</keyname><forenames>Dominique</forenames><affiliation>LIX</affiliation></author></authors><title>Deciding the finiteness of the number of simple permutations contained
  in a wreath-closed class is polynomial</title><categories>cs.DS math.CO</categories><proxy>ccsd</proxy><journal-ref>Pure Mathematics and Applications 21, 2 (2010) 119-135</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm running in time O(n ln n) which decides if a
wreath-closed permutation class Av(B) given by its finite basis B contains a
finite number of simple permutations. The method we use is based on an article
of Brignall, Ruskuc and Vatter which presents a decision procedure (of high
complexity) for solving this question, without the assumption that Av(B) is
wreath-closed. Using combinatorial, algorithmic and language theoretic
arguments together with one of our previous results on pin-permutations, we are
able to transform the problem into a co-finiteness problem in a complete
deterministic automaton.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3893</identifier>
 <datestamp>2010-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3893</id><created>2010-02-20</created><updated>2010-02-23</updated><authors><author><keyname>Chawla</keyname><forenames>Shuchi</forenames></author><author><keyname>Malec</keyname><forenames>David</forenames></author><author><keyname>Sivan</keyname><forenames>Balasubramanian</forenames></author></authors><title>The power of randomness in Bayesian optimal mechanism design</title><categories>cs.GT</categories><comments>Minor formatting changes</comments><acm-class>J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the power of randomness in the context of a fundamental
Bayesian optimal mechanism design problem--a single seller aims to maximize
expected revenue by allocating multiple kinds of resources to &quot;unit-demand&quot;
agents with preferences drawn from a known distribution. When the agents'
preferences are single-dimensional Myerson's seminal work [Myerson '81] shows
that randomness offers no benefit--the optimal mechanism is always
deterministic. In the multi-dimensional case, where each agent's preferences
are given by different values for each of the available services, Briest et al.
[Briest, Chawla, Kleinberg, and Weinberg '10] recently showed that the gap
between the expected revenue obtained by an optimal randomized mechanism and an
optimal deterministic mechanism can be unbounded even when a single agent is
offered only 4 services. However, this large gap is attained through unnatural
instances where values of the agent for different services are correlated in a
specific way. We show that when the agent's values involve no correlation or a
specific kind of positive correlation, the benefit of randomness is only a
small constant factor (4 and 8 respectively). Our model of positively
correlated values (that we call additive values) is a natural model for
unit-demand agents and items that are substitutes. Our results extend to
multiple agent settings as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3909</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3909</id><created>2010-02-22</created><updated>2010-03-24</updated><authors><author><keyname>Choe</keyname><forenames>HaengJin</forenames></author></authors><title>Proposal new area of study by connecting between information theory and
  Weber-Fechner law</title><categories>cs.IT math.IT</categories><comments>8 pages, no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rough speaking, information theory deals with data transmitted over a channel
such as the internet. Modern information theory is generally considered to have
been founded in 1948 by Shannon in his seminal paper, &quot;A mathematical theory of
communication.&quot; Shannon's formulation of information theory was an immediate
success with communications engineers. Shannon defined mathematically the
amount of information transmitted over a channel. The amount of information
doesn't mean the number of symbols of data. It depends on occurrence
probabilities of symbols of the data. Meanwhile, psychophysics is the study of
quantitative relations between psychological events and physical events or,
more specifically, between sensations and the stimuli that produce them. It
seems that Shannon's information theory bears no relation to psychophysics
established by German scientist and philosopher Fechner. Here I show that to
our astonishment it is possible to combine two fields. And therefore we come to
be capable of measuring mathematically perceptions of the physical stimuli
applicable to the Weber-Fechner law. I will define the concept of new entropy.
And as a consequence of this, new field will begin life.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3931</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3931</id><created>2010-02-20</created><authors><author><keyname>Noam</keyname><forenames>Yair</forenames></author><author><keyname>Leshem</keyname><forenames>Amir</forenames></author><author><keyname>Messer</keyname><forenames>Hagit</forenames></author></authors><title>Competitive Spectrum Management with Incomplete Information</title><categories>cs.IT cs.GT math.IT</categories><doi>10.1109/TSP.2010.2077286</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies an interference interaction (game) between selfish and
independent wireless communication systems in the same frequency band. Each
system (player) has incomplete information about the other player's channel
conditions. A trivial Nash equilibrium point in this game is where players
mutually full spread (FS) their transmit spectrum and interfere with each
other. This point may lead to poor spectrum utilization from a global network
point of view and even for each user individually.
  In this paper, we provide a closed form expression for a non pure-FS
epsilon-Nash equilibrium point; i.e., an equilibrium point where players choose
FDM for some channel realizations and FS for the others. We show that operating
in this non pure-FS epsilon-Nash equilibrium point increases each user's
throughput and therefore improves the spectrum utilization, and demonstrate
that this performance gain can be substantial. Finally, important insights are
provided into the behaviour of selfish and rational wireless users as a
function of the channel parameters such as fading probabilities, the
interference-to-signal ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3937</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3937</id><created>2010-02-20</created><authors><author><keyname>Palvolgyi</keyname><forenames>Domotor</forenames></author></authors><title>Partitionability to two trees is NP-complete</title><categories>cs.CC cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that P2T - the problem of deciding whether the edge set of a simple
graph can be partitioned into two trees or not - is NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3943</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3943</id><created>2010-02-20</created><updated>2012-12-12</updated><authors><author><keyname>Madhusudhanan</keyname><forenames>Prasanna</forenames></author><author><keyname>Restrepo</keyname><forenames>Juan G.</forenames></author><author><keyname>Liu</keyname><forenames>Youjian</forenames></author><author><keyname>Brown</keyname><forenames>Timothy X</forenames></author><author><keyname>Baker</keyname><forenames>Kenneth R.</forenames></author></authors><title>Downlink Performance Analysis for a Generalized Shotgun Cellular System</title><categories>cs.IT math.IT</categories><comments>30 pages, 8 figures, re-submitted to Transactions on Communications
  on Sep-12 2012, initial submission to Transactions on Communications on
  26-Apr 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the signal-to-interference-plus-noise ratio (SINR)
performance at a mobile station (MS) in a random cellular network. The cellular
network is formed by base-stations (BSs) placed in a one, two or three
dimensional space according to a possibly non-homogeneous Poisson point
process, which is a generalization of the so-called shotgun cellular system. We
develop a sequence of equivalence relations for the SCSs and use them to derive
semi-analytical expressions for the coverage probability at the MS when the
transmissions from each BS may be affected by random fading with arbitrary
distributions as well as attenuation following arbitrary path-loss models. For
homogeneous Poisson point processes in the interference-limited case with
power-law path-loss model, we show that the SINR distribution is the same for
all fading distributions and is not a function of the base station density. In
addition, the influence of random transmission powers, power control, multiple
channel reuse groups on the downlink performance are also discussed. The
techniques developed for the analysis of SINR have applications beyond cellular
networks and can be used in similar studies for cognitive radio networks,
femtocell networks and other heterogeneous and multi-tier networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3983</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3983</id><created>2010-02-21</created><authors><author><keyname>Shrivastava</keyname><forenames>Sonal</forenames></author><author><keyname>Pardasani</keyname><forenames>K. R.</forenames></author><author><keyname>Malik</keyname><forenames>M. M.</forenames></author></authors><title>SVM Model for Identification of human GPCRs</title><categories>cs.OH q-bio.QM</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  G-protein coupled receptors (GPCRs) constitute a broad class of cell-surface
receptors in eukaryotes and they possess seven transmembrane a-helical domains.
GPCRs are usually classified into several functionally distinct families that
play a key role in cellular signalling and regulation of basic physiological
processes. We can develop statistical models based on these common features
that can be used to classify proteins, to predict new members, and to study the
sequence-function relationship of this protein function group. In this study,
SVM based classification model has been developed for the identification of
human gpcr sequences. Sequences of Level 1 subfamilies of Class A rhodopsin is
considered as case study. In the present study, an attempt has been made to
classify GPCRs on the basis of species. The present study classifies human gpcr
sequences with rest of the species available in GPCRDB. Classification is based
on specific information derived from the n-terminal and extracellular loops of
the sequences, some physicochemical properties and amino acid composition of
corresponding gpcr sequences. Our method classifies Level 1 subfamilies of
GPCRs with 94% accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3984</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3984</id><created>2010-02-21</created><authors><author><keyname>Aggarwal</keyname><forenames>Deepak</forenames></author><author><keyname>Dhindsa</keyname><forenames>Kanwalvir Singh</forenames></author></authors><title>Effect of Embedding Watermark on Compression of the Digital Images</title><categories>cs.MM</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image Compression plays a very important role in image processing especially
when we are to send the image on the internet. The threat to the information on
the internet increases and image is no exception. Generally the image is sent
on the internet as the compressed image to optimally use the bandwidth of the
network. But as we are on the network, at any intermediate level the image can
be changed intentionally or unintentionally. To make sure that the correct
image is being delivered at the other end we embed the water mark to the image.
The watermarked image is then compressed and sent on the network. When the
image is decompressed at the other end we can extract the watermark and make
sure that the image is the same that was sent by the other end. Though
watermarking the image increases the size of the uncompressed image but that
has to done to achieve the high degree of robustness i.e. how an image sustains
the attacks on it. The present paper is an attempt to make transmission of the
images secure from the intermediate attacks by applying the generally used
compression transforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3985</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3985</id><created>2010-02-21</created><authors><author><keyname>Hossain</keyname><forenames>Md. Imran</forenames></author><author><keyname>Rajib</keyname><forenames>Syed Golam</forenames></author></authors><title>Supervised Learning of Digital image restoration based on Quantization
  Nearest Neighbor algorithm</title><categories>cs.CV</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an algorithm is proposed for Image Restoration. Such algorithm
is different from the traditional approaches in this area, by utilizing priors
that are learned from similar images. Original images and their degraded
versions by the known degradation operators are utilized for designing the
Quantization. The code vectors are designed using the blurred images. For each
such vector, the high frequency information obtained from the original images
is also available. During restoration, the high frequency information of a
given degraded image is estimated from its low frequency information based on
the artificial noise. For the restoration problem, a number of techniques are
designed corresponding to various versions of the blurring function. Given a
noisy and blurred image, one of the techniques is chosen based on a similarity
measure, therefore providing the identification of the blur. To make the
restoration process computationally efficient, the Quantization Nearest
Neighborhood approaches are utilized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3989</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3989</id><created>2010-02-21</created><updated>2011-12-14</updated><authors><author><keyname>Hossain</keyname><forenames>Md. Imran</forenames></author><author><keyname>Suvo</keyname><forenames>Md. Iqbal Hossain</forenames></author></authors><title>Performance analysis of Zone Routing Protocol in respect of Genetic
  Algorithm and Estimation of Distribution Algorithm</title><categories>cs.NI</categories><comments>Remove based on author's request</comments><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, Estimation of Distribution Algorithm (EDA) is used for Zone
Routing Protocol (ZRP) in Mobile Ad-hoc Network instead of Genetic Algorithm
(GA). It is an evolutionary approach, it is used when the network size grows
and the search space increases. When the destination is outside the zone, EDA
is applied to find the route with minimum cost and time. Finally, the
implementation of proposed method is compared with Genetic ZRP, i.e., GZRP and
the result demonstrates better performance for the proposed method. Since the
method provides a set of paths to the destination, it results in load balance
to the network. As both EDA and GA use random search method to reach the
optimal point, the searching cost reduced significantly, especially when the
number of data is large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3990</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3990</id><created>2010-02-21</created><authors><author><keyname>Chavet</keyname><forenames>Cyrille</forenames><affiliation>Lab-Sticc, ST Microelectronics</affiliation></author><author><keyname>Coussy</keyname><forenames>Philippe</forenames><affiliation>Lab-Sticc</affiliation></author><author><keyname>Martin</keyname><forenames>Eric</forenames><affiliation>Lab-Sticc</affiliation></author><author><keyname>Urard</keyname><forenames>Pascal</forenames><affiliation>ST Microelectronics</affiliation></author></authors><title>Static Address Generation Easing: a Design Methodology for Parallel
  Interleaver Architectures</title><categories>cs.AR cs.IT math.IT</categories><comments>4 pages</comments><proxy>ccsd hal-00455121</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For high throughput applications, turbo-like iterative decoders are
implemented with parallel architectures. However, to be efficient parallel
architectures require to avoid collision accesses i.e. concurrent read/write
accesses should not target the same memory block. This consideration applies to
the two main classes of turbo-like codes which are Low Density Parity Check
(LDPC) and Turbo-Codes. In this paper we propose a methodology which finds a
collision-free mapping of the variables in the memory banks and which optimizes
the resulting interleaving architecture. Finally, we show through a pedagogical
example the interest of our approach compared to state-of-the-art techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3992</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3992</id><created>2010-02-21</created><authors><author><keyname>Bercea</keyname><forenames>L.</forenames></author><author><keyname>Nemtoi</keyname><forenames>G.</forenames></author><author><keyname>Ungureanu</keyname><forenames>C.</forenames></author></authors><title>The government of state's power bodies by means of the Internet</title><categories>cs.CY</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The electronic government involves developing the informational society,
which refers to an economy and a society in which the access, acquisition,
memorizing, taking, transmitting, spreading and using the knowledge accede to a
decisive role. The informational society involves changes in the domains of
administration (e-Government), business (electronic commerce and e-business),
education (long distance education), culture (multimedia centers and virtual
libraries), mass- media (TV, video advertising panels), and in the labor manner
(tele-work and virtual commuting).The e-government refers to the interaction
between the Government, Parliament and other public institutions with the
citizens by the electronic means.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3994</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3994</id><created>2010-02-21</created><authors><author><keyname>Bhagyalakshmi</keyname><forenames>H. R.</forenames></author><author><keyname>Venkatesha</keyname><forenames>M. K.</forenames></author></authors><title>Optimized reversible BCD adder using new reversible logic gates</title><categories>cs.OH</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reversible logic has received great attention in the recent years due to
their ability to reduce the power dissipation which is the main requirement in
low power digital design. It has wide applications advanced computing, low
power CMOS design, Optical information processing, DNA computing, bio
information, quantum computation and nanotechnology. This paper presents an
optimized reversible BCD adder using a new reversible gate. A comparative
result is presented which shows that the proposed design is more optimized in
terms of number of gates, number of garbage outputs and quantum cost than the
existing designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3995</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3995</id><created>2010-02-21</created><authors><author><keyname>Holban</keyname><forenames>N.</forenames></author><author><keyname>Ditoiu</keyname><forenames>V.</forenames></author><author><keyname>Iancu</keyname><forenames>E.</forenames></author></authors><title>Determining the quality evaluation procedures using the expert systems</title><categories>cs.OH</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At this time, quality is a strategic instrument of the entities' global
management, but it is also a determining element of their competitive spirit.
The importance given to quality is abundantly found in the preoccupations of
the European Union's Minister Board, by elaborating documents with a high
impact over the quality of products/ services in special, and organizations in
general. We live in an era, when the evolution of the social life puts the
accent more and more on quality, resulted from various processes, at the level
of various domains of the economical and social development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3996</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3996</id><created>2010-02-21</created><updated>2010-03-29</updated><authors><author><keyname>Saqib</keyname><forenames>Sheikh Muhammad</forenames></author><author><keyname>Ahmad</keyname><forenames>Shakeel</forenames></author><author><keyname>Hussain</keyname><forenames>Shahid</forenames></author><author><keyname>Ahmad</keyname><forenames>Bashir</forenames></author><author><keyname>Bano</keyname><forenames>Arjamand</forenames></author></authors><title>Improvement in RUP Project Management via Service Monitoring: Best
  Practice of SOA</title><categories>cs.SE</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Management of project planning, monitoring, scheduling, estimation and risk
management are critical issues faced by a project manager during development
life cycle of software. In RUP, project management is considered as core
discipline whose activities are carried in all phases during development of
software products. On other side service monitoring is considered as best
practice of SOA which leads to availability, auditing, debugging and tracing
process. In this paper, authors define a strategy to incorporate the service
monitoring of SOA into RUP to improve the artifacts of project management
activities. Moreover, the authors define the rules to implement the features of
service monitoring, which help the project manager to carry on activities in
well define manner. Proposed frame work is implemented on RB (Resuming Bank)
application and obtained improved results on PM (Project Management) work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3997</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3997</id><created>2010-02-21</created><authors><author><keyname>Grosu</keyname><forenames>V.</forenames></author><author><keyname>Hlaciuc</keyname><forenames>E.</forenames></author><author><keyname>Iancu</keyname><forenames>E.</forenames></author><author><keyname>Petris</keyname><forenames>R.</forenames></author><author><keyname>Socoliuc</keyname><forenames>M.</forenames></author></authors><title>The Role of the XBRL Standard in Optimizing the Financial Reporting</title><categories>cs.OH</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When the financial information is difficult to produce, interpret, compare
and analyze, we are put in the situation to face inconvenient consequences with
negative repercussions, such as: the investor can give up the investment (with
negative consequences on the risk equity market), the banks may not give loans,
an auditor may not consider the financial statements as being credible etc.
These facts allow the introduction of this paper's main objective, the
eXtensible Business Reporting Language (XBRL) which is an open standard,
independent and international for the treatments, opportunity, correctness,
efficiency and minor costs of the financial and economical information. The
XBRL will be analyzed in the second part of the paper, the history of this
electronic communication language will be described, as there will also be
described the promoting organizations, the base technology (the WEB and XML
architecture which will be the next stage of the internet programming), and the
role it has within the chain of reporting between the XBRL consortium and the
international accounting organizations IASB-CI. This taxonomy serves clearly
every accounting and extra- accounting information made by the company. This
information which is treated in present by resorting to various formats or
structures (most times incompatible between them and the owners) will be
standardized with the XBRL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3998</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3998</id><created>2010-02-21</created><authors><author><keyname>Ahmad</keyname><forenames>Shakeel</forenames></author><author><keyname>Mustafa</keyname><forenames>Adli</forenames></author><author><keyname>Awan</keyname><forenames>Zahid</forenames></author><author><keyname>Ahmad</keyname><forenames>Bashir</forenames></author><author><keyname>Najeebullah</keyname></author><author><keyname>Bano</keyname><forenames>Arjamand</forenames></author></authors><title>E-Courseware Design and Implementation Issues and Strategies</title><categories>cs.CY</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the last few years electronic learning has been in use mostly by
corporate institutes in the form of computer aided instructions and computer
based training. The scope of such use has not only been limited to introductory
courses for beginners and working people but also to impart knowledge in higher
education sector. Due to increasing market demands and current prevailing law
and order situation of this area (during which the University remain closed for
uncertain period of time on many occasions) Gomal University D.I.Khan, Pakistan
is planning to introduce e-learning at undergraduate and post graduate level in
computer and management sciences for smooth and uninterrupted delivery of
quality education to local and distant students. Obvious result of elearning
will be two fold. First it will meet market demands along with smooth
uninterrupted delivery of quality education and secondly will solve the growing
problem of shortage of experts raised by the current law and order situation.
This paper investigates the main issues involved in designing and implementing
an effective electronic courseware for students with diverse backgrounds
belonging to this remote area. Some effective strategies for electronic
delivery of courses to local and distant students are also presented along with
some examples of implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.3999</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.3999</id><created>2010-02-21</created><authors><author><keyname>Ullah</keyname><forenames>M. Habib</forenames></author><author><keyname>Bari</keyname><forenames>Md. Niamul</forenames></author><author><keyname>Priantoro</keyname><forenames>A. Unggul</forenames></author></authors><title>FPGA Implementation of LS Code Generator for CDM Based MIMO Channel
  Sounder</title><categories>cs.NI</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MIMO (Multi Input Multi Output) wireless communication system is an
innovative solution to improve the bandwidth efficiency by exploiting
multipath-richness of the propagation environment. The degree of
multipath-richness of the channel will determine the capacity gain attainable
by MIMO deployment. Therefore, it is very important to have accurate knowledge
of the propagation environment/radio channel before MIMO implement. The radio
channel behavior can be estimated by channel measurement or channel sounding.
CDM (Code Division multiplexing) is one of the channel sounding techniques that
allow accurate measurement at the cost of hardware complexity. CDM based
channel sounder, requires code with excellent autocorrelation and
cross-correlation properties which generally difficult to achieve
simultaneously. Theoretical analysis and computer simulation result
demonstrated that, having excellent correlation propertied Loosely Synchronous
(LS) code sequence perform efficiently. Finally, the an efficient LS code
generator as a data source for transmitter implemented in Xilinx FPGA that can
be integrated into CDM based 2x2 MIMO complete channel sounder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4000</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4000</id><created>2010-02-21</created><authors><author><keyname>Sheikh</keyname><forenames>Rashid</forenames></author><author><keyname>Kumar</keyname><forenames>Beerendra</forenames></author><author><keyname>Mishra</keyname><forenames>Durgesh Kumar</forenames></author></authors><title>A Modified ck-Secure Sum Protocol for Multi-Party Computation</title><categories>cs.CR</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secure Multi-Party Computation (SMC) allows multiple parties to compute some
function of their inputs without disclosing the actual inputs to one another.
Secure sum computation is an easily understood example and the component of the
various SMC solutions. Secure sum computation allows parties to compute the sum
of their individual inputs without disclosing the inputs to one another. In
this paper, we propose a modified version of our ck-Secure Sum protocol with
more security when a group of the computing parties conspire to know the data
of some party.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4002</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4002</id><created>2010-02-21</created><authors><author><keyname>Ojha</keyname><forenames>A. K.</forenames></author><author><keyname>Das</keyname><forenames>A. K.</forenames></author></authors><title>Multi-Objective Geometric Programming Problem Being Cost Coefficients as
  Continous Function with Weighted Mean Method</title><categories>cs.DS cs.NA</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Geometric programming problems occur frequently in engineering design and
management. In multiobjective optimization, the trade-off information between
different objective functions is probably the most important piece of
information in a solution process to reach the most preferred solution. In this
paper we have discussed the basic concepts and principles of multiple objective
optimization problems and developed a solution procedure to solve this
optimization problem where the cost coefficients are continuous functions using
weighted method to obtain the non-inferior solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4003</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4003</id><created>2010-02-21</created><authors><author><keyname>Dhaliwal</keyname><forenames>Parneeta</forenames></author><author><keyname>Bhatia</keyname><forenames>M. P. S.</forenames></author><author><keyname>Bansal</keyname><forenames>Priti</forenames></author></authors><title>A Cluster-based Approach for Outlier Detection in Dynamic Data Streams
  (KORM: k-median OutlieR Miner)</title><categories>cs.DC</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Outlier detection in data streams has gained wide importance presently due to
the increasing cases of fraud in various applications of data streams. The
techniques for outlier detection have been divided into either statistics
based, distance based, density based or deviation based. Till now, most of the
work in the field of fraud detection was distance based but it is incompetent
from computational point of view. In this paper we introduced a new clustering
based approach, which divides the stream in chunks and clusters each chunk
using kmedian into variable number of clusters. Instead of storing complete
data stream chunk in memory, we replace it with the weighted medians found
after mining a data stream chunk and pass that information along with the newly
arrived data chunk to the next phase. The weighted medians found in each phase
are tested for outlierness and after a given number of phases, it is either
declared as a real outlier or an inlier. Our technique is theoretically better
than the k-means as it does not fix the number of clusters to k rather gives a
range to it and provides a more stable and better solution which runs in
poly-logarithmic space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4004</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4004</id><created>2010-02-21</created><authors><author><keyname>Singh</keyname><forenames>Manoj Kumar</forenames></author></authors><title>Nature inspired artificial intelligence based adaptive traffic flow
  distribution in computer network</title><categories>cs.NE</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Because of the stochastic nature of traffic requirement matrix, it is very
difficult to get the optimal traffic distribution to minimize the delay even
with adaptive routing protocol in a fixed connection network where capacity
already defined for each link. Hence there is a requirement to define such a
method, which could generate the optimal solution very quickly and efficiently.
This paper presenting a new concept to provide the adaptive optimal traffic
distribution for dynamic condition of traffic matrix using nature based
intelligence methods. With the defined load and fixed capacity of links,
average delay for packet has minimized with various variations of evolutionary
programming and particle swarm optimization. Comparative study has given over
their performance in terms of converging speed. Universal approximation
capability, the key feature of feed forward neural network has applied to
predict the flow distribution on each link to minimize the average delay for a
total load available at present on the network. For any variation in the total
load, the new flow distribution can be generated by neural network immediately,
which could generate minimum delay in the network. With the inclusion of this
information, performance of routing protocol will be improved very much.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4005</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4005</id><created>2010-02-21</created><authors><author><keyname>D'Souza</keyname><forenames>Rio G. L.</forenames></author><author><keyname>Sekaran</keyname><forenames>K. Chandra</forenames></author><author><keyname>Kandasamy</keyname><forenames>A.</forenames></author></authors><title>Improved NSGA-II Based on a Novel Ranking Scheme</title><categories>cs.DS</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-dominated Sorting Genetic Algorithm (NSGA) has established itself as a
benchmark algorithm for Multiobjective Optimization. The determination of
pareto-optimal solutions is the key to its success. However the basic algorithm
suffers from a high order of complexity, which renders it less useful for
practical applications. Among the variants of NSGA, several attempts have been
made to reduce the complexity. Though successful in reducing the runtime
complexity, there is scope for further improvements, especially considering
that the populations involved are frequently of large size. We propose a
variant which reduces the run-time complexity using the simple principle of
space-time trade-off. The improved algorithm is applied to the problem of
classifying types of leukemia based on microarray data. Results of comparative
tests are presented showing that the improved algorithm performs well on large
populations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4006</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4006</id><created>2010-02-21</created><authors><author><keyname>Mollah</keyname><forenames>Ayatullah Faruk</forenames></author><author><keyname>Basu</keyname><forenames>Subhadip</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author></authors><title>Text/Graphics Separation and Skew Correction of Text Regions of Business
  Card Images for Mobile Devices</title><categories>cs.GR</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Separation of the text regions from background texture and graphics is an
important step of any optical character recognition system for the images
containing both texts and graphics. In this paper, we have presented a novel
text/graphics separation technique and a method for skew correction of text
regions extracted from business card images captured with a cell-phone camera.
At first, the background is eliminated at a coarse level based on intensity
variance. This makes the foreground components distinct from each other. Then
the non-text components are removed using various characteristic features of
text and graphics. Finally, the text regions are skew corrected for further
processing. Experimenting with business card images of various resolutions, we
have found an optimum performance of 98.25% (recall) with 0.75 MP images, that
takes 0.17 seconds processing time and 1.1 MB peak memory on a moderately
powerful computer (DualCore 1.73 GHz Processor, 1 GB RAM, 1 MB L2 Cache). The
developed technique is computationally efficient and consumes low memory so as
to be applicable on mobile devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4007</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4007</id><created>2010-02-21</created><authors><author><keyname>Sarkar</keyname><forenames>Ram</forenames></author><author><keyname>Das</keyname><forenames>Nibaran</forenames></author><author><keyname>Basu</keyname><forenames>Subhadip</forenames></author><author><keyname>Kundu</keyname><forenames>Mahantapas</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author></authors><title>Word level Script Identification from Bangla and Devanagri Handwritten
  Texts mixed with Roman Script</title><categories>cs.LG</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  India is a multi-lingual country where Roman script is often used alongside
different Indic scripts in a text document. To develop a script specific
handwritten Optical Character Recognition (OCR) system, it is therefore
necessary to identify the scripts of handwritten text correctly. In this paper,
we present a system, which automatically separates the scripts of handwritten
words from a document, written in Bangla or Devanagri mixed with Roman scripts.
In this script separation technique, we first, extract the text lines and words
from document pages using a script independent Neighboring Component Analysis
technique. Then we have designed a Multi Layer Perceptron (MLP) based
classifier for script separation, trained with 8 different wordlevel holistic
features. Two equal sized datasets, one with Bangla and Roman scripts and the
other with Devanagri and Roman scripts, are prepared for the system evaluation.
On respective independent text samples, word-level script identification
accuracies of 99.29% and 98.43% are achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4014</identifier>
 <datestamp>2015-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4014</id><created>2010-02-21</created><updated>2011-06-16</updated><authors><author><keyname>Rampone</keyname><forenames>Salvatore</forenames></author><author><keyname>Russo</keyname><forenames>Ciro</forenames></author></authors><title>A fuzzified BRAIN algorithm for learning DNF from incomplete data</title><categories>cs.IT cs.AI math.IT math.LO</categories><msc-class>68T37</msc-class><journal-ref>Electronic Journal of Applied Statistical Analysis, Vol. 5, Issue
  2, 256-270, 2012</journal-ref><doi>10.1285/i20705948v5n2p256</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aim of this paper is to address the problem of learning Boolean functions
from training data with missing values. We present an extension of the BRAIN
algorithm, called U-BRAIN (Uncertainty-managing Batch Relevance-based
Artificial INtelligence), conceived for learning DNF Boolean formulas from
partial truth tables, possibly with uncertain values or missing bits.
  Such an algorithm is obtained from BRAIN by introducing fuzzy sets in order
to manage uncertainty. In the case where no missing bits are present, the
algorithm reduces to the original BRAIN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4019</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4019</id><created>2010-02-21</created><authors><author><keyname>Bellala</keyname><forenames>Gowtham</forenames></author><author><keyname>Bhavnani</keyname><forenames>Suresh</forenames></author><author><keyname>Scott</keyname><forenames>Clayton</forenames></author></authors><title>Query Learning with Exponential Query Costs</title><categories>stat.ML cs.IT math.IT</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In query learning, the goal is to identify an unknown object while minimizing
the number of &quot;yes&quot; or &quot;no&quot; questions (queries) posed about that object. A
well-studied algorithm for query learning is known as generalized binary search
(GBS). We show that GBS is a greedy algorithm to optimize the expected number
of queries needed to identify the unknown object. We also generalize GBS in two
ways. First, we consider the case where the cost of querying grows
exponentially in the number of queries and the goal is to minimize the expected
exponential cost. Then, we consider the case where the objects are partitioned
into groups, and the objective is to identify only the group to which the
object belongs. We derive algorithms to address these issues in a common,
information-theoretic framework. In particular, we present an exact formula for
the objective function in each case involving Shannon or Renyi entropy, and
develop a greedy algorithm for minimizing it. Our algorithms are demonstrated
on two applications of query learning, active learning and emergency response.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4020</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4020</id><created>2010-02-22</created><authors><author><keyname>Steudel</keyname><forenames>Bastian</forenames></author><author><keyname>Janzing</keyname><forenames>Dominik</forenames></author><author><keyname>Schoelkopf</keyname><forenames>Bernhard</forenames></author></authors><title>Causal Markov condition for submodular information measures</title><categories>cs.IT math.IT</categories><comments>21 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The causal Markov condition (CMC) is a postulate that links observations to
causality. It describes the conditional independences among the observations
that are entailed by a causal hypothesis in terms of a directed acyclic graph.
In the conventional setting, the observations are random variables and the
independence is a statistical one, i.e., the information content of
observations is measured in terms of Shannon entropy. We formulate a
generalized CMC for any kind of observations on which independence is defined
via an arbitrary submodular information measure. Recently, this has been
discussed for observations in terms of binary strings where information is
understood in the sense of Kolmogorov complexity. Our approach enables us to
find computable alternatives to Kolmogorov complexity, e.g., the length of a
text after applying existing data compression schemes. We show that our CMC is
justified if one restricts the attention to a class of causal mechanisms that
is adapted to the respective information measure. Our justification is similar
to deriving the statistical CMC from functional models of causality, where
every variable is a deterministic function of its observed causes and an
unobserved noise term.
  Our experiments on real data demonstrate the performance of compression based
causal inference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4022</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4022</id><created>2010-02-21</created><authors><author><keyname>Ekrem</keyname><forenames>Ersen</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>An Alternative Proof for the Capacity Region of the Degraded Gaussian
  MIMO Broadcast Channel</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, February 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide an alternative proof for the capacity region of the degraded
Gaussian multiple-input multiple-output (MIMO) broadcast channel. Our proof
does not use the channel enhancement technique as opposed to the original proof
of Weingertan {\it et. al.} and the alternative proof of Liu {\it et. al}. Our
proof starts with the single-letter description of the capacity region of the
degraded broadcast channel, and directly evaluates it for the degraded Gaussian
MIMO broadcast channel by using two main technical tools. The first one is the
generalized de Bruijn identity due to Palomar \emph{et. al.} which provides a
connection between the differential entropy and the Fisher information matrix.
The second tool we use is an inequality due to Dembo which lower bounds the
differential entropy in terms of the Fisher information matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4034</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4034</id><created>2010-02-21</created><authors><author><keyname>Li</keyname><forenames>Shi</forenames></author></authors><title>On constant factor approximation for earth mover distance over doubling
  metrics</title><categories>cs.DS</categories><comments>Extended abstract. An older version submitted to ICALP</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a metric space $(X,d_X)$, the earth mover distance between two
distributions over $X$ is defined as the minimum cost of a bipartite matching
between the two distributions. The doubling dimension of a metric $(X, d_X)$ is
the smallest value $\alpha$ such that every ball in $X$ can be covered by
$2^\alpha$ ball of half the radius. We study efficient algorithms for
approximating earth mover distance over metrics with bounded doubling
dimension.
  Given a metric $(X, d_X)$, with $|X| = n$, we can use $\tilde O(n^2)$
preprocessing time to create a data structure of size $\tilde O(n^{1 + \e})$,
such that subsequently queried EMDs can be $O(\alpha_X/\e)$-approximated in
$\tilde O(n)$ time.
  We also show a weaker form of sketching scheme, which we call &quot;encoding
scheme&quot;. Given $(X, d_X)$, by using $\tilde O(n^2)$ preprocessing time, every
subsequent distribution $\mu$ over $X$ can be encoded into $F(\mu)$ in $\tilde
O(n^{1 + \e})$ time. Given $F(\mu)$ and $F(\nu)$, the EMD between $\mu$ and
$\nu$ can be $O(\alpha_X/\e)$-approximated in $\tilde O(n^\e)$ time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4040</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4040</id><created>2010-02-21</created><updated>2010-02-23</updated><authors><author><keyname>Das</keyname><forenames>Nibaran</forenames></author><author><keyname>Das</keyname><forenames>Bindaban</forenames></author><author><keyname>Sarkar</keyname><forenames>Ram</forenames></author><author><keyname>Basu</keyname><forenames>Subhadip</forenames></author><author><keyname>Kundu</keyname><forenames>Mahantapas</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author></authors><title>Handwritten Bangla Basic and Compound character recognition using MLP
  and SVM classifier</title><categories>cs.CV cs.LG</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel approach for recognition of handwritten compound Bangla characters,
along with the Basic characters of Bangla alphabet, is presented here. Compared
to English like Roman script, one of the major stumbling blocks in Optical
Character Recognition (OCR) of handwritten Bangla script is the large number of
complex shaped character classes of Bangla alphabet. In addition to 50 basic
character classes, there are nearly 160 complex shaped compound character
classes in Bangla alphabet. Dealing with such a large varieties of handwritten
characters with a suitably designed feature set is a challenging problem.
Uncertainty and imprecision are inherent in handwritten script. Moreover, such
a large varieties of complex shaped characters, some of which have close
resemblance, makes the problem of OCR of handwritten Bangla characters more
difficult. Considering the complexity of the problem, the present approach
makes an attempt to identify compound character classes from most frequently to
less frequently occurred ones, i.e., in order of importance. This is to develop
a frame work for incrementally increasing the number of learned classes of
compound characters from more frequently occurred ones to less frequently
occurred ones along with Basic characters. On experimentation, the technique is
observed produce an average recognition rate of 79.25 after three fold cross
validation of data with future scope of improvement and extension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4041</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4041</id><created>2010-02-21</created><authors><author><keyname>Syafrullah</keyname><forenames>Mohammad</forenames></author><author><keyname>Salim</keyname><forenames>Naomie</forenames></author></authors><title>Improving Term Extraction Using Particle Swarm Optimization Techniques</title><categories>cs.IR</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Term extraction is one of the layers in the ontology development process
which has the task to extract all the terms contained in the input document
automatically. The purpose of this process is to generate list of terms that
are relevant to the domain of the input document. In the literature there are
many approaches, techniques and algorithms used for term extraction. In this
paper we propose a new approach using particle swarm optimization techniques in
order to improve the accuracy of term extraction results. We choose five
features to represent the term score. The approach has been applied to the
domain of religious document. We compare our term extraction method precision
with TFIDF, Weirdness, GlossaryExtraction and TermExtractor. The experimental
results show that our propose approach achieve better precision than those four
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4045</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4045</id><created>2010-02-21</created><authors><author><keyname>Tun</keyname><forenames>F. A. Hla Myo</forenames></author><author><keyname>Phyo</keyname><forenames>S. B. Aye Thandar</forenames></author><author><keyname>Naing</keyname><forenames>T. C. Zaw Min</forenames></author></authors><title>Equal Power Distribution and Dynamic Subcarrier Assignment in OFDM Using
  Minimum Channel Gain Flow with Robust Optimization Uncertain Demand</title><categories>cs.OH</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the minimum channel gain flow with uncertainty in the demand
vector is examined. The approach is based on a transformation of uncertainty in
the demand vector to uncertainty in the gain vector. OFDM systems are known to
overcome the impairment of the wireless channel by splitting the given system
bandwidth into parallel sub-carriers, on which data-symbols can be transmitted
simultaneously. This enables the possibility of enhancing the system's
performance by deploying adaptive mechanisms, namely power distribution and
dynamic sub-carrier assignments. The performances of maximizing the minimum
throughput have been analyzed by MATLAB codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4046</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4046</id><created>2010-02-21</created><authors><author><keyname>Perumal</keyname><forenames>K.</forenames></author><author><keyname>Bhaskaran</keyname><forenames>R.</forenames></author></authors><title>Supervised Classification Performance of Multispectral Images</title><categories>cs.LG cs.CV</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays government and private agencies use remote sensing imagery for a
wide range of applications from military applications to farm development. The
images may be a panchromatic, multispectral, hyperspectral or even
ultraspectral of terra bytes. Remote sensing image classification is one
amongst the most significant application worlds for remote sensing. A few
number of image classification algorithms have proved good precision in
classifying remote sensing data. But, of late, due to the increasing
spatiotemporal dimensions of the remote sensing data, traditional
classification algorithms have exposed weaknesses necessitating further
research in the field of remote sensing image classification. So an efficient
classifier is needed to classify the remote sensing images to extract
information. We are experimenting with both supervised and unsupervised
classification. Here we compare the different classification methods and their
performances. It is found that Mahalanobis classifier performed the best in our
classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4047</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4047</id><created>2010-02-21</created><authors><author><keyname>Alanazi</keyname><forenames>Hamdan. O.</forenames></author><author><keyname>Noor</keyname><forenames>Rafidah Md</forenames></author><author><keyname>Zaidan</keyname><forenames>B. B</forenames></author><author><keyname>Zaidan</keyname><forenames>A. A</forenames></author></authors><title>Intrusion Detection System: Overview</title><categories>cs.CR</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network Intrusion Detection (NID) is the process of identifying network
activity that can lead to the compromise of a security policy. In this paper,
we will look at four intrusion detection approaches, which include ANN or
Artificial Neural Network, SOM, Fuzzy Logic and SVM. ANN is one of the oldest
systems that have been used for Intrusion Detection System (IDS), which
presents supervised learning methods. However, in this research, we also came
across SOM or Self Organizing Map, which is an ANN-based system, but applies
unsupervised methods. Another approach is Fuzzy Logic (IDS-based), which also
applies unsupervised learning methods. Lastly, we will look at the SVM system
or Support Vector Machine for IDS. The goal of this paper is to draw an image
for hybrid approaches using these supervised and unsupervised methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4048</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4048</id><created>2010-02-21</created><authors><author><keyname>Saha</keyname><forenames>Satadal</forenames></author><author><keyname>Basu</keyname><forenames>Subhadip</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kr.</forenames></author></authors><title>A Hough Transform based Technique for Text Segmentation</title><categories>cs.IR</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Text segmentation is an inherent part of an OCR system irrespective of the
domain of application of it. The OCR system contains a segmentation module
where the text lines, words and ultimately the characters must be segmented
properly for its successful recognition. The present work implements a Hough
transform based technique for line and word segmentation from digitized images.
The proposed technique is applied not only on the document image dataset but
also on dataset for business card reader system and license plate recognition
system. For standardization of the performance of the system the technique is
also applied on public domain dataset published in the website by CMATER,
Jadavpur University. The document images consist of multi-script printed and
hand written text lines with variety in script and line spacing in single
document image. The technique performs quite satisfactorily when applied on
mobile camera captured business card images with low resolution. The usefulness
of the technique is verified by applying it in a commercial project for
localization of license plate of vehicles from surveillance camera images by
the process of segmentation itself. The accuracy of the technique for word
segmentation, as verified experimentally, is 85.7% for document images, 94.6%
for business card images and 88% for surveillance camera images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4049</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4049</id><created>2010-02-21</created><authors><author><keyname>Elnajjar</keyname><forenames>Mahmoud</forenames></author><author><keyname>Zaidan</keyname><forenames>A. A</forenames></author><author><keyname>Zaidan</keyname><forenames>B. B</forenames></author><author><keyname>Sharif</keyname><forenames>Mohamed Elhadi M.</forenames></author><author><keyname>Alanazi</keyname><forenames>Hamdan. O.</forenames></author></authors><title>Optimization Digital Image Watermarking Technique for Patent Protection</title><categories>cs.MM cs.CR</categories><journal-ref>Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapid development of multimedia and internet allows for wide distribution
of digital media data. It becomes much easier to edit, modify and duplicate
digital information besides that, digital documents are also easy to copy and
distribute, therefore it will be faced by many threats. It is a big security
and privacy issue. Another problem with digital document and video is that
undetectable modifications can be made with very simple and widely available
equipment, which put the digital material for evidential purposes under
question With the large flood of information and the development of the digital
format, it become necessary to find appropriate protection because of the
significance, accuracy and sensitivity of the information, therefore multimedia
technology and popularity of internet communications they have great interest
in using digital watermarks for the purpose of copy protection and content
authentication. Digital watermarking is a technique used to embed a known piece
of digital data within another piece of digital data .A digital data may
represent a digital signature or digital watermark that is embedded in the host
media. The signature or watermark is hidden such that it's perceptually and
statistically undetectable. Then this signature or watermark can be extracted
from the host media and used to identify the owner of the media.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4057</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4057</id><created>2010-02-22</created><authors><author><keyname>Agullo</keyname><forenames>Emmanuel</forenames></author><author><keyname>Bouwmeester</keyname><forenames>Henricus</forenames></author><author><keyname>Dongarra</keyname><forenames>Jack</forenames></author><author><keyname>Kurzak</keyname><forenames>Jakub</forenames></author><author><keyname>Langou</keyname><forenames>Julien</forenames></author><author><keyname>Rosenberg</keyname><forenames>Lee</forenames></author></authors><title>Towards an Efficient Tile Matrix Inversion of Symmetric Positive
  Definite Matrices on Multicore Architectures</title><categories>cs.MS cs.NA</categories><comments>8 pages, extended abstract submitted to VecPar10 on 12/11/09,
  notification of acceptance received on 02/05/10. See:
  http://vecpar.fe.up.pt/2010/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The algorithms in the current sequential numerical linear algebra libraries
(e.g. LAPACK) do not parallelize well on multicore architectures. A new family
of algorithms, the tile algorithms, has recently been introduced. Previous
research has shown that it is possible to write efficient and scalable tile
algorithms for performing a Cholesky factorization, a (pseudo) LU
factorization, and a QR factorization. In this extended abstract, we attack the
problem of the computation of the inverse of a symmetric positive definite
matrix. We observe that, using a dynamic task scheduler, it is relatively
painless to translate existing LAPACK code to obtain a ready-to-be-executed
tile algorithm. However we demonstrate that non trivial compiler techniques
(array renaming, loop reversal and pipelining) need then to be applied to
further increase the parallelism of our application. We present preliminary
experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4058</identifier>
 <datestamp>2011-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4058</id><created>2010-02-22</created><updated>2011-10-27</updated><authors><author><keyname>Beygelzimer</keyname><forenames>Alina</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author><author><keyname>Li</keyname><forenames>Lihong</forenames></author><author><keyname>Reyzin</keyname><forenames>Lev</forenames></author><author><keyname>Schapire</keyname><forenames>Robert E.</forenames></author></authors><title>Contextual Bandit Algorithms with Supervised Learning Guarantees</title><categories>cs.LG</categories><comments>10 pages</comments><acm-class>I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of learning in an online, bandit setting where the
learner must repeatedly select among $K$ actions, but only receives partial
feedback based on its choices. We establish two new facts: First, using a new
algorithm called Exp4.P, we show that it is possible to compete with the best
in a set of $N$ experts with probability $1-\delta$ while incurring regret at
most $O(\sqrt{KT\ln(N/\delta)})$ over $T$ time steps. The new algorithm is
tested empirically in a large-scale, real-world dataset. Second, we give a new
algorithm called VE that competes with a possibly infinite set of policies of
VC-dimension $d$ while incurring regret at most $O(\sqrt{T(d\ln(T) + \ln
(1/\delta))})$ with probability $1-\delta$. These guarantees improve on those
of all previous algorithms, whether in a stochastic or adversarial environment,
and bring us closer to providing supervised learning type guarantees for the
contextual bandit setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4061</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4061</id><created>2010-02-22</created><authors><author><keyname>Kahramano&#x11f;ullari</keyname><forenames>Ozan</forenames><affiliation>The Microsoft Research - University of Trento, Centre for Computational and Systems Biology</affiliation></author></authors><title>Flux Analysis in Process Models via Causality</title><categories>cs.CE cs.LO q-bio.QM</categories><journal-ref>EPTCS 19, 2010, pp. 20-39</journal-ref><doi>10.4204/EPTCS.19.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an approach for flux analysis in process algebra models of
biological systems. We perceive flux as the flow of resources in stochastic
simulations. We resort to an established correspondence between event
structures, a broadly recognised model of concurrency, and state transitions of
process models, seen as Petri nets. We show that we can this way extract the
causal resource dependencies in simulations between individual state
transitions as partial orders of events. We propose transformations on the
partial orders that provide means for further analysis, and introduce a
software tool, which implements these ideas. By means of an example of a
published model of the Rho GTP-binding proteins, we argue that this approach
can provide the substitute for flux analysis techniques on ordinary
differential equation models within the stochastic setting of process algebras.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4062</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4062</id><created>2010-02-22</created><authors><author><keyname>Donaldson</keyname><forenames>Robin</forenames><affiliation>University of Glasgow</affiliation></author><author><keyname>Calder</keyname><forenames>Muffy</forenames><affiliation>University of Glasgow</affiliation></author></authors><title>Modelling and Analysis of Biochemical Signalling Pathway Cross-talk</title><categories>cs.CE q-bio.QM</categories><journal-ref>EPTCS 19, 2010, pp. 40-54</journal-ref><doi>10.4204/EPTCS.19.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Signalling pathways are abstractions that help life scientists structure the
coordination of cellular activity. Cross-talk between pathways accounts for
many of the complex behaviours exhibited by signalling pathways and is often
critical in producing the correct signal-response relationship. Formal models
of signalling pathways and cross-talk in particular can aid understanding and
drive experimentation. We define an approach to modelling based on the concept
that a pathway is the (synchronising) parallel composition of instances of
generic modules (with internal and external labels). Pathways are then composed
by (synchronising) parallel composition and renaming; different types of
cross-talk result from different combinations of synchronisation and renaming.
We define a number of generic modules in PRISM and five types of cross-talk:
signal flow, substrate availability, receptor function, gene expression and
intracellular communication. We show that Continuous Stochastic Logic
properties can both detect and distinguish the types of cross-talk. The
approach is illustrated with small examples and an analysis of the cross-talk
between the TGF-b/BMP, WNT and MAPK pathways.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4063</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4063</id><created>2010-02-22</created><authors><author><keyname>Ciocchetta</keyname><forenames>Federica</forenames></author><author><keyname>Guerriero</keyname><forenames>Maria Luisa</forenames></author><author><keyname>Hillston</keyname><forenames>Jane</forenames></author></authors><title>Investigating modularity in the analysis of process algebra models of
  biochemical systems</title><categories>cs.CE q-bio.QM</categories><acm-class>I.6; F.4; G.4; J.3</acm-class><journal-ref>EPTCS 19, 2010, pp. 55-69</journal-ref><doi>10.4204/EPTCS.19.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compositionality is a key feature of process algebras which is often cited as
one of their advantages as a modelling technique. It is certainly true that in
biochemical systems, as in many other systems, model construction is made
easier in a formalism which allows the problem to be tackled compositionally.
In this paper we consider the extent to which the compositional structure which
is inherent in process algebra models of biochemical systems can be exploited
during model solution. In essence this means using the compositional structure
to guide decomposed solution and analysis.
  Unfortunately the dynamic behaviour of biochemical systems exhibits strong
interdependencies between the components of the model making decomposed
solution a difficult task. Nevertheless we believe that if such decomposition
based on process algebras could be established it would demonstrate substantial
benefits for systems biology modelling. In this paper we present our
preliminary investigations based on a case study of the pheromone pathway in
yeast, modelling in the stochastic process algebra Bio-PEPA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4064</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4064</id><created>2010-02-22</created><authors><author><keyname>Haack</keyname><forenames>Fiete</forenames></author><author><keyname>Leye</keyname><forenames>Stefan</forenames></author><author><keyname>Uhrmacher</keyname><forenames>Adelinde M.</forenames></author></authors><title>A flexible architecture for modeling and simulation of diffusional
  association</title><categories>cs.CE q-bio.QM</categories><journal-ref>EPTCS 19, 2010, pp. 70-84</journal-ref><doi>10.4204/EPTCS.19.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Up to now, it is not possible to obtain analytical solutions for complex
molecular association processes (e.g. Molecule recognition in Signaling or
catalysis). Instead Brownian Dynamics (BD) simulations are commonly used to
estimate the rate of diffusional association, e.g. to be later used in
mesoscopic simulations. Meanwhile a portfolio of diffusional association (DA)
methods have been developed that exploit BD.
  However, DA methods do not clearly distinguish between modeling, simulation,
and experiment settings. This hampers to classify and compare the existing
methods with respect to, for instance model assumptions, simulation
approximations or specific optimization strategies for steering the computation
of trajectories.
  To address this deficiency we propose FADA (Flexible Architecture for
Diffusional Association) - an architecture that allows the flexible definition
of the experiment comprising a formal description of the model in SpacePi,
different simulators, as well as validation and analysis methods. Based on the
NAM (Northrup-Allison-McCammon) method, which forms the basis of many existing
DA methods, we illustrate the structure and functioning of FADA. A discussion
of future validation experiments illuminates how the FADA can be exploited in
order to estimate reaction rates and how validation techniques may be applied
to validate additional features of the model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4065</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4065</id><created>2010-02-22</created><authors><author><keyname>Z&#xe1;mborszky</keyname><forenames>Judit</forenames><affiliation>CoSBi</affiliation></author><author><keyname>Priami</keyname><forenames>Corrado</forenames><affiliation>CoSBi</affiliation></author></authors><title>BlenX-based compositional modeling of complex reaction mechanisms</title><categories>cs.CE q-bio.QM</categories><journal-ref>EPTCS 19, 2010, pp. 85-102</journal-ref><doi>10.4204/EPTCS.19.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Molecular interactions are wired in a fascinating way resulting in complex
behavior of biological systems. Theoretical modeling provides a useful
framework for understanding the dynamics and the function of such networks. The
complexity of the biological networks calls for conceptual tools that manage
the combinatorial explosion of the set of possible interactions. A suitable
conceptual tool to attack complexity is compositionality, already successfully
used in the process algebra field to model computer systems. We rely on the
BlenX programming language, originated by the beta-binders process calculus, to
specify and simulate high-level descriptions of biological circuits. The
Gillespie's stochastic framework of BlenX requires the decomposition of
phenomenological functions into basic elementary reactions. Systematic
unpacking of complex reaction mechanisms into BlenX templates is shown in this
study. The estimation/derivation of missing parameters and the challenges
emerging from compositional model building in stochastic process algebras are
discussed. A biological example on circadian clock is presented as a case study
of BlenX compositionality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4066</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4066</id><created>2010-02-22</created><authors><author><keyname>Capecchi</keyname><forenames>Sara</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author><author><keyname>Troina</keyname><forenames>Angelo</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino</affiliation></author></authors><title>Types for BioAmbients</title><categories>cs.CE cs.LO q-bio.QM</categories><acm-class>F.3.3; J.3; F.1.2</acm-class><journal-ref>EPTCS 19, 2010, pp. 103-115</journal-ref><doi>10.4204/EPTCS.19.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The BioAmbients calculus is a process algebra suitable for representing
compartmentalization, molecular localization and movements between
compartments. In this paper we enrich this calculus with a static type system
classifying each ambient with group types specifying the kind of compartments
in which the ambient can stay. The type system ensures that, in a well-typed
process, ambients cannot be nested in a way that violates the type hierarchy.
Exploiting the information given by the group types, we also extend the
operational semantics of BioAmbients with rules signalling errors that may
derive from undesired ambients' moves (i.e. merging incompatible tissues).
Thus, the signal of errors can help the modeller to detect and locate unwanted
situations that may arise in a biological system, and give practical hints on
how to avoid the undesired behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4067</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4067</id><created>2010-02-22</created><authors><author><keyname>Bodei</keyname><forenames>Chiara</forenames><affiliation>Dipartimento di Informatica - Universit&#xe0; di Pisa</affiliation></author><author><keyname>Bracciali</keyname><forenames>Andrea</forenames><affiliation>Dipartimento di Informatica - Universit&#xe0; di Pisa</affiliation></author><author><keyname>Chiarugi</keyname><forenames>Davide</forenames><affiliation>Dipartimento di Scienze Matematiche e Informatiche, Universit&#xe0; di Siena</affiliation></author><author><keyname>Gori</keyname><forenames>Roberta</forenames><affiliation>Dipartimento di Informatica - Universit&#xe0; di Pisa</affiliation></author></authors><title>A Taxonomy of Causality-Based Biological Properties</title><categories>cs.CE q-bio.QM</categories><journal-ref>EPTCS 19, 2010, pp. 116-133</journal-ref><doi>10.4204/EPTCS.19.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We formally characterize a set of causality-based properties of metabolic
networks. This set of properties aims at making precise several notions on the
production of metabolites, which are familiar in the biologists' terminology.
  From a theoretical point of view, biochemical reactions are abstractly
represented as causal implications and the produced metabolites as causal
consequences of the implication representing the corresponding reaction. The
fact that a reactant is produced is represented by means of the chain of
reactions that have made it exist. Such representation abstracts away from
quantities, stoichiometric and thermodynamic parameters and constitutes the
basis for the characterization of our properties. Moreover, we propose an
effective method for verifying our properties based on an abstract model of
system dynamics. This consists of a new abstract semantics for the system seen
as a concurrent network and expressed using the Chemical Ground Form calculus.
  We illustrate an application of this framework to a portion of a real
metabolic pathway.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4084</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4084</id><created>2010-02-22</created><authors><author><keyname>Kari</keyname><forenames>Lila</forenames><affiliation>UWO</affiliation></author><author><keyname>Masson</keyname><forenames>Beno&#xee;t</forenames><affiliation>UWO</affiliation></author><author><keyname>Seki</keyname><forenames>Shinnosuke</forenames><affiliation>UWO</affiliation></author></authors><title>Properties of Pseudo-Primitive Words and their Applications</title><categories>cs.CC</categories><comments>Submitted to International Journal of Foundations of Computer Science</comments><proxy>ccsd hal-00458695</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A pseudo-primitive word with respect to an antimorphic involution \theta is a
word which cannot be written as a catenation of occurrences of a strictly
shorter word t and \theta(t). Properties of pseudo-primitive words are
investigated in this paper. These properties link pseudo-primitive words with
essential notions in combinatorics on words such as primitive words,
(pseudo)-palindromes, and (pseudo)-commutativity. Their applications include an
improved solution to the extended Lyndon-Sch\&quot;utzenberger equation u_1 u_2 ...
u_l = v_1 ... v_n w_1 ... w_m, where u_1, ..., u_l \in {u, \theta(u)}, v_1,
..., v_n \in {v, \theta(v)}, and w_1, ..., w_m \in {w, \theata(w)} for some
words u, v, w, integers l, n, m \ge 2, and an antimorphic involution \theta. We
prove that for l \ge 4, n,m \ge 3, this equation implies that u, v, w can be
expressed in terms of a common word t and its image \theta(t). Moreover,
several cases of this equation where l = 3 are examined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4088</identifier>
 <datestamp>2013-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4088</id><created>2010-02-22</created><updated>2011-03-29</updated><authors><author><keyname>Ezerman</keyname><forenames>Martianus Frederic</forenames></author><author><keyname>Ling</keyname><forenames>San</forenames></author><author><keyname>Sole</keyname><forenames>Patrick</forenames></author></authors><title>Additive Asymmetric Quantum Codes</title><categories>cs.IT math.IT</categories><comments>Accepted for publication March 2, 2011, IEEE Transactions on
  Information Theory, to appear</comments><journal-ref>IEEE Trans. IT vol. 57 no. 8 pp. 5536--5550, Aug. 2011</journal-ref><doi>10.1109/TIT.2011.2159040</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a general construction of asymmetric quantum codes based on
additive codes under the trace Hermitian inner product. Various families of
additive codes over $\F_{4}$ are used in the construction of many asymmetric
quantum codes over $\F_{4}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4172</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4172</id><created>2010-02-22</created><authors><author><keyname>Nayyar</keyname><forenames>Ashutosh</forenames></author><author><keyname>Mahajan</keyname><forenames>Aditya</forenames></author><author><keyname>Teneketzis</keyname><forenames>Demosthenis</forenames></author></authors><title>Optimal Control Strategies in Delayed Sharing Information Structures</title><categories>cs.OH</categories><comments>Sumbitted to IEEE Transactions on automatic control</comments><doi>10.1109/TAC.2010.2089381</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The $n$-step delayed sharing information structure is investigated. This
information structure comprises of $K$ controllers that share their information
with a delay of $n$ time steps. This information structure is a link between
the classical information structure, where information is shared perfectly
between the controllers, and a non-classical information structure, where there
is no &quot;lateral&quot; sharing of information among the controllers. Structural
results for optimal control strategies for systems with such information
structures are presented. A sequential methodology for finding the optimal
strategies is also derived. The solution approach provides an insight for
identifying structural results and sequential decomposition for general
decentralized stochastic control problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4180</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4180</id><created>2010-02-22</created><authors><author><keyname>Chakraborty</keyname><forenames>Saurav</forenames></author><author><keyname>Basu</keyname><forenames>Subhadip</forenames></author></authors><title>Design of a Smart Unmanned Ground Vehicle for Hazardous Environments</title><categories>cs.RO cs.HC</categories><comments>In proceedings of 2nd National Conference on Recent Trends in
  Information Systems (ReTIS-08), pp. 222-225, Feb 7-9, 2008, Kolkata</comments><journal-ref>In proceedings of 2nd National Conference on Recent Trends in
  Information Systems (ReTIS-08), pp. 222-225, Feb 7-9, 2008, Kolkata</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A smart Unmanned Ground Vehicle (UGV) is designed and developed for some
application specific missions to operate predominantly in hazardous
environments. In our work, we have developed a small and lightweight vehicle to
operate in general cross-country terrains in or without daylight. The UGV can
send visual feedbacks to the operator at a remote location. Onboard infrared
sensors can detect the obstacles around the UGV and sends signals to the
operator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4182</identifier>
 <datestamp>2010-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4182</id><created>2010-02-22</created><authors><author><keyname>Sharma</keyname><forenames>Gokarna</forenames></author><author><keyname>Estrade</keyname><forenames>Brett</forenames></author><author><keyname>Busch</keyname><forenames>Costas</forenames></author></authors><title>Window-Based Greedy Contention Management for Transactional Memory</title><categories>cs.DC cs.DS cs.PF</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider greedy contention managers for transactional memory for M x N
execution windows of transactions with M threads and N transactions per thread.
Assuming that each transaction conflicts with at most C other transactions
inside the window, a trivial greedy contention manager can schedule them within
CN time. In this paper, we show that there are much better schedules. We
present and analyze two new randomized greedy contention management algorithms.
The first algorithm Offline-Greedy produces a schedule of length O(C + N
log(MN)) with high probability, and gives competitive ratio O(log(MN)) for C &lt;=
N log(MN). The offline algorithm depends on knowing the conflict graph. The
second algorithm Online-Greedy produces a schedule of length O(C log(MN) + N
log^2(MN)) with high probability which is only a O(log(NM)) factor worse, but
does not require knowledge of the conflict graph. We also give an adaptive
version which achieves similar worst-case performance and C is determined on
the fly under execution. Our algorithms provide new tradeoffs for greedy
transaction scheduling that parameterize window sizes and transaction conflicts
within the window.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4248</identifier>
 <datestamp>2012-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4248</id><created>2010-02-23</created><updated>2012-11-17</updated><authors><author><keyname>Iacono</keyname><forenames>John</forenames></author><author><keyname>&#xd6;zkan</keyname><forenames>&#xd6;zg&#xfc;r</forenames></author></authors><title>Mergeable Dictionaries</title><categories>cs.DS cs.DM</categories><comments>34 pages, 6 figures</comments><acm-class>E.1; E.2; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A data structure is presented for the Mergeable Dictionary abstract data
type, which supports the following operations on a collection of disjoint sets
of totally ordered data: Predecessor-Search, Split and Merge. While
Predecessor-Search and Split work in the normal way, the novel operation is
Merge. While in a typical mergeable dictionary (e.g. 2-4 Trees), the Merge
operation can only be performed on sets that span disjoint intervals in
keyspace, the structure here has no such limitation, and permits the merging of
arbitrarily interleaved sets. Tarjan and Brown present a data structure which
can handle arbitrary Merge operations in O(log n) amortized time per operation
if the set of operations is restricted to exclude the Split operation. In the
presence of Split operations, the amortized time complexity of their structure
becomes \Omega(n). A data structure which supports both Split and Merge
operations in O(log^2 n) amortized time per operation was given by Farach and
Thorup. In contrast, our data structure supports all operations, including
Split and Merge, in O(log n) amortized time, thus showing that interleaved
Merge operations can be supported at no additional cost vis-a-vis disjoint
Merge operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4255</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4255</id><created>2010-02-23</created><updated>2010-12-29</updated><authors><author><keyname>Baek</keyname><forenames>Seung Jun</forenames></author><author><keyname>de Veciana</keyname><forenames>Gustavo</forenames></author></authors><title>A Quantile-Based Sequential Feedback Scheme via Overhearing in
  Multicarrier Access Networks</title><categories>cs.NI</categories><comments>The paper is withdrawn since the material will be reconstructed in an
  entirely different context</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a scheme to reduce the overhead associated with channel state
information (CSI) feedback required for opportunistic scheduling in
multicarrier access networks. We study the case where CSI is partially
overheard by mobiles and one can suppress transmitting CSI reports for time
varying channel of inferior quality. As a means to assess channel quality and
exploit multiuser diversity we adopt maximum quantile (MQ) scheduling. We show
that the problem of minimizing the average feedback overhead can be formulated
as a Bayesian network problem. A greedy heuristic using probabilistic inference
is proposed to deal with the NP-hardness of the problem. Leveraging properties
of MQ scheduling we first show that networks having tree-like overhearing
graphs admit simple inference. We then present a class of more general network
structures for which exact inference is computationally tractable. Simulation
results are provided to demonstrate the improvements offered by the proposed
heuristic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4263</identifier>
 <datestamp>2010-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4263</id><created>2010-02-23</created><authors><author><keyname>Mohammed</keyname><forenames>Saif Khan</forenames></author><author><keyname>Viterbo</keyname><forenames>Emanuele</forenames></author><author><keyname>Hong</keyname><forenames>Yi</forenames></author><author><keyname>Chockalingam</keyname><forenames>Ananthanarayanan</forenames></author></authors><title>Precoding by Pairing Subchannels to Increase MIMO Capacity with Discrete
  Input Alphabets</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider Gaussian multiple-input multiple-output (MIMO) channels with
discrete input alphabets. We propose a non-diagonal precoder based on the
X-Codes in \cite{Xcodes_paper} to increase the mutual information. The MIMO
channel is transformed into a set of parallel subchannels using Singular Value
Decomposition (SVD) and X-Codes are then used to pair the subchannels. X-Codes
are fully characterized by the pairings and a $2\times 2$ real rotation matrix
for each pair (parameterized with a single angle). This precoding structure
enables us to express the total mutual information as a sum of the mutual
information of all the pairs. The problem of finding the optimal precoder with
the above structure, which maximizes the total mutual information, is solved by
{\em i}) optimizing the rotation angle and the power allocation within each
pair and {\em ii}) finding the optimal pairing and power allocation among the
pairs. It is shown that the mutual information achieved with the proposed
pairing scheme is very close to that achieved with the optimal precoder by Cruz
{\em et al.}, and is significantly better than Mercury/waterfilling strategy by
Lozano {\em et al.}. Our approach greatly simplifies both the precoder
optimization and the detection complexity, making it suitable for practical
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4264</identifier>
 <datestamp>2010-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4264</id><created>2010-02-23</created><authors><author><keyname>Liu</keyname><forenames>Xu</forenames></author><author><keyname>Yuan</keyname><forenames>Lin</forenames></author><author><keyname>Zhan</keyname><forenames>Jianfeng</forenames></author><author><keyname>Tu</keyname><forenames>Bibo</forenames></author><author><keyname>Meng</keyname><forenames>Dan</forenames></author></authors><title>Automatic Performance Debugging of SPMD Parallel Programs</title><categories>cs.DC cs.PF</categories><comments>The preliminary version appeared on SC 08 workshop on Node Level
  Parallelism for Large Scale Supercomputers. The web site is
  http://iss.ices.utexas.edu/sc08nlplss/program.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic performance debugging of parallel applications usually involves two
steps: automatic detection of performance bottlenecks and uncovering their root
causes for performance optimization. Previous work fails to resolve this
challenging issue in several ways: first, several previous efforts automate
analysis processes, but present the results in a confined way that only
identifies performance problems with apriori knowledge; second, several tools
take exploratory or confirmatory data analysis to automatically discover
relevant performance data relationships. However, these efforts do not focus on
locating performance bottlenecks or uncovering their root causes. In this
paper, we design and implement an innovative system, AutoAnalyzer, to
automatically debug the performance problems of single program multi-data
(SPMD) parallel programs. Our system is unique in terms of two dimensions:
first, without any apriori knowledge, we automatically locate bottlenecks and
uncover their root causes for performance optimization; second, our method is
lightweight in terms of size of collected and analyzed performance data. Our
contribution is three-fold. First, we propose a set of simple performance
metrics to represent behavior of different processes of parallel programs, and
present two effective clustering and searching algorithms to locate
bottlenecks. Second, we propose to use the rough set algorithm to automatically
uncover the root causes of bottlenecks. Third, we design and implement the
AutoAnalyzer system, and use two production applications to verify the
effectiveness and correctness of our methods. According to the analysis results
of AutoAnalyzer, we optimize two parallel programs with performance
improvements by minimally 20% and maximally 170%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4286</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4286</id><created>2010-02-23</created><updated>2010-06-26</updated><authors><author><keyname>Balcazar</keyname><forenames>Jose L.</forenames></author></authors><title>Redundancy, Deduction Schemes, and Minimum-Size Bases for Association
  Rules</title><categories>cs.LO cs.AI</categories><comments>LMCS accepted paper</comments><proxy>Logical Methods In Computer Science</proxy><acm-class>I.2.3; H.2.8; I.2.4; G.2.3; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 2 (June 27,
  2010) lmcs:812</journal-ref><doi>10.2168/LMCS-6(2:5)2010</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Association rules are among the most widely employed data analysis methods in
the field of Data Mining. An association rule is a form of partial implication
between two sets of binary variables. In the most common approach, association
rules are parameterized by a lower bound on their confidence, which is the
empirical conditional probability of their consequent given the antecedent,
and/or by some other parameter bounds such as &quot;support&quot; or deviation from
independence. We study here notions of redundancy among association rules from
a fundamental perspective. We see each transaction in a dataset as an
interpretation (or model) in the propositional logic sense, and consider
existing notions of redundancy, that is, of logical entailment, among
association rules, of the form &quot;any dataset in which this first rule holds must
obey also that second rule, therefore the second is redundant&quot;. We discuss
several existing alternative definitions of redundancy between association
rules and provide new characterizations and relationships among them. We show
that the main alternatives we discuss correspond actually to just two variants,
which differ in the treatment of full-confidence implications. For each of
these two notions of redundancy, we provide a sound and complete deduction
calculus, and we show how to construct complete bases (that is,
axiomatizations) of absolutely minimum size in terms of the number of rules. We
explore finally an approach to redundancy with respect to several association
rules, and fully characterize its simplest case of two partial premises.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4290</identifier>
 <datestamp>2010-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4290</id><created>2010-02-23</created><authors><author><keyname>Maurice</keyname><forenames>Margenstern</forenames></author></authors><title>A weakly universal cellular automaton in the hyperbolic 3D space with
  three states</title><categories>cs.FL cs.DM</categories><comments>54 pages, 38 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we significantly improve a previous result by the same author
showing the existence of a weakly universal cellular automaton with five states
living in the hyperbolic 3D-space. Here, we get such a cellular automaton with
three states only.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4298</identifier>
 <datestamp>2010-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4298</id><created>2010-02-23</created><authors><author><keyname>Wu</keyname><forenames>Haoyang</forenames></author></authors><title>Signaling games with pattern recognition</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical model of signaling games assumes that the receiver exactly know
the type space (private information) of the sender and be able to discriminate
each type of the sender distinctly. However, the justification of this
assumption is questionable. It is more reasonable to let the receiver recognize
the pattern of the sender. In this paper, we investigate what happens if the
assumption is relaxed. A framework of signaling games with pattern recognition
and an example are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4303</identifier>
 <datestamp>2010-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4303</id><created>2010-02-23</created><authors><author><keyname>Mazurczyk</keyname><forenames>Wojciech</forenames></author><author><keyname>Cabaj</keyname><forenames>Krzysztof</forenames></author><author><keyname>Szczypiorski</keyname><forenames>Krzysztof</forenames></author></authors><title>What are suspicious VoIP delays?</title><categories>cs.CR cs.MM</categories><comments>17 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voice over IP (VoIP) is unquestionably the most popular real-time service in
IP networks today. Recent studies have shown that it is also a suitable carrier
for information hiding. Hidden communication may pose security concerns as it
can lead to confidential information leakage. In VoIP, RTP (Real-time Transport
Protocol) in particular, which provides the means for the successful transport
of voice packets through IP networks, is suitable for steganographic purposes.
It is characterised by a high packet rate compared to other protocols used in
IP telephony, resulting in a potentially high steganographic bandwidth. The
modification of an RTP packet stream provides many opportunities for hidden
communication as the packets may be delayed, reordered or intentionally lost.
In this paper, to enable the detection of steganographic exchanges in VoIP, we
examined real RTP traffic traces to answer the questions, what do the &quot;normal&quot;
delays in RTP packet streams look like? and, is it possible to detect the use
of known RTP steganographic methods based on this knowledge?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4311</identifier>
 <datestamp>2010-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4311</id><created>2010-02-23</created><authors><author><keyname>Asvadi</keyname><forenames>Reza</forenames></author><author><keyname>Banihashemi</keyname><forenames>Amir H.</forenames></author><author><keyname>Ahmadian-Attari</keyname><forenames>Mahmoud</forenames></author></authors><title>Lowering the Error Floor of LDPC Codes Using Cyclic Liftings</title><categories>cs.IT math.IT</categories><msc-class>'math'</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cyclic liftings are proposed to lower the error floor of low-density
parity-check (LDPC) codes. The liftings are designed to eliminate dominant
trapping sets of the base code by removing the short cycles which form the
trapping sets. We derive a necessary and sufficient condition for the cyclic
permutations assigned to the edges of a cycle $c$ of length $\ell(c)$ in the
base graph such that the inverse image of $c$ in the lifted graph consists of
only cycles of length strictly larger than $\ell(c)$. The proposed method is
universal in the sense that it can be applied to any LDPC code over any channel
and for any iterative decoding algorithm. It also preserves important
properties of the base code such as degree distributions, encoder and decoder
structure, and in some cases, the code rate. The proposed method is applied to
both structured and random codes over the binary symmetric channel (BSC). The
error floor improves consistently by increasing the lifting degree, and the
results show significant improvements in the error floor compared to the base
code, a random code of the same degree distribution and block length, and a
random lifting of the same degree. Similar improvements are also observed when
the codes designed for the BSC are applied to the additive white Gaussian noise
(AWGN) channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4314</identifier>
 <datestamp>2010-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4314</id><created>2010-02-23</created><updated>2010-04-09</updated><authors><author><keyname>Ganesh</keyname><forenames>A.</forenames></author><author><keyname>Lilienthal</keyname><forenames>S.</forenames></author><author><keyname>Manjunath</keyname><forenames>D.</forenames></author><author><keyname>Proutiere</keyname><forenames>A.</forenames></author><author><keyname>Simatos</keyname><forenames>F.</forenames></author></authors><title>Load Balancing via Random Local Search in Closed and Open systems</title><categories>cs.NI</categories><comments>Accepted to Sigmetrics 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the performance of random load resampling and
migration strategies in parallel server systems. Clients initially attach to an
arbitrary server, but may switch server independently at random instants of
time in an attempt to improve their service rate. This approach to load
balancing contrasts with traditional approaches where clients make smart server
selections upon arrival (e.g., Join-the-Shortest-Queue policy and variants
thereof). Load resampling is particularly relevant in scenarios where clients
cannot predict the load of a server before being actually attached to it. An
important example is in wireless spectrum sharing where clients try to share a
set of frequency bands in a distributed manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4315</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4315</id><created>2010-02-23</created><updated>2010-03-06</updated><authors><author><keyname>Dutta</keyname><forenames>Sourav</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Arnab</forenames></author></authors><title>Mining Statistically Significant Substrings Based on the Chi-Square
  Measure</title><categories>cs.DB</categories><comments>10 pages, 7 figures, to appear in PAKDD 2010</comments><acm-class>H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given the vast reservoirs of data stored worldwide, efficient mining of data
from a large information store has emerged as a great challenge. Many databases
like that of intrusion detection systems, web-click records, player statistics,
texts, proteins etc., store strings or sequences. Searching for an unusual
pattern within such long strings of data has emerged as a requirement for
diverse applications. Given a string, the problem then is to identify the
substrings that differs the most from the expected or normal behavior, i.e.,
the substrings that are statistically significant. In other words, these
substrings are less likely to occur due to chance alone and may point to some
interesting information or phenomenon that warrants further exploration. To
this end, we use the chi-square measure. We propose two heuristics for
retrieving the top-k substrings with the largest chi-square measure. We show
that the algorithms outperform other competing algorithms in the runtime, while
maintaining a high approximation ratio of more than 0.96.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4317</identifier>
 <datestamp>2014-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4317</id><created>2010-02-23</created><authors><author><keyname>Sparavigna</keyname><forenames>Amelia Carolina</forenames></author><author><keyname>Marazzato</keyname><forenames>Roberto</forenames></author></authors><title>CLD-shaped Brushstrokes in Non-Photorealistic Rendering</title><categories>cs.CV cs.GR</categories><comments>Keywords: Image processing, Non-photorealistic processing,
  Image-based rendering Coherence Length Diagram</comments><journal-ref>International Journal of Software Engineering and Computing, 2011,
  Volume 3, Issue 1, Pages 11-15</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rendering techniques based on a random grid can be improved by adapting
brushstrokes to the shape of different areas of the original picture. In this
paper, the concept of Coherence Length Diagram is applied to determine the
adaptive brushstrokes, in order to simulate an impressionist painting. Some
examples are provided to instance the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4330</identifier>
 <datestamp>2010-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4330</id><created>2010-02-23</created><authors><author><keyname>Dees</keyname><forenames>Jonathan</forenames></author><author><keyname>Geisberger</keyname><forenames>Robert</forenames></author><author><keyname>Sanders</keyname><forenames>Peter</forenames></author><author><keyname>Bader</keyname><forenames>Roland</forenames></author></authors><title>Defining and Computing Alternative Routes in Road Networks</title><categories>cs.DS</categories><comments>10 pages, technical report</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Every human likes choices. But today's fast route planning algorithms usually
compute just a single route between source and target. There are beginnings to
compute alternative routes, but this topic has not been studied thoroughly.
Often, the aspect of meaningful alternative routes is neglected from a human
point of view. We fill in this gap by suggesting mathematical definitions for
such routes. As a second contribution we propose heuristics to compute them, as
this is NP-hard in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4334</identifier>
 <datestamp>2010-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4334</id><created>2010-02-23</created><updated>2010-03-04</updated><authors><author><keyname>Sankaran</keyname><forenames>Abhisekh</forenames></author><author><keyname>Chakraborty</keyname><forenames>Supratik</forenames></author></authors><title>On Semantic Generalizations of the Bernays-Sch\&quot;onfinkel-Ramsey Class
  with Finite or Co-finite Spectra</title><categories>cs.LO</categories><comments>26 pages, no figures, submitted to LICS 2010 (decision pending); just
  added a reference to a related work in this version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by model-theoretic properties of the BSR class, we present a family
of semantic classes of FO formulae with finite or co-finite spectra over a
relational vocabulary \Sigma. A class in this family is denoted
EBS_\Sigma(\sigma), where \sigma is a subset of \Sigma. Formulae in
EBS_\Sigma(\sigma) are preserved under substructures modulo a bounded core and
modulo re-interpretation of predicates outside \sigma. We study properties of
the family EBS_\Sigma = {EBS_\Sigma(\sigma) | \sigma \subseteq \Sigma}, e.g.
classes in EBS_\Sigma are spectrally indistinguishable, EBS_\Sigma(\Sigma) is
semantically equivalent to BSR over \Sigma, and EBS_\Sigma(\emptyset) is the
set of all FO formulae over \Sigma with finite or co-finite spectra.
Furthermore, (EBS_\Sigma, \subseteq) forms a lattice isomorphic to the powerset
lattice (\wp({\Sigma}), \subseteq). This gives a natural semantic
generalization of BSR as ascending chains in (EBS_\Sigma, \subseteq). Many
well-known FO classes are semantically subsumed by EBS_\Sigma(\Sigma) or
EBS_\Sigma(\emptyset). Our study provides alternative proofs of interesting
results like the Lo\'s-Tarski Theorem and the semantic subsumption of the
L\&quot;owenheim class with equality by BSR. We also present a syntactic sub-class
of EBS_\Sigma(\sigma) called EDP_\Sigma(\sigma) and give an expression for the
size of the bounded cores of models of EDP_\Sigma(\sigma) formulae. We show
that the EDP_\Sigma(\sigma) classes also form a lattice structure. Finally, we
study some closure properties and applications of the classes presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4364</identifier>
 <datestamp>2010-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4364</id><created>2010-02-23</created><authors><author><keyname>Mitsche</keyname><forenames>Dieter</forenames></author><author><keyname>Saumell</keyname><forenames>Maria</forenames></author><author><keyname>Silveira</keyname><forenames>Rodrigo I.</forenames></author></authors><title>On the Number of Higher Order Delaunay Triangulations</title><categories>cs.CG</categories><comments>Manuscript accompanying shorter version in CIAC 2010; 13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Higher order Delaunay triangulations are a generalization of the Delaunay
triangulation which provides a class of well-shaped triangulations, over which
extra criteria can be optimized. A triangulation is order-$k$ Delaunay if the
circumcircle of each triangle of the triangulation contains at most $k$ points.
In this paper we study lower and upper bounds on the number of higher order
Delaunay triangulations, as well as their expected number for randomly
distributed points. We show that arbitrarily large point sets can have a single
higher order Delaunay triangulation, even for large orders, whereas for first
order Delaunay triangulations, the maximum number is $2^{n-3}$. Next we show
that uniformly distributed points have an expected number of at least
$2^{\rho_1 n(1+o(1))}$ first order Delaunay triangulations, where $\rho_1$ is
an analytically defined constant ($\rho_1 \approx 0.525785$), and for $k &gt; 1$,
the expected number of order-$k$ Delaunay triangulations (which are not
order-$i$ for any $i &lt; k$) is at least $2^{\rho_k n(1+o(1))}$, where $\rho_k$
can be calculated numerically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4384</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4384</id><created>2010-02-23</created><updated>2012-12-06</updated><authors><author><keyname>Koutschan</keyname><forenames>Christoph</forenames></author><author><keyname>Kauers</keyname><forenames>Manuel</forenames></author><author><keyname>Zeilberger</keyname><forenames>Doron</forenames></author></authors><title>Proof of George Andrews's and David Robbins's q-TSPP Conjecture</title><categories>math.CO cs.SC</categories><msc-class>05A15, 33F10</msc-class><journal-ref>Proceedings of the National Academy of Sciences 108(6), pp.
  2196-2199. 2011. ISSN 0027-8424</journal-ref><doi>10.1073/pnas.1019186108</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The conjecture that the orbit-counting generating function for totally
symmetric plane partitions can be written as an explicit product formula, has
been stated independently by George Andrews and David Robbins around 1983. We
present a proof of this long-standing conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4392</identifier>
 <datestamp>2010-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4392</id><created>2010-02-23</created><authors><author><keyname>Tong</keyname><forenames>Xin</forenames></author><author><keyname>Paquet</keyname><forenames>Joey</forenames></author><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author></authors><title>Complete Context Calculus Design and Implementation in GIPSY</title><categories>cs.FL cs.LO cs.PL</categories><comments>21 page; 18 listings; 2 figures; a complete version of the referenced
  simple context calculus implementation</comments><doi>10.1109/COMPSAC.2008.200</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the integration into the GIPSY of Lucx's context calculus
defined in Wan's PhD thesis. We start by defining different types of tag sets,
then we explain the concept of context, the types of context and the context
calculus operators. Finally, we present how context entities have been
abstracted into Java classes and embedded into the GIPSY system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4453</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4453</id><created>2010-02-23</created><updated>2010-06-26</updated><authors><author><keyname>Suzuki</keyname><forenames>Joe</forenames></author></authors><title>Nonparametric Estimation and On-Line Prediction for General Stationary
  Ergodic Sources</title><categories>cs.IT cs.AI math.IT math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We proposed a learning algorithm for nonparametric estimation and on-line
prediction for general stationary ergodic sources. We prepare histograms each
of which estimates the probability as a finite distribution, and mixture them
with weights to construct an estimator. The whole analysis is based on measure
theory. The estimator works whether the source is discrete or continuous. If it
is stationary ergodic, then the measure theoretically given Kullback-Leibler
information divided by the sequence length $n$ converges to zero as $n$ goes to
infinity. In particular, for continuous sources, the method does not require
existence of a probability density function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4458</identifier>
 <datestamp>2013-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4458</id><created>2010-02-23</created><updated>2013-02-04</updated><authors><author><keyname>Reeves</keyname><forenames>Galen</forenames></author><author><keyname>Gastpar</keyname><forenames>Michael</forenames></author></authors><title>Approximate Sparsity Pattern Recovery: Information-Theoretic Lower
  Bounds</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recovery of the sparsity pattern (or support) of an unknown sparse vector
from a small number of noisy linear measurements is an important problem in
compressed sensing. In this paper, the high-dimensional setting is considered.
It is shown that if the measurement rate and per-sample signal-to-noise ratio
(SNR) are finite constants independent of the length of the vector, then the
optimal sparsity pattern estimate will have a constant fraction of errors.
Lower bounds on the measurement rate needed to attain a desired fraction of
errors are given in terms of the SNR and various key parameters of the unknown
vector. The tightness of the bounds in a scaling sense, as a function of the
SNR and the fraction of errors, is established by comparison with existing
achievable bounds. Near optimality is shown for a wide variety of practically
motivated signal models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4464</identifier>
 <datestamp>2010-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4464</id><created>2010-02-23</created><authors><author><keyname>Dehne</keyname><forenames>Frank</forenames></author><author><keyname>Zaboli</keyname><forenames>Hamidreza</forenames></author></authors><title>Deterministic Sample Sort For GPUs</title><categories>cs.DC cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present and evaluate GPU Bucket Sort, a parallel deterministic sample sort
algorithm for many-core GPUs. Our method is considerably faster than Thrust
Merge (Satish et.al., Proc. IPDPS 2009), the best comparison-based sorting
algorithm for GPUs, and it is as fast as the new randomized sample sort for
GPUs by Leischner et.al. (to appear in Proc. IPDPS 2010). Our deterministic
sample sort has the advantage that bucket sizes are guaranteed and therefore
its running time does not have the input data dependent fluctuations that can
occur for randomized sample sort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4470</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4470</id><created>2010-02-24</created><updated>2011-04-20</updated><authors><author><keyname>Takeuchi</keyname><forenames>Keigo</forenames></author><author><keyname>Vehkaperae</keyname><forenames>Mikko</forenames></author><author><keyname>Tanaka</keyname><forenames>Toshiyuki</forenames></author><author><keyname>Mueller</keyname><forenames>Ralf R.</forenames></author></authors><title>Large-System Analysis of Joint Channel and Data Estimation for MIMO
  DS-CDMA Systems</title><categories>cs.IT math.IT</categories><comments>The paper was resubmitted to IEEE Trans. Inf. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a large-system analysis of the performance of joint
channel estimation, multiuser detection, and per-user decoding (CE-MUDD) for
randomly-spread multiple-input multiple-output (MIMO) direct-sequence
code-division multiple-access (DS-CDMA) systems. A suboptimal receiver based on
successive decoding in conjunction with linear minimum mean-squared error
(LMMSE) channel estimation is investigated. The replica method, developed in
statistical mechanics, is used to evaluate the performance in the large-system
limit, where the number of users and the spreading factor tend to infinity
while their ratio and the number of transmit and receive antennas are kept
constant. The performance of the joint CE-MUDD based on LMMSE channel
estimation is compared to the spectral efficiencies of several receivers based
on one-shot LMMSE channel estimation, in which the decoded data symbols are not
utilized to refine the initial channel estimates. The results imply that the
use of joint CE-MUDD significantly reduces rate loss due to transmission of
pilot signals, especially for multiple-antenna systems. As a result, joint
CE-MUDD can provide significant performance gains, compared to the receivers
based on one-shot channel estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4473</identifier>
 <datestamp>2010-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4473</id><created>2010-02-24</created><authors><author><keyname>Leong</keyname><forenames>Alex S.</forenames></author><author><keyname>Dey</keyname><forenames>Subhrakanti</forenames></author></authors><title>On Scaling Laws of Diversity Schemes in Decentralized Estimation</title><categories>cs.IT math.IT</categories><comments>23 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with decentralized estimation of a Gaussian source
using multiple sensors. We consider a diversity scheme where only the sensor
with the best channel sends their measurements over a fading channel to a
fusion center, using the analog amplify and forwarding technique. The fusion
centre reconstructs an MMSE estimate of the source based on the received
measurements. A distributed version of the diversity scheme where sensors
decide whether to transmit based only on their local channel information is
also considered. We derive asymptotic expressions for the expected distortion
(of the MMSE estimate at the fusion centre) of these schemes as the number of
sensors becomes large. For comparison, asymptotic expressions for the expected
distortion for a coherent multi-access scheme and an orthogonal access scheme
are derived. We also study for the diversity schemes, the optimal power
allocation for minimizing the expected distortion subject to average total
power constraints. The effect of optimizing the probability of transmission on
the expected distortion in the distributed scenario is also studied. It is seen
that as opposed to the coherent multi-access scheme and the orthogonal scheme
(where the expected distortion decays as 1/M, M being the number of sensors),
the expected distortion decays only as 1/ln(M) for the diversity schemes. This
reduction of the decay rate can be seen as a tradeoff between the simplicity of
the diversity schemes and the strict synchronization and large bandwidth
requirements for the coherent multi-access and the orthogonal schemes,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4482</identifier>
 <datestamp>2010-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4482</id><created>2010-02-24</created><authors><author><keyname>Dehne</keyname><forenames>Frank</forenames></author><author><keyname>Yogaratnam</keyname><forenames>Kumanan</forenames></author></authors><title>Exploring the Limits of GPUs With Parallel Graph Algorithms</title><categories>cs.DC cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we explore the limits of graphics processors (GPUs) for
general purpose parallel computing by studying problems that require highly
irregular data access patterns: parallel graph algorithms for list ranking and
connected components. Such graph problems represent a worst case scenario for
coalescing parallel memory accesses on GPUs which is critical for good GPU
performance. Our experimental study indicates that PRAM algorithms are a good
starting point for developing efficient parallel GPU methods but require
non-trivial modifications to ensure good GPU performance. We present a set of
guidelines that help algorithm designers adapt PRAM graph algorithms for
parallel GPU computation. We point out that the study of parallel graph
algorithms for GPUs is of wider interest for discrete and combinatorial
problems in general because many of these problems require similar irregular
data access patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4487</identifier>
 <datestamp>2010-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4487</id><created>2010-02-24</created><authors><author><keyname>Miled</keyname><forenames>Abdelwaheb</forenames></author><author><keyname>Ouertani</keyname><forenames>Ahmed</forenames></author></authors><title>Extended gcd of quadratic integers</title><categories>cs.DM</categories><comments>3 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computation of the extended gcd of two quadratic integers. The ring of
integers considered is principal but could be euclidean or not euclidean ring.
This method rely on principal ideal ring and reduction of binary quadratic
forms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4510</identifier>
 <datestamp>2010-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4510</id><created>2010-02-24</created><authors><author><keyname>Borges</keyname><forenames>Joaquim</forenames></author><author><keyname>Rifa</keyname><forenames>Josep</forenames></author><author><keyname>Zinoviev</keyname><forenames>Victor</forenames></author></authors><title>On linear $q$-ary completely regular codes with $\rho=2$ and dual
  antipodal</title><categories>cs.IT math.CO math.IT</categories><msc-class>94B25; 94B60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We characterize all linear $q$-ary completely regular codes with covering
radius $\rho=2$ when the dual codes are antipodal. These completely regular
codes are extensions of linear completely regular codes with covering radius 1,
which are all classified. For $\rho=2$, we give a list of all such codes known
to us. This also gives the characterization of two weight linear antipodal
codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4522</identifier>
 <datestamp>2010-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4522</id><created>2010-02-24</created><authors><author><keyname>Jakaite</keyname><forenames>L.</forenames></author><author><keyname>Schetinin</keyname><forenames>V.</forenames></author><author><keyname>Maple</keyname><forenames>C.</forenames></author></authors><title>Feature Importance in Bayesian Assessment of Newborn Brain Maturity from
  EEG</title><categories>cs.AI</categories><comments>Proceedings of the 9th WSEAS International Conference on Artificial
  Intelligence, Knowledge Engineering and Data Bases (AIKED), University of
  Cambridge, UK, 2010, edited by L. A. Zadeh et al, pp 191 - 195</comments><journal-ref>Proceedings of the 9th WSEAS International Conference on
  Artificial Intelligence, Knowledge Engineering and Data Bases (AIKED),
  University of Cambridge, UK, 2010, edited by L. A. Zadeh et al, pp 191 - 195</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The methodology of Bayesian Model Averaging (BMA) is applied for assessment
of newborn brain maturity from sleep EEG. In theory this methodology provides
the most accurate assessments of uncertainty in decisions. However, the
existing BMA techniques have been shown providing biased assessments in the
absence of some prior information enabling to explore model parameter space in
details within a reasonable time. The lack in details leads to disproportional
sampling from the posterior distribution. In case of the EEG assessment of
brain maturity, BMA results can be biased because of the absence of information
about EEG feature importance. In this paper we explore how the posterior
information about EEG features can be used in order to reduce a negative impact
of disproportional sampling on BMA performance. We use EEG data recorded from
sleeping newborns to test the efficiency of the proposed BMA technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4530</identifier>
 <datestamp>2010-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4530</id><created>2010-02-24</created><authors><author><keyname>Vasudevan</keyname><forenames>Rangarajan Athi</forenames></author><author><keyname>Abraham</keyname><forenames>Ajith</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author></authors><title>A Novel Scheme for Secured Data Transfer Over Computer Networks</title><categories>cs.CR</categories><comments>18 Pages, 6 figures, published in Journal of Universal Computer
  Science, 2005</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel encryption-less algorithm to enhance security in
transmission of data in networks. The algorithm uses an intuitively simple idea
of a &quot;jigsaw puzzle&quot; to break the transformed data into multiple parts where
these parts form the pieces of the puzzle. Then these parts are packaged into
packets and sent to the receiver. A secure and efficient mechanism is provided
to convey the information that is necessary for obtaining the original data at
the receiver-end from its parts in the packets, that is, for solving the
&quot;jigsaw puzzle&quot;. The algorithm is designed to provide information-theoretic
(that is, unconditional) security by the use of a one-time pad like scheme so
that no intermediate or unintended node can obtain the entire data. A
parallelizable design has been adopted for the implementation. An
authentication code is also used to ensure authenticity of every packet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4535</identifier>
 <datestamp>2010-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4535</id><created>2010-02-24</created><authors><author><keyname>Caballero</keyname><forenames>Rafael</forenames><affiliation>eds.</affiliation></author><author><keyname>Gallagher</keyname><forenames>John</forenames><affiliation>eds.</affiliation></author></authors><title>Proceedings of the 19th Workshop on Logic-based methods in Programming
  Environments (WLPE 2009)</title><categories>cs.LO</categories><comments>Html page including the links to the papers presented at the
  Workshop. The papers are already in CoRR</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the papers presented at the 19th Workshop on Logic-
based methods in Programming Environments (WLPE'09), which was held in
Pasadena, USA, on July 14th, 2009.
  WLPE aims at providing an informal meeting for researchers working on
logic-based methods and tools which support program development and analy- sis.
This year, we have continued and consolidated the shift in focus from en-
vironmental tools for logic programming to logic-based environmental tools for
programming in general, so that this workshop can be possibly interesting for a
wider scientific community.
  All the papers submitted to WLPE'09 have gone through a careful process of
peer reviewing, with at least three reviews for each paper and a subsequent
in-depth discussion in the Program Committee.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4548</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4548</id><created>2010-02-24</created><updated>2010-03-06</updated><authors><author><keyname>Khisti</keyname><forenames>Ashish</forenames></author></authors><title>Interference Alignment for the Multi-Antenna Compound Wiretap Channel</title><categories>cs.IT cs.CR math.IT</categories><comments>Minor edits. Submitted to IEEE Trans. Inf. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a wiretap channel model where the sender has $M$ transmit antennas
and there are two groups consisting of $J_1$ and $J_2$ receivers respectively.
Each receiver has a single antenna. We consider two scenarios. First we
consider the compound wiretap model -- group 1 constitutes the set of
legitimate receivers, all interested in a common message, whereas group 2 is
the set of eavesdroppers. We establish new lower and upper bounds on the secure
degrees of freedom. Our lower bound is based on the recently proposed
\emph{real interference alignment} scheme. The upper bound provides the first
known example which illustrates that the \emph{pairwise upper bound} used in
earlier works is not tight.
  The second scenario we study is the compound private broadcast channel. Each
group is interested in a message that must be protected from the other group.
Upper and lower bounds on the degrees of freedom are developed by extending the
results on the compound wiretap channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4561</identifier>
 <datestamp>2010-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4561</id><created>2010-02-24</created><authors><author><keyname>King</keyname><forenames>Valerie</forenames></author><author><keyname>Saia</keyname><forenames>Jared</forenames></author></authors><title>Breaking the O(n^2) Bit Barrier: Scalable Byzantine agreement with an
  Adaptive Adversary</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an algorithm for Byzantine agreement that is scalable in the
sense that each processor sends only $\tilde{O}(\sqrt{n})$ bits, where $n$ is
the total number of processors. Our algorithm succeeds with high probability
against an \emph{adaptive adversary}, which can take over processors at any
time during the protocol, up to the point of taking over arbitrarily close to a
1/3 fraction. We assume synchronous communication but a \emph{rushing}
adversary. Moreover, our algorithm works in the presence of flooding:
processors controlled by the adversary can send out any number of messages. We
assume the existence of private channels between all pairs of processors but
make no other cryptographic assumptions. Finally, our algorithm has latency
that is polylogarithmic in $n$. To the best of our knowledge, ours is the first
algorithm to solve Byzantine agreement against an adaptive adversary, while
requiring $o(n^{2})$ total bits of communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4569</identifier>
 <datestamp>2010-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4569</id><created>2010-02-24</created><updated>2010-03-02</updated><authors><author><keyname>Giraud</keyname><forenames>Christophe</forenames><affiliation>INRIA Bordeaux - Sud-Ouest</affiliation></author><author><keyname>Verneuil</keyname><forenames>Vincent</forenames><affiliation>INRIA Bordeaux - Sud-Ouest</affiliation></author></authors><title>Atomicity Improvement for Elliptic Curve Scalar Multiplication</title><categories>cs.CR</categories><proxy>ccsd inria-00459461</proxy><journal-ref>CARDIS 2010, Passau : Germany (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we address the problem of protecting elliptic curve scalar
multiplication implementations against side-channel analysis by using the
atomicity principle. First of all we reexamine classical assumptions made by
scalar multiplication designers and we point out that some of them are not
relevant in the context of embedded devices. We then describe the
state-of-the-art of atomic scalar multiplication and propose an atomic pattern
improvement method. Compared to the most ef?cient atomic scalar multiplication
published so far, our technique shows an average improvement of up to 10.6%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4577</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4577</id><created>2010-02-24</created><updated>2011-06-26</updated><authors><author><keyname>Chen</keyname><forenames>Hubie</forenames></author></authors><title>Bounded Rationality, Strategy Simplification, and Equilibrium</title><categories>cs.GT cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is frequently suggested that predictions made by game theory could be
improved by considering computational restrictions when modeling agents. Under
the supposition that players in a game may desire to balance maximization of
payoff with minimization of strategy complexity, Rubinstein and co-authors
studied forms of Nash equilibrium where strategies are maximally simplified in
that no strategy can be further simplified without sacrificing payoff. Inspired
by this line of work, we introduce a notion of equilibrium whereby strategies
are also maximally simplified, but with respect to a simplification procedure
that is more careful in that a player will not simplify if the simplification
incents other players to deviate. We study such equilibria in two-player
machine games in which players choose finite automata that succinctly represent
strategies for repeated games; in this context, we present techniques for
establishing that an outcome is at equilibrium and present results on the
structure of equilibria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4583</identifier>
 <datestamp>2010-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4583</id><created>2010-02-24</created><updated>2010-05-01</updated><authors><author><keyname>Shepelyansky</keyname><forenames>D. L.</forenames><affiliation>CNRS, Toulouse &amp; BINP, Novosibirsk</affiliation></author><author><keyname>Zhirov</keyname><forenames>O. V.</forenames><affiliation>CNRS, Toulouse &amp; BINP, Novosibirsk</affiliation></author></authors><title>Towards Google matrix of brain</title><categories>cond-mat.dis-nn cs.NI nlin.AO physics.soc-ph q-bio.NC q-bio.TO</categories><comments>revtex 5 pages, 7 figs, data added, research at
  http://www.quantware.ups-tlse.fr</comments><journal-ref>Phys. Lett. A v.374, p.3206-3209 (2010)</journal-ref><doi>10.1016/j.physleta.2010.06.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply the approach of the Google matrix, used in computer science and
World Wide Web, to description of properties of neuronal networks. The Google
matrix ${\bf G}$ is constructed on the basis of neuronal network of a brain
model discussed in PNAS {\bf 105}, 3593 (2008). We show that the spectrum of
eigenvalues of ${\bf G}$ has a gapless structure with long living relaxation
modes. The PageRank of the network becomes delocalized for certain values of
the Google damping factor $\alpha$. The properties of other eigenstates are
also analyzed. We discuss further parallels and similarities between the World
Wide Web and neuronal networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4587</identifier>
 <datestamp>2010-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4587</id><created>2010-02-24</created><authors><author><keyname>Nedzvetski</keyname><forenames>Vadim</forenames></author></authors><title>Using Information Semantic Systems for Absolutely Secure Processing</title><categories>cs.IT math.IT</categories><msc-class>94A15; 68Q30; 68P30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Propose a new cryptographic information concept. It allows : - to create
absolutely algorithmic unbreakable ciphers for communication through open
digital channels; - to create new code-breaking methods. They will be the most
efficient decoding methods to-date, with the help of which any of the existing
codes could, in principle, be broken, provided it is not absolutely
unbreakable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4592</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4592</id><created>2010-02-24</created><authors><author><keyname>Hasanhodzic</keyname><forenames>Jasmina</forenames></author><author><keyname>Lo</keyname><forenames>Andrew W.</forenames></author><author><keyname>Viola</keyname><forenames>Emanuele</forenames></author></authors><title>Is It Real, or Is It Randomized?: A Financial Turing Test</title><categories>q-fin.GN cs.CE cs.HC</categories><comments>12 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct a financial &quot;Turing test&quot; to determine whether human subjects
can differentiate between actual vs. randomized financial returns. The
experiment consists of an online video-game (http://arora.ccs.neu.edu) where
players are challenged to distinguish actual financial market returns from
random temporal permutations of those returns. We find overwhelming statistical
evidence (p-values no greater than 0.5%) that subjects can consistently
distinguish between the two types of time series, thereby refuting the
widespread belief that financial markets &quot;look random.&quot; A key feature of the
experiment is that subjects are given immediate feedback regarding the validity
of their choices, allowing them to learn and adapt. We suggest that such novel
interfaces can harness human capabilities to process and extract information
from financial data in ways that computers cannot.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4616</identifier>
 <datestamp>2010-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4616</id><created>2010-02-24</created><updated>2010-10-13</updated><authors><author><keyname>Gurfinkel</keyname><forenames>Arie</forenames></author><author><keyname>Chechik</keyname><forenames>Marsha</forenames></author></authors><title>Robust Vacuity for Branching Temporal Logic</title><categories>cs.LO</categories><acm-class>D.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a growing interest in techniques for detecting whether a logic
specification is satisfied too easily, or vacuously. For example, the
specification &quot;every request is eventually followed by an acknowledgment&quot; is
satisfied vacuously by a system that never generates any requests. Vacuous
satisfaction misleads users of model-checking into thinking that a system is
correct.
  There are several existing definitions of vacuity. Originally, Beer et al.
formalized vacuity as insensitivity to syntactic perturbation. However, this
definition is only reasonable for vacuity in a single occurrence. Armoni et al.
argued that vacuity must be robust -- not affected by semantically invariant
changes, such as extending a model with additional atomic propositions. They
show that syntactic vacuity is not robust for LTL, and propose an alternative
definition -- trace vacuity.
  In this article, we continue this line of research. We show that trace
vacuity is not robust for branching time logic. We refine it to apply uniformly
to linear and branching time logic and to not suffer from the common pitfalls
of prior definitions. Our new definition -- bisimulation vacuity -- is a proper
non-trivial extension of both syntactic and trace vacuity. We discuss the
complexity of detecting bisimulation vacuity, and give efficient algorithms to
detect vacuity for several practically-relevant subsets of CTL*.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4658</identifier>
 <datestamp>2010-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4658</id><created>2010-02-24</created><updated>2010-05-12</updated><authors><author><keyname>Xu</keyname><forenames>Huan</forenames></author><author><keyname>Caramanis</keyname><forenames>Constantine</forenames></author><author><keyname>Mannor</keyname><forenames>Shie</forenames></author></authors><title>Principal Component Analysis with Contaminated Data: The High
  Dimensional Case</title><categories>stat.ML cs.LG stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the dimensionality-reduction problem (finding a subspace
approximation of observed data) for contaminated data in the high dimensional
regime, where the number of observations is of the same magnitude as the number
of variables of each observation, and the data set contains some (arbitrarily)
corrupted observations. We propose a High-dimensional Robust Principal
Component Analysis (HR-PCA) algorithm that is tractable, robust to contaminated
points, and easily kernelizable. The resulting subspace has a bounded deviation
from the desired one, achieves maximal robustness -- a breakdown point of 50%
while all existing algorithms have a breakdown point of zero, and unlike
ordinary PCA algorithms, achieves optimality in the limit case where the
proportion of corrupted points goes to zero.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4661</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4661</id><created>2010-02-24</created><authors><author><keyname>Akman</keyname><forenames>Ozgur E.</forenames><affiliation>School of Engineering, Computing &amp; Mathematics, University of Exeter, UK</affiliation></author><author><keyname>Guerriero</keyname><forenames>Maria Luisa</forenames><affiliation>Centre for Systems Biology at Edinburgh, University of Edinburgh, UK</affiliation></author><author><keyname>Loewe</keyname><forenames>Laurence</forenames><affiliation>Centre for Systems Biology at Edinburgh, University of Edinburgh, UK</affiliation></author><author><keyname>Troein</keyname><forenames>Carl</forenames><affiliation>Centre for Systems Biology at Edinburgh and School of Biological Sciences, University of Edinburgh, UK</affiliation></author></authors><title>Complementary approaches to understanding the plant circadian clock</title><categories>cs.CE cs.MS q-bio.MN</categories><acm-class>F.4; G.4; I.6; J.3</acm-class><journal-ref>EPTCS 19, 2010, pp. 1-19</journal-ref><doi>10.4204/EPTCS.19.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Circadian clocks are oscillatory genetic networks that help organisms adapt
to the 24-hour day/night cycle. The clock of the green alga Ostreococcus tauri
is the simplest plant clock discovered so far. Its many advantages as an
experimental system facilitate the testing of computational predictions.
  We present a model of the Ostreococcus clock in the stochastic process
algebra Bio-PEPA and exploit its mapping to different analysis techniques, such
as ordinary differential equations, stochastic simulation algorithms and
model-checking. The small number of molecules reported for this system tests
the limits of the continuous approximation underlying differential equations.
We investigate the difference between continuous-deterministic and
discrete-stochastic approaches. Stochastic simulation and model-checking allow
us to formulate new hypotheses on the system behaviour, such as the presence of
self-sustained oscillations in single cells under constant light conditions.
  We investigate how to model the timing of dawn and dusk in the context of
model-checking, which we use to compute how the probability distributions of
key biochemical species change over time. These show that the relative
variation in expression level is smallest at the time of peak expression,
making peak time an optimal experimental phase marker. Building on these
analyses, we use approaches from evolutionary systems biology to investigate
how changes in the rate of mRNA degradation impacts the phase of a key protein
likely to affect fitness. We explore how robust this circadian clock is towards
such potential mutational changes in its underlying biochemistry. Our work
shows that multiple approaches lead to a more complete understanding of the
clock.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4665</identifier>
 <datestamp>2010-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4665</id><created>2010-02-24</created><authors><author><keyname>Boyd-Graber</keyname><forenames>Jordan</forenames></author><author><keyname>Blei</keyname><forenames>David M.</forenames></author></authors><title>Syntactic Topic Models</title><categories>cs.CL cs.AI math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The syntactic topic model (STM) is a Bayesian nonparametric model of language
that discovers latent distributions of words (topics) that are both
semantically and syntactically coherent. The STM models dependency parsed
corpora where sentences are grouped into documents. It assumes that each word
is drawn from a latent topic chosen by combining document-level features and
the local syntactic context. Each document has a distribution over latent
topics, as in topic models, which provides the semantic consistency. Each
element in the dependency parse tree also has a distribution over the topics of
its children, as in latent-state syntax models, which provides the syntactic
consistency. These distributions are convolved so that the topic of each word
is likely under both its document and syntactic context. We derive a fast
posterior inference algorithm based on variational methods. We report
qualitative and quantitative studies on both synthetic data and hand-parsed
documents. We show that the STM is a more predictive model of language than
current models based only on syntax or only on topics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4668</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4668</id><created>2010-02-24</created><authors><author><keyname>Aldinucci</keyname><forenames>Marco</forenames></author><author><keyname>Danelutto</keyname><forenames>Marco</forenames></author><author><keyname>Kilpatrick</keyname><forenames>Peter</forenames></author><author><keyname>Meneghin</keyname><forenames>Massimiliano</forenames></author><author><keyname>Torquati</keyname><forenames>Massimo</forenames></author></authors><title>Accelerating sequential programs using FastFlow and self-offloading</title><categories>cs.DC cs.PL cs.SE</categories><comments>17 pages + cover</comments><report-no>TR-10-03</report-no><acm-class>D.1.3; D.3.2; C.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  FastFlow is a programming environment specifically targeting cache-coherent
shared-memory multi-cores. FastFlow is implemented as a stack of C++ template
libraries built on top of lock-free (fence-free) synchronization mechanisms. In
this paper we present a further evolution of FastFlow enabling programmers to
offload part of their workload on a dynamically created software accelerator
running on unused CPUs. The offloaded function can be easily derived from
pre-existing sequential code. We emphasize in particular the effective
trade-off between human productivity and execution efficiency of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4676</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4676</id><created>2010-02-24</created><authors><author><keyname>Wehr</keyname><forenames>Dustin</forenames></author></authors><title>Pebbling and Branching Programs Solving the Tree Evaluation Problem</title><categories>cs.CC</categories><comments>Written as one of the requirements for my MSc. 29 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study restricted computation models related to the Tree Evaluation
Problem}. The TEP was introduced in earlier work as a simple candidate for the
(*very*) long term goal of separating L and LogDCFL. The input to the problem
is a rooted, balanced binary tree of height h, whose internal nodes are labeled
with binary functions on [k] = {1,...,k} (each given simply as a list of k^2
elements of [k]), and whose leaves are labeled with elements of [k]. Each node
obtains a value in [k] equal to its binary function applied to the values of
its children, and the output is the value of the root. The first restricted
computation model, called Fractional Pebbling, is a generalization of the
black/white pebbling game on graphs, and arises in a natural way from the
search for good upper bounds on the size of nondeterministic branching programs
(BPs) solving the TEP - for any fixed h, if the binary tree of height h has
fractional pebbling cost at most p, then there are nondeterministic BPs of size
O(k^p) solving the height h TEP. We prove a lower bound on the fractional
pebbling cost of d-ary trees that is tight to within an additive constant for
each fixed d. The second restricted computation model we study is a semantic
restriction on (non)deterministic BPs solving the TEP - Thrifty BPs.
Deterministic (resp. nondeterministic) thrifty BPs suffice to implement the
best known algorithms for the TEP, based on black (resp. fractional) pebbling.
In earlier work, for each fixed h a lower bound on the size of deterministic
thrifty BPs was proved that is tight for sufficiently large k. We give an
alternative proof that achieves the same bound for all k. We show the same
bound still holds in a less-restricted model, and also that gradually weaker
lower bounds can be obtained for gradually weaker restrictions on the model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4680</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4680</id><created>2010-02-25</created><authors><author><keyname>Srivastava</keyname><forenames>Neelam</forenames></author></authors><title>Challenges of Next-Generation Wireless Sensor Networks and its impact on
  Society</title><categories>cs.NI</categories><comments>Journal of Telecommunications,Volume 1, Issue 1, pp128-133, February
  2010</comments><journal-ref>Neelam Srivastava, &quot;Challenges of Next-Generation Wireless Sensor
  Networks and its impact on Society&quot;, Journal of Telecommunications, Volume 1,
  Issue 1, pp128-133, February 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Sensor Networks (WSNs) have gained worldwide attention in recent
years, particularly with the proliferation in Micro-Electro-Mechanical Systems
(MEMS) technology which has facilitated the development of smart sensors. The
paper discusses about classification of WSN and challenges of the Next
Generation WSN. One of the major challenges of Next Generation WSN is reduction
of power consumption. The two approaches are discussed: Ultra-Low-Power
Networks and Energy Harvesting. The paper also discusses about some major
applications as designing low cost secured Intelligent Buildings, In-Home
Health care and Agriculture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4724</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4724</id><created>2010-02-25</created><authors><author><keyname>Lee</keyname><forenames>Seokhyoung</forenames></author><author><keyname>Shin</keyname><forenames>Vladimir</forenames></author></authors><title>Low-complexity Fusion Filtering for Continuous-Discrete Systems</title><categories>cs.OH</categories><comments>Journal of Telecommunications,Volume 1, Issue 1, pp80-83, February
  2010</comments><journal-ref>S.Lee and V. Shin, &quot;Low-complexity Fusion Filtering for
  Continuous-Discrete Systems&quot;, Journal of Telecommunications, Volume 1, Issue
  1, pp80-83, February 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, low-complexity distributed fusion filtering algorithm for
mixed continuous-discrete multisensory dynamic systems is proposed. To
implement the algorithm a new recursive equations for local cross-covariances
are derived. To achieve an effective fusion filtering the covariance
intersection (CI) algorithm is used. The CI algorithm is useful due to its
low-computational complexity for calculation of a big number of
cross-covariances between local estimates and matrix weights. Theoretical and
numerical examples demonstrate the effectiveness of the covariance intersection
algorithm in distributed fusion filtering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4725</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4725</id><created>2010-02-25</created><authors><author><keyname>Bret</keyname><forenames>A.</forenames></author></authors><title>Transferring a symbolic polynomial expression from \emph{Mathematica} to
  \emph{Matlab}</title><categories>cs.MS physics.comp-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A \emph{Mathematica} Notebook is presented which allows for the transfer or
any kind of polynomial expression to \emph{Matlab}. The output is formatted in
such a way that \emph{Matlab} routines such as &quot;Root&quot; can be readily
implemented. Once the Notebook has been executed, only one copy-paste operation
in necessary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4727</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4727</id><created>2010-02-25</created><authors><author><keyname>Hossain</keyname><forenames>Md. M.</forenames></author><author><keyname>Rahman</keyname><forenames>Md. M.</forenames></author><author><keyname>Alim</keyname><forenames>Md. A.</forenames></author></authors><title>Performance Analysis of Uplink &amp; Downlink Transmission in CDMA System</title><categories>cs.NI</categories><comments>Journal of Telecommunications,Volume 1, Issue 1, pp84-86, February
  2010</comments><journal-ref>M. M. Hossain, M. M. Rahmand and M. A. Alim, &quot;Performance Analysis
  of Uplink &amp; Downlink Transmission in CDMA System&quot;, Journal of
  Telecommunications, Volume 1, Issue 1, pp84-86, February 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  CDMA is a multiple access method in which the user's uses spread spectrum
techniques and occupy the entire spectrum whenever they transmit. In wireless
communication signal-to-noise ratio (SNR) is the very important parameter that
influences the system performance. Any mode of mobile transmission is not free
from channel impairment such as noise, interference and fading. This channel
impairment caused signal distortion and degradation in SNR.Also there are
differences between uplink (forward channel) and downlink (reverse
channel).Along with these differences, both the links use different codes for
chanellizing the individual users. This paper simulates the expressions for the
pdfs of the SNR for both uplink and downlink transmission assuming that the
system is operating at an average signal-to-noise ratio is 6dB per information
bit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4738</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4738</id><created>2010-02-25</created><authors><author><keyname>Kirby</keyname><forenames>Graham</forenames></author><author><keyname>Dearle</keyname><forenames>Alan</forenames></author><author><keyname>Macdonald</keyname><forenames>Angus</forenames></author><author><keyname>Fernandes</keyname><forenames>Alvaro</forenames></author></authors><title>An Approach to Ad hoc Cloud Computing</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider how underused computing resources within an enterprise may be
harnessed to improve utilization and create an elastic computing
infrastructure. Most current cloud provision involves a data center model, in
which clusters of machines are dedicated to running cloud infrastructure
software. We propose an additional model, the ad hoc cloud, in which
infrastructure software is distributed over resources harvested from machines
already in existence within an enterprise. In contrast to the data center cloud
model, resource levels are not established a priori, nor are resources
dedicated exclusively to the cloud while in use. A participating machine is not
dedicated to the cloud, but has some other primary purpose such as running
interactive processes for a particular user. We outline the major
implementation challenges and one approach to tackling them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4759</identifier>
 <datestamp>2010-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4759</id><created>2010-02-25</created><updated>2010-11-03</updated><authors><author><keyname>Geil</keyname><forenames>Olav</forenames></author><author><keyname>Munuera</keyname><forenames>Carlos</forenames></author><author><keyname>Ruano</keyname><forenames>Diego</forenames></author><author><keyname>Torres</keyname><forenames>Fernando</forenames></author></authors><title>On the order bounds for one-point AG codes</title><categories>cs.IT math.IT</categories><msc-class>94B27 (Primary) 14G50, 14H55 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The order bound for the minimum distance of algebraic geometry codes was
originally defined for the duals of one-point codes and later generalized for
arbitrary algebraic geometry codes. Another bound of order type for the minimum
distance of general linear codes, and for codes from order domains in
particular, was given in [H. Andersen and O. Geil, Evaluation codes from order
domain theory, Finite Fields and their Applications 14 (2008), pp. 92-123].
Here we investigate in detail the application of that bound to one-point
algebraic geometry codes, obtaining a bound $d^*$ for the minimum distance of
these codes. We establish a connection between $d^*$ and the order bound and
its generalizations. We also study the improved code constructions based on
$d^*$. Finally we extend $d^*$ to all generalized Hamming weights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4768</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4768</id><created>2010-02-25</created><authors><author><keyname>Grif</keyname><forenames>Horatiu Stefan</forenames></author></authors><title>Neural daylight control system</title><categories>cs.NE nlin.AO</categories><comments>4 pages, 4 figures, The 5th International Conference ILUMINAT 2009</comments><journal-ref>Proceedings of The 5th International Conference ILUMINAT 2009,
  Cluj-Napoca, Romania</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper describes the design, the implementation of a neural controller
used in an automatic daylight control system. The automatic lighting control
system (ALCS) attempt to maintain constant the illuminance at the desired level
on working plane even if the daylight contribution is variable. Therefore, the
daylight will represent the perturbation signal for the ALCS. The mathematical
model of process is unknown. The applied structure of control need the inverse
model of process. For this purpose it was used other artificial neural network
(ANN) which identify the inverse model of process in an on-line manner. In
fact, this ANN identify the inverse model of process + the perturbation signal.
In this way the learning signal for neural controller has a better accuracy for
the present application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4784</identifier>
 <datestamp>2010-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4784</id><created>2010-02-25</created><updated>2010-05-13</updated><authors><author><keyname>Chen</keyname><forenames>Changbo</forenames></author><author><keyname>Davenport</keyname><forenames>James H.</forenames></author><author><keyname>May</keyname><forenames>John P.</forenames></author><author><keyname>Maza</keyname><forenames>Marc Moreno</forenames></author><author><keyname>Xia</keyname><forenames>Bican</forenames></author><author><keyname>Xiao</keyname><forenames>Rong</forenames></author></authors><title>Triangular Decomposition of Semi-algebraic Systems</title><categories>cs.SC cs.CG cs.MS</categories><comments>8 pages, accepted by ISSAC 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regular chains and triangular decompositions are fundamental and
well-developed tools for describing the complex solutions of polynomial
systems. This paper proposes adaptations of these tools focusing on solutions
of the real analogue: semi-algebraic systems. We show that any such system can
be decomposed into finitely many {\em regular semi-algebraic systems}. We
propose two specifications of such a decomposition and present corresponding
algorithms. Under some assumptions, one type of decomposition can be computed
in singly exponential time w.r.t.\ the number of variables. We implement our
algorithms and the experimental results illustrate their effectiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4802</identifier>
 <datestamp>2010-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4802</id><created>2010-02-25</created><updated>2010-03-12</updated><authors><author><keyname>Silva</keyname><forenames>Ricardo</forenames></author><author><keyname>Gramacy</keyname><forenames>Robert B.</forenames></author></authors><title>Gaussian Process Structural Equation Models with Latent Variables</title><categories>cs.LG stat.ML</categories><comments>12 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a variety of disciplines such as social sciences, psychology, medicine and
economics, the recorded data are considered to be noisy measurements of latent
variables connected by some causal structure. This corresponds to a family of
graphical models known as the structural equation model with latent variables.
While linear non-Gaussian variants have been well-studied, inference in
nonparametric structural equation models is still underdeveloped. We introduce
a sparse Gaussian process parameterization that defines a non-linear structure
connecting latent variables, unlike common formulations of Gaussian process
latent variable models. The sparse parameterization is given a full Bayesian
treatment without compromising Markov chain Monte Carlo efficiency. We compare
the stability of the sampling procedure and the predictive ability of the model
against the current practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4818</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4818</id><created>2010-02-25</created><authors><author><keyname>Gysin</keyname><forenames>Florian S.</forenames></author><author><keyname>Kuhn</keyname><forenames>Adrian</forenames></author></authors><title>A Trustability Metric for Code Search based on Developer Karma</title><categories>cs.SE cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The promise of search-driven development is that developers will save time
and resources by reusing external code in their local projects. To efficiently
integrate this code, users must be able to trust it, thus trustability of code
search results is just as important as their relevance. In this paper, we
introduce a trustability metric to help users assess the quality of code search
results and therefore ease the cost-benefit analysis they undertake trying to
find suitable integration candidates. The proposed trustability metric
incorporates both user votes and cross-project activity of developers to
calculate a &quot;karma&quot; value for each developer. Through the karma value of all
its developers a project is ranked on a trustability scale. We present JBender,
a proof-of-concept code search engine which implements our trustability metric
and we discuss preliminary results from an evaluation of the prototype.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4820</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4820</id><created>2010-02-25</created><authors><author><keyname>Desalle</keyname><forenames>Yann</forenames><affiliation>CLLE, Lordat</affiliation></author><author><keyname>Gaume</keyname><forenames>Bruno</forenames><affiliation>CLLE</affiliation></author><author><keyname>Duvignau</keyname><forenames>Karine</forenames><affiliation>CLLE, Erss</affiliation></author></authors><title>SLAM : Solutions lexicales automatique pour m\'etaphores</title><categories>cs.CL</categories><comments>30 pages</comments><proxy>ccsd hal-00459965</proxy><journal-ref>Traitement Automatique des Langues 50, 1 (2009) 145--175</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents SLAM, an Automatic Solver for Lexical Metaphors like
?d\'eshabiller* une pomme? (to undress* an apple). SLAM calculates a
conventional solution for these productions. To carry on it, SLAM has to
intersect the paradigmatic axis of the metaphorical verb ?d\'eshabiller*?,
where ?peler? (?to peel?) comes closer, with a syntagmatic axis that comes from
a corpus where ?peler une pomme? (to peel an apple) is semantically and
syntactically regular. We test this model on DicoSyn, which is a ?small world?
network of synonyms, to compute the paradigmatic axis and on Frantext.20, a
French corpus, to compute the syntagmatic axis. Further, we evaluate the model
with a sample of an experimental corpus of the database of Flexsem
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4830</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4830</id><created>2010-02-25</created><updated>2010-04-19</updated><authors><author><keyname>Huq</keyname><forenames>Kazi Mohammed Saidul</forenames></author><author><keyname>Arefin</keyname><forenames>Md. Taslim</forenames></author><author><keyname>Kabir</keyname><forenames>A. F. M. Sultanul</forenames></author></authors><title>Nonlinear System Identification and Behavioral Modeling</title><categories>cs.OH</categories><comments>This paper has been withdrawn by the author</comments><journal-ref>K. M. S. Huq, M. T. Arefin and A. F. M. S. Kabir, &quot;Nonlinear
  System Identification and Behavioral Modeling&quot;, Journal of
  Telecommunications, Volume 1, Issue 1, pp94-98, February 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4831</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4831</id><created>2010-02-25</created><authors><author><keyname>Al-Zahrani</keyname><forenames>F. A.</forenames></author><author><keyname>Mustafa</keyname><forenames>H. M.</forenames></author><author><keyname>Al-Hamadi</keyname><forenames>A.</forenames></author></authors><title>On Analysis and Evaluation of Multi-Sensory Cognitive Learning of a
  Mathematical Topic Using Artificial Neural Networks</title><categories>cs.NE</categories><comments>Journal of Telecommunications,Volume 1, Issue 1, pp99-104, February
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This piece of research belongs to the field of educational assessment issue
based upon the cognitive multimedia theory. Considering that theory; visual and
auditory material should be presented simultaneously to reinforce the retention
of a mathematical learned topic, a carefully computer-assisted learning (CAL)
module is designed for development of a multimedia tutorial for our suggested
mathematical topic. The designed CAL module is a multimedia tutorial computer
package with visual and/or auditory material. So, via suggested computer
package, Multi-Sensory associative memories and classical conditioning theories
are practically applicable at an educational field (a children classroom). It
is noticed that comparative practical results obtained are interesting for
field application of CAL package with and without associated teacher's voice.
Finally, the presented study highly recommends application of a novel teaching
trend aiming to improve quality of children mathematical learning performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4832</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4832</id><created>2010-02-25</created><updated>2010-05-11</updated><authors><author><keyname>Adsul</keyname><forenames>Bharat</forenames></author><author><keyname>Babu</keyname><forenames>Ch. Sobhan</forenames></author><author><keyname>Garg</keyname><forenames>Jugal</forenames></author><author><keyname>Mehta</keyname><forenames>Ruta</forenames></author><author><keyname>Sohoni</keyname><forenames>Milind</forenames></author></authors><title>Nash equilibria in Fisher market</title><categories>cs.GT</categories><doi>10.1007/978-3-642-16170-4_4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Much work has been done on the computation of market equilibria. However due
to strategic play by buyers, it is not clear whether these are actually
observed in the market. Motivated by the observation that a buyer may derive a
better payoff by feigning a different utility function and thereby manipulating
the Fisher market equilibrium, we formulate the {\em Fisher market game} in
which buyers strategize by posing different utility functions. We show that
existence of a {\em conflict-free allocation} is a necessary condition for the
Nash equilibria (NE) and also sufficient for the symmetric NE in this game.
There are many NE with very different payoffs, and the Fisher equilibrium
payoff is captured at a symmetric NE. We provide a complete polyhedral
characterization of all the NE for the two-buyer market game. Surprisingly, all
the NE of this game turn out to be symmetric and the corresponding payoffs
constitute a piecewise linear concave curve. We also study the correlated
equilibria of this game and show that third-party mediation does not help to
achieve a better payoff than NE payoffs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4833</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4833</id><created>2010-02-25</created><authors><author><keyname>Mohamedou</keyname><forenames>Ahmed</forenames></author><author><keyname>Othman</keyname><forenames>Mohamed</forenames></author></authors><title>Analytical Evaluation of Unfairness Problem in Wireless LANs</title><categories>cs.NI</categories><comments>Journal of Telecommunications,Volume 1, Issue 1, pp105-112, February
  2010</comments><journal-ref>A. Mohamedou and M. Othman, &quot;Analytical Evaluation of Unfairness
  Problem in Wireless LANs&quot;, Journal of Telecommunications, Volume 1, Issue 1,
  pp105-112, February 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The number of users using wireless Local Area Network is increasing
exponentially and their behavior is changing day after day. Nowadays, users of
wireless LAN are using huge amount of bandwidth because of the explosive growth
of some services and applications such as video sharing. This situation imposes
massive pressure on the wireless LAN performance especially in term of fairness
among wireless stations. The limited resources are not distributed fairly in
saturated conditions. The most important resource is the access point buffer
space. This importance is a result of access point being the bottleneck between
two different types of networks. These two types are wired network with
relatively huge bandwidth and wireless network with much smaller bandwidth.
Also the unfairness problem is keep getting worse because of the greedy nature
Transmission Control Protocol (TCP). In this paper, we conduct a comprehensive
study on wireless LAN dynamics and proposed a new mathematical model that
describes the performance and effects of its behavior. We validate the proposed
model by using the simulation technique. The proposed model was able to produce
very good approximation in most of the cases. It also gave us a great insight
into the effective variables in the wireless LAN behavior and what are the
dimensions of the unfairness problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4836</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4836</id><created>2010-02-25</created><authors><author><keyname>Ghosal</keyname><forenames>Prasun</forenames></author><author><keyname>Biswas</keyname><forenames>Malabika</forenames></author><author><keyname>Biswas</keyname><forenames>Manish</forenames></author></authors><title>Hardware Implementation of TDES Crypto System with On Chip Verification
  in FPGA</title><categories>cs.CR</categories><comments>Journal of Telecommunications,Volume 1, Issue 1, pp113-117, February
  2010</comments><journal-ref>P. Ghosal, M. Biswas and M. Biswas, &quot;Hardware Implementation of
  TDES Crypto System with On Chip Verification in FPGA&quot;, Journal of
  Telecommunications, Volume 1, Issue 1, pp113-117, February 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Security issues are playing dominant role in today's high speed communication
systems. A fast and compact FPGA based implementation of the Data Encryption
Standard (DES) and Triple DES algorithm is presented in this paper that is
widely used in cryptography for securing the Internet traffic in modern day
communication systems. The design of the digital cryptographic circuit was
implemented in a Vertex 5 series (XCVLX5110T) target device with the use of
VHDL as the hardware description language. In order to confirm the expected
behavior of these algorithms, the proposed design was extensively simulated,
synthesized for different FPGA devices both in Spartan and Virtex series from
Xilinx viz. Spartan 3, Spartan 3AN, Virtex 5, Virtex E device families. The
novelty and contribution of this work is in three folds: (i) Extensive
simulation and synthesis of the proposed design targeted for various FPGA
devices, (ii) Complete hardware implementation of encryption and decryption
algorithms onto Virtex 5 series device (XCVLX5110T) based FPGA boards and,
(iii) Generation of ICON and VIO core for the design and on chip verification
and analyzing using Chipscope Pro. The experimental as well as implementation
results compared to the implementations reported so far are quite encouraging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4837</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4837</id><created>2010-02-25</created><authors><author><keyname>Roy</keyname><forenames>A.</forenames></author><author><keyname>Ghosh</keyname><forenames>K.</forenames></author><author><keyname>Mondal</keyname><forenames>S.</forenames></author><author><keyname>Ray</keyname><forenames>B. N.</forenames></author></authors><title>Processing of Communication Signal Using Operational Transconductance
  Amplifier</title><categories>cs.OH</categories><comments>Journal of Telecommunications,Volume 1, Issue 1, pp118-122, February
  2010</comments><journal-ref>A. Roy, K. Ghosh, S. Mondal and B. N. Ray, &quot;Processing of
  Communication Signal Using Operational Transconductance Amplifier&quot;, Journal
  of Telecommunications, Volume 1, Issue 1, pp118-122, February 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a signal processing methodology of communication system
and realized that circuits using operational transconductance amplifier (OTA).
Two important classes of communication circuit, delta modulator and compander
have been designed using that procedure. In the first implementation coded
pulse modulation system is demonstrated which employ sampling, quantizing and
coding to convert analog waveforms to digital signals while the second gives
data compression and expansion in digital communication system. The proposed
compander circuit is realized with operational transconductance amplifier and
diode. Required power supply to operate the circuit is 3.5V. Performance of the
circuits realized with OTAs has been demonstrated through SPICE simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4838</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4838</id><created>2010-02-25</created><authors><author><keyname>Mamun</keyname><forenames>Md. Mainul Islam</forenames></author><author><keyname>Hasan-Al-Mahmud</keyname><forenames>Tarek</forenames></author><author><keyname>Kumar</keyname><forenames>Sumon</forenames></author><author><keyname>Islam</keyname><forenames>Md. Zahidul</forenames></author></authors><title>Analyzing the Low Power Wireless Links for Wireless Sensor Networks</title><categories>cs.NI</categories><comments>Journal of Telecommunications,Volume 1, Issue 1, pp123-127, February
  2010</comments><journal-ref>M. M. I. Mamun, T. Hasan-Al-Mahmud, S. Kumar and M. Z.Islam,
  &quot;Analyzing the Low Power Wireless Links for Wireless Sensor Networks&quot;,
  Journal of Telecommunications, Volume 1, Issue 1, pp123-127, February 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is now an increased understanding of the need for realistic link layer
models in the wireless sensor networks. In this paper, we have used
mathematical techniques from communication theory to model and analyze low
power wireless links. Our work provides theoretical models for the link layer
showing how Packet Reception Rate vary with Signal to Noise Ratio and distance
for different modulation schemes and a comparison between MICA2 and TinyNode in
terms of PRR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4862</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4862</id><created>2010-02-25</created><authors><author><keyname>Streeter</keyname><forenames>Matthew</forenames></author><author><keyname>McMahan</keyname><forenames>H. Brendan</forenames></author></authors><title>Less Regret via Online Conditioning</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze and evaluate an online gradient descent algorithm with adaptive
per-coordinate adjustment of learning rates. Our algorithm can be thought of as
an online version of batch gradient descent with a diagonal preconditioner.
This approach leads to regret bounds that are stronger than those of standard
online gradient descent for general online convex optimization problems.
Experimentally, we show that our algorithm is competitive with state-of-the-art
algorithms for large scale machine learning problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4885</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4885</id><created>2010-02-26</created><updated>2010-10-03</updated><authors><author><keyname>Seferoglu</keyname><forenames>Hulya</forenames></author><author><keyname>Markopoulou</keyname><forenames>Athina</forenames></author></authors><title>Network Coding-Aware Queue Management for TCP Flows over Coded Wireless
  Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are interested in unicast traffic over wireless networks that employ
constructive inter-session network coding, including single-hop and multi-hop
schemes. In this setting, TCP flows do not fully exploit the network coding
opportunities due to their bursty behavior and due to the fact that TCP is
agnostic to the underlying network coding. In order to improve the performance
of TCP flows over coded wireless networks, we take the following steps. First,
we formulate the problem as network utility maximization and we present a
distributed solution. Second, mimicking the structure of the optimal solution,
we propose a &quot;network-coding aware&quot; queue management scheme (NCAQM) at
intermediate nodes; we make no changes to TCP or to the MAC protocol (802.11).
We demonstrate, via simulation, that NCAQM significantly improves TCP
performance compared to TCP over baseline schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4907</identifier>
 <datestamp>2010-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4907</id><created>2010-02-25</created><authors><author><keyname>Gill</keyname><forenames>John T.</forenames><suffix>III</suffix></author><author><keyname>Wu</keyname><forenames>William</forenames></author></authors><title>Twenty Questions Games Always End With Yes</title><categories>cs.IT cs.DM math.IT</categories><comments>2 pages, 2 figures, submitted to IEEE Transactions on Information
  Theory</comments><acm-class>E.4; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Huffman coding is often presented as the optimal solution to Twenty
Questions. However, a caveat is that Twenty Questions games always end with a
reply of &quot;Yes,&quot; whereas Huffman codewords need not obey this constraint. We
bring resolution to this issue, and prove that the average number of questions
still lies between H(X) and H(X)+1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4908</identifier>
 <datestamp>2010-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4908</id><created>2010-02-25</created><updated>2010-07-07</updated><authors><author><keyname>McMahan</keyname><forenames>H. Brendan</forenames></author><author><keyname>Streeter</keyname><forenames>Matthew</forenames></author></authors><title>Adaptive Bound Optimization for Online Convex Optimization</title><categories>cs.LG</categories><comments>Updates to match final COLT version</comments><journal-ref>Proceedings of the 23rd Annual Conference on Learning Theory
  (COLT) 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new online convex optimization algorithm that adaptively
chooses its regularization function based on the loss functions observed so
far. This is in contrast to previous algorithms that use a fixed regularization
function such as L2-squared, and modify it only via a single time-dependent
parameter. Our algorithm's regret bounds are worst-case optimal, and for
certain realistic classes of loss functions they are much better than existing
bounds. These bounds are problem-dependent, which means they can exploit the
structure of the actual problem instance. Critically, however, our algorithm
does not need to know this structure in advance. Rather, we prove competitive
guarantees that show the algorithm provides a bound within a constant factor of
the best possible bound (of a certain functional form) in hindsight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4919</identifier>
 <datestamp>2010-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4919</id><created>2010-02-25</created><authors><author><keyname>Merelli</keyname><forenames>Emanuela</forenames><affiliation>University of Camerino, IT</affiliation></author><author><keyname>Quaglia</keyname><forenames>Paola</forenames><affiliation>CoSBi and University of Trento, IT</affiliation></author></authors><title>Proceedings Third Workshop From Biology To Concurrency and back</title><categories>cs.CE cs.PL</categories><journal-ref>EPTCS 19, 2010</journal-ref><doi>10.4204/EPTCS.19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the papers presented at the 3rd Workshop &quot;From Biology
To Concurrency and back&quot;, FBTC 2010, held in Paphos, Cyprus, on March 27, 2010,
as satellite event of the Joint European Conference on Theory and Practice of
Software, ETAPS 2010.
  The Workshop aimed at gathering together researchers with special interest at
the convergence of life and computer science, with particular focus on the
application of techniques and methods from concurrency. The papers contained in
this volume present works on modelling, analysis, and validation of biological
behaviours using concurrency-inspired methods and platforms, and bio-inspired
models and tools for describing distributed interactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4935</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4935</id><created>2010-02-26</created><updated>2013-05-24</updated><authors><author><keyname>Lim</keyname><forenames>Lek-Heng</forenames></author><author><keyname>Comon</keyname><forenames>Pierre</forenames></author></authors><title>Multiarray Signal Processing: Tensor decomposition meets compressed
  sensing</title><categories>math.NA cs.IT math.IT</categories><comments>10 pages, 1 figure</comments><msc-class>94A12, 15A69, 41A29, 41A50, 41A52</msc-class><doi>10.1016/j.crme.2010.06.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss how recently discovered techniques and tools from compressed
sensing can be used in tensor decompositions, with a view towards modeling
signals from multiple arrays of multiple sensors. We show that with appropriate
bounds on a measure of separation between radiating sources called coherence,
one could always guarantee the existence and uniqueness of a best rank-r
approximation of the tensor representing the signal. We also deduce a
computationally feasible variant of Kruskal's uniqueness condition, where the
coherence appears as a proxy for k-rank. Problems of sparsest recovery with an
infinite continuous dictionary, lowest-rank tensor representation, and blind
source separation are treated in a uniform fashion. The decomposition of the
measurement tensor leads to simultaneous localization and extraction of
radiating sources, in an entirely deterministic manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.4996</identifier>
 <datestamp>2010-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.4996</id><created>2010-02-26</created><authors><author><keyname>Kari</keyname><forenames>Lila</forenames></author><author><keyname>Seki</keyname><forenames>Shinnosuke</forenames></author><author><keyname>Xu</keyname><forenames>Zhi</forenames></author></authors><title>Triangular Self-Assembly</title><categories>cs.DM</categories><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the self-assembly system of triangular tiles instead of square
tiles, in particular right triangular tiles and equilateral triangular tiles.
We show that the triangular tile assembly system, either deterministic or
non-deterministic, has the same power to the square tile assembly system in
computation, which is Turing universal. By providing counter-examples, we show
that the triangular tile assembly system and the square tile assembly system
are not comparable in general. More precisely, there exists square tile
assembly system S such that no triangular tile assembly system is a division of
S and produces the same shape; there exists triangular tile assembly system T
such that no square tile assembly system produces the same compatible shape
with border glues. We also discuss the assembly of triangles by triangular
tiles and obtain results similar to the assembly of squares, that is to
assemble a triangular of size O(N^2), the minimal number of tiles required is
in O(log N/log log N).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.5026</identifier>
 <datestamp>2010-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.5026</id><created>2010-02-26</created><authors><author><keyname>Ekrem</keyname><forenames>Ersen</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Capacity Region of Gaussian MIMO Broadcast Channels with Common and
  Confidential Messages</title><categories>cs.IT cs.CR math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, February 2010.
  Conference version submitted to IEEE ISIT, January 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the two-user Gaussian multiple-input multiple-output (MIMO)
broadcast channel with common and confidential messages. In this channel, the
transmitter sends a common message to both users, and a confidential message to
each user which needs to be kept perfectly secret from the other user. We
obtain the entire capacity region of this channel. We also explore the
connections between the capacity region we obtain for the Gaussian MIMO
broadcast channel with common and confidential messages and the capacity region
of its non-confidential counterpart, i.e., the Gaussian MIMO broadcast channel
with common and private messages, which is not known completely.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1002.5034</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1002.5034</id><created>2010-02-26</created><updated>2010-07-16</updated><authors><author><keyname>Bach</keyname><forenames>Eric</forenames></author><author><keyname>Chawla</keyname><forenames>Shuchi</forenames></author><author><keyname>Umboh</keyname><forenames>Seeun</forenames></author></authors><title>Threshold rules for online sample selection</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following sample selection problem. We observe in an online
fashion a sequence of samples, each endowed by a quality. Our goal is to either
select or reject each sample, so as to maximize the aggregate quality of the
subsample selected so far. There is a natural trade-off here between the rate
of selection and the aggregate quality of the subsample. We show that for a
number of such problems extremely simple and oblivious &quot;threshold rules&quot; for
selection achieve optimal tradeoffs between rate of selection and aggregate
quality in a probabilistic sense. In some cases we show that the same threshold
rule is optimal for a large class of quality distributions and is thus
oblivious in a strong sense.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0024</identifier>
 <datestamp>2010-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0024</id><created>2010-02-26</created><authors><author><keyname>Dillon</keyname><forenames>Joshua V</forenames></author><author><keyname>Balasubramanian</keyname><forenames>Krishnakumar</forenames></author><author><keyname>Lebanon</keyname><forenames>Guy</forenames></author></authors><title>Asymptotic Analysis of Generative Semi-Supervised Learning</title><categories>cs.LG</categories><comments>12 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semisupervised learning has emerged as a popular framework for improving
modeling accuracy while controlling labeling cost. Based on an extension of
stochastic composite likelihood we quantify the asymptotic accuracy of
generative semi-supervised learning. In doing so, we complement
distribution-free analysis by providing an alternative framework to measure the
value associated with different labeling policies and resolve the fundamental
question of how much data to label and in what manner. We demonstrate our
approach with both simulation studies and real world experiments using naive
Bayes for text classification and MRFs and CRFs for structured prediction in
NLP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0034</identifier>
 <datestamp>2010-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0034</id><created>2010-02-26</created><authors><author><keyname>Chen</keyname><forenames>Yiling</forenames></author><author><keyname>Vaughan</keyname><forenames>Jennifer Wortman</forenames></author></authors><title>A New Understanding of Prediction Markets Via No-Regret Learning</title><categories>cs.AI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the striking mathematical connections that exist between market
scoring rules, cost function based prediction markets, and no-regret learning.
We show that any cost function based prediction market can be interpreted as an
algorithm for the commonly studied problem of learning from expert advice by
equating trades made in the market with losses observed by the learning
algorithm. If the loss of the market organizer is bounded, this bound can be
used to derive an O(sqrt(T)) regret bound for the corresponding learning
algorithm. We then show that the class of markets with convex cost functions
exactly corresponds to the class of Follow the Regularized Leader learning
algorithms, with the choice of a cost function in the market corresponding to
the choice of a regularizer in the learning problem. Finally, we show an
equivalence between market scoring rules and prediction markets with convex
cost functions. This implies that market scoring rules can also be interpreted
naturally as Follow the Regularized Leader algorithms, and may be of
independent interest. These connections provide new insight into how it is that
commonly studied markets, such as the Logarithmic Market Scoring Rule, can
aggregate opinions into accurate estimates of the likelihood of future events.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0054</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0054</id><created>2010-02-26</created><authors><author><keyname>Srivastava</keyname><forenames>Rahul</forenames></author><author><keyname>Koksal</keyname><forenames>Can Emre</forenames></author></authors><title>Energy Optimal Transmission Scheduling in Wireless Sensor Networks</title><categories>cs.NI</categories><comments>Accepted for publication in the IEEE Transactions on Wireless
  Communications</comments><doi>10.1109/TWC.2010.05.090275</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the main issues in the design of sensor networks is energy efficient
communication of time-critical data. Energy wastage can be caused by failed
packet transmission attempts at each node due to channel dynamics and
interference. Therefore transmission control techniques that are unaware of the
channel dynamics can lead to suboptimal channel use patterns. In this paper we
propose a transmission controller that utilizes different &quot;grades&quot; of channel
side information to schedule packet transmissions in an optimal way, while
meeting a deadline constraint for all packets waiting in the transmission
queue. The wireless channel is modeled as a finite-state Markov channel. We are
specifically interested in the case where the transmitter has low-grade channel
side information that can be obtained based solely on the ACK/NAK sequence for
the previous transmissions. Our scheduler is readily implementable and it is
based on the dynamic programming solution to the finite-horizon transmission
control problem. We also calculate the information theoretic capacity of the
finite state Markov channel with feedback containing different grades of
channel side information including that, obtained through the ACK/NAK sequence.
We illustrate that our scheduler achieves a given throughput at a power level
that is fairly close to the fundamental limit achievable over the channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0060</identifier>
 <datestamp>2010-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0060</id><created>2010-02-26</created><authors><author><keyname>Guo</keyname><forenames>Z. X.</forenames></author></authors><title>Comment on &quot;Fastest learning in small-world neural networks&quot;</title><categories>stat.ML cs.NE</categories><comments>8 pages, 5 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This comment reexamines Simard et al.'s work in [D. Simard, L. Nadeau, H.
Kroger, Phys. Lett. A 336 (2005) 8-15]. We found that Simard et al. calculated
mistakenly the local connectivity lengths Dlocal of networks. The right results
of Dlocal are presented and the supervised learning performance of feedforward
neural networks (FNNs) with different rewirings are re-investigated in this
comment. This comment discredits Simard et al's work by two conclusions: 1)
Rewiring connections of FNNs cannot generate networks with small-world
connectivity; 2) For different training sets, there do not exist networks with
a certain number of rewirings generating reduced learning errors than networks
with other numbers of rewiring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0064</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0064</id><created>2010-02-27</created><updated>2012-12-28</updated><authors><author><keyname>Liu</keyname><forenames>Shuiyin</forenames></author><author><keyname>Ling</keyname><forenames>Cong</forenames></author><author><keyname>Stehl&#xe9;</keyname><forenames>Damien</forenames></author></authors><title>Decoding by Sampling: A Randomized Lattice Algorithm for Bounded
  Distance Decoding</title><categories>cs.IT math.IT math.NT</categories><journal-ref>IEEE Trans. Inform. Theory, vol. 57, pp. 5933-5945, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite its reduced complexity, lattice reduction-aided decoding exhibits a
widening gap to maximum-likelihood (ML) performance as the dimension increases.
To improve its performance, this paper presents randomized lattice decoding
based on Klein's sampling technique, which is a randomized version of Babai's
nearest plane algorithm (i.e., successive interference cancelation (SIC)). To
find the closest lattice point, Klein's algorithm is used to sample some
lattice points and the closest among those samples is chosen. Lattice reduction
increases the probability of finding the closest lattice point, and only needs
to be run once during pre-processing. Further, the sampling can operate very
efficiently in parallel. The technical contribution of this paper is two-fold:
we analyze and optimize the decoding radius of sampling decoding resulting in
better error performance than Klein's original algorithm, and propose a very
efficient implementation of random rounding. Of particular interest is that a
fixed gain in the decoding radius compared to Babai's decoding can be achieved
at polynomial complexity. The proposed decoder is useful for moderate
dimensions where sphere decoding becomes computationally intensive, while
lattice reduction-aided decoding starts to suffer considerable loss. Simulation
results demonstrate near-ML performance is achieved by a moderate number of
samples, even if the dimension is as high as 32.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0079</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0079</id><created>2010-02-27</created><updated>2010-10-26</updated><authors><author><keyname>Kloft</keyname><forenames>Marius</forenames></author><author><keyname>Brefeld</keyname><forenames>Ulf</forenames></author><author><keyname>Sonnenburg</keyname><forenames>Soeren</forenames></author><author><keyname>Zien</keyname><forenames>Alexander</forenames></author></authors><title>Non-Sparse Regularization for Multiple Kernel Learning</title><categories>cs.LG stat.ML</categories><report-no>UCB/EECS-2010-21</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning linear combinations of multiple kernels is an appealing strategy
when the right choice of features is unknown. Previous approaches to multiple
kernel learning (MKL) promote sparse kernel combinations to support
interpretability and scalability. Unfortunately, this 1-norm MKL is rarely
observed to outperform trivial baselines in practical applications. To allow
for robust kernel mixtures, we generalize MKL to arbitrary norms. We devise new
insights on the connection between several existing MKL formulations and
develop two efficient interleaved optimization strategies for arbitrary norms,
like p-norms with p&gt;1. Empirically, we demonstrate that the interleaved
optimization strategies are much faster compared to the commonly used wrapper
approaches. A theoretical analysis and an experiment on controlled artificial
data experiment sheds light on the appropriateness of sparse, non-sparse and
$\ell_\infty$-norm MKL in various scenarios. Empirical applications of p-norm
MKL to three real-world problems from computational biology show that
non-sparse MKL achieves accuracies that go beyond the state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0090</identifier>
 <datestamp>2015-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0090</id><created>2010-02-27</created><updated>2011-03-29</updated><authors><author><keyname>Hsu</keyname><forenames>Fu-Te</forenames></author><author><keyname>Su</keyname><forenames>Hsuan-Jung</forenames></author></authors><title>Random Access Game in Fading Channels with Capture: Equilibria and
  Braess-like Paradoxes</title><categories>cs.GT cs.IT math.IT</categories><comments>30 pages, 5 figures</comments><journal-ref>IEEE Transactions on Signal Processing, Vol. 59, No. 3, pp.
  1158-1169, Mar. 2011</journal-ref><doi>10.1109/TSP.2010.2094194</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Nash equilibrium point of the transmission probabilities in a slotted
ALOHA system with selfish nodes is analyzed. The system consists of a finite
number of heterogeneous nodes, each trying to minimize its average transmission
probability (or power investment) selfishly while meeting its average
throughput demand over the shared wireless channel to a common base station
(BS). We use a game-theoretic approach to analyze the network under two
reception models: one is called power capture, the other is called signal to
interference plus noise ratio (SINR) capture. It is shown that, in some
situations, Braess-like paradoxes may occur. That is, the performance of the
system may become worse instead of better when channel state information (CSI)
is available at the selfish nodes. In particular, for homogeneous nodes, we
analytically present that Braess-like paradoxes occur in the power capture
model, and in the SINR capture model with the capture ratio larger than one and
the noise to signal ratio sufficiently small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0093</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0093</id><created>2010-02-27</created><updated>2011-03-29</updated><authors><author><keyname>Hsu</keyname><forenames>Chih-Ning</forenames></author><author><keyname>Su</keyname><forenames>Hsuan-Jung</forenames></author><author><keyname>Lin</keyname><forenames>Pin-Hsun</forenames></author></authors><title>Joint Subcarrier Pairing and Power Allocation for OFDM Transmission with
  Decode-and-Forward Relaying</title><categories>cs.IT math.IT</categories><comments>33 pages, 11 figures</comments><journal-ref>IEEE Transactions on Signal Processing, Vol. 59, No. 1, pp.
  399-414, Jan. 2011</journal-ref><doi>10.1109/TSP.2010.2081982</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a point-to-point Orthogonal Frequency Division Multiplexing
(OFDM) system with a decode-and-forward (DF) relay is considered. The
transmission consists of two hops. The source transmits in the first hop, and
the relay transmits in the second hop. Each hop occupies one time slot. The
relay is half-duplex, and capable of decoding the message on a particular
subcarrier in one time slot, and re-encoding and forwarding it on a different
subcarrier in the next time slot. Thus each message is transmitted on a pair of
subcarriers in two hops. It is assumed that the destination is capable of
combining the signals from the source and the relay pertaining to the same
message. The goal is to maximize the weighted sum rate of the system by jointly
optimizing subcarrier pairing and power allocation on each subcarrier in each
hop. The weighting of the rates is to take into account the fact that different
subcarriers may carry signals for different services. Both total and individual
power constraints for the source and the relay are investigated. For the
situations where the relay does not transmit on some subcarriers because doing
so does not improve the weighted sum rate, we further allow the source to
transmit new messages on these idle subcarriers. To the best of our knowledge,
such a joint optimization inclusive of the destination combining has not been
discussed in the literature. The problem is first formulated as a mixed integer
programming problem. It is then transformed to a convex optimization problem by
continuous relaxation, and solved in the dual domain. Based on the optimization
results, algorithms to achieve feasible solutions are also proposed. Simulation
results show that the proposed algorithms almost achieve the optimal weighted
sum rate, and outperform the existing methods in various channel conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0095</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0095</id><created>2010-02-27</created><updated>2011-03-29</updated><authors><author><keyname>Yang</keyname><forenames>Yu-Han</forenames></author><author><keyname>Lin</keyname><forenames>Shih-Chun</forenames></author><author><keyname>Su</keyname><forenames>Hsuan-Jung</forenames></author></authors><title>Multiuser MIMO Downlink Beamforming Design Based on Group Maximum SINR
  Filtering</title><categories>cs.IT math.IT</categories><comments>29 pages, 7 figures</comments><journal-ref>IEEE Transactions on Signal Processing, Vol. 59, No. 4, pp.
  1746-1758, Apr. 2011</journal-ref><doi>10.1109/TSP.2010.2099221</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we aim to solve the multiuser multi-input multi-output (MIMO)
downlink beamforming problem where one multi-antenna base station broadcasts
data to many users. Each user is assigned multiple data streams and has
multiple antennas at its receiver. Efficient solutions to the joint
transmit-receive beamforming and power allocation problem based on iterative
methods are proposed. We adopt the group maximum
signal-to-interference-plus-noise-ratio (SINR) filter bank (GSINR-FB) as our
beamformer which exploits receiver diversity through cooperation between the
data streams of a user. The data streams for each user are subject to an
average SINR constraint, which has many important applications in wireless
communication systems and serves as a good metric to measure the quality of
service (QoS). The GSINR-FB also optimizes the average SINR of its output.
Based on the GSINR-FB beamformer, we find an SINR balancing structure for
optimal power allocation which simplifies the complicated power allocation
problem to a linear one. Simulation results verify the superiority of the
proposed algorithms over previous works with approximately the same complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0107</identifier>
 <datestamp>2010-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0107</id><created>2010-02-27</created><authors><author><keyname>Churchill</keyname><forenames>Martin</forenames></author><author><keyname>Laird</keyname><forenames>James</forenames></author><author><keyname>McCusker</keyname><forenames>Guy</forenames></author></authors><title>A Concrete Representation of Observational Equivalence for PCF</title><categories>cs.LO</categories><comments>A result on observational equivalence for PCF and innocent
  strategies, as presented at the Games for Logic and Programming Languages
  (GaLoP) workshop in York, March 2009</comments><acm-class>F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The full abstraction result for PCF using game semantics requires one to
identify all innocent strategies that are innocently indistinguishable. This
involves a quantification over all innocent tests, cf. quantification over all
innocent contexts. Here we present a representation of innocent strategies that
equates innocently indistinguishable ones, yielding a representation of PCF
terms that equates precisely those terms that are observational equivalent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0118</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0118</id><created>2010-02-27</created><authors><author><keyname>Br&#xe1;zdil</keyname><forenames>Tom&#xe1;&#x161;</forenames></author><author><keyname>Bro&#x17e;ek</keyname><forenames>V&#xe1;clav</forenames></author><author><keyname>Ku&#x10d;era</keyname><forenames>Anton&#xed;n</forenames></author><author><keyname>Obdr&#x17e;&#xe1;lek</keyname><forenames>Jan</forenames></author></authors><title>Qualitative Reachability in Stochastic BPA Games</title><categories>cs.GT</categories><comments>Submitted to Information and Computation. 48 pages, 3 figures</comments><acm-class>G.3; F.1.1; F.3.1</acm-class><doi>10.1016/j.ic.2011.02.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a class of infinite-state stochastic games generated by stateless
pushdown automata (or, equivalently, 1-exit recursive state machines), where
the winning objective is specified by a regular set of target configurations
and a qualitative probability constraint `&gt;0' or `=1'. The goal of one player
is to maximize the probability of reaching the target set so that the
constraint is satisfied, while the other player aims at the opposite. We show
that the winner in such games can be determined in PTIME for the `&gt;0'
constraint, and both in NP and coNP for the `=1' constraint. Further, we prove
that the winning regions for both players are regular, and we design algorithms
which compute the associated finite-state automata. Finally, we show that
winning strategies can be synthesized effectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0120</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0120</id><created>2010-02-27</created><updated>2010-06-14</updated><authors><author><keyname>Strehl</keyname><forenames>Alex</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author><author><keyname>Kakade</keyname><forenames>Sham</forenames></author><author><keyname>Li</keyname><forenames>Lihong</forenames></author></authors><title>Learning from Logged Implicit Exploration Data</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a sound and consistent foundation for the use of \emph{nonrandom}
exploration data in &quot;contextual bandit&quot; or &quot;partially labeled&quot; settings where
only the value of a chosen action is learned.
  The primary challenge in a variety of settings is that the exploration
policy, in which &quot;offline&quot; data is logged, is not explicitly known. Prior
solutions here require either control of the actions during the learning
process, recorded random exploration, or actions chosen obliviously in a
repeated manner. The techniques reported here lift these restrictions, allowing
the learning of a policy for choosing actions given features from historical
data where no randomization occurred or was logged.
  We empirically verify our solution on two reasonably sized sets of real-world
data obtained from Yahoo!.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0139</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0139</id><created>2010-02-27</created><authors><author><keyname>Bose</keyname><forenames>Prosenjit</forenames><affiliation>School of Computer Science, Carleton University</affiliation></author><author><keyname>Dou&#xef;eb</keyname><forenames>Karim</forenames><affiliation>School of Computer Science, Carleton University</affiliation></author><author><keyname>Dujmovic</keyname><forenames>Vida</forenames><affiliation>School of Computer Science, Carleton University</affiliation></author><author><keyname>Fagerberg</keyname><forenames>Rolf</forenames><affiliation>Department of Mathematics and Computer Science, University of Southern Denmark</affiliation></author></authors><title>An O(loglog n)-Competitive Binary Search Tree with Optimal Worst-Case
  Access Times</title><categories>cs.DS</categories><comments>IMADA-preprint-cs</comments><doi>10.1007/978-3-642-13731-0_5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the zipper tree, an $O(\log \log n)$-competitive online binary
search tree that performs each access in $O(\log n)$ worst-case time. This
shows that for binary search trees, optimal worst-case access time and
near-optimal amortized access time can be guaranteed simultaneously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0146</identifier>
 <datestamp>2012-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0146</id><created>2010-02-27</created><updated>2012-03-01</updated><authors><author><keyname>Li</keyname><forenames>Lihong</forenames></author><author><keyname>Chu</keyname><forenames>Wei</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author><author><keyname>Schapire</keyname><forenames>Robert E.</forenames></author></authors><title>A Contextual-Bandit Approach to Personalized News Article Recommendation</title><categories>cs.LG cs.AI cs.IR</categories><comments>10 pages, 5 figures</comments><acm-class>H.3.5; I.2.6</acm-class><journal-ref>Presented at the Nineteenth International Conference on World Wide
  Web (WWW 2010), Raleigh, NC, USA, 2010</journal-ref><doi>10.1145/1772690.1772758</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Personalized web services strive to adapt their services (advertisements,
news articles, etc) to individual users by making use of both content and user
information. Despite a few recent advances, this problem remains challenging
for at least two reasons. First, web service is featured with dynamically
changing pools of content, rendering traditional collaborative filtering
methods inapplicable. Second, the scale of most web services of practical
interest calls for solutions that are both fast in learning and computation.
  In this work, we model personalized recommendation of news articles as a
contextual bandit problem, a principled approach in which a learning algorithm
sequentially selects articles to serve users based on contextual information
about the users and articles, while simultaneously adapting its
article-selection strategy based on user-click feedback to maximize total user
clicks.
  The contributions of this work are three-fold. First, we propose a new,
general contextual bandit algorithm that is computationally efficient and well
motivated from learning theory. Second, we argue that any bandit algorithm can
be reliably evaluated offline using previously recorded random traffic.
Finally, using this offline evaluation method, we successfully applied our new
algorithm to a Yahoo! Front Page Today Module dataset containing over 33
million events. Results showed a 12.5% click lift compared to a standard
context-free bandit algorithm, and the advantage becomes even greater when data
gets more scarce.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0150</identifier>
 <datestamp>2010-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0150</id><created>2010-02-28</created><authors><author><keyname>Cheung</keyname><forenames>Y. K.</forenames></author><author><keyname>Flajolet</keyname><forenames>Philippe</forenames></author><author><keyname>Golin</keyname><forenames>Mordecai</forenames></author><author><keyname>Lee</keyname><forenames>C. Y. James</forenames></author></authors><title>Multidimensional Divide-and-Conquer and Weighted Digital Sums</title><categories>cs.DS math.CA</categories><comments>44 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies three types of functions arising separately in the
analysis of algorithms that we analyze exactly using similar Mellin transform
techniques. The first is the solution to a Multidimensional Divide-and-Conquer
(MDC) recurrence that arises when solving problems on points in $d$-dimensional
space. The second involves weighted digital sums. Write $n$ in its binary
representation $n=(b_i b_{i-1}... b_1 b_0)_2$ and set $S_M(n) = \sum_{t=0}^i
t^{\bar{M}} b_t 2^t$. We analyze the average $TS_M(n) = \frac{1}{n}\sum_{j&lt;n}
S_M(j)$. The third is a different variant of weighted digital sums. Write $n$
as $n=2^{i_1} + 2^{i_2} + ... + 2^{i_k}$ with $i_1 &gt; i_2 &gt; ... &gt; i_k\geq 0$ and
set $W_M(n) = \sum_{t=1}^k t^M 2^{i_t}$. We analyze the average $TW_M(n) =
\frac{1}{n}\sum_{j&lt;n} W_M(j)$.
  We show that both the MDC functions and $TS_M(n)$ (with $d=M+1$) have
solutions of the form $\lambda_d n \lg^{d-1}n + \sum_{m=0}^{d-2}(n\lg^m
n)A_{d,m}(\lg n) + c_d,$ where $\lambda_d,c_d$ are constants and $A_{d,m}(u)$'s
are periodic functions with period one (given by absolutely convergent Fourier
series). We also show that $TW_M(n)$ has a solution of the form $n G_M(\lg n) +
d_M \lg^M n + \sum_{d=0}^{M-1}(\lg^d n)G_{M,d}(\lg n),$ where $d_M$ is a
constant, $G_M(u)$ and $G_{M,d}(u)$'s are again periodic functions with period
one (given by absolutely convergent Fourier series).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0167</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0167</id><created>2010-02-28</created><updated>2010-09-02</updated><authors><author><keyname>Bansal</keyname><forenames>Nikhil</forenames></author><author><keyname>Gupta</keyname><forenames>Anupam</forenames></author><author><keyname>Nagarajan</keyname><forenames>Viswanath</forenames></author><author><keyname>Rudra</keyname><forenames>Atri</forenames></author></authors><title>When LP is the Cure for Your Matching Woes: Approximating Stochastic
  Matchings</title><categories>cs.DS cs.DM</categories><comments>This paper has been withdrawn due to new merged paper
  arXiv:1008.5356v1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This results in this paper have been merged with the result in
arXiv:1002.3763v1
  The authors would like to withdraw this version.
  Please see arXiv:1008.5356v1 for the merged version.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0190</identifier>
 <datestamp>2010-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0190</id><created>2010-02-28</created><authors><author><keyname>Sukhov</keyname><forenames>A. M.</forenames></author><author><keyname>Kuznetsova</keyname><forenames>N. Yu.</forenames></author><author><keyname>Pervitsky</keyname><forenames>A. K.</forenames></author><author><keyname>Galtsev</keyname><forenames>A. A.</forenames></author></authors><title>Generating Function For Network Delay</title><categories>cs.NI</categories><comments>5 pages, 4 Tables, 5 Figures</comments><acm-class>C.2.5</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper correspondence between experimental data for packet delay and
two theoretical types of distribution is investigated. Statistical tests have
shown that only exponential distribution can be used for the description of
packet delays in global network. Precision experimental data to within
microseconds are gathered by means of the RIPE Test Box. Statistical
verification of hypothesis has shown that distribution parameters remain
constants during 500 second intervals at least. In paper cumulative
distribution function and generating function for packet delay in network are
in an explicit form written down, the algorithm of search of parameters of
distribution is resulted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0205</identifier>
 <datestamp>2010-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0205</id><created>2010-02-28</created><authors><author><keyname>Singh</keyname><forenames>Aarti</forenames></author><author><keyname>Nowak</keyname><forenames>Robert D.</forenames></author><author><keyname>Calderbank</keyname><forenames>Robert</forenames></author></authors><title>Detecting Weak but Hierarchically-Structured Patterns in Networks</title><categories>cs.IT cs.LG math.IT math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to detect weak distributed activation patterns in networks is
critical to several applications, such as identifying the onset of anomalous
activity or incipient congestion in the Internet, or faint traces of a
biochemical spread by a sensor network. This is a challenging problem since
weak distributed patterns can be invisible in per node statistics as well as a
global network-wide aggregate. Most prior work considers situations in which
the activation/non-activation of each node is statistically independent, but
this is unrealistic in many problems. In this paper, we consider structured
patterns arising from statistical dependencies in the activation process. Our
contributions are three-fold. First, we propose a sparsifying transform that
succinctly represents structured activation patterns that conform to a
hierarchical dependency graph. Second, we establish that the proposed transform
facilitates detection of very weak activation patterns that cannot be detected
with existing methods. Third, we show that the structure of the hierarchical
dependency graph governing the activation process, and hence the network
transform, can be learnt from very few (logarithmic in network size)
independent snapshots of network activity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0206</identifier>
 <datestamp>2010-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0206</id><created>2010-02-28</created><authors><author><keyname>Wegmann</keyname><forenames>Steven</forenames></author><author><keyname>Gillick</keyname><forenames>Larry</forenames></author></authors><title>Why has (reasonably accurate) Automatic Speech Recognition been so hard
  to achieve?</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hidden Markov models (HMMs) have been successfully applied to automatic
speech recognition for more than 35 years in spite of the fact that a key HMM
assumption -- the statistical independence of frames -- is obviously violated
by speech data. In fact, this data/model mismatch has inspired many attempts to
modify or replace HMMs with alternative models that are better able to take
into account the statistical dependence of frames. However it is fair to say
that in 2010 the HMM is the consensus model of choice for speech recognition
and that HMMs are at the heart of both commercially available products and
contemporary research systems. In this paper we present a preliminary
exploration aimed at understanding how speech data depart from HMMs and what
effect this departure has on the accuracy of HMM-based speech recognition. Our
analysis uses standard diagnostic tools from the field of statistics --
hypothesis testing, simulation and resampling -- which are rarely used in the
field of speech recognition. Our main result, obtained by novel manipulations
of real and resampled data, demonstrates that real data have statistical
dependency and that this dependency is responsible for significant numbers of
recognition errors. We also demonstrate, using simulation and resampling, that
if we `remove' the statistical dependency from data, then the resulting
recognition error rates become negligible. Taken together, these results
suggest that a better understanding of the structure of the statistical
dependency in speech data is a crucial first step towards improving HMM-based
speech recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0219</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0219</id><created>2010-02-28</created><authors><author><keyname>Malioutov</keyname><forenames>Dmitry</forenames></author><author><keyname>Sanghavi</keyname><forenames>Sujay</forenames></author><author><keyname>Willsky</keyname><forenames>Alan</forenames></author></authors><title>Sequential Compressed Sensing</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE transactions on Special Topics in Signal Processing</comments><doi>10.1109/JSTSP.2009.2038211</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing allows perfect recovery of sparse signals (or signals
sparse in some basis) using only a small number of random measurements.
Existing results in compressed sensing literature have focused on
characterizing the achievable performance by bounding the number of samples
required for a given level of signal sparsity. However, using these bounds to
minimize the number of samples requires a-priori knowledge of the sparsity of
the unknown signal, or the decay structure for near-sparse signals.
Furthermore, there are some popular recovery methods for which no such bounds
are known.
  In this paper, we investigate an alternative scenario where observations are
available in sequence. For any recovery method, this means that there is now a
sequence of candidate reconstructions. We propose a method to estimate the
reconstruction error directly from the samples themselves, for every candidate
in this sequence. This estimate is universal in the sense that it is based only
on the measurement ensemble, and not on the recovery method or any assumed
level of sparsity of the unknown signal. With these estimates, one can now stop
observations as soon as there is reasonable certainty of either exact or
sufficiently accurate reconstruction. They also provide a way to obtain
&quot;run-time&quot; guarantees for recovery methods that otherwise lack a-priori
performance bounds.
  We investigate both continuous (e.g. Gaussian) and discrete (e.g. Bernoulli)
random measurement ensembles, both for exactly sparse and general near-sparse
signals, and with both noisy and noiseless measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0221</identifier>
 <datestamp>2010-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0221</id><created>2010-02-28</created><authors><author><keyname>Formato</keyname><forenames>Richard A.</forenames></author></authors><title>Central Force Optimization Applied to the PBM Suite of Antenna
  Benchmarks</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Central Force Optimization (CFO) is a new nature-inspired deterministic
multi-dimensional search and optimization metaheuristic based on the metaphor
of gravitational kinematics. CFO is applied to the PBM antenna benchmark suite
and the results compared to published performance data for other optimization
algorithms. CFO acquits itself quite well. CFO's gradient-like nature is
discussed, and it is speculated that a &quot;generalized hyperspace derivative&quot;
might be defined for optimization problems as a new mathematical construct
based on the Unit Step function. What appears to be a sufficient but not
necessary condition for local trapping, oscillation in the probe average
distance curve, is discussed in the context of the theory of gravitational
&quot;resonant returns&quot; that gives rise to strikingly similar oscillatory curves. It
is suggested that the theory may be applicable to CFO as an aid to
understanding trapping and to developing effective mitigation techniques,
possibly based on a concept of &quot;energy&quot; in CFO space. It also is suggested that
CFO may be re-formulated as a &quot;total energy&quot; model by analogizing conservation
of energy for orbiting masses in physical space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0225</identifier>
 <datestamp>2010-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0225</id><created>2010-02-28</created><updated>2010-03-09</updated><authors><author><keyname>Levy</keyname><forenames>Uri</forenames></author></authors><title>The Magnetic Tower of Hanoi</title><categories>math.CO cs.DM</categories><comments>41 pages, 14 paper figures, 4 appendix figures, 10 tables</comments><msc-class>05D99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work I study a modified Tower of Hanoi puzzle, which I term Magnetic
Tower of Hanoi (MToH). The original Tower of Hanoi puzzle, invented by the
French mathematician Edouard Lucas in 1883, spans &quot;base 2&quot;. That is - the
number of moves of disk number k is 2^(k-1), and the total number of moves
required to solve the puzzle with N disks is 2^N - 1. In the MToH puzzle, each
disk has two distinct-color sides, and disks must be flipped and placed so that
no sides of the same color meet. I show here that the MToH puzzle spans &quot;base
3&quot; - the number of moves required to solve an N+1 disk puzzle is essentially
three times larger than he number of moves required to solve an N disk puzzle.
The MToH comes in 3 flavors which differ in the rules for placing a disk on a
free post and therefore differ in the possible evolutions of the Tower states
towards a puzzle solution. I analyze here algorithms for minimizing the number
of steps required to solve the MToH puzzle in its different versions. Thus,
while the colorful Magnetic Tower of Hanoi puzzle is rather challenging, its
inherent freedom nurtures mathematics with remarkable elegance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0242</identifier>
 <datestamp>2010-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0242</id><created>2010-02-28</created><authors><author><keyname>Lee</keyname><forenames>Chung-Pi</forenames></author><author><keyname>Su</keyname><forenames>Hsuan-Jung</forenames></author></authors><title>Peak to Average Power Ratio Reduction for Space-Time Codes That Achieve
  Diversity-Multiplexing Gain Tradeoff</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Zheng and Tse have shown that over a quasi-static channel, there exists a
fundamental tradeoff, known as the diversity-multiplexing gain (D-MG) tradeoff.
In a realistic system, to avoid inefficiently operating the power amplifier,
one should consider the situation where constraints are imposed on the peak to
average power ratio (PAPR) of the transmitted signal. In this paper, the D-MG
tradeoff of multi-antenna systems with PAPR constraints is analyzed. For
Rayleigh fading channels, we show that the D-MG tradeoff remains unchanged with
any PAPR constraints larger than one. This result implies that, instead of
designing codes on a case-by-case basis, as done by most existing works, there
possibly exist general methodologies for designing space-time codes with low
PAPR that achieve the optimal D-MG tradeoff. As an example of such
methodologies, we propose a PAPR reduction method based on constellation
shaping that can be applied to existing optimal space-time codes without
affecting their optimality in the D-MG tradeoff. Unlike most PAPR reduction
methods, the proposed method does not introduce redundancy or require side
information being transmitted to the decoder. Two realizations of the proposed
method are considered. The first is similar to the method proposed by Kwok
except that we employ the Hermite Normal Form (HNF) decomposition instead of
the Smith Normal Form (SNF) to reduce complexity. The second takes the idea of
integer reversible mapping which avoids the difficulty in matrix decomposition
when the number of antennas becomes large. Sphere decoding is performed to
verify that the proposed PAPR reduction method does not affect the performance
of optimal space-time codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0248</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0248</id><created>2010-02-28</created><updated>2010-10-06</updated><authors><author><keyname>Giacomelli</keyname><forenames>Riccardo</forenames></author><author><keyname>Ganti</keyname><forenames>Radha Krishna</forenames></author><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author></authors><title>Outage Probability of General Ad Hoc Networks in the High-Reliability
  Regime</title><categories>cs.IT cs.NI math.IT math.ST stat.TH</categories><comments>Submitted to IEEE Transactions on Networking (Revision 2)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Outage probabilities in wireless networks depend on various factors: the node
distribution, the MAC scheme, and the models for path loss, fading and
transmission success. In prior work on outage characterization for networks
with randomly placed nodes, most of the emphasis was put on networks whose
nodes are Poisson distributed and where ALOHA is used as the MAC protocol. In
this paper we provide a general framework for the analysis of outage
probabilities in the high-reliability regime. The outage probability
characterization is based on two parameters: the intrinsic spatial contention
$\gamma$ of the network, introduced in [1], and the coordination level achieved
by the MAC as measured by the interference scaling exponent $\kappa$ introduced
in this paper. We study outage probabilities under the signal-to-interference
ratio (SIR) model, Rayleigh fading, and power-law path loss, and explain how
the two parameters depend on the network model. The main result is that the
outage probability approaches $\gamma\eta^{\kappa}$ as the density of
interferers $\eta$ goes to zero, and that $\kappa$ assumes values in the range
$1\leq \kappa\leq \alpha/2$ for all practical MAC protocols, where $\alpha$ is
the path loss exponent. This asymptotic expression is valid for all
motion-invariant point processes. We suggest a novel and complete taxonomy of
MAC protocols based mainly on the value of $\kappa$. Finally, our findings
suggest a conjecture that tightly bounds the outage probability for all
interferer densities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0319</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0319</id><created>2010-03-01</created><authors><author><keyname>Gu</keyname><forenames>Feng</forenames></author><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Further Exploration of the Dendritic Cell Algorithm: Antigen Multiplier
  and Time Windows</title><categories>cs.AI cs.CR cs.NE</categories><comments>12 pages, 3 figures, 3 tables, 7th International Conference on
  Artificial Immune Systems (ICARIS 2008), Phuket, Thailand</comments><journal-ref>Proceedings of the 7th International Conference on Artificial
  Immune Systems (ICARIS 2008), Phuket, Thailand, 2008, 142-153</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As an immune-inspired algorithm, the Dendritic Cell Algorithm (DCA), produces
promising performances in the field of anomaly detection. This paper presents
the application of the DCA to a standard data set, the KDD 99 data set. The
results of different implementation versions of the DXA, including the antigen
multiplier and moving time windows are reported. The real-valued Negative
Selection Algorithm (NSA) using constant-sized detectors and the C4.5 decision
tree algorithm are used, to conduct a baseline comparison. The results suggest
that the DCA is applicable to KDD 99 data set, and the antigen multiplier and
moving time windows have the same effect on the DCA for this particular data
set. The real-valued NSA with constant-sized detectors is not applicable to the
data set, and the C4.5 decision tree algorithm provides a benchmark of the
classification performance for this data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0332</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0332</id><created>2010-03-01</created><updated>2011-04-11</updated><authors><author><keyname>Hoydis</keyname><forenames>Jakob</forenames></author><author><keyname>Kobayashi</keyname><forenames>Mari</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>On the Optimal Number of Cooperative Base Stations in Network MIMO
  Systems</title><categories>cs.IT math.IT</categories><comments>The paper has undergone a major revision during which the title was
  changed to: &quot;Optimal Channel Training in Uplink Network MIMO Systems&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a multi-cell, frequency-selective fading, uplink channel (network
MIMO) where K user terminals (UTs) communicate simultaneously with B
cooperative base stations (BSs). Although the potential benefit of multi-cell
cooperation grows with B, the overhead related to the acquisition of channel
state information (CSI) will rapidly dominate the uplink resource. Thus, there
exists a non-trivial tradeoff between the performance gains of network MIMO and
the related overhead in channel estimation for a finite coherence time. Using a
close approximation of the net ergodic achievable rate based on recent results
from random matrix theory, we study this tradeoff by taking some realistic
aspects into account such as unreliable backhaul links and different path
losses between the UTs and BSs. We determine the optimal training length, the
optimal number of cooperative BSs and the optimal number of sub-carriers to be
used for an extended version of the circular Wyner model where each UT can
communicate with B BSs. Our results provide some insight into practical
limitations as well as realistic dimensions of network MIMO systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0337</identifier>
 <datestamp>2010-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0337</id><created>2010-03-01</created><authors><author><keyname>Kutuzov</keyname><forenames>Andrey</forenames></author></authors><title>Change of word types to word tokens ratio in the course of translation
  (based on Russian translations of K. Vonnegut novels)</title><categories>cs.CL</categories><comments>11 pages, 5 figures, to be reported at International Computational
  Linguistic Conference &quot;Dialog-21&quot;-2010 (http://dialog-21.ru)</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The article provides lexical statistical analysis of K. Vonnegut's two novels
and their Russian translations. It is found out that there happen some changes
between the speed of word types and word tokens ratio change in the source and
target texts. The author hypothesizes that these changes are typical for
English-Russian translations, and moreover, they represent an example of
Baker's translation feature of levelling out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0339</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0339</id><created>2010-03-01</created><updated>2010-03-09</updated><authors><author><keyname>Twycross</keyname><forenames>Jamie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>libtissue - implementing innate immunity</title><categories>cs.AI cs.NE</categories><comments>8 pages, 4 tables, 5 figures, Workshop on Artificial Immune Systems
  and Immune System Modelling (AISB06), Bristol, UK</comments><journal-ref>499-506, Proceedings of the IEEE Congress on Evolutionary
  Computation (CEC2006), Vancouver, Canada, 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a previous paper the authors argued the case for incorporating ideas from
innate immunity into articficial immune systems (AISs) and presented an outline
for a conceptual framework for such systems. A number of key general properties
observed in the biological innate and adaptive immune systems were hughlighted,
and how such properties might be instantiated in artificial systems was
discussed in detail. The next logical step is to take these ideas and build a
software system with which AISs with these properties can be implemented and
experimentally evaluated. This paper reports on the results of that step - the
libtissue system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0358</identifier>
 <datestamp>2012-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0358</id><created>2010-03-01</created><authors><author><keyname>Ciresan</keyname><forenames>Dan Claudiu</forenames></author><author><keyname>Meier</keyname><forenames>Ueli</forenames></author><author><keyname>Gambardella</keyname><forenames>Luca Maria</forenames></author><author><keyname>Schmidhuber</keyname><forenames>Juergen</forenames></author></authors><title>Deep Big Simple Neural Nets Excel on Handwritten Digit Recognition</title><categories>cs.NE cs.AI</categories><comments>14 pages, 2 figures, 4 listings</comments><journal-ref>Neural Computation, Volume 22, Number 12, December 2010</journal-ref><doi>10.1162/NECO_a_00052</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Good old on-line back-propagation for plain multi-layer perceptrons yields a
very low 0.35% error rate on the famous MNIST handwritten digits benchmark. All
we need to achieve this best result so far are many hidden layers, many neurons
per layer, numerous deformed training images, and graphics cards to greatly
speed up learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0367</identifier>
 <datestamp>2010-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0367</id><created>2010-03-01</created><authors><author><keyname>Jiang</keyname><forenames>Yong</forenames></author><author><keyname>Xia</keyname><forenames>Shu-Tao</forenames></author><author><keyname>Fu</keyname><forenames>Fang-Wei</forenames></author></authors><title>Stopping Set Distributions of Some Linear Codes</title><categories>cs.IT math.IT</categories><comments>33 pages, submitted to IEEE Trans. Inform. Theory, Feb. 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stopping sets and stopping set distribution of an low-density parity-check
code are used to determine the performance of this code under iterative
decoding over a binary erasure channel (BEC). Let $C$ be a binary $[n,k]$
linear code with parity-check matrix $H$, where the rows of $H$ may be
dependent. A stopping set $S$ of $C$ with parity-check matrix $H$ is a subset
of column indices of $H$ such that the restriction of $H$ to $S$ does not
contain a row of weight one. The stopping set distribution $\{T_i(H)\}_{i=0}^n$
enumerates the number of stopping sets with size $i$ of $C$ with parity-check
matrix $H$. Note that stopping sets and stopping set distribution are related
to the parity-check matrix $H$ of $C$. Let $H^{*}$ be the parity-check matrix
of $C$ which is formed by all the non-zero codewords of its dual code
$C^{\perp}$. A parity-check matrix $H$ is called BEC-optimal if
$T_i(H)=T_i(H^*), i=0,1,..., n$ and $H$ has the smallest number of rows. On the
BEC, iterative decoder of $C$ with BEC-optimal parity-check matrix is an
optimal decoder with much lower decoding complexity than the exhaustive
decoder. In this paper, we study stopping sets, stopping set distributions and
BEC-optimal parity-check matrices of binary linear codes. Using finite geometry
in combinatorics, we obtain BEC-optimal parity-check matrices and then
determine the stopping set distributions for the Simplex codes, the Hamming
codes, the first order Reed-Muller codes and the extended Hamming codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0381</identifier>
 <datestamp>2010-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0381</id><created>2010-03-01</created><authors><author><keyname>Sirigineedi</keyname><forenames>Gopinadh</forenames></author><author><keyname>Tsourdos</keyname><forenames>Antonios</forenames></author><author><keyname>White</keyname><forenames>Brian A.</forenames></author><author><keyname>Zbikowski</keyname><forenames>Rafal</forenames></author></authors><title>Modelling and Verification of Multiple UAV Mission Using SMV</title><categories>cs.LO cs.MA cs.RO</categories><journal-ref>EPTCS 20, 2010, pp. 22-33</journal-ref><doi>10.4204/EPTCS.20.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Model checking has been used to verify the correctness of digital circuits,
security protocols, communication protocols, as they can be modelled by means
of finite state transition model. However, modelling the behaviour of hybrid
systems like UAVs in a Kripke model is challenging. This work is aimed at
capturing the behaviour of an UAV performing cooperative search mission into a
Kripke model, so as to verify it against the temporal properties expressed in
Computation Tree Logic (CTL). SMV model checker is used for the purpose of
model checking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0396</identifier>
 <datestamp>2010-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0396</id><created>2010-03-01</created><authors><author><keyname>Vassev</keyname><forenames>Emil</forenames></author><author><keyname>Hinchey</keyname><forenames>Mike</forenames></author></authors><title>Developing Experimental Models for NASA Missions with ASSL</title><categories>cs.SE cs.RO</categories><comments>7 pages, 4 figures, Workshop on Formal Methods for Aerospace (FMA'09)</comments><journal-ref>E. Vassev and M. Hinchey, Developing Experimental Models for NASA
  Missions with ASSL, M. Bujorianu and M. Fisher (Eds.): Workshop on Formal
  Methods for Aerospace (FMA'09), EPTCS 20, 2010, pp. 88--94</journal-ref><doi>10.4204/EPTCS.20.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  NASA's new age of space exploration augurs great promise for deep space
exploration missions whereby spacecraft should be independent, autonomous, and
smart. Nowadays NASA increasingly relies on the concepts of autonomic
computing, exploiting these to increase the survivability of remote missions,
particularly when human tending is not feasible. Autonomic computing has been
recognized as a promising approach to the development of self-managing
spacecraft systems that employ onboard intelligence and rely less on control
links. The Autonomic System Specification Language (ASSL) is a framework for
formally specifying and generating autonomic systems. As part of long-term
research targeted at the development of models for space exploration missions
that rely on principles of autonomic computing, we have employed ASSL to
develop formal models and generate functional prototypes for NASA missions.
This helps to validate features and perform experiments through simulation.
Here, we discuss our work on developing such missions with ASSL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0400</identifier>
 <datestamp>2010-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0400</id><created>2010-03-01</created><authors><author><keyname>Sprechmann</keyname><forenames>Pablo</forenames></author><author><keyname>Ramirez</keyname><forenames>Ignacio</forenames></author><author><keyname>Sapiro</keyname><forenames>Guillermo</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Collaborative Hierarchical Sparse Modeling</title><categories>cs.IT math.IT</categories><comments>To appear in CISS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse modeling is a powerful framework for data analysis and processing.
Traditionally, encoding in this framework is done by solving an l_1-regularized
linear regression problem, usually called Lasso. In this work we first combine
the sparsity-inducing property of the Lasso model, at the individual feature
level, with the block-sparsity property of the group Lasso model, where sparse
groups of features are jointly encoded, obtaining a sparsity pattern
hierarchically structured. This results in the hierarchical Lasso, which shows
important practical modeling advantages. We then extend this approach to the
collaborative case, where a set of simultaneously coded signals share the same
sparsity pattern at the higher (group) level but not necessarily at the lower
one. Signals then share the same active groups, or classes, but not necessarily
the same active set. This is very well suited for applications such as source
separation. An efficient optimization procedure, which guarantees convergence
to the global optimum, is developed for these new models. The underlying
presentation of the new framework and optimization approach is complemented
with experimental examples and preliminary theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0404</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0404</id><created>2010-03-01</created><authors><author><keyname>Gu</keyname><forenames>Feng</forenames></author><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Exploration Of The Dendritic Cell Algorithm Using The Duration Calculus</title><categories>cs.AI cs.LO</categories><comments>13 pages, 2 figures, 8th International Conference on Artificial
  Immune Systems (ICARIS 2009), Lecture Notes in Computer Science 5666, York,
  UK</comments><journal-ref>Proceedings of 8th International Conference on Artificial Immune
  Systems (ICARIS 2009), Lecture Notes in Computer Science 5666, York, UK</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As one of the newest members in Artificial Immune Systems (AIS), the
Dendritic Cell Algorithm (DCA) has been applied to a range of problems. These
applications mainly belong to the field of anomaly detection. However,
real-time detection, a new challenge to anomaly detection, requires improvement
on the real-time capability of the DCA. To assess such capability, formal
methods in the research of rea-time systems can be employed. The findings of
the assessment can provide guideline for the future development of the
algorithm. Therefore, in this paper we use an interval logic based method,
named the Duration Calculus (DC), to specify a simplified single-cell model of
the DCA. Based on the DC specifications with further induction, we find that
each individual cell in the DCA can perform its function as a detector in
real-time. Since the DCA can be seen as many such cells operating in parallel,
it is potentially capable of performing real-time detection. However, the
analysis process of the standard DCA constricts its real-time capability. As a
result, we conclude that the analysis process of the standard DCA should be
replaced by a real-time analysis component, which can perform periodic analysis
for the purpose of real-time detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0415</identifier>
 <datestamp>2014-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0415</id><created>2010-03-01</created><authors><author><keyname>Tropp</keyname><forenames>Joel A.</forenames></author></authors><title>The Sparsity Gap: Uncertainty Principles Proportional to Dimension</title><categories>cs.IT math.IT</categories><comments>6 pages. To appear in the Proceedings of the 44th Ann. IEEE Conf. on
  Information Sciences and Systems</comments><journal-ref>Invited paper, Proc. 44th IEEE Conf. Information Sciences and
  Systems (CISS), pp. 1-6, Princeton, NJ, Mar. 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an incoherent dictionary, most signals that admit a sparse representation
admit a unique sparse representation. In other words, there is no way to
express the signal without using strictly more atoms. This work demonstrates
that sparse signals typically enjoy a higher privilege: each nonoptimal
representation of the signal requires far more atoms than the sparsest
representation-unless it contains many of the same atoms as the sparsest
representation. One impact of this finding is to confer a certain degree of
legitimacy on the particular atoms that appear in a sparse representation. This
result can also be viewed as an uncertainty principle for random sparse signals
over an incoherent dictionary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0425</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0425</id><created>2010-03-01</created><updated>2011-03-14</updated><authors><author><keyname>Japaridze</keyname><forenames>Giorgi</forenames></author></authors><title>A logical basis for constructive systems</title><categories>cs.LO cs.CC math.LO</categories><msc-class>03F50, 03D75, 03D15, 03D20, 68Q10, 68T27, 68T30</msc-class><acm-class>F.1.1; F.1.2; F.1.3</acm-class><journal-ref>Journal of Logic and Computation 22 (2012), pp. 605-642</journal-ref><doi>10.1093/logcom/exr009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The work is devoted to Computability Logic (CoL) -- the
philosophical/mathematical platform and long-term project for redeveloping
classical logic after replacing truth} by computability in its underlying
semantics (see http://www.cis.upenn.edu/~giorgi/cl.html). This article
elaborates some basic complexity theory for the CoL framework. Then it proves
soundness and completeness for the deductive system CL12 with respect to the
semantics of CoL, including the version of the latter based on polynomial time
computability instead of computability-in-principle. CL12 is a sequent calculus
system, where the meaning of a sequent intuitively can be characterized as &quot;the
succedent is algorithmically reducible to the antecedent&quot;, and where formulas
are built from predicate letters, function letters, variables, constants,
identity, negation, parallel and choice connectives, and blind and choice
quantifiers. A case is made that CL12 is an adequate logical basis for
constructive applied theories, including complexity-oriented ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0431</identifier>
 <datestamp>2010-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0431</id><created>2010-03-01</created><authors><author><keyname>Kordy</keyname><forenames>Piotr</forenames></author><author><keyname>Langerak</keyname><forenames>Rom</forenames></author><author><keyname>Polderman</keyname><forenames>Jan Willem</forenames></author></authors><title>Re-verification of a Lip Synchronization Protocol using Robust
  Reachability</title><categories>cs.LO</categories><journal-ref>EPTCS 20, 2010, pp. 49-62</journal-ref><doi>10.4204/EPTCS.20.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The timed automata formalism is an important model for specifying and
analysing real-time systems. Robustness is the correctness of the model in the
presence of small drifts on clocks or imprecision in testing guards. A symbolic
algorithm for the analysis of the robustness of timed automata has been
implemented. In this paper, we re-analyse an industrial case lip
synchronization protocol using the new robust reachability algorithm. This lip
synchronization protocol is an interesting case because timing aspects are
crucial for the correctness of the protocol. Several versions of the model are
considered: with an ideal video stream, with anchored jitter, and with
non-anchored jitter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0445</identifier>
 <datestamp>2010-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0445</id><created>2010-03-01</created><authors><author><keyname>Moshksar</keyname><forenames>Kamyar</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>On The Design of Signature Codes in Decentralized Wireless Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses a unified approach towards communication in
decentralized wireless networks of separate transmitter-receiver pairs. In
general, users are unaware of each other's codebooks and there is no central
controller to assign the resources in the network to the users. A randomized
signaling scheme is introduced in which each user locally spreads its Gaussian
signal along a randomly generated spreading code comprised of a sequence of
nonzero elements over a certain alphabet. Along with spreading, each
transmitter also masks its output independently from transmission to
transmission. Using a conditional version of entropy power inequality and a key
lemma on the differential entropy of mixed Gaussian random vectors, achievable
rates are developed for the users. It is seen that as the number of users
increases, the achievable Sum Multiplexing Gain of the network approaches that
of a centralized orthogonal scheme where multiuser interference is completely
avoided. An interesting observation is that in general the elements of a
spreading code are not equiprobable over the underlying alphabet. Finally,
using the recently developed extremal inequality of Liu-Viswanath, we present
an optimality result showing that transmission of Gaussian signals via
spreading and masking yields higher achievable rates than the maximum
achievable rate attained by applying masking only.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0460</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0460</id><created>2010-03-01</created><updated>2012-01-29</updated><authors><author><keyname>Driemel</keyname><forenames>Anne</forenames></author><author><keyname>Har-Peled</keyname><forenames>Sariel</forenames></author><author><keyname>Wenk</keyname><forenames>Carola</forenames></author></authors><title>Approximating the Fr\'echet Distance for Realistic Curves in Near Linear
  Time</title><categories>cs.CG</categories><comments>To appear in SoCG 10</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present simple and practical $(1+\eps)$-approximation algorithm for the
Frechet distance between curves. To analyze this algorithm we introduce a new
realistic family of curves, $c$-packed curves, that is closed under
simplification. We believe the notion of $c$-packed curves to be of independent
interest. We show that our algorithm has near linear running time for
$c$-packed curves, and show similar results for other input models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0466</identifier>
 <datestamp>2011-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0466</id><created>2010-03-01</created><authors><author><keyname>Strufe</keyname><forenames>Thorsten</forenames></author></authors><title>Profile Popularity in a Business-oriented Online Social Network</title><categories>cs.CY</categories><doi>10.1145/1852658.1852660</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analysing Online Social Networks (OSN), voluntarily maintained and
automatically exploitable databases of electronic personal information,
promises a wealth of insight into their users' behavior, interest, and
utilization of these currently predominant services on the Internet. To
understand popularity in OSN, we monitored a large sample of profiles from a
highly popular network for three months, and analysed the relation between
profile properties and their impression frequency. Evaluating the data
indicates a strong relation between both the number of accepted contacts and
the diligence of updating contacts versus the frequency of requests for a
profile. Counter intuitively, the overall activity, gender, as well as
participation span of users have no remarkable impact on their profile's
popularity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0469</identifier>
 <datestamp>2010-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0469</id><created>2010-03-01</created><authors><author><keyname>Kleinberg</keyname><forenames>Jon</forenames></author><author><keyname>Ligett</keyname><forenames>Katrina</forenames></author></authors><title>Information-Sharing and Privacy in Social Networks</title><categories>cs.GT physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new model for reasoning about the way information is shared
among friends in a social network, and the resulting ways in which it spreads.
Our model formalizes the intuition that revealing personal information in
social settings involves a trade-off between the benefits of sharing
information with friends, and the risks that additional gossiping will
propagate it to people with whom one is not on friendly terms. We study the
behavior of rational agents in such a situation, and we characterize the
existence and computability of stable information-sharing networks, in which
agents do not have an incentive to change the partners with whom they share
information. We analyze the implications of these stable networks for social
welfare, and the resulting fragmentation of the social network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0470</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0470</id><created>2010-03-01</created><updated>2010-07-21</updated><authors><author><keyname>Balasubramanian</keyname><forenames>Krishnakumar</forenames></author><author><keyname>Donmez</keyname><forenames>Pinar</forenames></author><author><keyname>Lebanon</keyname><forenames>Guy</forenames></author></authors><title>Unsupervised Supervised Learning II: Training Margin Based Classifiers
  without Labels</title><categories>cs.LG</categories><comments>22 pages, 43 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many popular linear classifiers, such as logistic regression, boosting, or
SVM, are trained by optimizing a margin-based risk function. Traditionally,
these risk functions are computed based on a labeled dataset. We develop a
novel technique for estimating such risks using only unlabeled data and the
marginal label distribution. We prove that the proposed risk estimator is
consistent on high-dimensional datasets and demonstrate it on synthetic and
real-world data. In particular, we show how the estimate is used for evaluating
classifiers in transfer learning, and for training classifiers with no labeled
data whatsoever.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0480</identifier>
 <datestamp>2010-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0480</id><created>2010-03-01</created><authors><author><keyname>Brener</keyname><forenames>Nicolas</forenames></author></authors><title>A definable number which cannot be approximated algorithmically</title><categories>cs.CC cs.LO</categories><acm-class>F.1.1; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Turing machine (TM) and the Church thesis have formalized the concept of
computable number, this allowed to display non-computable numbers. This paper
defines the concept of number &quot;approachable&quot; by a TM and shows that some (if
not all) known non-computable numbers are approachable by TMs. Then an example
of a number not approachable by a TM is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0487</identifier>
 <datestamp>2010-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0487</id><created>2010-03-01</created><authors><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author><author><keyname>Kim</keyname><forenames>Junae</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author></authors><title>Scalable Large-Margin Mahalanobis Distance Metric Learning</title><categories>cs.CV</categories><comments>To publish/Published in IEEE Transactions on Neural Networks, 2010</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  For many machine learning algorithms such as $k$-Nearest Neighbor ($k$-NN)
classifiers and $ k $-means clustering, often their success heavily depends on
the metric used to calculate distances between different data points.
  An effective solution for defining such a metric is to learn it from a set of
labeled training samples. In this work, we propose a fast and scalable
algorithm to learn a Mahalanobis distance metric. By employing the principle of
margin maximization to achieve better generalization performances, this
algorithm formulates the metric learning as a convex optimization problem and a
positive semidefinite (psd) matrix is the unknown variable. a specialized
gradient descent method is proposed. our algorithm is much more efficient and
has a better performance in scalability compared with existing methods.
Experiments on benchmark data sets suggest that, compared with state-of-the-art
metric learning algorithms, our algorithm can achieve a comparable
classification accuracy with reduced computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0488</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0488</id><created>2010-03-01</created><updated>2010-05-14</updated><authors><author><keyname>Pawar</keyname><forenames>Sameer</forenames></author><author><keyname>Rouayheb</keyname><forenames>Salim El</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>On Secure Distributed Data Storage Under Repair Dynamics</title><categories>cs.IT cs.CR math.IT</categories><comments>5 pages, 4 figures, to appear in Proceedings of IEEE ISIT 2010</comments><report-no>EECS Department, University of California, Berkeley, Tech. Rep.
  UCB/EECS-2010-18, Feb. 2010</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of securing distributed storage systems against
passive eavesdroppers that can observe a limited number of storage nodes. An
important aspect of these systems is node failures over time, which demand a
repair mechanism aimed at maintaining a targeted high level of system
reliability. If an eavesdropper observes a node that is added to the system to
replace a failed node, it will have access to all the data downloaded during
repair, which can potentially compromise the entire information in the system.
We are interested in determining the secrecy capacity of distributed storage
systems under repair dynamics, i.e., the maximum amount of data that can be
securely stored and made available to a legitimate user without revealing any
information to any eavesdropper. We derive a general upper bound on the secrecy
capacity and show that this bound is tight for the bandwidth-limited regime
which is of importance in scenarios such as peer-to-peer distributed storage
systems. We also provide a simple explicit code construction that achieves the
capacity for this regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0502</identifier>
 <datestamp>2011-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0502</id><created>2010-03-02</created><updated>2011-04-22</updated><authors><author><keyname>Shalit</keyname><forenames>Orr</forenames></author></authors><title>Stable polynomial division and essential normality of graded Hilbert
  modules</title><categories>math.OA cs.SC math.AC math.FA</categories><comments>17 pages. Minor changes, close to published version</comments><msc-class>47A13, 46L07, 14Q99, 12Y05, 13P10</msc-class><journal-ref>J. London Math. Soc. (2011) 83(2): 273-289</journal-ref><doi>10.1112/jlms/jdq054</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this paper is to initiate a new attack on Arveson's resistant
conjecture, that all graded submodules of the $d$-shift Hilbert module $H^2$
are essentially normal. We introduce the stable division property for modules
(and ideals): a normed module $M$ over the ring of polynomials in $d$ variables
has the stable division property if it has a generating set $\{f_1, ..., f_k\}$
such that every $h \in M$ can be written as $h = \sum_i a_i f_i$ for some
polynomials $a_i$ such that $\sum \|a_i f_i\| \leq C\|h\|$. We show that
certain classes of modules have this property, and that the stable
decomposition $h = \sum a_i f_i$ may be obtained by carefully applying
techniques from computational algebra. We show that when the algebra of
polynomials in $d$ variables is given the natural $\ell^1$ norm, then every
ideal is linearly equivalent to an ideal that has the stable division property.
We then show that a module $M$ that has the stable division property (with
respect to the appropriate norm) is $p$-essentially normal for $p &gt; \dim(M)$,
as conjectured by Douglas. This result is used to give a new, unified proof
that certain classes of graded submodules are essentially normal. Finally, we
reduce the problem of determining whether all graded submodules of the
$d$-shift Hilbert module are essentially normal, to the problem of determining
whether all ideals generated by quadratic scalar valued polynomials are
essentially normal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0511</identifier>
 <datestamp>2010-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0511</id><created>2010-03-02</created><authors><author><keyname>Zouzias</keyname><forenames>Anastasios</forenames></author></authors><title>Low Dimensional Euclidean Volume Preserving Embeddings</title><categories>cs.DM cs.CG</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\mathcal{P}$ be an $n$-point subset of Euclidean space and $d\geq 3$ be
an integer. In this paper we study the following question: What is the smallest
(normalized) relative change of the volume of subsets of $\mathcal{P}$ when it
is projected into $\RR^d$. We prove that there exists a linear mapping
$f:\mathcal{P} \mapsto \RR^d$ that relatively preserves the volume of all
subsets of size up to $\lfloor d/2\rfloor$ within at most a factor of
$O(n^{2/d}\sqrt{\log n \log\log n})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0514</identifier>
 <datestamp>2010-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0514</id><created>2010-03-02</created><authors><author><keyname>Grover</keyname><forenames>Pulkit</forenames></author><author><keyname>Park</keyname><forenames>Se Yong</forenames></author><author><keyname>Sahai</keyname><forenames>Anant</forenames></author></authors><title>The finite-dimensional Witsenhausen counterexample</title><categories>cs.IT cs.CC math.IT math.OC</categories><comments>32 pages, 7 figures, 1 table. Presented at ConCom 2009, Seoul, Korea.
  Submitted to IEEE Transactions on Automatic Control</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Recently, a vector version of Witsenhausen's counterexample was considered
and it was shown that in that limit of infinite vector length, certain
quantization-based control strategies are provably within a constant factor of
the optimal cost for all possible problem parameters. In this paper, finite
vector lengths are considered with the dimension being viewed as an additional
problem parameter. By applying a large-deviation &quot;sphere-packing&quot; philosophy, a
lower bound to the optimal cost for the finite dimensional case is derived that
uses appropriate shadows of the infinite-length bound. Using the new lower
bound, we show that good lattice-based control strategies achieve within a
constant factor of the optimal cost uniformly over all possible problem
parameters, including the vector length. For Witsenhausen's original problem --
the scalar case -- the gap between regular lattice-based strategies and the
lower bound is numerically never more than a factor of 8.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0516</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0516</id><created>2010-03-02</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author><author><keyname>Tran</keyname><forenames>Minh-Ngoc</forenames></author></authors><title>Model Selection with the Loss Rank Principle</title><categories>cs.LG</categories><comments>31 LaTeX pages, 1 figure</comments><journal-ref>Computational Statistics and Data Analysis, 54 (2010) pages
  1288-1306</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A key issue in statistics and machine learning is to automatically select the
&quot;right&quot; model complexity, e.g., the number of neighbors to be averaged over in
k nearest neighbor (kNN) regression or the polynomial degree in regression with
polynomials. We suggest a novel principle - the Loss Rank Principle (LoRP) -
for model selection in regression and classification. It is based on the loss
rank, which counts how many other (fictitious) data would be fitted better.
LoRP selects the model that has minimal loss rank. Unlike most penalized
maximum likelihood variants (AIC, BIC, MDL), LoRP depends only on the
regression functions and the loss function. It works without a stochastic noise
model, and is directly applicable to any non-parametric regressor, like kNN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0520</identifier>
 <datestamp>2010-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0520</id><created>2010-03-02</created><authors><author><keyname>Grover</keyname><forenames>Pulkit</forenames></author><author><keyname>Wagner</keyname><forenames>Aaron B.</forenames></author><author><keyname>Sahai</keyname><forenames>Anant</forenames></author></authors><title>Information embedding meets distributed control</title><categories>cs.IT math.IT</categories><comments>19 pages, 7 figures. Presented at ITW'10. Submitted to IEEE
  Transactions on Information Theory</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  We consider the problem of information embedding where the encoder modifies a
white Gaussian host signal in a power-constrained manner to encode the message,
and the decoder recovers both the embedded message and the modified host
signal. This extends the recent work of Sumszyk and Steinberg to the
continuous-alphabet Gaussian setting. We show that a dirty-paper-coding based
strategy achieves the optimal rate for perfect recovery of the modified host
and the message. We also provide bounds for the extension wherein the modified
host signal is recovered only to within a specified distortion. When
specialized to the zero-rate case, our results provide the tightest known lower
bounds on the asymptotic costs for the vector version of a famous open problem
in distributed control -- the Witsenhausen counterexample. Using this bound, we
characterize the asymptotically optimal costs for the vector Witsenhausen
problem numerically to within a factor of 1.3 for all problem parameters,
improving on the earlier best known bound of 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0522</identifier>
 <datestamp>2010-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0522</id><created>2010-03-02</created><authors><author><keyname>Yodaiken</keyname><forenames>Victor</forenames></author></authors><title>State machine models of timing and circuit design</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper illustrates a technique for specifying the detailed timing,
logical operation, and compositional circuit design of digital circuits in
terms of ordinary state machines with output (transducers). The method is
illustrated here with specifications of gates, latches, and other simple
circuits and via the construction of devices starting with a SR latch built
from gates and then moving on to more complex devices. Circuit timing and
transients are treated in some detail. The method is based on &quot;classical&quot;
automata and recursive functions on strings. No formal methods, extended state
machines, or process algebras are involved but a reference is made to potential
applications of the Krohn-Rhodes theorem and other group/monoid based algebraic
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0529</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0529</id><created>2010-03-02</created><updated>2010-03-30</updated><authors><author><keyname>Agarwal</keyname><forenames>Arvind</forenames></author><author><keyname>Phillips</keyname><forenames>Jeff M.</forenames></author><author><keyname>Venkatasubramanian</keyname><forenames>Suresh</forenames></author></authors><title>A Unified Algorithmic Framework for Multi-Dimensional Scaling</title><categories>cs.LG cs.CG cs.CV</categories><comments>18 pages, 7 figures. This version fixes a bug in the proof of Theorem
  6.1 (dimensionality reduction for spherical data). The statement of the
  result remains the same.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a unified algorithmic framework for solving many
known variants of \mds. Our algorithm is a simple iterative scheme with
guaranteed convergence, and is \emph{modular}; by changing the internals of a
single subroutine in the algorithm, we can switch cost functions and target
spaces easily. In addition to the formal guarantees of convergence, our
algorithms are accurate; in most cases, they converge to better quality
solutions than existing methods, in comparable time. We expect that this
framework will be useful for a number of \mds variants that have not yet been
studied.
  Our framework extends to embedding high-dimensional points lying on a sphere
to points on a lower dimensional sphere, preserving geodesic distances. As a
compliment to this result, we also extend the Johnson-Lindenstrauss Lemma to
this spherical setting, where projecting to a random $O((1/\eps^2) \log
n)$-dimensional sphere causes $\eps$-distortion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0554</identifier>
 <datestamp>2010-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0554</id><created>2010-03-02</created><authors><author><keyname>Besnard</keyname><forenames>L.</forenames></author><author><keyname>Gautier</keyname><forenames>T.</forenames></author><author><keyname>Ouy</keyname><forenames>J.</forenames></author><author><keyname>Talpin</keyname><forenames>J. -P.</forenames></author><author><keyname>Bodeveix</keyname><forenames>J. -P.</forenames></author><author><keyname>Cortier</keyname><forenames>A.</forenames></author><author><keyname>Pantel</keyname><forenames>M.</forenames></author><author><keyname>Strecker</keyname><forenames>M.</forenames></author><author><keyname>Garcia</keyname><forenames>G.</forenames></author><author><keyname>Rugina</keyname><forenames>A.</forenames></author><author><keyname>Buisson</keyname><forenames>J.</forenames></author><author><keyname>Dagnat</keyname><forenames>F.</forenames></author></authors><title>Polychronous Interpretation of Synoptic, a Domain Specific Modeling
  Language for Embedded Flight-Software</title><categories>cs.PL</categories><comments>Workshop on Formal Methods for Aerospace (FMA 2009)</comments><journal-ref>EPTCS 20, 2010, pp. 80-87</journal-ref><doi>10.4204/EPTCS.20.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The SPaCIFY project, which aims at bringing advances in MDE to the satellite
flight software industry, advocates a top-down approach built on a
domain-specific modeling language named Synoptic. In line with previous
approaches to real-time modeling such as Statecharts and Simulink, Synoptic
features hierarchical decomposition of application and control modules in
synchronous block diagrams and state machines. Its semantics is described in
the polychronous model of computation, which is that of the synchronous
language Signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0588</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0588</id><created>2010-03-02</created><updated>2010-12-30</updated><authors><author><keyname>Gajardo</keyname><forenames>Anahi</forenames></author><author><keyname>Guillon</keyname><forenames>Pierre</forenames></author></authors><title>Zigzags in Turing machines</title><categories>cs.FL</categories><comments>17p</comments><proxy>ccsd</proxy><doi>10.1007/978-3-642-13182-0_11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study one-head machines through symbolic and topological dynamics. In
particular, a subshift is associated to the subshift, and we are interested in
its complexity in terms of realtime recognition. We emphasize the class of
one-head machines whose subshift can be recognized by a deterministic pushdown
automaton. We prove that this class corresponds to particular restrictions on
the head movement, and to equicontinuity in associated dynamical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0590</identifier>
 <datestamp>2010-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0590</id><created>2010-03-02</created><authors><author><keyname>Al-Maqtari</keyname><forenames>Sami</forenames><affiliation>LITIS</affiliation></author><author><keyname>Abdulrab</keyname><forenames>Habib</forenames><affiliation>LITIS</affiliation></author><author><keyname>Babkin</keyname><forenames>Eduard</forenames><affiliation>LITIS</affiliation></author></authors><title>A new model for solution of complex distributed constrained problems</title><categories>cs.AI</categories><proxy>ccsd hal-00460770</proxy><journal-ref>Computer Systems and Applications, ACS/IEEE International
  Conference on 0 (2009) 660-667</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe an original computational model for solving
different types of Distributed Constraint Satisfaction Problems (DCSP). The
proposed model is called Controller-Agents for Constraints Solving (CACS). This
model is intended to be used which is an emerged field from the integration
between two paradigms of different nature: Multi-Agent Systems (MAS) and the
Constraint Satisfaction Problem paradigm (CSP) where all constraints are
treated in central manner as a black-box. This model allows grouping
constraints to form a subset that will be treated together as a local problem
inside the controller. Using this model allows also handling non-binary
constraints easily and directly so that no translating of constraints into
binary ones is needed. This paper presents the implementation outlines of a
prototype of DCSP solver, its usage methodology and overview of the CACS
application for timetabling problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0617</identifier>
 <datestamp>2010-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0617</id><created>2010-03-02</created><authors><author><keyname>Dennis</keyname><forenames>Louise A.</forenames></author><author><keyname>Fisher</keyname><forenames>Michael</forenames></author><author><keyname>Lincoln</keyname><forenames>Nicholas</forenames></author><author><keyname>Lisitsa</keyname><forenames>Alexei</forenames></author><author><keyname>Veres</keyname><forenames>Sandor M.</forenames></author></authors><title>Agent Based Approaches to Engineering Autonomous Space Software</title><categories>cs.MA cs.AI</categories><comments>3 pages, 1 Figure, Formal Methods in Aerospace</comments><journal-ref>EPTCS 20, 2010, pp. 63-67</journal-ref><doi>10.4204/EPTCS.20.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current approaches to the engineering of space software such as satellite
control systems are based around the development of feedback controllers using
packages such as MatLab's Simulink toolbox. These provide powerful tools for
engineering real time systems that adapt to changes in the environment but are
limited when the controller itself needs to be adapted.
  We are investigating ways in which ideas from temporal logics and agent
programming can be integrated with the use of such control systems to provide a
more powerful layer of autonomous decision making. This paper will discuss our
initial approaches to the engineering of such systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0628</identifier>
 <datestamp>2010-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0628</id><created>2010-03-02</created><authors><author><keyname>Mao</keyname><forenames>Yi</forenames></author><author><keyname>Balasubramanian</keyname><forenames>Krishnakumar</forenames></author><author><keyname>Lebanon</keyname><forenames>Guy</forenames></author></authors><title>Linguistic Geometries for Unsupervised Dimensionality Reduction</title><categories>cs.CL</categories><comments>13 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Text documents are complex high dimensional objects. To effectively visualize
such data it is important to reduce its dimensionality and visualize the low
dimensional embedding as a 2-D or 3-D scatter plot. In this paper we explore
dimensionality reduction methods that draw upon domain knowledge in order to
achieve a better low dimensional embedding and visualization of documents. We
consider the use of geometries specified manually by an expert, geometries
derived automatically from corpus statistics, and geometries computed from
linguistic resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0634</identifier>
 <datestamp>2010-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0634</id><created>2010-03-02</created><authors><author><keyname>Lazar</keyname><forenames>M.</forenames></author></authors><title>Flexible Lyapunov Functions and Applications to Fast Mechatronic Systems</title><categories>cs.OH</categories><comments>2 figures</comments><journal-ref>EPTCS 20, 2010, pp. 76-79</journal-ref><doi>10.4204/EPTCS.20.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The property that every control system should posses is stability, which
translates into safety in real-life applications. A central tool in systems
theory for synthesizing control laws that achieve stability are control
Lyapunov functions (CLFs). Classically, a CLF enforces that the resulting
closed-loop state trajectory is contained within a cone with a fixed,
predefined shape, and which is centered at and converges to a desired
converging point. However, such a requirement often proves to be
overconservative, which is why most of the real-time controllers do not have a
stability guarantee. Recently, a novel idea that improves the design of CLFs in
terms of flexibility was proposed. The focus of this new approach is on the
design of optimization problems that allow certain parameters that define a
cone associated with a standard CLF to be decision variables. In this way
non-monotonicity of the CLF is explicitly linked with a decision variable that
can be optimized on-line. Conservativeness is significantly reduced compared to
classical CLFs, which makes \emph{flexible CLFs} more suitable for
stabilization of constrained discrete-time nonlinear systems and real-time
control. The purpose of this overview is to highlight the potential of flexible
CLFs for real-time control of fast mechatronic systems, with sampling periods
below one millisecond, which are widely employed in aerospace and automotive
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0642</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0642</id><created>2010-03-02</created><updated>2010-03-09</updated><authors><author><keyname>Mollah</keyname><forenames>Ayatullah Faruk</forenames></author><author><keyname>Basu</keyname><forenames>Subhadip</forenames></author><author><keyname>Das</keyname><forenames>Nibaran</forenames></author><author><keyname>Sarkar</keyname><forenames>Ram</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Kundu</keyname><forenames>Mahantapas</forenames></author></authors><title>Text Region Extraction from Business Card Images for Mobile Devices</title><categories>cs.CV</categories><comments>Proc. of International Conference on Information Technology and
  Business Intelligence (ITBI-09), pp.227-235, Nov 6-8, 2009, Nagpur, India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Designing a Business Card Reader (BCR) for mobile devices is a challenge to
the researchers because of huge deformation in acquired images, multiplicity in
nature of the business cards and most importantly the computational constraints
of the mobile devices. This paper presents a text extraction method designed in
our work towards developing a BCR for mobile devices. At first, the background
of a camera captured image is eliminated at a coarse level. Then, various rule
based techniques are applied on the Connected Components (CC) to filter out the
noises and picture regions. The CCs identified as text are then binarized using
an adaptive but light-weight binarization technique. Experiments show that the
text extraction accuracy is around 98% for a wide range of resolutions with
varying computation time and memory requirements. The optimum performance is
achieved for the images of resolution 1024x768 pixels with text extraction
accuracy of 98.54% and, space and time requirements as 1.1 MB and 0.16 seconds
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0645</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0645</id><created>2010-03-02</created><updated>2010-03-08</updated><authors><author><keyname>Mollah</keyname><forenames>Ayatullah Faruk</forenames></author><author><keyname>Basu</keyname><forenames>Subhadip</forenames></author><author><keyname>Das</keyname><forenames>Nibaran</forenames></author><author><keyname>Sarkar</keyname><forenames>Ram</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Kundu</keyname><forenames>Mahantapas</forenames></author></authors><title>Binarizing Business Card Images for Mobile Devices</title><categories>cs.CV</categories><comments>Proc. of International Conference on Computer Vision and Information
  Technology (ACVIT-2009), pp. 968-975, Dec 16-19, 2009, Aurangabad, India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Business card images are of multiple natures as these often contain graphics,
pictures and texts of various fonts and sizes both in background and
foreground. So, the conventional binarization techniques designed for document
images can not be directly applied on mobile devices. In this paper, we have
presented a fast binarization technique for camera captured business card
images. A card image is split into small blocks. Some of these blocks are
classified as part of the background based on intensity variance. Then the
non-text regions are eliminated and the text ones are skew corrected and
binarized using a simple yet adaptive technique. Experiment shows that the
technique is fast, efficient and applicable for the mobile devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0659</identifier>
 <datestamp>2010-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0659</id><created>2010-03-02</created><updated>2010-03-02</updated><authors><author><keyname>Ettinger</keyname><forenames>Evan</forenames></author><author><keyname>Freund</keyname><forenames>Yoav</forenames></author></authors><title>Particle Filtering on the Audio Localization Manifold</title><categories>cs.AI cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel particle filtering algorithm for tracking a moving sound
source using a microphone array. If there are N microphones in the array, we
track all $N \choose 2$ delays with a single particle filter over time. Since
it is known that tracking in high dimensions is rife with difficulties, we
instead integrate into our particle filter a model of the low dimensional
manifold that these delays lie on. Our manifold model is based off of work on
modeling low dimensional manifolds via random projection trees [1]. In
addition, we also introduce a new weighting scheme to our particle filtering
algorithm based on recent advancements in online learning. We show that our
novel TDOA tracking algorithm that integrates a manifold model can greatly
outperform standard particle filters on this audio tracking task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0662</identifier>
 <datestamp>2010-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0662</id><created>2010-03-02</created><authors><author><keyname>Arfi</keyname><forenames>Mustapha</forenames><affiliation>LITIS</affiliation></author><author><keyname>Lemine</keyname><forenames>Bedine Ould M.</forenames><affiliation>LITIS</affiliation></author><author><keyname>Selmi</keyname><forenames>Carla</forenames><affiliation>LITIS</affiliation></author></authors><title>Strategical languages of infinite words</title><categories>cs.GT</categories><proxy>ccsd hal-00460312</proxy><journal-ref>Information Processing Letters 109 (2009) 749-753</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We deal in this paper with strategical languages of infinite words, that is
those generated by a nondeterministic strategy in the sense of game theory. We
first show the existence of a minimal strategy for such languages, for which we
give an explicit expression. Then we characterize the family of strategical
languages as that of closed ones, in the topological space of infinite words.
Finally, we give a definition of a Nash equilibrium for such languages, that we
illustrate with a famous example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0691</identifier>
 <datestamp>2010-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0691</id><created>2010-03-02</created><authors><author><keyname>Dillon</keyname><forenames>Joshua V</forenames></author><author><keyname>Lebanon</keyname><forenames>Guy</forenames></author></authors><title>Statistical and Computational Tradeoffs in Stochastic Composite
  Likelihood</title><categories>cs.LG</categories><comments>30 pages, 97 figures, 2 authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximum likelihood estimators are often of limited practical use due to the
intensive computation they require. We propose a family of alternative
estimators that maximize a stochastic variation of the composite likelihood
function. Each of the estimators resolve the computation-accuracy tradeoff
differently, and taken together they span a continuous spectrum of
computation-accuracy tradeoff resolutions. We prove the consistency of the
estimators, provide formulas for their asymptotic variance, statistical
robustness, and computational complexity. We discuss experimental results in
the context of Boltzmann machines and conditional random fields. The
theoretical and experimental studies demonstrate the effectiveness of the
estimators when the computational resources are insufficient. They also
demonstrate that in some cases reduced computational complexity is associated
with robustness thereby increasing statistical accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0696</identifier>
 <datestamp>2010-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0696</id><created>2010-03-02</created><authors><author><keyname>Agarwal</keyname><forenames>Arvind</forenames></author><author><keyname>Daume</keyname><forenames>Hal</forenames><suffix>III</suffix></author></authors><title>Exponential Family Hybrid Semi-Supervised Learning</title><categories>cs.LG</categories><comments>6 pages, 3 figures</comments><journal-ref>Twenty-First International Joint Conference on Artificial
  Intelligence 2009, pg 974-979</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an approach to semi-supervised learning based on an exponential
family characterization. Our approach generalizes previous work on coupled
priors for hybrid generative/discriminative models. Our model is more flexible
and natural than previous approaches. Experimental results on several data sets
show that our approach also performs better in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0722</identifier>
 <datestamp>2010-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0722</id><created>2010-03-02</created><updated>2010-03-04</updated><authors><author><keyname>Gupta</keyname><forenames>Anupam</forenames></author><author><keyname>Krishnaswamy</keyname><forenames>Ravishankar</forenames></author><author><keyname>Nagarajan</keyname><forenames>Viswanath</forenames></author><author><keyname>Ravi</keyname><forenames>R.</forenames></author></authors><title>Approximation Algorithms for Optimal Decision Trees and Adaptive TSP
  Problems</title><categories>cs.DS</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of constructing optimal decision trees: given a
collection of tests which can disambiguate between a set of $m$ possible
diseases, each test having a cost, and the a-priori likelihood of the patient
having any particular disease, what is a good adaptive strategy to perform
these tests to minimize the expected cost to identify the disease? We settle
the approximability of this problem by giving a tight $O(\log m)$-approximation
algorithm. We also consider a more substantial generalization, the Adaptive TSP
problem. Given an underlying metric space, a random subset $S$ of cities is
drawn from a known distribution, but $S$ is initially unknown to us--we get
information about whether any city is in $S$ only when we visit the city in
question. What is a good adaptive way of visiting all the cities in the random
subset $S$ while minimizing the expected distance traveled? For this problem,
we give the first poly-logarithmic approximation, and show that this algorithm
is best possible unless we can improve the approximation guarantees for the
well-known group Steiner tree problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0723</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0723</id><created>2010-03-02</created><updated>2010-07-08</updated><authors><author><keyname>Fang</keyname><forenames>Chengfang</forenames></author><author><keyname>Chang</keyname><forenames>Ee-Chien</forenames></author></authors><title>Securing Interactive Sessions Using Mobile Device through Visual Channel
  and Visual Inspection</title><categories>cs.CR cs.CV</categories><comments>16 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communication channel established from a display to a device's camera is
known as visual channel, and it is helpful in securing key exchange protocol.
In this paper, we study how visual channel can be exploited by a network
terminal and mobile device to jointly verify information in an interactive
session, and how such information can be jointly presented in a user-friendly
manner, taking into account that the mobile device can only capture and display
a small region, and the user may only want to authenticate selective
regions-of-interests. Motivated by applications in Kiosk computing and
multi-factor authentication, we consider three security models: (1) the mobile
device is trusted, (2) at most one of the terminal or the mobile device is
dishonest, and (3) both the terminal and device are dishonest but they do not
collude or communicate. We give two protocols and investigate them under the
abovementioned models. We point out a form of replay attack that renders some
other straightforward implementations cumbersome to use. To enhance
user-friendliness, we propose a solution using visual cues embedded into the 2D
barcodes and incorporate the framework of &quot;augmented reality&quot; for easy
verifications through visual inspection. We give a proof-of-concept
implementation to show that our scheme is feasible in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0727</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0727</id><created>2010-03-02</created><updated>2010-05-23</updated><authors><author><keyname>Ye</keyname><forenames>Deping</forenames></author></authors><title>On the comparison of volumes of quantum states</title><categories>quant-ph cs.IT math-ph math.FA math.IT math.MP</categories><journal-ref>J. Phys. A: Math. Theor. 43 (2010) 315301 (17pp)</journal-ref><doi>10.1088/1751-8113/43/31/315301</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper aims to study the $\a$-volume of $\cK$, an arbitrary subset of the
set of $N\times N$ density matrices. The $\a$-volume is a generalization of the
Hilbert-Schmidt volume and the volume induced by partial trace. We obtain
two-side estimates for the $\a$-volume of $\cK$ in terms of its Hilbert-Schmidt
volume. The analogous estimates between the Bures volume and the $\a$-volume
are also established. We employ our results to obtain bounds for the
$\a$-volume of the sets of separable quantum states and of states with positive
partial transpose (PPT). Hence, our asymptotic results provide answers for
questions listed on page 9 in \cite{K. Zyczkowski1998} for large $N$ in the
sense of $\a$-volume.
  \vskip 3mm PACS numbers: 02.40.Ft, 03.65.Db, 03.65.Ud, 03.67.Mn
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0729</identifier>
 <datestamp>2010-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0729</id><created>2010-03-03</created><authors><author><keyname>Bagherikaram</keyname><forenames>Ghadamali</forenames></author><author><keyname>Motahari</keyname><forenames>Abolfazl S.</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>On the Secure Degrees-of-Freedom of the Multiple-Access-Channel</title><categories>cs.IT math.IT</categories><comments>The conference version of this work has been submitted to ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A $K$-user secure Gaussian Multiple-Access-Channel (MAC) with an external
eavesdropper is considered in this paper. An achievable rate region is
established for the secure discrete memoryless MAC. The secrecy sum capacity of
the degraded Gaussian MIMO MAC is proven using Gaussian codebooks. For the
non-degraded Gaussian MIMO MAC, an algorithm inspired by interference alignment
technique is proposed to achieve the largest possible total
Secure-Degrees-of-Freedom (S-DoF). When all the terminals are equipped with a
single antenna, Gaussian codebooks have shown to be inefficient in providing a
positive S-DoF. Instead, a novel secure coding scheme is proposed to achieve a
positive S-DoF in the single antenna MAC. This scheme converts the
single-antenna system into a multiple-dimension system with fractional
dimensions. The achievability scheme is based on the alignment of signals into
a small sub-space at the eavesdropper, and the simultaneous separation of the
signals at the intended receiver. Tools from the field of Diophantine
Approximation in number theory are used to analyze the probability of error in
the coding scheme. It is proven that the total S-DoF of $\frac{K-1}{K}$ can be
achieved for almost all channel gains. For the other channel gains, a
multi-layer coding scheme is proposed to achieve a positive S-DoF. As a
function of channel gains, therefore, the achievable S-DoF is discontinued.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0735</identifier>
 <datestamp>2010-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0735</id><created>2010-03-03</created><authors><author><keyname>Zhang</keyname><forenames>Lili</forenames></author><author><keyname>Jiang</keyname><forenames>Jinhua</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Compress-and-Forward Performance in Low-SNR Relay Channels</title><categories>cs.IT math.IT</categories><comments>13 pages, 5 figures, submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the Gaussian relay channels in the low
signal-to-noise ratio (SNR) regime with the time-sharing compress-and-forward
(CF) scheme, where at each time slot all the nodes keep silent at the first
fraction of time and then transmit with CF at a higher peak power in the second
fraction. Such a silent vs. active two-phase relay scheme is preferable in the
low-SNR regime. With this setup, the upper and lower bounds on the minimum
energy per bit required over the relay channel are established under both
full-duplex and half-duplex relaying modes. In particular, the lower bound is
derived by applying the max-flow min-cut capacity theorem; the upper bound is
established with the aforementioned time-sharing CF scheme, and is further
minimized by letting the active phase fraction decrease to zero at the same
rate as the SNR value. Numerical results are presented to validate the
theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0746</identifier>
 <datestamp>2010-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0746</id><created>2010-03-03</created><authors><author><keyname>Chenouard</keyname><forenames>Raphael</forenames><affiliation>LINA</affiliation></author><author><keyname>Jouault</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA - EMN</affiliation></author></authors><title>Automatically Discovering Hidden Transformation Chaining Constraints</title><categories>cs.AI</categories><proxy>ccsd hal-00460761</proxy><journal-ref>ACM/IEEE 12th International Conference on Model Driven Engineering
  Languages and Systems, Denver : United States (2009)</journal-ref><doi>10.1007/978-3-642-04425-0_8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Model transformations operate on models conforming to precisely defined
metamodels. Consequently, it often seems relatively easy to chain them: the
output of a transformation may be given as input to a second one if metamodels
match. However, this simple rule has some obvious limitations. For instance, a
transformation may only use a subset of a metamodel. Therefore, chaining
transformations appropriately requires more information. We present here an
approach that automatically discovers more detailed information about actual
chaining constraints by statically analyzing transformations. The objective is
to provide developers who decide to chain transformations with more data on
which to base their choices. This approach has been successfully applied to the
case of a library of endogenous transformations. They all have the same source
and target metamodel but have some hidden chaining constraints. In such a case,
the simple metamodel matching rule given above does not provide any useful
information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0773</identifier>
 <datestamp>2010-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0773</id><created>2010-03-03</created><authors><author><keyname>Kupusinac</keyname><forenames>Aleksandar</forenames></author><author><keyname>Malbaski</keyname><forenames>Dusan</forenames></author></authors><title>S-Program Calculus</title><categories>cs.LO cs.PL</categories><comments>24 pages, 2 figures</comments><acm-class>F.3.1; F.3.2; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a special subset of the first-order predicate logic named
S-program calculus (briefly S-calculus). The S-calculus is a calculus
consisting of so-called S-formulas that are defined over the abstract state
space of a virtual machine. We show that S-formulas are a highly general tool
for analyzing program semantics inasmuch as Hoare triplets of total and partial
correctness are not more than two S-formulas. Moreover, all the rules of Hoare
logic can be derived using S-formulas and axioms/theorems of first-order
predicate calculus. The S-calculus is a powerful mechanism for proving program
correctness as well as for building additional proving tools using theorems of
the predicate logic. Every proof is based on deriving the validity of some
S-formula, so the procedure may be automated using automatic theorem provers
(we will use Coq in this paper). As an example of the use of S-calculus, we
will prove the four basic properties of Dijsktra's operator wp. The proofs
given by Dijkstra are not completely formalized and we will show that a full
formalization can be achieved using S-calculus. Finally, we add one more
theorem to the above-mentioned four, namely the law of negation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0776</identifier>
 <datestamp>2010-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0776</id><created>2010-03-03</created><authors><author><keyname>Anguelov</keyname><forenames>Roumen</forenames></author><author><keyname>Fabris-Rotelli</keyname><forenames>Inger</forenames></author></authors><title>Properties of the Discrete Pulse Transform for Multi-Dimensional Arrays</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report presents properties of the Discrete Pulse Transform on
multi-dimensional arrays introduced by the authors two or so years ago. The
main result given here in Lemma 2.1 is also formulated in a paper to appear in
IEEE Transactions on Image Processing. However, the proof, being too technical,
was omitted there and hence it appears in full in this publication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0788</identifier>
 <datestamp>2010-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0788</id><created>2010-03-03</created><authors><author><keyname>Zhang</keyname><forenames>Chenyi</forenames></author><author><keyname>Pang</keyname><forenames>Jun</forenames></author></authors><title>On Probabilistic Alternating Simulations</title><categories>cs.LO cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents simulation-based relations for probabilistic game
structures. The first relation is called probabilistic alternating simulation,
and the second called probabilistic alternating forward simulation, following
the naming convention of Segala and Lynch. We study these relations with
respect to the preservation of properties specified in probabilistic
alternating-time temporal logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0789</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0789</id><created>2010-03-03</created><authors><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Tedesco</keyname><forenames>Gianni</forenames></author></authors><title>Information Fusion for Anomaly Detection with the Dendritic Cell
  Algorithm</title><categories>cs.AI cs.CR cs.NE</categories><comments>21 pages, 17 figures, Information Fusion</comments><journal-ref>Information Fusion, 11 (1), 21-34, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dendritic cells are antigen presenting cells that provide a vital link
between the innate and adaptive immune system, providing the initial detection
of pathogenic invaders. Research into this family of cells has revealed that
they perform information fusion which directs immune responses. We have derived
a Dendritic Cell Algorithm based on the functionality of these cells, by
modelling the biological signals and differentiation pathways to build a
control mechanism for an artificial immune system. We present algorithmic
details in addition to experimental results, when the algorithm was applied to
anomaly detection for the detection of port scans. The results show the
Dendritic Cell Algorithm is sucessful at detecting port scans.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0802</identifier>
 <datestamp>2010-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0802</id><created>2010-03-03</created><authors><author><keyname>Madelaine</keyname><forenames>Florent</forenames></author><author><keyname>Martin</keyname><forenames>Barnaby</forenames></author></authors><title>The complexity of positive first-order logic without equality</title><categories>cs.LO cs.CC</categories><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of evaluating positive equality-free sentences of
first-order (FO) logic over a fixed, finite structure B. This may be seen as a
natural generalisation of the non-uniform quantified constraint satisfaction
problem QCSP(B). We introduce surjective hyper-endomorphisms and use them in
proving a Galois connection that characterises definability in positive
equality-free FO. Through an algebraic method, we derive a complete complexity
classification for our problems as B ranges over structures of size at most
three. Specifically, each problem is either in Logspace, is NP-complete, is
co-NP-complete or is Pspace-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0888</identifier>
 <datestamp>2010-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0888</id><created>2010-03-03</created><authors><author><keyname>Jin</keyname><forenames>Yuzhe</forenames></author><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author><author><keyname>Rao</keyname><forenames>Bhaskar D.</forenames></author></authors><title>Support Recovery of Sparse Signals</title><categories>cs.IT math.IT</categories><comments>33 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of exact support recovery of sparse signals via noisy
measurements. The main focus is the sufficient and necessary conditions on the
number of measurements for support recovery to be reliable. By drawing an
analogy between the problem of support recovery and the problem of channel
coding over the Gaussian multiple access channel, and exploiting mathematical
tools developed for the latter problem, we obtain an information theoretic
framework for analyzing the performance limits of support recovery. Sharp
sufficient and necessary conditions on the number of measurements in terms of
the signal sparsity level and the measurement noise level are derived.
Specifically, when the number of nonzero entries is held fixed, the exact
asymptotics on the number of measurements for support recovery is developed.
When the number of nonzero entries increases in certain manners, we obtain
sufficient conditions tighter than existing results. In addition, we show that
the proposed methodology can deal with a variety of models of sparse signal
recovery, hence demonstrating its potential as an effective analytical tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0929</identifier>
 <datestamp>2010-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0929</id><created>2010-03-03</created><authors><author><keyname>Moallemi</keyname><forenames>Ciamac</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author></authors><title>On the Flow-level Dynamics of a Packet-switched Network</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The packet is the fundamental unit of transportation in modern communication
networks such as the Internet. Physical layer scheduling decisions are made at
the level of packets, and packet-level models with exogenous arrival processes
have long been employed to study network performance, as well as design
scheduling policies that more efficiently utilize network resources. On the
other hand, a user of the network is more concerned with end-to-end bandwidth,
which is allocated through congestion control policies such as TCP.
Utility-based flow-level models have played an important role in understanding
congestion control protocols. In summary, these two classes of models have
provided separate insights for flow-level and packet-level dynamics of a
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0931</identifier>
 <datestamp>2010-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0931</id><created>2010-03-03</created><authors><author><keyname>Miller</keyname><forenames>Casey W.</forenames></author><author><keyname>Chabot</keyname><forenames>Michelle D.</forenames></author><author><keyname>Messina</keyname><forenames>Troy C.</forenames></author></authors><title>A student's guide to searching the literature using online databases</title><categories>physics.ed-ph cs.DL cs.IR</categories><comments>16 pages, 5 figures, and 1 table</comments><journal-ref>Am. J. Phys. 77(12), 1112-1117 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method is described to empower students to efficiently perform general and
literature searches using online resources. The method was tested on
undergraduate and graduate students with varying backgrounds with scientific
literature. Students involved in this study showed marked improvement in their
awareness of how and where to find accurate scientific information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0951</identifier>
 <datestamp>2013-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0951</id><created>2010-03-03</created><updated>2013-01-15</updated><authors><author><keyname>Ren</keyname><forenames>Rui</forenames></author><author><keyname>Fu</keyname><forenames>Xiaoyu</forenames></author><author><keyname>Zhan</keyname><forenames>Jianfeng</forenames></author><author><keyname>Zhou</keyname><forenames>Wei</forenames></author></authors><title>LogMaster: Mining Event Correlations in Logs of Large scale Cluster
  Systems</title><categories>cs.DC</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a methodology and a system, named LogMaster, for mining
correlations of events that have multiple attributions, i.e., node ID,
application ID, event type, and event severity, in logs of large-scale cluster
systems. Different from traditional transactional data, e.g., supermarket
purchases, system logs have their unique characteristic, and hence we propose
several innovative approaches to mine their correlations. We present a simple
metrics to measure correlations of events that may happen interleavedly. On the
basis of the measurement of correlations, we propose two approaches to mine
event correlations; meanwhile, we propose an innovative abstraction: event
correlation graphs (ECGs) to represent event correlations, and present an ECGs
based algorithm for predicting events. For two system logs of a production
Hadoop-based cloud computing system at Research Institution of China Mobile and
a production HPC cluster system at Los Alamos National Lab (LANL), we evaluate
our approaches in three scenarios: (a) predicting all events on the basis of
both failure and non-failure events; (b) predicting only failure events on the
basis of both failure and non-failure events; (c) predicting failure events
after removing non-failure events.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0952</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0952</id><created>2010-03-03</created><updated>2010-05-28</updated><authors><author><keyname>Batista</keyname><forenames>Vicente H. F.</forenames></author><author><keyname>Ainsworth</keyname><forenames>George O.</forenames><suffix>Jr.</suffix></author><author><keyname>Ribeiro</keyname><forenames>Fernando L. B.</forenames></author></authors><title>Parallel structurally-symmetric sparse matrix-vector products on
  multi-core processors</title><categories>cs.DC</categories><comments>17 pages, 17 figures, reviewed related work section, fixed typos</comments><doi>10.4203/ccp.101.22</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of developing an efficient multi-threaded
implementation of the matrix-vector multiplication algorithm for sparse
matrices with structural symmetry. Matrices are stored using the compressed
sparse row-column format (CSRC), designed for profiting from the symmetric
non-zero pattern observed in global finite element matrices. Unlike classical
compressed storage formats, performing the sparse matrix-vector product using
the CSRC requires thread-safe access to the destination vector. To avoid race
conditions, we have implemented two partitioning strategies. In the first one,
each thread allocates an array for storing its contributions, which are later
combined in an accumulation step. We analyze how to perform this accumulation
in four different ways. The second strategy employs a coloring algorithm for
grouping rows that can be concurrently processed by threads. Our results
indicate that, although incurring an increase in the working set size, the
former approach leads to the best performance improvements for most matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0953</identifier>
 <datestamp>2010-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0953</id><created>2010-03-03</created><authors><author><keyname>Sung</keyname><forenames>Chi Wan</forenames></author><author><keyname>Shum</keyname><forenames>Kenneth W.</forenames></author><author><keyname>Yuen</keyname><forenames>Wing Ho</forenames></author></authors><title>Information Flow in One-Dimensional Vehicular Ad Hoc Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider content distribution in vehicular ad hoc networks. We assume that
a file is encoded using fountain code, and the encoded message is cached at
infostations. Vehicles are allowed to download data packets from infostations,
which are placed along a highway. In addition, two vehicles can exchange
packets with each other when they are in proximity. As long as a vehicle has
received enough packets from infostations or from other vehicles, the original
file can be recovered. In this work, we show that system throughput increases
linearly with number of users, meaning that the system exhibits linear
scalability. Furthermore, we analyze the effect of mobility on system
throughput by considering both discrete and continuous velocity distributions
for the vehicles. In both cases, system throughput is shown to decrease when
the average speed of all vehicles increases. In other words, higher overall
mobility reduces system throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0955</identifier>
 <datestamp>2010-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0955</id><created>2010-03-04</created><authors><author><keyname>Zhang</keyname><forenames>Zhihong</forenames></author><author><keyname>Zhan</keyname><forenames>Jianfeng</forenames></author><author><keyname>Li</keyname><forenames>Yong</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author><author><keyname>Meng</keyname><forenames>Dan</forenames></author><author><keyname>Sang</keyname><forenames>Bo</forenames></author></authors><title>Precise Request Tracing and Performance Debugging for Multi-tier
  Services of Black Boxes</title><categories>cs.DC cs.PF</categories><journal-ref>Proceeding of IEEE/IFIP 39th Dependable System and Network (DSN
  2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As more and more multi-tier services are developed from commercial components
or heterogeneous middleware without the source code available, both developers
and administrators need a precise request tracing tool to help understand and
debug performance problems of large concurrent services of black boxes.
Previous work fails to resolve this issue in several ways: they either accept
the imprecision of probabilistic correlation methods, or rely on knowledge of
protocols to isolate requests in pursuit of tracing accuracy. This paper
introduces a tool named PreciseTracer to help debug performance problems of
multi-tier services of black boxes. Our contributions are two-fold: first, we
propose a precise request tracing algorithm for multi-tier services of black
boxes, which only uses application-independent knowledge; secondly, we present
a component activity graph abstraction to represent causal paths of requests
and facilitate end-to-end performance debugging. The low overhead and tolerance
of noise make PreciseTracer a promising tracing tool for using on production
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0958</identifier>
 <datestamp>2010-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0958</id><created>2010-03-03</created><updated>2010-03-30</updated><authors><author><keyname>Zhan</keyname><forenames>Jianfeng</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author><author><keyname>Shi</keyname><forenames>Weisong</forenames></author><author><keyname>Gong</keyname><forenames>Shimin</forenames></author><author><keyname>Zang</keyname><forenames>Xiutao</forenames></author></authors><title>PhoenixCloud: Provisioning Resources for Heterogeneous Cloud Workloads</title><categories>cs.DC cs.PF</categories><comments>Submitted to IEEE Transaction on Service Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As more and more service providers choose Cloud platforms, a resource
provider needs to provision resources and supporting runtime environments (REs)
for heterogeneous workloads in different scenarios. Previous work fails to
resolve this issue in several ways: (1) it fails to pay attention to diverse RE
requirements, and does not enable creating coordinated REs on demand; (2) few
work investigates coordinated resource provisioning for heterogeneous
workloads. In this paper, our contributions are three-fold: (1) we present an
RE agreement that expresses diverse RE requirements, and build an innovative
system PhoenixCloud that enables a resource provider to create REs on demand
according to RE agreements; (2) we propose two coordinated resource
provisioning solutions for heterogeneous workloads in two typical Cloud
scenarios: first, a large organization operates a private Cloud for two
heterogeneous workloads; second, a large organization or two service providers
running heterogeneous workloads revert to a public Cloud; and (3) A
comprehensive evaluation has been performed in experiments. For typical
workload traces of parallel batch jobs and Web services, our experiments show
that: a) In the first Cloud scenario, when the throughput is almost same like
that of a dedicated cluster system, our solution decreases the configuration
size of cluster by about 40%; b) in the second scenario, our solution decreases
not only the total resource consumption, but also the peak resource consumption
maximally to 31% with respect to that of EC2 + RightScale solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.0959</identifier>
 <datestamp>2010-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.0959</id><created>2010-03-04</created><authors><author><keyname>Sang</keyname><forenames>Bo</forenames></author><author><keyname>Zhan</keyname><forenames>Jianfeng</forenames></author><author><keyname>Tian</keyname><forenames>Guanhua</forenames></author></authors><title>Decreasing log data of multi-tier services for effective request tracing</title><categories>cs.DC cs.PF</categories><journal-ref>Proceeding of IEEE/IFIP 39th Dependable System and Network (DSN
  2009), Fast Abstract</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous work shows request tracing systems help understand and debug the
performance problems of multi-tier services. However, for large-scale data
centers, more than hundreds of thousands of service instances provide online
service at the same time. Previous work such as white-box or black box tracing
systems will produce large amount of log data, which would be correlated into
large quantities of causal paths for performance debugging. In this paper, we
propose an innovative algorithm to eliminate valueless logs of multitiers
services. Our experiment shows our method filters 84% valueless causal paths
and is promising to be used in large-scale data centers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1010</identifier>
 <datestamp>2010-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1010</id><created>2010-03-04</created><authors><author><keyname>Genest</keyname><forenames>Blaise</forenames><affiliation>INRIA - Irisa</affiliation></author><author><keyname>Muscholl</keyname><forenames>Anca</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Wu</keyname><forenames>Zhilin</forenames><affiliation>LaBRI</affiliation></author></authors><title>Verifying Recursive Active Documents with Positive Data Tree Rewriting</title><categories>cs.DB cs.OH</categories><proxy>ccsd hal-00461272</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a data tree-rewriting framework for modeling evolving
documents. The framework is close to Guarded Active XML, a platform used for
handling XML repositories evolving through web services. We focus on automatic
verification of properties of evolving documents that can contain data from an
infinite domain. We establish the boundaries of decidability, and show that
verification of a {\em positive} fragment that can handle recursive service
calls is decidable. We also consider bounded model-checking in our data
tree-rewriting framework and show that it is $\nexptime$-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1018</identifier>
 <datestamp>2010-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1018</id><created>2010-03-04</created><authors><author><keyname>Perc</keyname><forenames>Matjaz</forenames></author></authors><title>Zipf's law and log-normal distributions in measures of scientific output
  across fields and institutions: 40 years of Slovenia's research as an example</title><categories>physics.data-an cs.DB stat.AP</categories><comments>8 pages, 3 figures; accepted for publication in Journal of
  Informetrics [supplementary material available at
  http://www.matjazperc.com/sicris/stats.html]</comments><journal-ref>Journal of Informetrics 4 (2010) 358-364</journal-ref><doi>10.1016/j.joi.2010.03.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Slovenia's Current Research Information System (SICRIS) currently hosts
86,443 publications with citation data from 8,359 researchers working on the
whole plethora of social and natural sciences from 1970 till present. Using
these data, we show that the citation distributions derived from individual
publications have Zipfian properties in that they can be fitted by a power law
$P(x) \sim x^{-\alpha}$, with $\alpha$ between 2.4 and 3.1 depending on the
institution and field of research. Distributions of indexes that quantify the
success of researchers rather than individual publications, on the other hand,
cannot be associated with a power law. We find that for Egghe's g-index and
Hirsch's h-index the log-normal form $P(x) \sim \exp[-a\ln x -b(\ln x)^2]$
applies best, with $a$ and $b$ depending moderately on the underlying set of
researchers. In special cases, particularly for institutions with a strongly
hierarchical constitution and research fields with high self-citation rates,
exponential distributions can be observed as well. Both indexes yield
distributions with equivalent statistical properties, which is a strong
indicator for their consistency and logical connectedness. At the same time,
differences in the assessment of citation histories of individual researchers
strengthen their importance for properly evaluating the quality and impact of
scientific output.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1020</identifier>
 <datestamp>2010-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1020</id><created>2010-03-04</created><updated>2010-05-29</updated><authors><author><keyname>Huang</keyname><forenames>Haiping</forenames></author><author><keyname>Zhou</keyname><forenames>Haijun</forenames></author></authors><title>Learning by random walks in the weight space of the Ising perceptron</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.LG q-bio.NC</categories><comments>12 pages, 4 figures, An extensively revised version</comments><journal-ref>J. Stat. Mech.: Theory Exp. P08014 (2010)</journal-ref><doi>10.1088/1742-5468/2010/08/P08014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several variants of a stochastic local search process for constructing the
synaptic weights of an Ising perceptron are studied. In this process, binary
patterns are sequentially presented to the Ising perceptron and are then
learned as the synaptic weight configuration is modified through a chain of
single- or double-weight flips within the compatible weight configuration space
of the earlier learned patterns. This process is able to reach a storage
capacity of $\alpha \approx 0.63$ for pattern length N = 101 and $\alpha
\approx 0.41$ for N = 1001. If in addition a relearning process is exploited,
the learning performance is further improved to a storage capacity of $\alpha
\approx 0.80$ for N = 101 and $\alpha \approx 0.42$ for N=1001. We found that,
for a given learning task, the solutions constructed by the random walk
learning process are separated by a typical Hamming distance, which decreases
with the constraint density $\alpha$ of the learning task; at a fixed value of
$\alpha$, the width of the Hamming distance distributions decreases with $N$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1039</identifier>
 <datestamp>2010-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1039</id><created>2010-03-04</created><updated>2010-03-22</updated><authors><author><keyname>Formato</keyname><forenames>Richard A.</forenames></author></authors><title>Parameter-Free Deterministic Global Search with Central Force
  Optimization</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note describes a parameter-free implementation of Central Force
Optimization for deterministic multidimensional search and optimization. The
user supplies only one input: the objective function to be maximized, nothing
more. The CFO equations of motion are simplified by assigning specific values
to CFO's basic parameters, and this particular algorithmic implementation also
includes hardwired internal parameters so that none is user-specified. The
algorithm's performance is tested against a widely used suite of twenty three
benchmark functions and compared to other state-of-the-art algorithms. CFO
performs very well indeed. Includes important update 20 March 2010 addressing
the issue of different probes coalescing into one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1048</identifier>
 <datestamp>2010-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1048</id><created>2010-03-04</created><authors><author><keyname>Knautz</keyname><forenames>Kathrin</forenames></author><author><keyname>Soubusta</keyname><forenames>Simone</forenames></author><author><keyname>Stock</keyname><forenames>Wolfgang G.</forenames></author></authors><title>Tag Clusters as Information Retrieval Interfaces</title><categories>cs.IR</categories><journal-ref>Proceedings of the 43th Annual Hawaii International Conference on
  System Sciences (HICSS-43), January 5-8, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents our design of a next generation information retrieval
system based on tag co-occurrences and subsequent clustering. We help users
getting access to digital data through information visualization in the form of
tag clusters. Current problems like the absence of interactivity and semantics
between tags or the difficulty of adding additional search arguments are
solved. In the evaluation, based upon SERVQUAL and IT systems quality
indicators, we found out that tag clusters are perceived as more useful than
tag clouds, are much more trustworthy, and are more enjoyable to use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1057</identifier>
 <datestamp>2010-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1057</id><created>2010-03-04</created><authors><author><keyname>Endrullis</keyname><forenames>Joerg</forenames></author></authors><title>Levels of Undecidability in Infinitary Rewriting: Normalization and
  Reachability</title><categories>cs.LO cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In [EGZ09] it has been shown that infinitary strong normalization (SNi) is
Pi-1-1-complete. Suprisingly, it turns out that infinitary weak normalization
(WNi) is a harder problem, being Pi-1-2-complete, and thereby strictly higher
in the analytical hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1058</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1058</id><created>2010-03-04</created><updated>2010-05-31</updated><authors><author><keyname>Delporte-Gallet</keyname><forenames>Carole</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Devismes</keyname><forenames>St&#xe9;phane</forenames><affiliation>VERIMAG - IMAG</affiliation></author><author><keyname>Fauconnier</keyname><forenames>Hugues</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Larrea</keyname><forenames>Mikel</forenames></author></authors><title>Algorithms For Extracting Timeliness Graphs</title><categories>cs.DC</categories><proxy>ccsd</proxy><doi>10.1007/978-3-642-13284-1_11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider asynchronous message-passing systems in which some links are
timely and processes may crash. Each run defines a timeliness graph among
correct processes: (p; q) is an edge of the timeliness graph if the link from p
to q is timely (that is, there is bound on communication delays from p to q).
The main goal of this paper is to approximate this timeliness graph by graphs
having some properties (such as being trees, rings, ...). Given a family S of
graphs, for runs such that the timeliness graph contains at least one graph in
S then using an extraction algorithm, each correct process has to converge to
the same graph in S that is, in a precise sense, an approximation of the
timeliness graph of the run. For example, if the timeliness graph contains a
ring, then using an extraction algorithm, all correct processes eventually
converge to the same ring and in this ring all nodes will be correct processes
and all links will be timely. We first present a general extraction algorithm
and then a more specific extraction algorithm that is communication efficient
(i.e., eventually all the messages of the extraction algorithm use only links
of the extracted graph).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1072</identifier>
 <datestamp>2015-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1072</id><created>2010-03-04</created><updated>2015-01-22</updated><authors><author><keyname>Saha</keyname><forenames>Satadal</forenames></author><author><keyname>Basu</keyname><forenames>Subhadip</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author></authors><title>An Offline Technique for Localization of License Plates for Indian
  Commercial Vehicles</title><categories>cs.CV</categories><comments>National Conference on Computing and Communication Systems
  (COCOSYS-09)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic License Plate Recognition (ALPR) is a challenging area of research
due to its importance to variety of commercial applications. The overall
problem may be subdivided into two key modules, firstly, localization of
license plates from vehicle images, and secondly, optical character recognition
of extracted license plates. In the current work, we have concentrated on the
first part of the problem, i.e., localization of license plate regions from
Indian commercial vehicles as a significant step towards development of a
complete ALPR system for Indian vehicles. The technique is based on color based
segmentation of vehicle images and identification of potential license plate
regions. True license plates are finally localized based on four spatial and
horizontal contrast features. The technique successfully localizes the actual
license plates in 73.4% images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1141</identifier>
 <datestamp>2010-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1141</id><created>2010-03-04</created><authors><author><keyname>Turney</keyname><forenames>Peter D.</forenames></author><author><keyname>Pantel</keyname><forenames>Patrick</forenames></author></authors><title>From Frequency to Meaning: Vector Space Models of Semantics</title><categories>cs.CL cs.IR cs.LG</categories><acm-class>H.3.1; I.2.6; I.2.7</acm-class><journal-ref>Journal of Artificial Intelligence Research, (2010), 37, 141-188</journal-ref><doi>10.1613/jair.2934</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computers understand very little of the meaning of human language. This
profoundly limits our ability to give instructions to computers, the ability of
computers to explain their actions to us, and the ability of computers to
analyse and process text. Vector space models (VSMs) of semantics are beginning
to address these limits. This paper surveys the use of VSMs for semantic
processing of text. We organize the literature on VSMs according to the
structure of the matrix in a VSM. There are currently three broad classes of
VSMs, based on term-document, word-context, and pair-pattern matrices, yielding
three classes of applications. We survey a broad range of applications in these
three categories and we take a detailed look at a specific open source project
in each category. Our goal in this survey is to show the breadth of
applications of VSMs for semantics, to provide a new perspective on VSMs for
those who are already familiar with the area, and to provide pointers into the
literature for those who are less familiar with the field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1160</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1160</id><created>2010-03-04</created><updated>2011-07-21</updated><authors><author><keyname>Lu</keyname><forenames>Lunjin</forenames></author><author><keyname>Kim</keyname><forenames>Dae-kyoo</forenames></author></authors><title>Required Behavior of Sequence Diagrams: Semantics and Conformance</title><categories>cs.SE cs.LO cs.PL</categories><comments>16 pages</comments><acm-class>D.2.4; D.3.1; D.3.2; F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequence diagrams are a widely used design notation for describing software
behaviors. Many reusable software artifacts such as design patterns and design
aspects make use of sequence diagrams to describe interaction behaviors. When a
pattern or an aspect is reused in an application, it is important to ensure
that the sequence diagrams for the application conform to the corresponding
sequence diagrams for the pattern or aspect. Reasoning about conformance
relationship between sequence diagrams has not been addressed adequately in
literature. In this paper, we focus on required behavior specified by a UML
sequence diagram. A novel trace semantics is given that captures precisely
required behavior specified by a sequence diagram and a conformance relation
between sequence diagrams is formalized based on the semantics. Properties of
the trace semantics and the conformance relation are studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1164</identifier>
 <datestamp>2010-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1164</id><created>2010-03-05</created><authors><author><keyname>Chermakani</keyname><forenames>Deepak Ponvel</forenames></author></authors><title>Repeating Patterns in Linear Programs that express NP-Complete Problems</title><categories>cs.CC</categories><comments>4 Pages, 1 Generalization of earlier Theorem, and 2 Conjectures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of my recent papers transforms an NP-Complete problem into the question
of whether or not a feasible real solution exists to some Linear Program. The
unique feature of this Linear Program is that though there is no explicit bound
on the minimum required number of linear inequalities, which is most probably
exponential to the size of the NP-Complete problem, the Linear Program can
still be described efficiently. The reason for this efficient description is
that coefficients keep repeating in some pattern, even as the number of
inequalities is conveniently assumed to tend to Infinity. I discuss why this
convenient assumption does not change the feasibility result of the Linear
Program. I conclude with two Conjectures, which might help to make an efficient
decision on the feasibility of this Linear Program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1168</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1168</id><created>2010-03-04</created><updated>2010-06-21</updated><authors><author><keyname>Wang</keyname><forenames>Lei</forenames></author><author><keyname>Zhan</keyname><forenames>Jianfeng</forenames></author><author><keyname>Shi</keyname><forenames>Weisong</forenames></author><author><keyname>Liang</keyname><forenames>Yi</forenames></author><author><keyname>Yuan</keyname><forenames>Lin</forenames></author></authors><title>In Cloud, Do MTC or HTC Service Providers Benefit from the Economies of
  Scale?</title><categories>cs.DC cs.PF</categories><journal-ref>Proceedings of 2nd Workshop on Many-Task Computing on Grids and
  Supercomputers, Co-located with ACM/IEEE SC 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we intend to answer one key question to the success of cloud
computing: in cloud, do many task computing (MTC) or high throughput computing
(HTC) service providers, which offer the corresponding computing service to end
users, benefit from the economies of scale? Our research contributions are
three-fold: first, we propose an innovative usage model, called dynamic service
provision (DSP) model, for MTC or HTC service providers. In the DSP model, the
resource provider provides the service of creating and managing runtime
environments for MTC or HTC service providers, and consolidates heterogeneous
MTC or HTC workloads on the cloud platform; second, according to the DSP model,
we design and implement DawningCloud, which provides automatic management for
heterogeneous workloads; third, a comprehensive evaluation of DawningCloud has
been performed in an emulatation experiment. We found that for typical
workloads, in comparison with the previous two cloud solutions, DawningCloud
saves the resource consumption maximally by 46.4% (HTC) and 74.9% (MTC) for the
service providers, and saves the total resource consumption maximally by 29.7%
for the resource provider. At the same time, comparing with the traditional
solution that provides MTC or HTC services with dedicated systems, DawningCloud
is more cost-effective. To this end, we conclude that for typical MTC and HTC
workloads, on the cloud platform, MTC and HTC service providers and the
resource provider can benefit from the economies of scale.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="11000" completeListSize="102538">1122234|12001</resumptionToken>
</ListRecords>
</OAI-PMH>
